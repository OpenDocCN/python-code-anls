# `.\transformers\models\nougat\convert_nougat_to_hf.py`

```
# è®¾ç½®æ–‡ä»¶ç¼–ç ä¸º UTF-8
# ç‰ˆæƒå£°æ˜
# æ ¹æ®Apacheè®¸å¯è¯2.0ç‰ˆçš„è§„å®šï¼Œæ‚¨ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ï¼Œé™¤ééµå®ˆè¯¥è®¸å¯è¯ã€‚
# æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ç½‘å€è·å–è®¸å¯è¯å‰¯æœ¬ï¼šhttp://www.apache.org/licenses/LICENSE-2.0
# é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æŒ‰"åŸæ ·"åˆ†å‘è½¯ä»¶ï¼Œæ²¡æœ‰ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿æˆ–æ¡ä»¶ã€‚
# è¯·æŸ¥çœ‹ç‰¹å®šè¯­è¨€æ‰€é€‚ç”¨çš„ç‰¹å®šè¯­è¨€ï¼Œä»¥åŠè®¸å¯è¯ä¸‹æ‰€é™åˆ¶çš„æ¡ä»¶ã€‚
"""ä½¿ç”¨åŸå§‹`nougat`åº“è½¬æ¢Nougatæ£€æŸ¥ç‚¹ã€‚URLï¼šhttps://github.com/facebookresearch/nougat/tree/main"""

# å¯¼å…¥å¿…è¦çš„åº“
import argparse
import torch
from huggingface_hub import hf_hub_download
from nougat import NougatModel
from nougat.dataset.rasterize import rasterize_paper
from nougat.utils.checkpoint import get_checkpoint
from PIL import Image
from transformers import (
    DonutSwinConfig,
    DonutSwinModel,
    MBartConfig,
    MBartForCausalLM,
    NougatImageProcessor,
    NougatProcessor,
    NougatTokenizerFast,
    VisionEncoderDecoderModel,
)

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè·å–ç¼–ç å™¨å’Œè§£ç å™¨çš„é…ç½®
def get_configs(model):
    # è·å–åŸå§‹æ¨¡å‹é…ç½®
    original_config = model.config
    # è®¾ç½®ç¼–ç å™¨çš„é…ç½®
    encoder_config = DonutSwinConfig(
        image_size=original_config.input_size,
        patch_size=4,
        depths=original_config.encoder_layer,
        num_heads=[4, 8, 16, 32],
        window_size=original_config.window_size,
        embed_dim=128,
    )
    # è®¾ç½®è§£ç å™¨çš„é…ç½®
    decoder_config = MBartConfig(
        is_decoder=True,
        is_encoder_decoder=False,
        add_cross_attention=True,
        decoder_layers=original_config.decoder_layer,
        max_position_embeddings=original_config.max_position_embeddings,
        vocab_size=len(
            model.decoder.tokenizer
        ),  # è¯æ±‡è¡¨å¤§å°ä¸ºè§£ç å™¨çš„æ ‡è®°æ•°ï¼Œè§hubä¸Šçš„repo(added_tokens.json)æ·»åŠ äº†å‡ ä¸ªç‰¹æ®Šæ ‡è®°
        scale_embedding=True,
        add_final_layer_norm=True,
        tie_word_embeddings=False,
    )
    # è¿”å›ç¼–ç å™¨å’Œè§£ç å™¨é…ç½®
    return encoder_config, decoder_config

# ä»transformers.models.donut.convert_donut_to_pytorch.rename_keyä¸­å¤åˆ¶çš„å‡½æ•°
# ç”¨äºé‡å‘½åé”®å
def rename_key(name):
    if "encoder.model" in name:
        name = name.replace("encoder.model", "encoder")
    if "decoder.model" in name:
        name = name.replace("decoder.model", "decoder")
    if "patch_embed.proj" in name:
        name = name.replace("patch_embed.proj", "embeddings.patch_embeddings.projection")
    if "patch_embed.norm" in name:
        name = name.replace("patch_embed.norm", "embeddings.norm")
    # æ£€æŸ¥å˜é‡åæ˜¯å¦ä»¥"encoder"å¼€å¤´
    if name.startswith("encoder"):
        # å¦‚æœå˜é‡ååŒ…å«"layers"ï¼Œåœ¨å‰é¢æ·»åŠ "encoder."
        if "layers" in name:
            name = "encoder." + name
        # å¦‚æœå˜é‡ååŒ…å«"attn.proj"ï¼Œæ›¿æ¢ä¸º"attention.output.dense"
        if "attn.proj" in name:
            name = name.replace("attn.proj", "attention.output.dense")
        # å¦‚æœå˜é‡ååŒ…å«"attn"ä½†ä¸åŒ…å«"mask"ï¼Œæ›¿æ¢ä¸º"attention.self"
        if "attn" in name and "mask" not in name:
            name = name.replace("attn", "attention.self")
        # å¦‚æœå˜é‡ååŒ…å«"norm1"ï¼Œæ›¿æ¢ä¸º"layernorm_before"
        if "norm1" in name:
            name = name.replace("norm1", "layernorm_before")
        # å¦‚æœå˜é‡ååŒ…å«"norm2"ï¼Œæ›¿æ¢ä¸º"layernorm_after"
        if "norm2" in name:
            name = name.replace("norm2", "layernorm_after")
        # å¦‚æœå˜é‡ååŒ…å«"mlp.fc1"ï¼Œæ›¿æ¢ä¸º"intermediate.dense"
        if "mlp.fc1" in name:
            name = name.replace("mlp.fc1", "intermediate.dense")
        # å¦‚æœå˜é‡ååŒ…å«"mlp.fc2"ï¼Œæ›¿æ¢ä¸º"output.dense"
        if "mlp.fc2" in name:
            name = name.replace("mlp.fc2", "output.dense")

        # å¦‚æœå˜é‡åä¸º"encoder.norm.weight"ï¼Œæ›¿æ¢ä¸º"encoder.layernorm.weight"
        if name == "encoder.norm.weight":
            name = "encoder.layernorm.weight"
        # å¦‚æœå˜é‡åä¸º"encoder.norm.bias"ï¼Œæ›¿æ¢ä¸º"encoder.layernorm.bias"
        if name == "encoder.norm.bias":
            name = "encoder.layernorm.bias"

    # è¿”å›ä¿®æ”¹åçš„å˜é‡å
    return name
# ä»transformers.models.donut.convert_donut_to_pytorch.convert_state_dictä¸­å¤åˆ¶è¿‡æ¥çš„å‡½æ•°
def convert_state_dict(orig_state_dict, model):
    # å¯¹åŸå§‹çŠ¶æ€å­—å…¸çš„é”®è¿›è¡Œæ·±æ‹·è´å¹¶éå†
    for key in orig_state_dict.copy().keys():
        # å¼¹å‡ºåŸå§‹çŠ¶æ€å­—å…¸ä¸­çš„å€¼
        val = orig_state_dict.pop(key)

        # å¦‚æœé”®ä¸­åŒ…å«"qkv"
        if "qkv" in key:
            # é€šè¿‡"."åˆ†å‰²é”®åè·å–å±‚å·å’Œå—å·
            key_split = key.split(".")
            layer_num = int(key_split[3])
            block_num = int(key_split[5])
            # è·å–ç¼–ç å™¨ä¸­ç‰¹å®šä½ç½®çš„æ³¨æ„åŠ›æ¨¡å—çš„ç»´åº¦
            dim = model.encoder.encoder.layers[layer_num].blocks[block_num].attention.self.all_head_size

            # å¦‚æœé”®ä¸­åŒ…å«"weight"
            if "weight" in key:
                # å°†å€¼æŒ‰ç»´åº¦åˆ†å‰²å¹¶èµ‹ç»™ç›¸åº”çš„æŸ¥è¯¢ã€é”®ã€å€¼æƒé‡
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.query.weight"
                ] = val[:dim, :]
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.key.weight"
                ] = val[dim : dim * 2, :]
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.value.weight"
                ] = val[-dim:, :]
            else:
                # å°†å€¼æŒ‰ç»´åº¦åˆ†å‰²å¹¶èµ‹ç»™ç›¸åº”çš„æŸ¥è¯¢ã€é”®ã€å€¼åç½®
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.query.bias"
                ] = val[:dim]
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.key.bias"
                ] = val[dim : dim * 2]
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.value.bias"
                ] = val[-dim:]
        # å¦‚æœé”®ä¸­åŒ…å«"attn_mask"æˆ–é”®ä¸º"encoder.model.norm.weight"æˆ–"encoder.model.norm.bias"
        elif "attn_mask" in key or key in ["encoder.model.norm.weight", "encoder.model.norm.bias"]:
            # HuggingFaceå®ç°ä¸ä½¿ç”¨attn_maskç¼“å†²åŒºï¼Œæ¨¡å‹ä¸ä½¿ç”¨æœ€ç»ˆçš„LayerNormsè¿›è¡Œç¼–ç å™¨
            pass
        else:
            # è½¬æ¢é”®å¹¶èµ‹äºˆæ–°çš„å€¼
            orig_state_dict[rename_key(key)] = val

    return orig_state_dict


def convert_nougat_checkpoint(model_tag, pytorch_dump_folder_path=None, push_to_hub=False):
    # åŠ è½½åŸå§‹æ¨¡å‹
    checkpoint_path = get_checkpoint(None, model_tag)
    original_model = NougatModel.from_pretrained(checkpoint_path)
    original_model.eval()

    # åŠ è½½HuggingFaceæ¨¡å‹
    encoder_config, decoder_config = get_configs(original_model)
    encoder = DonutSwinModel(encoder_config)
    decoder = MBartForCausalLM(decoder_config)
    model = VisionEncoderDecoderModel(encoder=encoder, decoder=decoder)
    model.eval()

    # è·å–åŸå§‹æ¨¡å‹çš„çŠ¶æ€å­—å…¸
    state_dict = original_model.state_dict()
    # è½¬æ¢çŠ¶æ€å­—å…¸å¹¶åŠ è½½åˆ°æ¨¡å‹ä¸­
    new_state_dict = convert_state_dict(state_dict, model)
    model.load_state_dict(new_state_dict)

    # åœ¨PDFä¸ŠéªŒè¯ç»“æœ
    filepath = hf_hub_download(repo_id="ysharma/nougat", filename="input/nougat.pdf", repo_type="space")
    images = rasterize_paper(pdf=filepath, return_pil=True)
    image = Image.open(images[0])

    # åŠ è½½tokenizer
    tokenizer_file = checkpoint_path / "tokenizer.json"
    tokenizer = NougatTokenizerFast(tokenizer_file=str(tokenizer_file))
    tokenizer.pad_token = "<pad>"
    # è®¾ç½®tokenizerçš„ç‰¹æ®Štoken
    tokenizer.bos_token = "<s>"
    tokenizer.eos_token = "</s>"
    tokenizer.unk_token = "<unk>"
    # è®¾ç½®tokenizerçš„æ¨¡å‹æœ€å¤§é•¿åº¦
    tokenizer.model_max_length = original_model.config.max_length
    
    # åˆ›å»ºå›¾åƒå¤„ç†å™¨
    size = {"height": original_model.config.input_size[0], "width": original_model.config.input_size[1]}
    image_processor = NougatImageProcessor(
        do_align_long_axis=original_model.config.align_long_axis,
        size=size,
    )
    # åˆ›å»ºNougatProcessorï¼Œç”¨äºå›¾åƒå’Œæ–‡æœ¬å¤„ç†
    processor = NougatProcessor(image_processor=image_processor, tokenizer=tokenizer)
    
    # éªŒè¯åƒç´ å€¼
    pixel_values = processor(image, return_tensors="pt").pixel_values
    original_pixel_values = original_model.encoder.prepare_input(image).unsqueeze(0)
    assert torch.allclose(original_pixel_values, pixel_values)
    
    # éªŒè¯è¡¥ä¸åµŒå…¥
    original_patch_embed = original_model.encoder.model.patch_embed(pixel_values)
    patch_embeddings, _ = model.encoder.embeddings(pixel_values)
    assert torch.allclose(original_patch_embed, patch_embeddings)
    
    # éªŒè¯ç¼–ç å™¨çš„éšè—çŠ¶æ€
    original_last_hidden_state = original_model.encoder(pixel_values)
    last_hidden_state = model.encoder(pixel_values).last_hidden_state
    assert torch.allclose(original_last_hidden_state, last_hidden_state, atol=1e-2)
    
    # éªŒè¯è¯‘ç å™¨çš„åµŒå…¥
    original_embeddings = original_model.decoder.model.model.decoder.embed_tokens
    embeddings = model.decoder.model.decoder.embed_tokens
    assert torch.allclose(original_embeddings.weight, embeddings.weight, atol=1e-3)
    
    # éªŒè¯è¯‘ç å™¨çš„éšè—çŠ¶æ€
    prompt = "hello world"
    decoder_input_ids = original_model.decoder.tokenizer(
        prompt, add_special_tokens=False, return_tensors="pt"
    ).input_ids
    decoder_attention_mask = torch.ones_like(decoder_input_ids)
    original_logits = original_model(
        image_tensors=pixel_values, decoder_input_ids=decoder_input_ids, attention_mask=decoder_attention_mask
    ).logits
    logits = model(
        pixel_values,
        decoder_input_ids=decoder_input_ids[:, :-1],
        decoder_attention_mask=decoder_attention_mask[:, :-1],
    ).logits
    assert torch.allclose(original_logits, logits, atol=1e-3)
    
    # éªŒè¯ç”Ÿæˆç»“æœ
    outputs = model.generate(
        pixel_values,
        min_length=1,
        max_length=30,
        pad_token_id=tokenizer.pad_token_id,
        eos_token_id=tokenizer.eos_token_id,
        use_cache=True,
        bad_words_ids=[
            [tokenizer.unk_token_id],
        ],
        return_dict_in_generate=True,
        do_sample=False,
    )
    generated = tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)[0]
    
    # å¦‚æœæ¨¡å‹æ ‡è®°ä¸º"0.1.0-base"ï¼Œåˆ™è®¾ç½®æœŸæœ›çš„ç”Ÿæˆç»“æœ
    if model_tag == "0.1.0-base":
        expected_generation = "# Nougat: Neural Optical Understanding for Academic Documents\n\nLukas Blecher\n\nCorrespondence to: lblec"
    elif model_tag == "0.1.0-small":
        # å°†é¢„æœŸç”Ÿæˆçš„æ–‡æœ¬å†…å®¹èµ‹å€¼ç»™å˜é‡ expected_generation
        expected_generation = (
            "# Nougat: Neural Optical Understanding for Academic Documents\n\nLukas Blecher\n\nCorrespondence to: lble"
        )
    else:
        # å¦‚æœ model_tag ä¸æ˜¯ "0.1.0-small"ï¼Œåˆ™æŠ›å‡º ValueError å¼‚å¸¸
        raise ValueError(f"Unexpected model tag: {model_tag}")

    # æ–­è¨€ç”Ÿæˆçš„æ–‡æœ¬ä¸é¢„æœŸç”Ÿæˆçš„æ–‡æœ¬ç›¸åŒ
    assert generated == expected_generation
    # æ‰“å°è¾“å‡º "Looks ok!"
    print("Looks ok!")

    # å¦‚æœ pytorch_dump_folder_path ä¸ä¸º None
    if pytorch_dump_folder_path is not None:
        # æ‰“å°è¾“å‡ºä¿å­˜æ¨¡å‹å’Œå¤„ç†å™¨çš„è·¯å¾„
        print(f"Saving model and processor to {pytorch_dump_folder_path}")
        # å°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        model.save_pretrained(pytorch_dump_folder_path)
        # å°†å¤„ç†å™¨ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        processor.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœ push_to_hub ä¸º True
    if push_to_hub:
        # å®šä¹‰ä¸€ä¸ªå­—å…¸ï¼Œå°† model_tag æ˜ å°„ä¸ºç›¸åº”çš„æ¨¡å‹å
        tag_to_name = {"0.1.0-base": "nougat-base", "0.1.0-small": "nougat-small"}
        # è·å– model_tag å¯¹åº”çš„æ¨¡å‹å
        model_name = tag_to_name[model_tag]

        # å°†æ¨¡å‹æ¨é€åˆ°æ¨¡å‹ä¸­å¿ƒçš„ facebook/{model_name}
        model.push_to_hub(f"facebook/{model_name}")
        # å°†å¤„ç†å™¨æ¨é€åˆ°æ¨¡å‹ä¸­å¿ƒçš„ facebook/{model_name}
        processor.push_to_hub(f"facebook/{model_name}")
if __name__ == "__main__":
    # åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser()
    # æ·»åŠ å¿…éœ€å‚æ•°
    parser.add_argument(
        "--model_tag",
        default="0.1.0-base",
        required=False,
        type=str,
        choices=["0.1.0-base", "0.1.0-small"],
        help="Tag of the original model you'd like to convert.",
    )
    # æ·»åŠ å‚æ•°ï¼šè¾“å‡º PyTorch æ¨¡å‹ç›®å½•è·¯å¾„
    parser.add_argument(
        "--pytorch_dump_folder_path",
        default=None,
        required=False,
        type=str,
        help="Path to the output PyTorch model directory.",
    )
    # æ·»åŠ å‚æ•°ï¼šæ˜¯å¦å°†è½¬æ¢åçš„æ¨¡å‹å’Œå¤„ç†å™¨æ¨é€åˆ° ğŸ¤— hub
    parser.add_argument(
        "--push_to_hub",
        action="store_true",
        help="Whether or not to push the converted model and processor to the ğŸ¤— hub.",
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    # è°ƒç”¨è½¬æ¢å‡½æ•°ï¼Œä¼ å…¥å‚æ•°
    convert_nougat_checkpoint(args.model_tag, args.pytorch_dump_folder_path, args.push_to_hub)
```