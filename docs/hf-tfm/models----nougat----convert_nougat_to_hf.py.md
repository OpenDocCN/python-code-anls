# `.\models\nougat\convert_nougat_to_hf.py`

```
# è®¾ç½®ç¼–ç ä¸º UTF-8ï¼Œç¡®ä¿å¯ä»¥æ­£ç¡®å¤„ç†ä¸­æ–‡ç­‰ç‰¹æ®Šå­—ç¬¦
# ç‰ˆæƒå£°æ˜ï¼ŒæŒ‡æ˜æœ¬ä»£ç çš„ç‰ˆæƒå½’å±äº HuggingFace Inc. å›¢é˜Ÿ
# æ ¹æ® Apache è®¸å¯è¯ 2.0 ç‰ˆæœ¬ä½¿ç”¨æœ¬ä»£ç ï¼Œè¯¦ç»†æ¡æ¬¾å¯å‚è€ƒè®¸å¯è¯é“¾æ¥
"""Convert Nougat checkpoints using the original `nougat` library. URL:
https://github.com/facebookresearch/nougat/tree/main"""
# å¯¼å…¥ argparse æ¨¡å—ï¼Œç”¨äºå¤„ç†å‘½ä»¤è¡Œå‚æ•°
import argparse

# å¯¼å…¥ torch åº“
import torch
# å¯¼å…¥ hf_hub_download å‡½æ•°ï¼Œç”¨äºä» Hugging Face Hub ä¸‹è½½æ¨¡å‹
from huggingface_hub import hf_hub_download
# å¯¼å…¥ NougatModel ç±»ï¼Œç”¨äºåŠ è½½ Nougat æ¨¡å‹
from nougat import NougatModel
# å¯¼å…¥ rasterize_paper å‡½æ•°ï¼Œç”¨äºå°†æ•°æ®è½¬æ¢ä¸ºå…‰æ …åŒ–çš„å›¾åƒæ•°æ®
from nougat.dataset.rasterize import rasterize_paper
# å¯¼å…¥ get_checkpoint å‡½æ•°ï¼Œç”¨äºè·å–æ£€æŸ¥ç‚¹
from nougat.utils.checkpoint import get_checkpoint
# å¯¼å…¥ Image ç±»ï¼Œç”¨äºå¤„ç†å›¾åƒ
from PIL import Image
# å¯¼å…¥ transformers åº“çš„å¤šä¸ªç±»å’Œå‡½æ•°
from transformers import (
    DonutSwinConfig,
    DonutSwinModel,
    MBartConfig,
    MBartForCausalLM,
    NougatImageProcessor,
    NougatProcessor,
    NougatTokenizerFast,
    VisionEncoderDecoderModel,
)

# å®šä¹‰å‡½æ•° get_configsï¼Œç”¨äºæ ¹æ®ç»™å®šæ¨¡å‹è·å–ç¼–ç å™¨å’Œè§£ç å™¨çš„é…ç½®
def get_configs(model):
    # è·å–åŸå§‹æ¨¡å‹çš„é…ç½®
    original_config = model.config

    # å®šä¹‰ç¼–ç å™¨çš„é…ç½®ï¼Œä½¿ç”¨ DonutSwinConfig ç±»
    encoder_config = DonutSwinConfig(
        image_size=original_config.input_size,
        patch_size=4,
        depths=original_config.encoder_layer,
        num_heads=[4, 8, 16, 32],
        window_size=original_config.window_size,
        embed_dim=128,
    )
    
    # å®šä¹‰è§£ç å™¨çš„é…ç½®ï¼Œä½¿ç”¨ MBartConfig ç±»
    decoder_config = MBartConfig(
        is_decoder=True,
        is_encoder_decoder=False,
        add_cross_attention=True,
        decoder_layers=original_config.decoder_layer,
        max_position_embeddings=original_config.max_position_embeddings,
        vocab_size=len(
            model.decoder.tokenizer
        ),  # æ ¹æ®æ¨¡å‹çš„è§£ç å™¨çš„ tokenizer è·å¾—è¯æ±‡è¡¨å¤§å°
        scale_embedding=True,
        add_final_layer_norm=True,
        tie_word_embeddings=False,
    )

    # è¿”å›ç¼–ç å™¨å’Œè§£ç å™¨çš„é…ç½®
    return encoder_config, decoder_config

# å®šä¹‰å‡½æ•° rename_keyï¼Œç”¨äºé‡å‘½åæ¨¡å‹ä¸­çš„ç‰¹å®šé”®åï¼Œä»¥ä¾¿ä¸ PyTorch æ¨¡å‹å…¼å®¹
# è¿™äº›åç§°æ›´æ”¹ä¸»è¦ç”¨äºé€‚åº”ä¸åŒæ¡†æ¶çš„ä¸åŒå‘½åä¹ æƒ¯
def rename_key(name):
    if "encoder.model" in name:
        name = name.replace("encoder.model", "encoder")
    if "decoder.model" in name:
        name = name.replace("decoder.model", "decoder")
    if "patch_embed.proj" in name:
        name = name.replace("patch_embed.proj", "embeddings.patch_embeddings.projection")
    if "patch_embed.norm" in name:
        name = name.replace("patch_embed.norm", "embeddings.norm")
    # æ£€æŸ¥å­—ç¬¦ä¸² name æ˜¯å¦ä»¥ "encoder" å¼€å¤´
    if name.startswith("encoder"):
        # å¦‚æœå­—ç¬¦ä¸² name ä¸­åŒ…å« "layers"
        if "layers" in name:
            # åœ¨å­—ç¬¦ä¸² name å‰åŠ ä¸Š "encoder."
            name = "encoder." + name
        # å¦‚æœå­—ç¬¦ä¸² name ä¸­åŒ…å« "attn.proj"
        if "attn.proj" in name:
            # å°†å­—ç¬¦ä¸² name ä¸­çš„ "attn.proj" æ›¿æ¢ä¸º "attention.output.dense"
            name = name.replace("attn.proj", "attention.output.dense")
        # å¦‚æœå­—ç¬¦ä¸² name ä¸­åŒ…å« "attn" ä¸”ä¸åŒ…å« "mask"
        if "attn" in name and "mask" not in name:
            # å°†å­—ç¬¦ä¸² name ä¸­çš„ "attn" æ›¿æ¢ä¸º "attention.self"
            name = name.replace("attn", "attention.self")
        # å¦‚æœå­—ç¬¦ä¸² name ä¸­åŒ…å« "norm1"
        if "norm1" in name:
            # å°†å­—ç¬¦ä¸² name ä¸­çš„ "norm1" æ›¿æ¢ä¸º "layernorm_before"
            name = name.replace("norm1", "layernorm_before")
        # å¦‚æœå­—ç¬¦ä¸² name ä¸­åŒ…å« "norm2"
        if "norm2" in name:
            # å°†å­—ç¬¦ä¸² name ä¸­çš„ "norm2" æ›¿æ¢ä¸º "layernorm_after"
            name = name.replace("norm2", "layernorm_after")
        # å¦‚æœå­—ç¬¦ä¸² name ä¸­åŒ…å« "mlp.fc1"
        if "mlp.fc1" in name:
            # å°†å­—ç¬¦ä¸² name ä¸­çš„ "mlp.fc1" æ›¿æ¢ä¸º "intermediate.dense"
            name = name.replace("mlp.fc1", "intermediate.dense")
        # å¦‚æœå­—ç¬¦ä¸² name ä¸­åŒ…å« "mlp.fc2"
        if "mlp.fc2" in name:
            # å°†å­—ç¬¦ä¸² name ä¸­çš„ "mlp.fc2" æ›¿æ¢ä¸º "output.dense"
            name = name.replace("mlp.fc2", "output.dense")

        # å¦‚æœå­—ç¬¦ä¸² name ç­‰äº "encoder.norm.weight"
        if name == "encoder.norm.weight":
            # å°†å­—ç¬¦ä¸² name æ›¿æ¢ä¸º "encoder.layernorm.weight"
            name = "encoder.layernorm.weight"
        # å¦‚æœå­—ç¬¦ä¸² name ç­‰äº "encoder.norm.bias"
        if name == "encoder.norm.bias":
            # å°†å­—ç¬¦ä¸² name æ›¿æ¢ä¸º "encoder.layernorm.bias"
            name = "encoder.layernorm.bias"

    # è¿”å›ç»è¿‡å¤„ç†çš„å­—ç¬¦ä¸² name
    return name
# ä» transformers.models.donut.convert_donut_to_pytorch.convert_state_dict å¤åˆ¶çš„å‡½æ•°ï¼Œç”¨äºå°†åŸå§‹çŠ¶æ€å­—å…¸è½¬æ¢ä¸º PyTorch æ¨¡å‹çš„çŠ¶æ€å­—å…¸
def convert_state_dict(orig_state_dict, model):
    # éå†åŸå§‹çŠ¶æ€å­—å…¸çš„å‰¯æœ¬çš„é”®
    for key in orig_state_dict.copy().keys():
        # å¼¹å‡ºå½“å‰é”®å¯¹åº”çš„å€¼
        val = orig_state_dict.pop(key)

        # å¦‚æœé”®åä¸­åŒ…å« "qkv"
        if "qkv" in key:
            # æ‹†åˆ†é”®åä¸ºåˆ—è¡¨
            key_split = key.split(".")
            # è·å–å±‚ç¼–å·å’Œå—ç¼–å·
            layer_num = int(key_split[3])
            block_num = int(key_split[5])
            # è·å–å½“å‰è‡ªæ³¨æ„åŠ›çš„ç»´åº¦
            dim = model.encoder.encoder.layers[layer_num].blocks[block_num].attention.self.all_head_size

            # å¦‚æœé”®ååŒ…å« "weight"
            if "weight" in key:
                # æ›´æ–°çŠ¶æ€å­—å…¸ï¼Œè®¾ç½®æŸ¥è¯¢æƒé‡çš„æ–°é”®å€¼å¯¹
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.query.weight"
                ] = val[:dim, :]
                # æ›´æ–°çŠ¶æ€å­—å…¸ï¼Œè®¾ç½®é”®æƒé‡çš„æ–°é”®å€¼å¯¹
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.key.weight"
                ] = val[dim : dim * 2, :]
                # æ›´æ–°çŠ¶æ€å­—å…¸ï¼Œè®¾ç½®å€¼æƒé‡çš„æ–°é”®å€¼å¯¹
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.value.weight"
                ] = val[-dim:, :]
            else:
                # æ›´æ–°çŠ¶æ€å­—å…¸ï¼Œè®¾ç½®æŸ¥è¯¢åç½®çš„æ–°é”®å€¼å¯¹
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.query.bias"
                ] = val[:dim]
                # æ›´æ–°çŠ¶æ€å­—å…¸ï¼Œè®¾ç½®é”®åç½®çš„æ–°é”®å€¼å¯¹
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.key.bias"
                ] = val[dim : dim * 2]
                # æ›´æ–°çŠ¶æ€å­—å…¸ï¼Œè®¾ç½®å€¼åç½®çš„æ–°é”®å€¼å¯¹
                orig_state_dict[
                    f"encoder.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.value.bias"
                ] = val[-dim:]
        # å¦‚æœé”®åä¸­åŒ…å« "attn_mask" æˆ–è€…æ˜¯ç‰¹å®šçš„é”®ååˆ—è¡¨
        elif "attn_mask" in key or key in ["encoder.model.norm.weight", "encoder.model.norm.bias"]:
            # HuggingFace å®ç°ä¸ä½¿ç”¨ attn_mask ç¼“å†²åŒºï¼Œä¸”æ¨¡å‹ä¸ä½¿ç”¨ç¼–ç å™¨çš„æœ€ç»ˆ LayerNorm
            # è·³è¿‡å¤„ç†è¿™äº›é”®
            pass
        else:
            # ä½¿ç”¨è‡ªå®šä¹‰çš„å‡½æ•°å¤„ç†é”®åï¼Œç„¶åæ›´æ–°çŠ¶æ€å­—å…¸
            orig_state_dict[rename_key(key)] = val

    # è¿”å›æ›´æ–°åçš„åŸå§‹çŠ¶æ€å­—å…¸
    return orig_state_dict


# æ ¹æ®æ¨¡å‹æ ‡ç­¾å’Œå¯èƒ½çš„ PyTorch å¯¼å‡ºæ–‡ä»¶å¤¹è·¯å¾„ï¼Œä»¥åŠæ˜¯å¦æ¨é€åˆ° Hubï¼Œè½¬æ¢ Nougat æ£€æŸ¥ç‚¹
def convert_nougat_checkpoint(model_tag, pytorch_dump_folder_path=None, push_to_hub=False):
    # è·å–æ£€æŸ¥ç‚¹è·¯å¾„
    checkpoint_path = get_checkpoint(None, model_tag)
    # ä»é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„åŠ è½½åŸå§‹æ¨¡å‹
    original_model = NougatModel.from_pretrained(checkpoint_path)
    # å°†åŸå§‹æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    original_model.eval()

    # åŠ è½½ HuggingFace æ¨¡å‹çš„ç¼–ç å™¨å’Œè§£ç å™¨é…ç½®
    encoder_config, decoder_config = get_configs(original_model)
    # åˆ›å»º DonutSwinModel ç¼–ç å™¨å’Œ MBartForCausalLM è§£ç å™¨
    encoder = DonutSwinModel(encoder_config)
    decoder = MBartForCausalLM(decoder_config)
    # åˆ›å»º VisionEncoderDecoderModel æ¨¡å‹ï¼Œè®¾ç½®ç¼–ç å™¨å’Œè§£ç å™¨
    model = VisionEncoderDecoderModel(encoder=encoder, decoder=decoder)
    # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()

    # è·å–åŸå§‹æ¨¡å‹çš„çŠ¶æ€å­—å…¸
    state_dict = original_model.state_dict()
    # å°†åŸå§‹çŠ¶æ€å­—å…¸è½¬æ¢ä¸ºæ–°çš„çŠ¶æ€å­—å…¸
    new_state_dict = convert_state_dict(state_dict, model)
    # ä½¿ç”¨æ–°çš„çŠ¶æ€å­—å…¸åŠ è½½æ¨¡å‹çš„å‚æ•°
    model.load_state_dict(new_state_dict)

    # åœ¨ PDF ä¸ŠéªŒè¯ç»“æœ
    filepath = hf_hub_download(repo_id="ysharma/nougat", filename="input/nougat.pdf", repo_type="space")
    # å°† PDF æ¸²æŸ“ä¸ºå›¾åƒï¼Œå¹¶è¿”å› PIL å›¾åƒåˆ—è¡¨
    images = rasterize_paper(pdf=filepath, return_pil=True)
    # æ‰“å¼€ç¬¬ä¸€å¼ å›¾åƒ
    image = Image.open(images[0])

    # åŠ è½½ NougatTokenizerFastï¼Œè®¾ç½® tokenizer æ–‡ä»¶è·¯å¾„å’Œå¡«å……æ ‡è®°
    tokenizer_file = checkpoint_path / "tokenizer.json"
    tokenizer = NougatTokenizerFast(tokenizer_file=str(tokenizer_file))
    tokenizer.pad_token = "<pad>"
    # è®¾ç½® tokenizer çš„ç‰¹æ®Šç¬¦å·
    tokenizer.bos_token = "<s>"  # å¼€å§‹ç¬¦å·
    tokenizer.eos_token = "</s>"  # ç»“æŸç¬¦å·
    tokenizer.unk_token = "<unk>"  # æœªçŸ¥ç¬¦å·
    # è®¾ç½® tokenizer çš„æœ€å¤§æ¨¡å‹é•¿åº¦ä¸ºåŸå§‹æ¨¡å‹çš„æœ€å¤§é•¿åº¦
    tokenizer.model_max_length = original_model.config.max_length

    # åˆ›å»ºå›¾åƒå¤„ç†å™¨å¯¹è±¡ï¼Œé…ç½®å¯¹é½é•¿è½´å’Œå¤§å°
    size = {"height": original_model.config.input_size[0], "width": original_model.config.input_size[1]}
    image_processor = NougatImageProcessor(
        do_align_long_axis=original_model.config.align_long_axis,
        size=size,
    )
    # åˆ›å»ºå¤„ç†å™¨å¯¹è±¡ï¼Œæ•´åˆå›¾åƒå¤„ç†å™¨å’Œ tokenizer
    processor = NougatProcessor(image_processor=image_processor, tokenizer=tokenizer)

    # éªŒè¯åƒç´ å€¼
    pixel_values = processor(image, return_tensors="pt").pixel_values
    # å‡†å¤‡è¾“å…¥å›¾åƒçš„åƒç´ å€¼å¹¶å±•å¼€ä¸ºå¼ é‡
    original_pixel_values = original_model.encoder.prepare_input(image).unsqueeze(0)

    # æ–­è¨€æ£€æŸ¥åŸå§‹åƒç´ å€¼ä¸å¤„ç†åçš„åƒç´ å€¼æ˜¯å¦ç›¸ç­‰
    assert torch.allclose(original_pixel_values, pixel_values)

    # éªŒè¯è¡¥ä¸åµŒå…¥
    original_patch_embed = original_model.encoder.model.patch_embed(pixel_values)
    # è®¡ç®—æ¨¡å‹çš„è¡¥ä¸åµŒå…¥å’Œè¡¥ä¸åµŒå…¥å™¨çš„ç»“æœ
    patch_embeddings, _ = model.encoder.embeddings(pixel_values)
    # æ–­è¨€æ£€æŸ¥åŸå§‹è¡¥ä¸åµŒå…¥å’Œæ¨¡å‹è¡¥ä¸åµŒå…¥æ˜¯å¦ç›¸ç­‰
    assert torch.allclose(original_patch_embed, patch_embeddings)

    # éªŒè¯ç¼–ç å™¨éšè—çŠ¶æ€
    original_last_hidden_state = original_model.encoder(pixel_values)
    # è®¡ç®—æ¨¡å‹çš„ç¼–ç å™¨æœ€åéšè—çŠ¶æ€
    last_hidden_state = model.encoder(pixel_values).last_hidden_state
    # æ–­è¨€æ£€æŸ¥åŸå§‹ç¼–ç å™¨éšè—çŠ¶æ€å’Œæ¨¡å‹ç¼–ç å™¨éšè—çŠ¶æ€æ˜¯å¦ç›¸ç­‰ï¼Œå®¹å¿åº¦ä¸º 1e-2
    assert torch.allclose(original_last_hidden_state, last_hidden_state, atol=1e-2)

    # æ³¨æ„ï¼šåŸå§‹æ¨¡å‹åœ¨è§£ç å™¨çš„åµŒå…¥ä¸­ä¸ä½¿ç”¨ç»‘å®šæƒé‡
    # æ£€æŸ¥åŸå§‹æ¨¡å‹å’Œå½“å‰æ¨¡å‹çš„è§£ç å™¨åµŒå…¥æƒé‡æ˜¯å¦ç›¸ç­‰ï¼Œå®¹å¿åº¦ä¸º 1e-3
    original_embeddings = original_model.decoder.model.model.decoder.embed_tokens
    embeddings = model.decoder.model.decoder.embed_tokens
    assert torch.allclose(original_embeddings.weight, embeddings.weight, atol=1e-3)

    # éªŒè¯è§£ç å™¨éšè—çŠ¶æ€
    prompt = "hello world"
    # ä½¿ç”¨åŸå§‹æ¨¡å‹çš„ tokenizer å¯¹æç¤ºè¿›è¡Œç¼–ç 
    decoder_input_ids = original_model.decoder.tokenizer(
        prompt, add_special_tokens=False, return_tensors="pt"
    ).input_ids
    decoder_attention_mask = torch.ones_like(decoder_input_ids)
    # è®¡ç®—åŸå§‹æ¨¡å‹å’Œå½“å‰æ¨¡å‹çš„ logits
    original_logits = original_model(
        image_tensors=pixel_values, decoder_input_ids=decoder_input_ids, attention_mask=decoder_attention_mask
    ).logits
    logits = model(
        pixel_values,
        decoder_input_ids=decoder_input_ids[:, :-1],
        decoder_attention_mask=decoder_attention_mask[:, :-1],
    ).logits
    # æ–­è¨€æ£€æŸ¥åŸå§‹ logits å’Œå½“å‰ logits æ˜¯å¦ç›¸ç­‰ï¼Œå®¹å¿åº¦ä¸º 1e-3
    assert torch.allclose(original_logits, logits, atol=1e-3)

    # éªŒè¯ç”Ÿæˆç»“æœ
    outputs = model.generate(
        pixel_values,
        min_length=1,
        max_length=30,
        pad_token_id=tokenizer.pad_token_id,
        eos_token_id=tokenizer.eos_token_id,
        use_cache=True,
        bad_words_ids=[
            [tokenizer.unk_token_id],
        ],
        return_dict_in_generate=True,
        do_sample=False,
    )
    # è§£ç ç”Ÿæˆçš„æ–‡æœ¬å¹¶è·³è¿‡ç‰¹æ®Šç¬¦å·
    generated = tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)[0]

    # å¦‚æœæ¨¡å‹ç‰ˆæœ¬æ ‡ç­¾æ˜¯ "0.1.0-base"ï¼Œåˆ™éªŒè¯ç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦ç¬¦åˆé¢„æœŸ
    if model_tag == "0.1.0-base":
        expected_generation = "# Nougat: Neural Optical Understanding for Academic Documents\n\nLukas Blecher\n\nCorrespondence to: lblec"
    # å¦‚æœæ¨¡å‹æ ‡ç­¾ä¸º "0.1.0-small"ï¼Œè®¾ç½®æœŸæœ›ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
    elif model_tag == "0.1.0-small":
        expected_generation = (
            "# Nougat: Neural Optical Understanding for Academic Documents\n\nLukas Blecher\n\nCorrespondence to: lble"
        )
    else:
        # å¦‚æœæ¨¡å‹æ ‡ç­¾ä¸æ˜¯å·²çŸ¥çš„ç‰ˆæœ¬ï¼Œåˆ™æŠ›å‡ºå€¼é”™è¯¯å¼‚å¸¸
        raise ValueError(f"Unexpected model tag: {model_tag}")

    # æ–­è¨€ç”Ÿæˆçš„æ–‡æœ¬ä¸æœŸæœ›çš„ç”Ÿæˆæ–‡æœ¬ç›¸ç­‰ï¼Œç”¨äºéªŒè¯ç”Ÿæˆç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
    assert generated == expected_generation
    # æ‰“å°ç¡®è®¤ä¿¡æ¯ï¼Œè¡¨ç¤ºç”Ÿæˆçš„æ–‡æœ¬ç¬¦åˆé¢„æœŸ
    print("Looks ok!")

    # å¦‚æœæŒ‡å®šäº† PyTorch æ¨¡å‹ä¿å­˜è·¯å¾„
    if pytorch_dump_folder_path is not None:
        # æ‰“å°ä¿å­˜æ¨¡å‹å’Œå¤„ç†å™¨åˆ°æŒ‡å®šè·¯å¾„çš„æ¶ˆæ¯
        print(f"Saving model and processor to {pytorch_dump_folder_path}")
        # å°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        model.save_pretrained(pytorch_dump_folder_path)
        # å°†å¤„ç†å™¨ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        processor.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœéœ€è¦æ¨é€åˆ° Hub
    if push_to_hub:
        # å®šä¹‰æ¨¡å‹æ ‡ç­¾åˆ° Hub ä»“åº“åç§°çš„æ˜ å°„
        tag_to_name = {"0.1.0-base": "nougat-base", "0.1.0-small": "nougat-small"}
        # è·å–å½“å‰æ¨¡å‹æ ‡ç­¾å¯¹åº”çš„ Hub ä»“åº“åç§°
        model_name = tag_to_name[model_tag]

        # å°†æ¨¡å‹æ¨é€åˆ° Facebook Hub ä¸­å¯¹åº”çš„ä»“åº“
        model.push_to_hub(f"facebook/{model_name}")
        # å°†å¤„ç†å™¨æ¨é€åˆ° Facebook Hub ä¸­å¯¹åº”çš„ä»“åº“
        processor.push_to_hub(f"facebook/{model_name}")
if __name__ == "__main__":
    # å¦‚æœä½œä¸ºä¸»ç¨‹åºæ‰§è¡Œï¼Œåˆ™å¼€å§‹æ‰§è¡Œä»¥ä¸‹ä»£ç 

    parser = argparse.ArgumentParser()
    # åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡

    # Required parameters
    parser.add_argument(
        "--model_tag",
        default="0.1.0-base",
        required=False,
        type=str,
        choices=["0.1.0-base", "0.1.0-small"],
        help="Tag of the original model you'd like to convert.",
    )
    # æ·»åŠ ä¸€ä¸ªå¿…éœ€çš„å‚æ•° --model_tagï¼Œç”¨äºæŒ‡å®šè¦è½¬æ¢çš„åŸå§‹æ¨¡å‹çš„æ ‡ç­¾

    parser.add_argument(
        "--pytorch_dump_folder_path",
        default=None,
        required=False,
        type=str,
        help="Path to the output PyTorch model directory.",
    )
    # æ·»åŠ ä¸€ä¸ªå‚æ•° --pytorch_dump_folder_pathï¼Œç”¨äºæŒ‡å®šè¾“å‡ºçš„ PyTorch æ¨¡å‹ç›®å½•çš„è·¯å¾„

    parser.add_argument(
        "--push_to_hub",
        action="store_true",
        help="Whether or not to push the converted model and processor to the ğŸ¤— hub.",
    )
    # æ·»åŠ ä¸€ä¸ªå‚æ•° --push_to_hubï¼Œæ˜¯ä¸€ä¸ªå¸ƒå°”æ ‡å¿—ï¼Œç”¨äºæŒ‡ç¤ºæ˜¯å¦å°†è½¬æ¢åçš„æ¨¡å‹å’Œå¤„ç†å™¨æ¨é€åˆ° ğŸ¤— hub

    args = parser.parse_args()
    # è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å­˜å‚¨åˆ° args å¯¹è±¡ä¸­

    convert_nougat_checkpoint(args.model_tag, args.pytorch_dump_folder_path, args.push_to_hub)
    # è°ƒç”¨å‡½æ•° convert_nougat_checkpointï¼Œä¼ å…¥è§£æåçš„å‚æ•° args ä¸­çš„ç›¸å…³ä¿¡æ¯ä½œä¸ºå‚æ•°
```