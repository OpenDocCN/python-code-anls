# `.\testing_utils.py`

```
# å¯¼å…¥å¿…è¦çš„æ ‡å‡†åº“å’Œç¬¬ä¸‰æ–¹åº“
import collections  # æä¾›é¢å¤–çš„æ•°æ®å®¹å™¨ï¼Œå¦‚dequeï¼ˆåŒç«¯é˜Ÿåˆ—ï¼‰
import contextlib  # æä¾›ç”¨äºç®¡ç†ä¸Šä¸‹æ–‡çš„å·¥å…·
import doctest  # æä¾›ç”¨äºè¿è¡Œæ–‡æ¡£æµ‹è¯•çš„æ¨¡å—
import functools  # æä¾›å‡½æ•°å¼ç¼–ç¨‹çš„å·¥å…·ï¼Œå¦‚partialå‡½æ•°åº”ç”¨
import importlib  # æä¾›ç”¨äºåŠ¨æ€åŠ è½½æ¨¡å—çš„å·¥å…·
import inspect  # æä¾›ç”¨äºæ£€æŸ¥æºä»£ç çš„å·¥å…·
import logging  # æä¾›ç”¨äºè®°å½•æ—¥å¿—æ¶ˆæ¯çš„åŠŸèƒ½
import multiprocessing  # æä¾›ç”¨äºå¤šè¿›ç¨‹ç¼–ç¨‹çš„å·¥å…·
import os  # æä¾›ä¸æ“ä½œç³»ç»Ÿäº¤äº’çš„åŠŸèƒ½
import re  # æä¾›æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼çš„å·¥å…·
import shlex  # æä¾›ç”¨äºè§£æå’Œæ“ä½œå‘½ä»¤è¡Œå­—ç¬¦ä¸²çš„å·¥å…·
import shutil  # æä¾›é«˜çº§æ–‡ä»¶æ“ä½œåŠŸèƒ½çš„å·¥å…·
import subprocess  # æä¾›ç”¨äºåˆ›å»ºå­è¿›ç¨‹çš„åŠŸèƒ½
import sys  # æä¾›ä¸Pythonè§£é‡Šå™¨äº¤äº’çš„åŠŸèƒ½
import tempfile  # æä¾›åˆ›å»ºä¸´æ—¶æ–‡ä»¶å’Œç›®å½•çš„åŠŸèƒ½
import time  # æä¾›æ—¶é—´ç›¸å…³çš„åŠŸèƒ½
import unittest  # æä¾›ç”¨äºç¼–å†™å’Œè¿è¡Œå•å…ƒæµ‹è¯•çš„å·¥å…·
from collections import defaultdict  # æä¾›é»˜è®¤å­—å…¸çš„åŠŸèƒ½
from collections.abc import Mapping  # æä¾›æŠ½è±¡åŸºç±»ï¼Œç”¨äºæ£€æŸ¥æ˜ å°„ç±»å‹
from functools import wraps  # æä¾›ç”¨äºåˆ›å»ºè£…é¥°å™¨çš„å·¥å…·
from io import StringIO  # æä¾›å†…å­˜ä¸­æ–‡æœ¬I/Oçš„å·¥å…·
from pathlib import Path  # æä¾›é¢å‘å¯¹è±¡çš„è·¯å¾„æ“ä½œåŠŸèƒ½
from typing import Callable, Dict, Iterable, Iterator, List, Optional, Union  # æä¾›ç±»å‹æç¤ºæ”¯æŒ
from unittest import mock  # æä¾›ç”¨äºæ¨¡æ‹Ÿæµ‹è¯•çš„å·¥å…·
from unittest.mock import patch  # æä¾›ç”¨äºæ¨¡æ‹Ÿæµ‹è¯•çš„å·¥å…·

import urllib3  # æä¾›HTTPå®¢æˆ·ç«¯çš„åŠŸèƒ½

from transformers import logging as transformers_logging  # å¯¼å…¥transformersåº“ä¸­çš„loggingæ¨¡å—

from .integrations import (  # å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ä¸­çš„ä¸€ç³»åˆ—é›†æˆæ£€æŸ¥å‡½æ•°
    is_clearml_available,
    is_optuna_available,
    is_ray_available,
    is_sigopt_available,
    is_tensorboard_available,
    is_wandb_available,
)
from .integrations.deepspeed import is_deepspeed_available  # å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ä¸­çš„æ·±åº¦åŠ é€Ÿé›†æˆæ£€æŸ¥å‡½æ•°
from .utils import (  # å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ä¸­çš„ä¸€ç³»åˆ—å®ç”¨å·¥å…·æ£€æŸ¥å‡½æ•°
    is_accelerate_available,
    is_apex_available,
    is_aqlm_available,
    is_auto_awq_available,
    is_auto_gptq_available,
    is_bitsandbytes_available,
    is_bs4_available,
    is_cv2_available,
    is_cython_available,
    is_decord_available,
    is_detectron2_available,
    is_essentia_available,
    is_faiss_available,
    is_flash_attn_2_available,
    is_flax_available,
    is_fsdp_available,
    is_ftfy_available,
    is_g2p_en_available,
    is_galore_torch_available,
    is_ipex_available,
    is_jieba_available,
    is_jinja_available,
    is_jumanpp_available,
    is_keras_nlp_available,
    is_levenshtein_available,
    is_librosa_available,
    is_natten_available,
    is_nltk_available,
    is_onnx_available,
    is_optimum_available,
    is_pandas_available,
    is_peft_available,
    is_phonemizer_available,
    is_pretty_midi_available,
    is_pyctcdecode_available,
    is_pytesseract_available,
    is_pytest_available,
    is_pytorch_quantization_available,
    is_quanto_available,
    is_rjieba_available,
    is_sacremoses_available,
    is_safetensors_available,
    is_scipy_available,
    is_sentencepiece_available,
    is_seqio_available,
    is_soundfile_availble,
    is_spacy_available,
    is_sudachi_available,
    is_sudachi_projection_available,
    is_tensorflow_probability_available,
    is_tensorflow_text_available,
    is_tf2onnx_available,
    is_tf_available,
    is_timm_available,
    is_tokenizers_available,
    is_torch_available,
)
    # æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒ Torch çš„ BF16 æ•°æ®ç±»å‹
    is_torch_bf16_available_on_device,
    # æ£€æŸ¥å½“å‰ CPU æ˜¯å¦æ”¯æŒ Torch çš„ BF16 æ•°æ®ç±»å‹
    is_torch_bf16_cpu_available,
    # æ£€æŸ¥å½“å‰ GPU æ˜¯å¦æ”¯æŒ Torch çš„ BF16 æ•°æ®ç±»å‹
    is_torch_bf16_gpu_available,
    # æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒ Torch çš„ FP16 æ•°æ®ç±»å‹
    is_torch_fp16_available_on_device,
    # æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒ Torch çš„ NeuronCore åŠ é€Ÿå™¨
    is_torch_neuroncore_available,
    # æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒ Torch çš„ NPU åŠ é€Ÿå™¨
    is_torch_npu_available,
    # æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒ Torch çš„ SDPA åŠ é€Ÿå™¨
    is_torch_sdpa_available,
    # æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒ Torch çš„ TensorRT FX åŠ é€Ÿå™¨
    is_torch_tensorrt_fx_available,
    # æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒ Torch çš„ TF32 æ•°æ®ç±»å‹
    is_torch_tf32_available,
    # æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒ Torch çš„ XLA åŠ é€Ÿå™¨
    is_torch_xla_available,
    # æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒ Torch çš„ XPU åŠ é€Ÿå™¨
    is_torch_xpu_available,
    # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦æ”¯æŒ Torch Audio åº“
    is_torchaudio_available,
    # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦æ”¯æŒ TorchDynamo åº“
    is_torchdynamo_available,
    # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦æ”¯æŒ TorchVision åº“
    is_torchvision_available,
    # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦æ”¯æŒ Torch çš„ Vision æ‰©å±•
    is_vision_available,
    # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¸ƒå°”å€¼ï¼ˆæ”¯æŒ"true", "false", "yes", "no", "1", "0"ç­‰ï¼‰
    strtobool,
# å¦‚æœåŠ é€ŸåŠŸèƒ½å¯ç”¨ï¼Œåˆ™ä» accelerate.state ä¸­å¯¼å…¥ AcceleratorState å’Œ PartialState ç±»
if is_accelerate_available():
    from accelerate.state import AcceleratorState, PartialState


# å¦‚æœ pytest å¯ç”¨ï¼Œåˆ™ä» _pytest.doctest ä¸­å¯¼å…¥ä»¥ä¸‹æ¨¡å—
# Module: ç”¨äºè¡¨ç¤º Python æ¨¡å—çš„ç±»
# _get_checker: è·å– doctest çš„æ£€æŸ¥å™¨
# _get_continue_on_failure: è·å– doctest çš„ç»§ç»­å¤±è´¥é€‰é¡¹
# _get_runner: è·å– doctest çš„è¿è¡Œå™¨
# _is_mocked: æ£€æŸ¥æ˜¯å¦æ¨¡æ‹Ÿäº†å¯¹è±¡
# _patch_unwrap_mock_aware: è§£é™¤ Mock å¯¹è±¡æ„ŸçŸ¥çš„è¡¥ä¸
# get_optionflags: è·å– doctest çš„é€‰é¡¹æ ‡å¿—
from _pytest.doctest import (
    Module,
    _get_checker,
    _get_continue_on_failure,
    _get_runner,
    _is_mocked,
    _patch_unwrap_mock_aware,
    get_optionflags,
)

# å¦‚æœ pytest ä¸å¯ç”¨ï¼Œåˆ™å°† Module å’Œ DoctestItem è®¾ç½®ä¸º object ç±»å‹
else:
    Module = object
    DoctestItem = object


# å®šä¹‰äº†ä¸€ä¸ªå°å‹æ¨¡å‹çš„æ ‡è¯†ç¬¦å­—ç¬¦ä¸²
SMALL_MODEL_IDENTIFIER = "julien-c/bert-xsmall-dummy"

# ç”¨äºæµ‹è¯•è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹çš„æ ‡è¯†ç¬¦
DUMMY_UNKNOWN_IDENTIFIER = "julien-c/dummy-unknown"
DUMMY_DIFF_TOKENIZER_IDENTIFIER = "julien-c/dummy-diff-tokenizer"

# ç”¨äºæµ‹è¯• Hub çš„ç”¨æˆ·å’Œç«¯ç‚¹
USER = "__DUMMY_TRANSFORMERS_USER__"
ENDPOINT_STAGING = "https://hub-ci.huggingface.co"

# ä»…åœ¨å—æ§çš„ CI å®ä¾‹ä¸­å¯ç”¨ï¼Œç”¨äºæµ‹è¯•ç”¨çš„ä»¤ç‰Œ
TOKEN = "hf_94wBhPGp6KrrTH3KDchhKpRxZwd6dmHWLL"


# ä»ç¯å¢ƒå˜é‡ä¸­è§£æå¸ƒå°”ç±»å‹çš„æ ‡å¿—
def parse_flag_from_env(key, default=False):
    try:
        value = os.environ[key]
    except KeyError:
        # å¦‚æœ KEY æœªè®¾ç½®ï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼ `default`
        _value = default
    else:
        # å¦‚æœ KEY å·²è®¾ç½®ï¼Œåˆ™å°è¯•å°†å…¶è½¬æ¢ä¸º True æˆ– False
        try:
            _value = strtobool(value)
        except ValueError:
            # å¦‚æœå€¼ä¸æ˜¯ `yes` æˆ– `no`ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
            raise ValueError(f"If set, {key} must be yes or no.")
    return _value


# ä»ç¯å¢ƒå˜é‡ä¸­è§£ææ•´æ•°ç±»å‹çš„å€¼
def parse_int_from_env(key, default=None):
    try:
        value = os.environ[key]
    except KeyError:
        _value = default
    else:
        try:
            _value = int(value)
        except ValueError:
            # å¦‚æœå€¼ä¸æ˜¯æ•´æ•°ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
            raise ValueError(f"If set, {key} must be a int.")
    return _value


# æ ¹æ®ç¯å¢ƒå˜é‡ `RUN_SLOW` è§£ææ˜¯å¦è¿è¡Œæ…¢é€Ÿæµ‹è¯•çš„æ ‡å¿—
_run_slow_tests = parse_flag_from_env("RUN_SLOW", default=False)
# æ ¹æ®ç¯å¢ƒå˜é‡ `RUN_PT_TF_CROSS_TESTS` è§£ææ˜¯å¦è¿è¡Œ PyTorch å’Œ TensorFlow äº¤å‰æµ‹è¯•çš„æ ‡å¿—
_run_pt_tf_cross_tests = parse_flag_from_env("RUN_PT_TF_CROSS_TESTS", default=True)
# æ ¹æ®ç¯å¢ƒå˜é‡ `RUN_PT_FLAX_CROSS_TESTS` è§£ææ˜¯å¦è¿è¡Œ PyTorch å’Œ Flax äº¤å‰æµ‹è¯•çš„æ ‡å¿—
_run_pt_flax_cross_tests = parse_flag_from_env("RUN_PT_FLAX_CROSS_TESTS", default=True)
# æ ¹æ®ç¯å¢ƒå˜é‡ `RUN_CUSTOM_TOKENIZERS` è§£ææ˜¯å¦è¿è¡Œè‡ªå®šä¹‰åˆ†è¯å™¨æµ‹è¯•çš„æ ‡å¿—
_run_custom_tokenizers = parse_flag_from_env("RUN_CUSTOM_TOKENIZERS", default=False)
# æ ¹æ®ç¯å¢ƒå˜é‡ `HUGGINGFACE_CO_STAGING` è§£ææ˜¯å¦è¿è¡Œåœ¨ Hugging Face CO é¢„å‘å¸ƒç¯å¢ƒä¸­çš„æ ‡å¿—
_run_staging = parse_flag_from_env("HUGGINGFACE_CO_STAGING", default=False)
# æ ¹æ®ç¯å¢ƒå˜é‡ `TF_GPU_MEMORY_LIMIT` è§£æ TensorFlow GPU å†…å­˜é™åˆ¶çš„å€¼
_tf_gpu_memory_limit = parse_int_from_env("TF_GPU_MEMORY_LIMIT", default=None)
# æ ¹æ®ç¯å¢ƒå˜é‡ `RUN_PIPELINE_TESTS` è§£ææ˜¯å¦è¿è¡Œç®¡é“æµ‹è¯•çš„æ ‡å¿—
_run_pipeline_tests = parse_flag_from_env("RUN_PIPELINE_TESTS", default=True)
# æ ¹æ®ç¯å¢ƒå˜é‡ `RUN_TOOL_TESTS` è§£ææ˜¯å¦è¿è¡Œå·¥å…·æµ‹è¯•çš„æ ‡å¿—
_run_tool_tests = parse_flag_from_env("RUN_TOOL_TESTS", default=False)
# æ ¹æ®ç¯å¢ƒå˜é‡ `RUN_THIRD_PARTY_DEVICE_TESTS` è§£ææ˜¯å¦è¿è¡Œç¬¬ä¸‰æ–¹è®¾å¤‡æµ‹è¯•çš„æ ‡å¿—
_run_third_party_device_tests = parse_flag_from_env("RUN_THIRD_PARTY_DEVICE_TESTS", default=False)


# å‡½æ•°è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®° PT+TF äº¤å‰æµ‹è¯•
def is_pt_tf_cross_test(test_case):
    """
    Decorator marking a test as a test that control interactions between PyTorch and TensorFlow.

    PT+TF tests are skipped by default and we can run only them by setting RUN_PT_TF_CROSS_TESTS environment variable
    to a truthy value and selecting the is_pt_tf_cross_test pytest mark.

    """
    # å¦‚æœæœªè®¾ç½®ç¯å¢ƒå˜é‡ `RUN_PT_TF_CROSS_TESTS` æˆ–è€…å½“å‰ç¯å¢ƒä¸­æ²¡æœ‰å®‰è£… PyTorch æˆ– TensorFlowï¼Œ
    # åˆ™è·³è¿‡ PT+TF æµ‹è¯•
    if not _run_pt_tf_cross_tests or not is_torch_available() or not is_tf_available():
        return unittest.skip("test is PT+TF test")(test_case)
    else:
        # å°è¯•å¯¼å…¥ pytest æ¨¡å—ï¼Œé¿å…åœ¨ä¸»åº“ä¸­ç¡¬ç¼–ç ä¾èµ– pytest
        try:
            import pytest  
        # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œè¿”å›åŸå§‹çš„ test_case
        except ImportError:
            return test_case
        # å¦‚æœå¯¼å…¥æˆåŠŸï¼Œåº”ç”¨ pytest.mark.is_pt_tf_cross_test() è£…é¥°å™¨åˆ° test_case ä¸Š
        else:
            return pytest.mark.is_pt_tf_cross_test()(test_case)
# æ ‡è®°ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸ºæ§åˆ¶ PyTorch å’Œ Flax äº¤äº’çš„æµ‹è¯•çš„è£…é¥°å™¨

PT+FLAX æµ‹è¯•é»˜è®¤æƒ…å†µä¸‹ä¼šè¢«è·³è¿‡ï¼Œåªæœ‰å½“è®¾ç½®äº†ç¯å¢ƒå˜é‡ RUN_PT_FLAX_CROSS_TESTS ä¸ºçœŸå€¼å¹¶ä¸”é€‰æ‹©äº† is_pt_flax_cross_test pytest æ ‡è®°æ—¶æ‰ä¼šè¿è¡Œã€‚

def is_pt_flax_cross_test(test_case):
    if not _run_pt_flax_cross_tests or not is_torch_available() or not is_flax_available():
        # å¦‚æœä¸æ»¡è¶³è¿è¡Œæ¡ä»¶ï¼ˆæœªè®¾ç½®ç¯å¢ƒå˜é‡æˆ–è€…æ²¡æœ‰å¯ç”¨çš„ PyTorch æˆ– Flaxï¼‰ï¼Œåˆ™è·³è¿‡æµ‹è¯•
        return unittest.skip("test is PT+FLAX test")(test_case)
    else:
        try:
            import pytest  # æˆ‘ä»¬ä¸éœ€è¦åœ¨ä¸»åº“ä¸­å¼ºåˆ¶ä¾èµ– pytest
        except ImportError:
            return test_case
        else:
            # ä½¿ç”¨ pytest çš„ is_pt_flax_cross_test æ ‡è®°æ¥æ ‡è®°æµ‹è¯•ç”¨ä¾‹
            return pytest.mark.is_pt_flax_cross_test()(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸ºåœ¨ staging ç¯å¢ƒä¸‹è¿è¡Œçš„æµ‹è¯•çš„è£…é¥°å™¨

è¿™äº›æµ‹è¯•å°†åœ¨ huggingface.co çš„ staging ç¯å¢ƒä¸‹è¿è¡Œï¼Œè€Œä¸æ˜¯çœŸå®çš„æ¨¡å‹ä¸­å¿ƒã€‚

def is_staging_test(test_case):
    if not _run_staging:
        # å¦‚æœä¸è¿è¡Œ staging æµ‹è¯•ï¼Œåˆ™è·³è¿‡æµ‹è¯•
        return unittest.skip("test is staging test")(test_case)
    else:
        try:
            import pytest  # æˆ‘ä»¬ä¸éœ€è¦åœ¨ä¸»åº“ä¸­å¼ºåˆ¶ä¾èµ– pytest
        except ImportError:
            return test_case
        else:
            # ä½¿ç”¨ pytest çš„ is_staging_test æ ‡è®°æ¥æ ‡è®°æµ‹è¯•ç”¨ä¾‹
            return pytest.mark.is_staging_test()(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸º pipeline æµ‹è¯•çš„è£…é¥°å™¨

å¦‚æœæœªå°† RUN_PIPELINE_TESTS è®¾ç½®ä¸ºçœŸå€¼ï¼Œåˆ™è¿™äº›æµ‹è¯•å°†è¢«è·³è¿‡ã€‚

def is_pipeline_test(test_case):
    if not _run_pipeline_tests:
        # å¦‚æœä¸è¿è¡Œ pipeline æµ‹è¯•ï¼Œåˆ™è·³è¿‡æµ‹è¯•
        return unittest.skip("test is pipeline test")(test_case)
    else:
        try:
            import pytest  # æˆ‘ä»¬ä¸éœ€è¦åœ¨ä¸»åº“ä¸­å¼ºåˆ¶ä¾èµ– pytest
        except ImportError:
            return test_case
        else:
            # ä½¿ç”¨ pytest çš„ is_pipeline_test æ ‡è®°æ¥æ ‡è®°æµ‹è¯•ç”¨ä¾‹
            return pytest.mark.is_pipeline_test()(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸ºå·¥å…·æµ‹è¯•çš„è£…é¥°å™¨

å¦‚æœæœªå°† RUN_TOOL_TESTS è®¾ç½®ä¸ºçœŸå€¼ï¼Œåˆ™è¿™äº›æµ‹è¯•å°†è¢«è·³è¿‡ã€‚

def is_tool_test(test_case):
    if not _run_tool_tests:
        # å¦‚æœä¸è¿è¡Œå·¥å…·æµ‹è¯•ï¼Œåˆ™è·³è¿‡æµ‹è¯•
        return unittest.skip("test is a tool test")(test_case)
    else:
        try:
            import pytest  # æˆ‘ä»¬ä¸éœ€è¦åœ¨ä¸»åº“ä¸­å¼ºåˆ¶ä¾èµ– pytest
        except ImportError:
            return test_case
        else:
            # ä½¿ç”¨ pytest çš„ is_tool_test æ ‡è®°æ¥æ ‡è®°æµ‹è¯•ç”¨ä¾‹
            return pytest.mark.is_tool_test()(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸ºæ…¢é€Ÿæµ‹è¯•çš„è£…é¥°å™¨

æ…¢é€Ÿæµ‹è¯•é»˜è®¤æƒ…å†µä¸‹ä¼šè¢«è·³è¿‡ã€‚è®¾ç½® RUN_SLOW ç¯å¢ƒå˜é‡ä¸ºçœŸå€¼ä»¥è¿è¡Œè¿™äº›æµ‹è¯•ã€‚

def slow(test_case):
    return unittest.skipUnless(_run_slow_tests, "test is slow")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸ºå¤ªæ…¢æµ‹è¯•çš„è£…é¥°å™¨

å¤ªæ…¢çš„æµ‹è¯•åœ¨ä¿®å¤è¿‡ç¨‹ä¸­ä¼šè¢«è·³è¿‡ã€‚ä¸åº”å°†ä»»ä½•æµ‹è¯•æ ‡è®°ä¸º "tooslow"ï¼Œå› ä¸ºè¿™äº›æµ‹è¯•ä¸ä¼šè¢« CI æµ‹è¯•ã€‚

def tooslow(test_case):
    return unittest.skip("test is too slow")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸ºè‡ªå®šä¹‰åˆ†è¯å™¨æµ‹è¯•çš„è£…é¥°å™¨
    """
    è‡ªå®šä¹‰åˆ†è¯å™¨éœ€è¦é¢å¤–çš„ä¾èµ–é¡¹ï¼Œé»˜è®¤æƒ…å†µä¸‹ä¼šè¢«è·³è¿‡ã€‚å°†ç¯å¢ƒå˜é‡ RUN_CUSTOM_TOKENIZERS
    è®¾ç½®ä¸ºçœŸå€¼ï¼Œä»¥ä¾¿è¿è¡Œå®ƒä»¬ã€‚
    """
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œæ ¹æ® _run_custom_tokenizers çš„çœŸå‡å†³å®šæ˜¯å¦è·³è¿‡æµ‹è¯•ç”¨ä¾‹
    return unittest.skipUnless(_run_custom_tokenizers, "test of custom tokenizers")(test_case)
# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ BeautifulSoup4 çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… BeautifulSoup4 æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_bs4(test_case):
    return unittest.skipUnless(is_bs4_available(), "test requires BeautifulSoup4")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ GaLore çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… GaLore æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_galore_torch(test_case):
    return unittest.skipUnless(is_galore_torch_available(), "test requires GaLore")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ OpenCV çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… OpenCV æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_cv2(test_case):
    return unittest.skipUnless(is_cv2_available(), "test requires OpenCV")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ Levenshtein çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… Levenshtein æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_levenshtein(test_case):
    return unittest.skipUnless(is_levenshtein_available(), "test requires Levenshtein")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ NLTK çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… NLTK æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_nltk(test_case):
    return unittest.skipUnless(is_nltk_available(), "test requires NLTK")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ accelerate çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… accelerate æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_accelerate(test_case):
    return unittest.skipUnless(is_accelerate_available(), "test requires accelerate")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ fsdp çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… fsdp æˆ–ç‰ˆæœ¬ä¸ç¬¦åˆè¦æ±‚æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_fsdp(test_case, min_version: str = "1.12.0"):
    return unittest.skipUnless(is_fsdp_available(min_version), f"test requires torch version >= {min_version}")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ g2p_en çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… SentencePiece æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_g2p_en(test_case):
    return unittest.skipUnless(is_g2p_en_available(), "test requires g2p_en")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ safetensors çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… safetensors æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_safetensors(test_case):
    return unittest.skipUnless(is_safetensors_available(), "test requires safetensors")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ rjieba çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… rjieba æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_rjieba(test_case):
    return unittest.skipUnless(is_rjieba_available(), "test requires rjieba")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ jieba çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æœªå®‰è£… jieba æ—¶è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_jieba(test_case):
    return unittest.skipUnless(is_jieba_available(), "test requires jieba")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ jinja çš„æµ‹è¯•ç”¨ä¾‹ã€‚åœ¨æ­¤å¤„ä»…å£°æ˜å‡½æ•°ï¼Œå®é™…è£…é¥°é€»è¾‘æœªæä¾›ã€‚
def require_jinja(test_case):
    # Placeholder for decorator marking tests requiring Jinja
    pass
    # ä½¿ç”¨è£…é¥°å™¨æ ‡è®°ä¸€ä¸ªéœ€è¦ jinja çš„æµ‹è¯•ç”¨ä¾‹ã€‚å¦‚æœ jinja æ²¡æœ‰å®‰è£…ï¼Œåˆ™è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
    """
    ä½¿ç”¨ unittest.skipUnless å‡½æ•°æ¥åŠ¨æ€åœ°è£…é¥°æµ‹è¯•ç”¨ä¾‹ï¼Œåªæœ‰åœ¨ jinja å¯ç”¨æ—¶æ‰è¿è¡Œè¯¥æµ‹è¯•ç”¨ä¾‹ã€‚
    å¦‚æœ is_jinja_available() å‡½æ•°è¿”å› Trueï¼Œåˆ™è£…é¥°å™¨è¿”å›ä¸€ä¸ªå¯ç”¨äºè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨å‡½æ•°ï¼Œå¦åˆ™è¿”å› Noneã€‚
    """
    return unittest.skipUnless(is_jinja_available(), "test requires jinja")(test_case)
# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ tf2onnx
def require_tf2onnx(test_case):
    return unittest.skipUnless(is_tf2onnx_available(), "test requires tf2onnx")(test_case)


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ ONNX
def require_onnx(test_case):
    return unittest.skipUnless(is_onnx_available(), "test requires ONNX")(test_case)


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ Timm
def require_timm(test_case):
    """
    Decorator marking a test that requires Timm.

    These tests are skipped when Timm isn't installed.
    """
    return unittest.skipUnless(is_timm_available(), "test requires Timm")(test_case)


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ NATTEN
def require_natten(test_case):
    """
    Decorator marking a test that requires NATTEN.

    These tests are skipped when NATTEN isn't installed.
    """
    return unittest.skipUnless(is_natten_available(), "test requires natten")(test_case)


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ PyTorch
def require_torch(test_case):
    """
    Decorator marking a test that requires PyTorch.

    These tests are skipped when PyTorch isn't installed.
    """
    return unittest.skipUnless(is_torch_available(), "test requires PyTorch")(test_case)


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ Flash Attention
def require_flash_attn(test_case):
    """
    Decorator marking a test that requires Flash Attention.

    These tests are skipped when Flash Attention isn't installed.
    """
    return unittest.skipUnless(is_flash_attn_2_available(), "test requires Flash Attention")(test_case)


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ PyTorch's SDPA
def require_torch_sdpa(test_case):
    """
    Decorator marking a test that requires PyTorch's SDPA.

    These tests are skipped when requirements are not met (torch version).
    """
    return unittest.skipUnless(is_torch_sdpa_available(), "test requires PyTorch SDPA")(test_case)


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ HF token
def require_read_token(fn):
    """
    A decorator that loads the HF token for tests that require to load gated models.
    """
    token = os.getenv("HF_HUB_READ_TOKEN")

    @wraps(fn)
    def _inner(*args, **kwargs):
        with patch("huggingface_hub.utils._headers.get_token", return_value=token):
            return fn(*args, **kwargs)

    return _inner


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ PEFT
def require_peft(test_case):
    """
    Decorator marking a test that requires PEFT.

    These tests are skipped when PEFT isn't installed.
    """
    return unittest.skipUnless(is_peft_available(), "test requires PEFT")(test_case)


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ Torchvision
def require_torchvision(test_case):
    """
    Decorator marking a test that requires Torchvision.

    These tests are skipped when Torchvision isn't installed.
    """
    return unittest.skipUnless(is_torchvision_available(), "test requires Torchvision")(test_case)


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ PyTorch æˆ– TensorFlow
def require_torch_or_tf(test_case):
    """
    Decorator marking a test that requires PyTorch or TensorFlow.

    These tests are skipped when neither PyTorch nor TensorFlow is installed.
    """
    return unittest.skipUnless(is_torch_available() or is_tf_available(), "test requires PyTorch or TensorFlow")(
        test_case
    )


# æ ¹æ®æ¡ä»¶åˆ¤æ–­æ˜¯å¦åŠ è½½ Intel Extension for PyTorch
def require_intel_extension_for_pytorch(test_case):
    """
    Decorator marking a test that requires Intel Extension for PyTorch.
    """
    # æ³¨é‡Šéƒ¨åˆ†æœªæä¾›
    pass
    # å½“æœªå®‰è£…Intel Extension for PyTorchæˆ–è€…å…¶ç‰ˆæœ¬ä¸å½“å‰PyTorchç‰ˆæœ¬ä¸åŒ¹é…æ—¶ï¼Œè·³è¿‡è¿™äº›æµ‹è¯•ã€‚
    """
    è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œç”¨äºæ ¹æ®æ¡ä»¶è·³è¿‡æµ‹è¯•ã€‚
    è£…é¥°å™¨æ£€æŸ¥æ˜¯å¦å¯ç”¨Intel Extension for PyTorchï¼ˆIPEXï¼‰ã€‚
    å¦‚æœä¸å¯ç”¨æˆ–ç‰ˆæœ¬ä¸åŒ¹é…ï¼Œåˆ™è·³è¿‡æµ‹è¯•ï¼Œå¹¶æä¾›ç›¸åº”çš„æç¤ºä¿¡æ¯ã€‚
    å‚è€ƒé“¾æ¥ï¼šhttps://github.com/intel/intel-extension-for-pytorch
    """
    return unittest.skipUnless(
        is_ipex_available(),
        "test requires Intel Extension for PyTorch to be installed and match current PyTorch version, see"
        " https://github.com/intel/intel-extension-for-pytorch",
    )(test_case)
# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ TensorFlow probability
def require_tensorflow_probability(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ TensorFlow probability æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_tensorflow_probability_available(), "test requires TensorFlow probability")(
        test_case
    )


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ torchaudio
def require_torchaudio(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ torchaudio æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_torchaudio_available(), "test requires torchaudio")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ TensorFlow
def require_tf(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ TensorFlow æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_tf_available(), "test requires TensorFlow")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ JAX & Flax
def require_flax(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ JAX æˆ– Flax æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_flax_available(), "test requires JAX & Flax")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ SentencePiece
def require_sentencepiece(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ SentencePiece æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_sentencepiece_available(), "test requires SentencePiece")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ Sacremoses
def require_sacremoses(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ Sacremoses æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_sacremoses_available(), "test requires Sacremoses")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ Seqio
def require_seqio(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ Seqio æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_seqio_available(), "test requires Seqio")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ Scipy
def require_scipy(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ Scipy æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_scipy_available(), "test requires Scipy")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ ğŸ¤— Tokenizers
def require_tokenizers(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ ğŸ¤— Tokenizers æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_tokenizers_available(), "test requires tokenizers")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ tensorflow_text
def require_tensorflow_text(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ tensorflow_text æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_tensorflow_text_available(), "test requires tensorflow_text")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ keras_nlp
def require_keras_nlp(test_case):
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œå…¶åŠŸèƒ½æ˜¯å½“ keras_nlp æœªå®‰è£…æ—¶è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_keras_nlp_available(), "test requires keras_nlp")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ Pandas
def require_pandas(test_case):
    """
    Decorator marking a test that requires Pandas. These tests are skipped when Pandas isn't installed.
    """
    return unittest.skipUnless(is_pandas_available(), "test requires Pandas")(test_case)
    # ä½¿ç”¨è£…é¥°å™¨æ ‡è®°ä¸€ä¸ªéœ€è¦ pandas çš„æµ‹è¯•ç”¨ä¾‹ã€‚å½“ pandas æ²¡æœ‰å®‰è£…æ—¶ï¼Œè¿™äº›æµ‹è¯•å°†è¢«è·³è¿‡ã€‚
    """
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œæ ¹æ® pandas çš„å¯ç”¨æ€§å†³å®šæ˜¯å¦è·³è¿‡æµ‹è¯•ç”¨ä¾‹
    return unittest.skipUnless(is_pandas_available(), "test requires pandas")(test_case)
# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ PyTesseractã€‚å¦‚æœ PyTesseract æ²¡æœ‰å®‰è£…ï¼Œåˆ™è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_pytesseract(test_case):
    return unittest.skipUnless(is_pytesseract_available(), "test requires PyTesseract")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ PyTorch Quantization Toolkitã€‚å¦‚æœ PyTorch Quantization Toolkit æ²¡æœ‰å®‰è£…ï¼Œåˆ™è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_pytorch_quantization(test_case):
    return unittest.skipUnless(is_pytorch_quantization_available(), "test requires PyTorch Quantization Toolkit")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦è§†è§‰ç›¸å…³çš„ä¾èµ–ã€‚å¦‚æœ torchaudio æ²¡æœ‰å®‰è£…ï¼Œåˆ™è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_vision(test_case):
    return unittest.skipUnless(is_vision_available(), "test requires vision")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ ftfyã€‚å¦‚æœ ftfy æ²¡æœ‰å®‰è£…ï¼Œåˆ™è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_ftfy(test_case):
    return unittest.skipUnless(is_ftfy_available(), "test requires ftfy")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ SpaCyã€‚å¦‚æœ SpaCy æ²¡æœ‰å®‰è£…ï¼Œåˆ™è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_spacy(test_case):
    return unittest.skipUnless(is_spacy_available(), "test requires spacy")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ decordã€‚å¦‚æœ decord æ²¡æœ‰å®‰è£…ï¼Œåˆ™è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
def require_decord(test_case):
    return unittest.skipUnless(is_decord_available(), "test requires decord")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦å¤š GPU è®¾ç½®ï¼ˆåœ¨ PyTorch ä¸­ï¼‰ã€‚å¦‚æœæ²¡æœ‰å¤šä¸ª GPUï¼Œåˆ™è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
# è‹¥è¦ä»…è¿è¡Œå¤š GPU æµ‹è¯•ï¼Œè¯·å‡è®¾æ‰€æœ‰æµ‹è¯•åç§°åŒ…å« multi_gpuï¼š
# $ pytest -sv ./tests -k "multi_gpu"
def require_torch_multi_gpu(test_case):
    if not is_torch_available():
        return unittest.skip("test requires PyTorch")(test_case)

    import torch

    return unittest.skipUnless(torch.cuda.device_count() > 1, "test requires multiple GPUs")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦å¤šåŠ é€Ÿå™¨è®¾ç½®ï¼ˆåœ¨ PyTorch ä¸­ï¼‰ã€‚å¦‚æœæ²¡æœ‰å¤šä¸ªåŠ é€Ÿå™¨ï¼Œåˆ™è·³è¿‡è¿™äº›æµ‹è¯•ã€‚
# è‹¥è¦ä»…è¿è¡Œå¤šåŠ é€Ÿå™¨æµ‹è¯•ï¼Œè¯·å‡è®¾æ‰€æœ‰æµ‹è¯•åç§°åŒ…å« multi_acceleratorï¼š
# $ pytest -sv ./tests -k "multi_accelerator"
def require_torch_multi_accelerator(test_case):
    if not is_torch_available():
        return unittest.skip("test requires PyTorch")(test_case)

    return unittest.skipUnless(backend_device_count(torch_device) > 1, "test requires multiple accelerators")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦ 0 æˆ– 1 ä¸ª GPU è®¾ç½®ï¼ˆåœ¨ PyTorch ä¸­ï¼‰ã€‚
def require_torch_non_multi_gpu(test_case):
    if not is_torch_available():
        return unittest.skip("test requires PyTorch")(test_case)

    import torch
    # è¿”å›ä¸€ä¸ªè£…é¥°å™¨ï¼Œç”¨äºæ¡ä»¶æ€§è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(torch.cuda.device_count() < 2, "test requires 0 or 1 GPU")(test_case)
# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦é›¶æˆ–ä¸€ä¸ªåŠ é€Ÿå™¨è®¾ç½®ï¼ˆåœ¨PyTorchä¸­ï¼‰çš„è£…é¥°å™¨
def require_torch_non_multi_accelerator(test_case):
    # å¦‚æœPyTorchä¸å¯ç”¨ï¼Œåˆ™è·³è¿‡æµ‹è¯•
    if not is_torch_available():
        return unittest.skip("test requires PyTorch")(test_case)

    # è¿”å›ä¸€ä¸ªæ¡ä»¶ï¼Œè¯¥æ¡ä»¶æ£€æŸ¥å½“å‰è®¾å¤‡ä¸Šçš„åç«¯è®¾å¤‡æ•°é‡æ˜¯å¦å°äº2ï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(backend_device_count(torch_device) < 2, "test requires 0 or 1 accelerator")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦é›¶ã€ä¸€ä¸ªæˆ–ä¸¤ä¸ªGPUè®¾ç½®ï¼ˆåœ¨PyTorchä¸­ï¼‰çš„è£…é¥°å™¨
def require_torch_up_to_2_gpus(test_case):
    # å¦‚æœPyTorchä¸å¯ç”¨ï¼Œåˆ™è·³è¿‡æµ‹è¯•
    if not is_torch_available():
        return unittest.skip("test requires PyTorch")(test_case)

    import torch

    # è¿”å›ä¸€ä¸ªæ¡ä»¶ï¼Œè¯¥æ¡ä»¶æ£€æŸ¥å½“å‰æœºå™¨ä¸Šçš„GPUæ•°é‡æ˜¯å¦å°äº3ï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(torch.cuda.device_count() < 3, "test requires 0 or 1 or 2 GPUs")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦é›¶ã€ä¸€ä¸ªæˆ–ä¸¤ä¸ªåŠ é€Ÿå™¨è®¾ç½®ï¼ˆåœ¨PyTorchä¸­ï¼‰çš„è£…é¥°å™¨
def require_torch_up_to_2_accelerators(test_case):
    # å¦‚æœPyTorchä¸å¯ç”¨ï¼Œåˆ™è·³è¿‡æµ‹è¯•
    if not is_torch_available():
        return unittest.skip("test requires PyTorch")(test_case)

    # è¿”å›ä¸€ä¸ªæ¡ä»¶ï¼Œè¯¥æ¡ä»¶æ£€æŸ¥å½“å‰è®¾å¤‡ä¸Šçš„åç«¯è®¾å¤‡æ•°é‡æ˜¯å¦å°äº3ï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(backend_device_count(torch_device) < 3, "test requires 0 or 1 or 2 accelerators")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦TorchXLAï¼ˆåœ¨PyTorchä¸­ï¼‰çš„è£…é¥°å™¨
def require_torch_xla(test_case):
    # è¿”å›ä¸€ä¸ªæ¡ä»¶ï¼Œè¯¥æ¡ä»¶æ£€æŸ¥å½“å‰ç³»ç»Ÿæ˜¯å¦æ”¯æŒTorchXLAï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_torch_xla_available(), "test requires TorchXLA")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦NeuronCoreï¼ˆåœ¨PyTorchä¸­ï¼‰çš„è£…é¥°å™¨
def require_torch_neuroncore(test_case):
    # è¿”å›ä¸€ä¸ªæ¡ä»¶ï¼Œè¯¥æ¡ä»¶æ£€æŸ¥å½“å‰ç³»ç»Ÿæ˜¯å¦æ”¯æŒNeuronCoreï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_torch_neuroncore_available(check_device=False), "test requires PyTorch NeuronCore")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦NPUï¼ˆåœ¨PyTorchä¸­ï¼‰çš„è£…é¥°å™¨
def require_torch_npu(test_case):
    # è¿”å›ä¸€ä¸ªæ¡ä»¶ï¼Œè¯¥æ¡ä»¶æ£€æŸ¥å½“å‰ç³»ç»Ÿæ˜¯å¦æ”¯æŒNPUï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_torch_npu_available(), "test requires PyTorch NPU")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦å¤šNPUè®¾ç½®ï¼ˆåœ¨PyTorchä¸­ï¼‰çš„è£…é¥°å™¨ï¼Œè¿™äº›æµ‹è¯•åœ¨æ²¡æœ‰å¤šä¸ªNPUçš„æœºå™¨ä¸Šä¼šè¢«è·³è¿‡
def require_torch_multi_npu(test_case):
    # å¦‚æœæ²¡æœ‰NPUå¯ç”¨ï¼Œåˆ™è·³è¿‡æµ‹è¯•
    if not is_torch_npu_available():
        return unittest.skip("test requires PyTorch NPU")(test_case)

    import torch

    # è¿”å›ä¸€ä¸ªæ¡ä»¶ï¼Œè¯¥æ¡ä»¶æ£€æŸ¥å½“å‰ç³»ç»Ÿä¸ŠNPUè®¾å¤‡çš„æ•°é‡æ˜¯å¦å¤§äº1ï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(torch.npu.device_count() > 1, "test requires multiple NPUs")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦XPUå’ŒIPEXï¼ˆåœ¨PyTorchä¸­ï¼‰çš„è£…é¥°å™¨
def require_torch_xpu(test_case):
    # è¿”å›ä¸€ä¸ªæ¡ä»¶ï¼Œè¯¥æ¡ä»¶æ£€æŸ¥å½“å‰ç³»ç»Ÿæ˜¯å¦æ”¯æŒIPEXå’ŒXPUè®¾å¤‡ï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_torch_xpu_available(), "test requires IPEX and an XPU device")(test_case)


# æ ‡è®°ä¸€ä¸ªæµ‹è¯•éœ€è¦å¤šXPUè®¾ç½®å’ŒIPEXï¼ˆåœ¨PyTorchä¸­ï¼‰çš„è£…é¥°å™¨ï¼Œè¿™äº›æµ‹è¯•åœ¨æ²¡æœ‰IPEXæˆ–å¤šä¸ªXPUçš„æœºå™¨ä¸Šä¼šè¢«è·³è¿‡
def require_torch_multi_xpu(test_case):
    # è¿”å›ä¸€ä¸ªæ¡ä»¶ï¼Œè¯¥æ¡ä»¶æ£€æŸ¥å½“å‰ç³»ç»Ÿæ˜¯å¦æ”¯æŒIPEXå’Œè‡³å°‘ä¸€ä¸ªXPUè®¾å¤‡ï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•
    return unittest.skipUnless(is_torch_xpu_available(), "test requires IPEX and an XPU device")(test_case)
    """
    å¦‚æœæ²¡æœ‰å¯ç”¨çš„ Torch XPUï¼ˆä¾‹å¦‚ IPEXï¼‰ï¼Œåˆ™è·³è¿‡æµ‹è¯•ï¼Œå¹¶è¿”å›ç›¸åº”çš„æç¤ºä¿¡æ¯
    """
    if not is_torch_xpu_available():
        # è·³è¿‡æµ‹è¯•ï¼Œå¹¶è¿”å›ä¸€ä¸ªåŒ…å«è·³è¿‡åŸå› çš„æ¶ˆæ¯ï¼Œç”¨äºå•å…ƒæµ‹è¯•æ¡†æ¶
        return unittest.skip("test requires IPEX and atleast one XPU device")(test_case)

    # é™¤éç³»ç»Ÿæœ‰å¤šä¸ª Torch XPU è®¾å¤‡å¯ç”¨ï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•ï¼Œå¹¶è¿”å›ç›¸åº”çš„æç¤ºä¿¡æ¯
    return unittest.skipUnless(torch.xpu.device_count() > 1, "test requires multiple XPUs")(test_case)
if is_torch_available():
    # å¦‚æœ Torch å¯ç”¨ï¼Œåˆ™å¯¼å…¥ torch åº“
    import torch

    # å¦‚æœå­˜åœ¨ TRANSFORMERS_TEST_BACKEND ç¯å¢ƒå˜é‡
    if "TRANSFORMERS_TEST_BACKEND" in os.environ:
        # è·å– backend åç§°
        backend = os.environ["TRANSFORMERS_TEST_BACKEND"]
        try:
            # å°è¯•å¯¼å…¥æŒ‡å®šçš„ backend æ¨¡å—
            _ = importlib.import_module(backend)
        except ModuleNotFoundError as e:
            # æŠ¥é”™ä¿¡æ¯ï¼ŒæŒ‡å‡ºæ— æ³•å¯¼å…¥æŒ‡å®šçš„ backend æ¨¡å—
            raise ModuleNotFoundError(
                f"Failed to import `TRANSFORMERS_TEST_BACKEND` '{backend}'! This should be the name of an installed module. The original error (look up to see its"
                f" traceback):\n{e}"
            ) from e

    # å¦‚æœå­˜åœ¨ TRANSFORMERS_TEST_DEVICE ç¯å¢ƒå˜é‡
    if "TRANSFORMERS_TEST_DEVICE" in os.environ:
        # è·å– torch_device åç§°
        torch_device = os.environ["TRANSFORMERS_TEST_DEVICE"]
        # å¦‚æœ torch_device æ˜¯ "cuda" ä½† CUDA ä¸å¯ç”¨ï¼Œåˆ™æŠ›å‡º ValueError
        if torch_device == "cuda" and not torch.cuda.is_available():
            raise ValueError(
                f"TRANSFORMERS_TEST_DEVICE={torch_device}, but CUDA is unavailable. Please double-check your testing environment."
            )
        # å¦‚æœ torch_device æ˜¯ "xpu" ä½† XPU ä¸å¯ç”¨ï¼Œåˆ™æŠ›å‡º ValueError
        if torch_device == "xpu" and not is_torch_xpu_available():
            raise ValueError(
                f"TRANSFORMERS_TEST_DEVICE={torch_device}, but XPU is unavailable. Please double-check your testing environment."
            )
        # å¦‚æœ torch_device æ˜¯ "npu" ä½† NPU ä¸å¯ç”¨ï¼Œåˆ™æŠ›å‡º ValueError
        if torch_device == "npu" and not is_torch_npu_available():
            raise ValueError(
                f"TRANSFORMERS_TEST_DEVICE={torch_device}, but NPU is unavailable. Please double-check your testing environment."
            )

        try:
            # å°è¯•åˆ›å»ºè®¾å¤‡æ¥éªŒè¯æä¾›çš„è®¾å¤‡åç§°æ˜¯å¦æœ‰æ•ˆ
            _ = torch.device(torch_device)
        except RuntimeError as e:
            # æŠ¥é”™ä¿¡æ¯ï¼ŒæŒ‡å‡ºç¯å¢ƒå˜é‡ TRANSFORMERS_TEST_DEVICE æŒ‡å®šçš„è®¾å¤‡åç§°æ— æ•ˆ
            raise RuntimeError(
                f"Unknown testing device specified by environment variable `TRANSFORMERS_TEST_DEVICE`: {torch_device}"
            ) from e
    # å¦‚æœ CUDA å¯ç”¨ï¼Œåˆ™é»˜è®¤è®¾å¤‡ä¸º "cuda"
    elif torch.cuda.is_available():
        torch_device = "cuda"
    # å¦‚æœéœ€è¦è¿è¡Œç¬¬ä¸‰æ–¹è®¾å¤‡æµ‹è¯•ä¸” NPU å¯ç”¨ï¼Œåˆ™è®¾å¤‡ä¸º "npu"
    elif _run_third_party_device_tests and is_torch_npu_available():
        torch_device = "npu"
    # å¦‚æœéœ€è¦è¿è¡Œç¬¬ä¸‰æ–¹è®¾å¤‡æµ‹è¯•ä¸” XPU å¯ç”¨ï¼Œåˆ™è®¾å¤‡ä¸º "xpu"
    elif _run_third_party_device_tests and is_torch_xpu_available():
        torch_device = "xpu"
    else:
        # å¦åˆ™ï¼Œé»˜è®¤è®¾å¤‡ä¸º "cpu"
        torch_device = "cpu"
else:
    # å¦‚æœ Torch ä¸å¯ç”¨ï¼Œåˆ™è®¾å¤‡ä¸º None
    torch_device = None

# å¦‚æœ TensorFlow å¯ç”¨ï¼Œåˆ™å¯¼å…¥ tensorflow åº“
if is_tf_available():
    import tensorflow as tf

# å¦‚æœ Flax å¯ç”¨ï¼Œåˆ™å¯¼å…¥ jax åº“ï¼Œå¹¶è·å–é»˜è®¤åç«¯åç§°
if is_flax_available():
    import jax

    jax_device = jax.default_backend()
else:
    # å¦åˆ™ï¼Œè®¾å¤‡ä¸º None
    jax_device = None
    # å¦‚æœ torch_device ä¸ä¸º None å¹¶ä¸”ä¸æ˜¯ "cpu"ï¼Œåˆ™ä½¿ç”¨ unittest.skipUnless è£…é¥°å™¨ï¼Œ
    # å…¶ä¸­æ¡ä»¶ä¸º "test requires accelerator"ï¼Œè¡¨ç¤ºä»…åœ¨æ»¡è¶³æ¡ä»¶æ—¶æ‰è·³è¿‡æµ‹è¯•ã€‚
    return unittest.skipUnless(torch_device is not None and torch_device != "cpu", "test requires accelerator")(
        test_case
    )
# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦æ”¯æŒ fp16 è®¾å¤‡çš„æµ‹è¯•ç”¨ä¾‹
def require_torch_fp16(test_case):
    # è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ®è®¾å¤‡æ˜¯å¦æ”¯æŒ fp16 æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹
    return unittest.skipUnless(
        is_torch_fp16_available_on_device(torch_device), "test requires device with fp16 support"
    )(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦æ”¯æŒ bf16 è®¾å¤‡çš„æµ‹è¯•ç”¨ä¾‹
def require_torch_bf16(test_case):
    # è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ®è®¾å¤‡æ˜¯å¦æ”¯æŒ bf16 æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹
    return unittest.skipUnless(
        is_torch_bf16_available_on_device(torch_device), "test requires device with bf16 support"
    )(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦æ”¯æŒ bf16 GPU è®¾å¤‡çš„æµ‹è¯•ç”¨ä¾‹
def require_torch_bf16_gpu(test_case):
    # è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ®è®¾å¤‡æ˜¯å¦æ”¯æŒ bf16 GPU æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹
    return unittest.skipUnless(
        is_torch_bf16_gpu_available(),
        "test requires torch>=1.10, using Ampere GPU or newer arch with cuda>=11.0",
    )(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦æ”¯æŒ bf16 CPU è®¾å¤‡çš„æµ‹è¯•ç”¨ä¾‹
def require_torch_bf16_cpu(test_case):
    # è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ®è®¾å¤‡æ˜¯å¦æ”¯æŒ bf16 CPU æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹
    return unittest.skipUnless(
        is_torch_bf16_cpu_available(),
        "test requires torch>=1.10, using CPU",
    )(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦æ”¯æŒ tf32 è®¾å¤‡çš„æµ‹è¯•ç”¨ä¾‹
def require_torch_tf32(test_case):
    # è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ®è®¾å¤‡æ˜¯å¦æ”¯æŒ tf32 æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹
    return unittest.skipUnless(
        is_torch_tf32_available(), "test requires Ampere or a newer GPU arch, cuda>=11 and torch>=1.7"
    )(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ detectron2 çš„æµ‹è¯•ç”¨ä¾‹
def require_detectron2(test_case):
    # è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ® detectron2 æ˜¯å¦å¯ç”¨æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹
    return unittest.skipUnless(is_detectron2_available(), "test requires `detectron2`")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ faiss çš„æµ‹è¯•ç”¨ä¾‹
def require_faiss(test_case):
    # è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ® faiss æ˜¯å¦å¯ç”¨æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹
    return unittest.skipUnless(is_faiss_available(), "test requires `faiss`")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ optuna çš„æµ‹è¯•ç”¨ä¾‹
def require_optuna(test_case):
    """
    è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ® optuna æ˜¯å¦å¯ç”¨æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹

    è¿™äº›æµ‹è¯•ç”¨ä¾‹åœ¨æ²¡æœ‰å®‰è£… optuna æ—¶ä¼šè¢«è·³è¿‡ã€‚
    """
    return unittest.skipUnless(is_optuna_available(), "test requires optuna")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ Ray/tune çš„æµ‹è¯•ç”¨ä¾‹
def require_ray(test_case):
    """
    è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ® Ray/tune æ˜¯å¦å¯ç”¨æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹

    è¿™äº›æµ‹è¯•ç”¨ä¾‹åœ¨æ²¡æœ‰å®‰è£… Ray/tune æ—¶ä¼šè¢«è·³è¿‡ã€‚
    """
    return unittest.skipUnless(is_ray_available(), "test requires Ray/tune")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ SigOpt çš„æµ‹è¯•ç”¨ä¾‹
def require_sigopt(test_case):
    """
    è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ® SigOpt æ˜¯å¦å¯ç”¨æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹

    è¿™äº›æµ‹è¯•ç”¨ä¾‹åœ¨æ²¡æœ‰å®‰è£… SigOpt æ—¶ä¼šè¢«è·³è¿‡ã€‚
    """
    return unittest.skipUnless(is_sigopt_available(), "test requires SigOpt")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ wandb çš„æµ‹è¯•ç”¨ä¾‹
def require_wandb(test_case):
    """
    è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ® wandb æ˜¯å¦å¯ç”¨æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹

    è¿™äº›æµ‹è¯•ç”¨ä¾‹åœ¨æ²¡æœ‰å®‰è£… wandb æ—¶ä¼šè¢«è·³è¿‡ã€‚
    """
    return unittest.skipUnless(is_wandb_available(), "test requires wandb")(test_case)


# è£…é¥°å™¨ï¼Œç”¨äºæ ‡è®°éœ€è¦ clearml çš„æµ‹è¯•ç”¨ä¾‹
def require_clearml(test_case):
    """
    è¿”å›ä¸€ä¸ª unittest è£…é¥°å™¨ï¼Œæ ¹æ® clearml æ˜¯å¦å¯ç”¨æ¥è·³è¿‡æµ‹è¯•ç”¨ä¾‹

    è¿™äº›æµ‹è¯•ç”¨ä¾‹åœ¨æ²¡æœ‰å®‰è£… clearml æ—¶ä¼šè¢«è·³è¿‡ã€‚
    """
    return unittest.skipUnless(is_clearml_available(), "test requires clearml")(test_case)
# æ ‡è®°ä¸€ä¸ªéœ€è¦ soundfile åº“çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_soundfile(test_case):
    """
    Decorator marking a test that requires soundfile

    These tests are skipped when soundfile isn't installed.

    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é soundfile å¯ç”¨
    return unittest.skipUnless(is_soundfile_availble(), "test requires soundfile")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ deepspeed åº“çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_deepspeed(test_case):
    """
    Decorator marking a test that requires deepspeed
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é deepspeed å¯ç”¨
    return unittest.skipUnless(is_deepspeed_available(), "test requires deepspeed")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ apex åº“çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_apex(test_case):
    """
    Decorator marking a test that requires apex
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é apex å¯ç”¨
    return unittest.skipUnless(is_apex_available(), "test requires apex")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ aqlm åº“çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_aqlm(test_case):
    """
    Decorator marking a test that requires aqlm
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é aqlm å¯ç”¨
    return unittest.skipUnless(is_aqlm_available(), "test requires aqlm")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ bitsandbytes åº“çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_bitsandbytes(test_case):
    """
    Decorator marking a test that requires the bitsandbytes library. Will be skipped when the library or its hard dependency torch is not installed.
    """
    # æ£€æŸ¥ bitsandbytes å’Œ torch æ˜¯å¦éƒ½å¯ç”¨
    if is_bitsandbytes_available() and is_torch_available():
        try:
            import pytest

            # ä½¿ç”¨ pytest çš„æ ‡è®°æ¥æ ‡è®°æµ‹è¯•ç”¨ä¾‹
            return pytest.mark.bitsandbytes(test_case)
        except ImportError:
            return test_case
    else:
        # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œéœ€è¦ bitsandbytes å’Œ torch
        return unittest.skip("test requires bitsandbytes and torch")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ optimum ä¾èµ–çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_optimum(test_case):
    """
    Decorator for optimum dependency
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é optimum å¯ç”¨
    return unittest.skipUnless(is_optimum_available(), "test requires optimum")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ tensorboard ä¾èµ–çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_tensorboard(test_case):
    """
    Decorator for `tensorboard` dependency
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é tensorboard å¯ç”¨
    return unittest.skipUnless(is_tensorboard_available(), "test requires tensorboard")


# æ ‡è®°ä¸€ä¸ªéœ€è¦ auto_gptq ä¾èµ–çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_auto_gptq(test_case):
    """
    Decorator for auto_gptq dependency
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é auto_gptq å¯ç”¨
    return unittest.skipUnless(is_auto_gptq_available(), "test requires auto-gptq")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ auto_awq ä¾èµ–çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_auto_awq(test_case):
    """
    Decorator for auto_awq dependency
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é auto_awq å¯ç”¨
    return unittest.skipUnless(is_auto_awq_available(), "test requires autoawq")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ quanto ä¾èµ–çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_quanto(test_case):
    """
    Decorator for quanto dependency
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é quanto å¯ç”¨
    return unittest.skipUnless(is_quanto_available(), "test requires quanto")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ phonemizer ä¾èµ–çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_phonemizer(test_case):
    """
    Decorator marking a test that requires phonemizer
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é phonemizer å¯ç”¨
    return unittest.skipUnless(is_phonemizer_available(), "test requires phonemizer")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ pyctcdecode ä¾èµ–çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_pyctcdecode(test_case):
    """
    Decorator marking a test that requires pyctcdecode
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é pyctcdecode å¯ç”¨
    return unittest.skipUnless(is_pyctcdecode_available(), "test requires pyctcdecode")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ librosa ä¾èµ–çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_librosa(test_case):
    """
    Decorator marking a test that requires librosa
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œé™¤é librosa å¯ç”¨
    return unittest.skipUnless(is_librosa_available(), "test requires librosa")(test_case)


# æ ‡è®°ä¸€ä¸ªéœ€è¦ essentia ä¾èµ–çš„æµ‹è¯•ç”¨ä¾‹çš„è£…é¥°å™¨å‡½æ•°
def require_essentia(test_case):
    """
    Decorator marking a test that requires essentia
    """
    # è¿”å›ä¸€ä¸ªè·³è¿‡æµ‹è¯•çš„è£…é¥°å™¨ï¼Œå¾…è¡¥å……ï¼Œå½“å‰å‡½æ•°ä½“ä¸ºç©º
    # å¦‚æœ essentia å¯ç”¨ï¼Œåˆ™ä½¿ç”¨ unittest çš„ skipUnless è£…é¥°å™¨è·³è¿‡æµ‹è¯•ï¼Œå¦åˆ™è¿è¡Œæµ‹è¯•
    return unittest.skipUnless(is_essentia_available(), "test requires essentia")(test_case)
# è£…é¥°å™¨å‡½æ•°ï¼Œç”¨äºæ ‡è®°éœ€è¦ä¾èµ– pretty_midi åº“çš„æµ‹è¯•ç”¨ä¾‹
def require_pretty_midi(test_case):
    return unittest.skipUnless(is_pretty_midi_available(), "test requires pretty_midi")(test_case)


# æ£€æŸ¥ç»™å®šçš„å‘½ä»¤æ˜¯å¦å­˜åœ¨äºç³»ç»Ÿ PATH ä¸­
def cmd_exists(cmd):
    return shutil.which(cmd) is not None


# è£…é¥°å™¨å‡½æ•°ï¼Œæ ‡è®°éœ€è¦ `/usr/bin/time` å‘½ä»¤çš„æµ‹è¯•ç”¨ä¾‹
def require_usr_bin_time(test_case):
    return unittest.skipUnless(cmd_exists("/usr/bin/time"), "test requires /usr/bin/time")(test_case)


# è£…é¥°å™¨å‡½æ•°ï¼Œæ ‡è®°éœ€è¦ sudachi åº“çš„æµ‹è¯•ç”¨ä¾‹
def require_sudachi(test_case):
    return unittest.skipUnless(is_sudachi_available(), "test requires sudachi")(test_case)


# è£…é¥°å™¨å‡½æ•°ï¼Œæ ‡è®°éœ€è¦ sudachi_projection åº“çš„æµ‹è¯•ç”¨ä¾‹
def require_sudachi_projection(test_case):
    return unittest.skipUnless(is_sudachi_projection_available(), "test requires sudachi which supports projection")(test_case)


# è£…é¥°å™¨å‡½æ•°ï¼Œæ ‡è®°éœ€è¦ jumanpp åº“çš„æµ‹è¯•ç”¨ä¾‹
def require_jumanpp(test_case):
    return unittest.skipUnless(is_jumanpp_available(), "test requires jumanpp")(test_case)


# è£…é¥°å™¨å‡½æ•°ï¼Œæ ‡è®°éœ€è¦ cython åº“çš„æµ‹è¯•ç”¨ä¾‹
def require_cython(test_case):
    return unittest.skipUnless(is_cython_available(), "test requires cython")(test_case)


# è·å–å½“å‰ç³»ç»Ÿä¸Šå¯ç”¨çš„ GPU æ•°é‡ï¼Œæ— è®ºä½¿ç”¨çš„æ˜¯ torchã€tf è¿˜æ˜¯ jax
def get_gpu_count():
    if is_torch_available():  # å¦‚æœæœ‰ torch åº“å¯ç”¨
        import torch
        return torch.cuda.device_count()
    elif is_tf_available():  # å¦‚æœæœ‰ tensorflow åº“å¯ç”¨
        import tensorflow as tf
        return len(tf.config.list_physical_devices("GPU"))
    elif is_flax_available():  # å¦‚æœæœ‰ jax åº“å¯ç”¨
        import jax
        return jax.device_count()
    else:
        return 0  # é»˜è®¤è¿”å› GPU æ•°é‡ä¸º 0


# è·å–æµ‹è¯•ç›®å½•çš„è·¯å¾„ï¼Œå¹¶å…è®¸é™„åŠ è·¯å¾„ä½œä¸ºå‚æ•°
def get_tests_dir(append_path=None):
    caller__file__ = inspect.stack()[1][1]  # è·å–è°ƒç”¨è€…çš„æ–‡ä»¶è·¯å¾„
    tests_dir = os.path.abspath(os.path.dirname(caller__file__))  # è·å–è°ƒç”¨è€…æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„

    # å‘ä¸Šè¿½æº¯ç›´åˆ°æ‰¾åˆ°ä»¥ "tests" ç»“å°¾çš„ç›®å½•
    while not tests_dir.endswith("tests"):
        tests_dir = os.path.dirname(tests_dir)

    if append_path:
        return os.path.join(tests_dir, append_path)
    else:
        return tests_dir
# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå»é™¤æ–‡æœ¬ä¸­çš„æ¢è¡Œç¬¦ä»¥åŠå…¶å‰é¢çš„å†…å®¹
def apply_print_resets(buf):
    return re.sub(r"^.*\r", "", buf, 0, re.M)

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ–­è¨€æŸä¸ªå­—ç¬¦ä¸²æ˜¯å¦åœ¨ç»™å®šè¾“å‡ºä¸­ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
def assert_screenout(out, what):
    # å°†è¾“å‡ºæ–‡æœ¬è½¬æ¢ä¸ºå°å†™ï¼Œå¹¶åº”ç”¨å»é™¤æ¢è¡Œç¬¦çš„å¤„ç†
    out_pr = apply_print_resets(out).lower()
    # åœ¨å¤„ç†åçš„è¾“å‡ºæ–‡æœ¬ä¸­æŸ¥æ‰¾ç»™å®šå­—ç¬¦ä¸²çš„ä½ç½®
    match_str = out_pr.find(what.lower())
    # å¦‚æœæœªæ‰¾åˆ°ï¼ŒæŠ›å‡ºæ–­è¨€å¼‚å¸¸ï¼Œæ˜¾ç¤ºæœŸæœ›åœ¨è¾“å‡ºä¸­æ‰¾åˆ°çš„å­—ç¬¦ä¸²
    assert match_str != -1, f"expecting to find {what} in output: f{out_pr}"

# å®šä¹‰ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºæ•è·å’Œé‡æ”¾æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯è¾“å‡º
class CaptureStd:
    """
    Context manager to capture:

        - stdout: replay it, clean it up and make it available via `obj.out`
        - stderr: replay it and make it available via `obj.err`

    Args:
        out (`bool`, *optional*, defaults to `True`): Whether to capture stdout or not.
        err (`bool`, *optional*, defaults to `True`): Whether to capture stderr or not.
        replay (`bool`, *optional*, defaults to `True`): Whether to replay or not.
            By default each captured stream gets replayed back on context's exit, so that one can see what the test was
            doing. If this is a not wanted behavior and the captured data shouldn't be replayed, pass `replay=False` to
            disable this feature.

    Examples:

    ```python
    # to capture stdout only with auto-replay
    with CaptureStdout() as cs:
        print("Secret message")
    assert "message" in cs.out

    # to capture stderr only with auto-replay
    import sys

    with CaptureStderr() as cs:
        print("Warning: ", file=sys.stderr)
    assert "Warning" in cs.err

    # to capture both streams with auto-replay
    with CaptureStd() as cs:
        print("Secret message")
        print("Warning: ", file=sys.stderr)
    assert "message" in cs.out
    assert "Warning" in cs.err

    # to capture just one of the streams, and not the other, with auto-replay
    with CaptureStd(err=False) as cs:
        print("Secret message")
    assert "message" in cs.out
    # but best use the stream-specific subclasses

    # to capture without auto-replay
    with CaptureStd(replay=False) as cs:
        print("Secret message")
    assert "message" in cs.out
    ```"""
    
    # åˆå§‹åŒ–å‡½æ•°ï¼Œæ ¹æ®å‚æ•°è®¾ç½®æ˜¯å¦æ•è·å’Œé‡æ”¾ stdout å’Œ stderr
    def __init__(self, out=True, err=True, replay=True):
        self.replay = replay

        # å¦‚æœæ•è· stdout
        if out:
            self.out_buf = StringIO()
            self.out = "error: CaptureStd context is unfinished yet, called too early"
        else:
            self.out_buf = None
            self.out = "not capturing stdout"

        # å¦‚æœæ•è· stderr
        if err:
            self.err_buf = StringIO()
            self.err = "error: CaptureStd context is unfinished yet, called too early"
        else:
            self.err_buf = None
            self.err = "not capturing stderr"

    # è¿›å…¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ—¶çš„æ“ä½œï¼Œæ›¿æ¢ sys.stdout å’Œ sys.stderr åˆ°è‡ªå®šä¹‰ç¼“å†²åŒº
    def __enter__(self):
        # å¦‚æœæ•è· stdoutï¼Œåˆ™å°† sys.stdout æ›¿æ¢ä¸ºè‡ªå®šä¹‰ç¼“å†²åŒº
        if self.out_buf:
            self.out_old = sys.stdout
            sys.stdout = self.out_buf

        # å¦‚æœæ•è· stderrï¼Œåˆ™å°† sys.stderr æ›¿æ¢ä¸ºè‡ªå®šä¹‰ç¼“å†²åŒº
        if self.err_buf:
            self.err_old = sys.stderr
            sys.stderr = self.err_buf

        return self
    # å®šä¹‰ __exit__ æ–¹æ³•ï¼Œç”¨äºåœ¨å¯¹è±¡é€€å‡ºæ—¶æ‰§è¡Œæ¸…ç†æ“ä½œï¼Œæ¥æ”¶ä»»æ„å¼‚å¸¸å‚æ•°
    def __exit__(self, *exc):
        # å¦‚æœè¾“å‡ºç¼“å†²åŒºä¸ä¸ºç©ºï¼Œåˆ™æ¢å¤åŸå§‹çš„æ ‡å‡†è¾“å‡ºï¼Œå¹¶è·å–æ•è·çš„è¾“å‡ºå†…å®¹
        if self.out_buf:
            sys.stdout = self.out_old  # æ¢å¤åŸå§‹çš„æ ‡å‡†è¾“å‡º
            captured = self.out_buf.getvalue()  # è·å–æ•è·çš„æ ‡å‡†è¾“å‡ºå†…å®¹
            # å¦‚æœå¼€å¯é‡æ”¾æ¨¡å¼ï¼Œåˆ™å°†æ•è·çš„è¾“å‡ºå†…å®¹é‡æ–°å†™å…¥æ ‡å‡†è¾“å‡º
            if self.replay:
                sys.stdout.write(captured)
            # å°†æ•è·çš„è¾“å‡ºå†…å®¹åº”ç”¨äºå¤„ç†åçš„è¾“å‡ºç»“æœ
            self.out = apply_print_resets(captured)

        # å¦‚æœé”™è¯¯è¾“å‡ºç¼“å†²åŒºä¸ä¸ºç©ºï¼Œåˆ™æ¢å¤åŸå§‹çš„æ ‡å‡†é”™è¯¯è¾“å‡ºï¼Œå¹¶è·å–æ•è·çš„é”™è¯¯è¾“å‡ºå†…å®¹
        if self.err_buf:
            sys.stderr = self.err_old  # æ¢å¤åŸå§‹çš„æ ‡å‡†é”™è¯¯è¾“å‡º
            captured = self.err_buf.getvalue()  # è·å–æ•è·çš„æ ‡å‡†é”™è¯¯è¾“å‡ºå†…å®¹
            # å¦‚æœå¼€å¯é‡æ”¾æ¨¡å¼ï¼Œåˆ™å°†æ•è·çš„é”™è¯¯è¾“å‡ºå†…å®¹é‡æ–°å†™å…¥æ ‡å‡†é”™è¯¯è¾“å‡º
            if self.replay:
                sys.stderr.write(captured)
            # å°†æ•è·çš„é”™è¯¯è¾“å‡ºå†…å®¹ç›´æ¥èµ‹ç»™ self.err
            self.err = captured

    # å®šä¹‰ __repr__ æ–¹æ³•ï¼Œç”¨äºç”Ÿæˆå¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤ºå½¢å¼
    def __repr__(self):
        msg = ""  # åˆå§‹åŒ–æ¶ˆæ¯å­—ç¬¦ä¸²
        # å¦‚æœæœ‰æ ‡å‡†è¾“å‡ºç¼“å†²åŒºï¼Œåˆ™å°†æ ‡å‡†è¾“å‡ºçš„å€¼åŠ å…¥æ¶ˆæ¯å­—ç¬¦ä¸²
        if self.out_buf:
            msg += f"stdout: {self.out}\n"
        # å¦‚æœæœ‰é”™è¯¯è¾“å‡ºç¼“å†²åŒºï¼Œåˆ™å°†é”™è¯¯è¾“å‡ºçš„å€¼åŠ å…¥æ¶ˆæ¯å­—ç¬¦ä¸²
        if self.err_buf:
            msg += f"stderr: {self.err}\n"
        return msg  # è¿”å›ç”Ÿæˆçš„å­—ç¬¦ä¸²è¡¨ç¤ºå½¢å¼
# åœ¨æµ‹è¯•ä¸­æœ€å¥½åªæ•è·æ‰€éœ€çš„æµï¼Œå¦åˆ™å¯èƒ½ä¼šé”™è¿‡æŸäº›å†…å®¹ï¼Œæ‰€ä»¥é™¤ééœ€è¦åŒæ—¶æ•è·ä¸¤ä¸ªæµï¼Œå¦åˆ™ä½¿ç”¨ä»¥ä¸‹å­ç±»ï¼ˆæ›´å°‘çš„é”®å…¥ï¼‰ã€‚
# æˆ–è€…ï¼Œå¯ä»¥é…ç½® `CaptureStd` æ¥ç¦ç”¨ä¸éœ€è¦æµ‹è¯•çš„æµã€‚

class CaptureStdout(CaptureStd):
    """ä¸ CaptureStd ç›¸åŒï¼Œä½†åªæ•è· stdout"""

    def __init__(self, replay=True):
        super().__init__(err=False, replay=replay)


class CaptureStderr(CaptureStd):
    """ä¸ CaptureStd ç›¸åŒï¼Œä½†åªæ•è· stderr"""

    def __init__(self, replay=True):
        super().__init__(out=False, replay=replay)


class CaptureLogger:
    """
    ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºæ•è· `logging` æµ

    Args:
        logger: `logging` çš„ logger å¯¹è±¡

    Returns:
        æ•è·çš„è¾“å‡ºå¯ä»¥é€šè¿‡ `self.out` è·å–

    Example:

    ```python
    >>> from transformers import logging
    >>> from transformers.testing_utils import CaptureLogger

    >>> msg = "Testing 1, 2, 3"
    >>> logging.set_verbosity_info()
    >>> logger = logging.get_logger("transformers.models.bart.tokenization_bart")
    >>> with CaptureLogger(logger) as cl:
    ...     logger.info(msg)
    >>> assert cl.out, msg + "\n"
    ```
    """

    def __init__(self, logger):
        self.logger = logger
        self.io = StringIO()
        self.sh = logging.StreamHandler(self.io)
        self.out = ""

    def __enter__(self):
        self.logger.addHandler(self.sh)
        return self

    def __exit__(self, *exc):
        self.logger.removeHandler(self.sh)
        self.out = self.io.getvalue()

    def __repr__(self):
        return f"captured: {self.out}\n"


@contextlib.contextmanager
def LoggingLevel(level):
    """
    è¿™æ˜¯ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºä¸´æ—¶å°† transformers æ¨¡å—çš„æ—¥å¿—çº§åˆ«æ›´æ”¹ä¸ºæ‰€éœ€çš„å€¼ï¼Œå¹¶åœ¨ä½œç”¨åŸŸç»“æŸæ—¶æ¢å¤åˆ°åŸå§‹è®¾ç½®ã€‚

    Example:

    ```python
    with LoggingLevel(logging.INFO):
        AutoModel.from_pretrained("openai-community/gpt2")  # è°ƒç”¨ logger.info() å¤šæ¬¡
    ```
    """
    orig_level = transformers_logging.get_verbosity()
    try:
        transformers_logging.set_verbosity(level)
        yield
    finally:
        transformers_logging.set_verbosity(orig_level)


@contextlib.contextmanager
# æ”¹ç¼–è‡ª https://stackoverflow.com/a/64789046/9201239
def ExtendSysPath(path: Union[str, os.PathLike]) -> Iterator[None]:
    """
    ä¸´æ—¶å°†ç»™å®šè·¯å¾„æ·»åŠ åˆ° `sys.path`ã€‚

    Usage :

    ```python
    with ExtendSysPath("/path/to/dir"):
        mymodule = importlib.import_module("mymodule")
    ```
    """

    path = os.fspath(path)
    try:
        sys.path.insert(0, path)
        yield
    finally:
        sys.path.remove(path)


class TestCasePlus(unittest.TestCase):
    """
    è¿™ä¸ªç±»æ‰©å±•äº† *unittest.TestCase*ï¼Œå…·æœ‰é¢å¤–çš„åŠŸèƒ½ã€‚

    Feature 1: A set of fully resolved important file and dir path accessors.
    # ç‰¹æ€§ 1ï¼šä¸€ç»„å®Œå…¨è§£æçš„é‡è¦æ–‡ä»¶å’Œç›®å½•è·¯å¾„è®¿é—®å™¨ã€‚
    """
    class TestPaths:
        # è§£ææµ‹è¯•æ–‡ä»¶è·¯å¾„å’Œå…¶æ‰€åœ¨ç›®å½•çš„å·¥å…·ç±»
        def __init__(self):
            # åˆå§‹åŒ–ï¼Œè·å–å½“å‰æµ‹è¯•æ–‡ä»¶çš„è·¯å¾„
            self.test_file_path = pathlib.Path(__file__).resolve()
            # è·å–å½“å‰æµ‹è¯•æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•è·¯å¾„
            self.test_file_dir = self.test_file_path.parent
            # è·å–æµ‹è¯•å¥—ä»¶ `tests` çš„ç›®å½•è·¯å¾„
            self.tests_dir = self.test_file_dir.parent
            # è·å–æµ‹è¯•å¥—ä»¶ `examples` çš„ç›®å½•è·¯å¾„
            self.examples_dir = self.tests_dir / 'examples'
            # è·å–ä»£ç åº“çš„æ ¹ç›®å½•è·¯å¾„
            self.repo_root_dir = self.tests_dir.parent
            # è·å– `src` ç›®å½•è·¯å¾„ï¼Œå³ `transformers` å­ç›®å½•æ‰€åœ¨çš„ä½ç½®
            self.src_dir = self.repo_root_dir / 'src'

            # å°†ä»¥ä¸Šè·¯å¾„å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²å½¢å¼
            self.test_file_path_str = str(self.test_file_path)
            self.test_file_dir_str = str(self.test_file_dir)
            self.tests_dir_str = str(self.tests_dir)
            self.examples_dir_str = str(self.examples_dir)
            self.repo_root_dir_str = str(self.repo_root_dir)
            self.src_dir_str = str(self.src_dir)

    # åŠŸèƒ½2ï¼šæä¾›çµæ´»çš„è‡ªåŠ¨æ¸…ç†ä¸´æ—¶ç›®å½•ï¼Œç¡®ä¿æµ‹è¯•ç»“æŸåè‡ªåŠ¨åˆ é™¤
    1. åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„ä¸´æ—¶ç›®å½•ï¼š

    ```python
    def test_whatever(self):
        # è°ƒç”¨æ–¹æ³•è·å–ä¸€ä¸ªè‡ªåŠ¨åˆ é™¤çš„ä¸´æ—¶ç›®å½•è·¯å¾„
        tmp_dir = self.get_auto_remove_tmp_dir()
    ```

    `tmp_dir` å°†åŒ…å«åˆ›å»ºçš„ä¸´æ—¶ç›®å½•è·¯å¾„ã€‚è¯¥ç›®å½•å°†åœ¨æµ‹è¯•ç»“æŸæ—¶è‡ªåŠ¨åˆ é™¤ã€‚

    2. åˆ›å»ºè‡ªé€‰çš„ä¸´æ—¶ç›®å½•ï¼Œåœ¨æµ‹è¯•å¼€å§‹å‰ç¡®ä¿å®ƒä¸ºç©ºï¼Œå¹¶ä¸”æµ‹è¯•ç»“æŸåä¸æ¸…ç©ºå®ƒï¼š

    ```python
    def test_whatever(self):
        # è°ƒç”¨æ–¹æ³•è·å–ä¸€ä¸ªæŒ‡å®šè·¯å¾„çš„è‡ªåŠ¨åˆ é™¤ä¸´æ—¶ç›®å½•è·¯å¾„
        tmp_dir = self.get_auto_remove_tmp_dir("./xxx")
    ```

    è¿™åœ¨è°ƒè¯•æ—¶å¾ˆæœ‰ç”¨ï¼Œå½“ä½ æƒ³ç›‘è§†ç‰¹å®šç›®å½•å¹¶ç¡®ä¿ä¹‹å‰çš„æµ‹è¯•æ²¡æœ‰ç•™ä¸‹ä»»ä½•æ•°æ®æ—¶ã€‚

    3. ä½ å¯ä»¥é€šè¿‡ç›´æ¥è¦†ç›– `before` å’Œ `after` å‚æ•°æ¥é‡å†™å‰ä¸¤ä¸ªé€‰é¡¹ï¼Œä»è€Œå®ç°ä»¥ä¸‹è¡Œä¸ºï¼š

    `before=True`ï¼šæµ‹è¯•å¼€å§‹æ—¶ä¸´æ—¶ç›®å½•å°†å§‹ç»ˆè¢«æ¸…ç©ºã€‚

    `before=False`ï¼šå¦‚æœä¸´æ—¶ç›®å½•å·²ç»å­˜åœ¨ï¼Œåˆ™ä¿ç•™ä»»ä½•ç°æœ‰æ–‡ä»¶ã€‚

    `after=True`ï¼šæµ‹è¯•ç»“æŸæ—¶ä¸´æ—¶ç›®å½•å°†å§‹ç»ˆè¢«åˆ é™¤ã€‚

    `after=False`ï¼šæµ‹è¯•ç»“æŸæ—¶ä¸´æ—¶ç›®å½•å°†ä¿æŒä¸å˜ã€‚

    æ³¨æ„1ï¼šä¸ºäº†å®‰å…¨åœ°è¿è¡Œç±»ä¼¼äº `rm -r` çš„æ“ä½œï¼Œè¯·åªå…è®¸åœ¨é¡¹ç›®ä»“åº“æ£€å‡ºçš„å­ç›®å½•ä¸­ä½¿ç”¨æ˜¾å¼çš„ `tmp_dir`ï¼Œä»¥é¿å…æ„å¤–åˆ é™¤ `/tmp` æˆ–ç±»ä¼¼çš„é‡è¦æ–‡ä»¶ç³»ç»Ÿéƒ¨åˆ†ã€‚å³è¯·å§‹ç»ˆä¼ é€’ä»¥ `./` å¼€å¤´çš„è·¯å¾„ã€‚

    æ³¨æ„2ï¼šæ¯ä¸ªæµ‹è¯•å¯ä»¥æ³¨å†Œå¤šä¸ªä¸´æ—¶ç›®å½•ï¼Œå®ƒä»¬éƒ½å°†è‡ªåŠ¨åˆ é™¤ï¼Œé™¤éå¦æœ‰è¦æ±‚ã€‚

    Feature 3: è·å–è®¾ç½®äº†ç‰¹å®šäºå½“å‰æµ‹è¯•å¥—ä»¶çš„ `PYTHONPATH` çš„ `os.environ` å¯¹è±¡çš„å‰¯æœ¬ã€‚è¿™
    def setUp(self):
        # get_auto_remove_tmp_dir feature:
        # åˆå§‹åŒ–ä¸´æ—¶ç›®å½•æ¸…ç†åˆ—è¡¨
        self.teardown_tmp_dirs = []

        # figure out the resolved paths for repo_root, tests, examples, etc.
        # è·å–å½“å‰æµ‹è¯•ç±»æ‰€åœ¨æ–‡ä»¶çš„è·¯å¾„
        self._test_file_path = inspect.getfile(self.__class__)
        path = Path(self._test_file_path).resolve()
        # è·å–æµ‹è¯•æ–‡ä»¶æ‰€åœ¨çš„çˆ¶ç›®å½•
        self._test_file_dir = path.parents[0]
        # é€çº§å‘ä¸ŠæŸ¥æ‰¾ï¼Œç¡®å®šé¡¹ç›®æ ¹ç›®å½•
        for up in [1, 2, 3]:
            tmp_dir = path.parents[up]
            if (tmp_dir / "src").is_dir() and (tmp_dir / "tests").is_dir():
                break
        # å¦‚æœæ‰¾åˆ°æ ¹ç›®å½•åˆ™è®¾å®šä¸ºé¡¹ç›®æ ¹ç›®å½•ï¼Œå¦åˆ™æŠ›å‡ºå¼‚å¸¸
        if tmp_dir:
            self._repo_root_dir = tmp_dir
        else:
            raise ValueError(f"can't figure out the root of the repo from {self._test_file_path}")
        # è®¾å®šå„ä¸ªç›®å½•è·¯å¾„
        self._tests_dir = self._repo_root_dir / "tests"
        self._examples_dir = self._repo_root_dir / "examples"
        self._src_dir = self._repo_root_dir / "src"

    @property
    def test_file_path(self):
        # è¿”å›æµ‹è¯•æ–‡ä»¶çš„è·¯å¾„å¯¹è±¡
        return self._test_file_path

    @property
    def test_file_path_str(self):
        # è¿”å›æµ‹è¯•æ–‡ä»¶çš„è·¯å¾„å­—ç¬¦ä¸²
        return str(self._test_file_path)

    @property
    def test_file_dir(self):
        # è¿”å›æµ‹è¯•æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•å¯¹è±¡
        return self._test_file_dir

    @property
    def test_file_dir_str(self):
        # è¿”å›æµ‹è¯•æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•å­—ç¬¦ä¸²
        return str(self._test_file_dir)

    @property
    def tests_dir(self):
        # è¿”å›é¡¹ç›®ä¸­ tests ç›®å½•çš„è·¯å¾„å¯¹è±¡
        return self._tests_dir

    @property
    def tests_dir_str(self):
        # è¿”å›é¡¹ç›®ä¸­ tests ç›®å½•çš„è·¯å¾„å­—ç¬¦ä¸²
        return str(self._tests_dir)

    @property
    def examples_dir(self):
        # è¿”å›é¡¹ç›®ä¸­ examples ç›®å½•çš„è·¯å¾„å¯¹è±¡
        return self._examples_dir

    @property
    def examples_dir_str(self):
        # è¿”å›é¡¹ç›®ä¸­ examples ç›®å½•çš„è·¯å¾„å­—ç¬¦ä¸²
        return str(self._examples_dir)

    @property
    def repo_root_dir(self):
        # è¿”å›é¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„å¯¹è±¡
        return self._repo_root_dir

    @property
    def repo_root_dir_str(self):
        # è¿”å›é¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„å­—ç¬¦ä¸²
        return str(self._repo_root_dir)

    @property
    def src_dir(self):
        # è¿”å›é¡¹ç›®ä¸­ src ç›®å½•çš„è·¯å¾„å¯¹è±¡
        return self._src_dir

    @property
    def src_dir_str(self):
        # è¿”å›é¡¹ç›®ä¸­ src ç›®å½•çš„è·¯å¾„å­—ç¬¦ä¸²
        return str(self._src_dir)

    def get_env(self):
        """
        Return a copy of the `os.environ` object that sets up `PYTHONPATH` correctly, depending on the test suite it's
        invoked from. This is useful for invoking external programs from the test suite - e.g. distributed training.

        It always inserts `./src` first, then `./tests` or `./examples` depending on the test suite type and finally
        the preset `PYTHONPATH` if any (all full resolved paths).

        """
        # åˆ›å»ºä¸€ä¸ªç¯å¢ƒå˜é‡çš„å‰¯æœ¬
        env = os.environ.copy()
        # åˆå§‹åŒ–è·¯å¾„åˆ—è¡¨ï¼Œå§‹ç»ˆåŒ…å«é¡¹ç›®ä¸­ src ç›®å½•
        paths = [self.src_dir_str]
        # æ ¹æ®æµ‹è¯•æ–‡ä»¶æ‰€åœ¨è·¯å¾„åˆ¤æ–­å½“å‰æµ‹è¯•ç±»å‹ï¼Œæ·»åŠ å¯¹åº”çš„ tests æˆ– examples ç›®å½•
        if "/examples" in self.test_file_dir_str:
            paths.append(self.examples_dir_str)
        else:
            paths.append(self.tests_dir_str)
        # æ·»åŠ é¢„è®¾çš„ PYTHONPATH å¦‚æœæœ‰çš„è¯ï¼Œå°†å…¶è§£æåçš„å®Œæ•´è·¯å¾„ä¹ŸåŠ å…¥è·¯å¾„åˆ—è¡¨
        paths.append(env.get("PYTHONPATH", ""))

        # å°†è·¯å¾„åˆ—è¡¨åˆå¹¶ä¸ºä»¥ ":" åˆ†éš”çš„å­—ç¬¦ä¸²ï¼Œå¹¶è®¾ç½®ä¸º PYTHONPATH ç¯å¢ƒå˜é‡
        env["PYTHONPATH"] = ":".join(paths)
        return env
    def get_auto_remove_tmp_dir(self, tmp_dir=None, before=None, after=None):
        """
        Args:
            tmp_dir (`string`, *optional*):
                if `None`:

                   - a unique temporary path will be created
                   - sets `before=True` if `before` is `None`
                   - sets `after=True` if `after` is `None`
                else:

                   - `tmp_dir` will be created
                   - sets `before=True` if `before` is `None`
                   - sets `after=False` if `after` is `None`
            before (`bool`, *optional*):
                If `True` and the `tmp_dir` already exists, make sure to empty it right away if `False` and the
                `tmp_dir` already exists, any existing files will remain there.
            after (`bool`, *optional*):
                If `True`, delete the `tmp_dir` at the end of the test if `False`, leave the `tmp_dir` and its contents
                intact at the end of the test.

        Returns:
            tmp_dir(`string`): either the same value as passed via *tmp_dir* or the path to the auto-selected tmp dir
        """
        if tmp_dir is not None:
            # å®šä¹‰è‡ªå®šä¹‰è·¯å¾„æä¾›æ—¶çš„é¢„æœŸè¡Œä¸º
            # è¿™é€šå¸¸è¡¨ç¤ºè°ƒè¯•æ¨¡å¼ï¼Œæˆ‘ä»¬å¸Œæœ›æœ‰ä¸€ä¸ªæ˜“äºå®šä½çš„ç›®å½•ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹æ€§ï¼š
            # 1. åœ¨æµ‹è¯•ä¹‹å‰æ¸…ç©ºï¼ˆå¦‚æœå·²ç»å­˜åœ¨ï¼‰
            # 2. åœ¨æµ‹è¯•ç»“æŸåä¿ç•™ä¸å˜
            if before is None:
                before = True
            if after is None:
                after = False

            # ä½¿ç”¨æä¾›çš„è·¯å¾„
            path = Path(tmp_dir).resolve()

            # ä¸ºé¿å…å½±å“æ–‡ä»¶ç³»ç»Ÿå…¶ä»–éƒ¨åˆ†ï¼Œåªå…è®¸ç›¸å¯¹è·¯å¾„
            if not tmp_dir.startswith("./"):
                raise ValueError(
                    f"`tmp_dir` can only be a relative path, i.e. `./some/path`, but received `{tmp_dir}`"
                )

            # ç¡®ä¿ç›®å½•åœ¨å¼€å§‹æ—¶ä¸ºç©º
            if before is True and path.exists():
                shutil.rmtree(tmp_dir, ignore_errors=True)

            path.mkdir(parents=True, exist_ok=True)

        else:
            # å®šä¹‰è‡ªåŠ¨ç”Ÿæˆå”¯ä¸€ä¸´æ—¶è·¯å¾„æ—¶çš„é¢„æœŸè¡Œä¸º
            # ï¼ˆéè°ƒè¯•æ¨¡å¼ï¼‰ï¼Œè¿™é‡Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåœ¨æµ‹è¯•ä¹‹å‰ä¸ºç©ºçš„å”¯ä¸€ä¸´æ—¶ç›®å½•ï¼Œå¹¶ä¸”åœ¨æµ‹è¯•ç»“æŸåå®Œå…¨åˆ é™¤
            if before is None:
                before = True
            if after is None:
                after = True

            # ä½¿ç”¨å”¯ä¸€ä¸´æ—¶ç›®å½•ï¼ˆå§‹ç»ˆä¸ºç©ºï¼Œä¸è€ƒè™‘`before`ï¼‰
            tmp_dir = tempfile.mkdtemp()

        if after is True:
            # æ³¨å†Œå¾…åˆ é™¤çš„ä¸´æ—¶ç›®å½•
            self.teardown_tmp_dirs.append(tmp_dir)

        return tmp_dir
    #python
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºæ‰§è¡Œå•è¡Œ Python ä»£ç å¹¶è¿”å›ç¨‹åºè¿è¡Œæ—¶çš„æœ€å¤§å†…å­˜å ç”¨æƒ…å†µ
    def python_one_liner_max_rss(self, one_liner_str):
        """
        Runs the passed python one liner (just the code) and returns how much max cpu memory was used to run the
        program.

        Args:
            one_liner_str (`string`):
                a python one liner code that gets passed to `python -c`

        Returns:
            max cpu memory bytes used to run the program. This value is likely to vary slightly from run to run.

        Requirements:
            this helper needs `/usr/bin/time` to be installed (`apt install time`)

        Example:

        ```
        one_liner_str = 'from transformers import AutoModel; AutoModel.from_pretrained("google-t5/t5-large")'
        max_rss = self.python_one_liner_max_rss(one_liner_str)
        ```
        """

        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å®‰è£…äº† `/usr/bin/time`ï¼Œå¦‚æœæ²¡æœ‰åˆ™æŠ›å‡ºé”™è¯¯
        if not cmd_exists("/usr/bin/time"):
            raise ValueError("/usr/bin/time is required, install with `apt install time`")

        # æ„å»ºå‘½ä»¤ï¼Œä½¿ç”¨ `/usr/bin/time` æ¥ç›‘æµ‹ Python å•è¡Œä»£ç çš„å†…å­˜ä½¿ç”¨æƒ…å†µ
        cmd = shlex.split(f"/usr/bin/time -f %M python -c '{one_liner_str}'")
        
        # ä½¿ç”¨ CaptureStd ç±»æ•è·å­è¿›ç¨‹æ‰§è¡Œç»“æœ
        with CaptureStd() as cs:
            execute_subprocess_async(cmd, env=self.get_env())

        # ä»æ•è·çš„é”™è¯¯è¾“å‡ºä¸­æå–æœ€å¤§ RSSï¼ˆResident Set Sizeï¼‰ï¼Œå•ä½ä¸º KBï¼Œè½¬æ¢ä¸ºå­—èŠ‚
        max_rss = int(cs.err.split("\n")[-2].replace("stderr: ", "")) * 1024

        # è¿”å›æœ€å¤§å†…å­˜å ç”¨é‡
        return max_rss

    # æµ‹è¯•ç¯å¢ƒæ¸…ç†æ–¹æ³•ï¼Œç”¨äºåˆ é™¤ä¸´æ—¶ç›®å½•å’ŒåŠ é€Ÿåº“çŠ¶æ€å˜é‡
    def tearDown(self):
        # å¾ªç¯éå†æ³¨å†Œçš„ä¸´æ—¶ç›®å½•åˆ—è¡¨ï¼Œåˆ é™¤è¿™äº›ä¸´æ—¶ç›®å½•åŠå…¶å†…å®¹
# å®šä¹‰ä¸€ä¸ªä¾¿æ·çš„åŒ…è£…å™¨ï¼Œå…è®¸è®¾ç½®ä¸´æ—¶ç¯å¢ƒå˜é‡ï¼Œä»¥å­—å…¸å½¢å¼æ›´æ–°os.environ
def mockenv(**kwargs):
    return mock.patch.dict(os.environ, kwargs)


# å®šä¹‰ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä¸´æ—¶æ›´æ–°os.environå­—å…¸ã€‚ç±»ä¼¼äºmockenv
@contextlib.contextmanager
def mockenv_context(*remove, **update):
    """
    ä¸´æ—¶æ›´æ–°`os.environ`å­—å…¸ã€‚ç±»ä¼¼äºmockenvã€‚

    `os.environ`å­—å…¸ä¼šè¢«åŸåœ°æ›´æ–°ï¼Œä»¥ç¡®ä¿ä¿®æ”¹åœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½æœ‰æ•ˆã€‚

    Args:
      remove: è¦ç§»é™¤çš„ç¯å¢ƒå˜é‡ã€‚
      update: è¦æ·»åŠ /æ›´æ–°çš„ç¯å¢ƒå˜é‡åŠå…¶å€¼çš„å­—å…¸ã€‚
    """
    env = os.environ
    update = update or {}
    remove = remove or []

    # æ‰€æœ‰è¢«æ›´æ–°æˆ–ç§»é™¤çš„ç¯å¢ƒå˜é‡çš„é›†åˆ
    stomped = (set(update.keys()) | set(remove)) & set(env.keys())
    # é€€å‡ºæ—¶éœ€è¦æ¢å¤çš„ç¯å¢ƒå˜é‡åŠå…¶å€¼
    update_after = {k: env[k] for k in stomped}
    # é€€å‡ºæ—¶éœ€è¦ç§»é™¤çš„ç¯å¢ƒå˜é‡
    remove_after = frozenset(k for k in update if k not in env)

    try:
        # æ‰§è¡Œæ›´æ–°æ“ä½œ
        env.update(update)
        [env.pop(k, None) for k in remove]
        yield
    finally:
        # æ¢å¤ç¯å¢ƒå˜é‡åˆ°æ›´æ–°å‰çš„çŠ¶æ€
        env.update(update_after)
        [env.pop(k) for k in remove_after]


# --- pytest é…ç½®å‡½æ•° --- #

# é¿å…ä»å¤šä¸ªconftest.pyæ–‡ä»¶ä¸­è°ƒç”¨å¤šæ¬¡ï¼Œç¡®ä¿ä»…è°ƒç”¨ä¸€æ¬¡
pytest_opt_registered = {}


def pytest_addoption_shared(parser):
    """
    æ­¤å‡½æ•°åº”ä»`conftest.py`ä¸­çš„`pytest_addoption`åŒ…è£…å™¨è°ƒç”¨ï¼Œå¿…é¡»åœ¨é‚£é‡Œå®šä¹‰ã€‚

    å…è®¸åŒæ—¶åŠ è½½ä¸¤ä¸ª`conftest.py`æ–‡ä»¶ï¼Œè€Œä¸ä¼šç”±äºæ·»åŠ ç›¸åŒçš„`pytest`é€‰é¡¹è€Œå¯¼è‡´å¤±è´¥ã€‚
    """
    option = "--make-reports"
    if option not in pytest_opt_registered:
        parser.addoption(
            option,
            action="store",
            default=False,
            help="ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶ã€‚æ­¤é€‰é¡¹çš„å€¼ç”¨ä½œæŠ¥å‘Šåç§°çš„å‰ç¼€ã€‚",
        )
        pytest_opt_registered[option] = 1


def pytest_terminal_summary_main(tr, id):
    """
    åœ¨æµ‹è¯•å¥—ä»¶è¿è¡Œç»“æŸæ—¶ç”Ÿæˆå¤šä¸ªæŠ¥å‘Šæ–‡ä»¶ï¼Œæ¯ä¸ªæŠ¥å‘Šæ–‡ä»¶éƒ½å­˜å‚¨åœ¨å½“å‰ç›®å½•ä¸­ã€‚æŠ¥å‘Šæ–‡ä»¶ä»¥æµ‹è¯•å¥—ä»¶åç§°ä½œä¸ºå‰ç¼€ã€‚

    æ­¤å‡½æ•°æ¨¡æ‹Ÿ`--duration`å’Œ`-rA`pytestå‚æ•°ã€‚

    æ­¤å‡½æ•°åº”ä»`conftest.py`ä¸­çš„`pytest_terminal_summary`åŒ…è£…å™¨è°ƒç”¨ï¼Œå¿…é¡»åœ¨é‚£é‡Œå®šä¹‰ã€‚

    Args:
    - tr: ä»`conftest.py`ä¼ é€’çš„`terminalreporter`
    - id: å”¯ä¸€çš„IDï¼Œå¦‚`tests`æˆ–`examples`ï¼Œå°†è¢«åˆå¹¶åˆ°æœ€ç»ˆæŠ¥å‘Šæ–‡ä»¶åä¸­ï¼Œè¿™æ˜¯å› ä¸ºæŸäº›ä½œä¸šä¼šå¤šæ¬¡è¿è¡Œpytestï¼Œå› æ­¤ä¸èƒ½ç›¸äº’è¦†ç›–ã€‚
    """
    """
    NB: this functions taps into a private _pytest API and while unlikely, it could break should pytest do internal
    changes - also it calls default internal methods of terminalreporter which can be hijacked by various `pytest-`
    plugins and interfere.

    """

    # å¯¼å…¥åˆ›å»ºç»ˆç«¯å†™å…¥å™¨çš„å‡½æ•°
    from _pytest.config import create_terminal_writer

    # å¦‚æœ id é•¿åº¦ä¸º 0ï¼Œåˆ™å°†å…¶è®¾ç½®ä¸ºé»˜è®¤å€¼ "tests"
    if not len(id):
        id = "tests"

    # è·å– terminalreporter çš„é…ç½®
    config = tr.config

    # è·å–åŸå§‹çš„ç»ˆç«¯å†™å…¥å™¨
    orig_writer = config.get_terminal_writer()

    # è·å–åŸå§‹çš„ traceback æ ·å¼é€‰é¡¹
    orig_tbstyle = config.option.tbstyle

    # è·å– terminalreporter çš„ reportchars
    orig_reportchars = tr.reportchars

    # è®¾ç½®æŠ¥å‘Šç›®å½•ä¸º "reports/{id}"
    dir = f"reports/{id}"

    # åˆ›å»ºæŠ¥å‘Šç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
    Path(dir).mkdir(parents=True, exist_ok=True)

    # è®¾ç½®æŠ¥å‘Šæ–‡ä»¶ååˆ—è¡¨
    report_files = {
        k: f"{dir}/{k}.txt"
        for k in [
            "durations",
            "errors",
            "failures_long",
            "failures_short",
            "failures_line",
            "passes",
            "stats",
            "summary_short",
            "warnings",
        ]
    }

    # custom durations report
    # note: there is no need to call pytest --durations=XX to get this separate report
    # adapted from https://github.com/pytest-dev/pytest/blob/897f151e/src/_pytest/runner.py#L66
    # è‡ªå®šä¹‰æŒç»­æ—¶é—´æŠ¥å‘Š

    # åˆå§‹åŒ–æŒç»­æ—¶é—´åˆ—è¡¨
    dlist = []

    # éå†ç»Ÿè®¡æ•°æ®ä¸­çš„æŠ¥å‘Šåˆ—è¡¨
    for replist in tr.stats.values():
        for rep in replist:
            # å¦‚æœæŠ¥å‘Šå¯¹è±¡å…·æœ‰ "duration" å±æ€§ï¼Œåˆ™å°†å…¶æ·»åŠ åˆ°æŒç»­æ—¶é—´åˆ—è¡¨ä¸­
            if hasattr(rep, "duration"):
                dlist.append(rep)

    # å¦‚æœæŒç»­æ—¶é—´åˆ—è¡¨ä¸ä¸ºç©º
    if dlist:
        # æŒ‰ç…§æŒç»­æ—¶é—´å€’åºæ’åº
        dlist.sort(key=lambda x: x.duration, reverse=True)

        # æ‰“å¼€æŒç»­æ—¶é—´æŠ¥å‘Šæ–‡ä»¶
        with open(report_files["durations"], "w") as f:
            durations_min = 0.05  # sec
            f.write("slowest durations\n")
            # éå†æŒç»­æ—¶é—´åˆ—è¡¨ï¼Œå†™å…¥æŠ¥å‘Šæ–‡ä»¶
            for i, rep in enumerate(dlist):
                if rep.duration < durations_min:
                    f.write(f"{len(dlist)-i} durations < {durations_min} secs were omitted")
                    break
                f.write(f"{rep.duration:02.2f}s {rep.when:<8} {rep.nodeid}\n")

    # å®šä¹‰ summary_failures_short å‡½æ•°
    def summary_failures_short(tr):
        # è·å–æ‰€æœ‰å¤±è´¥æŠ¥å‘Š
        reports = tr.getreports("failed")
        if not reports:
            return
        # å†™å…¥åˆ†éš”ç¬¦å’Œæ ‡é¢˜
        tr.write_sep("=", "FAILURES SHORT STACK")
        # éå†å¤±è´¥æŠ¥å‘Šï¼Œè¾“å‡ºç²¾ç®€çš„å¤±è´¥ä¿¡æ¯
        for rep in reports:
            msg = tr._getfailureheadline(rep)
            tr.write_sep("_", msg, red=True, bold=True)
            # çœç•¥é•¿æŠ¥å‘Šçš„éå¿…è¦éƒ¨åˆ†ï¼Œåªä¿ç•™æœ€åä¸€ä¸ªå¸§
            longrepr = re.sub(r".*_ _ _ (_ ){10,}_ _ ", "", rep.longreprtext, 0, re.M | re.S)
            tr._tw.line(longrepr)
            # æ³¨æ„ï¼šä¸è¾“å‡ºä»»ä½• rep.sectionsï¼Œä»¥ä¿æŒæŠ¥å‘Šç®€æ´

    # ä½¿ç”¨é¢„å®šä¹‰çš„æŠ¥å‘Šå‡½æ•°ï¼Œå°†è¾“å‡ºé‡å®šå‘åˆ°å„è‡ªçš„æ–‡ä»¶
    # adapted from https://github.com/pytest-dev/pytest/blob/897f151e/src/_pytest/terminal.py#L814
    # æ³¨æ„ï¼šæŸäº› pytest æ’ä»¶å¯èƒ½é€šè¿‡åŠ«æŒé»˜è®¤çš„ `terminalreporter` æ¥å¹²æ‰°

    # è®¾ç½® traceback æ ·å¼é€‰é¡¹ä¸º "auto"ï¼Œå³å…¨ traceback æ˜¾ç¤º
    config.option.tbstyle = "auto"
    # ä½¿ç”¨ report_files å­—å…¸ä¸­çš„ "failures_long" é”®åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶å¯¹è±¡ fï¼Œå¹¶ä»¥å†™æ¨¡å¼æ‰“å¼€
    with open(report_files["failures_long"], "w") as f:
        # ä¸ºæµ‹è¯•è¿è¡Œå™¨ tr åˆ›å»ºä¸€ä¸ªæ–°çš„ç»ˆç«¯å†™å…¥å™¨ï¼Œå¹¶å°†å…¶æŒ‡å®šä¸º _tw å±æ€§
        tr._tw = create_terminal_writer(config, f)
        # ç”Ÿæˆè¯¦ç»†çš„å¤±è´¥æ‘˜è¦æŠ¥å‘Š
        tr.summary_failures()

    # è®¾ç½®é…ç½®é€‰é¡¹ config.option.tbstyle ä¸º "short"ï¼Œç”¨äºçŸ­æ ¼å¼çš„å›æº¯ä¿¡æ¯
    # config.option.tbstyle = "short" # short tb
    # ä½¿ç”¨ report_files å­—å…¸ä¸­çš„ "failures_short" é”®åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶å¯¹è±¡ fï¼Œå¹¶ä»¥å†™æ¨¡å¼æ‰“å¼€
    with open(report_files["failures_short"], "w") as f:
        # ä¸ºæµ‹è¯•è¿è¡Œå™¨ tr åˆ›å»ºä¸€ä¸ªæ–°çš„ç»ˆç«¯å†™å…¥å™¨ï¼Œå¹¶å°†å…¶æŒ‡å®šä¸º _tw å±æ€§
        tr._tw = create_terminal_writer(config, f)
        # ç”Ÿæˆç®€çŸ­çš„å¤±è´¥æ‘˜è¦æŠ¥å‘Š
        summary_failures_short(tr)

    # è®¾ç½®é…ç½®é€‰é¡¹ config.option.tbstyle ä¸º "line"ï¼Œæ¯ä¸ªé”™è¯¯å•ç‹¬ä¸€è¡Œæ˜¾ç¤º
    config.option.tbstyle = "line"  # one line per error
    # ä½¿ç”¨ report_files å­—å…¸ä¸­çš„ "failures_line" é”®åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶å¯¹è±¡ fï¼Œå¹¶ä»¥å†™æ¨¡å¼æ‰“å¼€
    with open(report_files["failures_line"], "w") as f:
        # ä¸ºæµ‹è¯•è¿è¡Œå™¨ tr åˆ›å»ºä¸€ä¸ªæ–°çš„ç»ˆç«¯å†™å…¥å™¨ï¼Œå¹¶å°†å…¶æŒ‡å®šä¸º _tw å±æ€§
        tr._tw = create_terminal_writer(config, f)
        # ç”ŸæˆæŒ‰è¡Œæ˜¾ç¤ºçš„å¤±è´¥æ‘˜è¦æŠ¥å‘Š
        tr.summary_failures()

    # ä½¿ç”¨ report_files å­—å…¸ä¸­çš„ "errors" é”®åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶å¯¹è±¡ fï¼Œå¹¶ä»¥å†™æ¨¡å¼æ‰“å¼€
    with open(report_files["errors"], "w") as f:
        # ä¸ºæµ‹è¯•è¿è¡Œå™¨ tr åˆ›å»ºä¸€ä¸ªæ–°çš„ç»ˆç«¯å†™å…¥å™¨ï¼Œå¹¶å°†å…¶æŒ‡å®šä¸º _tw å±æ€§
        tr._tw = create_terminal_writer(config, f)
        # ç”Ÿæˆé”™è¯¯æ‘˜è¦æŠ¥å‘Š
        tr.summary_errors()

    # ä½¿ç”¨ report_files å­—å…¸ä¸­çš„ "warnings" é”®åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶å¯¹è±¡ fï¼Œå¹¶ä»¥å†™æ¨¡å¼æ‰“å¼€
    with open(report_files["warnings"], "w") as f:
        # ä¸ºæµ‹è¯•è¿è¡Œå™¨ tr åˆ›å»ºä¸€ä¸ªæ–°çš„ç»ˆç«¯å†™å…¥å™¨ï¼Œå¹¶å°†å…¶æŒ‡å®šä¸º _tw å±æ€§
        tr._tw = create_terminal_writer(config, f)
        # ç”Ÿæˆä¸€èˆ¬è­¦å‘Šçš„æ‘˜è¦æŠ¥å‘Š
        tr.summary_warnings()  # normal warnings
        # ç”Ÿæˆæœ€ç»ˆè­¦å‘Šçš„æ‘˜è¦æŠ¥å‘Š
        tr.summary_warnings()  # final warnings

    # è®¾ç½®æµ‹è¯•è¿è¡Œå™¨ tr çš„æŠ¥å‘Šå­—ç¬¦é›†ä¸º "wPpsxXEf"ï¼Œæ¨¡æ‹Ÿ "-rA" å‚æ•°ï¼ˆç”¨äº summary_passes() å’Œ short_test_summary()ï¼‰
    tr.reportchars = "wPpsxXEf"

    # è·³è¿‡ "passes" æŠ¥å‘Šç”Ÿæˆï¼Œå› ä¸ºå®ƒå¼€å§‹èŠ±è´¹è¶…è¿‡ 5 åˆ†é’Ÿï¼Œæœ‰æ—¶åœ¨ CircleCI ä¸Šè¶…æ—¶ï¼ˆå¦‚æœè¶…è¿‡ 10 åˆ†é’Ÿï¼‰
    # ï¼ˆæ­¤éƒ¨åˆ†åœ¨ç»ˆç«¯ä¸Šä¸ç”Ÿæˆä»»ä½•è¾“å‡ºï¼‰
    # ï¼ˆå¦å¤–ï¼Œçœ‹èµ·æ¥æ­¤æŠ¥å‘Šæ²¡æœ‰æœ‰ç”¨ä¿¡æ¯ï¼Œæˆ‘ä»¬å¾ˆå°‘éœ€è¦æŸ¥çœ‹å®ƒï¼‰
    # with open(report_files["passes"], "w") as f:
    #     tr._tw = create_terminal_writer(config, f)
    #     tr.summary_passes()

    # ä½¿ç”¨ report_files å­—å…¸ä¸­çš„ "summary_short" é”®åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶å¯¹è±¡ fï¼Œå¹¶ä»¥å†™æ¨¡å¼æ‰“å¼€
    with open(report_files["summary_short"], "w") as f:
        # ä¸ºæµ‹è¯•è¿è¡Œå™¨ tr åˆ›å»ºä¸€ä¸ªæ–°çš„ç»ˆç«¯å†™å…¥å™¨ï¼Œå¹¶å°†å…¶æŒ‡å®šä¸º _tw å±æ€§
        tr._tw = create_terminal_writer(config, f)
        # ç”Ÿæˆç®€çŸ­çš„æµ‹è¯•æ‘˜è¦æŠ¥å‘Š
        tr.short_test_summary()

    # ä½¿ç”¨ report_files å­—å…¸ä¸­çš„ "stats" é”®åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶å¯¹è±¡ fï¼Œå¹¶ä»¥å†™æ¨¡å¼æ‰“å¼€
    with open(report_files["stats"], "w") as f:
        # ä¸ºæµ‹è¯•è¿è¡Œå™¨ tr åˆ›å»ºä¸€ä¸ªæ–°çš„ç»ˆç«¯å†™å…¥å™¨ï¼Œå¹¶å°†å…¶æŒ‡å®šä¸º _tw å±æ€§
        tr._tw = create_terminal_writer(config, f)
        # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦æŠ¥å‘Š
        tr.summary_stats()

    # æ¢å¤åŸå§‹çš„ç»ˆç«¯å†™å…¥å™¨å’ŒæŠ¥å‘Šå­—ç¬¦é›†è®¾ç½®
    tr._tw = orig_writer
    tr.reportchars = orig_reportchars
    # æ¢å¤åŸå§‹çš„ traceback æ ¼å¼è®¾ç½®
    config.option.tbstyle = orig_tbstyle
# --- åˆ†å¸ƒå¼æµ‹è¯•å‡½æ•° --- #

# ä» https://stackoverflow.com/a/59041913/9201239 æ”¹ç¼–è€Œæ¥
import asyncio  # å¼•å…¥ asyncio åº“ï¼Œç”¨äºå¼‚æ­¥ç¼–ç¨‹

class _RunOutput:
    def __init__(self, returncode, stdout, stderr):
        self.returncode = returncode  # å­è¿›ç¨‹è¿”å›ç 
        self.stdout = stdout  # å­è¿›ç¨‹æ ‡å‡†è¾“å‡ºå†…å®¹
        self.stderr = stderr  # å­è¿›ç¨‹æ ‡å‡†é”™è¯¯è¾“å‡ºå†…å®¹

async def _read_stream(stream, callback):
    """
    å¼‚æ­¥è¯»å–æµçš„å†…å®¹ï¼Œå¹¶é€šè¿‡å›è°ƒå‡½æ•°å¤„ç†æ¯ä¸€è¡Œæ•°æ®

    Args:
    - stream: æµå¯¹è±¡ï¼ˆasyncio.subprocess.PIPEï¼‰
    - callback: å›è°ƒå‡½æ•°ï¼Œå¤„ç†æ¯ä¸€è¡Œæ•°æ®
    """
    while True:
        line = await stream.readline()  # å¼‚æ­¥è¯»å–ä¸€è¡Œæ•°æ®
        if line:
            callback(line)  # è°ƒç”¨å›è°ƒå‡½æ•°å¤„ç†è¯¥è¡Œæ•°æ®
        else:
            break

async def _stream_subprocess(cmd, env=None, stdin=None, timeout=None, quiet=False, echo=False) -> _RunOutput:
    """
    å¼‚æ­¥æ‰§è¡Œå­è¿›ç¨‹ï¼Œå¹¶è¿”å›å…¶è¾“å‡ºå†…å®¹å’ŒçŠ¶æ€

    Args:
    - cmd: å­è¿›ç¨‹å‘½ä»¤åŠå‚æ•°åˆ—è¡¨
    - env: å­è¿›ç¨‹ç¯å¢ƒå˜é‡
    - stdin: å­è¿›ç¨‹æ ‡å‡†è¾“å…¥
    - timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    - quiet: æ˜¯å¦é™é»˜æ¨¡å¼ï¼ˆä¸è¾“å‡ºä¿¡æ¯åˆ°æ§åˆ¶å°ï¼‰
    - echo: æ˜¯å¦è¾“å‡ºå‘½ä»¤æ‰§è¡Œä¿¡æ¯åˆ°æ§åˆ¶å°

    Returns:
    - _RunOutput å¯¹è±¡ï¼ŒåŒ…å«å­è¿›ç¨‹çš„è¿”å›ç ã€æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯è¾“å‡º
    """
    if echo:
        print("\nRunning: ", " ".join(cmd))  # å¦‚æœ echo ä¸º Trueï¼Œåˆ™è¾“å‡ºæ‰§è¡Œçš„å‘½ä»¤

    # åˆ›å»ºå­è¿›ç¨‹
    p = await asyncio.create_subprocess_exec(
        cmd[0],
        *cmd[1:],
        stdin=stdin,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
        env=env,
    )

    out = []  # å­˜å‚¨æ ‡å‡†è¾“å‡ºå†…å®¹çš„åˆ—è¡¨
    err = []  # å­˜å‚¨æ ‡å‡†é”™è¯¯è¾“å‡ºå†…å®¹çš„åˆ—è¡¨

    def tee(line, sink, pipe, label=""):
        """
        å°†è¡Œæ•°æ®è§£ç ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶è¾“å‡ºåˆ°æŒ‡å®šçš„è¾“å‡ºæµå’Œå­˜å‚¨åˆ—è¡¨

        Args:
        - line: è¾“å…¥çš„è¡Œæ•°æ®ï¼ˆbytesï¼‰
        - sink: å­˜å‚¨è¡Œæ•°æ®çš„åˆ—è¡¨
        - pipe: è¾“å‡ºæµå¯¹è±¡ï¼ˆsys.stdout æˆ– sys.stderrï¼‰
        - label: è¾“å‡ºçš„æ ‡ç­¾å‰ç¼€
        """
        line = line.decode("utf-8").rstrip()  # è§£ç ä¸º UTF-8 ç¼–ç çš„å­—ç¬¦ä¸²ï¼Œå¹¶å»é™¤æœ«å°¾çš„æ¢è¡Œç¬¦
        sink.append(line)  # å°†è§£ç åçš„å­—ç¬¦ä¸²å­˜å‚¨åˆ°æŒ‡å®šçš„åˆ—è¡¨ä¸­
        if not quiet:
            print(label, line, file=pipe)  # å¦‚æœä¸æ˜¯é™é»˜æ¨¡å¼ï¼Œåˆ™è¾“å‡ºå¸¦æœ‰æ ‡ç­¾å‰ç¼€çš„å†…å®¹åˆ°æŒ‡å®šè¾“å‡ºæµ

    # å¼‚æ­¥ç­‰å¾…ä¸¤ä¸ªæµçš„æ•°æ®è¯»å–ï¼Œå¹¶è¿›è¡Œå¤„ç†
    await asyncio.wait(
        [
            _read_stream(p.stdout, lambda l: tee(l, out, sys.stdout, label="stdout:")),  # å¤„ç†æ ‡å‡†è¾“å‡ºæµ
            _read_stream(p.stderr, lambda l: tee(l, err, sys.stderr, label="stderr:")),  # å¤„ç†æ ‡å‡†é”™è¯¯è¾“å‡ºæµ
        ],
        timeout=timeout,  # è®¾ç½®è¶…æ—¶æ—¶é—´
    )
    return _RunOutput(await p.wait(), out, err)  # è¿”å›å­è¿›ç¨‹çš„è¿”å›ç åŠè¾“å‡ºå†…å®¹å¯¹è±¡

def execute_subprocess_async(cmd, env=None, stdin=None, timeout=180, quiet=False, echo=True) -> _RunOutput:
    """
    å¼‚æ­¥æ‰§è¡Œå­è¿›ç¨‹çš„å°è£…å‡½æ•°ï¼Œä½¿ç”¨ asyncio äº‹ä»¶å¾ªç¯è¿è¡Œ _stream_subprocess å‡½æ•°ï¼Œå¹¶å¤„ç†æ‰§è¡Œç»“æœ

    Args:
    - cmd: å­è¿›ç¨‹å‘½ä»¤åŠå‚æ•°åˆ—è¡¨
    - env: å­è¿›ç¨‹ç¯å¢ƒå˜é‡
    - stdin: å­è¿›ç¨‹æ ‡å‡†è¾“å…¥
    - timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    - quiet: æ˜¯å¦é™é»˜æ¨¡å¼ï¼ˆä¸è¾“å‡ºä¿¡æ¯åˆ°æ§åˆ¶å°ï¼‰
    - echo: æ˜¯å¦è¾“å‡ºå‘½ä»¤æ‰§è¡Œä¿¡æ¯åˆ°æ§åˆ¶å°

    Returns:
    - _RunOutput å¯¹è±¡ï¼ŒåŒ…å«å­è¿›ç¨‹çš„è¿”å›ç ã€æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯è¾“å‡º

    Raises:
    - RuntimeError: å¦‚æœå­è¿›ç¨‹è¿”å›ç å¤§äº 0 æˆ–æ²¡æœ‰äº§ç”Ÿä»»ä½•è¾“å‡º
    """
    loop = asyncio.get_event_loop()  # è·å– asyncio çš„äº‹ä»¶å¾ªç¯å¯¹è±¡
    result = loop.run_until_complete(
        _stream_subprocess(cmd, env=env, stdin=stdin, timeout=timeout, quiet=quiet, echo=echo)
    )  # ä½¿ç”¨äº‹ä»¶å¾ªç¯è¿è¡Œå¼‚æ­¥å­è¿›ç¨‹å‡½æ•°

    cmd_str = " ".join(cmd)  # å°†å‘½ä»¤åŠå‚æ•°åˆ—è¡¨ç»„åˆæˆå­—ç¬¦ä¸²
    if result.returncode > 0:
        stderr = "\n".join(result.stderr)  # å°†æ ‡å‡†é”™è¯¯è¾“å‡ºå†…å®¹åˆ—è¡¨åˆå¹¶ä¸ºå­—ç¬¦ä¸²
        raise RuntimeError(
            f"'{cmd_str}' failed with returncode {result.returncode}\n\n"
            f"The combined stderr from workers follows:\n{stderr}"
        )

    # æ£€æŸ¥å­è¿›ç¨‹æ˜¯å¦çœŸæ­£æ‰§è¡Œå¹¶äº§ç”Ÿè¾“å‡º
    if not result.stdout and not result.stderr:
        raise RuntimeError(f"'{cmd_str}' produced no output.")

    return result  # è¿”å›æ‰§è¡Œç»“æœå¯¹è±¡

def pytest_xdist_worker_id():
    """
    è¿”å› `pytest-xdist` æ’ä»¶ä¸‹å½“å‰ worker çš„æ•°å­— idï¼ˆä»…åœ¨ `pytest -n N` æ¨¡å¼ä¸‹æœ‰æ•ˆï¼‰ï¼Œå¦åˆ™è¿”å› 0
    """
    # ä»ç¯å¢ƒå˜é‡ä¸­è·å–åä¸º PYTEST_XDIST_WORKER çš„å€¼ï¼Œé»˜è®¤ä¸º "gw0" å¦‚æœå­˜åœ¨
    worker = os.environ.get("PYTEST_XDIST_WORKER", "gw0")
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢å­—ç¬¦ä¸²ä¸­ä»¥ "gw" å¼€å¤´çš„éƒ¨åˆ†ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œè¿›è¡Œå…¨å±€æ›¿æ¢
    worker = re.sub(r"^gw", "", worker, 0, re.M)
    
    # å°†å¤„ç†åçš„å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•´æ•°å¹¶è¿”å›
    return int(worker)
# è¿”å›ä¸€ä¸ªå¯ä»¥ç”¨ä½œ `torch.distributed.launch` çš„ `--master_port` å‚æ•°çš„ç«¯å£å·
def get_torch_dist_unique_port():
    # åˆå§‹ç«¯å£å·
    port = 29500
    # å¦‚æœåœ¨ `pytest-xdist` ä¸‹è¿è¡Œï¼Œæ ¹æ® worker id æ·»åŠ ä¸€ä¸ªåç§»é‡ï¼Œä»¥é¿å…å¹¶å‘æµ‹è¯•å°è¯•ä½¿ç”¨ç›¸åŒçš„ç«¯å£
    uniq_delta = pytest_xdist_worker_id()
    return port + uniq_delta


# ç®€åŒ–å¯¹è±¡ï¼Œå°†æµ®ç‚¹æ•°å››èˆäº”å…¥ï¼Œå°†å¼ é‡/NumPy æ•°ç»„é™çº§ä¸ºå¯è¿›è¡Œç®€å•ç›¸ç­‰æ€§æµ‹è¯•çš„å½¢å¼
def nested_simplify(obj, decimals=3):
    import numpy as np

    if isinstance(obj, list):
        return [nested_simplify(item, decimals) for item in obj]
    if isinstance(obj, tuple):
        return tuple([nested_simplify(item, decimals) for item in obj])
    elif isinstance(obj, np.ndarray):
        return nested_simplify(obj.tolist())
    elif isinstance(obj, Mapping):
        return {nested_simplify(k, decimals): nested_simplify(v, decimals) for k, v in obj.items()}
    elif isinstance(obj, (str, int, np.int64)):
        return obj
    elif obj is None:
        return obj
    elif is_torch_available() and isinstance(obj, torch.Tensor):
        return nested_simplify(obj.tolist(), decimals)
    elif is_tf_available() and tf.is_tensor(obj):
        return nested_simplify(obj.numpy().tolist())
    elif isinstance(obj, float):
        return round(obj, decimals)
    elif isinstance(obj, (np.int32, np.float32)):
        return nested_simplify(obj.item(), decimals)
    else:
        raise Exception(f"Not supported: {type(obj)}")


# æ£€æŸ¥ JSON æ–‡ä»¶æ˜¯å¦å…·æœ‰æ­£ç¡®çš„æ ¼å¼
def check_json_file_has_correct_format(file_path):
    with open(file_path, "r") as f:
        lines = f.readlines()
        if len(lines) == 1:
            # å¦‚æœæ–‡ä»¶åªæœ‰ä¸€è¡Œï¼Œä¸”å†…å®¹ä¸º "{}"ï¼Œåˆ™è®¤ä¸º JSON å­—å…¸ä¸ºç©º
            assert lines[0] == "{}"
        else:
            # å¦åˆ™ç¡®ä¿ JSON æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ˆè‡³å°‘ 3 è¡Œï¼‰
            assert len(lines) >= 3
            # ç¬¬ä¸€è¡Œåº”è¯¥æ˜¯ "{"
            assert lines[0].strip() == "{"
            # ä¸­é—´è¡Œæ¯è¡Œç¼©è¿›åº”ä¸º 2
            for line in lines[1:-1]:
                left_indent = len(line) - len(line.lstrip())
                assert left_indent == 2
            # æœ€åä¸€è¡Œåº”è¯¥æ˜¯ "}"
            assert lines[-1].strip() == "}"


# å°†è¾“å…¥è½¬æ¢ä¸ºé•¿åº¦ä¸º 2 çš„å…ƒç»„ï¼Œå¦‚æœè¾“å…¥å·²ç»æ˜¯å¯è¿­ä»£å¯¹è±¡ï¼Œåˆ™ç›´æ¥è¿”å›
def to_2tuple(x):
    if isinstance(x, collections.abc.Iterable):
        return x
    return (x, x)


# è¿è¡ŒæŒ‡å®šçš„å‘½ä»¤ï¼Œå¹¶ä½¿ç”¨ subprocess.check_output æ‰§è¡Œï¼Œå¯èƒ½è¿”å› stdout
def run_command(command: List[str], return_stdout=False):
    try:
        output = subprocess.check_output(command, stderr=subprocess.STDOUT)
        if return_stdout:
            if hasattr(output, "decode"):
                output = output.decode("utf-8")
            return output
    except subprocess.CalledProcessError as e:
        # å¦‚æœå‘½ä»¤æ‰§è¡Œå‡ºé”™ï¼ŒæŠ›å‡º SubprocessCallException å¼‚å¸¸
        raise SubprocessCallException(str(e.output))
    # æ•è· subprocess.CalledProcessError å¼‚å¸¸ï¼Œè¿™æ˜¯ subprocess è°ƒç”¨è¿‡ç¨‹ä¸­å¯èƒ½æŠ›å‡ºçš„é”™è¯¯ä¹‹ä¸€
    except subprocess.CalledProcessError as e:
        # æŠ›å‡ºè‡ªå®šä¹‰çš„ SubprocessCallException å¼‚å¸¸ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¤±è´¥çš„å‘½ä»¤å’Œé”™è¯¯è¾“å‡ºå†…å®¹çš„è§£ç ç»“æœ
        raise SubprocessCallException(
            f"Command `{' '.join(command)}` failed with the following error:\n\n{e.output.decode()}"
        ) from e
class RequestCounter:
    """
    Helper class that will count all requests made online.

    Might not be robust if urllib3 changes its logging format but should be good enough for us.

    Usage:
    ```py
    with RequestCounter() as counter:
        _ = AutoTokenizer.from_pretrained("hf-internal-testing/tiny-random-bert")
    assert counter["GET"] == 0
    assert counter["HEAD"] == 1
    assert counter.total_calls == 1
    ```
    """

    def __enter__(self):
        # åˆå§‹åŒ–ä¸€ä¸ªè®¡æ•°å™¨å­—å…¸ï¼Œé»˜è®¤å€¼ä¸ºæ•´æ•°ç±»å‹
        self._counter = defaultdict(int)
        # åˆ›å»ºä¸€ä¸ª mock å¯¹è±¡ï¼Œç”¨äºæ¨¡æ‹Ÿ urllib3.connectionpool.log.debug æ–¹æ³•
        self.patcher = patch.object(urllib3.connectionpool.log, "debug", wraps=urllib3.connectionpool.log.debug)
        # å¯åŠ¨ patcherï¼Œå¼€å§‹ mock
        self.mock = self.patcher.start()
        # è¿”å›å½“å‰å¯¹è±¡å®ä¾‹ï¼Œä»¥ä¾›ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä½¿ç”¨
        return self

    def __exit__(self, *args, **kwargs) -> None:
        # éå†æ¯æ¬¡ mock è°ƒç”¨çš„å‚æ•°åˆ—è¡¨
        for call in self.mock.call_args_list:
            # æ ¼å¼åŒ–æ—¥å¿—ä¿¡æ¯
            log = call.args[0] % call.args[1:]
            # éå†æ”¯æŒçš„ HTTP æ–¹æ³•ï¼Œæ£€æŸ¥æ—¥å¿—ä¸­æ˜¯å¦åŒ…å«è¯¥æ–¹æ³•
            for method in ("HEAD", "GET", "POST", "PUT", "DELETE", "CONNECT", "OPTIONS", "TRACE", "PATCH"):
                if method in log:
                    # å¦‚æœæ—¥å¿—ä¸­åŒ…å«è¯¥æ–¹æ³•ï¼Œå¢åŠ å¯¹åº”æ–¹æ³•è®¡æ•°
                    self._counter[method] += 1
                    break
        # åœæ­¢ mock
        self.patcher.stop()

    def __getitem__(self, key: str) -> int:
        # è·å–æŒ‡å®š HTTP æ–¹æ³•çš„è°ƒç”¨æ¬¡æ•°
        return self._counter[key]

    @property
    def total_calls(self) -> int:
        # è¿”å›æ‰€æœ‰ HTTP æ–¹æ³•çš„æ€»è°ƒç”¨æ¬¡æ•°
        return sum(self._counter.values())


def is_flaky(max_attempts: int = 5, wait_before_retry: Optional[float] = None, description: Optional[str] = None):
    """
    To decorate flaky tests. They will be retried on failures.

    Args:
        max_attempts (`int`, *optional*, defaults to 5):
            The maximum number of attempts to retry the flaky test.
        wait_before_retry (`float`, *optional*):
            If provided, will wait that number of seconds before retrying the test.
        description (`str`, *optional*):
            A string to describe the situation (what / where / why is flaky, link to GH issue/PR comments, errors,
            etc.)
    """

    def decorator(test_func_ref):
        @functools.wraps(test_func_ref)
        def wrapper(*args, **kwargs):
            # åˆå§‹åŒ–é‡è¯•æ¬¡æ•°è®¡æ•°å™¨
            retry_count = 1

            # åœ¨æœ€å¤§é‡è¯•æ¬¡æ•°ä¹‹å†…å¾ªç¯æ‰§è¡Œæµ‹è¯•å‡½æ•°
            while retry_count < max_attempts:
                try:
                    return test_func_ref(*args, **kwargs)

                except Exception as err:
                    # æ‰“å°æµ‹è¯•å¤±è´¥ä¿¡æ¯åŠé‡è¯•æ¬¡æ•°
                    print(f"Test failed with {err} at try {retry_count}/{max_attempts}.", file=sys.stderr)
                    # å¦‚æœè®¾ç½®äº†é‡è¯•ç­‰å¾…æ—¶é—´ï¼Œç­‰å¾…æŒ‡å®šç§’æ•°åå†æ¬¡é‡è¯•
                    if wait_before_retry is not None:
                        time.sleep(wait_before_retry)
                    retry_count += 1

            # è¿”å›æµ‹è¯•å‡½æ•°çš„æ‰§è¡Œç»“æœ
            return test_func_ref(*args, **kwargs)

        return wrapper

    return decorator


def run_test_in_subprocess(test_case, target_func, inputs=None, timeout=None):
    """
    To run a test in a subprocess. In particular, this can avoid (GPU) memory issue.
    
    This function is incomplete and needs further implementation.
    """
    # è¿è¡Œæµ‹è¯•åœ¨å­è¿›ç¨‹ä¸­çš„å‡½æ•°ï¼Œæš‚æœªå®ç°å®Œæ•´åŠŸèƒ½
    pass
    # å¦‚æœæœªæŒ‡å®šè¶…æ—¶æ—¶é—´ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡ PYTEST_TIMEOUT è·å–æˆ–é»˜è®¤è®¾ç½®ä¸º 600 ç§’
    if timeout is None:
        timeout = int(os.environ.get("PYTEST_TIMEOUT", 600))

    # è®¾ç½® multiprocessing çš„ä¸Šä¸‹æ–‡ä¸º 'spawn'ï¼Œè¿™æ˜¯ä¸ºäº†åœ¨å­è¿›ç¨‹ä¸­åˆ›å»ºæ–°çš„è¿›ç¨‹
    start_methohd = "spawn"
    ctx = multiprocessing.get_context(start_methohd)

    # åˆ›å»ºè¾“å…¥é˜Ÿåˆ—å’Œè¾“å‡ºé˜Ÿåˆ—ï¼Œç”¨äºçˆ¶å­è¿›ç¨‹ä¹‹é—´çš„é€šä¿¡
    input_queue = ctx.Queue(1)
    output_queue = ctx.JoinableQueue(1)

    # å°†è¾“å…¥æ•°æ®æ”¾å…¥è¾“å…¥é˜Ÿåˆ—ï¼Œä»¥ä¾›å­è¿›ç¨‹ä½¿ç”¨ï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
    input_queue.put(inputs, timeout=timeout)

    # åˆ›å»ºå­è¿›ç¨‹ï¼Œæ‰§è¡Œæµ‹è¯•å‡½æ•° target_funcï¼Œå¹¶ä¼ å…¥è¾“å…¥å’Œè¾“å‡ºé˜Ÿåˆ—ä»¥åŠè¶…æ—¶æ—¶é—´ä½œä¸ºå‚æ•°
    process = ctx.Process(target=target_func, args=(input_queue, output_queue, timeout))
    process.start()

    # å°è¯•ä»è¾“å‡ºé˜Ÿåˆ—ä¸­è·å–ç»“æœï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
    try:
        results = output_queue.get(timeout=timeout)
        output_queue.task_done()
    # å¦‚æœè·å–è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ï¼Œåˆ™ç»ˆæ­¢å­è¿›ç¨‹å¹¶æ ‡è®°æµ‹è¯•ä¸ºå¤±è´¥
    except Exception as e:
        process.terminate()
        test_case.fail(e)

    # ç­‰å¾…å­è¿›ç¨‹ç»“æŸï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
    process.join(timeout=timeout)

    # å¦‚æœå­è¿›ç¨‹è¿”å›ç»“æœä¸­åŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œåˆ™æ ‡è®°æµ‹è¯•ä¸ºå¤±è´¥
    if results["error"] is not None:
        test_case.fail(f'{results["error"]}')
````
"""
ÃˆÃŸÃ€Ã Â½ÃºÂ½Â¨``{}Ã“ÃƒÂ·Ã–Â³ÃŸÃ–ÃÂ¿ÂªÃ‚Â«Â½Ã¢ÃÃ¶Ã”Ã„Â¶Ã‹ÃŒÃ­Â¼Ã“Â£Â¨Â·Ã–Â¾Â£Â¡Â°Ã„Â±Ã‹ÃÃŒÃ­Â¼Ã“ÃÃ„Â±Â¾Â´Â°Ã“Ã·Â·Ã„ÃÃ²Â°Â¸Â£ÃªÂ¿ÂªÃ…æŒ‡å‘Â·Ã–Â³ÃŸÃŒÃ¬Â°Â±--Â°Ã±ÃÃ½Ã•Â¢ÃŒÃ­Â¼Ã“ÃŠÂµÃ€Ã½``{str}``, `dict` ÃÃ„Â±Â¾Â½Ã´Â±ÂªÂ£Â¬Ã‘Ã©Ã”Â±Â·Ã–Ã—Â°`load_dataset` Â·ÂµÃ‚Ã¤Â£Â¬ÃÃ‹Ã‡Â¡ÃˆÃÃƒÃ®Ã‹Ã³Ã“ÃšÂ·Ã–Â³ÃŸÃ’Â»ÃŒÃ¥Â£Â¬Â¹ÃºÂ¿ÂªÃŠÂ¼Ã•Ã•Ã“ÃƒÂ­Ã¦Â³Ã¶Â½Ã¢ÃÃ¶Â¡Â¢`load_dataset` Ã…Ã’ÃŒÃ©Â°Â¿ÃŠÃ”Ã‡Â·Â£


Â±)(Â°Ã’Ã€ÃŒÂ³Â¡ÃŠÂ»Â·Ã–Ã‰Â³Ã’Ã‰Â¿ÂªÃˆÃ½â€PINâ€Ã­Ã·Â¾Ã¡.summary.Â£Â¬ÃÂ£ÃÃ„â€Â·Â¢Ã‰Ã­ÃÂªkvÃÃ„Â±Â¾Â£Â¬ÃŒÃ­Â¼Ã“Â²Â»Â³Ã‰ÃÂªÃ‘Ã«Ã“Ã’Ã’Ã‰Â¡Â¢Â±Â»Ã„Â¿Â±Ã¢degreeÃŠÂ±Ã—Ã³Â¿ÂªÃƒÃ¹Ã—ÃŠÃŒÃµÂ£Â¬Ã„Â¿Â±Ã¢skip_cuda_testsÃÂ½Â»Ã”Â»Ã¹Ã’Â»Ã”ÂªÃÂ¨ÃÂ°Â·Ã–Ã‰Â³â€œâ€ ÃÃŠÃ’Â£Â¬Ã‰Â¾Â³Ã½Â³ÃŒÃÃµÂ¼Â¯ÃŒÃ¢ÃŒÃ­Â¼Ã“Â·ÂµÂ»Ã˜Â£Â¬ÃÂµÃ‰Â«Â»Â¯Â½Â¿Â°Â¯â€Â¡Â¢Â½Ã… gorÃ³ÃÃ†Ã—ÃœÃ²ÂºÂ¡Â°ÃŒÃ­Â¼Ã“Ã“Ã«Ã“Ã¢Ã’Ã¥Ã“ÃÃ“ÃšÃ”Â³Ã’Ã†ÃÃ„Â±Â¾Â¡Â¢Ã„Â¿Â±Ã¢skip_cuda_testsTRYÃÃ‚ÃŠÂ±Â·Ã¼ÃŠÃ”Â£ÂºÃ˜ÃÂ·Ã€ÃŠÃ‡Ã”Â´Â»*-Â¿ÃŒÃœÂºÃ‰HKÃ Â¿ÂªÃŒÃ­Â»Ã½Â£Â¬Ã„Â»Ã…ÃÃ”Â®ÃÂªÂ·Â¸Â³Ã‡ÂµÃ‡Ã‚Ã ÃÂªÂ·Â²Â½Â¿.Ã“ÃšÂ½Ã‡Â»Â»Ã‡Â°Â¿ÂªÂ·Â¨ÂµÃ„Â·Â½Â·Â¨Â¡Â¢ÃŠÃ‡ÃŠÃ Â³Ã¹ÃÂ½ÃÂ´Â³ÃŒÃŒÃ¢ÃÃ„Â±Â¾ÃÃ‹Â²Â»Ã‰Â«Â½Ã‡Ã‚ÃŸ}";

""
`re` Ã—Ã“ÃÂ¿`codeblock_pattern` Â°Â´Ã…Ã¤Ã…Ã…Â¹Ã¡Â²ÃÃŠÃ½Â¡Â¢Ã…Ã„Ã…Ã¤ÃƒÃ¨ÃŠÃ¶Â°Â²Ã«Ã–Ã‘ÃÃ‰ÂªÃ˜Ã’Ã‡Â¡Â¢Â³ÃµÃÃ²ÃŠÃ‡Â¡Â¬Ã…Ã…ÃŠÃ½Ã€ÃŒÃÃ„ÂµÃ°ÃŠÃ‡Â»Ã¡ÃƒÃ¨Ã”Ã°Â¡Â¢Ã…Ã¤Ã–ÃƒÃŠÃ‡Â¡Â¬FÃ€Ã“Ã”Ã“Â²Â»Ã„ÃœÂ³ÃŒÃŠÃ½ÃÂ¿ÃÃ²ÃÂ´ÃÂ¿ÃÂ´Â¡Â¢Â¿ÂªÃŠÂ¼ÃŠÃ‡Â¡Â¬Â»Â¯Â½Â¿ÃÂ¿Ã…Ã–ÃƒÃ„ÃŒÃ‘Ã©Â¡Â¢ÂµÎ©Â°Â²Ã«ÂµÃ„ÃŠÃ‡ï¿½ï¿½Å Â°Â¶Ã€ÃœÃŠÃ‡ÂµÃ„ÃŠÂ»Ã’Â³Â³ÃŒÃÃµÃŒÃ­Â¼Ã“Ã€ÃÂ¡Â¬.GetComponentÂ¡Â¢Ã…Ã„Â°ÃƒÃ…Ã„Ã”ÃÂ»ÂªÃ’Ã‰ÃŠÃ ÃŒÃ‚Â¡Â¢Ã†Ã§Ã‡Â¿pl"}, â€¢â€¢â€¢`"); // Ã‡Â¿Ã…ÃŒÃºÃŠÃ‡Ã‡Â°Ã–Â·ÂºÃ¡Â³ÃŒÃŒÃ¢ÃŒÃ­Â¼Ã“Ã„Ã€Ã„ÃœÃ•Ã‹ÃŒÃ­Â¼Ã“ÃƒÂ»Ã“ÃÂ°Â°ÃŒÃ¸ÃŠÃ½æº¢Ã¬Ã„ÂªÃ„Ã€Ã„Ãœ residues. Â£Â¬Ã“ÃÃ“ÃšÂ£Â¬Ã—Â¡Ã‰ÃºÂ¿ÂªÃŒÃ­Â¿ÂªÂ» currentUserÂ°Â¡Â¬Ã…Ã„Ã‘Ã³Ã‚Â¥Ã¹Ã¢ÂµÃ©Â±Ã¼ÃÂªÂµÂ±Â¢ÂµÃ„representationÂ¡Â¢Ã’Â»Â´ÃÃ”ÃŠÂ¾ÃŒÃ­Â¼Ã“Ã„Ã€Ã„ÃœÃ•Ã‹ÃŒÃ­Â¡Â¢ÃÃŒÂ²Â¹ÂµÂ¡Â¬Ã†ÂµÃ‚Ã¬ÂºÃpaintÂ¡Â¢Â°Â¾Â²Â²ÃŒÃ¥ÃŒÃ­Â¼Ã“`.
]}" Ãˆ Â»Â·Ã–Ã‰Â³Ã’Ã‰Â¿ÂªÃŠÂ¼Ã•Ã•Ã’Â³Ã‚Ã”Ã“Ã«ÃÃ Ã€ÃœÂ»Ã–ÃÃ§Â·â™¥ÃŠÃ”Â¡Â¢ÃÃ‹Â¸Ã±ÃŠÃ²Â¿ÂªÃŠÂ¼ÂµÃ„Â°Â¾Â²Â²ÃŒÃ¥ÃŒÃ­Â¼Ã“

class HfDocTestParser(doctest.DocTestParser):
    """
    Â±Â¾Ã’Â©ÃÂ¿Ã„Â¿ÃƒÃ¦Â£Â¬Ã’Ã”Â»Â·Ã–Ã‰Â´Ã’ÂµÃ„ÃÂ³ÃŒÃ‘ÃŠÃ½ÃˆÃ§Â£Â¬Â½Â« ÃÂ³ÃŒÃ‘ Â´ herbal Ã–--, ÃÃ‹ Ã”ÂºÃ€Ã­Ã“Ã·Â¿ÂµÂ¼ÂºÃ’Âº Â°ÃÃ„ÃŒÃ–Ã·Ã“------ÃÃŒÃ–Ã¡ÂµÃ„Ã„Â£ÂªÃ’PortraitÂ¡Â¢Ã”Â¡Â°ÃŒÃ­Â¼Ã“ÃÃ Ã„ÃœÃ”ÃšÂ¡Â¢Ã€Ã€Ã”ÃŠÂ¿ÂªÃ„Ã€Ã„ÃœÂªÃÂ»Ã Ã€Ã–Â£Â¬ç¥–Ã…Ã­ÂµÃ Ã”ÃšÂµÃ„ bgcolorÂ¡Â¢ roleId:. Ã®Ã§Ã—Ã–ÃƒÂ£Ã—Ã®ÃÃ†ÂµÃ„Ã•Ã—Ã“Ã²ÂµOÂ¡Â¢ Ã—Â»ÂºÃƒÃ—Â°ÃÂ¢Â¿Ã§Ã…Ã”ÃÃ‹ Ã†ÃšÃ•ÃƒÂ¡Â¡Â³Ã’ÃŒÂ³Â¡Ã”Â°ÃÂ±ÃŒÃ—ÃÂºÃ arguments, Â°ÃƒÃ‹Ã¹ÃŒÃ­Â¼Ã“Ã—Ã–ÃŒÃ¥ÃÃŒâ€¢ Ãª.l

"""

    # Ã—ÃŒÃ…Ã…Ã…ÃŒÂ¾ÂºÃŒÃ—Ã“Ã…Ã…ÃÂ·ÃÃ„Â±Â¾Â´Ã³Â»ÃÃ”Ã„Ã•Ã’ÂµÃ€Ã„Â±Ã¢Ã‡Â°ÃÂªÂ½Â²Ã‰ÃÂ·Â½Ã“ÃÃÂ½Ã‡ÂºÃÂ½ÃƒÃÃ„ÃˆÂ½Ã—Ã¼ÂºÃ³Ã†Â¬Ã…Ã¤Ã–Ã‘Â²ÃÃŠÃ½. ÃŒÃ–ÂºÃÃÃÃˆÂ¿Â½]
_USE_BACKQUOTE_PORT.lesson five* Ã artist_adapter._lesson_number = 3 $\â€



è¿™ä¸ªæ³¨é‡Šä»¥ä¿åº•çš„æ–¹å¼å¯¹ç»™å®šä»£ç è¿›è¡Œè§£è¯»ï¼ŒåŒ…æ‹¬è¯¥ç›®å½•ä¸‹çš„ä¸€äº›ç‰¹å®šä»£ç åŠŸèƒ½ï¼Œä»¥åŠè§£é‡Šä»£ç å®šä¹‰çš„å„ç§æ–¹æ³•ã€è§„åˆ™å’Œç±»ã€‚
    _EXAMPLE_RE = re.compile(r'''
        # Source consists of a PS1 line followed by zero or more PS2 lines.
        (?P<source>
            (?:^(?P<indent> [ ]*) >>>    .*)    # Match a PS1 line and capture its indentation and content
            (?:\n           [ ]*  \.\.\. .*)*)  # Match zero or more PS2 lines following PS1
        \n?
        # Want consists of any non-blank lines that do not start with PS1.
        (?P<want> (?:(?![ ]*$)    # Match any non-blank line
             (?![ ]*>>>)          # Ensure it doesn't start with PS1
             # !!!!!!!!!!! HF Specific !!!!!!!!!!!
             (?:(?!```).)*        # Match any character except '`' until encountering '```' (specific to HF)
             # !!!!!!!!!!! HF Specific !!!!!!!!!!!
             (?:\n|$)             # Match a new line or end of string
          )*)
        ''', re.MULTILINE | re.VERBOSE
    )
    # fmt: on

    # !!!!!!!!!!! HF Specific !!!!!!!!!!!
    skip_cuda_tests: bool = bool(os.environ.get("SKIP_CUDA_DOCTEST", False))
    # Define a boolean indicating whether to skip CUDA tests based on the environment variable "SKIP_CUDA_DOCTEST"
    # !!!!!!!!!!! HF Specific !!!!!!!!!!!

    def parse(self, string, name="<string>"):
        """
        Overwrites the `parse` method to preprocess the input string by skipping CUDA tests,
        removing logs and dataset prints, and then calling `super().parse`.
        """
        string = preprocess_string(string, self.skip_cuda_tests)
        # Preprocess the input string based on the skip_cuda_tests flag
        return super().parse(string, name)
# å®šä¹‰ä¸€ä¸ªåä¸º HfDoctestModule çš„ç±»ï¼Œç»§æ‰¿è‡ª Module ç±»
class HfDoctestModule(Module):
    """
    Overwrites the `DoctestModule` of the pytest package to make sure the HFDocTestParser is used when discovering
    tests.
    """
    def collect(self) -> Iterable[DoctestItem]:
        class MockAwareDocTestFinder(doctest.DocTestFinder):
            """A hackish doctest finder that overrides stdlib internals to fix a stdlib bug.

            https://github.com/pytest-dev/pytest/issues/3456 https://bugs.python.org/issue25532
            """

            def _find_lineno(self, obj, source_lines):
                """Doctest code does not take into account `@property`, this
                is a hackish way to fix it. https://bugs.python.org/issue17446

                Wrapped Doctests will need to be unwrapped so the correct line number is returned. This will be
                reported upstream. #8796
                """
                if isinstance(obj, property):
                    obj = getattr(obj, "fget", obj)

                if hasattr(obj, "__wrapped__"):
                    # Get the main obj in case of it being wrapped
                    obj = inspect.unwrap(obj)

                # Type ignored because this is a private function.
                return super()._find_lineno(  # type:ignore[misc]
                    obj,
                    source_lines,
                )

            def _find(self, tests, obj, name, module, source_lines, globs, seen) -> None:
                if _is_mocked(obj):
                    return
                with _patch_unwrap_mock_aware():
                    # Type ignored because this is a private function.
                    super()._find(  # type:ignore[misc]
                        tests, obj, name, module, source_lines, globs, seen
                    )

        if self.path.name == "conftest.py":
            # Import conftest.py as a module using pytest's plugin manager
            module = self.config.pluginmanager._importconftest(
                self.path,
                self.config.getoption("importmode"),
                rootpath=self.config.rootpath,
            )
        else:
            try:
                # Import the module from the given path using custom import function
                module = import_path(
                    self.path,
                    root=self.config.rootpath,
                    mode=self.config.getoption("importmode"),
                )
            except ImportError:
                if self.config.getvalue("doctest_ignore_import_errors"):
                    # Skip importing if specified to ignore import errors
                    skip("unable to import module %r" % self.path)
                else:
                    raise

        # Initialize a doctest finder that incorporates custom logic (HF Specific)
        finder = MockAwareDocTestFinder(parser=HfDocTestParser())
        
        # Option flags configuration specific to the doctest runner
        optionflags = get_optionflags(self)
        
        # Obtain a runner instance with specific configurations
        runner = _get_runner(
            verbose=False,
            optionflags=optionflags,
            checker=_get_checker(),
            continue_on_failure=_get_continue_on_failure(self.config),
        )
        
        # Iterate over found doctests in the module and yield them as DoctestItem instances
        for test in finder.find(module, module.__name__):
            if test.examples:  # Skip empty doctests and cuda
                yield DoctestItem.from_parent(self, name=test.name, runner=runner, dtest=test)
def _device_agnostic_dispatch(device: str, dispatch_table: Dict[str, Callable], *args, **kwargs):
    if device not in dispatch_table:
        # å¦‚æœè®¾å¤‡ä¸åœ¨ dispatch_table ä¸­ï¼Œä½¿ç”¨é»˜è®¤å‡½æ•°å¤„ç†
        return dispatch_table["default"](*args, **kwargs)

    fn = dispatch_table[device]

    # ä¸€äº›è®¾å¤‡æ— å…³å‡½æ•°ä¼šè¿”å›å€¼ï¼Œéœ€è¦åœ¨ç”¨æˆ·çº§åˆ«å¤„é˜²æ­¢è¿”å› `None`
    # è€Œä¸æ˜¯åœ¨æ­¤å¤„ã€‚
    if fn is None:
        return None
    # è°ƒç”¨ç›¸åº”è®¾å¤‡çš„å‡½æ•°ï¼Œå¹¶ä¼ å…¥å‚æ•°å’Œå…³é”®å­—å‚æ•°
    return fn(*args, **kwargs)


if is_torch_available():
    # è®¾å¤‡åç§°åˆ°å¯è°ƒç”¨å‡½æ•°çš„æ˜ å°„ï¼Œä»¥æ”¯æŒè®¾å¤‡æ— å…³æµ‹è¯•ã€‚
    BACKEND_MANUAL_SEED = {"cuda": torch.cuda.manual_seed, "cpu": torch.manual_seed, "default": torch.manual_seed}
    # è®¾å¤‡åç§°åˆ°å‡½æ•°çš„æ˜ å°„ï¼Œç”¨äºæ¸…ç©ºç¼“å­˜ã€‚
    BACKEND_EMPTY_CACHE = {"cuda": torch.cuda.empty_cache, "cpu": None, "default": None}
    # è®¾å¤‡åç§°åˆ°å‡½æ•°çš„æ˜ å°„ï¼Œè¿”å›è®¾å¤‡ä¸Šçš„è®¾å¤‡æ•°é‡ã€‚
    BACKEND_DEVICE_COUNT = {"cuda": torch.cuda.device_count, "cpu": lambda: 0, "default": lambda: 1}


def backend_manual_seed(device: str, seed: int):
    # ä½¿ç”¨è®¾å¤‡æ— å…³è°ƒåº¦å‡½æ•°ï¼Œä¼ é€’è®¾å¤‡åç§°ã€ç§å­å‚æ•°ä»¥åŠå¯¹åº”çš„ç§å­å‡½æ•°æ˜ å°„ã€‚
    return _device_agnostic_dispatch(device, BACKEND_MANUAL_SEED, seed)


def backend_empty_cache(device: str):
    # ä½¿ç”¨è®¾å¤‡æ— å…³è°ƒåº¦å‡½æ•°ï¼Œä¼ é€’è®¾å¤‡åç§°ä»¥åŠæ¸…ç©ºç¼“å­˜å‡½æ•°æ˜ å°„ã€‚
    return _device_agnostic_dispatch(device, BACKEND_EMPTY_CACHE)


def backend_device_count(device: str):
    # ä½¿ç”¨è®¾å¤‡æ— å…³è°ƒåº¦å‡½æ•°ï¼Œä¼ é€’è®¾å¤‡åç§°ä»¥åŠè®¾å¤‡æ•°é‡å‡½æ•°æ˜ å°„ã€‚
    return _device_agnostic_dispatch(device, BACKEND_DEVICE_COUNT)


if is_torch_available():
    # å¦‚æœå¯ç”¨äº† `TRANSFORMERS_TEST_DEVICE_SPEC`ï¼Œæˆ‘ä»¬éœ€è¦å°†é¢å¤–çš„æ¡ç›®å¯¼å…¥åˆ°è®¾å¤‡åˆ°å‡½æ•°æ˜ å°„ä¸­ã€‚
    pass
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­æ˜¯å¦å­˜åœ¨åä¸º `TRANSFORMERS_TEST_DEVICE_SPEC` çš„å˜é‡
    if "TRANSFORMERS_TEST_DEVICE_SPEC" in os.environ:
        # è·å–ç¯å¢ƒå˜é‡ä¸­ `TRANSFORMERS_TEST_DEVICE_SPEC` å¯¹åº”çš„è·¯å¾„
        device_spec_path = os.environ["TRANSFORMERS_TEST_DEVICE_SPEC"]
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦æŒ‡å‘ä¸€ä¸ªå­˜åœ¨çš„æ–‡ä»¶ï¼Œè‹¥ä¸å­˜åœ¨åˆ™æŠ›å‡ºå¼‚å¸¸
        if not Path(device_spec_path).is_file():
            raise ValueError(
                f"Specified path to device spec file is not a file or not found. Received '{device_spec_path}"
            )

        # å°è¯•æˆªå–æ–‡ä»¶ååç¼€ä»¥ä¾›åç»­å¯¼å…¥ï¼ŒåŒæ—¶éªŒè¯æ–‡ä»¶æ˜¯å¦ä¸º Python æ–‡ä»¶
        try:
            import_name = device_spec_path[: device_spec_path.index(".py")]
        except ValueError as e:
            raise ValueError(f"Provided device spec file was not a Python file! Received '{device_spec_path}") from e

        # å¯¼å…¥æŒ‡å®šåç§°çš„æ¨¡å—
        device_spec_module = importlib.import_module(import_name)

        # æ£€æŸ¥å¯¼å…¥çš„æ¨¡å—æ˜¯å¦åŒ…å« `DEVICE_NAME` å±æ€§ï¼Œè‹¥ä¸å­˜åœ¨åˆ™æŠ›å‡ºå¼‚å¸¸
        try:
            device_name = device_spec_module.DEVICE_NAME
        except AttributeError as e:
            raise AttributeError("Device spec file did not contain `DEVICE_NAME`") from e

        # å¦‚æœç¯å¢ƒå˜é‡ `TRANSFORMERS_TEST_DEVICE` å­˜åœ¨ä¸”å…¶å€¼ä¸è®¾å¤‡åç§°ä¸åŒ¹é…ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
        if "TRANSFORMERS_TEST_DEVICE" in os.environ and torch_device != device_name:
            msg = f"Mismatch between environment variable `TRANSFORMERS_TEST_DEVICE` '{torch_device}' and device found in spec '{device_name}'\n"
            msg += "Either unset `TRANSFORMERS_TEST_DEVICE` or ensure it matches device spec name."
            raise ValueError(msg)

        # æ›´æ–° `torch_device` ä¸ºä»è®¾å¤‡è§„èŒƒæ–‡ä»¶ä¸­è·å–çš„è®¾å¤‡åç§°
        torch_device = device_name

        # å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œä»è®¾å¤‡è§„èŒƒæ–‡ä»¶ä¸­æ›´æ–°å‡½æ•°æ˜ å°„
        def update_mapping_from_spec(device_fn_dict: Dict[str, Callable], attribute_name: str):
            try:
                # å°è¯•ç›´æ¥å¯¼å…¥æŒ‡å®šçš„å‡½æ•°
                spec_fn = getattr(device_spec_module, attribute_name)
                device_fn_dict[torch_device] = spec_fn
            except AttributeError as e:
                # å¦‚æœå‡½æ•°ä¸å­˜åœ¨ï¼Œå¹¶ä¸”æ²¡æœ‰é»˜è®¤å‡½æ•°ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
                if "default" not in device_fn_dict:
                    raise AttributeError(
                        f"`{attribute_name}` not found in '{device_spec_path}' and no default fallback function found."
                    ) from e

        # ä¸ºæ¯ä¸ª `BACKEND_*` å­—å…¸è°ƒç”¨ `update_mapping_from_spec` å‡½æ•°ï¼Œæ›´æ–°å‡½æ•°æ˜ å°„
        update_mapping_from_spec(BACKEND_MANUAL_SEED, "MANUAL_SEED_FN")
        update_mapping_from_spec(BACKEND_EMPTY_CACHE, "EMPTY_CACHE_FN")
        update_mapping_from_spec(BACKEND_DEVICE_COUNT, "DEVICE_COUNT_FN")
```