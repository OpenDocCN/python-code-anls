# `.\models\fastspeech2_conformer\convert_model_with_hifigan.py`

```
# coding=utf-8
# è®¾ç½®æ–‡ä»¶ç¼–ç ä¸ºUTF-8ï¼Œç¡®ä¿æ”¯æŒä¸­æ–‡å’Œå…¶ä»–ç‰¹æ®Šå­—ç¬¦çš„æ­£ç¡®å¤„ç†

# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import argparse  # å¯¼å…¥ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°çš„æ¨¡å— argparse

import torch  # å¯¼å…¥ PyTorch åº“

from transformers import (  # ä» transformers åº“ä¸­å¯¼å…¥ä»¥ä¸‹æ¨¡å—å’Œç±»
    FastSpeech2ConformerConfig,  # FastSpeech2ConformerConfig ç±»ï¼Œç”¨äºé…ç½® FastSpeech2Conformer æ¨¡å‹
    FastSpeech2ConformerHifiGan,  # FastSpeech2ConformerHifiGan ç±»ï¼Œç”¨äº FastSpeech2Conformer å’Œ HifiGan çš„ç»“åˆ
    FastSpeech2ConformerHifiGanConfig,  # FastSpeech2ConformerHifiGanConfig ç±»ï¼Œé…ç½® FastSpeech2ConformerHifiGan æ¨¡å‹
    FastSpeech2ConformerModel,  # FastSpeech2ConformerModel ç±»ï¼ŒFastSpeech2Conformer æ¨¡å‹
    FastSpeech2ConformerWithHifiGan,  # FastSpeech2ConformerWithHifiGan ç±»ï¼Œç»“åˆ FastSpeech2Conformer å’Œ HifiGan çš„æ¨¡å‹
    FastSpeech2ConformerWithHifiGanConfig,  # FastSpeech2ConformerWithHifiGanConfig ç±»ï¼Œé…ç½® FastSpeech2ConformerWithHifiGan æ¨¡å‹
    logging,  # logging æ¨¡å—ï¼Œç”¨äºè®°å½•æ—¥å¿—
)

from .convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch import (  # å¯¼å…¥æœ¬åœ°çš„æ¨¡å—å’Œå‡½æ•°
    convert_espnet_state_dict_to_hf,  # convert_espnet_state_dict_to_hf å‡½æ•°ï¼Œå°† espnet æ¨¡å‹çš„çŠ¶æ€å­—å…¸è½¬æ¢ä¸º HF å…¼å®¹æ ¼å¼
    remap_model_yaml_config,  # remap_model_yaml_config å‡½æ•°ï¼Œé‡æ˜ å°„æ¨¡å‹çš„ YAML é…ç½®
)

from .convert_hifigan import load_weights, remap_hifigan_yaml_config  # å¯¼å…¥æœ¬åœ°çš„ load_weights å’Œ remap_hifigan_yaml_config å‡½æ•°

# è®¾ç½®æ—¥å¿—çš„è¯¦ç»†ç¨‹åº¦ä¸º info
logging.set_verbosity_info()

# è·å– logger å¯¹è±¡
logger = logging.get_logger("transformers.models.FastSpeech2Conformer")


def convert_FastSpeech2ConformerWithHifiGan_checkpoint(
    checkpoint_path,
    yaml_config_path,
    pytorch_dump_folder_path,
    repo_id=None,
):
    # å‡†å¤‡æ¨¡å‹
    model_params, *_ = remap_model_yaml_config(yaml_config_path)
    model_config = FastSpeech2ConformerConfig(**model_params)  # ä½¿ç”¨ä» YAML æ–‡ä»¶ä¸­æå–çš„å‚æ•°é…ç½® FastSpeech2ConformerConfig

    model = FastSpeech2ConformerModel(model_config)  # åŸºäºé…ç½®åˆ›å»º FastSpeech2ConformerModel å¯¹è±¡

    espnet_checkpoint = torch.load(checkpoint_path)  # åŠ è½½åŸå§‹ ESPnet æ¨¡å‹çš„æ£€æŸ¥ç‚¹
    hf_compatible_state_dict = convert_espnet_state_dict_to_hf(espnet_checkpoint)  # å°† ESPnet æ¨¡å‹çš„çŠ¶æ€å­—å…¸è½¬æ¢ä¸º HF å…¼å®¹æ ¼å¼
    model.load_state_dict(hf_compatible_state_dict)  # åŠ è½½ HF å…¼å®¹çš„çŠ¶æ€å­—å…¸åˆ°æ¨¡å‹ä¸­

    # å‡†å¤‡å£°ç å™¨
    config_kwargs = remap_hifigan_yaml_config(yaml_config_path)  # ä» YAML æ–‡ä»¶ä¸­è·å–å£°ç å™¨é…ç½®å‚æ•°
    vocoder_config = FastSpeech2ConformerHifiGanConfig(**config_kwargs)  # ä½¿ç”¨é…ç½®å‚æ•°åˆ›å»º FastSpeech2ConformerHifiGanConfig

    vocoder = FastSpeech2ConformerHifiGan(vocoder_config)  # åŸºäºé…ç½®åˆ›å»º FastSpeech2ConformerHifiGan å£°ç å™¨
    load_weights(espnet_checkpoint, vocoder, vocoder_config)  # åŠ è½½æƒé‡åˆ°å£°ç å™¨ä¸­

    # å‡†å¤‡æ¨¡å‹ + å£°ç å™¨ç»„åˆ
    config = FastSpeech2ConformerWithHifiGanConfig.from_sub_model_configs(model_config, vocoder_config)
    with_hifigan_model = FastSpeech2ConformerWithHifiGan(config)  # åŸºäºç»„åˆé…ç½®åˆ›å»º FastSpeech2ConformerWithHifiGan æ¨¡å‹
    with_hifigan_model.model = model  # å°† FastSpeech2Conformer æ¨¡å‹èµ‹ç»™ç»„åˆæ¨¡å‹çš„æˆå‘˜å˜é‡
    with_hifigan_model.vocoder = vocoder  # å°†å£°ç å™¨èµ‹ç»™ç»„åˆæ¨¡å‹çš„å£°ç å™¨æˆå‘˜å˜é‡

    with_hifigan_model.save_pretrained(pytorch_dump_folder_path)  # ä¿å­˜ç»„åˆæ¨¡å‹åˆ°æŒ‡å®šè·¯å¾„

    if repo_id:
        print("Pushing to the hub...")
        with_hifigan_model.push_to_hub(repo_id)  # å°†æ¨¡å‹æ¨é€åˆ°æ¨¡å‹ä¸­å¿ƒï¼ˆhubï¼‰
    # é…ç½®è§£æå™¨æ·»åŠ å‚æ•°
    def parse_args():
        parser = argparse.ArgumentParser(
            description="Script for converting FastSpeech2Conformer with HifiGAN Model"
        )
    
        # å¿…é¡»å‚æ•°: è¾“å‡ºçš„ PyTorch æ¨¡å‹è·¯å¾„
        parser.add_argument(
            "--pytorch_dump_folder_path",
            required=True,
            default=None,
            type=str,
            help="Path to the output `FastSpeech2ConformerModel` PyTorch model.",
        )
        # é€‰æ‹©å‚æ•°: å°†æ¨¡å‹ä¸Šä¼ åˆ° ğŸ¤— hub çš„é€‰é¡¹
        parser.add_argument(
            "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
        )
    
        # è§£æå‚æ•°
        args = parser.parse_args()
    
        # ä¸»å‡½æ•°è°ƒç”¨
        convert_FastSpeech2ConformerWithHifiGan_checkpoint(
            args.checkpoint_path,
            args.yaml_config_path,
            args.pytorch_dump_folder_path,
            args.push_to_hub,
        )
```