# `.\transformers\training_args.py`

```
# ç‰ˆæƒå£°æ˜åŠè®¸å¯ä¿¡æ¯
# Copyright 2020 The HuggingFace Team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# å¯¼å…¥æ‰€éœ€çš„åº“
import contextlib
import io
import json
import math
import os
import warnings
from dataclasses import asdict, dataclass, field, fields
from datetime import timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

# ä»huggingface_hubå¯¼å…¥è·å–å®Œæ•´ä»“åº“åç§°çš„å‡½æ•°
from huggingface_hub import get_full_repo_name
# å¯¼å…¥ç‰ˆæœ¬ä¿¡æ¯å¤„ç†åº“
from packaging import version

# å¯¼å…¥è°ƒè¯•å·¥å…·å‡½æ•°
from .debug_utils import DebugOption
# å¯¼å…¥è®­ç»ƒå™¨å·¥å…·å‡½æ•°
from .trainer_utils import (
    EvaluationStrategy,
    FSDPOption,
    HubStrategy,
    IntervalStrategy,
    SchedulerType,
)
# å¯¼å…¥å·¥å…·å‡½æ•°
from .utils import (
    ACCELERATE_MIN_VERSION,
    ExplicitEnum,
    cached_property,
    is_accelerate_available,
    is_safetensors_available,
    is_sagemaker_dp_enabled,
    is_sagemaker_mp_enabled,
    is_torch_available,
    is_torch_bf16_cpu_available,
    is_torch_bf16_gpu_available,
    is_torch_neuroncore_available,
    is_torch_npu_available,
    is_torch_tf32_available,
    is_torch_tpu_available,
    is_torch_xpu_available,
    logging,
    requires_backends,
)
# å¯¼å…¥é€šç”¨å·¥å…·å‡½æ•°
from .utils.generic import strtobool
# å¯¼å…¥æ¨¡å‹ä¼˜åŒ–å·¥å…·å‡½æ•°
from .utils.import_utils import is_optimum_neuron_available

# è·å–æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger(__name__)
# å¤åˆ¶æ—¥å¿—çº§åˆ«å­—å…¸ï¼Œä½œä¸ºæ—¥å¿—è®°å½•å™¨çš„æ—¥å¿—çº§åˆ«
log_levels = logging.get_log_levels_dict().copy()
# æ›´æ–°è®­ç»ƒå™¨æ—¥å¿—çº§åˆ«å­—å…¸
trainer_log_levels = dict(**log_levels, passive=-1)

# å¦‚æœtorchåº“å¯ç”¨
if is_torch_available():
    # å¯¼å…¥torchåº“
    import torch
    # å¯¼å…¥torchåˆ†å¸ƒå¼åº“
    import torch.distributed as dist

# å¦‚æœåŠ é€Ÿåº“å¯ç”¨
if is_accelerate_available():
    # ä»åŠ é€Ÿåº“å¯¼å…¥çŠ¶æ€å’Œéƒ¨åˆ†çŠ¶æ€
    from accelerate.state import AcceleratorState, PartialState
    # ä»åŠ é€Ÿåº“å¯¼å…¥åˆ†å¸ƒå¼ç±»å‹
    from accelerate.utils import DistributedType

# å¦‚æœå­˜åœ¨torch_tpuåº“å¯ç”¨ï¼ˆæ£€æŸ¥è®¾å¤‡æ—¶ä¸è¦æ±‚ï¼‰
if is_torch_tpu_available(check_device=False):
    # å¯¼å…¥torch_xla.core.xla_modelåº“
    import torch_xla.core.xla_model as xm

# å¦‚æœå­˜åœ¨torch_neuroncoreåº“å¯ç”¨ï¼ˆæ£€æŸ¥è®¾å¤‡æ—¶ä¸è¦æ±‚ï¼‰
if is_torch_neuroncore_available(check_device=False):
    # å¯¼å…¥torchrunæ”¯æŒåº“
    # https://github.com/pytorch/xla/pull/3609
```  
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åä¸º "TORCHELASTIC_RUN_ID" çš„ç¯å¢ƒå˜é‡
    if os.environ.get("TORCHELASTIC_RUN_ID"):
        # å¦‚æœå¯ç”¨çš„æœ€ä½³ç¥ç»å…ƒèµ„æºå¯ç”¨
        if is_optimum_neuron_available():
            # è¾“å‡ºä¿¡æ¯æç¤ºï¼Œå»ºè®®ä½¿ç”¨ optimum[neuron] çš„ TrainiumTrainer è¿›è¡Œè®­ç»ƒï¼Œå¦åˆ™ä¼šå¤±è´¥
            logger.info(
                "Make sure that you are performing the training with the TrainiumTrainer from optimum[neuron], this "
                "will fail otherwise."
            )
        else:
            # è¾“å‡ºè­¦å‘Šä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨ optimum[neuron] çš„ TrainiumTrainer ä»£æ›¿ Transformers åº“åœ¨ AWS Trainium å®ä¾‹ä¸Šè¿›è¡Œè®­ç»ƒ
            logger.warning(
                "Please use the TrainiumTrainer from optimum[neuron] instead of the Transformers library to perform "
                "training on AWS Trainium instances. More information here: "
                "https://github.com/huggingface/optimum-neuron"
            )
            # å¯¼å…¥ torch_xla.distributed.xla_backend æ¨¡å—
            import torch_xla.distributed.xla_backend as xbn

            # å¦‚æœ dist.group.WORLD ä¸æ˜¯ xbn.ProcessGroupXla ç±»å‹çš„å®ä¾‹
            if not isinstance(dist.group.WORLD, xbn.ProcessGroupXla):
                # ä½¿ç”¨ XLA åç«¯åˆå§‹åŒ– torch.distributed è¿›ç¨‹ç»„
                dist.init_process_group(backend="xla")
                # å¦‚æœ dist.group.WORLD ä»ç„¶ä¸æ˜¯ xbn.ProcessGroupXla ç±»å‹çš„å®ä¾‹
                if not isinstance(dist.group.WORLD, xbn.ProcessGroupXla):
                    # æŠ›å‡ºå¼‚å¸¸ï¼Œè¡¨ç¤ºä½¿ç”¨ XLA åç«¯åˆå§‹åŒ– torch.distributed è¿›ç¨‹ç»„å¤±è´¥
                    raise AssertionError("Failed to initialize torch.distributed process group using XLA backend.")
```  
# å¦‚æœ SageMaker å¤šæ¨¡å‹å¹¶è¡Œè®­ç»ƒè¢«å¯ç”¨
if is_sagemaker_mp_enabled():
    # å¯¼å…¥ SageMaker å¤šæ¨¡å‹å¹¶è¡Œè®­ç»ƒ Torch åº“
    import smdistributed.modelparallel.torch as smp
    # åˆå§‹åŒ–å¤šæ¨¡å‹å¹¶è¡Œè®­ç»ƒ
    smp.init()

# é»˜è®¤æ—¥å¿—ç›®å½•å‡½æ•°ï¼Œè¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²è·¯å¾„
def default_logdir() -> str:
    """
    Same default as PyTorch
    """
    # å¯¼å…¥ socket æ¨¡å—
    import socket
    # å¯¼å…¥ datetime æ¨¡å—ä¸­çš„ datetime å‡½æ•°
    from datetime import datetime

    # è·å–å½“å‰æ—¶é—´çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œæ ¼å¼ä¸ºæœˆä»½å’Œæ—¥æœŸ_å°æ—¶-åˆ†é’Ÿ-ç§’
    current_time = datetime.now().strftime("%b%d_%H-%M-%S")
    # è¿”å›é»˜è®¤æ—¥å¿—ç›®å½•ï¼Œç»“åˆå½“å‰æ—¶é—´å’Œä¸»æœºå
    return os.path.join("runs", current_time + "_" + socket.gethostname())

# ä»ç¯å¢ƒå˜é‡ä¸­è·å–æ•´æ•°å€¼å‡½æ•°
def get_int_from_env(env_keys, default):
    """Returns the first positive env value found in the `env_keys` list or the default."""
    # éå†ç¯å¢ƒå˜é‡é”®åˆ—è¡¨
    for e in env_keys:
        # è·å–ç¯å¢ƒå˜é‡å€¼å¹¶è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸º -1
        val = int(os.environ.get(e, -1))
        # å¦‚æœå€¼å¤§äºç­‰äº 0ï¼Œåˆ™è¿”å›è¯¥å€¼
        if val >= 0:
            return val
    # å¦‚æœæ‰€æœ‰ç¯å¢ƒå˜é‡çš„å€¼éƒ½å°äº 0ï¼Œåˆ™è¿”å›é»˜è®¤å€¼
    return default

# è·å– XLA è®¾å¤‡ç±»å‹å‡½æ•°ï¼Œå‚æ•°ä¸º torch è®¾å¤‡å¯¹è±¡ï¼Œè¿”å›å­—ç¬¦ä¸²ç±»å‹æˆ– None
def get_xla_device_type(device: "torch.device") -> Optional[str]:
    """
    Returns the xla device type (CPU|GPU|TPU) or None if the device is a non-xla device.
    """
    # å¦‚æœå½“å‰å¯ç”¨çš„æ˜¯ TPU
    if is_torch_tpu_available():
        # è¿”å› XLA è®¾å¤‡ç±»å‹ï¼ˆCPU|GPU|TPUï¼‰æˆ– None
        return xm.xla_real_devices([device])[0].split(":")[0]
    # å¦‚æœä¸æ˜¯ XLA è®¾å¤‡ï¼Œåˆ™è¿”å› None
    return None

# ä¼˜åŒ–å™¨åç§°æšä¸¾ç±»ï¼Œå­˜å‚¨ä¼˜åŒ–å™¨çš„å¯æ¥å—å­—ç¬¦ä¸²æ ‡è¯†ç¬¦
class OptimizerNames(ExplicitEnum):
    """
    Stores the acceptable string identifiers for optimizers.
    """

    ADAMW_HF = "adamw_hf"
    ADAMW_TORCH = "adamw_torch"
    ADAMW_TORCH_FUSED = "adamw_torch_fused"
    ADAMW_TORCH_XLA = "adamw_torch_xla"
    ADAMW_TORCH_NPU_FUSED = "adamw_torch_npu_fused"
    ADAMW_APEX_FUSED = "adamw_apex_fused"
    ADAFACTOR = "adafactor"
    ADAMW_ANYPRECISION = "adamw_anyprecision"
    SGD = "sgd"
    ADAGRAD = "adagrad"
    ADAMW_BNB = "adamw_bnb_8bit"
    ADAMW_8BIT = "adamw_8bit"  # just an alias for adamw_bnb_8bit
    LION_8BIT = "lion_8bit"
    LION = "lion_32bit"
    PAGED_ADAMW = "paged_adamw_32bit"
    PAGED_ADAMW_8BIT = "paged_adamw_8bit"
    PAGED_LION = "paged_lion_32bit"
    PAGED_LION_8BIT = "paged_lion_8bit"
    RMSPROP = "rmsprop"

# è®­ç»ƒå‚æ•°æ•°æ®ç±»ï¼Œç”¨äºæŒ‡å®šè®­ç»ƒç›¸å…³çš„å‚æ•°
# TODO: `TrainingArguments` users rely on it being fully mutable. In the future see if we can narrow this to a few keys: https://github.com/huggingface/transformers/pull/25903
@dataclass
class TrainingArguments:
    """
    TrainingArguments is the subset of the arguments we use in our example scripts **which relate to the training loop
    itself**.

    Using [`HfArgumentParser`] we can turn this class into
    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the
    command line.

    """

    # æ¡†æ¶ç±»å‹ï¼Œé»˜è®¤ä¸º "pt"ï¼ˆPyTorchï¼‰
    framework = "pt"
    # è¾“å‡ºç›®å½•ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹é¢„æµ‹å’Œæ£€æŸ¥ç‚¹
    output_dir: str = field(
        metadata={"help": "The output directory where the model predictions and checkpoints will be written."},
    )
    # æ˜¯å¦è¦†ç›–è¾“å‡ºç›®å½•çš„å†…å®¹ï¼Œé»˜è®¤ä¸º False
    overwrite_output_dir: bool = field(
        default=False,
        metadata={
            "help": (
                "Overwrite the content of the output directory. "
                "Use this to continue training if output_dir points to a checkpoint directory."
            )
        },
    )

    # æ˜¯å¦è¿è¡Œè®­ç»ƒï¼Œé»˜è®¤ä¸º False
    do_train: bool = field(default=False, metadata={"help": "Whether to run training."})
    # æ˜¯å¦åœ¨å¼€å‘é›†ä¸Šè¿è¡Œè¯„ä¼°ï¼Œé»˜è®¤ä¸º False
    do_eval: bool = field(default=False, metadata={"help": "Whether to run eval on the dev set."})
    # æ˜¯å¦è¿è¡Œæµ‹è¯•é›†ä¸Šçš„é¢„æµ‹
    do_predict: bool = field(default=False, metadata={"help": "Whether to run predictions on the test set."})
    
    # è¯„ä¼°ç­–ç•¥
    evaluation_strategy: Union[IntervalStrategy, str] = field(
        default="no",
        metadata={"help": "The evaluation strategy to use."},
    )
    
    # ä»…è¿”å›æŸå¤±å€¼
    prediction_loss_only: bool = field(
        default=False,
        metadata={"help": "When performing evaluation and predictions, only returns the loss."},
    )

    # è®­ç»ƒæ—¶æ¯ä¸ª GPU/TPU/MPS/NPU core/CPU çš„æ‰¹é‡å¤§å°
    per_device_train_batch_size: int = field(
        default=8, metadata={"help": "Batch size per GPU/TPU/MPS/NPU core/CPU for training."}
    )
    
    # è¯„ä¼°æ—¶æ¯ä¸ª GPU/TPU/MPS/NPU core/CPU çš„æ‰¹é‡å¤§å°
    per_device_eval_batch_size: int = field(
        default=8, metadata={"help": "Batch size per GPU/TPU/MPS/NPU core/CPU for evaluation."}
    )

    # è®­ç»ƒæ—¶æ¯ä¸ª GPU/TPU core/CPU çš„æ‰¹é‡å¤§å°ï¼ˆå·²å¼ƒç”¨ï¼‰
    per_gpu_train_batch_size: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "Deprecated, the use of `--per_device_train_batch_size` is preferred. "
                "Batch size per GPU/TPU core/CPU for training."
            )
        },
    )
    
    # è¯„ä¼°æ—¶æ¯ä¸ª GPU/TPU core/CPU çš„æ‰¹é‡å¤§å°ï¼ˆå·²å¼ƒç”¨ï¼‰
    per_gpu_eval_batch_size: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "Deprecated, the use of `--per_device_eval_batch_size` is preferred. "
                "Batch size per GPU/TPU core/CPU for evaluation."
            )
        },
    )

    # ç´¯ç§¯æ¢¯åº¦æ›´æ–°æ­¥æ•°
    gradient_accumulation_steps: int = field(
        default=1,
        metadata={"help": "Number of updates steps to accumulate before performing a backward/update pass."},
    )
    
    # ç´¯ç§¯è¯„ä¼°æ­¥æ•°
    eval_accumulation_steps: Optional[int] = field(
        default=None,
        metadata={"help": "Number of predictions steps to accumulate before moving the tensors to the CPU."},
    )

    # å»¶è¿Ÿè¯„ä¼°çš„æ—¶é—´
    eval_delay: Optional[float] = field(
        default=0,
        metadata={
            "help": (
                "Number of epochs or steps to wait for before the first evaluation can be performed, depending on the"
                " evaluation_strategy."
            )
        },
    )

    # AdamW çš„åˆå§‹å­¦ä¹ ç‡
    learning_rate: float = field(default=5e-5, metadata={"help": "The initial learning rate for AdamW."})
    
    # AdamW çš„æƒé‡è¡°å‡
    weight_decay: float = field(default=0.0, metadata={"help": "Weight decay for AdamW if we apply some."})
    
    # AdamW ä¼˜åŒ–å™¨çš„ Beta1
    adam_beta1: float = field(default=0.9, metadata={"help": "Beta1 for AdamW optimizer"})
    
    # AdamW ä¼˜åŒ–å™¨çš„ Beta2
    adam_beta2: float = field(default=0.999, metadata={"help": "Beta2 for AdamW optimizer"})
    
    # AdamW ä¼˜åŒ–å™¨çš„ Epsilon
    adam_epsilon: float = field(default=1e-8, metadata={"help": "Epsilon for AdamW optimizer."})
    
    # æœ€å¤§æ¢¯åº¦èŒƒæ•°
    max_grad_norm: float = field(default=1.0, metadata={"help": "Max gradient norm."})

    # æ€»è®­ç»ƒè½®æ•°
    num_train_epochs: float = field(default=3.0, metadata={"help": "Total number of training epochs to perform."})
    
    # æœ€å¤§è®­ç»ƒæ­¥æ•°
    max_steps: int = field(
        default=-1,
        metadata={"help": "If > 0: set total number of training steps to perform. Override num_train_epochs."},
    )
    
    # ä½¿ç”¨çš„è°ƒåº¦å™¨ç±»å‹
    lr_scheduler_type: Union[SchedulerType, str] = field(
        default="linear",
        metadata={"help": "The scheduler type to use."},
    )
    lr_scheduler_kwargs: Optional[Dict] = field(
        default_factory=dict,
        metadata={
            "help": (
                "Extra parameters for the lr_scheduler such as {'num_cycles': 1} for the cosine with hard restarts"
            )
        },
    )
    # å­¦ä¹ ç‡è°ƒåº¦å™¨çš„é¢å¤–å‚æ•°ï¼Œä¾‹å¦‚ {'num_cycles': 1} ç”¨äºä½™å¼¦é€€ç«é‡å¯çš„å‚æ•°

    warmup_ratio: float = field(
        default=0.0, metadata={"help": "Linear warmup over warmup_ratio fraction of total steps."}
    )
    # çº¿æ€§é¢„çƒ­ï¼Œå æ€»æ­¥æ•°çš„æ¯”ä¾‹

    warmup_steps: int = field(default=0, metadata={"help": "Linear warmup over warmup_steps."})
    # çº¿æ€§é¢„çƒ­çš„æ­¥æ•°

    log_level: Optional[str] = field(
        default="passive",
        metadata={
            "help": (
                "Logger log level to use on the main node. Possible choices are the log levels as strings: 'debug',"
                " 'info', 'warning', 'error' and 'critical', plus a 'passive' level which doesn't set anything and"
                " lets the application set the level. Defaults to 'passive'."
            ),
            "choices": trainer_log_levels.keys(),
        },
    )
    # ä¸»èŠ‚ç‚¹ä¸Šè¦ä½¿ç”¨çš„è®°å½•å™¨æ—¥å¿—çº§åˆ«

    log_level_replica: Optional[str] = field(
        default="warning",
        metadata={
            "help": "Logger log level to use on replica nodes. Same choices and defaults as ``log_level``",
            "choices": trainer_log_levels.keys(),
        },
    )
    # å‰¯æœ¬èŠ‚ç‚¹ä¸Šè¦ä½¿ç”¨çš„è®°å½•å™¨æ—¥å¿—çº§åˆ«ï¼Œä¸ log_level ç›¸åŒ

    log_on_each_node: bool = field(
        default=True,
        metadata={
            "help": (
                "When doing a multinode distributed training, whether to log once per node or just once on the main"
                " node."
            )
        },
    )
    # åœ¨å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œæ˜¯å¦æ¯ä¸ªèŠ‚ç‚¹éƒ½è®°å½•æ—¥å¿—

    logging_dir: Optional[str] = field(default=None, metadata={"help": "Tensorboard log dir."})
    # Tensorboard æ—¥å¿—ç›®å½•

    logging_strategy: Union[IntervalStrategy, str] = field(
        default="steps",
        metadata={"help": "The logging strategy to use."},
    )
    # ä½¿ç”¨çš„è®°å½•ç­–ç•¥

    logging_first_step: bool = field(default=False, metadata={"help": "Log the first global_step"})
    # è®°å½•ç¬¬ä¸€ä¸ªå…¨å±€æ­¥éª¤

    logging_steps: float = field(
        default=500,
        metadata={
            "help": (
                "Log every X updates steps. Should be an integer or a float in range `[0,1)`. "
                "If smaller than 1, will be interpreted as ratio of total training steps."
            )
        },
    )
    # æ¯ X æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—

    logging_nan_inf_filter: bool = field(default=True, metadata={"help": "Filter nan and inf losses for logging."})
    # è¿‡æ»¤è®°å½•ä¸­çš„ nan å’Œ inf æŸå¤±

    save_strategy: Union[IntervalStrategy, str] = field(
        default="steps",
        metadata={"help": "The checkpoint save strategy to use."},
    )
    # ä½¿ç”¨çš„æ£€æŸ¥ç‚¹ä¿å­˜ç­–ç•¥

    save_steps: float = field(
        default=500,
        metadata={
            "help": (
                "Save checkpoint every X updates steps. Should be an integer or a float in range `[0,1)`. "
                "If smaller than 1, will be interpreted as ratio of total training steps."
            )
        },
    )
    # æ¯ X æ­¥ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
    # ä¿å­˜æ£€æŸ¥ç‚¹çš„æ€»æ•°é™åˆ¶ï¼Œå¦‚æœä¼ å…¥å€¼ï¼Œåˆ™é™åˆ¶æ£€æŸ¥ç‚¹çš„æ€»æ•°ã€‚åˆ é™¤`output_dir`ä¸­è¾ƒæ—§çš„æ£€æŸ¥ç‚¹ã€‚å½“å¯ç”¨`load_best_model_at_end`æ—¶ï¼Œæ ¹æ®`metric_for_best_model`å§‹ç»ˆä¿ç•™â€œæœ€ä½³â€æ£€æŸ¥ç‚¹ï¼Œä»¥åŠæœ€è¿‘çš„æ£€æŸ¥ç‚¹ã€‚ä¾‹å¦‚ï¼Œå¯¹äº`save_total_limit=5`å’Œ`load_best_model_at_end=True`ï¼Œæœ€åå››ä¸ªæ£€æŸ¥ç‚¹å°†å§‹ç»ˆä¸æœ€ä½³æ¨¡å‹ä¸€èµ·ä¿ç•™ã€‚å½“`save_total_limit=1`å’Œ`load_best_model_at_end=True`æ—¶ï¼Œå¯èƒ½ä¿å­˜ä¸¤ä¸ªæ£€æŸ¥ç‚¹ï¼šæœ€åä¸€ä¸ªå’Œæœ€ä½³ä¸€ä¸ªï¼ˆå¦‚æœå®ƒä»¬ä¸åŒï¼‰ã€‚é»˜è®¤ä¸ºæ— é™åˆ¶æ£€æŸ¥ç‚¹
    save_total_limit: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in"
                " `output_dir`. When `load_best_model_at_end` is enabled, the 'best' checkpoint according to"
                " `metric_for_best_model` will always be retained in addition to the most recent ones. For example,"
                " for `save_total_limit=5` and `load_best_model_at_end=True`, the four last checkpoints will always be"
                " retained alongside the best model. When `save_total_limit=1` and `load_best_model_at_end=True`,"
                " it is possible that two checkpoints are saved: the last one and the best one (if they are different)."
                " Default is unlimited checkpoints"
            )
        },
    )
    
    # ä½¿ç”¨safetensorsä¿å­˜å’ŒåŠ è½½çŠ¶æ€å­—å…¸ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„torch.loadå’Œtorch.save
    save_safetensors: Optional[bool] = field(
        default=True,
        metadata={
            "help": "Use safetensors saving and loading for state dicts instead of default torch.load and torch.save."
        },
    )
    
    # åœ¨è¿›è¡Œå¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œæ˜¯å¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šä¿å­˜æ¨¡å‹å’Œæ£€æŸ¥ç‚¹ï¼Œè¿˜æ˜¯ä»…åœ¨ä¸»èŠ‚ç‚¹ä¸Šä¿å­˜
    save_on_each_node: bool = field(
        default=False,
        metadata={
            "help": (
                "When doing multi-node distributed training, whether to save models and checkpoints on each node, or"
                " only on the main one"
            )
        },
    )
    
    # åœ¨æ£€æŸ¥ç‚¹æ—¶ï¼Œæ˜¯å¦ä»…ä¿å­˜æ¨¡å‹ï¼Œè¿˜æ˜¯åŒæ—¶ä¿å­˜ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨å’Œéšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€ã€‚æ³¨æ„ï¼Œå½“æ­¤é€‰é¡¹ä¸ºçœŸæ—¶ï¼Œæ‚¨å°†æ— æ³•ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚è¿™æ ·å¯ä»¥é€šè¿‡ä¸å­˜å‚¨ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨å’Œéšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€æ¥èŠ‚çœå­˜å‚¨ç©ºé—´ã€‚æ‚¨åªèƒ½ä½¿ç”¨è®¾ç½®ä¸ºTrueçš„from_pretrainedåŠ è½½æ¨¡å‹ã€‚
    save_only_model: bool = field(
        default=False,
        metadata={
            "help": (
                "When checkpointing, whether to only save the model, or also the optimizer, scheduler & rng state."
                "Note that when this is true, you won't be able to resume training from checkpoint."
                "This enables you to save storage by not storing the optimizer, scheduler & rng state."
                "You can only load the model using from_pretrained with this option set to True."
            )
        },
    )
    
    # æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚åœ¨ğŸ¤— Transformersçš„5.0ç‰ˆæœ¬ä¸­å°†è¢«ç§»é™¤ã€‚
    no_cuda: bool = field(
        default=False,
        metadata={"help": "This argument is deprecated. It will be removed in version 5.0 of ğŸ¤— Transformers."},
    )
    
    # æ˜¯å¦ä½¿ç”¨cpuã€‚å¦‚æœè®¾ç½®ä¸ºFalseï¼Œå°†ä½¿ç”¨cuda/tpu/mps/npuè®¾å¤‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚
    use_cpu: bool = field(
        default=False,
        metadata={
            "help": " Whether or not to use cpu. If set to False, we will use cuda/tpu/mps/npu device if available."
        },
    )
    
    # æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚å°†ä½¿ç”¨`mps`è®¾å¤‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œç±»ä¼¼äº`cuda`è®¾å¤‡ã€‚åœ¨ğŸ¤— Transformersçš„5.0ç‰ˆæœ¬ä¸­å°†è¢«ç§»é™¤ã€‚
    use_mps_device: bool = field(
        default=False,
        metadata={
            "help": "This argument is deprecated. `mps` device will be used if available similar to `cuda` device."
            " It will be removed in version 5.0 of ğŸ¤— Transformers"
        },
    )
    
    # åœ¨è®­ç»ƒå¼€å§‹æ—¶è®¾ç½®çš„éšæœºç§å­
    seed: int = field(default=42, metadata={"help": "Random seed that will be set at the beginning of training."})
    
    # ç”¨äºæ•°æ®é‡‡æ ·å™¨çš„éšæœºç§å­
    data_seed: Optional[int] = field(default=None, metadata={"help": "Random seed to be used with data samplers."})
    
    # æ˜¯å¦åœ¨æ¨æ–­æ—¶ä½¿ç”¨PyTorch jitè·Ÿè¸ª
    jit_mode_eval: bool = field(
        default=False, metadata={"help": "Whether or not to use PyTorch jit trace for inference"}
    )
    use_ipex: bool = field(  # æ˜¯å¦ä½¿ç”¨ Intel PyTorch æ‰©å±•ï¼Œå¦‚æœå¯ç”¨
        default=False,  # é»˜è®¤ä¸º False
        metadata={  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
            "help": (
                "Use Intel extension for PyTorch when it is available, installation:"  # ä½¿ç”¨ Intel PyTorch æ‰©å±•ï¼Œå®‰è£…é“¾æ¥
                " 'https://github.com/intel/intel-extension-for-pytorch'"
            )
        },
    )
    bf16: bool = field(  # æ˜¯å¦ä½¿ç”¨ bf16ï¼ˆæ··åˆï¼‰ç²¾åº¦ä»£æ›¿ 32 ä½ç²¾åº¦
        default=False,  # é»˜è®¤ä¸º False
        metadata={  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
            "help": (
                "Whether to use bf16 (mixed) precision instead of 32-bit. Requires Ampere or higher NVIDIA"  # æ˜¯å¦ä½¿ç”¨ bf16ï¼ˆæ··åˆï¼‰ç²¾åº¦ä»£æ›¿ 32 ä½ç²¾åº¦ï¼Œéœ€è¦ Ampere æˆ–æ›´é«˜ç‰ˆæœ¬çš„ NVIDIA
                " architecture or using CPU (use_cpu) or Ascend NPU. This is an experimental API and it may change."  # æˆ–ä½¿ç”¨ CPUï¼ˆuse_cpuï¼‰æˆ– Ascend NPUã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§çš„ APIï¼Œå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–
            )
        },
    )
    fp16: bool = field(  # æ˜¯å¦ä½¿ç”¨ fp16ï¼ˆæ··åˆï¼‰ç²¾åº¦ä»£æ›¿ 32 ä½ç²¾åº¦
        default=False,  # é»˜è®¤ä¸º False
        metadata={"help": "Whether to use fp16 (mixed) precision instead of 32-bit"},  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
    )
    fp16_opt_level: str = field(  # fp16 ä¼˜åŒ–çº§åˆ«
        default="O1",  # é»˜è®¤ä¸º O1
        metadata={  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
            "help": (
                "For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']. "  # fp16 çš„ Apex AMP ä¼˜åŒ–çº§åˆ«ï¼Œå¯é€‰å€¼ä¸º ['O0', 'O1', 'O2', 'O3']
                "See details at https://nvidia.github.io/apex/amp.html"  # è¯¦æƒ…è¯·å‚é˜…é“¾æ¥
            )
        },
    )
    half_precision_backend: str = field(  # ä½¿ç”¨åŠç²¾åº¦çš„åç«¯
        default="auto",  # é»˜è®¤ä¸º auto
        metadata={  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
            "help": "The backend to be used for half precision.",  # ç”¨äºåŠç²¾åº¦çš„åç«¯
            "choices": ["auto", "apex", "cpu_amp"],  # å¯é€‰å€¼ä¸º autoã€apexã€cpu_amp
        },
    )
    bf16_full_eval: bool = field(  # æ˜¯å¦ä½¿ç”¨å®Œæ•´çš„ bf16 è¯„ä¼°ä»£æ›¿ 32 ä½ç²¾åº¦
        default=False,  # é»˜è®¤ä¸º False
        metadata={  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
            "help": (
                "Whether to use full bfloat16 evaluation instead of 32-bit. This is an experimental API and it may"  # æ˜¯å¦ä½¿ç”¨å®Œæ•´çš„ bf16 è¯„ä¼°ä»£æ›¿ 32 ä½ç²¾åº¦ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§çš„ APIï¼Œå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–
                " change."
            )
        },
    )
    fp16_full_eval: bool = field(  # æ˜¯å¦ä½¿ç”¨å®Œæ•´çš„ fp16 è¯„ä¼°ä»£æ›¿ 32 ä½ç²¾åº¦
        default=False,  # é»˜è®¤ä¸º False
        metadata={"help": "Whether to use full float16 evaluation instead of 32-bit"},  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
    )
    tf32: Optional[bool] = field(  # æ˜¯å¦å¯ç”¨ tf32 æ¨¡å¼ï¼Œä»…åœ¨ Ampere å’Œæ›´æ–°çš„ GPU æ¶æ„ä¸Šå¯ç”¨
        default=None,  # é»˜è®¤ä¸º None
        metadata={  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
            "help": (
                "Whether to enable tf32 mode, available in Ampere and newer GPU architectures. This is an experimental"  # æ˜¯å¦å¯ç”¨ tf32 æ¨¡å¼ï¼Œä»…åœ¨ Ampere å’Œæ›´æ–°çš„ GPU æ¶æ„ä¸Šå¯ç”¨ã€‚è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§çš„ APIï¼Œå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–
                " API and it may change."
            )
        },
    )
    local_rank: int = field(default=-1, metadata={"help": "For distributed training: local_rank"})  # ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒçš„æœ¬åœ°æ’å
    ddp_backend: Optional[str] = field(  # ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒçš„åç«¯
        default=None,  # é»˜è®¤ä¸º None
        metadata={  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
            "help": "The backend to be used for distributed training",  # ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒçš„åç«¯
            "choices": ["nccl", "gloo", "mpi", "ccl", "hccl"],  # å¯é€‰å€¼ä¸º ncclã€glooã€mpiã€cclã€hccl
        },
    )
    tpu_num_cores: Optional[int] = field(  # TPU çš„æ ¸å¿ƒæ•°
        default=None, metadata={"help": "TPU: Number of TPU cores (automatically passed by launcher script)"}  # TPUï¼šTPU æ ¸å¿ƒæ•°ï¼ˆç”±å¯åŠ¨è„šæœ¬è‡ªåŠ¨ä¼ é€’ï¼‰
    )
    tpu_metrics_debug: bool = field(  # TPUï¼šæ˜¯å¦æ‰“å°è°ƒè¯•æŒ‡æ ‡
        default=False,  # é»˜è®¤ä¸º False
        metadata={  # å…ƒæ•°æ®ï¼Œæä¾›å¸®åŠ©ä¿¡æ¯
            "help": (
                "Deprecated, the use of `--debug tpu_metrics_debug` is preferred. TPU: Whether to print debug metrics"  # ä¸æ¨èä½¿ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨ `--debug tpu_metrics_debug`ã€‚TPUï¼šæ˜¯å¦æ‰“å°è°ƒè¯•æŒ‡æ ‡
            )
        },
    )
    debug: Union[str, List[DebugOption]] = field(
        default="",
        metadata={
            "help": (
                "Whether or not to enable debug mode. Current options: "
                "`underflow_overflow` (Detect underflow and overflow in activations and weights), "
                "`tpu_metrics_debug` (print debug metrics on TPU)."
            )
        },
    )
    # è°ƒè¯•æ¨¡å¼é€‰é¡¹ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–DebugOptionåˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
    # å¯é€‰é¡¹åŒ…æ‹¬ï¼š`underflow_overflow`ï¼ˆæ£€æµ‹æ¿€æ´»å’Œæƒé‡ä¸­çš„ä¸‹æº¢å’Œä¸Šæº¢ï¼‰ï¼Œ
    # `tpu_metrics_debug`ï¼ˆåœ¨TPUä¸Šæ‰“å°è°ƒè¯•æŒ‡æ ‡ï¼‰

    dataloader_drop_last: bool = field(
        default=False, metadata={"help": "Drop the last incomplete batch if it is not divisible by the batch size."}
    )
    # æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡ï¼Œå¦‚æœä¸æ˜¯æ‰¹æ¬¡å¤§å°çš„æ•´æ•°å€ï¼Œåˆ™ä¸¢å¼ƒ

    eval_steps: Optional[float] = field(
        default=None,
        metadata={
            "help": (
                "Run an evaluation every X steps. Should be an integer or a float in range `[0,1)`. "
                "If smaller than 1, will be interpreted as ratio of total training steps."
            )
        },
    )
    # æ¯éš”Xæ­¥è¿è¡Œä¸€æ¬¡è¯„ä¼°ï¼Œåº”ä¸ºèŒƒå›´`[0,1)`å†…çš„æ•´æ•°æˆ–æµ®ç‚¹æ•°
    # å¦‚æœå°äº1ï¼Œåˆ™å°†è§£é‡Šä¸ºæ€»è®­ç»ƒæ­¥æ•°çš„æ¯”ç‡

    dataloader_num_workers: int = field(
        default=0,
        metadata={
            "help": (
                "Number of subprocesses to use for data loading (PyTorch only). 0 means that the data will be loaded"
                " in the main process."
            )
        },
    )
    # ç”¨äºæ•°æ®åŠ è½½çš„å­è¿›ç¨‹æ•°ï¼ˆä»…é€‚ç”¨äºPyTorchï¼‰ã€‚0è¡¨ç¤ºæ•°æ®å°†åœ¨ä¸»è¿›ç¨‹ä¸­åŠ è½½

    past_index: int = field(
        default=-1,
        metadata={"help": "If >=0, uses the corresponding part of the output as the past state for next step."},
    )
    # å¦‚æœ>=0ï¼Œåˆ™ä½¿ç”¨è¾“å‡ºçš„ç›¸åº”éƒ¨åˆ†ä½œä¸ºä¸‹ä¸€æ­¥çš„è¿‡å»çŠ¶æ€

    run_name: Optional[str] = field(
        default=None, metadata={"help": "An optional descriptor for the run. Notably used for wandb logging."}
    )
    # è¿è¡Œçš„å¯é€‰æè¿°ç¬¦ã€‚ä¸»è¦ç”¨äºwandbæ—¥å¿—è®°å½•

    disable_tqdm: Optional[bool] = field(
        default=None, metadata={"help": "Whether or not to disable the tqdm progress bars."}
    )
    # æ˜¯å¦ç¦ç”¨tqdmè¿›åº¦æ¡

    remove_unused_columns: Optional[bool] = field(
        default=True, metadata={"help": "Remove columns not required by the model when using an nlp.Dataset."}
    )
    # åœ¨ä½¿ç”¨nlp.Datasetæ—¶ï¼Œæ˜¯å¦åˆ é™¤æ¨¡å‹ä¸éœ€è¦çš„åˆ—

    label_names: Optional[List[str]] = field(
        default=None, metadata={"help": "The list of keys in your dictionary of inputs that correspond to the labels."}
    )
    # è¾“å…¥å­—å…¸ä¸­å¯¹åº”æ ‡ç­¾çš„é”®åˆ—è¡¨

    load_best_model_at_end: Optional[bool] = field(
        default=False,
        metadata={
            "help": (
                "Whether or not to load the best model found during training at the end of training. When this option"
                " is enabled, the best checkpoint will always be saved. See `save_total_limit` for more."
            )
        },
    )
    # æ˜¯å¦åœ¨è®­ç»ƒç»“æŸæ—¶åŠ è½½æ‰¾åˆ°çš„æœ€ä½³æ¨¡å‹
    # å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œå°†å§‹ç»ˆä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹

    metric_for_best_model: Optional[str] = field(
        default=None, metadata={"help": "The metric to use to compare two different models."}
    )
    # ç”¨äºæ¯”è¾ƒä¸¤ä¸ªä¸åŒæ¨¡å‹çš„æŒ‡æ ‡

    greater_is_better: Optional[bool] = field(
        default=None, metadata={"help": "Whether the `metric_for_best_model` should be maximized or not."}
    )
    # `metric_for_best_model`æ˜¯å¦åº”è¯¥æœ€å¤§åŒ–

    ignore_data_skip: bool = field(
        default=False,
        metadata={
            "help": (
                "When resuming training, whether or not to skip the first epochs and batches to get to the same"
                " training data."
            )
        },
    )
    # æ¢å¤è®­ç»ƒæ—¶ï¼Œæ˜¯å¦è·³è¿‡ç¬¬ä¸€ä¸ªå‘¨æœŸå’Œæ‰¹æ¬¡ä»¥è·å–ç›¸åŒçš„è®­ç»ƒæ•°æ®
    # å®šä¹‰ä¸€ä¸ªå¯é€‰çš„å­—æ®µ fsdpï¼Œç±»å‹ä¸º Optional[Union[List[FSDPOption], str]]ï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
    fsdp: Optional[Union[List[FSDPOption], str]] = field(
        default="",
        metadata={
            "help": (
                "æ˜¯å¦ä½¿ç”¨ PyTorch Fully Sharded Data Parallel (FSDP) è®­ç»ƒï¼ˆä»…åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ä½¿ç”¨ï¼‰ã€‚"
                "åŸºæœ¬é€‰é¡¹åº”ä¸º `full_shard`ã€`shard_grad_op` æˆ– `no_shard`ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼æ·»åŠ  CPU-offload åˆ° `full_shard` æˆ– `shard_grad_op`ï¼š"
                " `full_shard offload` æˆ– `shard_grad_op offload`ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ç›¸åŒè¯­æ³•ä¸º `full_shard` æˆ– `shard_grad_op` æ·»åŠ è‡ªåŠ¨åŒ…è£…ï¼š"
                " `full_shard auto_wrap` æˆ– `shard_grad_op auto_wrap`ã€‚"
            ),
        },
    )
    
    # å®šä¹‰ä¸€ä¸ªæ•´æ•°å­—æ®µ fsdp_min_num_paramsï¼Œé»˜è®¤å€¼ä¸º 0ï¼Œç”¨äº FSDP çš„é»˜è®¤è‡ªåŠ¨åŒ…è£…çš„æœ€å°å‚æ•°æ•°é‡ï¼ˆä»…å½“ä¼ é€’äº† `fsdp` å­—æ®µæ—¶æœ‰æ•ˆï¼‰
    fsdp_min_num_params: int = field(
        default=0,
        metadata={
            "help": (
                "æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚FSDP çš„é»˜è®¤è‡ªåŠ¨åŒ…è£…çš„æœ€å°å‚æ•°æ•°é‡ï¼ˆä»…å½“ä¼ é€’äº† `fsdp` å­—æ®µæ—¶æœ‰æ•ˆï¼‰ã€‚"
            )
        },
    )
    
    # å®šä¹‰ä¸€ä¸ªå¯é€‰çš„å­—ç¬¦ä¸²å­—æ®µ fsdp_configï¼Œé»˜è®¤å€¼ä¸º Noneï¼Œç”¨äºæŒ‡å®š FSDP çš„é…ç½®æ–‡ä»¶
    fsdp_config: Optional[str] = field(
        default=None,
        metadata={
            "help": (
                "ç”¨äº FSDPï¼ˆPyTorch Fully Sharded Data Parallelï¼‰çš„é…ç½®ã€‚å€¼å¯ä»¥æ˜¯ä¸€ä¸ª fsdp json é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ `fsdp_config.json`ï¼‰"
                " æˆ–å·²åŠ è½½çš„ json æ–‡ä»¶ä½œä¸º `dict`ã€‚"
            )
        },
    )
    
    # å®šä¹‰ä¸€ä¸ªå¯é€‰çš„å­—ç¬¦ä¸²å­—æ®µ fsdp_transformer_layer_cls_to_wrapï¼Œé»˜è®¤å€¼ä¸º Noneï¼Œç”¨äºæŒ‡å®šè¦åŒ…è£…çš„ Transformer å±‚ç±»åï¼ˆå¤§å°å†™æ•æ„Ÿï¼‰
    fsdp_transformer_layer_cls_to_wrap: Optional[str] = field(
        default=None,
        metadata={
            "help": (
                "æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚è¦åŒ…è£…çš„ Transformer å±‚ç±»åï¼ˆå¤§å°å†™æ•æ„Ÿï¼‰ï¼Œä¾‹å¦‚ `BertLayer`ã€`GPTJBlock`ã€`T5Block` ......ï¼ˆä»…å½“ä¼ é€’äº† `fsdp` æ ‡å¿—æ—¶æœ‰æ•ˆï¼‰ã€‚"
            )
        },
    )
    
    # å®šä¹‰ä¸€ä¸ªå¯é€‰çš„å­—ç¬¦ä¸²å­—æ®µ deepspeedï¼Œé»˜è®¤å€¼ä¸º Noneï¼Œç”¨äºå¯ç”¨ deepspeed å¹¶ä¼ é€’ deepspeed json é…ç½®æ–‡ä»¶çš„è·¯å¾„
    deepspeed: Optional[str] = field(
        default=None,
        metadata={
            "help": (
                "å¯ç”¨ deepspeed å¹¶ä¼ é€’ deepspeed json é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼ˆä¾‹å¦‚ `ds_config.json`ï¼‰"
                " æˆ–å·²åŠ è½½çš„ json æ–‡ä»¶ä½œä¸º dict"
            )
        },
    )
    
    # å®šä¹‰ä¸€ä¸ªæµ®ç‚¹æ•°å­—æ®µ label_smoothing_factorï¼Œé»˜è®¤å€¼ä¸º 0.0ï¼Œç”¨äºåº”ç”¨æ ‡ç­¾å¹³æ»‘åº¦ï¼ˆé›¶è¡¨ç¤ºä¸è¿›è¡Œæ ‡ç­¾å¹³æ»‘ï¼‰
    label_smoothing_factor: float = field(
        default=0.0, metadata={"help": "åº”ç”¨çš„æ ‡ç­¾å¹³æ»‘åº¦ï¼ˆé›¶è¡¨ç¤ºä¸è¿›è¡Œæ ‡ç­¾å¹³æ»‘ï¼‰ã€‚"}
    )
    
    # é»˜è®¤ä¼˜åŒ–å™¨ä¸º "adamw_torch"
    default_optim = "adamw_torch"
    
    # XXX: å½“ pytorch==2.0.1 å‘å¸ƒæ—¶å¯ç”¨ - æˆ‘ä»¬å¸Œæœ›ç»™å®ƒè¶³å¤Ÿçš„æ—¶é—´æ¥è§£å†³æ‰€æœ‰çš„ bug
    # if is_torch_available() and version.parse(version.parse(torch.__version__).base_version) >= version.parse("2.1.0"):
    #     default_optim = "adamw_torch_fused"
    # å¹¶æ›´æ–°ä¸Šé¢çš„æ–‡æ¡£ä¸º:
    # optim (`str` or [`training_args.OptimizerNames`], *optional*, é»˜è®¤ä¸º `"adamw_torch_fused"`ï¼ˆå¯¹äº torch<2.1.0 ä¸º `"adamw_torch"`ï¼‰:
    # å®šä¹‰ä¸€ä¸ªè”åˆç±»å‹å­—æ®µ optimï¼Œç±»å‹ä¸º Union[OptimizerNames, str]ï¼Œé»˜è®¤ä¸º default_optimï¼Œç”¨äºæŒ‡å®šè¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨
    optim: Union[OptimizerNames, str] = field(
        default=default_optim,
        metadata={"help": "è¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨ã€‚"},
    )
    # å®šä¹‰ä¸€ä¸ªå¯é€‰çš„å­—ç¬¦ä¸²å‚æ•°ï¼Œç”¨äºä¼ é€’ç»™ä¼˜åŒ–å™¨çš„å¯é€‰å‚æ•°
    optim_args: Optional[str] = field(default=None, metadata={"help": "Optional arguments to supply to optimizer."})
    # æ˜¯å¦ä½¿ç”¨ Adafactor æ›¿ä»£ AdamW
    adafactor: bool = field(default=False, metadata={"help": "Whether or not to replace AdamW by Adafactor."})
    # æ˜¯å¦åœ¨æ‰¹å¤„ç†æ—¶å°†å¤§è‡´ç›¸åŒé•¿åº¦çš„æ ·æœ¬åˆ†ç»„åœ¨ä¸€èµ·
    group_by_length: bool = field(
        default=False,
        metadata={"help": "Whether or not to group samples of roughly the same length together when batching."},
    )
    # ç”¨äºåˆ†ç»„é•¿åº¦çš„é¢„å…ˆè®¡ç®—é•¿åº¦çš„åˆ—å
    length_column_name: Optional[str] = field(
        default="length",
        metadata={"help": "Column name with precomputed lengths to use when grouping by length."},
    )
    # æŠ¥å‘Šç»“æœå’Œæ—¥å¿—çš„é›†æˆåˆ—è¡¨
    report_to: Optional[List[str]] = field(
        default=None, metadata={"help": "The list of integrations to report the results and logs to."}
    )
    # åœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä¼ é€’ç»™ DistributedDataParallel çš„ find_unused_parameters æ ‡å¿—çš„å€¼
    ddp_find_unused_parameters: Optional[bool] = field(
        default=None,
        metadata={
            "help": (
                "When using distributed training, the value of the flag `find_unused_parameters` passed to "
                "`DistributedDataParallel`."
            )
        },
    )
    # åœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä¼ é€’ç»™ DistributedDataParallel çš„ bucket_cap_mb æ ‡å¿—çš„å€¼
    ddp_bucket_cap_mb: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "When using distributed training, the value of the flag `bucket_cap_mb` passed to "
                "`DistributedDataParallel`."
            )
        },
    )
    # åœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œä¼ é€’ç»™ DistributedDataParallel çš„ broadcast_buffers æ ‡å¿—çš„å€¼
    ddp_broadcast_buffers: Optional[bool] = field(
        default=None,
        metadata={
            "help": (
                "When using distributed training, the value of the flag `broadcast_buffers` passed to "
                "`DistributedDataParallel`."
            )
        },
    )
    # æ˜¯å¦ä¸º DataLoader å›ºå®šå†…å­˜
    dataloader_pin_memory: bool = field(
        default=True, metadata={"help": "Whether or not to pin memory for DataLoader."}
    )
    # æ˜¯å¦ä¿æŒ DataLoader çš„ worker è¿›ç¨‹æŒä¹…åŒ–
    dataloader_persistent_workers: bool = field(
        default=False,
        metadata={
            "help": "If True, the data loader will not shut down the worker processes after a dataset has been consumed once. This allows to maintain the workers Dataset instances alive. Can potentially speed up training, but will increase RAM usage."
        },
    )
    # æ˜¯å¦è·³è¿‡å°†å†…å­˜åˆ†ææŠ¥å‘Šæ·»åŠ åˆ°æŒ‡æ ‡ä¸­
    skip_memory_metrics: bool = field(
        default=True, metadata={"help": "Whether or not to skip adding of memory profiler reports to metrics."}
    )
    # æ˜¯å¦ä½¿ç”¨ä¼ ç»Ÿçš„ prediction_loop
    use_legacy_prediction_loop: bool = field(
        default=False, metadata={"help": "Whether or not to use the legacy prediction_loop in the Trainer."}
    )
    # æ˜¯å¦åœ¨è®­ç»ƒåå°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¸Šä¼ åˆ°æ¨¡å‹ä¸­å¿ƒ
    push_to_hub: bool = field(
        default=False, metadata={"help": "Whether or not to upload the trained model to the model hub after training."}
    )
    # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒçš„è·¯å¾„
    resume_from_checkpoint: Optional[str] = field(
        default=None,
        metadata={"help": "The path to a folder with a valid checkpoint for your model."},
    )
    # ä¸æœ¬åœ° output_dir åŒæ­¥çš„å­˜å‚¨åº“åç§°
    hub_model_id: Optional[str] = field(
        default=None, metadata={"help": "The name of the repository to keep in sync with the local `output_dir`."}
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ hub_strategyï¼Œç±»å‹ä¸º Union[HubStrategy, str]ï¼Œé»˜è®¤ä¸º"every_save"ï¼Œå½“`--push_to_hub`è¢«æ¿€æ´»æ—¶ä½¿ç”¨çš„ Hub ç­–ç•¥
    hub_strategy: Union[HubStrategy, str] = field(
        default="every_save",
        metadata={"help": "The hub strategy to use when `--push_to_hub` is activated."},
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ hub_tokenï¼Œç±»å‹ä¸º Optional[str]ï¼Œé»˜è®¤ä¸º Noneï¼Œç”¨äºæ¨é€åˆ° Model Hub çš„ä»¤ç‰Œ
    hub_token: Optional[str] = field(default=None, metadata={"help": "The token to use to push to the Model Hub."})
    # å®šä¹‰ä¸€ä¸ªå˜é‡ hub_private_repoï¼Œç±»å‹ä¸º boolï¼Œé»˜è®¤ä¸º Falseï¼ŒæŒ‡ç¤ºæ¨¡å‹ä»“åº“æ˜¯å¦ä¸ºç§æœ‰
    hub_private_repo: bool = field(default=False, metadata={"help": "Whether the model repository is private or not."})
    # å®šä¹‰ä¸€ä¸ªå˜é‡ hub_always_pushï¼Œç±»å‹ä¸º boolï¼Œé»˜è®¤ä¸º Falseï¼Œé™¤éä¸º Trueï¼Œå¦åˆ™ Trainer å°†è·³è¿‡æ¨é€ï¼Œå¦‚æœä¸Šä¸€ä¸ªæ¨é€å°šæœªå®Œæˆ
    hub_always_push: bool = field(
        default=False,
        metadata={"help": "Unless `True`, the Trainer will skip pushes if the previous one wasn't finished yet."},
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ gradient_checkpointingï¼Œç±»å‹ä¸º boolï¼Œé»˜è®¤ä¸º Falseï¼Œå¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜ï¼Œä½†ä¼šå‡æ…¢åå‘ä¼ æ’­é€Ÿåº¦
    gradient_checkpointing: bool = field(
        default=False,
        metadata={
            "help": "If True, use gradient checkpointing to save memory at the expense of slower backward pass."
        },
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ gradient_checkpointing_kwargsï¼Œç±»å‹ä¸º Optional[dict]ï¼Œé»˜è®¤ä¸º Noneï¼Œæ¢¯åº¦æ£€æŸ¥ç‚¹å…³é”®å­—å‚æ•°ï¼Œå¦‚`use_reentrant`ï¼Œå°†é€šè¿‡`model.gradient_checkpointing_enable`ä¼ é€’ç»™`torch.utils.checkpoint.checkpoint`
    gradient_checkpointing_kwargs: Optional[dict] = field(
        default=None,
        metadata={
            "help": "Gradient checkpointing key word arguments such as `use_reentrant`. Will be passed to `torch.utils.checkpoint.checkpoint` through `model.gradient_checkpointing_enable`."
        },
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ include_inputs_for_metricsï¼Œç±»å‹ä¸º boolï¼Œé»˜è®¤ä¸º Falseï¼ŒæŒ‡ç¤ºæ˜¯å¦å°†è¾“å…¥ä¼ é€’ç»™`compute_metrics`å‡½æ•°
    include_inputs_for_metrics: bool = field(
        default=False, metadata={"help": "Whether or not the inputs will be passed to the `compute_metrics` function."}
    )
    # Deprecated arguments
    # å®šä¹‰ä¸€ä¸ªå˜é‡ fp16_backendï¼Œç±»å‹ä¸º strï¼Œé»˜è®¤ä¸º"auto"ï¼Œå·²å¼ƒç”¨ï¼Œä½¿ç”¨ half_precision_backend æ›¿ä»£
    fp16_backend: str = field(
        default="auto",
        metadata={
            "help": "Deprecated. Use half_precision_backend instead",
            "choices": ["auto", "apex", "cpu_amp"],
        },
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ push_to_hub_model_idï¼Œç±»å‹ä¸º Optional[str]ï¼Œé»˜è®¤ä¸º Noneï¼Œè¦æ¨é€åˆ°çš„`Trainer`çš„ä»“åº“åç§°
    push_to_hub_model_id: Optional[str] = field(
        default=None, metadata={"help": "The name of the repository to which push the `Trainer`."}
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ push_to_hub_organizationï¼Œç±»å‹ä¸º Optional[str]ï¼Œé»˜è®¤ä¸º Noneï¼Œè¦æ¨é€åˆ°çš„ç»„ç»‡åç§°
    push_to_hub_organization: Optional[str] = field(
        default=None, metadata={"help": "The name of the organization in with to which push the `Trainer`."}
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ push_to_hub_tokenï¼Œç±»å‹ä¸º Optional[str]ï¼Œé»˜è®¤ä¸º Noneï¼Œç”¨äºæ¨é€åˆ° Model Hub çš„ä»¤ç‰Œ
    push_to_hub_token: Optional[str] = field(
        default=None, metadata={"help": "The token to use to push to the Model Hub."}
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ _n_gpuï¼Œç±»å‹ä¸º intï¼Œåˆå§‹åŒ–ä¸º -1ï¼Œä¸å¯è¡¨ç¤ºï¼Œç”¨äºè¡¨ç¤º GPU æ•°é‡
    _n_gpu: int = field(init=False, repr=False, default=-1)
    # å®šä¹‰ä¸€ä¸ªå˜é‡ mp_parametersï¼Œç±»å‹ä¸º strï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œç”± SageMaker å¯åŠ¨å™¨ä½¿ç”¨ä»¥å‘é€ mp-specific å‚æ•°ï¼Œåœ¨ Trainer ä¸­è¢«å¿½ç•¥
    mp_parameters: str = field(
        default="",
        metadata={"help": "Used by the SageMaker launcher to send mp-specific args. Ignored in Trainer"},
    )

    # å®šä¹‰ä¸€ä¸ªå˜é‡ auto_find_batch_sizeï¼Œç±»å‹ä¸º boolï¼Œé»˜è®¤ä¸º Falseï¼Œæ˜¯å¦è‡ªåŠ¨å‡å°‘æ‰¹é‡å¤§å°å¹¶é‡æ–°è¿è¡Œè®­ç»ƒå¾ªç¯ï¼Œæ¯æ¬¡è¾¾åˆ° CUDA å†…å­˜ä¸è¶³æ—¶
    auto_find_batch_size: bool = field(
        default=False,
        metadata={
            "help": (
                "Whether to automatically decrease the batch size in half and rerun the training loop again each time"
                " a CUDA Out-of-Memory was reached"
            )
        },
    )
    # å®šä¹‰ä¸€ä¸ªå˜é‡ full_determinismï¼Œç±»å‹ä¸º boolï¼Œé»˜è®¤ä¸º Falseï¼Œæ˜¯å¦è°ƒç”¨ enable_full_determinism è€Œä¸æ˜¯ set_seed ä»¥å®ç°åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„å¯é‡ç°æ€§ï¼Œé‡è¦ï¼šè¿™ä¼šå¯¹æ€§èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ï¼Œä»…ç”¨äºè°ƒè¯•
    full_determinism: bool = field(
        default=False,
        metadata={
            "help": (
                "Whether to call enable_full_determinism instead of set_seed for reproducibility in distributed"
                " training. Important: this will negatively impact the performance, so only use it for debugging."
            )
        },
    )
    torchdynamo: Optional[str] = field(
        default=None,
        metadata={
            "help": "This argument is deprecated, use `--torch_compile_backend` instead.",
        },
    )

# `torchdynamo`æ˜¯ä¸€ä¸ªå¯é€‰çš„å­—ç¬¦ä¸²ç±»å‹å­—æ®µï¼Œç”¨äºè®¾ç½®Torch Dynamoçš„å‚æ•°ã€‚é»˜è®¤å€¼ä¸ºNoneã€‚
# å…ƒæ•°æ®(metadata)æä¾›äº†å¸®åŠ©ä¿¡æ¯ï¼ŒæŒ‡å‡ºè¯¥å‚æ•°å·²å¼ƒç”¨ï¼Œåº”ä½¿ç”¨`--torch_compile_backend`ä»£æ›¿ã€‚

    ray_scope: Optional[str] = field(
        default="last",
        metadata={
            "help": (
                'The scope to use when doing hyperparameter search with Ray. By default, `"last"` will be used. Ray'
                " will then use the last checkpoint of all trials, compare those, and select the best one. However,"
                " other options are also available. See the Ray documentation"
                " (https://docs.ray.io/en/latest/tune/api_docs/analysis.html"
                "#ray.tune.ExperimentAnalysis.get_best_trial)"
                " for more options."
            )
        },
    )

# `ray_scope`æ˜¯ä¸€ä¸ªå¯é€‰çš„å­—ç¬¦ä¸²ç±»å‹å­—æ®µï¼Œç”¨äºè®¾ç½®Rayçš„è¶…å‚æ•°æœç´¢èŒƒå›´ã€‚
# é»˜è®¤å€¼ä¸º"last"ï¼Œè¡¨ç¤ºä½¿ç”¨æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹è¿›è¡Œè¶…å‚æ•°æœç´¢ã€‚
# å…ƒæ•°æ®(metadata)æä¾›äº†å¸®åŠ©ä¿¡æ¯ï¼Œè¯´æ˜äº†ä¸åŒé€‰é¡¹çš„å«ä¹‰ï¼Œå¹¶æä¾›äº†é“¾æ¥åˆ°Rayæ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯ã€‚

    ddp_timeout: Optional[int] = field(
        default=1800,
        metadata={
            "help": "Overrides the default timeout for distributed training (value should be given in seconds)."
        },
    )

# `ddp_timeout`æ˜¯ä¸€ä¸ªå¯é€‰çš„æ•´æ•°ç±»å‹å­—æ®µï¼Œç”¨äºè®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒçš„è¶…æ—¶æ—¶é—´ã€‚
# é»˜è®¤å€¼ä¸º1800ç§’ã€‚
# å…ƒæ•°æ®(metadata)æä¾›äº†å¸®åŠ©ä¿¡æ¯ï¼ŒæŒ‡å‡ºäº†è¶…æ—¶æ—¶é—´çš„å•ä½ä¸ºç§’ã€‚

    torch_compile: bool = field(
        default=False, metadata={"help": "If set to `True`, the model will be wrapped in `torch.compile`."}
    )

# `torch_compile`æ˜¯ä¸€ä¸ªå¸ƒå°”ç±»å‹å­—æ®µï¼Œç”¨äºè®¾ç½®æ˜¯å¦ä½¿ç”¨`torch.compile`å¯¹æ¨¡å‹è¿›è¡Œå°è£…ã€‚
# é»˜è®¤å€¼ä¸ºFalseã€‚
# å…ƒæ•°æ®(metadata)æä¾›äº†å¸®åŠ©ä¿¡æ¯ï¼Œè¯´æ˜äº†å½“è®¾ç½®ä¸º`True`æ—¶çš„è¡Œä¸ºã€‚

    torch_compile_backend: Optional[str] = field(
        default=None,
        metadata={
            "help": "Which backend to use with `torch.compile`, passing one will trigger a model compilation.",
        },
    )

# `torch_compile_backend`æ˜¯ä¸€ä¸ªå¯é€‰çš„å­—ç¬¦ä¸²ç±»å‹å­—æ®µï¼Œç”¨äºè®¾ç½®`torch.compile`ä½¿ç”¨çš„åç«¯ã€‚
# é»˜è®¤å€¼ä¸ºNoneã€‚
# å…ƒæ•°æ®(metadata)æä¾›äº†å¸®åŠ©ä¿¡æ¯ï¼Œè¯´æ˜äº†å¦‚ä½•è§¦å‘æ¨¡å‹ç¼–è¯‘ä»¥åŠå¯èƒ½çš„åç«¯é€‰é¡¹ã€‚

    torch_compile_mode: Optional[str] = field(
        default=None,
        metadata={
            "help": "Which mode to use with `torch.compile`, passing one will trigger a model compilation.",
        },
    )

# `torch_compile_mode`æ˜¯ä¸€ä¸ªå¯é€‰çš„å­—ç¬¦ä¸²ç±»å‹å­—æ®µï¼Œç”¨äºè®¾ç½®`torch.compile`çš„æ¨¡å¼ã€‚
# é»˜è®¤å€¼ä¸ºNoneã€‚
# å…ƒæ•°æ®(metadata)æä¾›äº†å¸®åŠ©ä¿¡æ¯ï¼Œè¯´æ˜äº†å¦‚ä½•è§¦å‘æ¨¡å‹ç¼–è¯‘ä»¥åŠå¯èƒ½çš„æ¨¡å¼é€‰é¡¹ã€‚

    dispatch_batches: Optional[bool] = field(
        default=None,
        metadata={
            "help": "Whether to dispatch batches across devices in distributed training. If set to `True`, the dataloader prepared by the Accelerator is only iterated through on the main process "
            "and then the batches are split and broadcast to each process. Will default to `True` for `DataLoader` whose"
            "underlying dataset is an `IterableDataset`, `False` otherwise."
        },
    )

# `dispatch_batches`æ˜¯ä¸€ä¸ªå¯é€‰çš„å¸ƒå°”ç±»å‹å­—æ®µï¼Œç”¨äºè®¾ç½®åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­æ˜¯å¦è·¨è®¾å¤‡åˆ†å‘æ‰¹æ¬¡ã€‚
# å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™ç”±åŠ é€Ÿå™¨å‡†å¤‡çš„æ•°æ®åŠ è½½å™¨åªåœ¨ä¸»è¿›ç¨‹ä¸Šè¿›è¡Œè¿­ä»£ï¼Œ
# ç„¶åå°†æ‰¹æ¬¡æ‹†åˆ†å¹¶å¹¿æ’­åˆ°æ¯ä¸ªè¿›ç¨‹ã€‚
# å¯¹äºåº•å±‚æ•°æ®é›†ä¸º`IterableDataset`çš„`DataLoader`ï¼Œé»˜è®¤å€¼ä¸º`True`ï¼Œå¦åˆ™ä¸º`False`ã€‚
# å…ƒæ•°æ®(metadata)æä¾›äº†å¸®åŠ©ä¿¡æ¯ï¼Œè¯´æ˜äº†è¯¥é€‰é¡¹çš„å«ä¹‰ã€‚

    split_batches: Optional[bool] = field(
        default=False,
        metadata={
            "help": "Whether or not the accelerator should split the batches yielded by the dataloaders across the devices during distributed training. If"
            "set to `True`, the actual batch size used will be the same on any kind of distributed processes, but it must be a"
            "round multiple of the number of processes you are using (such as GPUs)."
        },
    )

# `split_batches`æ˜¯ä¸€ä¸ªå¯é€‰çš„å¸ƒå°”ç±»å‹å­—æ®µï¼Œç”¨äºè®¾ç½®åŠ é€Ÿå™¨åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´æ˜¯å¦åº”è¯¥è·¨è®¾å¤‡æ‹†åˆ†æ•°æ®åŠ è½½å™¨äº§ç”Ÿçš„æ‰¹æ¬¡ã€‚
# å¦‚æœè®¾ç½®ä¸º`True`ï¼Œåˆ™åœ¨ä»»ä½•ç±»å‹çš„åˆ†å¸ƒå¼è¿›ç¨‹ä¸Šä½¿ç”¨çš„å®é™…æ‰¹æ¬¡å¤§å°å°†ç›¸åŒï¼Œ
# ä½†å®ƒå¿…é¡»æ˜¯æ‚¨ä½¿ç”¨çš„è¿›ç¨‹æ•°é‡çš„åœ†æ•´å€æ•°ï¼ˆä¾‹å¦‚GPUæ•°é‡ï¼‰ã€‚
# å…ƒæ•°æ®(metadata)æä¾›äº†å¸®åŠ©ä¿¡æ¯ï¼Œè¯´æ˜äº†è¯¥é€‰é¡¹çš„å«ä¹‰ã€‚

    include_tokens_per_second: Optional[bool] = field(
        default=False,
        metadata={"help": "If set to `True`, the speed metrics will include `tgs` (tokens per second per device)."},
    )

# `include_tokens_per_second`æ˜¯ä¸€ä¸ªå¯é€‰çš„å¸ƒå°”ç±»å‹å­—æ®µï¼Œç”¨äºè®¾ç½®æ˜¯å¦åœ¨é€Ÿåº¦æŒ‡æ ‡ä¸­åŒ…å«`tgs`ï¼ˆæ¯ä¸ªè®¾å¤‡çš„æ¯ç§’æ ‡è®°æ•°ï¼‰ã€‚
# é»˜è®¤å€¼ä¸ºFalseã€‚
# å…ƒæ•°æ®(metadata)æä¾›äº†å¸®åŠ©ä¿¡æ¯ï¼Œè¯´æ˜äº†è¯¥é€‰é¡¹çš„å«ä¹‰ã€‚
    # å®šä¹‰ä¸€ä¸ªå¯é€‰çš„å¸ƒå°”ç±»å‹å˜é‡ï¼Œç”¨äºæŒ‡ç¤ºæ˜¯å¦åŒ…å«è§‚å¯Ÿåˆ°çš„è¾“å…¥æ ‡è®°æ•°ã€‚é»˜è®¤ä¸º Falseã€‚
    include_num_input_tokens_seen: Optional[bool] = field(
        default=False,
        metadata={
            "help": "If set to `True`, will track the number of input tokens seen throughout training. (May be slower in distributed training)"
        },
    )

    # å®šä¹‰ä¸€ä¸ªæµ®ç‚¹å‹å˜é‡ï¼Œç”¨äºæ¿€æ´» NEFTune å™ªå£°åµŒå…¥åˆ°æ¨¡å‹ä¸­ã€‚NEFTune å·²è¢«è¯æ˜å¯ä»¥æ˜¾è‘—æé«˜æŒ‡ä»¤å¾®è°ƒçš„æ¨¡å‹æ€§èƒ½ã€‚
    # åªæ”¯æŒ `PreTrainedModel` å’Œ `PeftModel` ç±»ã€‚
    # è¯·å‚é˜…åŸå§‹è®ºæ–‡ï¼šhttps://arxiv.org/abs/2310.05914ï¼ŒåŸå§‹ä»£ç ï¼šhttps://github.com/neelsjain/NEFTuneã€‚
    neftune_noise_alpha: float = field(
        default=None,
        metadata={
            "help": "Activates neftune noise embeddings into the model. NEFTune has been proven to drastically improve model performances for instrcution fine-tuning. Check out the original paper here: https://arxiv.org/abs/2310.05914 and the original code here: https://github.com/neelsjain/NEFTune. Only supported for `PreTrainedModel` and `PeftModel` classes."
        },
    )

    # å®šä¹‰ __str__ æ–¹æ³•ï¼Œè¿”å›è¯¥å¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤ºå½¢å¼
    def __str__(self):
        # å°†å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸å½¢å¼
        self_as_dict = asdict(self)

        # ç§»é™¤ä¸æ¨èä½¿ç”¨çš„å‚æ•°ã€‚ä¸€æ—¦è¿™äº›ä¸æ¨èä½¿ç”¨çš„å‚æ•°ä» TrainingArguments ä¸­ç§»é™¤ï¼Œè¿™æ®µä»£ç å°±åº”è¯¥è¢«ç§»é™¤ã€‚ï¼ˆTODO: v5ï¼‰
        del self_as_dict["per_gpu_train_batch_size"]
        del self_as_dict["per_gpu_eval_batch_size"]

        # å°†æ‰€æœ‰ token ç»“å°¾çš„é”®çš„å€¼æ”¹ä¸ºå¤§å†™å½¢å¼
        self_as_dict = {k: f"<{k.upper()}>" if k.endswith("_token") else v for k, v in self_as_dict.items()}

        # å°†å­—å…¸é”®å€¼å¯¹è½¬æ¢ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨
        attrs_as_str = [f"{k}={v},\n" for k, v in sorted(self_as_dict.items())]
        # è¿”å›ç±»åå’Œå±æ€§çš„å­—ç¬¦ä¸²è¡¨ç¤ºå½¢å¼
        return f"{self.__class__.__name__}(\n{''.join(attrs_as_str)})"

    # å°† __repr__ æ–¹æ³•æŒ‡å‘ __str__ æ–¹æ³•
    __repr__ = __str__

    # å®šä¹‰ train_batch_size å±æ€§ï¼Œè¿”å›å®é™…çš„è®­ç»ƒæ‰¹é‡å¤§å°ï¼ˆåœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­å¯èƒ½ä¸ per_gpu_train_batch_size ä¸åŒï¼‰
    @property
    def train_batch_size(self) -> int:
        """
        The actual batch size for training (may differ from `per_gpu_train_batch_size` in distributed training).
        """
        if self.per_gpu_train_batch_size:
            logger.warning(
                "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future "
                "version. Using `--per_device_train_batch_size` is preferred."
            )
        # è·å–æ¯ä¸ªè®¾å¤‡çš„æ‰¹é‡å¤§å°
        per_device_batch_size = self.per_gpu_train_batch_size or self.per_device_train_batch_size
        # è®¡ç®—å®é™…çš„è®­ç»ƒæ‰¹é‡å¤§å°
        train_batch_size = per_device_batch_size * max(1, self.n_gpu)
        return train_batch_size

    # å®šä¹‰ eval_batch_size å±æ€§ï¼Œè¿”å›å®é™…çš„è¯„ä¼°æ‰¹é‡å¤§å°ï¼ˆåœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­å¯èƒ½ä¸ per_gpu_eval_batch_size ä¸åŒï¼‰
    @property
    def eval_batch_size(self) -> int:
        """
        The actual batch size for evaluation (may differ from `per_gpu_eval_batch_size` in distributed training).
        """
        if self.per_gpu_eval_batch_size:
            logger.warning(
                "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future "
                "version. Using `--per_device_eval_batch_size` is preferred."
            )
        # è·å–æ¯ä¸ªè®¾å¤‡çš„æ‰¹é‡å¤§å°
        per_device_batch_size = self.per_gpu_eval_batch_size or self.per_device_eval_batch_size
        # è®¡ç®—å®é™…çš„è¯„ä¼°æ‰¹é‡å¤§å°
        eval_batch_size = per_device_batch_size * max(1, self.n_gpu)
        return eval_batch_size

    # å®šä¹‰ ddp_timeout_delta å±æ€§ï¼Œè¿”å› torch.distributed.init_process_group çš„å®é™…è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºå®ƒæœŸæœ›ä¸€ä¸ª timedelta å˜é‡ã€‚
    @property
    def ddp_timeout_delta(self) -> timedelta:
        """
        The actual timeout for torch.distributed.init_process_group since it expects a timedelta variable.
        """
        return timedelta(seconds=self.ddp_timeout)

    # å®šä¹‰ cached_property å±æ€§
    @cached_property
    @property
    def device(self) -> "torch.device":
        """
        è¿”å›å½“å‰è¿›ç¨‹ä½¿ç”¨çš„è®¾å¤‡ã€‚

        Returns:
            torch.device: å½“å‰è¿›ç¨‹ä½¿ç”¨çš„è®¾å¤‡ã€‚
        """
        # ç¡®ä¿éœ€è¦çš„åç«¯å·²ç»åŠ è½½
        requires_backends(self, ["torch"])
        # è¿”å›è®¾å¤‡è®¾ç½®
        return self._setup_devices

    @property
    def n_gpu(self):
        """
        æœ¬è¿›ç¨‹ä½¿ç”¨çš„ GPU æ•°é‡ã€‚

        æ³¨æ„:
            å½“æœ‰å¤šä¸ª GPU å¯ç”¨ä½†ä¸ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œæ­¤å€¼å°†å¤§äº 1ã€‚
            å¯¹äºåˆ†å¸ƒå¼è®­ç»ƒï¼Œå®ƒå°†å§‹ç»ˆä¸º 1ã€‚
        """
        # ç¡®ä¿éœ€è¦çš„åç«¯å·²ç»åŠ è½½
        requires_backends(self, ["torch"])
        # ç¡®ä¿ `_n_gpu` å±æ€§æ­£ç¡®è®¾ç½®
        if not hasattr(self, "_n_gpu"):
            _ = self._setup_devices
        # è¿”å› GPU æ•°é‡
        return self._n_gpu

    @property
    def parallel_mode(self):
        """
        å¦‚æœæœ‰å¤šä¸ª GPU/TPU æ ¸å¿ƒå¯ç”¨ï¼Œåˆ™è¿”å›å½“å‰ä½¿ç”¨çš„å¹¶è¡Œæ¨¡å¼ä¹‹ä¸€ã€‚

        - `ParallelMode.NOT_PARALLEL`: æ— å¹¶è¡Œï¼ˆCPU æˆ–ä¸€ä¸ª GPUï¼‰ã€‚
        - `ParallelMode.NOT_DISTRIBUTED`: å•ä¸ªè¿›ç¨‹ä¸­æœ‰å¤šä¸ª GPUï¼ˆä½¿ç”¨ `torch.nn.DataParallel`ï¼‰ã€‚
        - `ParallelMode.DISTRIBUTED`: å¤šä¸ª GPUï¼Œæ¯ä¸ª GPU æœ‰è‡ªå·±çš„è¿›ç¨‹ï¼ˆä½¿ç”¨ `torch.nn.DistributedDataParallel`ï¼‰ã€‚
        - `ParallelMode.TPU`: å¤šä¸ª TPU æ ¸å¿ƒã€‚
        """
        # ç¡®ä¿éœ€è¦çš„åç«¯å·²ç»åŠ è½½
        requires_backends(self, ["torch"])
        if is_torch_tpu_available():
            return ParallelMode.TPU
        elif is_sagemaker_mp_enabled():
            return ParallelMode.SAGEMAKER_MODEL_PARALLEL
        elif is_sagemaker_dp_enabled():
            return ParallelMode.SAGEMAKER_DATA_PARALLEL
        elif (
            self.distributed_state is not None and self.distributed_state.distributed_type != DistributedType.NO
        ) or (self.distributed_state is None and self.local_rank != -1):
            return ParallelMode.DISTRIBUTED
        elif self.n_gpu > 1:
            return ParallelMode.NOT_DISTRIBUTED
        else:
            return ParallelMode.NOT_PARALLEL

    @property
    def world_size(self):
        """
        å¹¶è¡Œä½¿ç”¨çš„è¿›ç¨‹æ•°ã€‚
        """
        # ç¡®ä¿éœ€è¦çš„åç«¯å·²ç»åŠ è½½
        requires_backends(self, ["torch"])
        if self.distributed_state is not None:
            return self.distributed_state.num_processes
        elif is_sagemaker_mp_enabled():
            return smp.dp_size() if not smp.state.cfg.prescaled_batch else smp.rdp_size()
        return 1

    @property
    def process_index(self):
        """
        å½“å‰ä½¿ç”¨çš„è¿›ç¨‹ç´¢å¼•ã€‚
        """
        # ç¡®ä¿éœ€è¦çš„åç«¯å·²ç»åŠ è½½
        requires_backends(self, ["torch"])
        if self.distributed_state is not None:
            return self.distributed_state.process_index
        elif is_sagemaker_mp_enabled():
            return smp.dp_rank() if not smp.state.cfg.prescaled_batch else smp.rdp_rank()
        return 0

    @property
    def local_process_index(self):
        """
        The index of the local process used.
        """
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åç«¯æ”¯æŒ
        requires_backends(self, ["torch"])

        # å¦‚æœå­˜åœ¨åˆ†å¸ƒå¼çŠ¶æ€ï¼Œåˆ™è¿”å›æœ¬åœ°è¿›ç¨‹ç´¢å¼•
        if self.distributed_state is not None:
            return self.distributed_state.local_process_index
        # å¦‚æœå¯ç”¨äº† SageMaker å¤šè¿›ç¨‹ï¼Œåˆ™è¿”å›æœ¬åœ°è¿›ç¨‹ç´¢å¼•
        elif is_sagemaker_mp_enabled():
            return smp.local_rank()
        # é»˜è®¤è¿”å›ç´¢å¼• 0
        return 0

    @property
    def should_log(self):
        """
        Whether or not the current process should produce log.
        """
        # å¦‚æœè®¾ç½®äº†åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè®°å½•æ—¥å¿—ï¼Œåˆ™è¿”å›å½“å‰è¿›ç¨‹æ˜¯å¦ä¸ºç´¢å¼• 0
        if self.log_on_each_node:
            return self.local_process_index == 0
        else:
            # å¦‚æœå¯ç”¨äº† SageMaker å¤šè¿›ç¨‹ï¼Œåˆ™è¿”å›å½“å‰è¿›ç¨‹æ˜¯å¦ä¸ºç´¢å¼• 0
            if is_sagemaker_mp_enabled():
                return smp.rank() == 0
            else:
                return self.process_index == 0

    @property
    def should_save(self):
        """
        Whether or not the current process should write to disk, e.g., to save models and checkpoints.
        """
        # å¦‚æœè®¾ç½®äº†åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šä¿å­˜æ¨¡å‹ï¼Œåˆ™è¿”å›å½“å‰è¿›ç¨‹æ˜¯å¦ä¸ºç´¢å¼• 0
        if self.save_on_each_node:
            return self.local_process_index == 0
        else:
            # å¦‚æœå¯ç”¨äº† SageMaker å¤šè¿›ç¨‹ï¼Œåˆ™è¿”å›å½“å‰è¿›ç¨‹æ˜¯å¦ä¸ºç´¢å¼• 0
            if is_sagemaker_mp_enabled():
                return smp.rank() == 0
            else:
                return self.process_index == 0

    def get_process_log_level(self):
        """
        Returns the log level to be used depending on whether this process is the main process of node 0, main process
        of node non-0, or a non-main process.

        For the main process the log level defaults to the logging level set (`logging.WARNING` if you didn't do
        anything) unless overridden by `log_level` argument.

        For the replica processes the log level defaults to `logging.WARNING` unless overridden by `log_level_replica`
        argument.

        The choice between the main and replica process settings is made according to the return value of `should_log`.
        """
        # å°†æ—¥å¿—çº§åˆ«è½¬æ¢ä¸ºæ•´æ•°
        log_level = trainer_log_levels[self.log_level]
        log_level_replica = trainer_log_levels[self.log_level_replica]

        # è·å–ä¸»èŠ‚ç‚¹å’Œå‰¯æœ¬èŠ‚ç‚¹çš„æ—¥å¿—çº§åˆ«
        log_level_main_node = logging.get_verbosity() if log_level == -1 else log_level
        log_level_replica_node = logging.get_verbosity() if log_level_replica == -1 else log_level_replica
        # æ ¹æ®æ˜¯å¦åº”è®°å½•æ—¥å¿—è¿”å›ç›¸åº”çš„æ—¥å¿—çº§åˆ«
        return log_level_main_node if self.should_log else log_level_replica_node

    @property
    def place_model_on_device(self):
        """
        Can be subclassed and overridden for some specific integrations.
        """
        # å¦‚æœæœªå¯ç”¨ SageMaker å¤šè¿›ç¨‹ï¼Œåˆ™è¿”å› True
        return not is_sagemaker_mp_enabled()

    @property
    def _no_sync_in_gradient_accumulation(self):
        """
        Whether or not to use no_sync for the gradients when doing gradient accumulation.
        """
        # å¦‚æœæœªä½¿ç”¨ DeepSpeedã€SageMaker DPã€SageMaker MP æˆ– Torch NeuronCoreï¼Œåˆ™è¿”å› True
        return not (
            self.deepspeed or is_sagemaker_dp_enabled() or is_sagemaker_mp_enabled() or is_torch_neuroncore_available()
        )

    @contextlib.contextmanager
    def main_process_first(self, local=True, desc="work"):
        """
        A context manager for torch distributed environment where one needs to do something on the main process, while
        blocking replicas, and when it's finished releasing the replicas.

        One such use is for `datasets`'s `map` feature which to be efficient should be run once on the main process,
        which upon completion saves a cached version of results and which then automatically gets loaded by the
        replicas.

        Args:
            local (`bool`, *optional*, defaults to `True`):
                if `True` first means process of rank 0 of each node if `False` first means process of rank 0 of node
                rank 0 In multi-node environment with a shared filesystem you most likely will want to use
                `local=False` so that only the main process of the first node will do the processing. If however, the
                filesystem is not shared, then the main process of each node will need to do the processing, which is
                the default behavior.
            desc (`str`, *optional*, defaults to `"work"`):
                a work description to be used in debug logs

        """
        # Check if torch is available and the world size is greater than 1 (i.e., distributed environment)
        if is_torch_available() and self.world_size > 1:
            # Define the description for the main process based on the value of 'local'
            main_process_desc = "main local process" if local else "main process"
            # Check if distributed state is available
            if self.distributed_state is not None:
                # Determine if the current process is the main process based on 'local' value
                is_main_process = (
                    self.distributed_state.is_local_main_process if local else self.distributed_state.is_main_process
                )
            # Check if SageMaker multi-processing is enabled
            elif is_sagemaker_mp_enabled():
                is_main_process = smp.rank() == 0

            try:
                # If the current process is not the main process, wait for the main process to finish its task
                if not is_main_process:
                    # Tell all replicas to wait
                    logger.debug(f"{self.process_index}: waiting for the {main_process_desc} to perform {desc}")

                    # If running on TPU, synchronize all processes
                    if is_torch_tpu_available():
                        xm.rendezvous(desc)
                    else:
                        dist.barrier()
                # Yield control to the block of code where this context manager is used
                yield
            finally:
                # If the current process is the main process, signal that it has completed its task
                if is_main_process:
                    # The wait is over
                    logger.debug(f"{self.process_index}: {main_process_desc} completed {desc}, releasing all replicas")
                    # If running on TPU, synchronize all processes
                    if is_torch_tpu_available():
                        xm.rendezvous(desc)
                    else:
                        dist.barrier()
        else:
            # If torch is not available or world size <= 1, yield control without synchronization
            yield

    def get_warmup_steps(self, num_training_steps: int):
        """
        Get number of steps used for a linear warmup.
        """
        # Calculate the number of warmup steps based on provided warmup steps or warmup ratio
        warmup_steps = (
            self.warmup_steps if self.warmup_steps > 0 else math.ceil(num_training_steps * self.warmup_ratio)
        )
        # Return the calculated warmup steps
        return warmup_steps
    # å°†å®ä¾‹åºåˆ—åŒ–ä¸ºå­—å…¸ï¼Œæ›¿æ¢`Enum`ä¸ºå…¶å€¼ï¼ˆç”¨äº JSON åºåˆ—åŒ–æ”¯æŒï¼‰ï¼Œå¹¶ç§»é™¤ä»¤ç‰Œå€¼ä»¥æ··æ·†
    def to_dict(self):
        # è¿‡æ»¤æ‰å®šä¹‰ä¸º field(init=False) çš„å­—æ®µ
        d = {field.name: getattr(self, field.name) for field in fields(self) if field.init}

        for k, v in d.items():
            # å¦‚æœå€¼æ˜¯ Enum ç±»å‹ï¼Œåˆ™æ›¿æ¢ä¸ºå…¶å€¼
            if isinstance(v, Enum):
                d[k] = v.value
            # å¦‚æœå€¼æ˜¯åˆ—è¡¨ä¸”ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ Enum ç±»å‹ï¼Œåˆ™æ›¿æ¢ä¸ºå…¶å€¼åˆ—è¡¨
            if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):
                d[k] = [x.value for x in v]
            # å¦‚æœé”®ä»¥ "_token" ç»“å°¾ï¼Œåˆ™æ›¿æ¢ä¸ºç‰¹å®šæ ¼å¼çš„å­—ç¬¦ä¸²
            if k.endswith("_token"):
                d[k] = f"<{k.upper()}>"
        return d

    # å°†å®ä¾‹åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²
    def to_json_string(self):
        return json.dumps(self.to_dict(), indent=2)

    # ç”¨äº TensorBoard çš„ hparams çš„åºåˆ—åŒ–ï¼Œè¿”å›ç»è¿‡å¤„ç†çš„å­—å…¸
    def to_sanitized_dict(self) -> Dict[str, Any]:
        d = self.to_dict()
        # æ·»åŠ é¢å¤–çš„å­—æ®µåˆ°å­—å…¸ä¸­
        d = {**d, **{"train_batch_size": self.train_batch_size, "eval_batch_size": self.eval_batch_size}}

        valid_types = [bool, int, float, str]
        # å¦‚æœæœ‰ torch åº“å¯ç”¨ï¼Œåˆ™æ·»åŠ  torch.Tensor ç±»å‹åˆ°æœ‰æ•ˆç±»å‹åˆ—è¡¨ä¸­
        if is_torch_available():
            valid_types.append(torch.Tensor)

        # æ ¹æ®å€¼çš„ç±»å‹è¿›è¡Œå¤„ç†ï¼Œå¦‚æœä¸åœ¨æœ‰æ•ˆç±»å‹åˆ—è¡¨ä¸­ï¼Œåˆ™è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return {k: v if type(v) in valid_types else str(v) for k, v in d.items()}

    # ä¸‹é¢çš„æ–¹æ³•ç”¨äºç®€åŒ– `TrainingArguments` çš„å®ä¾‹åŒ–
    def set_training(
        self,
        learning_rate: float = 5e-5,
        batch_size: int = 8,
        weight_decay: float = 0,
        num_epochs: float = 3,
        max_steps: int = -1,
        gradient_accumulation_steps: int = 1,
        seed: int = 42,
        gradient_checkpointing: bool = False,
        """
        A method that regroups all basic arguments linked to the training.

        <Tip>

        Calling this method will automatically set `self.do_train` to `True`.

        </Tip>

        Args:
            learning_rate (`float`, *optional*, defaults to 5e-5):
                The initial learning rate for the optimizer.
            batch_size (`int` *optional*, defaults to 8):
                The batch size per device (GPU/TPU core/CPU...) used for training.
            weight_decay (`float`, *optional*, defaults to 0):
                The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in the
                optimizer.
            num_train_epochs(`float`, *optional*, defaults to 3.0):
                Total number of training epochs to perform (if not an integer, will perform the decimal part percents
                of the last epoch before stopping training).
            max_steps (`int`, *optional*, defaults to -1):
                If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.
                For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until
                `max_steps` is reached.
            gradient_accumulation_steps (`int`, *optional*, defaults to 1):
                Number of updates steps to accumulate the gradients for, before performing a backward/update pass.

                <Tip warning={true}>

                When using gradient accumulation, one step is counted as one step with backward pass. Therefore,
                logging, evaluation, save will be conducted every `gradient_accumulation_steps * xxx_step` training
                examples.

                </Tip>

            seed (`int`, *optional*, defaults to 42):
                Random seed that will be set at the beginning of training. To ensure reproducibility across runs, use
                the [`~Trainer.model_init`] function to instantiate the model if it has some randomly initialized
                parameters.
            gradient_checkpointing (`bool`, *optional*, defaults to `False`):
                If True, use gradient checkpointing to save memory at the expense of slower backward pass.

        Example:

        ```py
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_training(learning_rate=1e-4, batch_size=32)
        >>> args.learning_rate
        1e-4
        ```
        """
        # è®¾ç½® self.do_train ä¸º True
        self.do_train = True
        # è®¾ç½®å­¦ä¹ ç‡
        self.learning_rate = learning_rate
        # è®¾ç½®æ¯ä¸ªè®¾å¤‡çš„ï¿½ï¿½ï¿½ç»ƒæ‰¹æ¬¡å¤§å°
        self.per_device_train_batch_size = batch_size
        # è®¾ç½®æƒé‡è¡°å‡
        self.weight_decay = weight_decay
        # è®¾ç½®è®­ç»ƒçš„æ€»è½®æ•°
        self.num_train_epochs = num_epochs
        # è®¾ç½®æœ€å¤§è®­ç»ƒæ­¥æ•°
        self.max_steps = max_steps
        # è®¾ç½®æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
        self.gradient_accumulation_steps = gradient_accumulation_steps
        # è®¾ç½®éšæœºç§å­
        self.seed = seed
        # è®¾ç½®æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
        self.gradient_checkpointing = gradient_checkpointing
        # è¿”å› self
        return self
    def set_evaluate(
        self,
        strategy: Union[str, IntervalStrategy] = "no",  # å®šä¹‰è¯„ä¼°ç­–ç•¥ï¼Œé»˜è®¤ä¸º"no"
        steps: int = 500,  # æ¯æ¬¡è¯„ä¼°ä¹‹é—´çš„æ›´æ–°æ­¥æ•°ï¼Œé»˜è®¤ä¸º500æ­¥
        batch_size: int = 8,  # ç”¨äºè¯„ä¼°çš„æ¯ä¸ªè®¾å¤‡ï¼ˆGPU/TPUæ ¸å¿ƒ/CPUç­‰ï¼‰çš„æ‰¹é‡å¤§å°ï¼Œé»˜è®¤ä¸º8
        accumulation_steps: Optional[int] = None,  # åœ¨å°†è¾“å‡ºå¼ é‡ç§»åŠ¨åˆ° CPU ä¹‹å‰ç´¯ç§¯è¾“å‡ºå¼ é‡çš„é¢„æµ‹æ­¥æ•°ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™åœ¨å°†æ•´ä¸ªé¢„æµ‹ç´¯ç§¯åœ¨ GPU/TPU ä¸Šä¹‹åå°†å…¶ç§»åŠ¨åˆ° CPUï¼ˆé€Ÿåº¦æ›´å¿«ä½†éœ€è¦æ›´å¤šå†…å­˜ï¼‰ã€‚
        delay: Optional[float] = None,  # åœ¨ç¬¬ä¸€æ¬¡è¯„ä¼°ä¹‹å‰éœ€è¦ç­‰å¾…çš„å‘¨æœŸæˆ–æ­¥æ•°ï¼Œå–å†³äºè¯„ä¼°ç­–ç•¥ã€‚
        loss_only: bool = False,  # ä»…è€ƒè™‘æŸå¤±ï¼Œå¿½ç•¥é™¤æŸå¤±ä¹‹å¤–çš„æ‰€æœ‰è¾“å‡ºã€‚
        jit_mode: bool = False,  # æ˜¯å¦ä½¿ç”¨ PyTorch jit è·Ÿè¸ªè¿›è¡Œæ¨ç†ã€‚
    ):
        """
        A method that regroups all arguments linked to evaluation.

        Args:
            strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `"no"`):
                The evaluation strategy to adopt during training. Possible values are:

                    - `"no"`: No evaluation is done during training.
                    - `"steps"`: Evaluation is done (and logged) every `steps`.
                    - `"epoch"`: Evaluation is done at the end of each epoch.

                Setting a `strategy` different from `"no"` will set `self.do_eval` to `True`.
            steps (`int`, *optional*, defaults to 500):
                Number of update steps between two evaluations if `strategy="steps"`.
            batch_size (`int` *optional*, defaults to 8):
                The batch size per device (GPU/TPU core/CPU...) used for evaluation.
            accumulation_steps (`int`, *optional*):
                Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU.
                If left unset, the whole predictions are accumulated on GPU/TPU before being moved to the CPU (faster
                but requires more memory).
            delay (`float`, *optional*):
                Number of epochs or steps to wait for before the first evaluation can be performed, depending on the
                evaluation_strategy.
            loss_only (`bool`, *optional*, defaults to `False`):
                Ignores all outputs except the loss.
            jit_mode (`bool`, *optional*):
                Whether or not to use PyTorch jit trace for inference.

        Example:

        ```py
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_evaluate(strategy="steps", steps=100)
        >>> args.eval_steps
        100
        ```
        """
        self.evaluation_strategy = IntervalStrategy(strategy)  # è®¾ç½®è¯„ä¼°ç­–ç•¥
        if self.evaluation_strategy == IntervalStrategy.STEPS and steps == 0:  # å¦‚æœè¯„ä¼°ç­–ç•¥ä¸ºæ­¥æ•°ä¸”æ­¥æ•°ä¸º0ï¼Œåˆ™æŠ›å‡ºå€¼é”™è¯¯
            raise ValueError("Setting `strategy` as 'steps' requires a positive value for `steps`.")
        self.do_eval = self.evaluation_strategy != IntervalStrategy.NO  # è®¾ç½®æ˜¯å¦æ‰§è¡Œè¯„ä¼°
        self.eval_steps = steps  # è®¾ç½®è¯„ä¼°æ­¥æ•°
        self.per_device_eval_batch_size = batch_size  # è®¾ç½®æ¯ä¸ªè®¾å¤‡çš„è¯„ä¼°æ‰¹é‡å¤§å°
        self.eval_accumulation_steps = accumulation_steps  # è®¾ç½®ç´¯ç§¯æ­¥æ•°
        self.eval_delay = delay  # è®¾ç½®å»¶è¿Ÿ
        self.prediction_loss_only = loss_only  # è®¾ç½®æ˜¯å¦ä»…æŸå¤±
        self.jit_mode_eval = jit_mode  # è®¾ç½® JIT æ¨¡å¼æ˜¯å¦å¯ç”¨
        return self

    def set_testing(
        self,
        batch_size: int = 8,  # ç”¨äºæµ‹è¯•çš„æ¯ä¸ªè®¾å¤‡çš„æ‰¹é‡å¤§å°ï¼Œé»˜è®¤ä¸º8
        loss_only: bool = False,  # æ˜¯å¦ä»…è€ƒè™‘æŸå¤±ï¼Œé»˜è®¤ä¸º False
        jit_mode: bool = False,  # æ˜¯å¦ä½¿ç”¨ PyTorch jit è·Ÿè¸ªè¿›è¡Œæ¨ç†ï¼Œé»˜è®¤ä¸º False
```  
        """
        ä¸€ä¸ªæ–¹æ³•ï¼Œé‡æ–°ç»„ç»‡æ‰€æœ‰ä¸åœ¨ä¿ç•™æ•°æ®é›†ä¸Šè¿›è¡Œæµ‹è¯•ç›¸å…³çš„åŸºæœ¬å‚æ•°ã€‚

        <æç¤º>

        è°ƒç”¨æ­¤æ–¹æ³•å°†è‡ªåŠ¨å°† `self.do_predict` è®¾ç½®ä¸º `True`ã€‚

        </æç¤º>

        Args:
            batch_size (`int` *å¯é€‰*, é»˜è®¤ä¸º 8):
                ç”¨äºæµ‹è¯•çš„æ¯ä¸ªè®¾å¤‡ï¼ˆGPU/TPU æ ¸å¿ƒ/CPU...ï¼‰çš„æ‰¹é‡å¤§å°ã€‚
            loss_only (`bool`, *å¯é€‰*, é»˜è®¤ä¸º `False`):
                ä»…å¿½ç•¥æŸå¤±ä»¥å¤–çš„æ‰€æœ‰è¾“å‡ºã€‚
            jit_mode (`bool`, *å¯é€‰*):
                æ˜¯å¦ä½¿ç”¨ PyTorch jit trace è¿›è¡Œæ¨æ–­ã€‚

        ç¤ºä¾‹:

        ```py
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_testing(batch_size=32)
        >>> args.per_device_eval_batch_size
        32
        ```
        """
        # è®¾ç½® self.do_predict ä¸º True
        self.do_predict = True
        # è®¾ç½®æ¯ä¸ªè®¾å¤‡çš„è¯„ä¼°æ‰¹é‡å¤§å°
        self.per_device_eval_batch_size = batch_size
        # è®¾ç½®æ˜¯å¦ä»…é¢„æµ‹æŸå¤±
        self.prediction_loss_only = loss_only
        # è®¾ç½®æ˜¯å¦ä½¿ç”¨ jit æ¨¡å¼è¿›è¡Œè¯„ä¼°
        self.jit_mode_eval = jit_mode
        # è¿”å› self
        return self

    def set_save(
        self,
        strategy: Union[str, IntervalStrategy] = "steps",
        steps: int = 500,
        total_limit: Optional[int] = None,
        on_each_node: bool = False,
    ):
        """
        A method that regroups all arguments linked to checkpoint saving.

        Args:
            strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `"steps"`):
                The checkpoint save strategy to adopt during training. Possible values are:

                    - `"no"`: No save is done during training.
                    - `"epoch"`: Save is done at the end of each epoch.
                    - `"steps"`: Save is done every `save_steps`.

            steps (`int`, *optional*, defaults to 500):
                Number of updates steps before two checkpoint saves if `strategy="steps"`.
            total_limit (`int`, *optional*):
                If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in
                `output_dir`.
            on_each_node (`bool`, *optional*, defaults to `False`):
                When doing multi-node distributed training, whether to save models and checkpoints on each node, or
                only on the main one.

                This should not be activated when the different nodes use the same storage as the files will be saved
                with the same names for each node.

        Example:

        ```py
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_save(strategy="steps", steps=100)
        >>> args.save_steps
        100
        ```
        """
        # è®¾ç½®ä¿å­˜ç­–ç•¥
        self.save_strategy = IntervalStrategy(strategy)
        # è‹¥ä¿å­˜ç­–ç•¥ä¸ºæ­¥æ•°é—´éš”ä¸”æ­¥æ•°ä¸º0ï¼Œåˆ™å¼•å‘å€¼é”™è¯¯
        if self.save_strategy == IntervalStrategy.STEPS and steps == 0:
            raise ValueError("Setting `strategy` as 'steps' requires a positive value for `steps`.")
        # è®¾ç½®ä¿å­˜æ­¥æ•°
        self.save_steps = steps
        # è®¾ç½®ä¿å­˜æ€»æ•°é™åˆ¶
        self.save_total_limit = total_limit
        # è®¾ç½®æ˜¯å¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¿å­˜
        self.save_on_each_node = on_each_node
        # è¿”å›è®¾ç½®åçš„å‚æ•°å¯¹è±¡
        return self

    def set_logging(
        self,
        strategy: Union[str, IntervalStrategy] = "steps",
        steps: int = 500,
        report_to: Union[str, List[str]] = "none",
        level: str = "passive",
        first_step: bool = False,
        nan_inf_filter: bool = False,
        on_each_node: bool = False,
        replica_level: str = "passive",
    def set_push_to_hub(
        self,
        model_id: str,
        strategy: Union[str, HubStrategy] = "every_save",
        token: Optional[str] = None,
        private_repo: bool = False,
        always_push: bool = False,
    def set_optimizer(
        self,
        name: Union[str, OptimizerNames] = "adamw_torch",
        learning_rate: float = 5e-5,
        weight_decay: float = 0,
        beta1: float = 0.9,
        beta2: float = 0.999,
        epsilon: float = 1e-8,
        args: Optional[str] = None,
        """
        ä¸€ä¸ªæ–¹æ³•ï¼Œé‡æ–°ç»„ç»‡æ‰€æœ‰ä¸ä¼˜åŒ–å™¨åŠå…¶è¶…å‚æ•°ç›¸å…³çš„å‚æ•°ã€‚

        Args:
            name (`str` or [`training_args.OptimizerNames`], *optional*, defaults to `"adamw_torch"`):
                è¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨ï¼š"adamw_hf"ã€"adamw_torch"ã€"adamw_torch_fused"ã€"adamw_apex_fused"ã€
                "adamw_anyprecision"æˆ–"adafactor"ã€‚
            learning_rate (`float`, *optional*, defaults to 5e-5):
                åˆå§‹å­¦ä¹ ç‡ã€‚
            weight_decay (`float`, *optional*, defaults to 0):
                åº”ç”¨çš„æƒé‡è¡°å‡ï¼ˆå¦‚æœä¸ä¸ºé›¶ï¼‰åˆ°é™¤æ‰€æœ‰åç½®å’ŒLayerNormæƒé‡ä¹‹å¤–çš„æ‰€æœ‰å±‚ã€‚
            beta1 (`float`, *optional*, defaults to 0.9):
                adamä¼˜åŒ–å™¨æˆ–å…¶å˜ä½“çš„beta1è¶…å‚æ•°ã€‚
            beta2 (`float`, *optional*, defaults to 0.999):
                adamä¼˜åŒ–å™¨æˆ–å…¶å˜ä½“çš„beta2è¶…å‚æ•°ã€‚
            epsilon (`float`, *optional*, defaults to 1e-8):
                adamä¼˜åŒ–å™¨æˆ–å…¶å˜ä½“çš„epsilonè¶…å‚æ•°ã€‚
            args (`str`, *optional*):
                æä¾›ç»™AnyPrecisionAdamWçš„å¯é€‰å‚æ•°ï¼ˆä»…åœ¨`optim="adamw_anyprecision"`æ—¶æœ‰ç”¨ï¼‰ã€‚

        Example:

        ```py
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_optimizer(name="adamw_torch", beta1=0.8)
        >>> args.optim
        'adamw_torch'
        ```
        """
        # è®¾ç½®ä¼˜åŒ–å™¨åç§°
        self.optim = OptimizerNames(name)
        # è®¾ç½®å­¦ä¹ ç‡
        self.learning_rate = learning_rate
        # è®¾ç½®æƒé‡è¡°å‡
        self.weight_decay = weight_decay
        # è®¾ç½®adamä¼˜åŒ–å™¨çš„beta1è¶…å‚æ•°
        self.adam_beta1 = beta1
        # è®¾ç½®adamä¼˜åŒ–å™¨çš„beta2è¶…å‚æ•°
        self.adam_beta2 = beta2
        # è®¾ç½®adamä¼˜åŒ–å™¨çš„epsilonè¶…å‚æ•°
        self.adam_epsilon = epsilon
        # è®¾ç½®ä¼˜åŒ–å™¨å‚æ•°
        self.optim_args = args
        # è¿”å›å½“å‰å®ä¾‹
        return self

    def set_lr_scheduler(
        self,
        name: Union[str, SchedulerType] = "linear",
        num_epochs: float = 3.0,
        max_steps: int = -1,
        warmup_ratio: float = 0,
        warmup_steps: int = 0,
        """
        å°†æ‰€æœ‰ä¸å­¦ä¹ ç‡è°ƒåº¦å™¨åŠå…¶è¶…å‚æ•°ç›¸å…³çš„å‚æ•°é‡æ–°ç»„åˆçš„æ–¹æ³•ã€‚

        Args:
            name (`str` æˆ– [`SchedulerType`]ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º `"linear"`):
                è¦ä½¿ç”¨çš„è°ƒåº¦å™¨ç±»å‹ã€‚å‚è§ [`SchedulerType`] æ–‡æ¡£ä»¥è·å–æ‰€æœ‰å¯èƒ½çš„å€¼ã€‚
            num_epochs (`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 3.0):
                è¦æ‰§è¡Œçš„æ€»è®­ç»ƒè½®æ•°ï¼ˆå¦‚æœä¸æ˜¯æ•´æ•°ï¼Œå°†åœ¨åœæ­¢è®­ç»ƒä¹‹å‰æ‰§è¡Œæœ€åä¸€ä¸ªå‘¨æœŸçš„å°æ•°éƒ¨åˆ†ç™¾åˆ†æ¯”ï¼‰ã€‚
            max_steps (`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º -1):
                å¦‚æœè®¾ç½®ä¸ºæ­£æ•°ï¼Œåˆ™è¦æ‰§è¡Œçš„æ€»è®­ç»ƒæ­¥æ•°ã€‚è¦†ç›– `num_train_epochs`ã€‚å¯¹äºæœ‰é™æ•°æ®é›†ï¼Œ
                è®­ç»ƒå°†åœ¨æ•°æ®é›†ä¸Šé‡å¤è¿›è¡Œï¼ˆå¦‚æœæ‰€æœ‰æ•°æ®éƒ½å·²è€—å°½ï¼‰ï¼Œç›´åˆ°è¾¾åˆ° `max_steps`ã€‚
            warmup_ratio (`float`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0.0):
                ç”¨äºä» 0 çº¿æ€§é¢„çƒ­åˆ° `learning_rate` çš„æ€»è®­ç»ƒæ­¥éª¤çš„æ¯”ç‡ã€‚
            warmup_steps (`int`ï¼Œ*å¯é€‰*ï¼Œé»˜è®¤ä¸º 0):
                ç”¨äºä» 0 çº¿æ€§é¢„çƒ­åˆ° `learning_rate` çš„æ­¥éª¤æ•°ã€‚è¦†ç›–ä»»ä½• `warmup_ratio` çš„æ•ˆæœã€‚

        Example:

        ```py
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_lr_scheduler(name="cosine", warmup_ratio=0.05)
        >>> args.warmup_ratio
        0.05
        ```
        """
        # è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨ç±»å‹
        self.lr_scheduler_type = SchedulerType(name)
        # è®¾ç½®æ€»è®­ç»ƒè½®æ•°
        self.num_train_epochs = num_epochs
        # è®¾ç½®æ€»è®­ç»ƒæ­¥æ•°
        self.max_steps = max_steps
        # è®¾ç½®é¢„çƒ­æ¯”ç‡
        self.warmup_ratio = warmup_ratio
        # è®¾ç½®é¢„çƒ­æ­¥æ•°
        self.warmup_steps = warmup_steps
        # è¿”å›ä¿®æ”¹åçš„å‚æ•°å¯¹è±¡
        return self

    def set_dataloader(
        self,
        train_batch_size: int = 8,
        eval_batch_size: int = 8,
        drop_last: bool = False,
        num_workers: int = 0,
        pin_memory: bool = True,
        persistent_workers: bool = False,
        auto_find_batch_size: bool = False,
        ignore_data_skip: bool = False,
        sampler_seed: Optional[int] = None,
``` 
    ):
        """
        A method that regroups all arguments linked to the dataloaders creation.

        Args:
            drop_last (`bool`, *optional*, defaults to `False`):
                Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch
                size) or not.
            num_workers (`int`, *optional*, defaults to 0):
                Number of subprocesses to use for data loading (PyTorch only). 0 means that the data will be loaded in
                the main process.
            pin_memory (`bool`, *optional*, defaults to `True`):
                Whether you want to pin memory in data loaders or not. Will default to `True`.
            persistent_workers (`bool`, *optional*, defaults to `False`):
                If True, the data loader will not shut down the worker processes after a dataset has been consumed
                once. This allows to maintain the workers Dataset instances alive. Can potentially speed up training,
                but will increase RAM usage. Will default to `False`.
            auto_find_batch_size (`bool`, *optional*, defaults to `False`)
                Whether to find a batch size that will fit into memory automatically through exponential decay,
                avoiding CUDA Out-of-Memory errors. Requires accelerate to be installed (`pip install accelerate`)
            ignore_data_skip (`bool`, *optional*, defaults to `False`):
                When resuming training, whether or not to skip the epochs and batches to get the data loading at the
                same stage as in the previous training. If set to `True`, the training will begin faster (as that
                skipping step can take a long time) but will not yield the same results as the interrupted training
                would have.
            sampler_seed (`int`, *optional*):
                Random seed to be used with data samplers. If not set, random generators for data sampling will use the
                same seed as `self.seed`. This can be used to ensure reproducibility of data sampling, independent of
                the model seed.

        Example:

        ```py
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_dataloader(train_batch_size=16, eval_batch_size=64)
        >>> args.per_device_train_batch_size
        16
        ```

        Set the training and evaluation batch sizes along with other dataloader related options.
        """
        # Set the training batch size per device
        self.per_device_train_batch_size = train_batch_size
        # Set the evaluation batch size per device
        self.per_device_eval_batch_size = eval_batch_size
        # Set whether to drop the last incomplete batch
        self.dataloader_drop_last = drop_last
        # Set the number of worker subprocesses for data loading
        self.dataloader_num_workers = num_workers
        # Set whether to pin memory in data loaders
        self.dataloader_pin_memory = pin_memory
        # Set whether to keep worker processes alive after dataset consumption
        self.dataloader_persistent_workers = persistent_workers
        # Set whether to automatically find a batch size that fits into memory
        self.auto_find_batch_size = auto_find_batch_size
        # Set whether to ignore data skipping when resuming training
        self.ignore_data_skip = ignore_data_skip
        # Set the random seed for data samplers
        self.data_seed = sampler_seed
        # Return the modified TrainingArguments object
        return self
# å®šä¹‰ä¸€ä¸ªæšä¸¾ç±»ï¼Œè¡¨ç¤ºå¹¶è¡Œæ¨¡å¼ï¼ŒåŒ…æ‹¬ä»¥ä¸‹é€‰é¡¹ï¼š
class ParallelMode(Enum):
    # æœªå¹¶è¡Œï¼ŒæŒ‡ç¤ºä¸ä½¿ç”¨å¹¶è¡Œæ¨¡å¼
    NOT_PARALLEL = "not_parallel"
    # éåˆ†å¸ƒå¼ï¼Œå¹¶è¡Œï¼Œä½†ä¸æ¶‰åŠåˆ†å¸ƒå¼è®¡ç®—
    NOT_DISTRIBUTED = "not_distributed"
    # åˆ†å¸ƒå¼ï¼Œå¹¶è¡Œï¼Œæ¶‰åŠåˆ°åˆ†å¸ƒå¼è®¡ç®—
    DISTRIBUTED = "distributed"
    # SageMaker æ¨¡å‹å¹¶è¡Œï¼ŒæŒ‡ç¤ºä½¿ç”¨ Amazon SageMaker è¿›è¡Œæ¨¡å‹å¹¶è¡Œè®¡ç®—
    SAGEMAKER_MODEL_PARALLEL = "sagemaker_model_parallel"
    # SageMaker æ•°æ®å¹¶è¡Œï¼ŒæŒ‡ç¤ºä½¿ç”¨ Amazon SageMaker è¿›è¡Œæ•°æ®å¹¶è¡Œè®¡ç®—
    SAGEMAKER_DATA_PARALLEL = "sagemaker_data_parallel"
    # TPUï¼Œå¹¶è¡Œï¼ŒæŒ‡ç¤ºä½¿ç”¨ Google çš„ TPUï¼ˆå¼ é‡å¤„ç†å•å…ƒï¼‰è¿›è¡Œå¹¶è¡Œè®¡ç®—
    TPU = "tpu"
```