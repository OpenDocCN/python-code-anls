# `.\training_args.py`

```py
# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—ï¼Œè¿™äº›åº“å’Œæ¨¡å—ç”¨äºæ•´ä¸ªç¨‹åºçš„åŠŸèƒ½å®ç°
import contextlib  # ä¸Šä¸‹æ–‡ç®¡ç†å·¥å…·ï¼Œç”¨äºåˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨å’Œæ”¯æŒä¸Šä¸‹æ–‡ç®¡ç†åè®®çš„å¯¹è±¡
import io  # æä¾›äº†ç”¨äºå¤„ç†æµçš„æ ¸å¿ƒå·¥å…·ï¼Œå¦‚æ–‡æœ¬ã€äºŒè¿›åˆ¶å’Œå†…å­˜ç¼“å†²åŒº
import json  # å¤„ç† JSON æ ¼å¼æ•°æ®çš„åº“
import math  # æ•°å­¦å‡½æ•°åº“ï¼Œæä¾›äº†æ ‡å‡†çš„æ•°å­¦è¿ç®—å‡½æ•°
import os  # æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½çš„åº“ï¼Œæä¾›äº†ä¸æ“ä½œç³»ç»Ÿäº¤äº’çš„æ–¹æ³•
import warnings  # è­¦å‘Šå¤„ç†å·¥å…·ï¼Œç”¨äºæ§åˆ¶è­¦å‘Šçš„æ˜¾ç¤ºæ–¹å¼

from dataclasses import asdict, dataclass, field, fields  # æ•°æ®ç±»ç›¸å…³åŠŸèƒ½ï¼Œç”¨äºåˆ›å»ºå’Œæ“ä½œæ•°æ®ç±»
from datetime import timedelta  # å¤„ç†æ—¶é—´é—´éš”çš„ç±»å’Œå‡½æ•°
from enum import Enum  # æšä¸¾ç±»å‹çš„æ”¯æŒ
from pathlib import Path  # å¤„ç†è·¯å¾„çš„ç±»å’Œå‡½æ•°
from typing import Any, Dict, List, Optional, Union  # ç±»å‹æç¤ºç›¸å…³åŠŸèƒ½

from huggingface_hub import get_full_repo_name  # Hugging Face Hub ç›¸å…³åŠŸèƒ½ï¼Œç”¨äºè·å–å®Œæ•´ä»“åº“å
from packaging import version  # ç‰ˆæœ¬å·å¤„ç†å·¥å…·ï¼Œç”¨äºæ¯”è¾ƒå’Œæ“ä½œç‰ˆæœ¬å·

from .debug_utils import DebugOption  # è‡ªå®šä¹‰æ¨¡å—ä¸­çš„è°ƒè¯•é€‰é¡¹
from .trainer_utils import (  # è‡ªå®šä¹‰æ¨¡å—ä¸­çš„è®­ç»ƒå™¨ç›¸å…³å·¥å…·
    EvaluationStrategy,
    FSDPOption,
    HubStrategy,
    IntervalStrategy,
    SchedulerType,
)
from .utils import (  # è‡ªå®šä¹‰æ¨¡å—ä¸­çš„å®ç”¨å·¥å…·é›†åˆ
    ACCELERATE_MIN_VERSION,
    ExplicitEnum,
    cached_property,
    is_accelerate_available,
    is_safetensors_available,
    is_sagemaker_dp_enabled,
    is_sagemaker_mp_enabled,
    is_torch_available,
    is_torch_bf16_cpu_available,
    is_torch_bf16_gpu_available,
    is_torch_neuroncore_available,
    is_torch_npu_available,
    is_torch_tf32_available,
    is_torch_xla_available,
    is_torch_xpu_available,
    logging,
    requires_backends,
)
from .utils.generic import strtobool  # è‡ªå®šä¹‰æ¨¡å—ä¸­çš„é€šç”¨å·¥å…·ï¼Œå¦‚å­—ç¬¦ä¸²è½¬å¸ƒå°”å€¼
from .utils.import_utils import is_optimum_neuron_available  # è‡ªå®šä¹‰æ¨¡å—ä¸­çš„å¯¼å…¥å·¥å…·ï¼Œæ£€æŸ¥ç¥ç»æ ¸æ˜¯å¦å¯ç”¨

# è·å–å½“å‰æ¨¡å—çš„æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger(__name__)
# å¤åˆ¶æ—¥å¿—çº§åˆ«å­—å…¸ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒå™¨æ—¥å¿—çº§åˆ«ä¸­æ·»åŠ  passsive çº§åˆ«
log_levels = logging.get_log_levels_dict().copy()
trainer_log_levels = dict(**log_levels, passive=-1)

# å¦‚æœ Torch å¯ç”¨ï¼Œå¯¼å…¥ç›¸å…³æ¨¡å—
if is_torch_available():
    import torch  # å¯¼å…¥ PyTorch åº“
    import torch.distributed as dist  # å¯¼å…¥ PyTorch åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒæ¨¡å—

    from .pytorch_utils import is_torch_greater_or_equal_than_2_0  # å¯¼å…¥è‡ªå®šä¹‰çš„ PyTorch å·¥å…·å‡½æ•°

# å¦‚æœ Accelerate å¯ç”¨ï¼Œå¯¼å…¥ç›¸å…³æ¨¡å—
if is_accelerate_available():
    from accelerate.state import AcceleratorState, PartialState  # å¯¼å…¥åŠ é€Ÿå™¨çŠ¶æ€ç›¸å…³æ¨¡å—
    from accelerate.utils import DistributedType  # å¯¼å…¥åˆ†å¸ƒå¼ç±»å‹æšä¸¾

    from .trainer_pt_utils import AcceleratorConfig  # å¯¼å…¥è‡ªå®šä¹‰çš„åŠ é€Ÿå™¨é…ç½®ç±»

# å¦‚æœ Torch XLA å¯ç”¨ï¼Œå¯¼å…¥ç›¸å…³æ¨¡å—
if is_torch_xla_available():
    import torch_xla.core.xla_model as xm  # å¯¼å…¥ Torch XLA æ ¸å¿ƒæ¨¡å—

# å¦‚æœ Torch NeuronCore å¯ç”¨ï¼Œå¯¼å…¥ç›¸å…³æ¨¡å—
if is_torch_neuroncore_available(check_device=False):
    # æ”¯æŒ Torchrun çš„ç‰¹å®šå¯¼å…¥ï¼Œå‚è€ƒï¼šhttps://github.com/pytorch/xla/pull/3609
    pass
    # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†ç¯å¢ƒå˜é‡ TORCHELASTIC_RUN_ID
    if os.environ.get("TORCHELASTIC_RUN_ID"):
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ä½³ç¥ç»å…ƒå¯ç”¨
        if is_optimum_neuron_available():
            # å¦‚æœæœ‰æœ€ä½³ç¥ç»å…ƒå¯ç”¨ï¼Œè®°å½•ä¿¡æ¯æç¤ºç”¨æˆ·ä½¿ç”¨ TrainiumTrainer è¿›è¡Œè®­ç»ƒ
            logger.info(
                "Make sure that you are performing the training with the TrainiumTrainer from optimum[neuron], this "
                "will fail otherwise."
            )
        else:
            # å¦‚æœæ²¡æœ‰æœ€ä½³ç¥ç»å…ƒå¯ç”¨ï¼Œè­¦å‘Šç”¨æˆ·ä½¿ç”¨ optimum[neuron] çš„ TrainiumTrainer æ›¿ä»£ Transformers åº“è¿›è¡Œè®­ç»ƒ
            logger.warning(
                "Please use the TrainiumTrainer from optimum[neuron] instead of the Transformers library to perform "
                "training on AWS Trainium instances. More information here: "
                "https://github.com/huggingface/optimum-neuron"
            )
            # å¯¼å…¥ torch_xla.distributed.xla_backend å¹¶ä½¿ç”¨å…¶ ProcessGroupXla
            import torch_xla.distributed.xla_backend as xbn
            
            # å¦‚æœå½“å‰çš„åˆ†å¸ƒå¼ç»„ä¸æ˜¯ ProcessGroupXla ç±»å‹ï¼Œåˆ™å°è¯•ä½¿ç”¨ XLA åç«¯åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„
            if not isinstance(dist.group.WORLD, xbn.ProcessGroupXla):
                dist.init_process_group(backend="xla")
                # å†æ¬¡æ£€æŸ¥åˆ†å¸ƒå¼ç»„æ˜¯å¦æˆåŠŸåˆå§‹åŒ–ä¸º ProcessGroupXla ç±»å‹ï¼Œå¦åˆ™æŠ›å‡ºæ–­è¨€é”™è¯¯
                if not isinstance(dist.group.WORLD, xbn.ProcessGroupXla):
                    raise AssertionError("Failed to initialize torch.distributed process group using XLA backend.")
if is_sagemaker_mp_enabled():
    # å¦‚æœåœ¨SageMakerä¸­å¯ç”¨äº†æ¨¡å‹å¹¶è¡Œï¼Œåˆ™å¯¼å…¥ç›¸åº”çš„æ¨¡å‹å¹¶è¡Œåº“
    import smdistributed.modelparallel.torch as smp
    # åˆå§‹åŒ–æ¨¡å‹å¹¶è¡Œ
    smp.init()


def default_logdir() -> str:
    """
    Same default as PyTorch
    """
    # å¯¼å…¥æ‰€éœ€çš„åº“
    import socket
    from datetime import datetime

    # è·å–å½“å‰æ—¶é—´å¹¶æ ¼å¼åŒ–
    current_time = datetime.now().strftime("%b%d_%H-%M-%S")
    # æ„å»ºé»˜è®¤çš„æ—¥å¿—ç›®å½•è·¯å¾„
    return os.path.join("runs", current_time + "_" + socket.gethostname())


def get_int_from_env(env_keys, default):
    """Returns the first positive env value found in the `env_keys` list or the default."""
    # éå†ç¯å¢ƒå˜é‡åˆ—è¡¨
    for e in env_keys:
        # è·å–ç¯å¢ƒå˜é‡å€¼ï¼Œå¹¶å°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¦‚æœæ— æ³•è½¬æ¢åˆ™è¿”å›é»˜è®¤å€¼
        val = int(os.environ.get(e, -1))
        if val >= 0:
            return val
    # å¦‚æœæ‰€æœ‰ç¯å¢ƒå˜é‡éƒ½ä¸ç¬¦åˆè¦æ±‚ï¼Œåˆ™è¿”å›é»˜è®¤å€¼
    return default


def get_xla_device_type(device: "torch.device") -> Optional[str]:
    """
    Returns the xla device type (CPU|GPU|TPU) or None if the device is a non-xla device.
    """
    # æ£€æŸ¥æ˜¯å¦æ”¯æŒPyTorch XLA
    if is_torch_xla_available():
        # å¦‚æœè®¾å¤‡ç±»å‹ä¸ºCPUï¼Œåˆ™è¿”å›"CPU"
        if device.type == "cpu":
            return "CPU"
        # å¦åˆ™è¿”å›XLAçœŸå®è®¾å¤‡åˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ªè®¾å¤‡ç±»å‹
        return xm.xla_real_devices([device])[0].split(":")[0]
    # å¦‚æœä¸æ”¯æŒPyTorch XLAï¼Œåˆ™è¿”å›None
    return None


class OptimizerNames(ExplicitEnum):
    """
    Stores the acceptable string identifiers for optimizers.
    """

    # æšä¸¾ä¼˜åŒ–å™¨çš„å¯æ¥å—å­—ç¬¦ä¸²æ ‡è¯†
    ADAMW_HF = "adamw_hf"
    ADAMW_TORCH = "adamw_torch"
    ADAMW_TORCH_FUSED = "adamw_torch_fused"
    ADAMW_TORCH_XLA = "adamw_torch_xla"
    ADAMW_TORCH_NPU_FUSED = "adamw_torch_npu_fused"
    ADAMW_APEX_FUSED = "adamw_apex_fused"
    ADAFACTOR = "adafactor"
    ADAMW_ANYPRECISION = "adamw_anyprecision"
    SGD = "sgd"
    ADAGRAD = "adagrad"
    ADAMW_BNB = "adamw_bnb_8bit"
    ADAMW_8BIT = "adamw_8bit"  # just an alias for adamw_bnb_8bit
    LION_8BIT = "lion_8bit"
    LION = "lion_32bit"
    PAGED_ADAMW = "paged_adamw_32bit"
    PAGED_ADAMW_8BIT = "paged_adamw_8bit"
    PAGED_LION = "paged_lion_32bit"
    PAGED_LION_8BIT = "paged_lion_8bit"
    RMSPROP = "rmsprop"
    RMSPROP_BNB = "rmsprop_bnb"
    RMSPROP_8BIT = "rmsprop_bnb_8bit"
    RMSPROP_32BIT = "rmsprop_bnb_32bit"
    GALORE_ADAMW = "galore_adamw"
    GALORE_ADAMW_8BIT = "galore_adamw_8bit"
    GALORE_ADAFACTOR = "galore_adafactor"
    GALORE_ADAMW_LAYERWISE = "galore_adamw_layerwise"
    GALORE_ADAMW_8BIT_LAYERWISE = "galore_adamw_8bit_layerwise"
    GALORE_ADAFACTOR_LAYERWISE = "galore_adafactor_layerwise"


# TODO: `TrainingArguments` users rely on it being fully mutable. In the future see if we can narrow this to a few keys: https://github.com/huggingface/transformers/pull/25903
@dataclass
class TrainingArguments:
    """
    TrainingArguments is the subset of the arguments we use in our example scripts **which relate to the training loop
    itself**.

    Using [`HfArgumentParser`] we can turn this class into
    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the
    command line.

    """

    # æŒ‡å®šæ¡†æ¶ä¸ºPyTorch
    framework = "pt"
    # å®šä¹‰è¾“å‡ºç›®å½•è·¯å¾„ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹é¢„æµ‹å’Œæ£€æŸ¥ç‚¹
    output_dir: str = field(
        metadata={"help": "The output directory where the model predictions and checkpoints will be written."},
    )
    overwrite_output_dir: bool = field(
        default=False,
        metadata={
            "help": (
                "Overwrite the content of the output directory. "
                "Use this to continue training if output_dir points to a checkpoint directory."
            )
        },
    )
    # æ˜¯å¦è¦†ç›–è¾“å‡ºç›®å½•çš„å†…å®¹ï¼Œé»˜è®¤ä¸ºFalse
    # å½“output_diræŒ‡å‘æ£€æŸ¥ç‚¹ç›®å½•æ—¶ï¼Œè®¾ç½®ä¸ºTrueä»¥ç»§ç»­è®­ç»ƒ

    do_train: bool = field(default=False, metadata={"help": "Whether to run training."})
    # æ˜¯å¦è¿è¡Œè®­ç»ƒï¼Œé»˜è®¤ä¸ºFalse

    do_eval: bool = field(default=False, metadata={"help": "Whether to run eval on the dev set."})
    # æ˜¯å¦åœ¨å¼€å‘é›†ä¸Šè¿è¡Œè¯„ä¼°ï¼Œé»˜è®¤ä¸ºFalse

    do_predict: bool = field(default=False, metadata={"help": "Whether to run predictions on the test set."})
    # æ˜¯å¦åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œé¢„æµ‹ï¼Œé»˜è®¤ä¸ºFalse

    evaluation_strategy: Union[IntervalStrategy, str] = field(
        default="no",
        metadata={"help": "The evaluation strategy to use."},
    )
    # ä½¿ç”¨çš„è¯„ä¼°ç­–ç•¥ï¼Œé»˜è®¤ä¸º"no"

    prediction_loss_only: bool = field(
        default=False,
        metadata={"help": "When performing evaluation and predictions, only returns the loss."},
    )
    # åœ¨æ‰§è¡Œè¯„ä¼°å’Œé¢„æµ‹æ—¶ï¼Œæ˜¯å¦åªè¿”å›æŸå¤±ï¼Œé»˜è®¤ä¸ºFalse

    per_device_train_batch_size: int = field(
        default=8, metadata={"help": "Batch size per GPU/TPU/MPS/NPU core/CPU for training."}
    )
    # æ¯ä¸ªGPU/TPU/MPS/NPU core/CPUçš„è®­ç»ƒæ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤ä¸º8

    per_device_eval_batch_size: int = field(
        default=8, metadata={"help": "Batch size per GPU/TPU/MPS/NPU core/CPU for evaluation."}
    )
    # æ¯ä¸ªGPU/TPU/MPS/NPU core/CPUçš„è¯„ä¼°æ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤ä¸º8

    per_gpu_train_batch_size: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "Deprecated, the use of `--per_device_train_batch_size` is preferred. "
                "Batch size per GPU/TPU core/CPU for training."
            )
        },
    )
    # æ¯ä¸ªGPU/TPU core/CPUçš„è®­ç»ƒæ‰¹æ¬¡å¤§å°ï¼ˆå·²å¼ƒç”¨ï¼‰ï¼Œå»ºè®®ä½¿ç”¨`--per_device_train_batch_size`

    per_gpu_eval_batch_size: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "Deprecated, the use of `--per_device_eval_batch_size` is preferred. "
                "Batch size per GPU/TPU core/CPU for evaluation."
            )
        },
    )
    # æ¯ä¸ªGPU/TPU core/CPUçš„è¯„ä¼°æ‰¹æ¬¡å¤§å°ï¼ˆå·²å¼ƒç”¨ï¼‰ï¼Œå»ºè®®ä½¿ç”¨`--per_device_eval_batch_size`

    gradient_accumulation_steps: int = field(
        default=1,
        metadata={"help": "Number of updates steps to accumulate before performing a backward/update pass."},
    )
    # æ‰§è¡Œåå‘ä¼ æ’­/æ›´æ–°æ­¥éª¤ä¹‹å‰ç´¯ç§¯çš„æ›´æ–°æ­¥éª¤æ•°ï¼Œé»˜è®¤ä¸º1

    eval_accumulation_steps: Optional[int] = field(
        default=None,
        metadata={"help": "Number of predictions steps to accumulate before moving the tensors to the CPU."},
    )
    # åœ¨å°†å¼ é‡ç§»åŠ¨åˆ°CPUä¹‹å‰ç´¯ç§¯çš„é¢„æµ‹æ­¥éª¤æ•°ï¼Œé»˜è®¤ä¸ºNone

    eval_delay: Optional[float] = field(
        default=0,
        metadata={
            "help": (
                "Number of epochs or steps to wait for before the first evaluation can be performed, depending on the"
                " evaluation_strategy."
            )
        },
    )
    # åœ¨ç¬¬ä¸€æ¬¡è¯„ä¼°ä¹‹å‰ç­‰å¾…çš„æ—¶æœŸæˆ–æ­¥éª¤æ•°ï¼Œå–å†³äºè¯„ä¼°ç­–ç•¥ï¼Œé»˜è®¤ä¸º0

    learning_rate: float = field(default=5e-5, metadata={"help": "The initial learning rate for AdamW."})
    # AdamWä¼˜åŒ–å™¨çš„åˆå§‹å­¦ä¹ ç‡ï¼Œé»˜è®¤ä¸º5e-5

    weight_decay: float = field(default=0.0, metadata={"help": "Weight decay for AdamW if we apply some."})
    # å¦‚æœåº”ç”¨çš„è¯ï¼ŒAdamWçš„æƒé‡è¡°å‡ç‡ï¼Œé»˜è®¤ä¸º0.0

    adam_beta1: float = field(default=0.9, metadata={"help": "Beta1 for AdamW optimizer"})
    # AdamWä¼˜åŒ–å™¨çš„Beta1å‚æ•°ï¼Œé»˜è®¤ä¸º0.9

    adam_beta2: float = field(default=0.999, metadata={"help": "Beta2 for AdamW optimizer"})
    # AdamWä¼˜åŒ–å™¨çš„Beta2å‚æ•°ï¼Œé»˜è®¤ä¸º0.999

    adam_epsilon: float = field(default=1e-8, metadata={"help": "Epsilon for AdamW optimizer."})
    # AdamWä¼˜åŒ–å™¨çš„Epsilonå‚æ•°ï¼Œé»˜è®¤ä¸º1e-8
    # å®šä¹‰æœ€å¤§æ¢¯åº¦èŒƒæ•°ï¼Œé»˜è®¤ä¸º1.0ï¼Œç”¨äºæ¢¯åº¦è£å‰ª
    max_grad_norm: float = field(default=1.0, metadata={"help": "Max gradient norm."})

    # å®šä¹‰æ€»çš„è®­ç»ƒå‘¨æœŸæ•°ï¼Œé»˜è®¤ä¸º3.0
    num_train_epochs: float = field(default=3.0, metadata={"help": "Total number of training epochs to perform."})
    
    # å®šä¹‰æœ€å¤§è®­ç»ƒæ­¥æ•°ï¼Œé»˜è®¤ä¸º-1ï¼Œå¦‚æœå¤§äº0ï¼Œåˆ™è®¾ç½®æ€»çš„è®­ç»ƒæ­¥æ•°ï¼Œè¦†ç›–num_train_epochsçš„è®¾å®š
    max_steps: int = field(
        default=-1,
        metadata={"help": "If > 0: set total number of training steps to perform. Override num_train_epochs."},
    )
    
    # å®šä¹‰å­¦ä¹ ç‡è°ƒåº¦å™¨çš„ç±»å‹ï¼Œé»˜è®¤ä¸º"linear"
    lr_scheduler_type: Union[SchedulerType, str] = field(
        default="linear",
        metadata={"help": "The scheduler type to use."},
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨çš„é¢å¤–å‚æ•°è®¾å®šï¼Œé»˜è®¤ä¸ºç©ºå­—å…¸ï¼Œä¾‹å¦‚{'num_cycles': 1}ç”¨äºä½™å¼¦é€€ç«é‡å¯æ—¶çš„å‚æ•°è®¾ç½®
    lr_scheduler_kwargs: Optional[Dict] = field(
        default_factory=dict,
        metadata={
            "help": (
                "Extra parameters for the lr_scheduler such as {'num_cycles': 1} for the cosine with hard restarts"
            )
        },
    )
    
    # çº¿æ€§é¢„çƒ­çš„æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º0.0ï¼Œè¡¨ç¤ºåœ¨æ€»æ­¥æ•°çš„è¿™ä¸€éƒ¨åˆ†ä¸Šè¿›è¡Œçº¿æ€§é¢„çƒ­
    warmup_ratio: float = field(
        default=0.0, metadata={"help": "Linear warmup over warmup_ratio fraction of total steps."}
    )
    
    # çº¿æ€§é¢„çƒ­çš„æ­¥æ•°ï¼Œé»˜è®¤ä¸º0ï¼Œè¡¨ç¤ºå›ºå®šçš„çº¿æ€§é¢„çƒ­æ­¥æ•°
    warmup_steps: int = field(default=0, metadata={"help": "Linear warmup over warmup_steps."})

    # ä¸»èŠ‚ç‚¹æ—¥å¿—è®°å½•çº§åˆ«ï¼Œé»˜è®¤ä¸º"passive"ï¼Œå…è®¸åº”ç”¨ç¨‹åºè®¾å®šæ—¥å¿—çº§åˆ«
    log_level: Optional[str] = field(
        default="passive",
        metadata={
            "help": (
                "Logger log level to use on the main node. Possible choices are the log levels as strings: 'debug',"
                " 'info', 'warning', 'error' and 'critical', plus a 'passive' level which doesn't set anything and"
                " lets the application set the level. Defaults to 'passive'."
            ),
            "choices": trainer_log_levels.keys(),  # å¯é€‰çš„æ—¥å¿—çº§åˆ«
        },
    )
    
    # å¤åˆ¶èŠ‚ç‚¹æ—¥å¿—è®°å½•çº§åˆ«ï¼Œé»˜è®¤ä¸º"warning"ï¼Œä¸ä¸»èŠ‚ç‚¹æ—¥å¿—è®°å½•çº§åˆ«ç›¸åŒ
    log_level_replica: Optional[str] = field(
        default="warning",
        metadata={
            "help": "Logger log level to use on replica nodes. Same choices and defaults as ``log_level``",
            "choices": trainer_log_levels.keys(),  # å¯é€‰çš„æ—¥å¿—çº§åˆ«
        },
    )
    
    # å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œæ˜¯å¦åœ¨æ¯ä¸ªèŠ‚ç‚¹è®°å½•æ—¥å¿—ï¼Œé»˜è®¤ä¸ºTrueè¡¨ç¤ºæ¯ä¸ªèŠ‚ç‚¹éƒ½è®°å½•æ—¥å¿—
    log_on_each_node: bool = field(
        default=True,
        metadata={
            "help": (
                "When doing a multinode distributed training, whether to log once per node or just once on the main"
                " node."
            )
        },
    )
    
    # Tensorboardæ—¥å¿—ç›®å½•ï¼Œé»˜è®¤ä¸ºNone
    logging_dir: Optional[str] = field(default=None, metadata={"help": "Tensorboard log dir."})
    
    # è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ—¥å¿—è®°å½•ç­–ç•¥ï¼Œé»˜è®¤ä¸º"steps"ï¼Œè¡¨ç¤ºæ¯éš”ä¸€å®šæ­¥æ•°è®°å½•ä¸€æ¬¡æ—¥å¿—
    logging_strategy: Union[IntervalStrategy, str] = field(
        default="steps",
        metadata={"help": "The logging strategy to use."},
    )
    
    # æ˜¯å¦è®°å½•ç¬¬ä¸€ä¸ªå…¨å±€æ­¥æ•°ï¼Œé»˜è®¤ä¸ºFalse
    logging_first_step: bool = field(default=False, metadata={"help": "Log the first global_step"})
    
    # æ¯éš”å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—ï¼Œé»˜è®¤ä¸º500ï¼Œå¯ä»¥æ˜¯æ•´æ•°æˆ–å°äº1çš„æµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºæ¯”ä¾‹
    logging_steps: float = field(
        default=500,
        metadata={
            "help": (
                "Log every X updates steps. Should be an integer or a float in range `[0,1)`. "
                "If smaller than 1, will be interpreted as ratio of total training steps."
            )
        },
    )
    
    # æ˜¯å¦è¿‡æ»¤æ‰è®°å½•ä¸­çš„NaNå’ŒInfæŸå¤±ï¼Œé»˜è®¤ä¸ºTrue
    logging_nan_inf_filter: bool = field(default=True, metadata={"help": "Filter nan and inf losses for logging."})
    
    # æ£€æŸ¥ç‚¹ä¿å­˜ç­–ç•¥ï¼Œé»˜è®¤ä¸º"steps"ï¼Œè¡¨ç¤ºæ¯éš”ä¸€å®šæ­¥æ•°ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
    save_strategy: Union[IntervalStrategy, str] = field(
        default="steps",
        metadata={"help": "The checkpoint save strategy to use."},
    )
    # å®šä¹‰ä¸€ä¸ªæµ®ç‚¹ç±»å‹çš„å­—æ®µ `save_steps`ï¼Œé»˜è®¤å€¼ä¸º 500
    save_steps: float = field(
        default=500,
        metadata={
            "help": (
                "Save checkpoint every X updates steps. Should be an integer or a float in range `[0,1)`. "
                "If smaller than 1, will be interpreted as ratio of total training steps."
            )
        },
    )

    # å®šä¹‰ä¸€ä¸ªå¯é€‰æ•´æ•°ç±»å‹çš„å­—æ®µ `save_total_limit`ï¼Œé»˜è®¤å€¼ä¸º None
    save_total_limit: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in"
                " `output_dir`. When `load_best_model_at_end` is enabled, the 'best' checkpoint according to"
                " `metric_for_best_model` will always be retained in addition to the most recent ones. For example,"
                " for `save_total_limit=5` and `load_best_model_at_end=True`, the four last checkpoints will always be"
                " retained alongside the best model. When `save_total_limit=1` and `load_best_model_at_end=True`,"
                " it is possible that two checkpoints are saved: the last one and the best one (if they are different)."
                " Default is unlimited checkpoints"
            )
        },
    )

    # å®šä¹‰ä¸€ä¸ªå¯é€‰å¸ƒå°”ç±»å‹çš„å­—æ®µ `save_safetensors`ï¼Œé»˜è®¤å€¼ä¸º True
    save_safetensors: Optional[bool] = field(
        default=True,
        metadata={
            "help": "Use safetensors saving and loading for state dicts instead of default torch.load and torch.save."
        },
    )

    # å®šä¹‰ä¸€ä¸ªå¸ƒå°”ç±»å‹çš„å­—æ®µ `save_on_each_node`ï¼Œé»˜è®¤å€¼ä¸º False
    save_on_each_node: bool = field(
        default=False,
        metadata={
            "help": (
                "When doing multi-node distributed training, whether to save models and checkpoints on each node, or"
                " only on the main one"
            )
        },
    )

    # å®šä¹‰ä¸€ä¸ªå¸ƒå°”ç±»å‹çš„å­—æ®µ `save_only_model`ï¼Œé»˜è®¤å€¼ä¸º False
    save_only_model: bool = field(
        default=False,
        metadata={
            "help": (
                "When checkpointing, whether to only save the model, or also the optimizer, scheduler & rng state."
                "Note that when this is true, you won't be able to resume training from checkpoint."
                "This enables you to save storage by not storing the optimizer, scheduler & rng state."
                "You can only load the model using from_pretrained with this option set to True."
            )
        },
    )

    # å®šä¹‰ä¸€ä¸ªå¸ƒå°”ç±»å‹çš„å­—æ®µ `no_cuda`ï¼Œé»˜è®¤å€¼ä¸º False
    no_cuda: bool = field(
        default=False,
        metadata={"help": "This argument is deprecated. It will be removed in version 5.0 of ğŸ¤— Transformers."},
    )

    # å®šä¹‰ä¸€ä¸ªå¸ƒå°”ç±»å‹çš„å­—æ®µ `use_cpu`ï¼Œé»˜è®¤å€¼ä¸º False
    use_cpu: bool = field(
        default=False,
        metadata={
            "help": " Whether or not to use cpu. If set to False, we will use cuda/tpu/mps/npu device if available."
        },
    )

    # å®šä¹‰ä¸€ä¸ªå¸ƒå°”ç±»å‹çš„å­—æ®µ `use_mps_device`ï¼Œé»˜è®¤å€¼ä¸º False
    use_mps_device: bool = field(
        default=False,
        metadata={
            "help": "This argument is deprecated. `mps` device will be used if available similar to `cuda` device."
            " It will be removed in version 5.0 of ğŸ¤— Transformers"
        },
    )
    seed: int = field(default=42, metadata={"help": "Random seed that will be set at the beginning of training."})
    # è®¾ç½®éšæœºç§å­ï¼Œç”¨äºè®­ç»ƒå¼€å§‹æ—¶çš„éšæœºæ€§
    data_seed: Optional[int] = field(default=None, metadata={"help": "Random seed to be used with data samplers."})
    # æ•°æ®é‡‡æ ·å™¨ä½¿ç”¨çš„éšæœºç§å­ï¼Œå¯é€‰å‚æ•°
    jit_mode_eval: bool = field(
        default=False, metadata={"help": "Whether or not to use PyTorch jit trace for inference"}
    )
    # æ˜¯å¦ä½¿ç”¨ PyTorch jit è¿½è¸ªè¿›è¡Œæ¨æ–­
    use_ipex: bool = field(
        default=False,
        metadata={
            "help": (
                "Use Intel extension for PyTorch when it is available, installation:"
                " 'https://github.com/intel/intel-extension-for-pytorch'"
            )
        },
    )
    # åœ¨å¯ç”¨æ—¶æ˜¯å¦ä½¿ç”¨ Intel æ‰©å±•è¿›è¡Œ PyTorch åŠ é€Ÿ
    bf16: bool = field(
        default=False,
        metadata={
            "help": (
                "Whether to use bf16 (mixed) precision instead of 32-bit. Requires Ampere or higher NVIDIA"
                " architecture or using CPU (use_cpu) or Ascend NPU. This is an experimental API and it may change."
            )
        },
    )
    # æ˜¯å¦ä½¿ç”¨ bf16ï¼ˆæ··åˆï¼‰ç²¾åº¦æ›¿ä»£ 32 ä½ç²¾åº¦
    fp16: bool = field(
        default=False,
        metadata={"help": "Whether to use fp16 (mixed) precision instead of 32-bit"},
    )
    # æ˜¯å¦ä½¿ç”¨ fp16ï¼ˆæ··åˆï¼‰ç²¾åº¦æ›¿ä»£ 32 ä½ç²¾åº¦
    fp16_opt_level: str = field(
        default="O1",
        metadata={
            "help": (
                "For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']. "
                "See details at https://nvidia.github.io/apex/amp.html"
            )
        },
    )
    # fp16 ä½¿ç”¨çš„ä¼˜åŒ–çº§åˆ«ï¼Œé€‰æ‹©åœ¨ ['O0', 'O1', 'O2', 'O3'] ä¸­çš„ä¸€ä¸ª
    half_precision_backend: str = field(
        default="auto",
        metadata={
            "help": "The backend to be used for half precision.",
            "choices": ["auto", "apex", "cpu_amp"],
        },
    )
    # ç”¨äºåŠç²¾åº¦è®¡ç®—çš„åç«¯é€‰æ‹©ï¼Œå¯é€‰å€¼ä¸º ['auto', 'apex', 'cpu_amp']
    bf16_full_eval: bool = field(
        default=False,
        metadata={
            "help": (
                "Whether to use full bfloat16 evaluation instead of 32-bit. This is an experimental API and it may"
                " change."
            )
        },
    )
    # æ˜¯å¦ä½¿ç”¨ bf16ï¼ˆå®Œæ•´ï¼‰è¯„ä¼°æ›¿ä»£ 32 ä½ç²¾åº¦
    fp16_full_eval: bool = field(
        default=False,
        metadata={"help": "Whether to use full float16 evaluation instead of 32-bit"},
    )
    # æ˜¯å¦ä½¿ç”¨ fp16ï¼ˆå®Œæ•´ï¼‰è¯„ä¼°æ›¿ä»£ 32 ä½ç²¾åº¦
    tf32: Optional[bool] = field(
        default=None,
        metadata={
            "help": (
                "Whether to enable tf32 mode, available in Ampere and newer GPU architectures. This is an experimental"
                " API and it may change."
            )
        },
    )
    # æ˜¯å¦å¯ç”¨ tf32 æ¨¡å¼ï¼Œä»…é€‚ç”¨äº Ampere åŠæ›´æ–°çš„ GPU æ¶æ„
    local_rank: int = field(default=-1, metadata={"help": "For distributed training: local_rank"})
    # åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„æœ¬åœ°æ’å
    ddp_backend: Optional[str] = field(
        default=None,
        metadata={
            "help": "The backend to be used for distributed training",
            "choices": ["nccl", "gloo", "mpi", "ccl", "hccl"],
        },
    )
    # åˆ†å¸ƒå¼è®­ç»ƒä½¿ç”¨çš„åç«¯é€‰æ‹©ï¼Œå¯é€‰å€¼ä¸º ['nccl', 'gloo', 'mpi', 'ccl', 'hccl']
    tpu_num_cores: Optional[int] = field(
        default=None, metadata={"help": "TPU: Number of TPU cores (automatically passed by launcher script)"}
    )
    # TPU ä½¿ç”¨çš„æ ¸å¿ƒæ•°
    tpu_metrics_debug: bool = field(
        default=False,
        metadata={
            "help": (
                "å·²å¼ƒç”¨ï¼Œæ¨èä½¿ç”¨ `--debug tpu_metrics_debug`ã€‚TPUï¼šæ˜¯å¦æ‰“å°è°ƒè¯•æŒ‡æ ‡"
            )
        },
    )
    debug: Union[str, List[DebugOption]] = field(
        default="",
        metadata={
            "help": (
                "æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ã€‚å½“å‰é€‰é¡¹ï¼š"
                "`underflow_overflow`ï¼ˆæ£€æµ‹æ¿€æ´»å’Œæƒé‡ä¸­çš„ä¸‹æº¢å’Œä¸Šæº¢ï¼‰ï¼Œ"
                "`tpu_metrics_debug`ï¼ˆåœ¨TPUä¸Šæ‰“å°è°ƒè¯•æŒ‡æ ‡ï¼‰ã€‚"
            )
        },
    )

    dataloader_drop_last: bool = field(
        default=False, metadata={"help": "å¦‚æœä¸æ˜¯æ‰¹é‡å¤§å°çš„æ•´æ•°å€ï¼Œä¸¢å¼ƒæœ€åä¸å®Œæ•´çš„æ‰¹æ¬¡ã€‚"}
    )
    eval_steps: Optional[float] = field(
        default=None,
        metadata={
            "help": (
                "æ¯éš”Xæ­¥è¿è¡Œä¸€æ¬¡è¯„ä¼°ã€‚åº”ä¸ºæ•´æ•°æˆ–èŒƒå›´ä¸º`[0,1)`çš„æµ®ç‚¹æ•°ã€‚"
                "å¦‚æœå°äº1ï¼Œå°†è§£é‡Šä¸ºæ€»è®­ç»ƒæ­¥æ•°çš„æ¯”ä¾‹ã€‚"
            )
        },
    )
    dataloader_num_workers: int = field(
        default=0,
        metadata={
            "help": (
                "ç”¨äºæ•°æ®åŠ è½½çš„å­è¿›ç¨‹æ•°ï¼ˆä»…é€‚ç”¨äºPyTorchï¼‰ã€‚"
                "0è¡¨ç¤ºæ•°æ®å°†åœ¨ä¸»è¿›ç¨‹ä¸­åŠ è½½ã€‚"
            )
        },
    )
    dataloader_prefetch_factor: Optional[int] = field(
        default=None if not is_torch_available() or is_torch_greater_or_equal_than_2_0 else 2,
        metadata={
            "help": (
                "æ¯ä¸ªå·¥ä½œè¿›ç¨‹é¢„åŠ è½½çš„æ‰¹æ¬¡æ•°ã€‚"
                "2è¡¨ç¤ºæ¯ä¸ªå·¥ä½œè¿›ç¨‹é¢„åŠ è½½2 * num_workersæ‰¹æ¬¡ã€‚"
                "å¯¹äºPyTorch < 2.0.0ï¼Œé»˜è®¤ä¸º2ï¼Œå¦åˆ™ä¸ºNoneã€‚"
            )
        },
    )
    past_index: int = field(
        default=-1,
        metadata={"help": "å¦‚æœ >= 0ï¼Œåˆ™ä½¿ç”¨è¾“å‡ºçš„ç›¸åº”éƒ¨åˆ†ä½œä¸ºä¸‹ä¸€æ­¥çš„è¿‡å»çŠ¶æ€ã€‚"},
    )

    run_name: Optional[str] = field(
        default=None, metadata={"help": "è¿è¡Œçš„å¯é€‰æè¿°ç¬¦ã€‚ä¸»è¦ç”¨äºwandbæ—¥å¿—è®°å½•ã€‚"}
    )
    disable_tqdm: Optional[bool] = field(
        default=None, metadata={"help": "æ˜¯å¦ç¦ç”¨tqdmè¿›åº¦æ¡ã€‚"}
    )

    remove_unused_columns: Optional[bool] = field(
        default=True, metadata={"help": "åœ¨ä½¿ç”¨nlp.Datasetæ—¶ï¼Œç§»é™¤æ¨¡å‹ä¸éœ€è¦çš„åˆ—ã€‚"}
    )
    label_names: Optional[List[str]] = field(
        default=None, metadata={"help": "è¾“å…¥å­—å…¸ä¸­ä¸æ ‡ç­¾å¯¹åº”çš„é”®åˆ—è¡¨ã€‚"}
    )
    load_best_model_at_end: Optional[bool] = field(
        default=False,
        metadata={
            "help": (
                "Whether or not to load the best model found during training at the end of training. When this option"
                " is enabled, the best checkpoint will always be saved. See `save_total_limit` for more."
            )
        },
    )
    # æ˜¯å¦åœ¨è®­ç»ƒç»“æŸæ—¶åŠ è½½æ‰¾åˆ°çš„æœ€ä½³æ¨¡å‹ã€‚å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œå§‹ç»ˆä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹ã€‚è¯¦è§ `save_total_limit`ã€‚
    
    metric_for_best_model: Optional[str] = field(
        default=None, metadata={"help": "The metric to use to compare two different models."}
    )
    # ç”¨äºæ¯”è¾ƒä¸¤ä¸ªä¸åŒæ¨¡å‹çš„åº¦é‡æ ‡å‡†ã€‚

    greater_is_better: Optional[bool] = field(
        default=None, metadata={"help": "Whether the `metric_for_best_model` should be maximized or not."}
    )
    # æ˜¯å¦åº”æœ€å¤§åŒ– `metric_for_best_model`ã€‚

    ignore_data_skip: bool = field(
        default=False,
        metadata={
            "help": (
                "When resuming training, whether or not to skip the first epochs and batches to get to the same"
                " training data."
            )
        },
    )
    # åœ¨æ¢å¤è®­ç»ƒæ—¶ï¼Œæ˜¯å¦è·³è¿‡åˆå§‹çš„è‹¥å¹²è½®æ¬¡å’Œæ‰¹æ¬¡ï¼Œä»¥è¾¾åˆ°ç›¸åŒçš„è®­ç»ƒæ•°æ®ã€‚

    fsdp: Optional[Union[List[FSDPOption], str]] = field(
        default="",
        metadata={
            "help": (
                "Whether or not to use PyTorch Fully Sharded Data Parallel (FSDP) training (in distributed training"
                " only). The base option should be `full_shard`, `shard_grad_op` or `no_shard` and you can add"
                " CPU-offload to `full_shard` or `shard_grad_op` like this: full_shard offload` or `shard_grad_op"
                " offload`. You can add auto-wrap to `full_shard` or `shard_grad_op` with the same syntax: full_shard"
                " auto_wrap` or `shard_grad_op auto_wrap`."
            ),
        },
    )
    # æ˜¯å¦ä½¿ç”¨ PyTorch å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œï¼ˆFSDPï¼‰è®­ç»ƒï¼ˆä»…é™åˆ†å¸ƒå¼è®­ç»ƒï¼‰ã€‚åŸºæœ¬é€‰é¡¹åº”ä¸º `full_shard`ã€`shard_grad_op` æˆ– `no_shard`ï¼Œ
    # å¯ä»¥å¦‚ä¸‹æ–¹å¼æ·»åŠ  CPU-offload åˆ° `full_shard` æˆ– `shard_grad_op`ï¼š`full_shard offload` æˆ– `shard_grad_op offload`ã€‚
    # å¯ä»¥ä½¿ç”¨ç›¸åŒçš„è¯­æ³•ä¸º `full_shard` æˆ– `shard_grad_op` æ·»åŠ è‡ªåŠ¨åŒ…è£…ï¼š`full_shard auto_wrap` æˆ– `shard_grad_op auto_wrap`ã€‚

    fsdp_min_num_params: int = field(
        default=0,
        metadata={
            "help": (
                "This parameter is deprecated. FSDP's minimum number of parameters for Default Auto Wrapping. (useful"
                " only when `fsdp` field is passed)."
            )
        },
    )
    # æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚FSDP çš„é»˜è®¤è‡ªåŠ¨åŒ…è£…æœ€å°å‚æ•°æ•°é‡ã€‚ï¼ˆä»…å½“ä¼ é€’ `fsdp` å­—æ®µæ—¶æœ‰æ•ˆï¼‰ã€‚

    # Do not touch this type annotation or it will stop working in CLI
    fsdp_config: Optional[Union[dict, str]] = field(
        default=None,
        metadata={
            "help": (
                "Config to be used with FSDP (Pytorch Fully Sharded  Data Parallel). The value is either a "
                "fsdp json config file (e.g., `fsdp_config.json`) or an already loaded json file as `dict`."
            )
        },
    )
    # ç”¨äº FSDPï¼ˆPytorch å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œï¼‰çš„é…ç½®ã€‚å€¼å¯ä»¥æ˜¯ fsdp çš„ JSON é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ `fsdp_config.json`ï¼‰æˆ–å·²åŠ è½½çš„ `dict`ã€‚

    fsdp_transformer_layer_cls_to_wrap: Optional[str] = field(
        default=None,
        metadata={
            "help": (
                "This parameter is deprecated. Transformer layer class name (case-sensitive) to wrap, e.g,"
                " `BertLayer`, `GPTJBlock`, `T5Block` .... (useful only when `fsdp` flag is passed)."
            )
        },
    )
    # æ­¤å‚æ•°å·²å¼ƒç”¨ã€‚è¦åŒ…è£…çš„ Transformer å±‚ç±»åï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼Œä¾‹å¦‚ `BertLayer`ã€`GPTJBlock`ã€`T5Block` ...... ï¼ˆä»…å½“ä¼ é€’ `fsdp` æ ‡å¿—æ—¶æœ‰æ•ˆï¼‰ã€‚

    # Do not touch this type annotation or it will stop working in CLI
    accelerator_config: Optional[str] = field(
        default=None,
        metadata={
            "help": (
                "Config to be used with the internal Accelerator object initializtion. The value is either a "
                "accelerator json config file (e.g., `accelerator_config.json`) or an already loaded json file as `dict`."
            )
        },
    )
    # accelerator_configå‚æ•°ï¼Œç”¨äºå†…éƒ¨åŠ é€Ÿå™¨å¯¹è±¡åˆå§‹åŒ–çš„é…ç½®
    deepspeed: Optional[str] = field(
        default=None,
        metadata={
            "help": (
                "Enable deepspeed and pass the path to deepspeed json config file (e.g. `ds_config.json`) or an already"
                " loaded json file as a dict"
            )
        },
    )
    # deepspeedå‚æ•°ï¼Œç”¨äºå¯ç”¨deepspeedå¹¶ä¼ é€’deepspeed jsoné…ç½®æ–‡ä»¶çš„è·¯å¾„æˆ–å·²åŠ è½½çš„jsonæ–‡ä»¶ä½œä¸ºå­—å…¸
    label_smoothing_factor: float = field(
        default=0.0, metadata={"help": "The label smoothing epsilon to apply (zero means no label smoothing)."}
    )
    # label_smoothing_factorå‚æ•°ï¼Œç”¨äºåº”ç”¨æ ‡ç­¾å¹³æ»‘çš„Îµå€¼ï¼ˆé›¶è¡¨ç¤ºä¸è¿›è¡Œæ ‡ç­¾å¹³æ»‘ï¼‰

    default_optim = "adamw_torch"
    # é»˜è®¤ä¼˜åŒ–å™¨è®¾å®šä¸º"adamw_torch"
    # XXX: enable when pytorch==2.0.1 comes out - we want to give it time to get all the bugs sorted out
    # if is_torch_available() and version.parse(version.parse(torch.__version__).base_version) >= version.parse("2.1.0"):
    #     default_optim = "adamw_torch_fused"
    # and update the doc above to:
    # optim (`str` or [`training_args.OptimizerNames`], *optional*, defaults to `"adamw_torch_fused"` (for torch<2.1.0 `"adamw_torch"`):
    # å½“pytorchç‰ˆæœ¬ä¸º2.0.1æ—¶å¯ç”¨ï¼Œæˆ‘ä»¬å¸Œæœ›ç»™å®ƒè¶³å¤Ÿçš„æ—¶é—´æ¥è§£å†³æ‰€æœ‰çš„bug
    # å¦‚æœtorchå¯ç”¨ä¸”ç‰ˆæœ¬å¤§äºç­‰äº2.1.0ï¼Œåˆ™å°†é»˜è®¤ä¼˜åŒ–å™¨æ›´æ–°ä¸º"adamw_torch_fused"ï¼Œå¦åˆ™ä¸º"adamw_torch"
    optim: Union[OptimizerNames, str] = field(
        default=default_optim,
        metadata={"help": "The optimizer to use."},
    )
    # optimå‚æ•°ï¼Œç”¨äºæŒ‡å®šè¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨
    optim_args: Optional[str] = field(default=None, metadata={"help": "Optional arguments to supply to optimizer."})
    # optim_argså‚æ•°ï¼Œç”¨äºä¼ é€’ç»™ä¼˜åŒ–å™¨çš„å¯é€‰å‚æ•°
    adafactor: bool = field(default=False, metadata={"help": "Whether or not to replace AdamW by Adafactor."})
    # adafactorå‚æ•°ï¼Œç”¨äºæŒ‡å®šæ˜¯å¦ä½¿ç”¨Adafactoræ›¿ä»£AdamW
    group_by_length: bool = field(
        default=False,
        metadata={"help": "Whether or not to group samples of roughly the same length together when batching."},
    )
    # group_by_lengthå‚æ•°ï¼Œç”¨äºæŒ‡å®šæ˜¯å¦åœ¨æ‰¹å¤„ç†æ—¶å°†å¤§è‡´ç›¸åŒé•¿åº¦çš„æ ·æœ¬åˆ†ç»„åœ¨ä¸€èµ·
    length_column_name: Optional[str] = field(
        default="length",
        metadata={"help": "Column name with precomputed lengths to use when grouping by length."},
    )
    # length_column_nameå‚æ•°ï¼Œç”¨äºæŒ‡å®šåœ¨æŒ‰é•¿åº¦åˆ†ç»„æ—¶ä½¿ç”¨çš„é¢„è®¡ç®—é•¿åº¦çš„åˆ—å
    report_to: Optional[List[str]] = field(
        default=None, metadata={"help": "The list of integrations to report the results and logs to."}
    )
    # report_toå‚æ•°ï¼Œç”¨äºæŒ‡å®šè¦æŠ¥å‘Šç»“æœå’Œæ—¥å¿—çš„é›†æˆåˆ—è¡¨
    ddp_find_unused_parameters: Optional[bool] = field(
        default=None,
        metadata={
            "help": (
                "When using distributed training, the value of the flag `find_unused_parameters` passed to "
                "`DistributedDataParallel`."
            )
        },
    )
    # ddp_find_unused_parameterså‚æ•°ï¼Œç”¨äºåœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ä¼ é€’ç»™`DistributedDataParallel`çš„`find_unused_parameters`æ ‡å¿—çš„å€¼
    ddp_bucket_cap_mb: Optional[int] = field(
        default=None,
        metadata={
            "help": (
                "When using distributed training, the value of the flag `bucket_cap_mb` passed to "
                "`DistributedDataParallel`."
            )
        },
    )
    # ddp_bucket_cap_mbå‚æ•°ï¼Œç”¨äºåœ¨ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ä¼ é€’ç»™`DistributedDataParallel`çš„`bucket_cap_mb`æ ‡å¿—çš„å€¼
    # ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼ŒæŒ‡å®šæ˜¯å¦å°† `broadcast_buffers` æ ‡å¿—ä¼ é€’ç»™ `DistributedDataParallel`ã€‚
    ddp_broadcast_buffers: Optional[bool] = field(
        default=None,
        metadata={
            "help": (
                "When using distributed training, the value of the flag `broadcast_buffers` passed to "
                "`DistributedDataParallel`."
            )
        },
    )

    # æ˜¯å¦ä¸º DataLoader å›ºå®šå†…å­˜ã€‚
    dataloader_pin_memory: bool = field(
        default=True, metadata={"help": "Whether or not to pin memory for DataLoader."}
    )

    # æ˜¯å¦ä¿æŒ DataLoader çš„ worker è¿›ç¨‹æŒä¹…åŒ–ï¼Œä¸åœ¨æ¯æ¬¡æ•°æ®é›†ä½¿ç”¨å®Œåå…³é—­ã€‚
    dataloader_persistent_workers: bool = field(
        default=False,
        metadata={
            "help": "If True, the data loader will not shut down the worker processes after a dataset has been consumed once. This allows to maintain the workers Dataset instances alive. Can potentially speed up training, but will increase RAM usage."
        },
    )

    # æ˜¯å¦è·³è¿‡å°†å†…å­˜åˆ†ææŠ¥å‘Šæ·»åŠ åˆ°æŒ‡æ ‡ä¸­ã€‚
    skip_memory_metrics: bool = field(
        default=True, metadata={"help": "Whether or not to skip adding of memory profiler reports to metrics."}
    )

    # æ˜¯å¦ä½¿ç”¨æ—§ç‰ˆçš„ prediction_loop åœ¨ Trainer ä¸­ã€‚
    use_legacy_prediction_loop: bool = field(
        default=False, metadata={"help": "Whether or not to use the legacy prediction_loop in the Trainer."}
    )

    # æ˜¯å¦åœ¨è®­ç»ƒç»“æŸåä¸Šä¼ è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°æ¨¡å‹ä¸­å¿ƒã€‚
    push_to_hub: bool = field(
        default=False, metadata={"help": "Whether or not to upload the trained model to the model hub after training."}
    )

    # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒçš„è·¯å¾„ã€‚
    resume_from_checkpoint: Optional[str] = field(
        default=None,
        metadata={"help": "The path to a folder with a valid checkpoint for your model."},
    )

    # ä¸æœ¬åœ° `output_dir` ä¿æŒåŒæ­¥çš„æ¨¡å‹ä¸­å¿ƒçš„åç§°ã€‚
    hub_model_id: Optional[str] = field(
        default=None, metadata={"help": "The name of the repository to keep in sync with the local `output_dir`."}
    )

    # åœ¨ `--push_to_hub` æ¿€æ´»æ—¶ä½¿ç”¨çš„æ¨¡å‹ä¸­å¿ƒç­–ç•¥ã€‚
    hub_strategy: Union[HubStrategy, str] = field(
        default="every_save",
        metadata={"help": "The hub strategy to use when `--push_to_hub` is activated."},
    )

    # ç”¨äºæ¨é€æ¨¡å‹åˆ°æ¨¡å‹ä¸­å¿ƒçš„ä»¤ç‰Œã€‚
    hub_token: Optional[str] = field(default=None, metadata={"help": "The token to use to push to the Model Hub."})

    # æ¨¡å‹å­˜å‚¨åº“æ˜¯å¦æ˜¯ç§æœ‰çš„ã€‚
    hub_private_repo: bool = field(default=False, metadata={"help": "Whether the model repository is private or not."})

    # å¦‚æœä¸º `False`ï¼Œåˆ™å¦‚æœä¸Šä¸€ä¸ªæ¨é€æœªå®Œæˆï¼ŒTrainer å°†è·³è¿‡æ¨é€ã€‚
    hub_always_push: bool = field(
        default=False,
        metadata={"help": "Unless `True`, the Trainer will skip pushes if the previous one wasn't finished yet."},
    )

    # æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æ¥èŠ‚çœå†…å­˜ï¼Œå°½ç®¡ä¼šå¯¼è‡´åå‘ä¼ æ’­é€Ÿåº¦å˜æ…¢ã€‚
    gradient_checkpointing: bool = field(
        default=False,
        metadata={
            "help": "If True, use gradient checkpointing to save memory at the expense of slower backward pass."
        },
    )

    # æ¢¯åº¦æ£€æŸ¥ç‚¹çš„å…³é”®å­—å‚æ•°ï¼Œä¾‹å¦‚ `use_reentrant`ï¼Œå°†ä¼ é€’ç»™ `torch.utils.checkpoint.checkpoint` é€šè¿‡ `model.gradient_checkpointing_enable`ã€‚
    gradient_checkpointing_kwargs: Optional[dict] = field(
        default=None,
        metadata={
            "help": "Gradient checkpointing key word arguments such as `use_reentrant`. Will be passed to `torch.utils.checkpoint.checkpoint` through `model.gradient_checkpointing_enable`."
        },
    )

    # æ˜¯å¦å°†è¾“å…¥ä¼ é€’ç»™ `compute_metrics` å‡½æ•°ä»¥è®¡ç®—æŒ‡æ ‡ã€‚
    include_inputs_for_metrics: bool = field(
        default=False, metadata={"help": "Whether or not the inputs will be passed to the `compute_metrics` function."}
    )
    # å·²å¼ƒç”¨çš„å‚æ•°
    fp16_backend: str = field(
        default="auto",
        metadata={
            "help": "Deprecated. Use half_precision_backend instead",
            "choices": ["auto", "apex", "cpu_amp"],
        },
    )
    # åˆå§‹åŒ–ä¸€ä¸ªå­—ç¬¦ä¸²å­—æ®µï¼Œè¡¨ç¤ºæ··åˆç²¾åº¦è®¡ç®—çš„åç«¯é€‰æ‹©ï¼Œé»˜è®¤ä¸º"auto"ï¼Œå¯é€‰å€¼ä¸º["auto", "apex", "cpu_amp"]ã€‚
    push_to_hub_model_id: Optional[str] = field(
        default=None, metadata={"help": "The name of the repository to which push the `Trainer`."}
    )
    # å¯é€‰çš„å­—ç¬¦ä¸²å­—æ®µï¼Œç”¨äºæŒ‡å®šè¦æ¨é€åˆ°çš„æ¨¡å‹ä»“åº“çš„åç§°ã€‚
    push_to_hub_organization: Optional[str] = field(
        default=None, metadata={"help": "The name of the organization in with to which push the `Trainer`."}
    )
    # å¯é€‰çš„å­—ç¬¦ä¸²å­—æ®µï¼Œç”¨äºæŒ‡å®šè¦æ¨é€åˆ°çš„ç»„ç»‡çš„åç§°ã€‚
    push_to_hub_token: Optional[str] = field(
        default=None, metadata={"help": "The token to use to push to the Model Hub."}
    )
    # å¯é€‰çš„å­—ç¬¦ä¸²å­—æ®µï¼Œç”¨äºæŒ‡å®šç”¨äºæ¨é€åˆ°æ¨¡å‹ä¸­å¿ƒçš„ä»¤ç‰Œã€‚
    _n_gpu: int = field(init=False, repr=False, default=-1)
    # ä¸å¯åˆå§‹åŒ–å’Œä¸å¯æ˜¾ç¤ºçš„æ•´æ•°å­—æ®µï¼Œè¡¨ç¤ºGPUçš„æ•°é‡ï¼Œé»˜è®¤ä¸º-1ã€‚
    mp_parameters: str = field(
        default="",
        metadata={"help": "Used by the SageMaker launcher to send mp-specific args. Ignored in Trainer"},
    )
    # å­—ç¬¦ä¸²å­—æ®µï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œç”¨äºSageMakerå¯åŠ¨å™¨å‘é€ç‰¹å®šçš„å¤šè¿›ç¨‹å‚æ•°ï¼ŒTrainerä¸­è¢«å¿½ç•¥ã€‚

    auto_find_batch_size: bool = field(
        default=False,
        metadata={
            "help": (
                "Whether to automatically decrease the batch size in half and rerun the training loop again each time"
                " a CUDA Out-of-Memory was reached"
            )
        },
    )
    # å¸ƒå°”å­—æ®µï¼Œé»˜è®¤ä¸ºFalseï¼Œæ§åˆ¶æ˜¯å¦åœ¨æ¯æ¬¡CUDAå†…å­˜æº¢å‡ºæ—¶è‡ªåŠ¨å‡å°‘æ‰¹é‡å¤§å°å¹¶é‡æ–°è¿è¡Œè®­ç»ƒå¾ªç¯ã€‚
    full_determinism: bool = field(
        default=False,
        metadata={
            "help": (
                "Whether to call enable_full_determinism instead of set_seed for reproducibility in distributed"
                " training. Important: this will negatively impact the performance, so only use it for debugging."
            )
        },
    )
    # å¸ƒå°”å­—æ®µï¼Œé»˜è®¤ä¸ºFalseï¼Œæ§åˆ¶æ˜¯å¦åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ä½¿ç”¨enable_full_determinismè€Œä¸æ˜¯set_seedæ¥å®ç°å¯é‡å¤æ€§ã€‚
    torchdynamo: Optional[str] = field(
        default=None,
        metadata={
            "help": "This argument is deprecated, use `--torch_compile_backend` instead.",
        },
    )
    # å¯é€‰çš„å­—ç¬¦ä¸²å­—æ®µï¼Œå·²åºŸå¼ƒï¼Œå»ºè®®ä½¿ç”¨`--torch_compile_backend`ä»£æ›¿ã€‚
    ray_scope: Optional[str] = field(
        default="last",
        metadata={
            "help": (
                'The scope to use when doing hyperparameter search with Ray. By default, `"last"` will be used. Ray'
                " will then use the last checkpoint of all trials, compare those, and select the best one. However,"
                " other options are also available. See the Ray documentation"
                " (https://docs.ray.io/en/latest/tune/api_docs/analysis.html"
                "#ray.tune.ExperimentAnalysis.get_best_trial)"
                " for more options."
            )
        },
    )
    # å¯é€‰çš„å­—ç¬¦ä¸²å­—æ®µï¼Œé»˜è®¤ä¸º"last"ï¼Œç”¨äºåœ¨ä½¿ç”¨Rayè¿›è¡Œè¶…å‚æ•°æœç´¢æ—¶æŒ‡å®šä½œç”¨åŸŸã€‚
    ddp_timeout: Optional[int] = field(
        default=1800,
        metadata={
            "help": "Overrides the default timeout for distributed training (value should be given in seconds)."
        },
    )
    # å¯é€‰çš„æ•´æ•°å­—æ®µï¼Œé»˜è®¤ä¸º1800ï¼Œç”¨äºè¦†ç›–åˆ†å¸ƒå¼è®­ç»ƒçš„é»˜è®¤è¶…æ—¶æ—¶é—´ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰ã€‚
    torch_compile: bool = field(
        default=False, metadata={"help": "If set to `True`, the model will be wrapped in `torch.compile`."}
    )
    # å¸ƒå°”å­—æ®µï¼Œé»˜è®¤ä¸ºFalseï¼Œå¦‚æœè®¾ç½®ä¸ºTrueï¼Œæ¨¡å‹å°†è¢«åŒ…è£…åœ¨torch.compileä¸­ã€‚
    torch_compile_backend: Optional[str] = field(
        default=None,
        metadata={
            "help": "Which backend to use with `torch.compile`, passing one will trigger a model compilation.",
        },
    )
    # å¯é€‰çš„å­—ç¬¦ä¸²å­—æ®µï¼Œç”¨äºæŒ‡å®šåœ¨torch.compileä¸­ä½¿ç”¨çš„åç«¯ã€‚
    torch_compile_mode: Optional[str] = field(
        default=None,
        metadata={
            "help": "Which mode to use with `torch.compile`, passing one will trigger a model compilation.",
        },
    )
    # å¯é€‰çš„ç¼–è¯‘æ¨¡å¼ï¼Œç”¨äºæŒ‡å®š `torch.compile` çš„æ¨¡å¼ï¼Œä¼ å…¥ä¸€ä¸ªå€¼å°†è§¦å‘æ¨¡å‹ç¼–è¯‘ã€‚

    dispatch_batches: Optional[bool] = field(
        default=None,
        metadata={"help": "Deprecated. Pass {'dispatch_batches':VALUE} to `accelerator_config`."},
    )
    # å·²å¼ƒç”¨ã€‚é€šè¿‡å°† {'dispatch_batches':VALUE} ä¼ é€’ç»™ `accelerator_config` æ¥ä»£æ›¿ã€‚

    split_batches: Optional[bool] = field(
        default=None,
        metadata={"help": "Deprecated. Pass {'split_batches':True} to `accelerator_config`."},
    )
    # å·²å¼ƒç”¨ã€‚é€šè¿‡å°† {'split_batches':True} ä¼ é€’ç»™ `accelerator_config` æ¥ä»£æ›¿ã€‚

    include_tokens_per_second: Optional[bool] = field(
        default=False,
        metadata={"help": "If set to `True`, the speed metrics will include `tgs` (tokens per second per device)."},
    )
    # å¦‚æœè®¾ç½®ä¸º `True`ï¼Œé€Ÿåº¦æŒ‡æ ‡å°†åŒ…æ‹¬ `tgs`ï¼ˆæ¯è®¾å¤‡æ¯ç§’æ ‡è®°æ•°ï¼‰ã€‚

    include_num_input_tokens_seen: Optional[bool] = field(
        default=False,
        metadata={
            "help": "If set to `True`, will track the number of input tokens seen throughout training. (May be slower in distributed training)"
        },
    )
    # å¦‚æœè®¾ç½®ä¸º `True`ï¼Œå°†è·Ÿè¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çœ‹åˆ°çš„è¾“å…¥æ ‡è®°æ•°é‡ã€‚ï¼ˆåœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­å¯èƒ½ä¼šå˜æ…¢ï¼‰

    neftune_noise_alpha: Optional[float] = field(
        default=None,
        metadata={
            "help": "Activates neftune noise embeddings into the model. NEFTune has been proven to drastically improve model performances for instrcution fine-tuning. Check out the original paper here: https://arxiv.org/abs/2310.05914 and the original code here: https://github.com/neelsjain/NEFTune. Only supported for `PreTrainedModel` and `PeftModel` classes."
        },
    )
    # æ¿€æ´» NEFTune å™ªå£°åµŒå…¥åˆ°æ¨¡å‹ä¸­ã€‚NEFTune å·²è¢«è¯æ˜å¯ä»¥æ˜¾è‘—æ”¹å–„æŒ‡ä»¤å¾®è°ƒçš„æ¨¡å‹æ€§èƒ½ã€‚æŸ¥çœ‹åŸå§‹è®ºæ–‡ï¼šhttps://arxiv.org/abs/2310.05914 å’ŒåŸå§‹ä»£ç ï¼šhttps://github.com/neelsjain/NEFTuneã€‚ä»…æ”¯æŒ `PreTrainedModel` å’Œ `PeftModel` ç±»ã€‚

    optim_target_modules: Union[None, str, List[str]] = field(
        default=None,
        metadata={
            "help": "Target modules for the optimizer defined in the `optim` argument. Only used for the GaLore optimizer at the moment."
        },
    )
    # ç”¨äºä¼˜åŒ–å™¨ä¸­ `optim` å‚æ•°å®šä¹‰çš„ç›®æ ‡æ¨¡å—ã€‚ç›®å‰ä»…ç”¨äº GaLore ä¼˜åŒ–å™¨ã€‚

    def __str__(self):
        self_as_dict = asdict(self)

        # Remove deprecated arguments. That code should be removed once
        # those deprecated arguments are removed from TrainingArguments. (TODO: v5)
        del self_as_dict["per_gpu_train_batch_size"]
        del self_as_dict["per_gpu_eval_batch_size"]

        self_as_dict = {k: f"<{k.upper()}>" if k.endswith("_token") else v for k, v in self_as_dict.items()}

        attrs_as_str = [f"{k}={v},\n" for k, v in sorted(self_as_dict.items())]
        return f"{self.__class__.__name__}(\n{''.join(attrs_as_str)})"

    __repr__ = __str__
    # å°†å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤ºå½¢å¼çš„æ–¹æ³•å’Œå…¶ `__repr__` æ–¹æ³•çš„é‡å†™ã€‚

    @property
    def train_batch_size(self) -> int:
        """
        The actual batch size for training (may differ from `per_gpu_train_batch_size` in distributed training).
        """
        # å¦‚æœå®šä¹‰äº† per_gpu_train_batch_sizeï¼Œåˆ™å‘å‡ºè­¦å‘Šä¿¡æ¯ï¼Œå› ä¸ºè¿™ä¸ªå‚æ•°åœ¨å°†æ¥ç‰ˆæœ¬ä¸­å°†è¢«ç§»é™¤
        if self.per_gpu_train_batch_size:
            logger.warning(
                "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future "
                "version. Using `--per_device_train_batch_size` is preferred."
            )
        # æ ¹æ®æ˜¯å¦è®¾ç½®äº† per_gpu_train_batch_size æ¥ç¡®å®šæ¯ä¸ªè®¾å¤‡çš„æ‰¹å¤„ç†å¤§å°
        per_device_batch_size = self.per_gpu_train_batch_size or self.per_device_train_batch_size
        # è®¡ç®—å®é™…çš„è®­ç»ƒæ‰¹å¤„ç†å¤§å°ï¼Œè€ƒè™‘åˆ° GPU æ•°é‡
        train_batch_size = per_device_batch_size * max(1, self.n_gpu)
        return train_batch_size

    @property
    def eval_batch_size(self) -> int:
        """
        The actual batch size for evaluation (may differ from `per_gpu_eval_batch_size` in distributed training).
        """
        # å¦‚æœå®šä¹‰äº† per_gpu_eval_batch_sizeï¼Œåˆ™å‘å‡ºè­¦å‘Šä¿¡æ¯ï¼Œå› ä¸ºè¿™ä¸ªå‚æ•°åœ¨å°†æ¥ç‰ˆæœ¬ä¸­å°†è¢«ç§»é™¤
        if self.per_gpu_eval_batch_size:
            logger.warning(
                "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future "
                "version. Using `--per_device_eval_batch_size` is preferred."
            )
        # æ ¹æ®æ˜¯å¦è®¾ç½®äº† per_gpu_eval_batch_size æ¥ç¡®å®šæ¯ä¸ªè®¾å¤‡çš„æ‰¹å¤„ç†å¤§å°
        per_device_batch_size = self.per_gpu_eval_batch_size or self.per_device_eval_batch_size
        # è®¡ç®—å®é™…çš„è¯„ä¼°æ‰¹å¤„ç†å¤§å°ï¼Œè€ƒè™‘åˆ° GPU æ•°é‡
        eval_batch_size = per_device_batch_size * max(1, self.n_gpu)
        return eval_batch_size

    @property
    def ddp_timeout_delta(self) -> timedelta:
        """
        The actual timeout for torch.distributed.init_process_group since it expects a timedelta variable.
        """
        # è¿”å›ç”¨äº torch.distributed.init_process_group çš„è¶…æ—¶æ—¶é—´ï¼Œä½œä¸º timedelta å˜é‡
        return timedelta(seconds=self.ddp_timeout)

    @cached_property
    @property
    def device(self) -> "torch.device":
        """
        The device used by this process.
        """
        # ç¡®ä¿ torch è¢«æ­£ç¡®åŠ è½½
        requires_backends(self, ["torch"])
        # è¿”å›å½“å‰è¿›ç¨‹ä½¿ç”¨çš„è®¾å¤‡å¯¹è±¡
        return self._setup_devices

    @property
    def n_gpu(self):
        """
        The number of GPUs used by this process.

        Note:
            This will only be greater than one when you have multiple GPUs available but are not using distributed
            training. For distributed training, it will always be 1.
        """
        # ç¡®ä¿ torch è¢«æ­£ç¡®åŠ è½½
        requires_backends(self, ["torch"])
        # ç¡®ä¿ self._n_gpu è¢«æ­£ç¡®è®¾ç½®
        if not hasattr(self, "_n_gpu"):
            _ = self._setup_devices
        # è¿”å›å½“å‰è¿›ç¨‹ä½¿ç”¨çš„ GPU æ•°é‡
        return self._n_gpu
    def parallel_mode(self):
        """
        The current mode used for parallelism if multiple GPUs/TPU cores are available. One of:

        - `ParallelMode.NOT_PARALLEL`: no parallelism (CPU or one GPU).
        - `ParallelMode.NOT_DISTRIBUTED`: several GPUs in one single process (uses `torch.nn.DataParallel`).
        - `ParallelMode.DISTRIBUTED`: several GPUs, each having its own process (uses
          `torch.nn.DistributedDataParallel`).
        - `ParallelMode.TPU`: several TPU cores.
        """
        # ç¡®ä¿æ‰€éœ€åç«¯åº“å­˜åœ¨ï¼Œæ­¤å¤„éœ€è¦ "torch"
        requires_backends(self, ["torch"])
        # å¦‚æœå½“å‰ç¯å¢ƒæ”¯æŒ TPUï¼Œåˆ™è¿”å› TPU å¹¶è¡Œæ¨¡å¼
        if is_torch_xla_available():
            return ParallelMode.TPU
        # å¦‚æœä½¿ç”¨ SageMaker å¹¶å¯ç”¨äº†æ¨¡å‹å¹¶è¡Œï¼Œåˆ™è¿”å› SageMaker æ¨¡å‹å¹¶è¡Œæ¨¡å¼
        elif is_sagemaker_mp_enabled():
            return ParallelMode.SAGEMAKER_MODEL_PARALLEL
        # å¦‚æœä½¿ç”¨ SageMaker å¹¶å¯ç”¨äº†æ•°æ®å¹¶è¡Œï¼Œåˆ™è¿”å› SageMaker æ•°æ®å¹¶è¡Œæ¨¡å¼
        elif is_sagemaker_dp_enabled():
            return ParallelMode.SAGEMAKER_DATA_PARALLEL
        # å¦‚æœåˆ†å¸ƒå¼çŠ¶æ€å­˜åœ¨ä¸”ä¸æ˜¯æœªåˆ†å¸ƒå¼ç±»å‹ï¼Œæˆ–è€…æœ¬åœ°æ’åä¸ä¸º -1ï¼Œåˆ™è¿”å›åˆ†å¸ƒå¼å¹¶è¡Œæ¨¡å¼
        elif (
            self.distributed_state is not None and self.distributed_state.distributed_type != DistributedType.NO
        ) or (self.distributed_state is None and self.local_rank != -1):
            return ParallelMode.DISTRIBUTED
        # å¦‚æœ GPU æ•°é‡å¤§äº 1ï¼Œåˆ™è¿”å›éåˆ†å¸ƒå¼å¹¶è¡Œæ¨¡å¼
        elif self.n_gpu > 1:
            return ParallelMode.NOT_DISTRIBUTED
        # å¦åˆ™è¿”å›éå¹¶è¡Œæ¨¡å¼
        else:
            return ParallelMode.NOT_PARALLEL

    @property
    def world_size(self):
        """
        The number of processes used in parallel.
        """
        # ç¡®ä¿æ‰€éœ€åç«¯åº“å­˜åœ¨ï¼Œæ­¤å¤„éœ€è¦ "torch"
        requires_backends(self, ["torch"])
        # å¦‚æœåˆ†å¸ƒå¼çŠ¶æ€å­˜åœ¨ï¼Œåˆ™è¿”å›å¹¶è¡Œä½¿ç”¨çš„è¿›ç¨‹æ•°
        if self.distributed_state is not None:
            return self.distributed_state.num_processes
        # å¦‚æœä½¿ç”¨ SageMaker å¹¶ä¸”æœªå¯ç”¨æ‰¹æ¬¡é¢„è°ƒæ•´ï¼Œåˆ™è¿”å›æ•°æ®å¹¶è¡Œçš„å¤§å°
        elif is_sagemaker_mp_enabled():
            return smp.dp_size() if not smp.state.cfg.prescaled_batch else smp.rdp_size()
        # å¦åˆ™è¿”å›é»˜è®¤å€¼ 1
        return 1

    @property
    def process_index(self):
        """
        The index of the current process used.
        """
        # ç¡®ä¿æ‰€éœ€åç«¯åº“å­˜åœ¨ï¼Œæ­¤å¤„éœ€è¦ "torch"
        requires_backends(self, ["torch"])
        # å¦‚æœåˆ†å¸ƒå¼çŠ¶æ€å­˜åœ¨ï¼Œåˆ™è¿”å›å½“å‰è¿›ç¨‹çš„ç´¢å¼•
        if self.distributed_state is not None:
            return self.distributed_state.process_index
        # å¦‚æœä½¿ç”¨ SageMaker å¹¶ä¸”æœªå¯ç”¨æ‰¹æ¬¡é¢„è°ƒæ•´ï¼Œåˆ™è¿”å›æ•°æ®å¹¶è¡Œçš„æ’å
        elif is_sagemaker_mp_enabled():
            return smp.dp_rank() if not smp.state.cfg.prescaled_batch else smp.rdp_rank()
        # å¦åˆ™è¿”å›é»˜è®¤å€¼ 0
        return 0

    @property
    def local_process_index(self):
        """
        The index of the local process used.
        """
        # ç¡®ä¿æ‰€éœ€åç«¯åº“å­˜åœ¨ï¼Œæ­¤å¤„éœ€è¦ "torch"
        requires_backends(self, ["torch"])

        # å¦‚æœåˆ†å¸ƒå¼çŠ¶æ€å­˜åœ¨ï¼Œåˆ™è¿”å›æœ¬åœ°è¿›ç¨‹çš„ç´¢å¼•
        if self.distributed_state is not None:
            return self.distributed_state.local_process_index
        # å¦‚æœä½¿ç”¨ SageMaker å¹¶å¯ç”¨äº†æœ¬åœ°æ’åï¼Œåˆ™è¿”å›æœ¬åœ°æ’å
        elif is_sagemaker_mp_enabled():
            return smp.local_rank()
        # å¦åˆ™è¿”å›é»˜è®¤å€¼ 0
        return 0

    @property
    def should_log(self):
        """
        Whether or not the current process should produce log.
        """
        # å¦‚æœè®¾ç½®ä¸ºåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè®°å½•æ—¥å¿—ï¼Œåˆ™ä»…å½“æœ¬åœ°è¿›ç¨‹ç´¢å¼•ä¸º 0 æ—¶è¿”å› True
        if self.log_on_each_node:
            return self.local_process_index == 0
        else:
            # å¦‚æœä½¿ç”¨ SageMaker å¹¶ä¸”å½“å‰è¿›ç¨‹æ’åä¸º 0ï¼Œåˆ™è¿”å› True
            if is_sagemaker_mp_enabled():
                return smp.rank() == 0
            # å¦åˆ™ä»…å½“å½“å‰è¿›ç¨‹ç´¢å¼•ä¸º 0 æ—¶è¿”å› True
            else:
                return self.process_index == 0
    def should_save(self):
        """
        Whether or not the current process should write to disk, e.g., to save models and checkpoints.
        """
        # å¦‚æœè®¾ç½®ä¸ºåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¿å­˜ï¼Œåˆ™ä»…åœ¨æœ¬åœ°è¿›ç¨‹ç´¢å¼•ä¸º0æ—¶è¿”å›True
        if self.save_on_each_node:
            return self.local_process_index == 0
        else:
            # å¦‚æœåœ¨SageMakerå¤šè¿›ç¨‹ç¯å¢ƒä¸­å¯ç”¨äº†å¤šè¿›ç¨‹ï¼Œåˆ™ä»…åœ¨æ’åä¸º0çš„è¿›ç¨‹è¿”å›True
            if is_sagemaker_mp_enabled():
                return smp.rank() == 0
            else:
                # å¦åˆ™ï¼Œä»…åœ¨è¿›ç¨‹ç´¢å¼•ä¸º0æ—¶è¿”å›True
                return self.process_index == 0

    def get_process_log_level(self):
        """
        Returns the log level to be used depending on whether this process is the main process of node 0, main process
        of node non-0, or a non-main process.

        For the main process the log level defaults to the logging level set (`logging.WARNING` if you didn't do
        anything) unless overridden by `log_level` argument.

        For the replica processes the log level defaults to `logging.WARNING` unless overridden by `log_level_replica`
        argument.

        The choice between the main and replica process settings is made according to the return value of `should_log`.
        """
        # å°†log_levelå’Œlog_level_replicaè½¬æ¢ä¸ºæ•´æ•°
        log_level = trainer_log_levels[self.log_level]
        log_level_replica = trainer_log_levels[self.log_level_replica]

        # å¦‚æœlog_levelä¸º-1ï¼Œåˆ™ä½¿ç”¨å½“å‰æ—¥å¿—çº§åˆ«è®¾ç½®çš„è¯¦ç»†ç¨‹åº¦
        log_level_main_node = logging.get_verbosity() if log_level == -1 else log_level
        # å¦‚æœlog_level_replicaä¸º-1ï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„WARNINGæ—¥å¿—çº§åˆ«
        log_level_replica_node = logging.get_verbosity() if log_level_replica == -1 else log_level_replica
        # æ ¹æ®should_logæ–¹æ³•çš„è¿”å›å€¼é€‰æ‹©ä¸»è¿›ç¨‹æˆ–å‰¯æœ¬è¿›ç¨‹çš„æ—¥å¿—çº§åˆ«è®¾ç½®
        return log_level_main_node if self.should_log else log_level_replica_node

    @property
    def place_model_on_device(self):
        """
        Can be subclassed and overridden for some specific integrations.
        """
        # å¦‚æœæœªå¯ç”¨SageMakerå¤šè¿›ç¨‹ï¼Œåˆ™è¿”å›Trueï¼›å¦åˆ™è¿”å›False
        return not is_sagemaker_mp_enabled()

    @property
    def _no_sync_in_gradient_accumulation(self):
        """
        Whether or not to use no_sync for the gradients when doing gradient accumulation.
        """
        # å½“ä¸ä½¿ç”¨DeepSpeedã€SageMakeråˆ†å¸ƒå¼è®­ç»ƒã€SageMakerå¤šè¿›ç¨‹æˆ–Torch NeuronCoreæ—¶è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        return not (
            self.deepspeed or is_sagemaker_dp_enabled() or is_sagemaker_mp_enabled() or is_torch_neuroncore_available()
        )

    @contextlib.contextmanager
    # å®šä¹‰ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºåœ¨ Torch åˆ†å¸ƒå¼ç¯å¢ƒä¸­æ‰§è¡Œä¸»è¿›ç¨‹çš„æ“ä½œï¼Œ
    # é˜»å¡å‰¯æœ¬è¿›ç¨‹ï¼Œå¹¶åœ¨å®Œæˆåé‡Šæ”¾å‰¯æœ¬ã€‚
    def main_process_first(self, local=True, desc="work"):
        """
        A context manager for torch distributed environment where on needs to do something on the main process, while
        blocking replicas, and when it's finished releasing the replicas.

        One such use is for `datasets`'s `map` feature which to be efficient should be run once on the main process,
        which upon completion saves a cached version of results and which then automatically gets loaded by the
        replicas.

        Args:
            local (`bool`, *optional*, defaults to `True`):
                if `True` first means process of rank 0 of each node if `False` first means process of rank 0 of node
                rank 0 In multi-node environment with a shared filesystem you most likely will want to use
                `local=False` so that only the main process of the first node will do the processing. If however, the
                filesystem is not shared, then the main process of each node will need to do the processing, which is
                the default behavior.
            desc (`str`, *optional*, defaults to `"work"`):
                a work description to be used in debug logs

        """
        # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦æ”¯æŒ Torchï¼Œå¹¶ä¸”æ˜¯å¦å¤„äºåˆ†å¸ƒå¼ç¯å¢ƒä¸­
        if is_torch_available() and self.world_size > 1:
            # æ ¹æ®å‚æ•°ç¡®å®šä¸»è¿›ç¨‹çš„æè¿°ä¿¡æ¯
            main_process_desc = "main local process" if local else "main process"
            # æ ¹æ®å½“å‰çš„åˆ†å¸ƒå¼çŠ¶æ€ç¡®å®šæ˜¯å¦ä¸ºä¸»è¿›ç¨‹
            if self.distributed_state is not None:
                is_main_process = (
                    self.distributed_state.is_local_main_process if local else self.distributed_state.is_main_process
                )
            elif is_sagemaker_mp_enabled():
                is_main_process = smp.rank() == 0

            try:
                if not is_main_process:
                    # å‘ŠçŸ¥æ‰€æœ‰å‰¯æœ¬è¿›ç¨‹ç­‰å¾…
                    logger.debug(f"{self.process_index}: waiting for the {main_process_desc} to perform {desc}")

                    # å¦‚æœæ”¯æŒ Torch XLAï¼Œåˆ™ä½¿ç”¨å…¶åŒæ­¥æ–¹æ³•
                    if is_torch_xla_available():
                        xm.rendezvous(desc)
                    else:
                        # å¦åˆ™ä½¿ç”¨ Torch çš„åˆ†å¸ƒå¼ barrier
                        dist.barrier()
                # ä½¿ç”¨ yield å°†æ§åˆ¶æƒäº¤ç»™è°ƒç”¨è€…ï¼Œå…è®¸åœ¨ä¸»è¿›ç¨‹å®Œæˆåç»§ç»­æ‰§è¡Œ
                yield
            finally:
                if is_main_process:
                    # ä¸»è¿›ç¨‹å®Œæˆä»»åŠ¡ï¼Œé‡Šæ”¾æ‰€æœ‰å‰¯æœ¬
                    logger.debug(f"{self.process_index}: {main_process_desc} completed {desc}, releasing all replicas")
                    if is_torch_xla_available():
                        xm.rendezvous(desc)
                    else:
                        dist.barrier()
        else:
            # å¦‚æœä¸æ»¡è¶³åˆ†å¸ƒå¼æ¡ä»¶ï¼Œåˆ™ç›´æ¥ yield
            yield

    # è·å–çº¿æ€§é¢„çƒ­æ‰€éœ€çš„æ­¥æ•°
    def get_warmup_steps(self, num_training_steps: int):
        """
        Get number of steps used for a linear warmup.
        """
        warmup_steps = (
            self.warmup_steps if self.warmup_steps > 0 else math.ceil(num_training_steps * self.warmup_ratio)
        )
        return warmup_steps
    def to_dict(self):
        """
        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates
        the token values by removing their value.
        """
        # åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸ `d`ï¼Œç”¨äºå­˜å‚¨å®ä¾‹çš„åºåˆ—åŒ–æ•°æ®ï¼Œä»…åŒ…å«å¯ä»¥åˆå§‹åŒ–çš„å­—æ®µ
        d = {field.name: getattr(self, field.name) for field in fields(self) if field.init}

        # éå†å­—å…¸ `d` ä¸­çš„æ¯ä¸ªé”®å€¼å¯¹
        for k, v in d.items():
            # å¦‚æœå€¼ `v` æ˜¯æšä¸¾ç±»å‹ `Enum`ï¼Œåˆ™å°†å…¶æ›¿æ¢ä¸ºå…¶å€¼
            if isinstance(v, Enum):
                d[k] = v.value
            # å¦‚æœå€¼ `v` æ˜¯åˆ—è¡¨ä¸”ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æšä¸¾ç±»å‹ `Enum`ï¼Œåˆ™å°†åˆ—è¡¨ä¸­æ‰€æœ‰æšä¸¾å…ƒç´ æ›¿æ¢ä¸ºå…¶å€¼
            if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):
                d[k] = [x.value for x in v]
            # å¦‚æœé”® `k` ä»¥ "_token" ç»“å°¾ï¼Œå°†å…¶å€¼ `v` æ›¿æ¢ä¸º `<K_UPPERCASE>` å½¢å¼çš„å­—ç¬¦ä¸²
            if k.endswith("_token"):
                d[k] = f"<{k.upper()}>"
            # å¦‚æœåŠ é€Ÿå™¨é…ç½®å¯ç”¨ä¸”å€¼ `v` æ˜¯ `AcceleratorConfig` ç±»å‹ï¼Œåˆ™å°†å…¶åºåˆ—åŒ–ä¸ºå­—å…¸å½¢å¼
            if is_accelerate_available() and isinstance(v, AcceleratorConfig):
                d[k] = v.to_dict()
        return d

    def to_json_string(self):
        """
        Serializes this instance to a JSON string.
        """
        # å°†å®ä¾‹åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ï¼Œä½¿ç”¨ä¸¤ä¸ªç©ºæ ¼ç¼©è¿›
        return json.dumps(self.to_dict(), indent=2)

    def to_sanitized_dict(self) -> Dict[str, Any]:
        """
        Sanitized serialization to use with TensorBoardâ€™s hparams
        """
        # è·å–åŸå§‹çš„å­—å…¸è¡¨ç¤ºå½¢å¼
        d = self.to_dict()
        # å°†è®­ç»ƒæ‰¹æ¬¡å¤§å°å’Œè¯„ä¼°æ‰¹æ¬¡å¤§å°æ·»åŠ åˆ°å­—å…¸ `d` ä¸­
        d = {**d, **{"train_batch_size": self.train_batch_size, "eval_batch_size": self.eval_batch_size}}

        # å®šä¹‰æœ‰æ•ˆçš„æ•°æ®ç±»å‹åˆ—è¡¨
        valid_types = [bool, int, float, str]
        if is_torch_available():
            valid_types.append(torch.Tensor)

        # è¿”å›å­—å…¸ï¼Œå…¶ä¸­å€¼çš„ç±»å‹åœ¨æœ‰æ•ˆç±»å‹åˆ—è¡¨ä¸­ï¼Œå¦åˆ™è½¬æ¢ä¸ºå­—ç¬¦ä¸²å½¢å¼
        return {k: v if type(v) in valid_types else str(v) for k, v in d.items()}

    # The following methods are there to simplify the instantiation of `TrainingArguments`
    # ä¸‹é¢çš„æ–¹æ³•ç”¨äºç®€åŒ– `TrainingArguments` çš„å®ä¾‹åŒ–è®¾ç½®
    def set_training(
        self,
        learning_rate: float = 5e-5,
        batch_size: int = 8,
        weight_decay: float = 0,
        num_epochs: float = 3,
        max_steps: int = -1,
        gradient_accumulation_steps: int = 1,
        seed: int = 42,
        gradient_checkpointing: bool = False,
    ):
        """
        A method that regroups all basic arguments linked to the training.

        <Tip>

        Calling this method will automatically set `self.do_train` to `True`.

        </Tip>

        Args:
            learning_rate (`float`, *optional*, defaults to 5e-5):
                The initial learning rate for the optimizer.
            batch_size (`int` *optional*, defaults to 8):
                The batch size per device (GPU/TPU core/CPU...) used for training.
            weight_decay (`float`, *optional*, defaults to 0):
                The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in the
                optimizer.
            num_train_epochs(`float`, *optional*, defaults to 3.0):
                Total number of training epochs to perform (if not an integer, will perform the decimal part percents
                of the last epoch before stopping training).
            max_steps (`int`, *optional*, defaults to -1):
                If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.
                For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until
                `max_steps` is reached.
            gradient_accumulation_steps (`int`, *optional*, defaults to 1):
                Number of updates steps to accumulate the gradients for, before performing a backward/update pass.

                <Tip warning={true}>

                When using gradient accumulation, one step is counted as one step with backward pass. Therefore,
                logging, evaluation, save will be conducted every `gradient_accumulation_steps * xxx_step` training
                examples.

                </Tip>

            seed (`int`, *optional*, defaults to 42):
                Random seed that will be set at the beginning of training. To ensure reproducibility across runs, use
                the [`~Trainer.model_init`] function to instantiate the model if it has some randomly initialized
                parameters.
            gradient_checkpointing (`bool`, *optional*, defaults to `False`):
                If True, use gradient checkpointing to save memory at the expense of slower backward pass.

        Example:

        ```
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_training(learning_rate=1e-4, batch_size=32)
        >>> args.learning_rate
        1e-4
        ```
        """
        # è®¾ç½® self.do_train ä¸º Trueï¼Œè¡¨æ˜å°†æ‰§è¡Œè®­ç»ƒè¿‡ç¨‹
        self.do_train = True
        # è®¾ç½®åˆå§‹å­¦ä¹ ç‡
        self.learning_rate = learning_rate
        # è®¾ç½®æ¯ä¸ªè®¾å¤‡ä¸Šçš„è®­ç»ƒæ‰¹æ¬¡å¤§å°
        self.per_device_train_batch_size = batch_size
        # è®¾ç½®æƒé‡è¡°å‡
        self.weight_decay = weight_decay
        # è®¾ç½®è®­ç»ƒçš„æ€»è½®æ•°
        self.num_train_epochs = num_epochs
        # è®¾ç½®æœ€å¤§è®­ç»ƒæ­¥æ•°
        self.max_steps = max_steps
        # è®¾ç½®æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
        self.gradient_accumulation_steps = gradient_accumulation_steps
        # è®¾ç½®éšæœºç§å­
        self.seed = seed
        # è®¾ç½®æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
        self.gradient_checkpointing = gradient_checkpointing
        # è¿”å›è®¾ç½®å¥½çš„å‚æ•°å¯¹è±¡ self
        return self
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºè®¾ç½®è¯„ä¼°ç›¸å…³çš„æ‰€æœ‰å‚æ•°
    def set_evaluate(
        self,
        strategy: Union[str, IntervalStrategy] = "no",
        steps: int = 500,
        batch_size: int = 8,
        accumulation_steps: Optional[int] = None,
        delay: Optional[float] = None,
        loss_only: bool = False,
        jit_mode: bool = False,
    ):
        """
        A method that regroups all arguments linked to evaluation.

        Args:
            strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `"no"`):
                The evaluation strategy to adopt during training. Possible values are:

                    - `"no"`: No evaluation is done during training.
                    - `"steps"`: Evaluation is done (and logged) every `steps`.
                    - `"epoch"`: Evaluation is done at the end of each epoch.

                Setting a `strategy` different from `"no"` will set `self.do_eval` to `True`.
            steps (`int`, *optional*, defaults to 500):
                Number of update steps between two evaluations if `strategy="steps"`.
            batch_size (`int` *optional*, defaults to 8):
                The batch size per device (GPU/TPU core/CPU...) used for evaluation.
            accumulation_steps (`int`, *optional*):
                Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU.
                If left unset, the whole predictions are accumulated on GPU/TPU before being moved to the CPU (faster
                but requires more memory).
            delay (`float`, *optional*):
                Number of epochs or steps to wait for before the first evaluation can be performed, depending on the
                evaluation_strategy.
            loss_only (`bool`, *optional*, defaults to `False`):
                Ignores all outputs except the loss.
            jit_mode (`bool`, *optional*):
                Whether or not to use PyTorch jit trace for inference.

        Example:

        ```
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_evaluate(strategy="steps", steps=100)
        >>> args.eval_steps
        100
        ```
        """
        # å°†ä¼ å…¥çš„è¯„ä¼°ç­–ç•¥è½¬æ¢ä¸ºIntervalStrategyæšä¸¾ç±»å‹
        self.evaluation_strategy = IntervalStrategy(strategy)
        # å¦‚æœè¯„ä¼°ç­–ç•¥ä¸ºSTEPSï¼Œå¹¶ä¸”stepsè®¾ç½®ä¸º0ï¼Œåˆ™æŠ›å‡ºæ•°å€¼é”™è¯¯
        if self.evaluation_strategy == IntervalStrategy.STEPS and steps == 0:
            raise ValueError("Setting `strategy` as 'steps' requires a positive value for `steps`.")
        # æ ¹æ®è¯„ä¼°ç­–ç•¥æ˜¯å¦ä¸ºNOæ¥è®¾ç½®æ˜¯å¦è¿›è¡Œè¯„ä¼°
        self.do_eval = self.evaluation_strategy != IntervalStrategy.NO
        # è®¾ç½®è¯„ä¼°æ­¥æ•°
        self.eval_steps = steps
        # è®¾ç½®æ¯ä¸ªè®¾å¤‡çš„è¯„ä¼°æ‰¹é‡å¤§å°
        self.per_device_eval_batch_size = batch_size
        # è®¾ç½®è¯„ä¼°ç´¯ç§¯æ­¥æ•°
        self.eval_accumulation_steps = accumulation_steps
        # è®¾ç½®è¯„ä¼°å»¶è¿Ÿ
        self.eval_delay = delay
        # è®¾ç½®æ˜¯å¦åªè®¡ç®—æŸå¤±
        self.prediction_loss_only = loss_only
        # è®¾ç½®æ˜¯å¦å¯ç”¨JITæ¨¡å¼ç”¨äºè¯„ä¼°
        self.jit_mode_eval = jit_mode
        # è¿”å›å½“å‰å¯¹è±¡çš„å¼•ç”¨
        return self
    ):
        """
        A method that regroups all basic arguments linked to testing on a held-out dataset.

        <Tip>

        Calling this method will automatically set `self.do_predict` to `True`.

        </Tip>

        Args:
            batch_size (`int` *optional*, defaults to 8):
                The batch size per device (GPU/TPU core/CPU...) used for testing.
            loss_only (`bool`, *optional*, defaults to `False`):
                Ignores all outputs except the loss.
            jit_mode (`bool`, *optional*):
                Whether or not to use PyTorch jit trace for inference.

        Example:

        ```
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_testing(batch_size=32)
        >>> args.per_device_eval_batch_size
        32
        ```
        """
        # å°†self.do_predictè®¾ç½®ä¸ºTrueï¼Œè¡¨ç¤ºåœ¨è°ƒç”¨æ­¤æ–¹æ³•åè¿›è¡Œé¢„æµ‹
        self.do_predict = True
        # è®¾ç½®æ¯ä¸ªè®¾å¤‡ï¼ˆGPU/TPUæ ¸å¿ƒ/CPU...ï¼‰ç”¨äºæµ‹è¯•çš„æ‰¹å¤„ç†å¤§å°
        self.per_device_eval_batch_size = batch_size
        # è®¾ç½®æ˜¯å¦ä»…è®¡ç®—é¢„æµ‹æŸå¤±ï¼Œå¿½ç•¥æ‰€æœ‰å…¶ä»–è¾“å‡º
        self.prediction_loss_only = loss_only
        # è®¾ç½®æ˜¯å¦ä½¿ç”¨PyTorchçš„jitè¿½è¸ªè¿›è¡Œæ¨æ–­
        self.jit_mode_eval = jit_mode
        # è¿”å›è®¾ç½®åçš„å¯¹è±¡æœ¬èº«ï¼Œä»¥æ”¯æŒæ–¹æ³•é“¾å¼è°ƒç”¨
        return self
    ):
        """
        A method that regroups all arguments linked to checkpoint saving.

        Args:
            strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `"steps"`):
                The checkpoint save strategy to adopt during training. Possible values are:

                    - `"no"`: No save is done during training.
                    - `"epoch"`: Save is done at the end of each epoch.
                    - `"steps"`: Save is done every `save_steps`.

            steps (`int`, *optional*, defaults to 500):
                Number of updates steps before two checkpoint saves if `strategy="steps"`.
            total_limit (`int`, *optional*):
                If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in
                `output_dir`.
            on_each_node (`bool`, *optional*, defaults to `False`):
                When doing multi-node distributed training, whether to save models and checkpoints on each node, or
                only on the main one.

                This should not be activated when the different nodes use the same storage as the files will be saved
                with the same names for each node.

        Example:

        ```
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_save(strategy="steps", steps=100)
        >>> args.save_steps
        100
        ```
        """
        self.save_strategy = IntervalStrategy(strategy)
        # è®¾ç½®ä¿å­˜ç­–ç•¥ä¸ºæŒ‡å®šçš„ç­–ç•¥ç±»å‹
        if self.save_strategy == IntervalStrategy.STEPS and steps == 0:
            raise ValueError("Setting `strategy` as 'steps' requires a positive value for `steps`.")
        # å¦‚æœä¿å­˜ç­–ç•¥ä¸ºæ­¥æ•°ï¼Œå¹¶ä¸”æ­¥æ•°è®¾ç½®ä¸º0ï¼Œåˆ™æŠ›å‡ºæ•°å€¼é”™è¯¯
        self.save_steps = steps
        # è®¾ç½®ä¿å­˜æ­¥æ•°
        self.save_total_limit = total_limit
        # è®¾ç½®æ€»å…±ä¿å­˜çš„æœ€å¤§æ•°é‡é™åˆ¶
        self.save_on_each_node = on_each_node
        # è®¾ç½®æ˜¯å¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šä¿å­˜æ¨¡å‹å’Œæ£€æŸ¥ç‚¹
        return self
        # è¿”å›å½“å‰å®ä¾‹åŒ–å¯¹è±¡ï¼Œä»¥ä¾¿æ”¯æŒé“¾å¼è°ƒç”¨
    def set_logging(
        self,
        strategy: Union[str, IntervalStrategy] = "steps",
        steps: int = 500,
        report_to: Union[str, List[str]] = "none",
        level: str = "passive",
        first_step: bool = False,
        nan_inf_filter: bool = False,
        on_each_node: bool = False,
        replica_level: str = "passive",
    def set_push_to_hub(
        self,
        model_id: str,
        strategy: Union[str, HubStrategy] = "every_save",
        token: Optional[str] = None,
        private_repo: bool = False,
        always_push: bool = False,
    def set_optimizer(
        self,
        name: Union[str, OptimizerNames] = "adamw_torch",
        learning_rate: float = 5e-5,
        weight_decay: float = 0,
        beta1: float = 0.9,
        beta2: float = 0.999,
        epsilon: float = 1e-8,
        args: Optional[str] = None,
    ):
        """
        A method that regroups all arguments linked to the optimizer and its hyperparameters.

        Args:
            name (`str` or [`training_args.OptimizerNames`], *optional*, defaults to `"adamw_torch"`):
                The optimizer to use: `"adamw_hf"`, `"adamw_torch"`, `"adamw_torch_fused"`, `"adamw_apex_fused"`,
                `"adamw_anyprecision"` or `"adafactor"`.
            learning_rate (`float`, *optional*, defaults to 5e-5):
                The initial learning rate.
            weight_decay (`float`, *optional*, defaults to 0):
                The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights.
            beta1 (`float`, *optional*, defaults to 0.9):
                The beta1 hyperparameter for the adam optimizer or its variants.
            beta2 (`float`, *optional*, defaults to 0.999):
                The beta2 hyperparameter for the adam optimizer or its variants.
            epsilon (`float`, *optional*, defaults to 1e-8):
                The epsilon hyperparameter for the adam optimizer or its variants.
            args (`str`, *optional*):
                Optional arguments that are supplied to AnyPrecisionAdamW (only useful when
                `optim="adamw_anyprecision"`).

        Example:

        ```
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_optimizer(name="adamw_torch", beta1=0.8)
        >>> args.optim
        'adamw_torch'
        ```
        """
        # è®¾ç½®ä¼˜åŒ–å™¨åç§°ï¼Œå°†è¾“å…¥çš„åç§°è½¬æ¢ä¸º OptimizerNames å¯¹è±¡
        self.optim = OptimizerNames(name)
        # è®¾ç½®åˆå§‹å­¦ä¹ ç‡
        self.learning_rate = learning_rate
        # è®¾ç½®æƒé‡è¡°å‡ç‡ï¼Œåº”ç”¨äºé™¤æ‰€æœ‰åç½®å’Œ LayerNorm æƒé‡ä»¥å¤–çš„æ‰€æœ‰å±‚
        self.weight_decay = weight_decay
        # è®¾ç½® adam ä¼˜åŒ–å™¨åŠå…¶å˜ä½“çš„ beta1 å‚æ•°
        self.adam_beta1 = beta1
        # è®¾ç½® adam ä¼˜åŒ–å™¨åŠå…¶å˜ä½“çš„ beta2 å‚æ•°
        self.adam_beta2 = beta2
        # è®¾ç½® adam ä¼˜åŒ–å™¨åŠå…¶å˜ä½“çš„ epsilon å‚æ•°
        self.adam_epsilon = epsilon
        # è®¾ç½®ä¼˜åŒ–å™¨çš„é¢å¤–å‚æ•°
        self.optim_args = args
        # è¿”å›å½“å‰å¯¹è±¡ï¼Œä»¥æ”¯æŒæ–¹æ³•é“¾è°ƒç”¨
        return self
    ):
        """
        A method that regroups all arguments linked to the learning rate scheduler and its hyperparameters.

        Args:
            name (`str` or [`SchedulerType`], *optional*, defaults to `"linear"`):
                The scheduler type to use. See the documentation of [`SchedulerType`] for all possible values.
            num_epochs(`float`, *optional*, defaults to 3.0):
                Total number of training epochs to perform (if not an integer, will perform the decimal part percents
                of the last epoch before stopping training).
            max_steps (`int`, *optional*, defaults to -1):
                If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.
                For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until
                `max_steps` is reached.
            warmup_ratio (`float`, *optional*, defaults to 0.0):
                Ratio of total training steps used for a linear warmup from 0 to `learning_rate`.
            warmup_steps (`int`, *optional*, defaults to 0):
                Number of steps used for a linear warmup from 0 to `learning_rate`. Overrides any effect of
                `warmup_ratio`.

        Example:

        ```
        >>> from transformers import TrainingArguments

        >>> args = TrainingArguments("working_dir")
        >>> args = args.set_lr_scheduler(name="cosine", warmup_ratio=0.05)
        >>> args.warmup_ratio
        0.05
        ```
        """
        # è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨ç±»å‹
        self.lr_scheduler_type = SchedulerType(name)
        # è®¾ç½®è®­ç»ƒçš„æ€»è½®æ¬¡
        self.num_train_epochs = num_epochs
        # è®¾ç½®æœ€å¤§è®­ç»ƒæ­¥æ•°
        self.max_steps = max_steps
        # è®¾ç½®çº¿æ€§é¢„çƒ­çš„æ¯”ä¾‹
        self.warmup_ratio = warmup_ratio
        # è®¾ç½®çº¿æ€§é¢„çƒ­çš„æ­¥æ•°
        self.warmup_steps = warmup_steps
        # è¿”å›è®¾ç½®åçš„å¯¹è±¡æœ¬èº«
        return self

    def set_dataloader(
        self,
        train_batch_size: int = 8,
        eval_batch_size: int = 8,
        drop_last: bool = False,
        num_workers: int = 0,
        pin_memory: bool = True,
        persistent_workers: bool = False,
        prefetch_factor: Optional[int] = None,
        auto_find_batch_size: bool = False,
        ignore_data_skip: bool = False,
        sampler_seed: Optional[int] = None,
# å®šä¹‰ä¸€ä¸ªæšä¸¾ç±» ParallelModeï¼Œç”¨äºè¡¨ç¤ºå¹¶è¡Œè®¡ç®—æ¨¡å¼çš„é€‰é¡¹
class ParallelMode(Enum):
    # è¡¨ç¤ºéå¹¶è¡Œæ¨¡å¼
    NOT_PARALLEL = "not_parallel"
    # è¡¨ç¤ºéåˆ†å¸ƒå¼æ¨¡å¼
    NOT_DISTRIBUTED = "not_distributed"
    # è¡¨ç¤ºåˆ†å¸ƒå¼æ¨¡å¼
    DISTRIBUTED = "distributed"
    # è¡¨ç¤ºä½¿ç”¨Sagemakerçš„æ¨¡å‹å¹¶è¡Œè®¡ç®—æ¨¡å¼
    SAGEMAKER_MODEL_PARALLEL = "sagemaker_model_parallel"
    # è¡¨ç¤ºä½¿ç”¨Sagemakerçš„æ•°æ®å¹¶è¡Œè®¡ç®—æ¨¡å¼
    SAGEMAKER_DATA_PARALLEL = "sagemaker_data_parallel"
    # è¡¨ç¤ºä½¿ç”¨TPUè¿›è¡Œè®¡ç®—
    TPU = "tpu"
```