# `.\transformers\utils\import_utils.py`

```
# ç‰ˆæƒå£°æ˜å’Œè®¸å¯è¯ä¿¡æ¯
# ç‰ˆæƒå£°æ˜å’Œè®¸å¯è¯ä¿¡æ¯ï¼ŒæŒ‡å®šäº†ä»£ç çš„ç‰ˆæƒå’Œè®¸å¯è¯ä¿¡æ¯
# è¯¦ç»†ä¿¡æ¯å¯åœ¨ http://www.apache.org/licenses/LICENSE-2.0 è·å–

"""
å¯¼å…¥å·¥å…·ï¼šä¸å¯¼å…¥å’Œæ‡’åŠ è½½ç›¸å…³çš„å·¥å…·ã€‚
"""

# å¯¼å…¥æ¨¡å—
import importlib.metadata
import importlib.util
import json
import os
import shutil
import subprocess
import sys
import warnings
from collections import OrderedDict
from functools import lru_cache
from itertools import chain
from types import ModuleType
from typing import Any, Tuple, Union

# å¯¼å…¥ packaging æ¨¡å—ä¸­çš„ version ç±»
from packaging import version

# å¯¼å…¥ logging æ¨¡å—
from . import logging

# è·å– logger å¯¹è±¡
logger = logging.get_logger(__name__)  # pylint: disable=invalid-name

# æ£€æŸ¥æŒ‡å®šåŒ…æ˜¯å¦å¯ç”¨
def _is_package_available(pkg_name: str, return_version: bool = False) -> Union[Tuple[bool, str], bool]:
    # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰¾åˆ°æŒ‡å®šåŒ…çš„è§„èŒƒ
    package_exists = importlib.util.find_spec(pkg_name) is not None
    package_version = "N/A"
    if package_exists:
        try:
            # å°è¯•è·å–æŒ‡å®šåŒ…çš„ç‰ˆæœ¬ä¿¡æ¯
            package_version = importlib.metadata.version(pkg_name)
            package_exists = True
        except importlib.metadata.PackageNotFoundError:
            package_exists = False
        logger.debug(f"Detected {pkg_name} version {package_version}")
    if return_version:
        return package_exists, package_version
    else:
        return package_exists

# ç¯å¢ƒå˜é‡ä¸­è¡¨ç¤º True çš„å€¼é›†åˆ
ENV_VARS_TRUE_VALUES = {"1", "ON", "YES", "TRUE"}
# ç¯å¢ƒå˜é‡ä¸­è¡¨ç¤º True å’Œ AUTO çš„å€¼é›†åˆ
ENV_VARS_TRUE_AND_AUTO_VALUES = ENV_VARS_TRUE_VALUES.union({"AUTO"})

# è·å–ç¯å¢ƒå˜é‡ USE_TFã€USE_TORCHã€USE_JAX çš„å€¼
USE_TF = os.environ.get("USE_TF", "AUTO").upper()
USE_TORCH = os.environ.get("USE_TORCH", "AUTO").upper()
USE_JAX = os.environ.get("USE_FLAX", "AUTO").upper()

# è·å–ç¯å¢ƒå˜é‡ FORCE_TF_AVAILABLE çš„å€¼
FORCE_TF_AVAILABLE = os.environ.get("FORCE_TF_AVAILABLE", "AUTO").upper()

# `transformers` éœ€è¦ `torch>=1.11`ï¼Œä½†è¿™ä¸ªå˜é‡æ˜¯å…¬å¼€çš„ï¼Œä¸èƒ½ç®€å•åœ°åˆ é™¤å®ƒã€‚
# è¿è¡Œ torch.fx ç‰¹æ€§å’Œ torch.onnx éœ€è¦çš„ torch ç‰ˆæœ¬ã€‚
TORCH_FX_REQUIRED_VERSION = version.parse("1.10")

# åŠ é€Ÿåº“çš„æœ€å°ç‰ˆæœ¬è¦æ±‚
ACCELERATE_MIN_VERSION = "0.21.0"
# FSDP çš„æœ€å°ç‰ˆæœ¬è¦æ±‚
FSDP_MIN_VERSION = "1.12.0"

# æ£€æŸ¥ accelerate åŒ…æ˜¯å¦å¯ç”¨ï¼Œå¹¶è·å–å…¶ç‰ˆæœ¬ä¿¡æ¯
_accelerate_available, _accelerate_version = _is_package_available("accelerate", return_version=True)
# æ£€æŸ¥ apex åŒ…æ˜¯å¦å¯ç”¨
_apex_available = _is_package_available("apex")
# æ£€æŸ¥ bitsandbytes åŒ…æ˜¯å¦å¯ç”¨
_bitsandbytes_available = _is_package_available("bitsandbytes")
# å¯¹äº bs4 åŒ…ï¼Œ`importlib.metadata.version` æ— æ³•ä½¿ç”¨ï¼Œéœ€è¦ä½¿ç”¨ `beautifulsoup4`ã€‚
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `bs4` æ¨¡å—
_bs4_available = importlib.util.find_spec("bs4") is not None
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `coloredlogs` æ¨¡å—
_coloredlogs_available = _is_package_available("coloredlogs")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `cv2` æ¨¡å—
_cv2_available = importlib.util.find_spec("cv2") is not None
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `datasets` æ¨¡å—
_datasets_available = _is_package_available("datasets")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `decord` æ¨¡å—
_decord_available = importlib.util.find_spec("decord") is not None
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `detectron2` æ¨¡å—
_detectron2_available = _is_package_available("detectron2")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `faiss` æˆ– `faiss-cpu` æ¨¡å—
_faiss_available = importlib.util.find_spec("faiss") is not None
# å°è¯•è·å– `faiss` æˆ– `faiss-cpu` æ¨¡å—çš„ç‰ˆæœ¬ä¿¡æ¯
try:
    _faiss_version = importlib.metadata.version("faiss")
    logger.debug(f"Successfully imported faiss version {_faiss_version}")
except importlib.metadata.PackageNotFoundError:
    try:
        _faiss_version = importlib.metadata.version("faiss-cpu")
        logger.debug(f"Successfully imported faiss version {_faiss_version}")
    except importlib.metadata.PackageNotFoundError:
        _faiss_available = False
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `ftfy` æ¨¡å—
_ftfy_available = _is_package_available("ftfy")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `g2p_en` æ¨¡å—
_g2p_en_available = _is_package_available("g2p_en")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `intel_extension_for_pytorch` æ¨¡å—ï¼Œå¹¶è·å–ç‰ˆæœ¬ä¿¡æ¯
_ipex_available, _ipex_version = _is_package_available("intel_extension_for_pytorch", return_version=True)
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `jieba` æ¨¡å—
_jieba_available = _is_package_available("jieba")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `jinja2` æ¨¡å—
_jinja_available = _is_package_available("jinja2")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `kenlm` æ¨¡å—
_kenlm_available = _is_package_available("kenlm")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `keras_nlp` æ¨¡å—
_keras_nlp_available = _is_package_available("keras_nlp")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `Levenshtein` æ¨¡å—
_levenshtein_available = _is_package_available("Levenshtein")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `librosa` æ¨¡å—
_librosa_available = _is_package_available("librosa")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `natten` æ¨¡å—
_natten_available = _is_package_available("natten")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `nltk` æ¨¡å—
_nltk_available = _is_package_available("nltk")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `onnx` æ¨¡å—
_onnx_available = _is_package_available("onnx")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `openai` æ¨¡å—
_openai_available = _is_package_available("openai")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `optimum` æ¨¡å—
_optimum_available = _is_package_available("optimum")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `auto_gptq` æ¨¡å—
_auto_gptq_available = _is_package_available("auto_gptq")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `awq` æ¨¡å—
_auto_awq_available = importlib.util.find_spec("awq") is not None
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `pandas` æ¨¡å—
_pandas_available = _is_package_available("pandas")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `peft` æ¨¡å—
_peft_available = _is_package_available("peft")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `phonemizer` æ¨¡å—
_phonemizer_available = _is_package_available("phonemizer")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `psutil` æ¨¡å—
_psutil_available = _is_package_available("psutil")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `py3nvml` æ¨¡å—
_py3nvml_available = _is_package_available("py3nvml")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `pyctcdecode` æ¨¡å—
_pyctcdecode_available = _is_package_available("pyctcdecode")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `pytesseract` æ¨¡å—
_pytesseract_available = _is_package_available("pytesseract")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `pytest` æ¨¡å—
_pytest_available = _is_package_available("pytest")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `pytorch_quantization` æ¨¡å—
_pytorch_quantization_available = _is_package_available("pytorch_quantization")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `rjieba` æ¨¡å—
_rjieba_available = _is_package_available("rjieba")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `sacremoses` æ¨¡å—
_sacremoses_available = _is_package_available("sacremoses")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `safetensors` æ¨¡å—
_safetensors_available = _is_package_available("safetensors")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `scipy` æ¨¡å—
_scipy_available = _is_package_available("scipy")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `sentencepiece` æ¨¡å—
_sentencepiece_available = _is_package_available("sentencepiece")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `seqio` æ¨¡å—
_is_seqio_available = _is_package_available("seqio")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† `sklearn` æ¨¡å—
_sklearn_available = importlib.util.find_spec("sklearn") is not None
# å¦‚æœå®‰è£…äº† `sklearn` æ¨¡å—ï¼Œåˆ™å°è¯•è·å– `scikit-learn` æ¨¡å—çš„ç‰ˆæœ¬ä¿¡æ¯
if _sklearn_available:
    try:
        importlib.metadata.version("scikit-learn")
    # æ•è· importlib.metadata.PackageNotFoundError å¼‚å¸¸
    except importlib.metadata.PackageNotFoundError:
        # è®¾ç½® _sklearn_available ä¸º False
        _sklearn_available = False
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†smdistributedåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_smdistributed_available = importlib.util.find_spec("smdistributed") is not None
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†soundfileåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_soundfile_available = _is_package_available("soundfile")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†spacyåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_spacy_available = _is_package_available("spacy")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†sudachipyåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_sudachipy_available = _is_package_available("sudachipy")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†tensorflow_probabilityåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_tensorflow_probability_available = _is_package_available("tensorflow_probability")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†tensorflow_textåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_tensorflow_text_available = _is_package_available("tensorflow_text")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†tf2onnxåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_tf2onnx_available = _is_package_available("tf2onnx")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†timmåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_timm_available = _is_package_available("timm")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†tokenizersåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_tokenizers_available = _is_package_available("tokenizers")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†torchaudioåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_torchaudio_available = _is_package_available("torchaudio")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†torchdistxåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_torchdistx_available = _is_package_available("torchdistx")
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†torchvisionåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_torchvision_available = _is_package_available("torchvision")

# åˆå§‹åŒ–torchç‰ˆæœ¬ä¸º"N/A"ï¼Œtorchæ˜¯å¦å¯ç”¨ä¸ºFalse
_torch_version = "N/A"
_torch_available = False
# å¦‚æœUSE_TORCHåœ¨ENV_VARS_TRUE_AND_AUTO_VALUESä¸­ä¸”USE_TFä¸åœ¨ENV_VARS_TRUE_VALUESä¸­
if USE_TORCH in ENV_VARS_TRUE_AND_AUTO_VALUES and USE_TF not in ENV_VARS_TRUE_VALUES:
    # æ£€æŸ¥torchåŒ…æ˜¯å¦å¯ç”¨ï¼Œå¦‚æœå¯ç”¨åˆ™è·å–ç‰ˆæœ¬å·
    _torch_available, _torch_version = _is_package_available("torch", return_version=True)
else:
    logger.info("Disabling PyTorch because USE_TF is set")
    _torch_available = False

# åˆå§‹åŒ–tensorflowç‰ˆæœ¬ä¸º"N/A"ï¼Œtensorflowæ˜¯å¦å¯ç”¨ä¸ºFalse
_tf_version = "N/A"
_tf_available = False
# å¦‚æœFORCE_TF_AVAILABLEåœ¨ENV_VARS_TRUE_VALUESä¸­
if FORCE_TF_AVAILABLE in ENV_VARS_TRUE_VALUES:
    _tf_available = True
else:
    if USE_TF in ENV_VARS_TRUE_AND_AUTO_VALUES and USE_TORCH not in ENV_VARS_TRUE_VALUES:
        # æ£€æŸ¥tensorflowåŒ…æ˜¯å¦å¯ç”¨
        _tf_available = importlib.util.find_spec("tensorflow") is not None
        if _tf_available:
            candidates = (
                "tensorflow",
                "tensorflow-cpu",
                "tensorflow-gpu",
                "tf-nightly",
                "tf-nightly-cpu",
                "tf-nightly-gpu",
                "tf-nightly-rocm",
                "intel-tensorflow",
                "intel-tensorflow-avx512",
                "tensorflow-rocm",
                "tensorflow-macos",
                "tensorflow-aarch64",
            )
            _tf_version = None
            # è·å–tensorflowçš„ç‰ˆæœ¬å·
            for pkg in candidates:
                try:
                    _tf_version = importlib.metadata.version(pkg)
                    break
                except importlib.metadata.PackageNotFoundError:
                    pass
            _tf_available = _tf_version is not None
        if _tf_available:
            if version.parse(_tf_version) < version.parse("2"):
                logger.info(
                    f"TensorFlow found but with version {_tf_version}. Transformers requires version 2 minimum."
                )
                _tf_available = False
    else:
        logger.info("Disabling Tensorflow because USE_TORCH is set")

# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†essentiaåŒ…ï¼Œè¿”å›å¸ƒå°”å€¼
_essentia_available = importlib.util.find_spec("essentia") is not None
try:
    # è·å–essentiaçš„ç‰ˆæœ¬å·
    _essentia_version = importlib.metadata.version("essentia")
    # ä½¿ç”¨ debug çº§åˆ«çš„æ—¥å¿—è®°å½•æˆåŠŸå¯¼å…¥çš„ essentia ç‰ˆæœ¬ä¿¡æ¯
    logger.debug(f"Successfully imported essentia version {_essentia_version}")
# æ•è· importlib.metadata.PackageNotFoundError å¼‚å¸¸ï¼Œè®¾ç½® _essentia_version ä¸º False
except importlib.metadata.PackageNotFoundError:
    _essentia_version = False

# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† pretty_midi æ¨¡å—ï¼Œè®¾ç½® _pretty_midi_available ä¸º True æˆ– False
_pretty_midi_available = importlib.util.find_spec("pretty_midi") is not None
try:
    # è·å– pretty_midi æ¨¡å—çš„ç‰ˆæœ¬å·ï¼Œè®°å½•æ—¥å¿—
    _pretty_midi_version = importlib.metadata.version("pretty_midi")
    logger.debug(f"Successfully imported pretty_midi version {_pretty_midi_version}")
except importlib.metadata.PackageNotFoundError:
    # æ•è· importlib.metadata.PackageNotFoundError å¼‚å¸¸ï¼Œè®¾ç½® _pretty_midi_available ä¸º False
    _pretty_midi_available = False

# åˆå§‹åŒ– ccl_version ä¸º "N/A"ï¼Œæ£€æŸ¥æ˜¯å¦å®‰è£…äº† torch_ccl æˆ– oneccl_bindings_for_pytorch æ¨¡å—ï¼Œè®¾ç½® _is_ccl_available ä¸º True æˆ– False
ccl_version = "N/A"
_is_ccl_available = (
    importlib.util.find_spec("torch_ccl") is not None
    or importlib.util.find_spec("oneccl_bindings_for_pytorch") is not None
)
try:
    # è·å– oneccl_bind_pt æ¨¡å—çš„ç‰ˆæœ¬å·ï¼Œè®°å½•æ—¥å¿—
    ccl_version = importlib.metadata.version("oneccl_bind_pt")
    logger.debug(f"Detected oneccl_bind_pt version {ccl_version}")
except importlib.metadata.PackageNotFoundError:
    # æ•è· importlib.metadata.PackageNotFoundError å¼‚å¸¸ï¼Œè®¾ç½® _is_ccl_available ä¸º False
    _is_ccl_available = False

# åˆå§‹åŒ– _flax_available ä¸º Falseï¼Œæ£€æŸ¥æ˜¯å¦å®‰è£…äº† flax æ¨¡å—ï¼Œè®¾ç½® _flax_available ä¸º True æˆ– False
if USE_JAX in ENV_VARS_TRUE_AND_AUTO_VALUES:
    _flax_available, _flax_version = _is_package_available("flax", return_version=True)
    if _flax_available:
        # å¦‚æœ flax æ¨¡å—å¯ç”¨ï¼Œæ£€æŸ¥æ˜¯å¦å®‰è£…äº† jax æ¨¡å—ï¼Œè®°å½•æ—¥å¿—
        _jax_available, _jax_version = _is_package_available("jax", return_version=True)
        if _jax_available:
            logger.info(f"JAX version {_jax_version}, Flax version {_flax_version} available.")
        else:
            # å¦‚æœ jax æ¨¡å—ä¸å¯ç”¨ï¼Œè®¾ç½® _flax_available å’Œ _jax_available ä¸º False
            _flax_available = _jax_available = False
            _jax_version = _flax_version = "N/A"

# åˆå§‹åŒ– _torch_fx_available ä¸º Falseï¼Œå¦‚æœ torch æ¨¡å—å¯ç”¨ï¼Œæ£€æŸ¥ torch ç‰ˆæœ¬æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Œè®¾ç½® _torch_fx_available ä¸º True æˆ– False
if _torch_available:
    torch_version = version.parse(_torch_version)
    _torch_fx_available = (torch_version.major, torch_version.minor) >= (
        TORCH_FX_REQUIRED_VERSION.major,
        TORCH_FX_REQUIRED_VERSION.minor,
    )

# è¿”å› kenlm æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_kenlm_available():
    return _kenlm_available

# è¿”å› cv2 æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_cv2_available():
    return _cv2_available

# è¿”å› torch æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_torch_available():
    return _torch_available

# è¿”å› torch æ¨¡å—çš„ç‰ˆæœ¬å·
def get_torch_version():
    return _torch_version

# è¿”å› torch_sdpa æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_torch_sdpa_available():
    if not is_torch_available():
        return False
    elif _torch_version == "N/A":
        return False
    # æ£€æŸ¥ torch ç‰ˆæœ¬æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Œè¿”å›å¸ƒå°”å€¼
    return version.parse(_torch_version) >= version.parse("2.1.1")

# è¿”å› torchvision æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_torchvision_available():
    return _torchvision_available

# è¿”å› pyctcdecode æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_pyctcdecode_available():
    return _pyctcdecode_available

# è¿”å› librosa æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_librosa_available():
    return _librosa_available

# è¿”å› essentia æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_essentia_available():
    return _essentia_available

# è¿”å› pretty_midi æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_pretty_midi_available():
    return _pretty_midi_available

# è¿”å› torch.cuda æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_torch_cuda_available():
    if is_torch_available():
        import torch
        return torch.cuda.is_available()
    else:
        return False

# è¿”å› torch_mps æ¨¡å—æ˜¯å¦å¯ç”¨çš„å¸ƒå°”å€¼
def is_torch_mps_available():
    # æ£€æŸ¥æ˜¯å¦å®‰è£…äº† torch åº“
    if is_torch_available():
        # å¯¼å…¥ torch åº“
        import torch
        # æ£€æŸ¥ torch.backends ä¸­æ˜¯å¦æœ‰ "mps" å±æ€§
        if hasattr(torch.backends, "mps"):
            # è¿”å› torch.backends.mps.is_available() çš„ç»“æœ
            return torch.backends.mps.is_available()
    # å¦‚æœæœªå®‰è£… torch æˆ–è€…æ²¡æœ‰ "mps" å±æ€§ï¼Œåˆ™è¿”å› False
    return False
# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ torch åº“
def is_torch_bf16_gpu_available():
    if not is_torch_available():
        return False

    import torch

    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ CUDA GPU å¹¶ä¸”æ˜¯å¦æ”¯æŒ bf16
    return torch.cuda.is_available() and torch.cuda.is_bf16_supported()


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ torch åº“
def is_torch_bf16_cpu_available():
    if not is_torch_available():
        return False

    import torch

    try:
        # å°è¯•è®¿é—® torch.cpu.amp.autocast å±æ€§ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨
        _ = torch.cpu.amp.autocast
    except AttributeError:
        return False

    return True


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ torch åº“
def is_torch_bf16_available():
    # åŸå§‹çš„ bf16 æ£€æŸ¥ä»…é€‚ç”¨äº GPUï¼Œä½†åæ¥å‡ºç°äº† CPU/bf16 ç»„åˆï¼Œå› æ­¤æ­¤å®ç”¨ç¨‹åºå·²å˜å¾—æ¨¡ç³Šï¼Œå› æ­¤å·²å¼ƒç”¨
    warnings.warn(
        "The util is_torch_bf16_available is deprecated, please use is_torch_bf16_gpu_available "
        "or is_torch_bf16_cpu_available instead according to whether it's used with cpu or gpu",
        FutureWarning,
    )
    return is_torch_bf16_gpu_available()


# æ£€æŸ¥åœ¨ç‰¹å®šè®¾å¤‡ä¸Šæ˜¯å¦å­˜åœ¨å¯ç”¨çš„ torch fp16
@lru_cache()
def is_torch_fp16_available_on_device(device):
    if not is_torch_available():
        return False

    import torch

    try:
        x = torch.zeros(2, 2, dtype=torch.float16).to(device)
        _ = x @ x
    except:  # noqa: E722
        # TODO: æ›´ç²¾ç¡®çš„å¼‚å¸¸åŒ¹é…ï¼Œå¦‚æœå¯èƒ½çš„è¯
        # å¤§å¤šæ•°åç«¯åº”è¯¥è¿”å› `RuntimeError`ï¼Œä½†è¿™å¹¶ä¸æ˜¯ä¿è¯
        return False

    return True


# æ£€æŸ¥åœ¨ç‰¹å®šè®¾å¤‡ä¸Šæ˜¯å¦å­˜åœ¨å¯ç”¨çš„ torch bf16
@lru_cache()
def is_torch_bf16_available_on_device(device):
    if not is_torch_available():
        return False

    import torch

    if device == "cuda":
        return is_torch_bf16_gpu_available()

    try:
        x = torch.zeros(2, 2, dtype=torch.bfloat16).to(device)
        _ = x @ x
    except:  # noqa: E722
        # TODO: æ›´ç²¾ç¡®çš„å¼‚å¸¸åŒ¹é…ï¼Œå¦‚æœå¯èƒ½çš„è¯
        # å¤§å¤šæ•°åç«¯åº”è¯¥è¿”å› `RuntimeError`ï¼Œä½†è¿™å¹¶ä¸æ˜¯ä¿è¯
        return False

    return True


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ torch tf32
def is_torch_tf32_available():
    if not is_torch_available():
        return False

    import torch

    if not torch.cuda.is_available() or torch.version.cuda is None:
        return False
    if torch.cuda.get_device_properties(torch.cuda.current_device()).major < 8:
        return False
    if int(torch.version.cuda.split(".")[0]) < 11:
        return False
    if version.parse(version.parse(torch.__version__).base_version) < version.parse("1.7"):
        return False

    return True


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ torch fx
def is_torch_fx_available():
    return _torch_fx_available


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ peft
def is_peft_available():
    return _peft_available


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ bs4
def is_bs4_available():
    return _bs4_available


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ tensorflow
def is_tf_available():
    return _tf_available


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ coloredlogs
def is_coloredlogs_available():
    return _coloredlogs_available


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ tf2onnx
def is_tf2onnx_available():
    return _tf2onnx_available


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ onnx
def is_onnx_available():
    return _onnx_available


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ openai
def is_openai_available():
    return _openai_available


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ flax
def is_flax_available():
    return _flax_available


# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯ç”¨çš„ ftfy
def is_ftfy_available():
    return _ftfy_available
# æ£€æŸ¥æ˜¯å¦å¯ç”¨ G2P è‹±æ–‡æ¨¡å‹
def is_g2p_en_available():
    return _g2p_en_available


# ä½¿ç”¨ lru_cache è£…é¥°å™¨ç¼“å­˜ç»“æœï¼Œæ£€æŸ¥æ˜¯å¦å¯ç”¨ Torch TPU
def is_torch_tpu_available(check_device=True):
    "Checks if `torch_xla` is installed and potentially if a TPU is in the environment"
    if not _torch_available:
        return False
    if importlib.util.find_spec("torch_xla") is not None:
        if check_device:
            # æ£€æŸ¥æ˜¯å¦èƒ½æ‰¾åˆ° `xla_device`ï¼Œå¦‚æœæ‰¾ä¸åˆ°ä¼šå¼•å‘ RuntimeError
            try:
                import torch_xla.core.xla_model as xm

                _ = xm.xla_device()
                return True
            except RuntimeError:
                return False
        return True
    return False


# ä½¿ç”¨ lru_cache è£…é¥°å™¨ç¼“å­˜ç»“æœï¼Œæ£€æŸ¥æ˜¯å¦å¯ç”¨ Torch NeuronCore
def is_torch_neuroncore_available(check_device=True):
    if importlib.util.find_spec("torch_neuronx") is not None:
        return is_torch_tpu_available(check_device)
    return False


# ä½¿ç”¨ lru_cache è£…é¥°å™¨ç¼“å­˜ç»“æœï¼Œæ£€æŸ¥æ˜¯å¦å¯ç”¨ Torch NPU
def is_torch_npu_available(check_device=False):
    "Checks if `torch_npu` is installed and potentially if a NPU is in the environment"
    if not _torch_available or importlib.util.find_spec("torch_npu") is None:
        return False

    import torch
    import torch_npu  # noqa: F401

    if check_device:
        try:
            # å¦‚æœæ‰¾ä¸åˆ° NPU ä¼šå¼•å‘ RuntimeError
            _ = torch.npu.device_count()
            return torch.npu.is_available()
        except RuntimeError:
            return False
    return hasattr(torch, "npu") and torch.npu.is_available()


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ Torch Dynamo
def is_torchdynamo_available():
    if not is_torch_available():
        return False
    try:
        import torch._dynamo as dynamo  # noqa: F401

        return True
    except Exception:
        return False


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ Torch ç¼–è¯‘
def is_torch_compile_available():
    if not is_torch_available():
        return False

    import torch

    # è¿™é‡Œä¸è¿›è¡Œä»»ä½•ç‰ˆæœ¬æ£€æŸ¥ï¼Œä»¥æ”¯æŒæ ‡è®°ä¸º 1.14 çš„å¤œé—´ç‰ˆæœ¬ã€‚æœ€ç»ˆéœ€è¦ä¸ 2.0 ç‰ˆæœ¬è¿›è¡Œç‰ˆæœ¬æ£€æŸ¥ï¼Œä½†æš‚æ—¶ä¸åšã€‚
    return hasattr(torch, "compile")


# æ£€æŸ¥æ˜¯å¦æ­£åœ¨ç¼–è¯‘ Torch Dynamo
def is_torchdynamo_compiling():
    if not is_torch_available():
        return False
    try:
        import torch._dynamo as dynamo  # noqa: F401

        return dynamo.is_compiling()
    except Exception:
        return False


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ Torch TensorRT FX
def is_torch_tensorrt_fx_available():
    if importlib.util.find_spec("torch_tensorrt") is None:
        return False
    return importlib.util.find_spec("torch_tensorrt.fx") is not None


# æ£€æŸ¥æ˜¯å¦å¯ç”¨æ•°æ®é›†
def is_datasets_available():
    return _datasets_available


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ Detectron2
def is_detectron2_available():
    return _detectron2_available


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ rJieba
def is_rjieba_available():
    return _rjieba_available


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ psutil
def is_psutil_available():
    return _psutil_available


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ py3nvml
def is_py3nvml_available():
    return _py3nvml_available


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ SacreMoses
def is_sacremoses_available():
    return _sacremoses_available


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ Apex
def is_apex_available():
    return _apex_available


# æ£€æŸ¥æ˜¯å¦å¯ç”¨ Ninja
def is_ninja_available():
    r"""
    Code comes from *torch.utils.cpp_extension.is_ninja_available()*. Returns `True` if the
    # æ£€æŸ¥ç³»ç»Ÿä¸Šæ˜¯å¦å®‰è£…äº† ninja æ„å»ºç³»ç»Ÿï¼Œå¦‚æœæœ‰åˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
    """
    # å°è¯•è¿è¡Œå‘½ä»¤ "ninja --version"ï¼Œå¦‚æœæˆåŠŸåˆ™è¯´æ˜ç³»ç»Ÿä¸Šå®‰è£…äº† ninja
    try:
        subprocess.check_output("ninja --version".split())
    # å¦‚æœè¿è¡Œå‘½ä»¤å¤±è´¥ï¼Œåˆ™æ•è·å¼‚å¸¸
    except Exception:
        # è¿”å› False
        return False
    # å¦‚æœæ²¡æœ‰å¼‚å¸¸ï¼Œåˆ™è¯´æ˜ç³»ç»Ÿä¸Šå®‰è£…äº† ninjaï¼Œè¿”å› True
    else:
        return True
# æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦å®‰è£…äº† Intel Extension for PyTorchï¼Œå¹¶ä¸”æ˜¯å¦å¯ç”¨
def is_ipex_available():
    # ä»å®Œæ•´ç‰ˆæœ¬å·ä¸­è·å–ä¸»ç‰ˆæœ¬å·å’Œæ¬¡ç‰ˆæœ¬å·
    def get_major_and_minor_from_version(full_version):
        return str(version.parse(full_version).major) + "." + str(version.parse(full_version).minor)

    # å¦‚æœ Torch ä¸å¯ç”¨æˆ–è€… _ipex_available ä¸º Falseï¼Œåˆ™è¿”å› False
    if not is_torch_available() or not _ipex_available:
        return False

    # è·å– Torch å’Œ Intel Extension for PyTorch çš„ä¸»ç‰ˆæœ¬å·å’Œæ¬¡ç‰ˆæœ¬å·
    torch_major_and_minor = get_major_and_minor_from_version(_torch_version)
    ipex_major_and_minor = get_major_and_minor_from_version(_ipex_version)
    # å¦‚æœ Torch å’Œ Intel Extension for PyTorch çš„ä¸»ç‰ˆæœ¬å·å’Œæ¬¡ç‰ˆæœ¬å·ä¸ä¸€è‡´ï¼Œåˆ™è¾“å‡ºè­¦å‘Šä¿¡æ¯å¹¶è¿”å› False
    if torch_major_and_minor != ipex_major_and_minor:
        logger.warning(
            f"Intel Extension for PyTorch {ipex_major_and_minor} needs to work with PyTorch {ipex_major_and_minor}.*,"
            f" but PyTorch {_torch_version} is found. Please switch to the matching version and run again."
        )
        return False
    # è¿”å› True
    return True


# ä½¿ç”¨ç¼“å­˜è£…é¥°å™¨æ£€æŸ¥æ˜¯å¦å®‰è£…äº† Torch XPUï¼Œå¹¶ä¸”å¯èƒ½æ£€æŸ¥ç¯å¢ƒä¸­æ˜¯å¦æœ‰ XPU è®¾å¤‡
@lru_cache
def is_torch_xpu_available(check_device=False):
    "Checks if `intel_extension_for_pytorch` is installed and potentially if a XPU is in the environment"
    # å¦‚æœ Intel Extension for PyTorch ä¸å¯ç”¨ï¼Œåˆ™è¿”å› False
    if not is_ipex_available():
        return False

    import intel_extension_for_pytorch  # noqa: F401
    import torch

    # å¦‚æœéœ€è¦æ£€æŸ¥è®¾å¤‡ï¼Œåˆ™å°è¯•è·å– XPU è®¾å¤‡æ•°é‡ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å› False
    if check_device:
        try:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ° XPU è®¾å¤‡ï¼Œåˆ™ä¼šå¼•å‘ RuntimeError
            _ = torch.xpu.device_count()
            return torch.xpu.is_available()
        except RuntimeError:
            return False
    # æ£€æŸ¥æ˜¯å¦æœ‰ torch.xpu å±æ€§å¹¶ä¸” XPU å¯ç”¨
    return hasattr(torch, "xpu") and torch.xpu.is_available()


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† bitsandbytes
def is_bitsandbytes_available():
    # å¦‚æœ Torch ä¸å¯ç”¨ï¼Œåˆ™è¿”å› False
    if not is_torch_available():
        return False

    # bitsandbytes åœ¨æ²¡æœ‰å¯ç”¨çš„ cuda æ—¶ä¼šå¼•å‘é”™è¯¯ï¼Œé€šè¿‡æ·»åŠ ç®€å•æ£€æŸ¥æ¥é¿å…è¿™ç§æƒ…å†µ
    import torch

    return _bitsandbytes_available and torch.cuda.is_available()


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† flash_attn_2
def is_flash_attn_2_available():
    # å¦‚æœ Torch ä¸å¯ç”¨ï¼Œåˆ™è¿”å› False
    if not is_torch_available():
        return False

    # å¦‚æœ flash_attn åŒ…ä¸å¯ç”¨ï¼Œåˆ™è¿”å› False
    if not _is_package_available("flash_attn"):
        return False

    # æ£€æŸ¥æ˜¯å¦æœ‰ cuda å¯ç”¨
    import torch

    if not torch.cuda.is_available():
        return False

    # æ ¹æ®ä¸åŒçš„ç¯å¢ƒç‰ˆæœ¬è¦æ±‚ï¼Œè¿”å›æ˜¯å¦ flash_attn ç‰ˆæœ¬å¤§äºç­‰äºæŒ‡å®šç‰ˆæœ¬
    if torch.version.cuda:
        return version.parse(importlib.metadata.version("flash_attn")) >= version.parse("2.1.0")
    elif torch.version.hip:
        # TODO: ä¸€æ—¦åœ¨ https://github.com/ROCmSoftwarePlatform/flash-attention ä¸­å‘å¸ƒç‰ˆæœ¬ï¼Œè¯·å°†è¦æ±‚æé«˜åˆ° 2.1.0
        return version.parse(importlib.metadata.version("flash_attn")) >= version.parse("2.0.4")
    else:
        return False


# æ£€æŸ¥æ˜¯å¦ flash_attn ç‰ˆæœ¬å¤§äºç­‰äº 2.1.0
def is_flash_attn_greater_or_equal_2_10():
    # å¦‚æœ flash_attn åŒ…ä¸å¯ç”¨ï¼Œåˆ™è¿”å› False
    if not _is_package_available("flash_attn"):
        return False

    return version.parse(importlib.metadata.version("flash_attn")) >= version.parse("2.1.0")


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† flash_attn
def is_flash_attn_available():
    logger.warning(
        "Using `is_flash_attn_available` is deprecated and will be removed in v4.38. "
        "Please use `is_flash_attn_2_available` instead."
    )
    return is_flash_attn_2_available()


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† torchdistx
def is_torchdistx_available():
    return _torchdistx_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† faiss
def is_faiss_available():
    return _faiss_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† scipy
def is_scipy_available():
    return _scipy_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† sklearn
def is_sklearn_available():
    # è¿”å›ä¸€ä¸ªå˜é‡ _sklearn_available çš„å€¼
    return _sklearn_available
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† sentencepiece åº“
def is_sentencepiece_available():
    return _sentencepiece_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† seqio åº“
def is_seqio_available():
    return _is_seqio_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† protobuf åº“
def is_protobuf_available():
    if importlib.util.find_spec("google") is None:
        return False
    return importlib.util.find_spec("google.protobuf") is not None


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† accelerate åº“ï¼Œå¹¶ä¸”ç‰ˆæœ¬ç¬¦åˆè¦æ±‚
def is_accelerate_available(min_version: str = ACCELERATE_MIN_VERSION):
    if min_version is not None:
        return _accelerate_available and version.parse(_accelerate_version) >= version.parse(min_version)
    return _accelerate_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† fsdp åº“ï¼Œå¹¶ä¸”ç‰ˆæœ¬ç¬¦åˆè¦æ±‚
def is_fsdp_available(min_version: str = FSDP_MIN_VERSION):
    return is_torch_available() and version.parse(_torch_version) >= version.parse(min_version)


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† optimum åº“
def is_optimum_available():
    return _optimum_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† auto_awq åº“
def is_auto_awq_available():
    return _auto_awq_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† auto_gptq åº“
def is_auto_gptq_available():
    return _auto_gptq_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† levenshtein åº“
def is_levenshtein_available():
    return _levenshtein_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† optimum.neuron åº“
def is_optimum_neuron_available():
    return _optimum_available and _is_package_available("optimum.neuron")


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† safetensors åº“
def is_safetensors_available():
    return _safetensors_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† tokenizers åº“
def is_tokenizers_available():
    return _tokenizers_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† vision åº“
def is_vision_available():
    _pil_available = importlib.util.find_spec("PIL") is not None
    if _pil_available:
        try:
            package_version = importlib.metadata.version("Pillow")
        except importlib.metadata.PackageNotFoundError:
            try:
                package_version = importlib.metadata.version("Pillow-SIMD")
            except importlib.metadata.PackageNotFoundError:
                return False
        logger.debug(f"Detected PIL version {package_version}")
    return _pil_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† pytesseract åº“
def is_pytesseract_available():
    return _pytesseract_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† pytest åº“
def is_pytest_available():
    return _pytest_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† spacy åº“
def is_spacy_available():
    return _spacy_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† tensorflow_text åº“
def is_tensorflow_text_available():
    return is_tf_available() and _tensorflow_text_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† keras_nlp åº“
def is_keras_nlp_available():
    return is_tensorflow_text_available() and _keras_nlp_available


# æ£€æŸ¥æ˜¯å¦åœ¨ notebook ç¯å¢ƒä¸­
def is_in_notebook():
    try:
        # ä» tqdm.autonotebook ä¸­é€‚é…çš„æµ‹è¯•
        get_ipython = sys.modules["IPython"].get_ipython
        if "IPKernelApp" not in get_ipython().config:
            raise ImportError("console")
        if "VSCODE_PID" in os.environ:
            raise ImportError("vscode")
        if "DATABRICKS_RUNTIME_VERSION" in os.environ and os.environ["DATABRICKS_RUNTIME_VERSION"] < "11.0":
            # Databricks Runtime 11.0 åŠä»¥ä¸Šé»˜è®¤ä½¿ç”¨ IPython å†…æ ¸ï¼Œå› æ­¤åº”ä¸ Jupyter notebook å…¼å®¹
            # https://docs.microsoft.com/en-us/azure/databricks/notebooks/ipython-kernel
            raise ImportError("databricks")

        return importlib.util.find_spec("IPython") is not None
    except (AttributeError, ImportError, KeyError):
        return False
# æ£€æŸ¥æ˜¯å¦ PyTorch é‡åŒ–å¯ç”¨
def is_pytorch_quantization_available():
    return _pytorch_quantization_available


# æ£€æŸ¥æ˜¯å¦ TensorFlow æ¦‚ç‡å¯ç”¨
def is_tensorflow_probability_available():
    return _tensorflow_probability_available


# æ£€æŸ¥æ˜¯å¦ Pandas å¯ç”¨
def is_pandas_available():
    return _pandas_available


# æ£€æŸ¥æ˜¯å¦ SageMaker æ•°æ®å¹¶è¡Œå¯ç”¨
def is_sagemaker_dp_enabled():
    # è·å– SageMaker ç‰¹å®šç¯å¢ƒå˜é‡
    sagemaker_params = os.getenv("SM_FRAMEWORK_PARAMS", "{}")
    try:
        # è§£æå¹¶æ£€æŸ¥å­—æ®µ "sagemaker_distributed_dataparallel_enabled"
        sagemaker_params = json.loads(sagemaker_params)
        if not sagemaker_params.get("sagemaker_distributed_dataparallel_enabled", False):
            return False
    except json.JSONDecodeError:
        return False
    # æœ€åï¼Œæ£€æŸ¥ `smdistributed` æ¨¡å—æ˜¯å¦å­˜åœ¨
    return _smdistributed_available


# æ£€æŸ¥æ˜¯å¦ SageMaker æ¨¡å‹å¹¶è¡Œå¯ç”¨
def is_sagemaker_mp_enabled():
    # ä» smp_options å˜é‡è·å– SageMaker ç‰¹å®š mp å‚æ•°
    smp_options = os.getenv("SM_HP_MP_PARAMETERS", "{}")
    try:
        # è§£æå¹¶æ£€æŸ¥å­—æ®µ "partitions" æ˜¯å¦åŒ…å«åœ¨å†…ï¼Œè¿™æ˜¯æ¨¡å‹å¹¶è¡Œæ‰€éœ€çš„
        smp_options = json.loads(smp_options)
        if "partitions" not in smp_options:
            return False
    except json.JSONDecodeError:
        return False

    # ä» mpi_options å˜é‡è·å– SageMaker ç‰¹å®šæ¡†æ¶å‚æ•°
    mpi_options = os.getenv("SM_FRAMEWORK_PARAMS", "{}")
    try:
        # è§£æå¹¶æ£€æŸ¥å­—æ®µ "sagemaker_mpi_enabled"
        mpi_options = json.loads(mpi_options)
        if not mpi_options.get("sagemaker_mpi_enabled", False):
            return False
    except json.JSONDecodeError:
        return False
    # æœ€åï¼Œæ£€æŸ¥ `smdistributed` æ¨¡å—æ˜¯å¦å­˜åœ¨
    return _smdistributed_available


# æ£€æŸ¥æ˜¯å¦åœ¨ SageMaker ä¸Šè¿è¡Œè®­ç»ƒ
def is_training_run_on_sagemaker():
    return "SAGEMAKER_JOB_NAME" in os.environ


# æ£€æŸ¥æ˜¯å¦ SoundFile å¯ç”¨
def is_soundfile_availble():
    return _soundfile_available


# æ£€æŸ¥æ˜¯å¦ Timm å¯ç”¨
def is_timm_available():
    return _timm_available


# æ£€æŸ¥æ˜¯å¦ Natten å¯ç”¨
def is_natten_available():
    return _natten_available


# æ£€æŸ¥æ˜¯å¦ NLTK å¯ç”¨
def is_nltk_available():
    return _nltk_available


# æ£€æŸ¥æ˜¯å¦ TorchAudio å¯ç”¨
def is_torchaudio_available():
    return _torchaudio_available


# æ£€æŸ¥æ˜¯å¦ Speech å¯ç”¨
def is_speech_available():
    # ç›®å‰ä¾èµ–äº TorchAudioï¼Œä½†ç¡®åˆ‡çš„ä¾èµ–å…³ç³»å¯èƒ½ä¼šåœ¨æœªæ¥å‘ç”Ÿå˜åŒ–
    return _torchaudio_available


# æ£€æŸ¥æ˜¯å¦ Phonemizer å¯ç”¨
def is_phonemizer_available():
    return _phonemizer_available


# ä»…é€‚ç”¨äº Torch çš„æ–¹æ³•
def torch_only_method(fn):
    def wrapper(*args, **kwargs):
        if not _torch_available:
            raise ImportError(
                "You need to install pytorch to use this method or class, "
                "or activate it with environment variables USE_TORCH=1 and USE_TF=0."
            )
        else:
            return fn(*args, **kwargs)

    return wrapper


# æ£€æŸ¥æ˜¯å¦ CCL å¯ç”¨
def is_ccl_available():
    return _is_ccl_available


# æ£€æŸ¥æ˜¯å¦ Decord å¯ç”¨
def is_decord_available():
    return _decord_available


# æ£€æŸ¥æ˜¯å¦ Sudachi å¯ç”¨
def is_sudachi_available():
    return _sudachipy_available


# æ£€æŸ¥æ˜¯å¦ Juman++ å¯ç”¨
def is_jumanpp_available():
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åä¸º"rhoknp"çš„æ¨¡å—ï¼Œå¹¶ä¸”æ£€æŸ¥æ˜¯å¦å­˜åœ¨åä¸º"jumanpp"çš„å¯æ‰§è¡Œæ–‡ä»¶ï¼Œè¿”å›ä¸¤è€…çš„é€»è¾‘ä¸ç»“æœ
    return (importlib.util.find_spec("rhoknp") is not None) and (shutil.which("jumanpp") is not None)
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† Cython
def is_cython_available():
    return importlib.util.find_spec("pyximport") is not None


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†ç»“å·´åˆ†è¯åº“
def is_jieba_available():
    return _jieba_available


# æ£€æŸ¥æ˜¯å¦å®‰è£…äº† Jinja æ¨¡æ¿åº“
def is_jinja_available():
    return _jinja_available


# å¿½ç•¥æ–‡æ¡£é£æ ¼æ£€æŸ¥ï¼ŒOpenCV åº“æœªæ‰¾åˆ°æ—¶çš„é”™è¯¯æç¤ºä¿¡æ¯
CV2_IMPORT_ERROR = """
{0} requires the OpenCV library but it was not found in your environment. You can install it with:

pip install opencv-python

Please note that you may need to restart your runtime after installation.
"""


# å¿½ç•¥æ–‡æ¡£é£æ ¼æ£€æŸ¥ï¼ŒDatasets åº“æœªæ‰¾åˆ°æ—¶çš„é”™è¯¯æç¤ºä¿¡æ¯
DATASETS_IMPORT_ERROR = """
{0} requires the ğŸ¤— Datasets library but it was not found in your environment. You can install it with:

pip install datasets

In a notebook or a colab, you can install it by executing a cell with

!pip install datasets

then restarting your kernel.

Note that if you have a local folder named `datasets` or a local python file named `datasets.py` in your current
working directory, python may try to import this instead of the ğŸ¤— Datasets library. You should rename this folder or
that python file if that's the case. Please note that you may need to restart your runtime after installation.
"""


# å¿½ç•¥æ–‡æ¡£é£æ ¼æ£€æŸ¥ï¼ŒTokenizers åº“æœªæ‰¾åˆ°æ—¶çš„é”™è¯¯æç¤ºä¿¡æ¯
TOKENIZERS_IMPORT_ERROR = """
{0} requires the ğŸ¤— Tokenizers library but it was not found in your environment. You can install it with:

pip install tokenizers

In a notebook or a colab, you can install it by executing a cell with

!pip install tokenizers

Please note that you may need to restart your runtime after installation.
"""


# å¿½ç•¥æ–‡æ¡£é£æ ¼æ£€æŸ¥ï¼ŒSentencePiece åº“æœªæ‰¾åˆ°æ—¶çš„é”™è¯¯æç¤ºä¿¡æ¯
SENTENCEPIECE_IMPORT_ERROR = """
{0} requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
"""


# å¿½ç•¥æ–‡æ¡£é£æ ¼æ£€æŸ¥ï¼ŒProtobuf åº“æœªæ‰¾åˆ°æ—¶çš„é”™è¯¯æç¤ºä¿¡æ¯
PROTOBUF_IMPORT_ERROR = """
{0} requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
"""


# å¿½ç•¥æ–‡æ¡£é£æ ¼æ£€æŸ¥ï¼ŒFaiss åº“æœªæ‰¾åˆ°æ—¶çš„é”™è¯¯æç¤ºä¿¡æ¯
FAISS_IMPORT_ERROR = """
{0} requires the faiss library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
"""


# å¿½ç•¥æ–‡æ¡£é£æ ¼æ£€æŸ¥ï¼ŒPyTorch åº“æœªæ‰¾åˆ°æ—¶çš„é”™è¯¯æç¤ºä¿¡æ¯
PYTORCH_IMPORT_ERROR = """
{0} requires the PyTorch library but it was not found in your environment. Checkout the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.
"""


# å¿½ç•¥æ–‡æ¡£é£æ ¼æ£€æŸ¥
# å½“å¯¼å…¥æŸä¸ªæ¨¡å—æ—¶å‡ºç° Torchvision åº“æœªæ‰¾åˆ°çš„é”™è¯¯æç¤ºä¿¡æ¯
TORCHVISION_IMPORT_ERROR = """
{0} requires the Torchvision library but it was not found in your environment. Checkout the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.
"""

# docstyle-ignore
# å½“å¯¼å…¥æŸä¸ªæ¨¡å—æ—¶å‡ºç° PyTorch åº“æœªæ‰¾åˆ°çš„é”™è¯¯æç¤ºä¿¡æ¯ï¼Œä½†æ‰¾åˆ° TensorFlow å®‰è£…çš„æƒ…å†µä¸‹çš„æç¤ºä¿¡æ¯
PYTORCH_IMPORT_ERROR_WITH_TF = """
{0} requires the PyTorch library but it was not found in your environment.
However, we were able to find a TensorFlow installation. TensorFlow classes begin
with "TF", but are otherwise identically named to our PyTorch classes. This
means that the TF equivalent of the class you tried to import would be "TF{0}".
If you want to use TensorFlow, please use TF classes instead!

If you really do want to use PyTorch please go to
https://pytorch.org/get-started/locally/ and follow the instructions that
match your environment.
"""

# docstyle-ignore
# å½“å¯¼å…¥æŸä¸ªæ¨¡å—æ—¶å‡ºç° TensorFlow åº“æœªæ‰¾åˆ°çš„é”™è¯¯æç¤ºä¿¡æ¯ï¼Œä½†æ‰¾åˆ° PyTorch å®‰è£…çš„æƒ…å†µä¸‹çš„æç¤ºä¿¡æ¯
TF_IMPORT_ERROR_WITH_PYTORCH = """
{0} requires the TensorFlow library but it was not found in your environment.
However, we were able to find a PyTorch installation. PyTorch classes do not begin
with "TF", but are otherwise identically named to our TF classes.
If you want to use PyTorch, please use those classes instead!

If you really do want to use TensorFlow, please follow the instructions on the
installation page https://www.tensorflow.org/install that match your environment.
"""

# docstyle-ignore
# å½“å¯¼å…¥æŸä¸ªæ¨¡å—æ—¶å‡ºç° Beautiful Soup åº“æœªæ‰¾åˆ°çš„é”™è¯¯æç¤ºä¿¡æ¯
BS4_IMPORT_ERROR = """
{0} requires the Beautiful Soup library but it was not found in your environment. You can install it with pip:
`pip install beautifulsoup4`. Please note that you may need to restart your runtime after installation.
"""

# docstyle-ignore
# å½“å¯¼å…¥æŸä¸ªæ¨¡å—æ—¶å‡ºç° scikit-learn åº“æœªæ‰¾åˆ°çš„é”™è¯¯æç¤ºä¿¡æ¯
SKLEARN_IMPORT_ERROR = """
{0} requires the scikit-learn library but it was not found in your environment. You can install it with:

pip install -U scikit-learn

In a notebook or a colab, you can install it by executing a cell with

!pip install -U scikit-learn

Please note that you may need to restart your runtime after installation.
"""

# docstyle-ignore
# å½“å¯¼å…¥æŸä¸ªæ¨¡å—æ—¶å‡ºç° TensorFlow åº“æœªæ‰¾åˆ°çš„é”™è¯¯æç¤ºä¿¡æ¯
TENSORFLOW_IMPORT_ERROR = """
{0} requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the
installation page: https://www.tensorflow.org/install and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.
"""

# docstyle-ignore
# å½“å¯¼å…¥æŸä¸ªæ¨¡å—æ—¶å‡ºç° detectron2 åº“æœªæ‰¾åˆ°çš„é”™è¯¯æç¤ºä¿¡æ¯
DETECTRON2_IMPORT_ERROR = """
{0} requires the detectron2 library but it was not found in your environment. Checkout the instructions on the
installation page: https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
"""

# docstyle-ignore
# å½“å¯¼å…¥æŸä¸ªæ¨¡å—æ—¶å‡ºç° FLAX åº“æœªæ‰¾åˆ°çš„é”™è¯¯æç¤ºä¿¡æ¯
FLAX_IMPORT_ERROR = """
{0} requires the FLAX library but it was not found in your environment. Checkout the instructions on the
# å®‰è£…é¡µé¢: https://github.com/google/flax å¹¶ä¸”éµå¾ªä¸æ‚¨çš„ç¯å¢ƒç›¸åŒ¹é…çš„æŒ‡å—ã€‚
# è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ ftfy åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
FTFY_IMPORT_ERROR = """
{0} éœ€è¦ ftfy åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚æ£€æŸ¥å®‰è£…éƒ¨åˆ†çš„è¯´æ˜ï¼š
https://github.com/rspeer/python-ftfy/tree/master#installing å¹¶éµå¾ªä¸æ‚¨çš„ç¯å¢ƒåŒ¹é…çš„æŒ‡å—ã€‚
è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ python-Levenshtein åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
LEVENSHTEIN_IMPORT_ERROR = """
{0} éœ€è¦ python-Levenshtein åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ pip å®‰è£…å®ƒï¼š`pip install python-Levenshtein`ã€‚
è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ g2p-en åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
G2P_EN_IMPORT_ERROR = """
{0} éœ€è¦ g2p-en åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ pip å®‰è£…å®ƒï¼š`pip install g2p-en`ã€‚
è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ pytorch-quantization åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
PYTORCH_QUANTIZATION_IMPORT_ERROR = """
{0} éœ€è¦ pytorch-quantization åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ pip å®‰è£…å®ƒï¼š`pip install pytorch-quantization --extra-index-url
https://pypi.ngc.nvidia.com`
è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ tensorflow_probability åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
TENSORFLOW_PROBABILITY_IMPORT_ERROR = """
{0} éœ€è¦ tensorflow_probability åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚æ‚¨å¯ä»¥æŒ‰ç…§è¿™é‡Œçš„è¯´æ˜ä½¿ç”¨ pip å®‰è£…ï¼š
https://github.com/tensorflow/probabilityã€‚
è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ tensorflow_text åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
TENSORFLOW_TEXT_IMPORT_ERROR = """
{0} éœ€è¦ tensorflow_text åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚æ‚¨å¯ä»¥æŒ‰ç…§è¿™é‡Œçš„è¯´æ˜ä½¿ç”¨ pip å®‰è£…ï¼š
https://www.tensorflow.org/text/guide/tf_text_introã€‚
è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ pandas åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
PANDAS_IMPORT_ERROR = """
{0} éœ€è¦ pandas åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚æ‚¨å¯ä»¥æŒ‰ç…§è¿™é‡Œçš„è¯´æ˜ä½¿ç”¨ pip å®‰è£…ï¼š
https://pandas.pydata.org/pandas-docs/stable/getting_started/install.htmlã€‚
è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ phonemizer åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
PHONEMIZER_IMPORT_ERROR = """
{0} éœ€è¦ phonemizer åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚ä½ å¯ä»¥ä½¿ç”¨ pip å®‰è£…å®ƒï¼š`pip install phonemizer`ã€‚
è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ sacremoses åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
SACREMOSES_IMPORT_ERROR = """
{0} éœ€è¦ sacremoses åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ pip å®‰è£…å®ƒï¼š`pip install sacremoses`ã€‚
è¯·æ³¨æ„ï¼Œå®‰è£…åå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚

# å¦‚æœ scipy åº“åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
SCIPY_IMPORT_ERROR = """
{0} éœ€è¦ scipy åº“ï¼Œä½†åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰¾ä¸åˆ°ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ pip å®‰è£…å®ƒï¼š
# å®šä¹‰ Speech ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
SPEECH_IMPORT_ERROR = """
{0} requires the torchaudio library but it was not found in your environment. You can install it with pip:
`pip install torchaudio`. Please note that you may need to restart your runtime after installation.
"""

# å®šä¹‰ Timm ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
TIMM_IMPORT_ERROR = """
{0} requires the timm library but it was not found in your environment. You can install it with pip:
`pip install timm`. Please note that you may need to restart your runtime after installation.
"""

# å®šä¹‰ Natten ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
NATTEN_IMPORT_ERROR = """
{0} requires the natten library but it was not found in your environment. You can install it by referring to:
shi-labs.com/natten . You can also install it with pip (may take longer to build):
`pip install natten`. Please note that you may need to restart your runtime after installation.
"""

# å®šä¹‰ NLTK ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
NLTK_IMPORT_ERROR = """
{0} requires the NLTK library but it was not found in your environment. You can install it by referring to:
https://www.nltk.org/install.html. Please note that you may need to restart your runtime after installation.
"""

# å®šä¹‰ Vision ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
VISION_IMPORT_ERROR = """
{0} requires the PIL library but it was not found in your environment. You can install it with pip:
`pip install pillow`. Please note that you may need to restart your runtime after installation.
"""

# å®šä¹‰ PyTesseract ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
PYTESSERACT_IMPORT_ERROR = """
{0} requires the PyTesseract library but it was not found in your environment. You can install it with pip:
`pip install pytesseract`. Please note that you may need to restart your runtime after installation.
"""

# å®šä¹‰ PyCTCDecode ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
PYCTCDECODE_IMPORT_ERROR = """
{0} requires the pyctcdecode library but it was not found in your environment. You can install it with pip:
`pip install pyctcdecode`. Please note that you may need to restart your runtime after installation.
"""

# å®šä¹‰ Accelerate ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
ACCELERATE_IMPORT_ERROR = """
{0} requires the accelerate library >= {ACCELERATE_MIN_VERSION} it was not found in your environment.
You can install or update it with pip: `pip install --upgrade accelerate`. Please note that you may need to restart your
runtime after installation.
"""

# å®šä¹‰ CCL ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
CCL_IMPORT_ERROR = """
{0} requires the torch ccl library but it was not found in your environment. You can install it with pip:
`pip install oneccl_bind_pt -f https://developer.intel.com/ipex-whl-stable`
Please note that you may need to restart your runtime after installation.
"""

# å®šä¹‰ Essentia ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
ESSENTIA_IMPORT_ERROR = """
{0} requires essentia library. But that was not found in your environment. You can install them with pip:
`pip install essentia==2.1b6.dev1034`
Please note that you may need to restart your runtime after installation.
"""

# å®šä¹‰ Librosa ç›¸å…³é”™è¯¯æç¤ºä¿¡æ¯
LIBROSA_IMPORT_ERROR = """
# This block intentionally left blank
"""
# æ˜¾ç¤ºç¼ºå°‘ librosa åº“çš„é”™è¯¯ä¿¡æ¯åŠå®‰è£…æç¤º
{0} requires thes librosa library. But that was not found in your environment. You can install them with pip:
`pip install librosa`
Please note that you may need to restart your runtime after installation.
"""

# æ˜¾ç¤ºç¼ºå°‘ pretty_midi åº“çš„é”™è¯¯ä¿¡æ¯åŠå®‰è£…æç¤º
PRETTY_MIDI_IMPORT_ERROR = """
{0} requires thes pretty_midi library. But that was not found in your environment. You can install them with pip:
`pip install pretty_midi`
Please note that you may need to restart your runtime after installation.
"""

# æ˜¾ç¤ºç¼ºå°‘ decord åº“çš„é”™è¯¯ä¿¡æ¯åŠå®‰è£…æç¤º
DECORD_IMPORT_ERROR = """
{0} requires the decord library but it was not found in your environment. You can install it with pip: `pip install
decord`. Please note that you may need to restart your runtime after installation.
"""

# æ˜¾ç¤ºç¼ºå°‘ Cython åº“çš„é”™è¯¯ä¿¡æ¯åŠå®‰è£…æç¤º
CYTHON_IMPORT_ERROR = """
{0} requires the Cython library but it was not found in your environment. You can install it with pip: `pip install
Cython`. Please note that you may need to restart your runtime after installation.
"""

# æ˜¾ç¤ºç¼ºå°‘ jieba åº“çš„é”™è¯¯ä¿¡æ¯åŠå®‰è£…æç¤º
JIEBA_IMPORT_ERROR = """
{0} requires the jieba library but it was not found in your environment. You can install it with pip: `pip install
jieba`. Please note that you may need to restart your runtime after installation.
"""

# æ˜¾ç¤ºç¼ºå°‘ peft åº“çš„é”™è¯¯ä¿¡æ¯åŠå®‰è£…æç¤º
PEFT_IMPORT_ERROR = """
{0} requires the peft library but it was not found in your environment. You can install it with pip: `pip install
peft`. Please note that you may need to restart your runtime after installation.
"""

# æ˜¾ç¤ºç¼ºå°‘ jinja åº“çš„é”™è¯¯ä¿¡æ¯åŠå®‰è£…æç¤º
JINJA_IMPORT_ERROR = """
{0} requires the jinja library but it was not found in your environment. You can install it with pip: `pip install
jinja2`. Please note that you may need to restart your runtime after installation.
"""

# æŒ‡å®šä¸åŒçš„åç«¯å’Œå…¶å¯¹åº”çš„é¡ºåº
BACKENDS_MAPPING = OrderedDict(
    [
        # æ£€æŸ¥æ˜¯å¦ bs4 åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ BS4_IMPORT_ERROR
        ("bs4", (is_bs4_available, BS4_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ cv2 åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ CV2_IMPORT_ERROR
        ("cv2", (is_cv2_available, CV2_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ datasets åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ DATASETS_IMPORT_ERROR
        ("datasets", (is_datasets_available, DATASETS_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ detectron2 åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ DETECTRON2_IMPORT_ERROR
        ("detectron2", (is_detectron2_available, DETECTRON2_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ essentia åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ ESSENTIA_IMPORT_ERROR
        ("essentia", (is_essentia_available, ESSENTIA_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ faiss åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ FAISS_IMPORT_ERROR
        ("faiss", (is_faiss_available, FAISS_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ flax åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ FLAX_IMPORT_ERROR
        ("flax", (is_flax_available, FLAX_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ ftfy åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ FTFY_IMPORT_ERROR
        ("ftfy", (is_ftfy_available, FTFY_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ g2p_en åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ G2P_EN_IMPORT_ERROR
        ("g2p_en", (is_g2p_en_available, G2P_EN_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ pandas åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ PANDAS_IMPORT_ERROR
        ("pandas", (is_pandas_available, PANDAS_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ phonemizer åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ PHONEMIZER_IMPORT_ERROR
        ("phonemizer", (is_phonemizer_available, PHONEMIZER_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ pretty_midi åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ PRETTY_MIDI_IMPORT_ERROR
        ("pretty_midi", (is_pretty_midi_available, PRETTY_MIDI_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ levenshtein åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ LEVENSHTEIN_IMPORT_ERROR
        ("levenshtein", (is_levenshtein_available, LEVENSHTEIN_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ librosa åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ LIBROSA_IMPORT_ERROR
        ("librosa", (is_librosa_available, LIBROSA_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ protobuf åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ PROTOBUF_IMPORT_ERROR
        ("protobuf", (is_protobuf_available, PROTOBUF_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ pyctcdecode åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ PYCTCDECODE_IMPORT_ERROR
        ("pyctcdecode", (is_pyctcdecode_available, PYCTCDECODE_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ pytesseract åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ PYTESSERACT_IMPORT_ERROR
        ("pytesseract", (is_pytesseract_available, PYTESSERACT_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ sacremoses åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ SACREMOSES_IMPORT_ERROR
        ("sacremoses", (is_sacremoses_available, SACREMOSES_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ pytorch_quantization åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ PYTORCH_QUANTIZATION_IMPORT_ERROR
        ("pytorch_quantization", (is_pytorch_quantization_available, PYTORCH_QUANTIZATION_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ sentencepiece åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ SENTENCEPIECE_IMPORT_ERROR
        ("sentencepiece", (is_sentencepiece_available, SENTENCEPIECE_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ sklearn åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ SKLEARN_IMPORT_ERROR
        ("sklearn", (is_sklearn_available, SKLEARN_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ speech åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ SPEECH_IMPORT_ERROR
        ("speech", (is_speech_available, SPEECH_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ tensorflow_probability åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ TENSORFLOW_PROBABILITY_IMPORT_ERROR
        ("tensorflow_probability", (is_tensorflow_probability_available, TENSORFLOW_PROBABILITY_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ tf åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ TENSORFLOW_IMPORT_ERROR
        ("tf", (is_tf_available, TENSORFLOW_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ tensorflow_text åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ TENSORFLOW_TEXT_IMPORT_ERROR
        ("tensorflow_text", (is_tensorflow_text_available, TENSORFLOW_TEXT_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ timm åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ TIMM_IMPORT_ERROR
        ("timm", (is_timm_available, TIMM_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ natten åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ NATTEN_IMPORT_ERROR
        ("natten", (is_natten_available, NATTEN_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ nltk åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ NLTK_IMPORT_ERROR
        ("nltk", (is_nltk_available, NLTK_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ tokenizers åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ TOKENIZERS_IMPORT_ERROR
        ("tokenizers", (is_tokenizers_available, TOKENIZERS_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ torch åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ PYTORCH_IMPORT_ERROR
        ("torch", (is_torch_available, PYTORCH_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ torchvision åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ TORCHVISION_IMPORT_ERROR
        ("torchvision", (is_torchvision_available, TORCHVISION_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ vision åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ VISION_IMPORT_ERROR
        ("vision", (is_vision_available, VISION_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ scipy åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ SCIPY_IMPORT_ERROR
        ("scipy", (is_scipy_available, SCIPY_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ accelerate åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ ACCELERATE_IMPORT_ERROR
        ("accelerate", (is_accelerate_available, ACCELERATE_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ oneccl_bind_pt åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ CCL_IMPORT_ERROR
        ("oneccl_bind_pt", (is_ccl_available, CCL_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ decord åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ DECORD_IMPORT_ERROR
        ("decord", (is_decord_available, DECORD_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ cython åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ CYTHON_IMPORT_ERROR
        ("cython", (is_cython_available, CYTHON_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ jieba åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ JIEBA_IMPORT_ERROR
        ("jieba", (is_jieba_available, JIEBA_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ peft åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ PEFT_IMPORT_ERROR
        ("peft", (is_peft_available, PEFT_IMPORT_ERROR)),
        # æ£€æŸ¥æ˜¯å¦ jinja åº“å¯ç”¨, å¦‚ä¸å¯ç”¨åˆ™å¼•å‘ JINJA_IMPORT_ERROR
        ("jinja", (is_jinja_available, JINJA_IMPORT_ERROR)),
    ]
    ```py  
# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ£€æŸ¥å¯¹è±¡æ‰€éœ€çš„åç«¯
def requires_backends(obj, backends):
    # å¦‚æœbackendsä¸æ˜¯åˆ—è¡¨æˆ–å…ƒç»„ç±»å‹ï¼Œåˆ™å°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨
    if not isinstance(backends, (list, tuple)):
        backends = [backends]

    # è·å–å¯¹è±¡çš„åç§°ï¼Œå¦‚æœæœ‰ "__name__" å±æ€§åˆ™ä½¿ç”¨è¯¥å±æ€§ï¼Œå¦åˆ™ä½¿ç”¨ç±»å
    name = obj.__name__ if hasattr(obj, "__name__") else obj.__class__.__name__

    # å¯¹äºæ²¡æœ‰ "TF" çš„ç±»è¿›è¡Œ torch-only çš„é”™è¯¯æç¤º
    if "torch" in backends and "tf" not in backends and not is_torch_available() and is_tf_available():
        raise ImportError(PYTORCH_IMPORT_ERROR_WITH_TF.format(name))

    # å¯¹äºå°è¯•åŠ è½½ TF ç±»çš„ PyTorch ç”¨æˆ·è¿›è¡Œåå‘é”™è¯¯æç¤º
    if "tf" in backends and "torch" not in backends and is_torch_available() and not is_tf_available():
        raise ImportError(TF_IMPORT_ERROR_WITH_PYTORCH.format(name))

    # å¯¹äºæ¯ä¸ªåç«¯è¿›è¡Œæ£€æŸ¥ï¼Œå¦‚æœæœ‰æœªæ»¡è¶³æ¡ä»¶çš„åˆ™æŠ›å‡º ImportError
    checks = (BACKENDS_MAPPING[backend] for backend in backends)
    failed = [msg.format(name) for available, msg in checks if not available()]
    if failed:
        raise ImportError("".join(failed))


# å®šä¹‰ä¸€ä¸ªå…ƒç±»ï¼Œç”¨äºåˆ›å»ºå ä½å¯¹è±¡ï¼Œå°è¯•è®¿é—®å¯¹è±¡çš„æ–¹æ³•æ—¶å°†æŠ›å‡º ImportError
class DummyObject(type):
    # é‡è½½__getattribute__æ–¹æ³•ï¼Œå®ç°è®¿é—®å¯¹è±¡æ–¹æ³•æ—¶æŠ›å‡º ImportError çš„åŠŸèƒ½
    def __getattribute__(cls, key):
        if key.startswith("_") and key != "_from_config":
            return super().__getattribute__(key)
        requires_backends(cls, cls._backends)


# åˆ¤æ–­å¯¹è±¡æ˜¯å¦ä¸º torch.fx.Proxy å¯¹è±¡
def is_torch_fx_proxy(x):
    # å¦‚æœå­˜åœ¨ torch.fx æ¨¡å—ï¼Œåˆ™åˆ¤æ–­æ˜¯å¦ä¸º torch.fx.Proxy å¯¹è±¡
    if is_torch_fx_available():
        import torch.fx
        return isinstance(x, torch.fx.Proxy)
    return False


# å®šä¹‰ä¸€ä¸ªæ‡’åŠ è½½æ¨¡å—ç±»ï¼Œå»¶è¿Ÿå¯¼å…¥æ¨¡å—ä¸­çš„å¯¹è±¡ç›´åˆ°å¯¹è±¡è¢«è®¿é—®æ—¶
class _LazyModule(ModuleType):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®æ¨¡å—çš„å±æ€§å’Œå¯¼å…¥ç»“æ„
    def __init__(self, name, module_file, import_structure, module_spec=None, extra_objects=None):
        super().__init__(name)
        self._modules = set(import_structure.keys())  # è®¾ç½®æ¨¡å—é›†åˆ
        self._class_to_module = {}  # è®¾ç½®ç±»ååˆ°æ¨¡å—åçš„æ˜ å°„å­—å…¸
        for key, values in import_structure.items():
            for value in values:
                self._class_to_module[value] = key
        # ç”¨äº IDE çš„è‡ªåŠ¨è¡¥å…¨
        self.__all__ = list(import_structure.keys()) + list(chain(*import_structure.values()))
        self.__file__ = module_file  # æ¨¡å—æ–‡ä»¶è·¯å¾„
        self.__spec__ = module_spec  # æ¨¡å—è§„èŒƒ
        self.__path__ = [os.path.dirname(module_file)]  # æ¨¡å—è·¯å¾„
        self._objects = {} if extra_objects is None else extra_objects  # é¢å¤–çš„å¯¹è±¡é›†åˆ
        self._name = name  # æ¨¡å—åç§°
        self._import_structure = import_structure  # å¯¼å…¥ç»“æ„
    # å®šä¹‰ __dir__ æ–¹æ³•ï¼Œè¿”å›å¯¹è±¡çš„å±æ€§åˆ—è¡¨
    def __dir__(self):
        # å…ˆè°ƒç”¨çˆ¶ç±»çš„ __dir__ æ–¹æ³•è·å–å±æ€§åˆ—è¡¨
        result = super().__dir__()
        # éå† self.__all__ ä¸­çš„å…ƒç´ 
        for attr in self.__all__:
            # å¦‚æœè¯¥å…ƒç´ ä¸åœ¨ result ä¸­
            if attr not in result:
                # åˆ™æ·»åŠ åˆ° result ä¸­
                result.append(attr)
        # è¿”å›æœ€ç»ˆçš„å±æ€§åˆ—è¡¨
        return result
    
    # å®šä¹‰ __getattr__ æ–¹æ³•ï¼Œç”¨äºè·å–å¯¹è±¡çš„å±æ€§
    def __getattr__(self, name: str) -> Any:
        # å¦‚æœ name åœ¨ self._objects ä¸­
        if name in self._objects:
            # è¿”å›å¯¹åº”çš„å€¼
            return self._objects[name]
        # å¦‚æœ name åœ¨ self._modules ä¸­
        elif name in self._modules:
            # è·å–å¯¹åº”çš„æ¨¡å—
            value = self._get_module(name)
        # å¦‚æœ name åœ¨ self._class_to_module çš„é”®ä¸­
        elif name in self._class_to_module.keys():
            # è·å–å¯¹åº”çš„æ¨¡å—
            module = self._get_module(self._class_to_module[name])
            # ä»æ¨¡å—ä¸­è·å–å¯¹åº”çš„å±æ€§å€¼
            value = getattr(module, name)
        else:
            # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œåˆ™æŠ›å‡ºå±æ€§é”™è¯¯å¼‚å¸¸
            raise AttributeError(f"module {self.__name__} has no attribute {name}")
        
        # å°†è·å–åˆ°çš„å±æ€§å€¼è®¾ç½®åˆ° self ä¸­
        setattr(self, name, value)
        # è¿”å›å±æ€§å€¼
        return value
    
    # å®šä¹‰ _get_module æ–¹æ³•ï¼Œç”¨äºè·å–æ¨¡å—
    def _get_module(self, module_name: str):
        try:
            # ä½¿ç”¨ importlib.import_module å¯¼å…¥æ¨¡å—
            return importlib.import_module("." + module_name, self.__name__)
        except Exception as e:
            # å¦‚æœå¯¼å…¥æ¨¡å—å‡ºé”™ï¼ŒæŠ›å‡ºè¿è¡Œæ—¶é”™è¯¯å¼‚å¸¸
            raise RuntimeError(
                f"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its"
                f" traceback):\n{e}"
            ) from e
    
    # å®šä¹‰ __reduce__ æ–¹æ³•ï¼Œç”¨äºå¯¹è±¡åºåˆ—åŒ–
    def __reduce__(self):
        # è¿”å›å…ƒç»„ï¼ŒåŒ…å«ç±»å¯¹è±¡å’Œæ„é€ å‚æ•°
        return (self.__class__, (self._name, self.__file__, self._import_structure))
class OptionalDependencyNotAvailable(BaseException):
    """è‡ªå®šä¹‰å¼‚å¸¸ç±»ï¼Œç”¨äºè¡¨ç¤ºæœªæ‰¾åˆ°å¯é€‰ä¾èµ–ã€‚"""


def direct_transformers_import(path: str, file="__init__.py") -> ModuleType:
    """ç›´æ¥å¯¼å…¥transformersæ¨¡å—

    Args:
        path (`str`): æºæ–‡ä»¶çš„è·¯å¾„
        file (`str`, optional): ä¸è·¯å¾„ç»„åˆçš„æ–‡ä»¶åã€‚é»˜è®¤ä¸º"__init__.py"ã€‚

    Returns:
        `ModuleType`: å¯¼å…¥çš„æ¨¡å—
    """
    # æ¨¡å—åç§°
    name = "transformers"
    # æºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
    location = os.path.join(path, file)
    # æ ¹æ®è·¯å¾„å’Œæ–‡ä»¶åˆ›å»ºæ¨¡å—çš„è§„èŒƒ
    spec = importlib.util.spec_from_file_location(name, location, submodule_search_locations=[path])
    # æ ¹æ®è§„èŒƒåˆ›å»ºæ¨¡å—å¯¹è±¡
    module = importlib.util.module_from_spec(spec)
    # æ‰§è¡Œæ¨¡å—å¯¹è±¡ï¼Œå°†å…¶è½½å…¥åˆ°å†…å­˜ä¸­
    spec.loader.exec_module(module)
    # è·å–æ¨¡å—å¯¹è±¡
    module = sys.modules[name]
    # è¿”å›å¯¼å…¥çš„æ¨¡å—
    return module
```