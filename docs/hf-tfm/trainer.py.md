# `.\transformers\trainer.py`

```
# è®¾ç½®æ–‡ä»¶ç¼–ç ä¸º utf-8
# ç‰ˆæƒå£°æ˜
# æ ¹æ® Apache è®¸å¯è¯ 2.0 ç‰ˆæœ¬ï¼Œä½ å¯ä»¥åœ¨éµå®ˆè®¸å¯è¯çš„æƒ…å†µä¸‹ä½¿ç”¨æ­¤æ–‡ä»¶
# ä½ å¯ä»¥åœ¨ä»¥ä¸‹é“¾æ¥è·å–è®¸å¯è¯çš„å‰¯æœ¬
#     http://www.apache.org/licenses/LICENSE-2.0
# é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æ˜¯åŸºäº"åŸæ ·"åˆ†å‘çš„ï¼Œ
# æ²¡æœ‰ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯æˆ–æ¡ä»¶ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºç‰¹å®šç”¨é€”çš„é€‚ç”¨æ€§ä¿è¯
# è¯·æŸ¥çœ‹è®¸å¯è¯ä»¥è·å–æœ‰å…³æƒé™å’Œé™åˆ¶çš„è¯¦ç»†ä¿¡æ¯

"""
Trainer ç±»ï¼Œç”¨äºè½»æ¾ä»å¤´å¼€å§‹è®­ç»ƒæˆ–åœ¨æ–°ä»»åŠ¡ä¸Šå¾®è°ƒ ğŸ¤— Transformers æ¨¡å‹ã€‚
"""

import contextlib
import copy
import functools
import glob
import importlib.metadata
import inspect
import math
import os
import random
import re
import shutil
import sys
import tempfile
import time
import warnings
from collections.abc import Mapping
from pathlib import Path
from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union

# åœ¨å¯¼å…¥ ML æ¡†æ¶ä¹‹å‰å¿…é¡»å¯¼å…¥é›†æˆ:
# isort: off
from .integrations import (
    get_reporting_integration_callbacks,
    hp_params,
)

# isort: on

import huggingface_hub.utils as hf_hub_utils
import numpy as np
import torch
import torch.distributed as dist
from huggingface_hub import ModelCard, create_repo, upload_folder
from packaging import version
from torch import nn
from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler

from . import __version__
from .configuration_utils import PretrainedConfig
from .data.data_collator import DataCollator, DataCollatorWithPadding, default_data_collator
from .debug_utils import DebugOption, DebugUnderflowOverflow
from .hyperparameter_search import ALL_HYPERPARAMETER_SEARCH_BACKENDS, default_hp_search_backend
from .integrations.deepspeed import deepspeed_init, deepspeed_load_checkpoint, is_deepspeed_available
from .modelcard import TrainingSummary
from .modeling_utils import PreTrainedModel, load_sharded_checkpoint, unwrap_model
from .models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES, MODEL_MAPPING_NAMES
from .optimization import Adafactor, get_scheduler
from .pytorch_utils import ALL_LAYERNORM_LAYERS, is_torch_greater_or_equal_than_1_13
from .tokenization_utils_base import PreTrainedTokenizerBase
from .trainer_callback import (
    CallbackHandler,
    DefaultFlowCallback,
    PrinterCallback,
    ProgressCallback,
    TrainerCallback,
    TrainerControl,
    TrainerState,
)
from .trainer_pt_utils import (
    DistributedTensorGatherer,
    IterableDatasetShard,
    LabelSmoother,
    LengthGroupedSampler,
    SequentialDistributedSampler,
    distributed_broadcast_scalars,
    distributed_concat,
    find_batch_size,
    get_dataloader_sampler,
    get_model_param_count,
    get_module_class_from_name,
    get_parameter_names,
    nested_concat,
    nested_detach,
    nested_numpify,
    nested_xla_mesh_reduce,
    # è°ƒç”¨ nested_xla_mesh_reduce å‡½æ•°ï¼Œæ‰§è¡ŒæŸç§ XLA ç½‘æ ¼å½’çº¦æ“ä½œ
    
    reissue_pt_warnings,
    # è°ƒç”¨ reissue_pt_warnings å‡½æ•°ï¼Œé‡æ–°å‘å‡º PyTorch çš„è­¦å‘Š
    
    remove_dummy_checkpoint,
    # è°ƒç”¨ remove_dummy_checkpoint å‡½æ•°ï¼Œç§»é™¤è™šæ‹Ÿæ£€æŸ¥ç‚¹
# å¯¼å…¥æ¨¡å—ä¸­çš„å‡½æ•°å’Œå˜é‡
from .trainer_utils import (
    PREFIX_CHECKPOINT_DIR,
    BestRun,
    EvalLoopOutput,
    EvalPrediction,
    HPSearchBackend,
    HubStrategy,
    IntervalStrategy,
    PredictionOutput,
    RemoveColumnsCollator,
    TrainerMemoryTracker,
    TrainOutput,
    default_compute_objective,
    denumpify_detensorize,
    enable_full_determinism,
    find_executable_batch_size,
    get_last_checkpoint,
    has_length,
    neftune_post_forward_hook,
    number_of_arguments,
    seed_worker,
    set_seed,
    speed_metrics,
)
# å¯¼å…¥æ¨¡å—ä¸­çš„ç±»å’Œå‡½æ•°
from .training_args import OptimizerNames, ParallelMode, TrainingArguments
# å¯¼å…¥æ¨¡å—ä¸­çš„å˜é‡å’Œå‡½æ•°
from .utils import (
    ADAPTER_CONFIG_NAME,
    ADAPTER_SAFE_WEIGHTS_NAME,
    ADAPTER_WEIGHTS_NAME,
    CONFIG_NAME,
    SAFE_WEIGHTS_INDEX_NAME,
    SAFE_WEIGHTS_NAME,
    WEIGHTS_INDEX_NAME,
    WEIGHTS_NAME,
    PushInProgress,
    can_return_loss,
    find_labels,
    is_accelerate_available,
    is_apex_available,
    is_bitsandbytes_available,
    is_datasets_available,
    is_in_notebook,
    is_ipex_available,
    is_peft_available,
    is_safetensors_available,
    is_sagemaker_dp_enabled,
    is_sagemaker_mp_enabled,
    is_torch_compile_available,
    is_torch_neuroncore_available,
    is_torch_npu_available,
    is_torch_tpu_available,
    logging,
    strtobool,
)
# å¯¼å…¥æ¨¡å—ä¸­çš„ç±»
from .utils.quantization_config import QuantizationMethod

# é»˜è®¤å›è°ƒå‡½æ•°åˆ—è¡¨
DEFAULT_CALLBACKS = [DefaultFlowCallback]
# é»˜è®¤è¿›åº¦å›è°ƒå‡½æ•°
DEFAULT_PROGRESS_CALLBACK = ProgressCallback

# å¦‚æœåœ¨ç¬”è®°æœ¬ä¸­
if is_in_notebook():
    # å¯¼å…¥ç¬”è®°æœ¬è¿›åº¦å›è°ƒå‡½æ•°
    from .utils.notebook import NotebookProgressCallback
    # è®¾ç½®é»˜è®¤è¿›åº¦å›è°ƒå‡½æ•°ä¸ºç¬”è®°æœ¬è¿›åº¦å›è°ƒå‡½æ•°
    DEFAULT_PROGRESS_CALLBACK = NotebookProgressCallback

# å¦‚æœå®‰è£…äº† Apex åº“
if is_apex_available():
    # å¯¼å…¥ Apex åº“çš„ amp æ¨¡å—
    from apex import amp

# å¦‚æœå®‰è£…äº† datasets åº“
if is_datasets_available():
    # å¯¼å…¥ datasets åº“
    import datasets

# å¦‚æœ Torch TPU å¯ç”¨
if is_torch_tpu_available(check_device=False):
    # å¯¼å…¥ Torch TPU æ¨¡å—
    import torch_xla.core.xla_model as xm
    import torch_xla.debug.metrics as met

# å¦‚æœå¯ç”¨äº† SageMaker MP
if is_sagemaker_mp_enabled():
    # å¯¼å…¥ SageMaker MP åº“
    import smdistributed.modelparallel.torch as smp
    from smdistributed.modelparallel import __version__ as SMP_VERSION
    # åˆ¤æ–­æ˜¯å¦ä¸º SageMaker MP 1.10 ä¹‹åçš„ç‰ˆæœ¬
    IS_SAGEMAKER_MP_POST_1_10 = version.parse(SMP_VERSION) >= version.parse("1.10")
    # å¯¼å…¥è®­ç»ƒå™¨ PT å·¥å…·
    from .trainer_pt_utils import smp_forward_backward, smp_forward_only, smp_gather, smp_nested_concat
else:
    IS_SAGEMAKER_MP_POST_1_10 = False

# å¦‚æœå®‰è£…äº† SafeTensors åº“
if is_safetensors_available():
    # å¯¼å…¥ SafeTensors åº“
    import safetensors.torch

# å¦‚æœå®‰è£…äº† PEFT åº“
if is_peft_available():
    # å¯¼å…¥ PEFT æ¨¡å‹
    from peft import PeftModel

# å¦‚æœå®‰è£…äº† Accelerate åº“
if is_accelerate_available():
    # å¯¼å…¥ Accelerate åº“çš„ç›¸å…³æ¨¡å—å’Œå‡½æ•°
    from accelerate import Accelerator, skip_first_batches
    from accelerate import __version__ as accelerate_version
    from accelerate.utils import (
        DistributedDataParallelKwargs,
        GradientAccumulationPlugin,
        load_fsdp_model,
        load_fsdp_optimizer,
        save_fsdp_model,
        save_fsdp_optimizer,
    )
    # é»˜è®¤æ•°æ®é‡‡æ ·å™¨åˆ—è¡¨
    DATA_SAMPLERS = [RandomSampler]
    # å¦‚æœ Accelerate ç‰ˆæœ¬å¤§äº 0.23.0
    if version.parse(accelerate_version) > version.parse("0.23.0"):
        # å¯¼å…¥ SeedableRandomSampler ç±»
        from accelerate.data_loader import SeedableRandomSampler
        # æ·»åŠ  SeedableRandomSampler åˆ°æ•°æ®é‡‡æ ·å™¨åˆ—è¡¨
        DATA_SAMPLERS += [SeedableRandomSampler]
    # å¦‚æœ DeepSpeed å¯ç”¨
    if is_deepspeed_available():
        # ä» accelerate.utils ä¸­å¯¼å…¥ DeepSpeedSchedulerWrapper å·¥å…·
        from accelerate.utils import DeepSpeedSchedulerWrapper
# åˆ¤æ–­ç»™å®šçš„æ¨¡å‹æ˜¯å¦æ˜¯ PeftModel ç±»å‹ï¼Œéœ€è¦æ»¡è¶³ PeftModel å¯ç”¨ä¸”ç»™å®šæ¨¡å‹ç¡®å®æ˜¯ PeftModel ç±»å‹
def _is_peft_model(model):
    # æ£€æŸ¥ PeftModel æ˜¯å¦å¯ç”¨ï¼Œå¹¶ä¸”ç»™å®šæ¨¡å‹æ˜¯å¦æ˜¯ PeftModel çš„å®ä¾‹
    return is_peft_available() and isinstance(model, PeftModel)


# å¦‚æœæ˜¯ç±»å‹æ£€æŸ¥é˜¶æ®µï¼Œå¯¼å…¥ optuna æ¨¡å—
if TYPE_CHECKING:
    import optuna


# å¯¼å…¥ logging æ¨¡å—å¹¶è·å– logger å¯¹è±¡
logger = logging.get_logger(__name__)


# ç”¨äºæ£€æŸ¥ç‚¹ä¿å­˜çš„æ–‡ä»¶å
TRAINING_ARGS_NAME = "training_args.bin"
TRAINER_STATE_NAME = "trainer_state.json"
OPTIMIZER_NAME = "optimizer.pt"
OPTIMIZER_NAME_BIN = "optimizer.bin"
SCHEDULER_NAME = "scheduler.pt"
SCALER_NAME = "scaler.pt"
FSDP_MODEL_NAME = "pytorch_model_fsdp"


# Trainer ç±»å®šä¹‰ï¼Œæä¾›äº†ä¸€ä¸ªç®€å•ä½†åŠŸèƒ½é½å…¨çš„ PyTorch è®­ç»ƒå’Œè¯„ä¼°å¾ªç¯ï¼Œé’ˆå¯¹ ğŸ¤— Transformers è¿›è¡Œäº†ä¼˜åŒ–
class Trainer:
    """
    Trainer is a simple but feature-complete training and eval loop for PyTorch, optimized for ğŸ¤— Transformers.

    Important attributes:

        - **model** -- Always points to the core model. If using a transformers model, it will be a [`PreTrainedModel`]
          subclass.
        - **model_wrapped** -- Always points to the most external model in case one or more other modules wrap the
          original model. This is the model that should be used for the forward pass. For example, under `DeepSpeed`,
          the inner model is wrapped in `DeepSpeed` and then again in `torch.nn.DistributedDataParallel`. If the inner
          model hasn't been wrapped, then `self.model_wrapped` is the same as `self.model`.
        - **is_model_parallel** -- Whether or not a model has been switched to a model parallel mode (different from
          data parallelism, this means some of the model layers are split on different GPUs).
        - **place_model_on_device** -- Whether or not to automatically place the model on the device - it will be set
          to `False` if model parallel or deepspeed is used, or if the default
          `TrainingArguments.place_model_on_device` is overridden to return `False` .
        - **is_in_train** -- Whether or not a model is currently running `train` (e.g. when `evaluate` is called while
          in `train`)

    """

    # Those are used as methods of the Trainer in examples.
    from .trainer_pt_utils import _get_learning_rate, log_metrics, metrics_format, save_metrics, save_state

    # Trainer ç±»çš„æ„é€ å‡½æ•°
    def __init__(
        self,
        model: Union[PreTrainedModel, nn.Module] = None,  # æ¨¡å‹å‚æ•°ï¼Œé»˜è®¤ä¸º None
        args: TrainingArguments = None,  # è®­ç»ƒå‚æ•°ï¼Œé»˜è®¤ä¸º None
        data_collator: Optional[DataCollator] = None,  # æ•°æ®æ”¶é›†å™¨ï¼Œé»˜è®¤ä¸º None
        train_dataset: Optional[Dataset] = None,  # è®­ç»ƒæ•°æ®é›†ï¼Œé»˜è®¤ä¸º None
        eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]] = None,  # è¯„ä¼°æ•°æ®é›†ï¼Œé»˜è®¤ä¸º None
        tokenizer: Optional[PreTrainedTokenizerBase] = None,  # åˆ†è¯å™¨ï¼Œé»˜è®¤ä¸º None
        model_init: Optional[Callable[[], PreTrainedModel]] = None,  # æ¨¡å‹åˆå§‹åŒ–å‡½æ•°ï¼Œé»˜è®¤ä¸º None
        compute_metrics: Optional[Callable[[EvalPrediction], Dict]] = None,  # è®¡ç®—æŒ‡æ ‡çš„å‡½æ•°ï¼Œé»˜è®¤ä¸º None
        callbacks: Optional[List[TrainerCallback]] = None,  # å›è°ƒå‡½æ•°åˆ—è¡¨ï¼Œé»˜è®¤ä¸º None
        optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None),  # ä¼˜åŒ–å™¨å…ƒç»„ï¼Œé»˜è®¤ä¸º (None, None)
        preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,  # ä¸ºæŒ‡æ ‡é¢„å¤„ç†é€»è¾‘çš„å‡½æ•°ï¼Œé»˜è®¤ä¸º None
    # æ¿€æ´»neftuneæ–¹æ³•ï¼Œæ ¹æ®ç»™å®šçš„æ¨¡å‹
    def _activate_neftune(self, model):
        r"""
        Activates the neftune as presented in this code: https://github.com/neelsjain/NEFTune and paper:
        https://arxiv.org/abs/2310.05914
        """
        # è§£åŒ…æ¨¡å‹
        unwrapped_model = unwrap_model(model)

        # æ£€æŸ¥æ˜¯å¦æ˜¯peftæ¨¡å‹ï¼Œè·å–å¯¹åº”çš„åµŒå…¥å±‚
        if _is_peft_model(unwrapped_model):
            embeddings = unwrapped_model.base_model.model.get_input_embeddings()
        else:
            embeddings = unwrapped_model.get_input_embeddings()

        # åˆ é™¤è§£åŒ…åçš„æ¨¡å‹
        del unwrapped_model

        # è®¾ç½®neftuneå™ªå£°alphaå€¼
        embeddings.neftune_noise_alpha = self.neftune_noise_alpha
        # æ³¨å†Œå‰å‘é’©å­
        hook_handle = embeddings.register_forward_hook(neftune_post_forward_hook)
        self.neftune_hook_handle = hook_handle
        return model

    # å…³é—­neftuneæ–¹æ³•
    def _deactivate_neftune(self, model):
        """
        Deactivates the neftune method. Make sure to call `_activate_neftune` first.
        """
        # å¦‚æœæ²¡æœ‰neftuneé’©å­å¥æŸ„ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
        if not hasattr(self, "neftune_hook_handle"):
            raise ValueError("Neftune is not activated make sure to call `trainer._activate_neftune()` first")

        # è§£åŒ…æ¨¡å‹
        unwrapped_model = unwrap_model(model)

        # æ£€æŸ¥æ˜¯å¦æ˜¯peftæ¨¡å‹ï¼Œè·å–å¯¹åº”çš„åµŒå…¥å±‚
        if _is_peft_model(unwrapped_model):
            embeddings = unwrapped_model.base_model.model.get_input_embeddings()
        else:
            embeddings = unwrapped_model.get_input_embeddings()

        # ç§»é™¤neftuneé’©å­å¥æŸ„
        self.neftune_hook_handle.remove()
        # åˆ é™¤neftuneå™ªå£°alphaå€¼å’Œè§£åŒ…åçš„æ¨¡å‹
        del embeddings.neftune_noise_alpha, unwrapped_model

    # æ·»åŠ å›è°ƒå‡½æ•°åˆ°å½“å‰çš„å›è°ƒåˆ—è¡¨ä¸­
    def add_callback(self, callback):
        """
        Add a callback to the current list of [`~transformers.TrainerCallback`].

        Args:
           callback (`type` or [`~transformers.TrainerCallback`]):
               A [`~transformers.TrainerCallback`] class or an instance of a [`~transformers.TrainerCallback`]. In the
               first case, will instantiate a member of that class.
        """
        self.callback_handler.add_callback(callback)

    # ä»å½“å‰çš„å›è°ƒåˆ—è¡¨ä¸­ç§»é™¤å›è°ƒå‡½æ•°å¹¶è¿”å›
    def pop_callback(self, callback):
        """
        Remove a callback from the current list of [`~transformers.TrainerCallback`] and returns it.

        If the callback is not found, returns `None` (and no error is raised).

        Args:
           callback (`type` or [`~transformers.TrainerCallback`]):
               A [`~transformers.TrainerCallback`] class or an instance of a [`~transformers.TrainerCallback`]. In the
               first case, will pop the first member of that class found in the list of callbacks.

        Returns:
            [`~transformers.TrainerCallback`]: The callback removed, if found.
        """
        return self.callback_handler.pop_callback(callback)
    # ä»å½“å‰çš„ [`~transformers.TrainerCallback`] åˆ—è¡¨ä¸­ç§»é™¤ä¸€ä¸ªå›è°ƒå‡½æ•°
    def remove_callback(self, callback):
        self.callback_handler.remove_callback(callback)

    # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ä¸Š
    def _move_model_to_device(self, model, device):
        # ä½¿ç”¨ model.to(device) æ–¹æ³•å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        model = model.to(device)
        # å¦‚æœæ¨¡å‹å¹¶è¡Œæ¨¡å¼ä¸º TPUï¼Œå¹¶ä¸”æ¨¡å‹æœ‰ tie_weights æ–¹æ³•ï¼Œåˆ™é‡æ–°ç»‘å®šæƒé‡
        if self.args.parallel_mode == ParallelMode.TPU and hasattr(model, "tie_weights"):
            model.tie_weights()

    # å¦‚æœéœ€è¦ï¼Œè®¾ç½®æ¨¡å‹çš„è¾“å…¥åˆ—æ ‡ç­¾
    def _set_signature_columns_if_needed(self):
        # å¦‚æœæœªè®¾ç½®æ¨¡å‹çš„è¾“å…¥åˆ—æ ‡ç­¾
        if self._signature_columns is None:
            # æ£€æŸ¥æ¨¡å‹çš„å‰å‘å‡½æ•°ç­¾åï¼Œä»…ä¿ç•™å…¶æ¥å—çš„å‚æ•°
            model_to_inspect = self.model
            if _is_peft_model(self.model):
                model_to_inspect = self.model.get_base_model()
            signature = inspect.signature(model_to_inspect.forward)
            self._signature_columns = list(signature.parameters.keys())
            # æ ‡ç­¾å¯èƒ½å‘½åä¸º label æˆ– label_idsï¼Œé»˜è®¤çš„æ•°æ®æ”¶é›†å™¨ä¼šå¤„ç†è¿™ä¸ªé—®é¢˜
            self._signature_columns += list(set(["label", "label_ids"] + self.label_names))

    # ç§»é™¤æ•°æ®é›†ä¸­æœªä½¿ç”¨çš„åˆ—
    def _remove_unused_columns(self, dataset: "datasets.Dataset", description: Optional[str] = None):
        # å¦‚æœæœªè®¾ç½®åˆ é™¤æœªä½¿ç”¨åˆ—çš„å‚æ•°ï¼Œåˆ™ç›´æ¥è¿”å›æ•°æ®é›†
        if not self.args.remove_unused_columns:
            return dataset
        self._set_signature_columns_if_needed()
        signature_columns = self._signature_columns

        # æ‰¾å‡ºæœªä½¿ç”¨çš„åˆ—
        ignored_columns = list(set(dataset.column_names) - set(signature_columns))
        if len(ignored_columns) > 0:
            dset_description = "" if description is None else f"in the {description} set"
            logger.info(
                f"The following columns {dset_description} don't have a corresponding argument in "
                f"`{self.model.__class__.__name__}.forward` and have been ignored: {', '.join(ignored_columns)}."
                f" If {', '.join(ignored_columns)} are not expected by `{self.model.__class__.__name__}.forward`, "
                " you can safely ignore this message."
            )

        # ä»æ•°æ®é›†ä¸­ç§»é™¤æœªä½¿ç”¨çš„åˆ—
        columns = [k for k in signature_columns if k in dataset.column_names]
        if version.parse(datasets.__version__) < version.parse("1.4.0"):
            dataset.set_format(
                type=dataset.format["type"], columns=columns, format_kwargs=dataset.format["format_kwargs"]
            )
            return dataset
        else:
            return dataset.remove_columns(ignored_columns)

    # è·å–ç§»é™¤äº†æŒ‡å®šåˆ—çš„æ•°æ®æ”¶é›†å™¨
    def _get_collator_with_removed_columns(
        self, data_collator: Callable, description: Optional[str] = None
    # å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå°†æ•°æ®æ”¶é›†å™¨åŒ…è£…åœ¨ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ä¸­ï¼Œç§»é™¤æœªä½¿ç”¨çš„åˆ—
    def wrap_data_collator(self, data_collator) -> Callable:
        # å¦‚æœä¸éœ€è¦ç§»é™¤æœªä½¿ç”¨çš„åˆ—ï¼Œåˆ™ç›´æ¥è¿”å›æ•°æ®æ”¶é›†å™¨
        if not self.args.remove_unused_columns:
            return data_collator
        # å¦‚æœéœ€è¦ç§»é™¤æœªä½¿ç”¨çš„åˆ—ï¼Œåˆ™è®¾ç½®ç­¾ååˆ—ï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
        self._set_signature_columns_if_needed()
        signature_columns = self._signature_columns

        # åˆ›å»ºä¸€ä¸ªç§»é™¤åˆ—çš„æ•°æ®æ”¶é›†å™¨
        remove_columns_collator = RemoveColumnsCollator(
            data_collator=data_collator,
            signature_columns=signature_columns,
            logger=logger,
            description=description,
            model_name=self.model.__class__.__name__,
        )
        return remove_columns_collator

    # è·å–è®­ç»ƒæ•°æ®é‡‡æ ·å™¨
    def _get_train_sampler(self) -> Optional[torch.utils.data.Sampler]:
        # å¦‚æœè®­ç»ƒæ•°æ®é›†ä¸ºç©ºæˆ–è€…æ²¡æœ‰é•¿åº¦ä¿¡æ¯ï¼Œåˆ™è¿”å›ç©º
        if self.train_dataset is None or not has_length(self.train_dataset):
            return None

        # æ„å»ºé‡‡æ ·å™¨
        if self.args.group_by_length:
            # å¦‚æœå¯ç”¨æŒ‰é•¿åº¦åˆ†ç»„ï¼Œå¹¶ä¸”è®­ç»ƒæ•°æ®é›†æ˜¯ datasets.Dataset ç±»å‹
            if is_datasets_available() and isinstance(self.train_dataset, datasets.Dataset):
                # è·å–é•¿åº¦ä¿¡æ¯
                lengths = (
                    self.train_dataset[self.args.length_column_name]
                    if self.args.length_column_name in self.train_dataset.column_names
                    else None
                )
            else:
                lengths = None
            # è·å–æ¨¡å‹è¾“å…¥åç§°
            model_input_name = self.tokenizer.model_input_names[0] if self.tokenizer is not None else None
            # è¿”å›ä¸€ä¸ªæŒ‰é•¿åº¦åˆ†ç»„çš„é‡‡æ ·å™¨
            return LengthGroupedSampler(
                self.args.train_batch_size * self.args.gradient_accumulation_steps,
                dataset=self.train_dataset,
                lengths=lengths,
                model_input_name=model_input_name,
            )

        else:
            # è¿”å›ä¸€ä¸ªéšæœºé‡‡æ ·å™¨
            return RandomSampler(self.train_dataset)
    def get_train_dataloader(self) -> DataLoader:
        """
        Returns the training [`~torch.utils.data.DataLoader`].

        Will use no sampler if `train_dataset` does not implement `__len__`, a random sampler (adapted to distributed
        training if necessary) otherwise.

        Subclass and override this method if you want to inject some custom behavior.
        """
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è®­ç»ƒæ•°æ®é›†
        if self.train_dataset is None:
            raise ValueError("Trainer: training requires a train_dataset.")

        # è·å–è®­ç»ƒæ•°æ®é›†å’Œæ•°æ®æ”¶é›†å™¨
        train_dataset = self.train_dataset
        data_collator = self.data_collator
        # å¦‚æœæ”¯æŒ datasets åº“ä¸”è®­ç»ƒæ•°æ®é›†æ˜¯ datasets.Dataset ç±»å‹ï¼Œåˆ™ç§»é™¤æœªä½¿ç”¨çš„åˆ—
        if is_datasets_available() and isinstance(train_dataset, datasets.Dataset):
            train_dataset = self._remove_unused_columns(train_dataset, description="training")
        else:
            # å¦åˆ™ï¼Œè·å–ç§»é™¤æœªä½¿ç”¨åˆ—åçš„æ•°æ®æ”¶é›†å™¨
            data_collator = self._get_collator_with_removed_columns(data_collator, description="training")

        # è®¾ç½®æ•°æ®åŠ è½½å™¨å‚æ•°
        dataloader_params = {
            "batch_size": self._train_batch_size,
            "collate_fn": data_collator,
            "num_workers": self.args.dataloader_num_workers,
            "pin_memory": self.args.dataloader_pin_memory,
            "persistent_workers": self.args.dataloader_persistent_workers,
        }

        # å¦‚æœè®­ç»ƒæ•°æ®é›†ä¸æ˜¯ torch.utils.data.IterableDataset ç±»å‹ï¼Œåˆ™è®¾ç½®é‡‡æ ·å™¨å’Œæ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªæ‰¹æ¬¡
        if not isinstance(train_dataset, torch.utils.data.IterableDataset):
            dataloader_params["sampler"] = self._get_train_sampler()
            dataloader_params["drop_last"] = self.args.dataloader_drop_last
            dataloader_params["worker_init_fn"] = seed_worker

        # å‡†å¤‡æ•°æ®åŠ è½½å™¨å¹¶è¿”å›
        return self.accelerator.prepare(DataLoader(train_dataset, **dataloader_params))

    def _get_eval_sampler(self, eval_dataset: Dataset) -> Optional[torch.utils.data.Sampler]:
        # Deprecated code
        # å¦‚æœä½¿ç”¨æ—§çš„é¢„æµ‹å¾ªç¯
        if self.args.use_legacy_prediction_loop:
            # å¦‚æœæ˜¯åœ¨ Torch TPU ç¯å¢ƒä¸‹
            if is_torch_tpu_available():
                return SequentialDistributedSampler(
                    eval_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal()
                )
            # å¦‚æœæ˜¯åœ¨ SageMaker MP ç¯å¢ƒä¸‹
            elif is_sagemaker_mp_enabled():
                return SequentialDistributedSampler(
                    eval_dataset,
                    num_replicas=smp.dp_size(),
                    rank=smp.dp_rank(),
                    batch_size=self.args.per_device_eval_batch_size,
                )
            else:
                return SequentialSampler(eval_dataset)

        # å¦‚æœ world_size å°äºç­‰äº 1ï¼Œåˆ™è¿”å›é¡ºåºé‡‡æ ·å™¨ï¼›å¦åˆ™è¿”å› None
        if self.args.world_size <= 1:
            return SequentialSampler(eval_dataset)
        else:
            return None
    def get_eval_dataloader(self, eval_dataset: Optional[Dataset] = None) -> DataLoader:
        """
        Returns the evaluation [`~torch.utils.data.DataLoader`].

        Subclass and override this method if you want to inject some custom behavior.

        Args:
            eval_dataset (`torch.utils.data.Dataset`, *optional*):
                If provided, will override `self.eval_dataset`. If it is a [`~datasets.Dataset`], columns not accepted
                by the `model.forward()` method are automatically removed. It must implement `__len__`.
        """
        # æ£€æŸ¥æ˜¯å¦æä¾›äº†è¯„ä¼°æ•°æ®é›†ï¼Œå¦‚æœæ²¡æœ‰åˆ™æŠ›å‡ºå¼‚å¸¸
        if eval_dataset is None and self.eval_dataset is None:
            raise ValueError("Trainer: evaluation requires an eval_dataset.")
        # å¦‚æœæä¾›äº†è¯„ä¼°æ•°æ®é›†ï¼Œåˆ™ä½¿ç”¨æä¾›çš„æ•°æ®é›†ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤çš„self.eval_dataset
        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset
        data_collator = self.data_collator

        # å¦‚æœdatasetsåº“å¯ç”¨ä¸”è¯„ä¼°æ•°æ®é›†æ˜¯datasets.Datasetç±»å‹ï¼Œåˆ™ç§»é™¤ä¸è¢«model.forward()æ–¹æ³•æ¥å—çš„åˆ—
        if is_datasets_available() and isinstance(eval_dataset, datasets.Dataset):
            eval_dataset = self._remove_unused_columns(eval_dataset, description="evaluation")
        else:
            # å¦åˆ™ï¼Œä½¿ç”¨_get_collator_with_removed_columnsæ–¹æ³•ç§»é™¤ä¸éœ€è¦çš„åˆ—
            data_collator = self._get_collator_with_removed_columns(data_collator, description="evaluation")

        # è®¾ç½®DataLoaderçš„å‚æ•°
        dataloader_params = {
            "batch_size": self.args.eval_batch_size,
            "collate_fn": data_collator,
            "num_workers": self.args.dataloader_num_workers,
            "pin_memory": self.args.dataloader_pin_memory,
            "persistent_workers": self.args.dataloader_persistent_workers,
        }

        # å¦‚æœè¯„ä¼°æ•°æ®é›†ä¸æ˜¯torch.utils.data.IterableDatasetç±»å‹ï¼Œåˆ™è®¾ç½®samplerå’Œdrop_lastå‚æ•°
        if not isinstance(eval_dataset, torch.utils.data.IterableDataset):
            dataloader_params["sampler"] = self._get_eval_sampler(eval_dataset)
            dataloader_params["drop_last"] = self.args.dataloader_drop_last

        # ä½¿ç”¨åŠ é€Ÿå™¨å‡†å¤‡DataLoaderå¹¶è¿”å›
        return self.accelerator.prepare(DataLoader(eval_dataset, **dataloader_params))
    def get_test_dataloader(self, test_dataset: Dataset) -> DataLoader:
        """
        è¿”å›æµ‹è¯•[`~torch.utils.data.DataLoader`]ã€‚

        å¦‚æœæ‚¨å¸Œæœ›æ³¨å…¥ä¸€äº›è‡ªå®šä¹‰è¡Œä¸ºï¼Œè¯·å­ç±»åŒ–å¹¶é‡å†™æ­¤æ–¹æ³•ã€‚

        Args:
            test_dataset (`torch.utils.data.Dataset`, *optional*):
                è¦ä½¿ç”¨çš„æµ‹è¯•æ•°æ®é›†ã€‚å¦‚æœå®ƒæ˜¯ä¸€ä¸ª[`~datasets.Dataset`]ï¼Œåˆ™ä¼šè‡ªåŠ¨åˆ é™¤`model.forward()`æ–¹æ³•ä¸æ¥å—çš„åˆ—ã€‚å®ƒå¿…é¡»å®ç°`__len__`ã€‚
        """
        data_collator = self.data_collator

        if is_datasets_available() and isinstance(test_dataset, datasets.Dataset):
            # å¦‚æœå¯ç”¨ï¼Œå¹¶ä¸”æµ‹è¯•æ•°æ®é›†æ˜¯datasets.Datasetçš„å®ä¾‹ï¼Œåˆ™åˆ é™¤æœªä½¿ç”¨çš„åˆ—
            test_dataset = self._remove_unused_columns(test_dataset, description="test")
        else:
            # å¦åˆ™ï¼Œæ ¹æ®æµ‹è¯•æ•°æ®é›†åˆ›å»ºæ•°æ®æ”¶é›†å™¨
            data_collator = self._get_collator_with_removed_columns(data_collator, description="test")

        dataloader_params = {
            "batch_size": self.args.eval_batch_size,
            "collate_fn": data_collator,
            "num_workers": self.args.dataloader_num_workers,
            "pin_memory": self.args.dataloader_pin_memory,
            "persistent_workers": self.args.dataloader_persistent_workers,
        }

        if not isinstance(test_dataset, torch.utils.data.IterableDataset):
            # å¦‚æœæµ‹è¯•æ•°æ®é›†ä¸æ˜¯å¯è¿­ä»£æ•°æ®é›†ï¼Œåˆ™è®¾ç½®é‡‡æ ·å™¨å’Œæ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªæ‰¹æ¬¡
            dataloader_params["sampler"] = self._get_eval_sampler(test_dataset)
            dataloader_params["drop_last"] = self.args.dataloader_drop_last

        # æˆ‘ä»¬ä½¿ç”¨ä¸è¯„ä¼°ç›¸åŒçš„æ‰¹é‡å¤§å°ã€‚
        return self.accelerator.prepare(DataLoader(test_dataset, **dataloader_params))

    def create_optimizer_and_scheduler(self, num_training_steps: int):
        """
        è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚

        æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè‰¯å¥½çš„é»˜è®¤å€¼ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨å…¶ä»–å†…å®¹ï¼Œå¯ä»¥é€šè¿‡Trainerçš„initä¼ é€’ä¸€ä¸ªå…ƒç»„åˆ°`optimizers`ï¼Œæˆ–è€…åœ¨å­ç±»ä¸­é‡å†™æ­¤æ–¹æ³•ï¼ˆæˆ–`create_optimizer`å’Œ/æˆ–
        `create_scheduler`ï¼‰ã€‚
        """
        self.create_optimizer()
        if IS_SAGEMAKER_MP_POST_1_10 and smp.state.cfg.fp16:
            # å¦‚æœSagemakerç‰ˆæœ¬å¤§äºç­‰äº1.10å¹¶ä¸”å¯ç”¨äº†fp16ï¼Œåˆ™è§£å¼€ä¼˜åŒ–å™¨
            optimizer = self.optimizer.optimizer
        else:
            optimizer = self.optimizer
        self.create_scheduler(num_training_steps=num_training_steps, optimizer=optimizer)

    def get_decay_parameter_names(self, model) -> List[str]:
        """
        è·å–å°†åº”ç”¨æƒé‡è¡°å‡çš„æ‰€æœ‰å‚æ•°åç§°

        æ³¨æ„ï¼ŒæŸäº›æ¨¡å‹å®ç°äº†è‡ªå·±çš„layernormè€Œä¸æ˜¯è°ƒç”¨nn.LayerNormï¼Œå› æ­¤è¿™äº›æ¨¡å—ä»ç„¶å¯èƒ½ä¼šåº”ç”¨æƒé‡è¡°å‡ï¼Œå› ä¸ºæ­¤å‡½æ•°ä»…è¿‡æ»¤å‡ºnn.LayerNormçš„å®ä¾‹
        """
        # è·å–å°†åº”ç”¨æƒé‡è¡°å‡çš„æ‰€æœ‰å‚æ•°åç§°
        decay_parameters = get_parameter_names(model, ALL_LAYERNORM_LAYERS)
        # è¿‡æ»¤æ‰åŒ…å«â€œbiasâ€çš„å‚æ•°åç§°
        decay_parameters = [name for name in decay_parameters if "bias" not in name]
        return decay_parameters
    def create_optimizer(self):
        """
        Setup the optimizer.

        We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the
        Trainer's init through `optimizers`, or subclass and override this method in a subclass.
        """
        # å¦‚æœå¯ç”¨äº† SageMaker Model Parallelismï¼Œåˆ™ä½¿ç”¨åŒ…è£…åçš„æ¨¡å‹ï¼Œå¦åˆ™ä½¿ç”¨åŸå§‹æ¨¡å‹
        opt_model = self.model_wrapped if is_sagemaker_mp_enabled() else self.model

        # å¦‚æœæœªæŒ‡å®šä¼˜åŒ–å™¨ï¼Œåˆ™æ ¹æ®æ¨¡å‹å‚æ•°è®¾ç½®é»˜è®¤ä¼˜åŒ–å™¨
        if self.optimizer is None:
            # è·å–éœ€è¦è¿›è¡Œæƒé‡è¡°å‡çš„å‚æ•°å
            decay_parameters = self.get_decay_parameter_names(opt_model)
            # åˆ†ç»„æ¨¡å‹å‚æ•°ï¼Œæ ¹æ®æ˜¯å¦éœ€è¦è¡°å‡å°†å‚æ•°åˆ†ä¸ºä¸¤ç»„
            optimizer_grouped_parameters = [
                {
                    "params": [
                        p for n, p in opt_model.named_parameters() if (n in decay_parameters and p.requires_grad)
                    ],
                    "weight_decay": self.args.weight_decay,
                },
                {
                    "params": [
                        p for n, p in opt_model.named_parameters() if (n not in decay_parameters and p.requires_grad)
                    ],
                    "weight_decay": 0.0,
                },
            ]

            # è·å–ä¼˜åŒ–å™¨ç±»å’Œåˆå§‹åŒ–å‚æ•°
            optimizer_cls, optimizer_kwargs = Trainer.get_optimizer_cls_and_kwargs(self.args)

            # æ ¹æ®ä¼˜åŒ–å™¨ç±»å’Œå‚æ•°åˆå§‹åŒ–ä¼˜åŒ–å™¨
            self.optimizer = optimizer_cls(optimizer_grouped_parameters, **optimizer_kwargs)
            # å¦‚æœä¼˜åŒ–å™¨æ˜¯ Adam8bitï¼Œåˆ™è¿›è¡Œç‰¹å®šçš„é…ç½®
            if optimizer_cls.__name__ == "Adam8bit":
                # å¯¼å…¥ bitsandbytes æ¨¡å—
                import bitsandbytes

                # è·å–å…¨å±€ä¼˜åŒ–ç®¡ç†å™¨å®ä¾‹
                manager = bitsandbytes.optim.GlobalOptimManager.get_instance()

                # åˆå§‹åŒ–è·³è¿‡å‚æ•°è®¡æ•°å™¨
                skipped = 0
                # éå†æ¨¡å‹çš„æ‰€æœ‰æ¨¡å—
                for module in opt_model.modules():
                    # å¦‚æœæ¨¡å—æ˜¯ nn.Embedding ç±»å‹
                    if isinstance(module, nn.Embedding):
                        # ç»Ÿè®¡è·³è¿‡çš„å‚æ•°æ•°é‡
                        skipped += sum({p.data_ptr(): p.numel() for p in module.parameters()}.values())
                        # è®°å½•è·³è¿‡çš„å‚æ•°ä¿¡æ¯
                        logger.info(f"skipped {module}: {skipped/2**20}M params")
                        # æ³¨å†Œæ¨¡å—è¦†ç›–ä»¥è¿›è¡Œä¼˜åŒ–
                        manager.register_module_override(module, "weight", {"optim_bits": 32})
                        # è®°å½•è°ƒè¯•ä¿¡æ¯
                        logger.debug(f"bitsandbytes: will optimize {module} in fp32")
                # è®°å½•æ€»å…±è·³è¿‡çš„å‚æ•°æ•°é‡
                logger.info(f"skipped: {skipped/2**20}M params")

        # å¦‚æœå¯ç”¨äº† SageMaker Model Parallelismï¼Œåˆ™ä½¿ç”¨åˆ†å¸ƒå¼ä¼˜åŒ–å™¨
        if is_sagemaker_mp_enabled():
            self.optimizer = smp.DistributedOptimizer(self.optimizer)

        # è¿”å›ä¼˜åŒ–å™¨
        return self.optimizer

    @staticmethod
    def create_scheduler(self, num_training_steps: int, optimizer: torch.optim.Optimizer = None):
        """
        è®¾ç½®è°ƒåº¦å™¨ã€‚è®­ç»ƒå™¨çš„ä¼˜åŒ–å™¨å¿…é¡»åœ¨è°ƒç”¨æ­¤æ–¹æ³•ä¹‹å‰è®¾ç½®å¥½ï¼Œæˆ–è€…ä½œä¸ºå‚æ•°ä¼ é€’ã€‚

        Args:
            num_training_steps (int): è¦æ‰§è¡Œçš„è®­ç»ƒæ­¥æ•°ã€‚
        """
        # å¦‚æœè°ƒåº¦å™¨å°šæœªè®¾ç½®ï¼Œåˆ™æ ¹æ®å‚æ•°è®¾ç½®è°ƒåº¦å™¨
        if self.lr_scheduler is None:
            self.lr_scheduler = get_scheduler(
                self.args.lr_scheduler_type,
                optimizer=self.optimizer if optimizer is None else optimizer,
                num_warmup_steps=self.args.get_warmup_steps(num_training_steps),
                num_training_steps=num_training_steps,
                scheduler_specific_kwargs=self.args.lr_scheduler_kwargs,
            )
            self._created_lr_scheduler = True
        # è¿”å›è®¾ç½®å¥½çš„è°ƒåº¦å™¨
        return self.lr_scheduler

    def num_examples(self, dataloader: DataLoader) -> int:
        """
        é€šè¿‡è®¿é—®å…¶æ•°æ®é›†æ¥è·å– [`~torch.utils.data.DataLoader`] ä¸­æ ·æœ¬æ•°é‡çš„è¾…åŠ©å‡½æ•°ã€‚å½“dataloader.datasetä¸å­˜åœ¨æˆ–æ²¡æœ‰é•¿åº¦æ—¶ï¼Œå°½æœ€å¤§åŠªåŠ›ä¼°è®¡ã€‚
        """
        try:
            dataset = dataloader.dataset
            # å¯¹äºIterableDatasetShardçš„ç‰¹æ®Šæƒ…å†µï¼Œéœ€è¦æ·±å…¥æŒ–æ˜
            if isinstance(dataset, IterableDatasetShard):
                return len(dataloader.dataset.dataset)
            return len(dataloader.dataset)
        except (NameError, AttributeError, TypeError):  # æ²¡æœ‰æ•°æ®é›†æˆ–é•¿åº¦ï¼Œé€šè¿‡dataloaderçš„é•¿åº¦ä¼°è®¡
            return len(dataloader) * self.args.per_device_train_batch_size

    def num_tokens(self, train_dl: DataLoader, max_steps: Optional[int] = None) -> int:
        """
        é€šè¿‡æšä¸¾dataloaderæ¥è·å– [`~torch.utils.data.DataLoader`] ä¸­æ ‡è®°æ•°é‡çš„è¾…åŠ©å‡½æ•°ã€‚
        """
        train_tokens = 0
        try:
            for step, batch in enumerate(train_dl):
                tokens = batch["input_ids"].numel()
                if max_steps is not None:
                    return tokens * max_steps
                train_tokens += tokens
            return train_tokens
        except KeyError:
            logger.warning("æ— æ³•ä»dataloaderè·å–æ ‡è®°æ•°é‡")
            return train_tokens
    def _hp_search_setup(self, trial: Union["optuna.Trial", Dict[str, Any]]):
        """HP search setup code"""
        # è®¾ç½®è¯•éªŒå‚æ•°
        self._trial = trial

        # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯æœªæŒ‡å®šæˆ–è€…è¯•éªŒä¸ºç©ºï¼Œåˆ™è¿”å›
        if self.hp_search_backend is None or trial is None:
            return
        # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯ä¸º OPTUNA
        if self.hp_search_backend == HPSearchBackend.OPTUNA:
            # ä»è¯•éªŒä¸­è·å–è¶…å‚æ•°ç©ºé—´
            params = self.hp_space(trial)
        # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯ä¸º RAY
        elif self.hp_search_backend == HPSearchBackend.RAY:
            # ç›´æ¥ä»è¯•éªŒä¸­è·å–å‚æ•°ï¼ŒåŒæ—¶ç§»é™¤ 'wandb' é”®
            params = trial
            params.pop("wandb", None)
        # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯ä¸º SIGOPT
        elif self.hp_search_backend == HPSearchBackend.SIGOPT:
            # å°†è¯•éªŒåˆ†é…çš„å‚æ•°è½¬æ¢æˆå­—å…¸å½¢å¼
            params = {k: int(v) if isinstance(v, str) else v for k, v in trial.assignments.items()}
        # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯ä¸º WANDB
        elif self.hp_search_backend == HPSearchBackend.WANDB:
            # ç›´æ¥ä½¿ç”¨è¯•éªŒå‚æ•°
            params = trial

        # éå†å‚æ•°å­—å…¸ï¼Œå°†å‚æ•°è®¾ç½®åˆ° `TrainingArguments` ä¸­
        for key, value in params.items():
            if not hasattr(self.args, key):
                # è‹¥åœ¨ `TrainingArguments` ä¸­ä¸å­˜åœ¨å¯¹åº”çš„å±æ€§ï¼Œåˆ™å‘å‡ºè­¦å‘Š
                logger.warning(
                    f"Trying to set {key} in the hyperparameter search but there is no corresponding field in"
                    " `TrainingArguments`."
                )
                continue
            old_attr = getattr(self.args, key, None)
            # å°†å‚æ•°å€¼è½¬æ¢ä¸ºæ­£ç¡®çš„ç±»å‹
            if old_attr is not None:
                value = type(old_attr)(value)

            setattr(self.args, key, value)
        
        # æ‰“å°ç›¸åº”çš„æ—¥å¿—ï¼Œæ˜¾ç¤ºè¶…å‚æ•°è®¾ç½®ä¿¡æ¯
        if self.hp_search_backend == HPSearchBackend.OPTUNA:
            logger.info(f"Trial: {trial.params}")
        if self.hp_search_backend == HPSearchBackend.SIGOPT:
            logger.info(f"SigOpt Assignments: {trial.assignments}")
        if self.hp_search_backend == HPSearchBackend.WANDB:
            logger.info(f"W&B Sweep parameters: {trial}")
        
        # å¦‚æœå¯ç”¨äº† DeepSpeedï¼Œåˆ™é‡æ–°æ„å»º DeepSpeed é…ç½®ä»¥åæ˜ æ›´æ–°çš„è®­ç»ƒå‚æ•°
        if self.is_deepspeed_enabled:
            if self.args.deepspeed is None:
                raise ValueError("For sweeps with deepspeed, `args.deepspeed` must be set")
            # é‡æ–°æ„å»º DeepSpeed é…ç½®
            from accelerate.utils import DeepSpeedPlugin
            from transformers.integrations.deepspeed import HfTrainerDeepSpeedConfig

            self.args.hf_deepspeed_config = HfTrainerDeepSpeedConfig(self.args.deepspeed)
            self.args.hf_deepspeed_config.trainer_config_process(self.args)
            self.args.deepspeed_plugin = DeepSpeedPlugin(hf_ds_config=self.args.hf_deepspeed_config)

        # åˆ›å»ºåŠ é€Ÿå™¨å¹¶è¿›è¡Œåå¤„ç†
        self.create_accelerator_and_postprocess()
    # å°†è®­ç»ƒæŒ‡æ ‡æŠ¥å‘Šç»™è¶…å‚æ•°æœç´¢åç«¯
    def _report_to_hp_search(self, trial: Union["optuna.Trial", Dict[str, Any]], step: int, metrics: Dict[str, float]):
        # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯ä¸ºç©ºæˆ–è¯•éªŒä¸ºç©ºï¼Œåˆ™è¿”å›
        if self.hp_search_backend is None or trial is None:
            return
        # å¤åˆ¶æŒ‡æ ‡å­—å…¸
        metrics = metrics.copy()
        # è®¡ç®—ç›®æ ‡å€¼
        self.objective = self.compute_objective(metrics)
        # å¦‚æœä½¿ç”¨çš„æ˜¯ Optuna è¶…å‚æ•°æœç´¢åç«¯
        if self.hp_search_backend == HPSearchBackend.OPTUNA:
            import optuna

            # å¦‚æœè¯•éªŒä¸æ˜¯å¤šç›®æ ‡
            if not trial.study._is_multi_objective():
                # æŠ¥å‘Šç›®æ ‡å€¼
                trial.report(self.objective, step)
                # å¦‚æœè¯•éªŒåº”è¯¥å‰ªæ
                if trial.should_prune():
                    # åœ¨è®­ç»ƒç»“æŸæ—¶è°ƒç”¨å›è°ƒå¤„ç†ç¨‹åº
                    self.callback_handler.on_train_end(self.args, self.state, self.control)
                    # æŠ›å‡ºè¯•éªŒè¢«å‰ªæçš„å¼‚å¸¸
                    raise optuna.TrialPruned()
        # å¦‚æœä½¿ç”¨çš„æ˜¯ Ray è¶…å‚æ•°æœç´¢åç«¯
        elif self.hp_search_backend == HPSearchBackend.RAY:
            import ray.train

            # ä½¿ç”¨ä¸´æ—¶ç›®å½•
            with tempfile.TemporaryDirectory() as temp_checkpoint_dir:
                checkpoint = None
                # å¦‚æœåº”è¯¥ä¿å­˜
                if self.control.should_save:
                    # ä¿å­˜æ£€æŸ¥ç‚¹
                    self._tune_save_checkpoint(checkpoint_dir=temp_checkpoint_dir)
                    checkpoint = ray.train.Checkpoint.from_directory(temp_checkpoint_dir)
                # æ·»åŠ ç›®æ ‡å€¼åˆ°æŒ‡æ ‡å­—å…¸
                metrics["objective"] = self.objective
                # æŠ¥å‘ŠæŒ‡æ ‡
                ray.train.report(metrics, checkpoint=checkpoint)

    # ä¿å­˜æ£€æŸ¥ç‚¹
    def _tune_save_checkpoint(self, checkpoint_dir: str):
        # è®¾ç½®è¾“å‡ºç›®å½•
        output_dir = os.path.join(checkpoint_dir, f"{PREFIX_CHECKPOINT_DIR}-{self.state.global_step}")
        # ä¿å­˜æ¨¡å‹
        self.save_model(output_dir, _internal_call=True)
        # å¦‚æœåº”è¯¥ä¿å­˜
        if self.args.should_save:
            # ä¿å­˜çŠ¶æ€åˆ° JSON æ–‡ä»¶
            self.state.save_to_json(os.path.join(output_dir, TRAINER_STATE_NAME))
            # ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€
            torch.save(self.optimizer.state_dict(), os.path.join(output_dir, OPTIMIZER_NAME))
            # ä¿å­˜å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
            torch.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))

    # è°ƒç”¨æ¨¡å‹åˆå§‹åŒ–å‡½æ•°
    def call_model_init(self, trial=None):
        # è·å–æ¨¡å‹åˆå§‹åŒ–å‡½æ•°çš„å‚æ•°æ•°é‡
        model_init_argcount = number_of_arguments(self.model_init)
        # å¦‚æœå‚æ•°æ•°é‡ä¸º 0
        if model_init_argcount == 0:
            # è°ƒç”¨æ¨¡å‹åˆå§‹åŒ–å‡½æ•°
            model = self.model_init()
        # å¦‚æœå‚æ•°æ•°é‡ä¸º 1
        elif model_init_argcount == 1:
            # ä½¿ç”¨è¯•éªŒå‚æ•°è°ƒç”¨æ¨¡å‹åˆå§‹åŒ–å‡½æ•°
            model = self.model_init(trial)
        else:
            # æŠ›å‡ºå¼‚å¸¸ï¼Œæ¨¡å‹åˆå§‹åŒ–å‡½æ•°åº”è¯¥æœ‰ 0 æˆ– 1 ä¸ªå‚æ•°
            raise RuntimeError("model_init should have 0 or 1 argument.")

        # å¦‚æœæ¨¡å‹ä¸ºç©º
        if model is None:
            # æŠ›å‡ºå¼‚å¸¸ï¼Œæ¨¡å‹åˆå§‹åŒ–å‡½æ•°ä¸åº”è¿”å› None
            raise RuntimeError("model_init should not return None.")

        # è¿”å›æ¨¡å‹
        return model
    # ä½¿ç”¨ Torch JIT æ¨¡å¼å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°
    def torch_jit_model_eval(self, model, dataloader, training=False):
        # å¦‚æœä¸æ˜¯è®­ç»ƒæ¨¡å¼
        if not training:
            # å¦‚æœæ•°æ®åŠ è½½å™¨ä¸ºç©º
            if dataloader is None:
                logger.warning("failed to use PyTorch jit mode due to current dataloader is none.")
                return model
            # è·å–ä¸€ä¸ªç¤ºä¾‹æ‰¹æ¬¡æ•°æ®å¹¶å‡†å¤‡è¾“å…¥
            example_batch = next(iter(dataloader))
            example_batch = self._prepare_inputs(example_batch)
            try:
                # å¤åˆ¶æ¨¡å‹å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                jit_model = copy.copy(model)
                jit_model.eval()
                # ä¿å­˜åŸå§‹çš„å‰å‘ä¼ æ’­å‡½æ•°
                original_forward = jit_model.__dict__.pop("_original_forward", None)
                # ä»æ¨¡å‹ä¸­ç§»é™¤æ··åˆç²¾åº¦é’©å­
                if original_forward:
                    jit_model.forward = original_forward
                # ç¦ç”¨è‡ªåŠ¨ç¼“å­˜åŠ é€Ÿå™¨ï¼Œå…³é—­æ¢¯åº¦è®¡ç®—
                with self.accelerator.autocast(cache_enabled=False), torch.no_grad():
                    # æ ¹æ® Torch ç‰ˆæœ¬é€‰æ‹©ä¸åŒçš„ JIT è·Ÿè¸ªæ–¹å¼
                    if version.parse(version.parse(torch.__version__).base_version) >= version.parse("2.0.0"):
                        if isinstance(example_batch, dict):
                            jit_model = torch.jit.trace(jit_model, example_kwarg_inputs=example_batch, strict=False)
                        else:
                            jit_model = torch.jit.trace(
                                jit_model,
                                example_kwarg_inputs={key: example_batch[key] for key in example_batch},
                                strict=False,
                            )
                    else:
                        # åˆ›å»º JIT è¾“å…¥
                        jit_inputs = []
                        for key in example_batch:
                            example_tensor = torch.ones_like(example_batch[key])
                            jit_inputs.append(example_tensor)
                        jit_inputs = tuple(jit_inputs)
                        jit_model = torch.jit.trace(jit_model, jit_inputs, strict=False)
                # å†»ç»“ JIT æ¨¡å‹
                jit_model = torch.jit.freeze(jit_model)
                # ä½¿ç”¨ JIT æ¨¡å‹è¿›è¡Œæ¨ç†
                with torch.no_grad():
                    jit_model(**example_batch)
                    jit_model(**example_batch)
                # æ›´æ–°æ¨¡å‹ä¸º JIT æ¨¡å‹
                model = jit_model
                # ç¦ç”¨ CPU è‡ªåŠ¨æ··åˆç²¾åº¦
                self.use_cpu_amp = False
            except (RuntimeError, TypeError, ValueError, NameError, IndexError) as e:
                logger.warning(f"failed to use PyTorch jit mode due to: {e}.")

        return model
    # å¯¹æ¨¡å‹è¿›è¡Œ IPEX ä¼˜åŒ–ï¼Œæ”¯æŒåœ¨è®­ç»ƒæˆ–æ¨æ–­æ—¶è¿›è¡Œï¼Œå¯ä»¥æŒ‡å®šæ•°æ®ç±»å‹
    def ipex_optimize_model(self, model, training=False, dtype=torch.float32):
        # å¦‚æœæ²¡æœ‰å®‰è£… IPEXï¼Œåˆ™æŠ›å‡º ImportError
        if not is_ipex_available():
            raise ImportError(
                "Using IPEX but IPEX is not installed or IPEX's version does not match current PyTorch, please refer"
                " to https://github.com/intel/intel-extension-for-pytorch."
            )

        # å¯¼å…¥ IPEX æ¨¡å—
        import intel_extension_for_pytorch as ipex

        # å¦‚æœä¸å¤„äºè®­ç»ƒçŠ¶æ€
        if not training:
            # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            model.eval()
            # å¦‚æœä¸å¤„äºè®­ç»ƒä¸­ä¸”å‚æ•°ä¸­æŒ‡å®šäº†å®Œå…¨ BF16 è¯„ä¼°ï¼Œåˆ™å°†æ•°æ®ç±»å‹è®¾ç½®ä¸º BF16
            dtype = torch.bfloat16 if not self.is_in_train and self.args.bf16_full_eval else dtype
            # å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–ï¼Œè®¾ç½®æ•°æ®ç±»å‹ï¼Œä¼˜åŒ–çº§åˆ«ä¸º O1ï¼Œå…³é—­å·ç§¯ BN æŠ˜å åŠŸèƒ½ï¼Œinplace å‚æ•°æ ¹æ®æ˜¯å¦å¤„äºè®­ç»ƒçŠ¶æ€ç¡®å®š
            model = ipex.optimize(model, dtype=dtype, level="O1", conv_bn_folding=False, inplace=not self.is_in_train)
        else:
            # å¦‚æœæ¨¡å‹ä¸å¤„äºè®­ç»ƒçŠ¶æ€ï¼Œåˆ™è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
            if not model.training:
                model.train()
            # å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–ï¼Œè®¾ç½®æ•°æ®ç±»å‹ï¼Œä¼˜åŒ–å™¨ä¸ºå½“å‰ä¼˜åŒ–å™¨ï¼Œinplace å‚æ•°è®¾ç½®ä¸º Trueï¼Œä¼˜åŒ–çº§åˆ«ä¸º O1
            model, self.optimizer = ipex.optimize(
                model, dtype=dtype, optimizer=self.optimizer, inplace=True, level="O1"
            )

        # è¿”å›ä¼˜åŒ–åçš„æ¨¡å‹
        return model

    # è®­ç»ƒå‡½æ•°ï¼Œæ”¯æŒä»æ£€æŸ¥ç‚¹æ¢å¤ã€ä½¿ç”¨ Optuna ç­‰å‚æ•°ä¼˜åŒ–å·¥å…·ã€æŒ‡å®šå¿½ç•¥è¯„ä¼°çš„é”®ç­‰
    def train(
        self,
        resume_from_checkpoint: Optional[Union[str, bool]] = None,
        trial: Union["optuna.Trial", Dict[str, Any]] = None,
        ignore_keys_for_eval: Optional[List[str]] = None,
        **kwargs,
    # å†…éƒ¨è®­ç»ƒå¾ªç¯å‡½æ•°ï¼Œç”¨äºæ‰§è¡Œå®é™…çš„è®­ç»ƒè¿‡ç¨‹
    def _inner_training_loop(
        self, batch_size=None, args=None, resume_from_checkpoint=None, trial=None, ignore_keys_for_eval=None
    # è·å–è¾“å‡ºç›®å½•å‡½æ•°ï¼Œæ ¹æ®è¶…å‚æ•°æœç´¢åç«¯å’Œè¯•éªŒå¯¹è±¡ç¡®å®šè¾“å‡ºç›®å½•
    def _get_output_dir(self, trial):
        # å¦‚æœå¯ç”¨äº†è¶…å‚æ•°æœç´¢ä¸”å­˜åœ¨è¯•éªŒå¯¹è±¡
        if self.hp_search_backend is not None and trial is not None:
            # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯ä¸º OPTUNAï¼Œåˆ™ä½¿ç”¨è¯•éªŒç¼–å·ä½œä¸ºè¿è¡Œç¼–å·
            if self.hp_search_backend == HPSearchBackend.OPTUNA:
                run_id = trial.number
            # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯ä¸º RAYï¼Œåˆ™ä½¿ç”¨ Ray æä¾›çš„è¿è¡Œä¸Šä¸‹æ–‡è·å–è¯•éªŒ ID
            elif self.hp_search_backend == HPSearchBackend.RAY:
                import ray.train

                run_id = ray.train.get_context().get_trial_id()
            # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯ä¸º SIGOPTï¼Œåˆ™ä½¿ç”¨è¯•éªŒ ID ä½œä¸ºè¿è¡Œç¼–å·
            elif self.hp_search_backend == HPSearchBackend.SIGOPT:
                run_id = trial.id
            # å¦‚æœè¶…å‚æ•°æœç´¢åç«¯ä¸º WANDBï¼Œåˆ™ä½¿ç”¨ WandB æä¾›çš„è¿è¡Œ ID
            elif self.hp_search_backend == HPSearchBackend.WANDB:
                import wandb

                run_id = wandb.run.id
            # å¦‚æœæŒ‡å®šäº†è¶…å‚æ•°åç§°å‡½æ•°ï¼Œåˆ™ä½¿ç”¨è¯¥å‡½æ•°ç”Ÿæˆè¿è¡Œåç§°ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤åç§°
            run_name = self.hp_name(trial) if self.hp_name is not None else f"run-{run_id}"
            # æ‹¼æ¥è¿è¡Œç›®å½•è·¯å¾„
            run_dir = os.path.join(self.args.output_dir, run_name)
        else:
            # å¦åˆ™ç›´æ¥ä½¿ç”¨æŒ‡å®šçš„è¾“å‡ºç›®å½•
            run_dir = self.args.output_dir
        # è¿”å›æœ€ç»ˆçš„è¿è¡Œç›®å½•è·¯å¾„
        return run_dir

    # åŠ è½½æ¨¡å‹åå‘å‡ºè­¦å‘Šå‡½æ•°ï¼Œç”¨äºæ£€æµ‹åŠ è½½æ¨¡å‹æ—¶å‡ºç°çš„é”®ç¼ºå¤±æˆ–é”®ä¸åŒ¹é…æƒ…å†µå¹¶å‘å‡ºè­¦å‘Š
    def _issue_warnings_after_load(self, load_result):
        # å¦‚æœåŠ è½½ç»“æœä¸­å­˜åœ¨ç¼ºå¤±çš„é”®
        if len(load_result.missing_keys) != 0:
            # å¦‚æœæ¨¡å‹å®šä¹‰äº†åœ¨ä¿å­˜æ—¶å¿½ç•¥çš„é”®ä¸”ç¼ºå¤±çš„é”®ä¸ä¹‹åŒ¹é…ï¼Œåˆ™å°è¯•ç»‘å®šæƒé‡
            if self.model._keys_to_ignore_on_save is not None and set(load_result.missing_keys) == set(
                self.model._keys_to_ignore_on_save
            ):
                self.model.tie_weights()
            else:
                # å¦åˆ™å‘å‡ºç¼ºå¤±é”®çš„è­¦å‘Š
                logger.warning(f"There were missing keys in the checkpoint model loaded: {load_result.missing_keys}.")
        # å¦‚æœåŠ è½½ç»“æœä¸­å­˜åœ¨ä¸åŒ¹é…çš„é”®
        if len(load_result.unexpected_keys) != 0:
            # å‘å‡ºä¸åŒ¹é…é”®çš„è­¦å‘Š
            logger.warning(
                f"There were unexpected keys in the checkpoint model loaded: {load_result.unexpected_keys}."
            )
    # æ£€æŸ¥æ˜¯å¦åº”è¯¥è®°å½•å’Œè¯„ä¼°æ¨¡å‹ï¼Œåœ¨å…¨å±€æ­¥éª¤å¤§äºä¸Šæ¬¡è®°å½•çš„å…¨å±€æ­¥éª¤æ—¶æ‰§è¡Œ
    def _maybe_log_save_evaluate(self, tr_loss, model, trial, epoch, ignore_keys_for_eval):
        if self.control.should_log and self.state.global_step > self._globalstep_last_logged:
            # å¦‚æœæ˜¯åœ¨ Torch TPU ä¸Šè¿è¡Œï¼Œæ ‡è®°æ­¥éª¤
            if is_torch_tpu_available():
                xm.mark_step()

            # åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸ç”¨äºå­˜å‚¨æ—¥å¿—ä¿¡æ¯
            logs: Dict[str, float] = {}

            # ä½¿ç”¨ all_gather + mean() è·å–æ‰€æœ‰è¿›ç¨‹çš„å¹³å‡æŸå¤±
            tr_loss_scalar = self._nested_gather(tr_loss).mean().item()

            # å°†æŸå¤±é‡ç½®ä¸ºé›¶
            tr_loss -= tr_loss

            # è®¡ç®—å¹¶è®°å½•å¹³å‡æŸå¤±
            logs["loss"] = round(tr_loss_scalar / (self.state.global_step - self._globalstep_last_logged), 4)
            # è®°å½•å­¦ä¹ ç‡
            logs["learning_rate"] = self._get_learning_rate()

            # æ›´æ–°æ€»æŸå¤±
            self._total_loss_scalar += tr_loss_scalar
            # æ›´æ–°ä¸Šæ¬¡è®°å½•çš„å…¨å±€æ­¥éª¤
            self._globalstep_last_logged = self.state.global_step
            # å­˜å‚¨ FLOPs
            self.store_flos()

            # è®°å½•æ—¥å¿—
            self.log(logs)

        # åˆå§‹åŒ–è¯„ä¼°æŒ‡æ ‡ä¸ºç©º
        metrics = None
        # å¦‚æœåº”è¯¥è¯„ä¼°æ¨¡å‹
        if self.control.should_evaluate:
            # è¿›è¡Œæ¨¡å‹è¯„ä¼°
            metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
            # å‘è¶…å‚æ•°æœç´¢æŠ¥å‘Šç»“æœ
            self._report_to_hp_search(trial, self.state.global_step, metrics)

            # å¦‚æœä½¿ç”¨ ReduceLROnPlateau è°ƒåº¦å™¨ï¼Œåˆ™ç°åœ¨è¿è¡Œå»¶è¿Ÿçš„ LR è°ƒåº¦å™¨ï¼Œå› ä¸ºæ­¤æ—¶æŒ‡æ ‡å·²å¡«å……
            if isinstance(self.lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                # è·å–ç”¨äºæœ€ä½³æ¨¡å‹çš„æŒ‡æ ‡åç§°
                metric_to_check = self.args.metric_for_best_model
                # å¦‚æœæŒ‡æ ‡åç§°ä¸æ˜¯ä»¥ "eval_" å¼€å¤´ï¼Œåˆ™æ·»åŠ  "eval_" å‰ç¼€
                if not metric_to_check.startswith("eval_"):
                    metric_to_check = f"eval_{metric_to_check}"
                # æ ¹æ®æŒ‡æ ‡æ›´æ–°å­¦ä¹ ç‡
                self.lr_scheduler.step(metrics[metric_to_check])

        # å¦‚æœåº”è¯¥ä¿å­˜æ¨¡å‹
        if self.control.should_save:
            # ä¿å­˜æ£€æŸ¥ç‚¹
            self._save_checkpoint(model, trial, metrics=metrics)
            # è°ƒç”¨ä¿å­˜æ—¶çš„å›è°ƒå‡½æ•°
            self.control = self.callback_handler.on_save(self.args, self.state, self.control)
    # åŠ è½½æ£€æŸ¥ç‚¹ä¸­çš„éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€
    def _load_rng_state(self, checkpoint):
        # å¦‚æœæ£€æŸ¥ç‚¹ä¸ºç©ºï¼Œåˆ™ç›´æ¥è¿”å›
        if checkpoint is None:
            return

        # å¦‚æœè¿è¡Œåœ¨å¤šä¸ªè¿›ç¨‹ä¸­
        if self.args.world_size > 1:
            # è·å–å½“å‰è¿›ç¨‹ç´¢å¼•
            process_index = self.args.process_index
            # æ„å»ºå½“å‰è¿›ç¨‹çš„ RNG æ–‡ä»¶è·¯å¾„
            rng_file = os.path.join(checkpoint, f"rng_state_{process_index}.pth")
            # å¦‚æœ RNG æ–‡ä»¶ä¸å­˜åœ¨
            if not os.path.isfile(rng_file):
                # æç¤ºæœªæ‰¾åˆ°å½“å‰è¿›ç¨‹çš„ RNG æ–‡ä»¶ï¼Œå¹¶è¯´æ˜å¯èƒ½å¯¼è‡´çš„ä¸ç¡®å®šæ€§
                logger.info(
                    f"Didn't find an RNG file for process {process_index}, if you are resuming a training that "
                    "wasn't launched in a distributed fashion, reproducibility is not guaranteed."
                )
                # ç›´æ¥è¿”å›ï¼Œä¸è¿›è¡ŒçŠ¶æ€åŠ è½½
                return
        # å¦‚æœåªè¿è¡Œåœ¨å•ä¸ªè¿›ç¨‹ä¸­
        else:
            # æ„å»ºé€šç”¨çš„ RNG æ–‡ä»¶è·¯å¾„
            rng_file = os.path.join(checkpoint, "rng_state.pth")
            # å¦‚æœ RNG æ–‡ä»¶ä¸å­˜åœ¨
            if not os.path.isfile(rng_file):
                # æç¤ºæœªæ‰¾åˆ° RNG æ–‡ä»¶ï¼Œå¹¶è¯´æ˜å¯èƒ½å¯¼è‡´çš„ä¸ç¡®å®šæ€§
                logger.info(
                    "Didn't find an RNG file, if you are resuming a training that was launched in a distributed "
                    "fashion, reproducibility is not guaranteed."
                )
                # ç›´æ¥è¿”å›ï¼Œä¸è¿›è¡ŒçŠ¶æ€åŠ è½½
                return

        # åŠ è½½æ£€æŸ¥ç‚¹ä¸­ä¿å­˜çš„ RNG çŠ¶æ€
        checkpoint_rng_state = torch.load(rng_file)
        # æ¢å¤ Python å†…ç½®çš„éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€
        random.setstate(checkpoint_rng_state["python"])
        # æ¢å¤ NumPy éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€
        np.random.set_state(checkpoint_rng_state["numpy"])
        # æ¢å¤ PyTorch CPU éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€
        torch.random.set_rng_state(checkpoint_rng_state["cpu"])
        # å¦‚æœ CUDA å¯ç”¨
        if torch.cuda.is_available():
            # å¦‚æœå½“å‰æ˜¯åˆ†å¸ƒå¼å¹¶è¡Œæ¨¡å¼
            if self.args.parallel_mode == ParallelMode.DISTRIBUTED:
                # æ¢å¤æ‰€æœ‰ GPU çš„éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€
                torch.cuda.random.set_rng_state_all(checkpoint_rng_state["cuda"])
            else:
                # å°è¯•æ¢å¤å•ä¸ª GPU çš„éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€
                try:
                    torch.cuda.random.set_rng_state(checkpoint_rng_state["cuda"])
                # å¦‚æœå‡ºç°å¼‚å¸¸
                except Exception as e:
                    # æç¤ºæ— æ³•æ¢å¤ GPU çš„ RNG çŠ¶æ€ï¼Œå¹¶è¯´æ˜å¯èƒ½å¯¼è‡´çš„ä¸ç¡®å®šæ€§
                    logger.info(
                        f"Didn't manage to set back the RNG states of the GPU because of the following error:\n {e}"
                        "\nThis won't yield the same results as if the training had not been interrupted."
                    )
        # å¦‚æœæ˜¯ Torch TPU å¯ç”¨
        if is_torch_tpu_available():
            # æ¢å¤ Torch XLA çš„ RNG çŠ¶æ€
            xm.set_rng_state(checkpoint_rng_state["xla"])
        # å¦‚æœæ˜¯ Torch NPU å¯ç”¨
        if is_torch_npu_available():
            # å¦‚æœå½“å‰æ˜¯åˆ†å¸ƒå¼å¹¶è¡Œæ¨¡å¼
            if self.args.parallel_mode == ParallelMode.DISTRIBUTED:
                # æ¢å¤æ‰€æœ‰ NPU çš„ RNG çŠ¶æ€
                torch.npu.random.set_rng_state_all(checkpoint_rng_state["npu"])
            else:
                # å°è¯•æ¢å¤å•ä¸ª NPU çš„ RNG çŠ¶æ€
                try:
                    torch.npu.random.set_rng_state(checkpoint_rng_state["npu"])
                # å¦‚æœå‡ºç°å¼‚å¸¸
                except Exception as e:
                    # æç¤ºæ— æ³•æ¢å¤ NPU çš„ RNG çŠ¶æ€ï¼Œå¹¶è¯´æ˜å¯èƒ½å¯¼è‡´çš„ä¸ç¡®å®šæ€§
                    logger.info(
                        f"Didn't manage to set back the RNG states of the NPU because of the following error:\n {e}"
                        "\nThis won't yield the same results as if the training had not been interrupted."
                    )
    # åœ¨éåˆ†å¸ƒå¼è®­ç»ƒä¸­ä¿å­˜ RNG çŠ¶æ€
    def _save_rng_state(self, output_dir):
        # åˆ›å»ºåŒ…å«ä¸åŒ RNG çŠ¶æ€çš„å­—å…¸
        rng_states = {
            "python": random.getstate(),
            "numpy": np.random.get_state(),
            "cpu": torch.random.get_rng_state(),
        }
        # å¦‚æœ CUDA å¯ç”¨
        if torch.cuda.is_available():
            # å¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼
            if self.args.parallel_mode == ParallelMode.DISTRIBUTED:
                # åœ¨éåˆ†å¸ƒå¼æƒ…å†µä¸‹ï¼Œä¿å­˜å…¨å±€ CUDA RNG çŠ¶æ€ï¼ˆä¼šå¤„ç† DataParallelï¼‰
                rng_states["cuda"] = torch.cuda.random.get_rng_state_all()
            else:
                rng_states["cuda"] = torch.cuda.random.get_rng_state()

        # å¦‚æœæ˜¯ Torch TPU å¯ç”¨
        if is_torch_tpu_available():
            rng_states["xla"] = xm.get_rng_state()

        # å¦‚æœæ˜¯ Torch NPU å¯ç”¨
        if is_torch_npu_available():
            # å¦‚æœæ˜¯åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼
            if self.args.parallel_mode == ParallelMode.DISTRIBUTED:
                rng_states["npu"] = torch.npu.random.get_rng_state_all()
            else:
                rng_states["npu"] = torch.npu.random.get_rng_state()

        # ä¸€ä¸ªè¿›ç¨‹å¯èƒ½åœ¨è¿›ç¨‹ 0 æœ‰æœºä¼šä¿å­˜æ¨¡å‹ä¹‹å‰åˆ°è¾¾è¿™é‡Œï¼Œæ­¤æ—¶ output_dir å¯èƒ½è¿˜ä¸å­˜åœ¨
        # åˆ›å»ºç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨åˆ™ä¸æŠ¥é”™
        os.makedirs(output_dir, exist_ok=True)

        # å¦‚æœè¿›ç¨‹æ•°å°äºç­‰äº 1
        if self.args.world_size <= 1:
            # ä¿å­˜ RNG çŠ¶æ€åˆ°æ–‡ä»¶ rng_state.pth
            torch.save(rng_states, os.path.join(output_dir, "rng_state.pth"))
        else:
            # ä¿å­˜ RNG çŠ¶æ€åˆ°æ–‡ä»¶ rng_state_{self.args.process_index}.pth
            torch.save(rng_states, os.path.join(output_dir, f"rng_state_{self.args.process_index}.pth"))
    # å®šä¹‰ä¿å­˜ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨çš„æ–¹æ³•ï¼Œå°†å‚æ•°è¾“å‡ºåˆ°æŒ‡å®šç›®å½•
    def _save_optimizer_and_scheduler(self, output_dir):
        # å¦‚æœæ˜¯åœ¨ Torch TPU ä¸Šå¯ç”¨
        if is_torch_tpu_available():
            # ä½¿ç”¨ Torch XLA ç­‰å¾…è¿›ç¨‹ï¼Œç¡®ä¿ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€
            xm.rendezvous("saving_optimizer_states")
            # ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€å­—å…¸åˆ°æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶ä¸­
            xm.save(self.optimizer.state_dict(), os.path.join(output_dir, OPTIMIZER_NAME))
            # æ•è·å¯èƒ½çš„è­¦å‘Šä¿¡æ¯
            with warnings.catch_warnings(record=True) as caught_warnings:
                # ä¿å­˜å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€å­—å…¸åˆ°æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶ä¸­
                xm.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))
                # é‡æ–°è§¦å‘æ•è·çš„è­¦å‘Šä¿¡æ¯
                reissue_pt_warnings(caught_warnings)
        # å¦‚æœå¯ç”¨äº† SageMaker æ¨¡å‹å¹¶è¡Œè®­ç»ƒ
        elif is_sagemaker_mp_enabled():
            # è·å–ä¼˜åŒ–å™¨çš„æœ¬åœ°çŠ¶æ€å­—å…¸ï¼Œä¸æ”¶é›†åˆ†ç‰‡ä¿¡æ¯
            opt_state_dict = self.optimizer.local_state_dict(gather_if_shard=False)
            # åœ¨ SageMaker æ¨¡å‹å¹¶è¡Œè®­ç»ƒä¸­è¿›è¡ŒåŒæ­¥
            smp.barrier()
            # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªè¿›ç¨‹æˆ–è€…é…ç½®ä¸­æŒ‡å®šè¦åˆ†ç‰‡ä¼˜åŒ–å™¨çŠ¶æ€
            if smp.rdp_rank() == 0 or smp.state.cfg.shard_optimizer_state:
                # éƒ¨åˆ†åœ°ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€å­—å…¸åˆ°æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶ä¸­
                smp.save(
                    opt_state_dict,
                    os.path.join(output_dir, OPTIMIZER_NAME),
                    partial=True,
                    v3=smp.state.cfg.shard_optimizer_state,
                )
        # å¦‚æœå¯ç”¨äº† DeepSpeed
        elif self.is_deepspeed_enabled:
            # åœ¨ zero3 æ¨¡å‹ä¸­ï¼Œæ¨¡å‹æ–‡ä»¶æœ¬èº«ä¸ä¼šä¿å­˜ï¼Œé™¤é DeepSpeed é…ç½®ä¸­ `stage3_gather_16bit_weights_on_model_save` ä¸º True
            accept_exclude_frozen_parameters = "exclude_frozen_parameters" in set(
                inspect.signature(self.model_wrapped.save_checkpoint).parameters.keys()
            )
            # å¦‚æœæ¥å—æ’é™¤å†»ç»“å‚æ•°ï¼Œå¹¶ä¸”æ¨¡å‹æ˜¯ PEFT æ¨¡å‹
            if accept_exclude_frozen_parameters and _is_peft_model(self.model):
                # ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œæ’é™¤å†»ç»“å‚æ•°
                self.model_wrapped.save_checkpoint(output_dir, exclude_frozen_parameters=True)
            else:
                # ä¿å­˜æ£€æŸ¥ç‚¹
                self.model_wrapped.save_checkpoint(output_dir)
        # å¦‚æœå¯ç”¨äº† FSDPï¼ˆFully Sharded Data Parallelismï¼‰
        elif self.is_fsdp_enabled:
            # ä¿å­˜ FSDP ç‰¹å®šçš„æ£€æŸ¥ç‚¹ä»¥ä¾¿ä»æ£€æŸ¥ç‚¹ä¸­æ¢å¤
            save_fsdp_model(self.accelerator.state.fsdp_plugin, self.accelerator, self.model, output_dir)
            save_fsdp_optimizer(
                self.accelerator.state.fsdp_plugin, self.accelerator, self.optimizer, self.model, output_dir
            )
        # å¦‚æœéœ€è¦ä¿å­˜æ£€æŸ¥ç‚¹
        elif self.args.should_save:
            # åœ¨ä¸Šè¿°æ¡ä»¶ä¸æ»¡è¶³æ—¶ï¼Œä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€å­—å…¸åˆ°æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶ä¸­
            torch.save(self.optimizer.state_dict(), os.path.join(output_dir, OPTIMIZER_NAME))

        # ä¿å­˜å­¦ä¹ ç‡è°ƒåº¦å™¨å’Œæ ‡é‡
        # å¦‚æœä¸æ˜¯ DeepSpeed æˆ–è€…ä¸æ˜¯ DeepSpeed è‡ªå®šä¹‰è°ƒåº¦å™¨ï¼Œå¹¶ä¸”ä¸æ˜¯åœ¨ Torch TPU ä¸Šå¯ç”¨
        is_deepspeed_custom_scheduler = self.is_deepspeed_enabled and not isinstance(
            self.lr_scheduler, DeepSpeedSchedulerWrapper
        )
        if (
            self.args.should_save
            and (not self.is_deepspeed_enabled or is_deepspeed_custom_scheduler)
            and not is_torch_tpu_available()
        ):
            # æ•è·å¯èƒ½çš„è­¦å‘Šä¿¡æ¯
            with warnings.catch_warnings(record=True) as caught_warnings:
                # ä¿å­˜å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€å­—å…¸åˆ°æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶ä¸­
                torch.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))
            # é‡æ–°è§¦å‘æ•è·çš„è­¦å‘Šä¿¡æ¯
            reissue_pt_warnings(caught_warnings)
    def hyperparameter_search(
        self,
        hp_space: Optional[Callable[["optuna.Trial"], Dict[str, float]]] = None,
        compute_objective: Optional[Callable[[Dict[str, float]], float]] = None,
        n_trials: int = 20,
        direction: Union[str, List[str]] = "minimize",
        backend: Optional[Union["str", HPSearchBackend]] = None,
        hp_name: Optional[Callable[["optuna.Trial"], str]] = None,
        **kwargs,
    ):
        """
        Perform hyperparameter search using Optuna.

        Args:
            hp_space (Optional[Callable[["optuna.Trial"], Dict[str, float]]]):
                A function defining the hyperparameter search space.
            compute_objective (Optional[Callable[[Dict[str, float]], float]]):
                A function to compute the objective value given hyperparameters.
            n_trials (int):
                Number of trials for hyperparameter search.
            direction (Union[str, List[str]]):
                Direction to optimize the objective, either 'minimize' or 'maximize'.
            backend (Optional[Union[str, HPSearchBackend]]):
                Backend for hyperparameter search.
            hp_name (Optional[Callable[["optuna.Trial"], str]]):
                A function to define the hyperparameter's name.

        **kwargs:
            Additional keyword arguments.

        """
        # å®ç°è¶…å‚æ•°æœç´¢çš„å‡½æ•°
        if hp_space is None or compute_objective is None:
            raise ValueError("Both hp_space and compute_objective must be provided for hyperparameter search.")
        
        # å¦‚æœæœªæŒ‡å®šä¼˜åŒ–æ–¹å‘ï¼Œåˆ™é»˜è®¤ä¸ºæœ€å°åŒ–
        if isinstance(direction, str):
            directions = [direction]
        else:
            directions = direction
        
        # è°ƒç”¨ Optuna è¿›è¡Œè¶…å‚æ•°æœç´¢
        optuna_search(
            hp_space=hp_space,
            compute_objective=compute_objective,
            n_trials=n_trials,
            directions=directions,
            backend=backend,
            hp_name=hp_name,
            **kwargs,
        )

    def log(self, logs: Dict[str, float]) -> None:
        """
        Log `logs` on the various objects watching training.

        Subclass and override this method to inject custom behavior.

        Args:
            logs (`Dict[str, float]`):
                The values to log.
        """
        # å¦‚æœå½“å‰å¤„äºæŸä¸ª epochï¼Œåˆ™å°†è¯¥ epoch çš„å€¼è®°å½•åˆ°æ—¥å¿—ä¸­
        if self.state.epoch is not None:
            logs["epoch"] = round(self.state.epoch, 2)
        
        # å¦‚æœè®¾ç½®äº†åŒ…å«è¾“å…¥ä»¤ç‰Œæ•°ï¼Œåˆ™å°†å…¶è®°å½•åˆ°æ—¥å¿—ä¸­
        if self.args.include_num_input_tokens_seen:
            logs["num_input_tokens_seen"] = self.state.num_input_tokens_seen
        
        # å°†å…¨å±€æ­¥æ•°è®°å½•åˆ°æ—¥å¿—ä¸­
        output = {**logs, **{"step": self.state.global_step}}
        self.state.log_history.append(output)
        
        # è°ƒç”¨å›è°ƒå¤„ç†ç¨‹åºçš„ on_log æ–¹æ³•
        self.control = self.callback_handler.on_log(self.args, self.state, self.control, logs)

    def _prepare_input(self,  Union[torch.Tensor, Any]) -> Union[torch.Tensor, Any]:
        """
        Prepares one `data` before feeding it to the model, be it a tensor or a nested list/dictionary of tensors.
        """
        # å¦‚æœæ•°æ®æ˜¯å­—å…¸ï¼Œåˆ™é€’å½’è°ƒç”¨_prepare_inputå¯¹å…¶è¿›è¡Œå‡†å¤‡
        if isinstance(data, Mapping):
            return type(data)({k: self._prepare_input(v) for k, v in data.items()})
        # å¦‚æœæ•°æ®æ˜¯å…ƒç»„æˆ–åˆ—è¡¨ï¼Œåˆ™é€’å½’è°ƒç”¨_prepare_inputå¯¹å…¶ä¸­æ¯ä¸ªå…ƒç´ è¿›è¡Œå‡†å¤‡
        elif isinstance(data, (tuple, list)):
            return type(data)(self._prepare_input(v) for v in data)
        # å¦‚æœæ•°æ®æ˜¯å¼ é‡ï¼Œåˆ™å°†å…¶ç§»åˆ°é€‚å½“çš„è®¾å¤‡ä¸Šï¼Œå¹¶æ ¹æ®æƒ…å†µè¿›è¡Œæ·±åº¦åŠ é€Ÿå¤„ç†
        elif isinstance(data, torch.Tensor):
            kwargs = {"device": self.args.device}
            if self.is_deepspeed_enabled and (torch.is_floating_point(data) or torch.is_complex(data)):
                # NLP æ¨¡å‹çš„è¾“å…¥æ˜¯ int/uintï¼Œä¼šè°ƒæ•´ä¸ºæ­£ç¡®çš„åµŒå…¥ dtypeã€‚è€Œå…¶ä»–æ¨¡å‹ï¼ˆä¾‹å¦‚ wav2vec2ï¼‰çš„è¾“å…¥å·²ç»æ˜¯ floatï¼Œ
                # å› æ­¤å¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†ä»¥åŒ¹é…æ¨¡å‹çš„ dtype
                kwargs.update({"dtype": self.accelerator.state.deepspeed_plugin.hf_ds_config.dtype()})
            return data.to(**kwargs)
        return data
    def _prepare_inputs(self, inputs: Dict[str, Union[torch.Tensor, Any]]) -> Dict[str, Union[torch.Tensor, Any]]]:
        """
        Prepare `inputs` before feeding them to the model, converting them to tensors if they are not already and
        handling potential state.
        """
        # è°ƒç”¨å†…éƒ¨æ–¹æ³•_prepare_inputå¯¹è¾“å…¥è¿›è¡Œå‡†å¤‡å¤„ç†
        inputs = self._prepare_input(inputs)
        # å¦‚æœè¾“å…¥ä¸ºç©ºï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
        if len(inputs) == 0:
            raise ValueError(
                "The batch received was empty, your model won't be able to train on it. Double-check that your "
                f"training dataset contains keys expected by the model: {','.join(self._signature_columns)}."
            )
        # å¦‚æœæ¨¡å‹è®¾ç½®äº†`past_index`ä¸”è¿‡å»çŠ¶æ€ä¸ä¸ºç©ºï¼Œåˆ™å°†è¿‡å»çŠ¶æ€å­˜å…¥è¾“å…¥ä¸­çš„"mems"é”®
        if self.args.past_index >= 0 and self._past is not None:
            inputs["mems"] = self._past

        return inputs

    def compute_loss_context_manager(self):
        """
        A helper wrapper to group together context managers.
        """
        # è¿”å›ä¸€ä¸ªåŒ…å«æ‰€éœ€ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„è¾…åŠ©åŒ…è£…å™¨
        return self.autocast_smart_context_manager()

    def autocast_smart_context_manager(self, cache_enabled: Optional[bool] = True):
        """
        A helper wrapper that creates an appropriate context manager for `autocast` while feeding it the desired
        arguments, depending on the situation.
        """
        # å¦‚æœä½¿ç”¨ CPU AMPï¼Œåˆ™åˆ›å»ºç›¸åº”çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        if self.use_cpu_amp:
            ctx_manager = torch.cpu.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)
        # å¦‚æœæœªä½¿ç”¨ CPU AMPï¼Œåˆ™åˆ›å»ºä¸€ä¸ªç©ºçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        else:
            ctx_manager = contextlib.nullcontext()

        return ctx_manager

    def training_step(self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:
        """
        Perform a training step on a batch of inputs.

        Subclass and override to inject custom behavior.

        Args:
            model (`nn.Module`):
                The model to train.
            inputs (`Dict[str, Union[torch.Tensor, Any]]`):
                The inputs and targets of the model.

                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the
                argument `labels`. Check your model's documentation for all accepted arguments.

        Return:
            `torch.Tensor`: The tensor with training loss on this batch.
        """
        # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        model.train()
        # å‡†å¤‡è¾“å…¥æ•°æ®
        inputs = self._prepare_inputs(inputs)

        # å¦‚æœä½¿ç”¨ SageMaker å¤šè¿›ç¨‹è®­ç»ƒï¼Œåˆ™è°ƒç”¨ç›¸åº”çš„å‡½æ•°è¿›è¡Œå‰å‘å’Œåå‘ä¼ æ’­
        if is_sagemaker_mp_enabled():
            loss_mb = smp_forward_backward(model, inputs, self.args.gradient_accumulation_steps)
            return loss_mb.reduce_mean().detach().to(self.args.device)

        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è®¡ç®—æŸå¤±
        with self.compute_loss_context_manager():
            loss = self.compute_loss(model, inputs)

        # å¦‚æœä½¿ç”¨å¤šä¸ª GPUï¼Œåˆ™å¯¹æŸå¤±è¿›è¡Œå¹³å‡
        if self.args.n_gpu > 1:
            loss = loss.mean()  # mean() to average on multi-gpu parallel training

        # å¦‚æœä½¿ç”¨ Apexï¼Œåˆ™ä½¿ç”¨ amp å¯¹æŸå¤±è¿›è¡Œç¼©æ”¾
        if self.use_apex:
            with amp.scale_loss(loss, self.optimizer) as scaled_loss:
                scaled_loss.backward()
        # å¦åˆ™ï¼Œä½¿ç”¨åŠ é€Ÿå™¨å¯¹æŸå¤±è¿›è¡Œåå‘ä¼ æ’­
        else:
            self.accelerator.backward(loss)

        # è¿”å›ç»è¿‡å¤„ç†çš„æŸå¤±
        return loss.detach() / self.args.gradient_accumulation_steps
    # è®¡ç®—æŸå¤±å‡½æ•°çš„æ–¹æ³•ï¼Œç”± Trainer è°ƒç”¨ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½åœ¨ç¬¬ä¸€ä¸ªå…ƒç´ ä¸­è¿”å›æŸå¤±å€¼ã€‚
    # å­ç±»å¯ä»¥é‡å†™æ­¤æ–¹æ³•ä»¥å®ç°è‡ªå®šä¹‰è¡Œä¸ºã€‚
    def compute_loss(self, model, inputs, return_outputs=False):
        # å¦‚æœå­˜åœ¨æ ‡ç­¾å¹³æ»‘å™¨ä¸”è¾“å…¥ä¸­åŒ…å« "labels" é”®
        if self.label_smoother is not None and "labels" in inputs:
            # ä»è¾“å…¥ä¸­å¼¹å‡º "labels" é”®å¯¹åº”çš„å€¼ä½œä¸ºæ ‡ç­¾
            labels = inputs.pop("labels")
        else:
            labels = None
        # ä½¿ç”¨æ¨¡å‹å¤„ç†è¾“å…¥æ•°æ®ï¼Œå¾—åˆ°æ¨¡å‹è¾“å‡º
        outputs = model(**inputs)
        # å¦‚æœå­˜åœ¨è¿‡å»çŠ¶æ€ï¼Œä¿å­˜è¿‡å»çŠ¶æ€
        # TODO: åç»­éœ€è¦ä¿®å¤å¹¶ä¼˜åŒ–æ­¤éƒ¨åˆ†ä»£ç ã€‚
        if self.args.past_index >= 0:
            self._past = outputs[self.args.past_index]

        # å¦‚æœå­˜åœ¨æ ‡ç­¾ï¼Œåˆ™æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©æ ‡ç­¾å¹³æ»‘å™¨å¤„ç†æŸå¤±
        if labels is not None:
            unwrapped_model = unwrap_model(model)
            if _is_peft_model(unwrapped_model):
                model_name = unwrapped_model.base_model.model._get_name()
            else:
                model_name = unwrapped_model._get_name()
            if model_name in MODEL_FOR_CAUSAL_LM_MAPPING_NAMES.values():
                loss = self.label_smoother(outputs, labels, shift_labels=True)
            else:
                loss = self.label_smoother(outputs, labels)
        else:
            # å¦‚æœæ¨¡å‹è¾“å‡ºæ˜¯å­—å…¸ä¸”ä¸åŒ…å« "loss" é”®ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
            if isinstance(outputs, dict) and "loss" not in outputs:
                raise ValueError(
                    "The model did not return a loss from the inputs, only the following keys: "
                    f"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}."
                )
            # ç”±äºæ¨¡å‹å¯èƒ½è¿”å›å…ƒç»„è€Œä¸æ˜¯ ModelOutputï¼Œå› æ­¤è¿™é‡Œä¸ä½¿ç”¨ .loss
            loss = outputs["loss"] if isinstance(outputs, dict) else outputs[0]

        # å¦‚æœéœ€è¦è¿”å›æ¨¡å‹è¾“å‡ºï¼Œåˆ™è¿”å›æŸå¤±å€¼å’Œæ¨¡å‹è¾“å‡ºï¼›å¦åˆ™åªè¿”å›æŸå¤±å€¼
        return (loss, outputs) if return_outputs else loss

    # åˆ¤æ–­å½“å‰è¿›ç¨‹æ˜¯å¦ä¸ºæœ¬åœ°ä¸»è¿›ç¨‹ï¼ˆä¾‹å¦‚ï¼Œåœ¨å¤šå°æœºå™¨ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œæœ¬åœ°ä¸»è¿›ç¨‹ä¸º 0 å·è¿›ç¨‹ï¼‰
    def is_local_process_zero(self) -> bool:
        """
        Whether or not this process is the local (e.g., on one machine if training in a distributed fashion on several
        machines) main process.
        """
        return self.args.local_process_index == 0

    # åˆ¤æ–­å½“å‰è¿›ç¨‹æ˜¯å¦ä¸ºå…¨å±€ä¸»è¿›ç¨‹ï¼ˆåœ¨å¤šå°æœºå™¨ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œåªæœ‰ä¸€ä¸ªè¿›ç¨‹ä¼šè¿”å› Trueï¼‰
    def is_world_process_zero(self) -> bool:
        """
        Whether or not this process is the global main process (when training in a distributed fashion on several
        machines, this is only going to be `True` for one process).
        """
        # å¯¹äº SageMaker ModelParallelï¼Œè¿›ç¨‹ç´¢å¼•ä¸º dp_process_indexï¼Œè€Œä¸æ˜¯å…¨å±€è¿›ç¨‹ç´¢å¼•
        if is_sagemaker_mp_enabled():
            return smp.rank() == 0
        else:
            return self.args.process_index == 0
    # å®šä¹‰ä¿å­˜æ¨¡å‹çš„æ–¹æ³•ï¼Œå…è®¸æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º Noneï¼Œ_internal_call ç”¨äºå†…éƒ¨è°ƒç”¨
    def save_model(self, output_dir: Optional[str] = None, _internal_call: bool = False):
        """
        Will save the model, so you can reload it using `from_pretrained()`.

        Will only save from the main process.
        """

        # å¦‚æœè¾“å‡ºç›®å½•ä¸º Noneï¼Œåˆ™ä½¿ç”¨ self.args.output_dir
        if output_dir is None:
            output_dir = self.args.output_dir

        # å¦‚æœåœ¨ Torch TPU å¯ç”¨çš„æƒ…å†µä¸‹ï¼Œè°ƒç”¨ _save_tpu æ–¹æ³•ä¿å­˜æ¨¡å‹
        if is_torch_tpu_available():
            self._save_tpu(output_dir)
        # å¦‚æœå¯ç”¨äº† SageMaker Model Parallelismï¼Œåˆ™åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè°ƒç”¨ state_dict æ–¹æ³•
        elif is_sagemaker_mp_enabled():
            # è°ƒç”¨ state_dict éœ€è¦åœ¨åŒ…è£…æ¨¡å‹å’Œæ‰€æœ‰è¿›ç¨‹ä¸Šè¿›è¡Œ
            os.makedirs(output_dir, exist_ok=True)
            state_dict = self.model_wrapped.state_dict()
            # å¦‚æœåº”è¯¥ä¿å­˜ï¼Œåˆ™ä¿å­˜æ¨¡å‹
            if self.args.should_save:
                self._save(output_dir, state_dict=state_dict)
            # å¦‚æœä½¿ç”¨çš„ SageMaker Model Parallelism ç‰ˆæœ¬å¤§äº 1.10ï¼Œåˆ™åˆ›å»ºä¸€ä¸ª 'user_content.pt' æ–‡ä»¶ä½œä¸ºæ ‡è®°
            if IS_SAGEMAKER_MP_POST_1_10:
                # 'user_content.pt' è¡¨ç¤ºä½¿ç”¨ smp >= 1.10 ä¿å­˜çš„æ¨¡å‹ state_dict
                Path(os.path.join(output_dir, "user_content.pt")).touch()
        # å¦‚æœå¯ç”¨äº† Fully Sharded Data Parallelismï¼ˆFSDPï¼‰ï¼Œå¹¶ä¸”ç‰ˆæœ¬å¤§äº 0.24.1ï¼Œåˆ™ä¿å­˜ FSDP æ¨¡å‹çš„çŠ¶æ€å­—å…¸
        elif self.is_fsdp_enabled:
            if ("FULL_STATE_DICT" in str(self.accelerator.state.fsdp_plugin.state_dict_type)) and (
                version.parse(accelerate_version) > version.parse("0.24.1")
            ):
                state_dict = self.accelerator.get_state_dict(self.model)
                if self.args.should_save:
                    self._save(output_dir, state_dict=state_dict)
        # å¦‚æœå¯ç”¨äº† DeepSpeedï¼Œåˆ™ä¿å­˜ DeepSpeed æ¨¡å‹çš„çŠ¶æ€å­—å…¸
        elif self.is_deepspeed_enabled:
            try:
                state_dict = self.accelerator.get_state_dict(self.deepspeed)
                if self.args.should_save:
                    self._save(output_dir, state_dict=state_dict)
            # å¦‚æœå‡ºç° ValueErrorï¼Œåˆ™è¡¨ç¤º stage3_gather_16bit_weights_on_model_save=falseï¼Œä¿å­˜å®Œæ•´çš„æ£€æŸ¥ç‚¹
            except ValueError:
                logger.warning(
                    " stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use"
                    " zero_to_fp32.py to recover weights"
                )
                if self.args.should_save:
                    self._save(output_dir, state_dict={})
                # ç§»é™¤è™šæ‹Ÿçš„çŠ¶æ€å­—å…¸
                remove_dummy_checkpoint(self.args.should_save, output_dir, [WEIGHTS_NAME, SAFE_WEIGHTS_NAME])
                # ä¿å­˜åŒ…è£…æ¨¡å‹çš„æ£€æŸ¥ç‚¹
                self.model_wrapped.save_checkpoint(output_dir)

        # å¦‚æœåº”è¯¥ä¿å­˜ï¼Œåˆ™ä¿å­˜æ¨¡å‹
        elif self.args.should_save:
            self._save(output_dir)

        # å½“ç”¨æˆ·è°ƒç”¨ save_model æ—¶ï¼Œæ¨é€åˆ° Hub
        if self.args.push_to_hub and not _internal_call:
            self.push_to_hub(commit_message="Model save")
    # å®šä¹‰ä¸€ä¸ªç§æœ‰æ–¹æ³•ç”¨äºä¿å­˜æ¨¡å‹åˆ°TPUï¼Œå¯æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºself.args.output_dir
    def _save_tpu(self, output_dir: Optional[str] = None):
        # å¦‚æœæœªæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œåˆ™ä½¿ç”¨self.args.output_dirä½œä¸ºè¾“å‡ºç›®å½•
        output_dir = output_dir if output_dir is not None else self.args.output_dir
        # æ‰“å°æç¤ºä¿¡æ¯ï¼ŒæŒ‡ç¤ºæ­£åœ¨ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹åˆ°æŒ‡å®šç›®å½•
        logger.info(f"Saving model checkpoint to {output_dir}")
        # è·å–æ¨¡å‹å¯¹è±¡
        model = self.model
        # å°†æ¨¡å‹è½¬ç§»åˆ°CPU
        model.to("cpu")

        # å¦‚æœå½“å‰è¿›ç¨‹æ˜¯ä¸»è¿›ç¨‹
        if xm.is_master_ordinal():
            # åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨åˆ™ä¸ä¼šè¦†ç›–
            os.makedirs(output_dir, exist_ok=True)
            # ä¿å­˜è®­ç»ƒå‚æ•°åˆ°è¾“å‡ºç›®å½•ä¸‹çš„TRAINING_ARGS_NAMEæ–‡ä»¶ä¸­
            torch.save(self.args, os.path.join(output_dir, TRAINING_ARGS_NAME))

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹éƒ½åˆ°è¾¾æ­¤å¤„ï¼Œç„¶åç»§ç»­æ‰§è¡Œ
        xm.rendezvous("saving_checkpoint")
        # å¦‚æœæ¨¡å‹ä¸æ˜¯PreTrainedModelç±»å‹
        if not isinstance(model, PreTrainedModel):
            # å¦‚æœæ¨¡å‹çš„åŒ…è£…æ¨¡å‹æ˜¯PreTrainedModelç±»å‹
            if isinstance(unwrap_model(model), PreTrainedModel):
                # è°ƒç”¨PreTrainedModelçš„save_pretrainedæ–¹æ³•ä¿å­˜æ¨¡å‹å’Œé…ç½®
                unwrap_model(model).save_pretrained(
                    output_dir,
                    is_main_process=self.args.should_save,
                    state_dict=model.state_dict(),
                    save_function=xm.save,
                )
            else:
                # æ‰“å°æç¤ºä¿¡æ¯ï¼Œè¯´æ˜Trainer.modelä¸æ˜¯PreTrainedModelç±»å‹ï¼Œåªä¿å­˜å…¶çŠ¶æ€å­—å…¸
                logger.info("Trainer.model is not a `PreTrainedModel`, only saving its state dict.")
                # è·å–æ¨¡å‹çš„çŠ¶æ€å­—å…¸
                state_dict = model.state_dict()
                # å°†çŠ¶æ€å­—å…¸ä¿å­˜åˆ°è¾“å‡ºç›®å½•ä¸‹çš„WEIGHTS_NAMEæ–‡ä»¶ä¸­
                xm.save(state_dict, os.path.join(output_dir, WEIGHTS_NAME))
        else:
            # è°ƒç”¨PreTrainedModelçš„save_pretrainedæ–¹æ³•ä¿å­˜æ¨¡å‹å’Œé…ç½®
            model.save_pretrained(output_dir, is_main_process=self.args.should_save, save_function=xm.save)
        # å¦‚æœå­˜åœ¨åˆ†è¯å™¨å¯¹è±¡ä¸”åº”è¯¥ä¿å­˜ï¼Œåˆ™ä¿å­˜åˆ†è¯å™¨åˆ°è¾“å‡ºç›®å½•
        if self.tokenizer is not None and self.args.should_save:
            self.tokenizer.save_pretrained(output_dir)

        # å°†æ¨¡å‹ä»CPUç§»å›åˆ°è®¾å¤‡ä¸Šï¼Œä»¥ä¾¿åç»­è®¡ç®—å¯ä»¥æ­£å¸¸è¿›è¡Œ
        model.to(self.args.device)
    def _save(self, output_dir: Optional[str] = None, state_dict=None):
        # å¦‚æœæ‰§è¡Œæ­¤å‡½æ•°ï¼Œæˆ‘ä»¬æ˜¯è¿›ç¨‹é›¶ï¼Œæ‰€ä»¥ä¸éœ€è¦æ£€æŸ¥
        output_dir = output_dir if output_dir is not None else self.args.output_dir
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        os.makedirs(output_dir, exist_ok=True)
        # è®°å½•æ—¥å¿—ï¼ŒæŒ‡ç¤ºæ­£åœ¨å°†æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜åˆ°output_dirç›®å½•
        logger.info(f"Saving model checkpoint to {output_dir}")

        # æ”¯æŒçš„ç±»ï¼Œå¦‚æœæ²¡æœ‰å®‰è£… Peft åº“ï¼Œåˆ™ä»…æ”¯æŒ PreTrainedModel ç±»
        supported_classes = (PreTrainedModel,) if not is_peft_available() else (PreTrainedModel, PeftModel)
        # ä¿å­˜å·²è®­ç»ƒçš„æ¨¡å‹å’Œé…ç½®ä½¿ç”¨ `save_pretrained()`ã€‚
        # ç„¶åå¯ä»¥ä½¿ç”¨ `from_pretrained()` é‡æ–°åŠ è½½å®ƒä»¬
        if not isinstance(self.model, supported_classes):
            if state_dict is None:
                state_dict = self.model.state_dict()

            if isinstance(unwrap_model(self.model), supported_classes):
                # ä¿å­˜æ¨¡å‹å’ŒçŠ¶æ€å­—å…¸åˆ°output_dir
                unwrap_model(self.model).save_pretrained(
                    output_dir, state_dict=state_dict, safe_serialization=self.args.save_safetensors
                )
            else:
                # å¦‚æœTrainer.modelä¸æ˜¯`PreTrainedModel`ï¼Œåˆ™åªä¿å­˜å…¶çŠ¶æ€å­—å…¸
                logger.info("Trainer.model is not a `PreTrainedModel`, only saving its state dict.")
                if self.args.save_safetensors:
                    # ä»¥å®‰å…¨çš„æ–¹å¼ä¿å­˜çŠ¶æ€å­—å…¸
                    safetensors.torch.save_file(
                        state_dict, os.path.join(output_dir, SAFE_WEIGHTS_NAME), metadata={"format": "pt"}
                    )
                else:
                    # ä¿å­˜çŠ¶æ€å­—å…¸
                    torch.save(state_dict, os.path.join(output_dir, WEIGHTS_NAME))
        else:
            # ä¿å­˜æ¨¡å‹å’ŒçŠ¶æ€å­—å…¸åˆ°output_dir
            self.model.save_pretrained(
                output_dir, state_dict=state_dict, safe_serialization=self.args.save_safetensors
            )

        # å¦‚æœå­˜åœ¨tokenizerï¼Œä¿å­˜å…¶é…ç½®åˆ°output_dir
        if self.tokenizer is not None:
            self.tokenizer.save_pretrained(output_dir)

        # å¥½çš„åšæ³•ï¼šå°†è®­ç»ƒå‚æ•°ä¸è®­ç»ƒçš„æ¨¡å‹ä¸€èµ·ä¿å­˜
        torch.save(self.args, os.path.join(output_dir, TRAINING_ARGS_NAME))

    def store_flos(self):
        # å­˜å‚¨ç”¨äºæ¨¡å‹çš„æµ®ç‚¹è¿ç®—æ•°é‡
        if self.args.parallel_mode == ParallelMode.DISTRIBUTED:
            # å¦‚æœæ˜¯åˆ†å¸ƒå¼å¹¶è¡Œæ¨¡å¼ï¼Œå°†å½“å‰floså¹¿æ’­åˆ°æ‰€æœ‰è®¾å¤‡ä¸Šå¹¶è®¡ç®—æ€»å’Œ
            self.state.total_flos += (
                distributed_broadcast_scalars([self.current_flos], device=self.args.device).sum().item()
            )
            self.current_flos = 0
        else:
            # å¦åˆ™ç›´æ¥å°†å½“å‰flosæ·»åŠ åˆ°æ€»flosä¸­
            self.state.total_flos += self.current_flos
            self.current_flos = 0

    def _sorted_checkpoints(
        self, output_dir=None, checkpoint_prefix=PREFIX_CHECKPOINT_DIR, use_mtime=False
    # å®šä¹‰å‡½æ•°_sorted_checkpointsï¼Œè¿”å›æŒ‰ç…§æ—¶é—´æˆ–è€…æ–‡ä»¶åæ’åºçš„æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„åˆ—è¡¨
    def _sorted_checkpoints(self, use_mtime=False, output_dir=None) -> List[str]:
        # åˆå§‹åŒ–æ’åºåçš„æ£€æŸ¥ç‚¹è·¯å¾„åˆ—è¡¨
        ordering_and_checkpoint_path = []

        # è·å–è¾“å‡ºç›®å½•ä¸‹ä»¥æŒ‡å®šå‰ç¼€å¼€å¤´çš„æ‰€æœ‰æ–‡ä»¶å¤¹çš„è·¯å¾„åˆ—è¡¨
        glob_checkpoints = [str(x) for x in Path(output_dir).glob(f"{checkpoint_prefix}-*") if os.path.isdir(x)]

        # éå†æ‰€æœ‰æ£€æŸ¥ç‚¹è·¯å¾„
        for path in glob_checkpoints:
            # å¦‚æœä½¿ç”¨ä¿®æ”¹æ—¶é—´æ’åº
            if use_mtime:
                # å°†ä¿®æ”¹æ—¶é—´å’Œè·¯å¾„æ·»åŠ åˆ°æ’åºåˆ—è¡¨ä¸­
                ordering_and_checkpoint_path.append((os.path.getmtime(path), path))
            else:
                # å¦åˆ™ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–‡ä»¶åä¸­çš„æ•°å­—éƒ¨åˆ†ä½œä¸ºæ’åºä¾æ®
                regex_match = re.match(f".*{checkpoint_prefix}-([0-9]+)", path)
                # å¦‚æœåŒ¹é…æˆåŠŸ
                if regex_match is not None and regex_match.groups() is not None:
                    # å°†æ•°å­—éƒ¨åˆ†è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¹¶å°†å…¶ä¸è·¯å¾„æ·»åŠ åˆ°æ’åºåˆ—è¡¨ä¸­
                    ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))

        # å¯¹æ’åºåçš„æ£€æŸ¥ç‚¹è·¯å¾„åˆ—è¡¨è¿›è¡Œæ’åº
        checkpoints_sorted = sorted(ordering_and_checkpoint_path)
        # æå–æ’åºåçš„æ£€æŸ¥ç‚¹è·¯å¾„åˆ—è¡¨ä¸­çš„è·¯å¾„éƒ¨åˆ†
        checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]
        
        # ç¡®ä¿ä¸åˆ é™¤æœ€ä½³æ¨¡å‹
        if (
            self.state.best_model_checkpoint is not None
            and str(Path(self.state.best_model_checkpoint)) in checkpoints_sorted
        ):
            # è·å–æœ€ä½³æ¨¡å‹åœ¨æ’åºåçš„æ£€æŸ¥ç‚¹è·¯å¾„åˆ—è¡¨ä¸­çš„ç´¢å¼•
            best_model_index = checkpoints_sorted.index(str(Path(self.state.best_model_checkpoint)))
            # å°†æœ€ä½³æ¨¡å‹ç§»åŠ¨åˆ°æ’åºåçš„æ£€æŸ¥ç‚¹è·¯å¾„åˆ—è¡¨çš„å€’æ•°ç¬¬äºŒä¸ªä½ç½®
            for i in range(best_model_index, len(checkpoints_sorted) - 2):
                checkpoints_sorted[i], checkpoints_sorted[i + 1] = checkpoints_sorted[i + 1], checkpoints_sorted[i]
        
        # è¿”å›æ’åºåçš„æ£€æŸ¥ç‚¹è·¯å¾„åˆ—è¡¨
        return checkpoints_sorted

    # å®šä¹‰_rotate_checkpointså‡½æ•°ï¼Œç”¨äºè½®æ¢å’Œåˆ é™¤æ¨¡å‹æ£€æŸ¥ç‚¹
    def _rotate_checkpoints(self, use_mtime=False, output_dir=None) -> None:
        # å¦‚æœæœªè®¾ç½®ä¿å­˜é™åˆ¶æˆ–ä¿å­˜é™åˆ¶å°äºç­‰äº0ï¼Œåˆ™ç›´æ¥è¿”å›
        if self.args.save_total_limit is None or self.args.save_total_limit <= 0:
            return

        # è·å–æŒ‰ç…§æ—¶é—´æˆ–è€…æ–‡ä»¶åæ’åºçš„æ£€æŸ¥ç‚¹è·¯å¾„åˆ—è¡¨
        checkpoints_sorted = self._sorted_checkpoints(use_mtime=use_mtime, output_dir=output_dir)
        # å¦‚æœæ£€æŸ¥ç‚¹æ•°é‡ä¸è¶…è¿‡ä¿å­˜é™åˆ¶ï¼Œåˆ™ç›´æ¥è¿”å›
        if len(checkpoints_sorted) <= self.args.save_total_limit:
            return

        # å¤„ç†åœ¨æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹æ˜¯æœ€ä½³æ¨¡å‹ä½†ä¸æ˜¯å”¯ä¸€æ£€æŸ¥ç‚¹çš„æƒ…å†µ
        save_total_limit = self.args.save_total_limit
        if (
            self.state.best_model_checkpoint is not None
            and self.args.save_total_limit == 1
            and checkpoints_sorted[-1] != self.state.best_model_checkpoint
        ):
            save_total_limit = 2

        # è®¡ç®—éœ€è¦åˆ é™¤çš„æ£€æŸ¥ç‚¹æ•°é‡
        number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - save_total_limit)
        # è·å–éœ€è¦åˆ é™¤çš„æ£€æŸ¥ç‚¹åˆ—è¡¨
        checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]
        # éå†å¹¶åˆ é™¤éœ€è¦åˆ é™¤çš„æ£€æŸ¥ç‚¹
        for checkpoint in checkpoints_to_be_deleted:
            logger.info(f"Deleting older checkpoint [{checkpoint}] due to args.save_total_limit")
            shutil.rmtree(checkpoint, ignore_errors=True)

    # å®šä¹‰evaluateå‡½æ•°ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½
    def evaluate(
        self,
        eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]] = None,
        ignore_keys: Optional[List[str]] = None,
        metric_key_prefix: str = "eval",
    # å®šä¹‰predictå‡½æ•°ï¼Œç”¨äºæ¨¡å‹æ¨æ–­
    def predict(
        self, test_dataset: Dataset, ignore_keys: Optional[List[str]] = None, metric_key_prefix: str = "test"
    ) -> PredictionOutput:
        """
        Run prediction and returns predictions and potential metrics.

        Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
        will also return metrics, like in `evaluate()`.

        Args:
            test_dataset (`Dataset`):
                Dataset to run the predictions on. If it is an `datasets.Dataset`, columns not accepted by the
                `model.forward()` method are automatically removed. Has to implement the method `__len__`
            ignore_keys (`List[str]`, *optional*):
                A list of keys in the output of your model (if it is a dictionary) that should be ignored when
                gathering predictions.
            metric_key_prefix (`str`, *optional*, defaults to `"test"`):
                An optional prefix to be used as the metrics key prefix. For example the metrics "bleu" will be named
                "test_bleu" if the prefix is "test" (default)

        <Tip>

        If your predictions or labels have different sequence length (for instance because you're doing dynamic padding
        in a token classification task) the predictions will be padded (on the right) to allow for concatenation into
        one array. The padding index is -100.

        </Tip>

        Returns: *NamedTuple* A namedtuple with the following keys:

            - predictions (`np.ndarray`): The predictions on `test_dataset`.
            - label_ids (`np.ndarray`, *optional*): The labels (if the dataset contained some).
            - metrics (`Dict[str, float]`, *optional*): The potential dictionary of metrics (if the dataset contained
              labels).
        """
        # memory metrics - must set up as early as possible
        self._memory_tracker.start()

        # è·å–æµ‹è¯•æ•°æ®åŠ è½½å™¨
        test_dataloader = self.get_test_dataloader(test_dataset)
        start_time = time.time()

        # æ ¹æ®ä½¿ç”¨çš„é¢„æµ‹å¾ªç¯æ–¹æ³•é€‰æ‹©ç›¸åº”çš„å¾ªç¯å‡½æ•°
        eval_loop = self.prediction_loop if self.args.use_legacy_prediction_loop else self.evaluation_loop
        # è¿è¡Œé¢„æµ‹å¾ªç¯ï¼Œè·å–è¾“å‡ºç»“æœ
        output = eval_loop(
            test_dataloader, description="Prediction", ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix
        )
        total_batch_size = self.args.eval_batch_size * self.args.world_size
        # å¦‚æœè¾“å‡ºä¸­åŒ…å«å³æ—¶ç¼–è¯‘æ—¶é—´ï¼Œåˆ™æ›´æ–°å¼€å§‹æ—¶é—´
        if f"{metric_key_prefix}_jit_compilation_time" in output.metrics:
            start_time += output.metrics[f"{metric_key_prefix}_jit_compilation_time"]
        # æ›´æ–°è¾“å‡ºä¸­çš„é€Ÿåº¦æŒ‡æ ‡
        output.metrics.update(
            speed_metrics(
                metric_key_prefix,
                start_time,
                num_samples=output.num_samples,
                num_steps=math.ceil(output.num_samples / total_batch_size),
            )
        )

        # åœ¨é¢„æµ‹ä¹‹å‰è°ƒç”¨å›è°ƒå‡½æ•°
        self.control = self.callback_handler.on_predict(self.args, self.state, self.control, output.metrics)
        # åœæ­¢å†…å­˜è¿½è¸ªå¹¶æ›´æ–°æŒ‡æ ‡
        self._memory_tracker.stop_and_update_metrics(output.metrics)

        # è¿”å›é¢„æµ‹ç»“æœ
        return PredictionOutput(predictions=output.predictions, label_ids=output.label_ids, metrics=output.metrics)
    # å®šä¹‰è¯„ä¼°å¾ªç¯å‡½æ•°ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨ç»™å®šæ•°æ®é›†ä¸Šçš„æ€§èƒ½
    def evaluation_loop(
        self,
        dataloader: DataLoader,
        description: str,
        prediction_loss_only: Optional[bool] = None,
        ignore_keys: Optional[List[str]] = None,
        metric_key_prefix: str = "eval",
    # å†…éƒ¨å‡½æ•°ï¼Œç”¨äºæ”¶é›†å¹¶æ±‡æ€»åˆ†å¸ƒå¼ç¯å¢ƒä¸­çš„å¼ é‡æ•°æ®
    def _nested_gather(self, tensors, name=None):
        """
        Gather value of `tensors` (tensor or list/tuple of nested tensors) and convert them to numpy before
        concatenating them to `gathered`
        """
        # å¦‚æœå¼ é‡ä¸ºç©ºï¼Œåˆ™ç›´æ¥è¿”å›
        if tensors is None:
            return
        # å¦‚æœæ˜¯åœ¨ Torch TPU ç¯å¢ƒä¸­ï¼Œè¿›è¡Œå¼ é‡çš„æ±‡æ€»æ“ä½œ
        if is_torch_tpu_available():
            # å¦‚æœæœªæŒ‡å®šåç§°ï¼Œåˆ™ä½¿ç”¨é»˜è®¤åç§°
            if name is None:
                name = "nested_gather"
            # ä½¿ç”¨ XLA ç½‘æ ¼å‡å°‘å‡½æ•°å¯¹å¼ é‡è¿›è¡Œæ±‡æ€»
            tensors = nested_xla_mesh_reduce(tensors, name)
        # å¦‚æœæ˜¯åœ¨ SageMaker å¤šè¿›ç¨‹ç¯å¢ƒä¸­ï¼Œä½¿ç”¨ SageMaker æä¾›çš„æ±‡æ€»å‡½æ•°
        elif is_sagemaker_mp_enabled():
            tensors = smp_gather(tensors)
        # å¦‚æœæ˜¯åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ï¼Œä½¿ç”¨åˆ†å¸ƒå¼ç¯å¢ƒæä¾›çš„æ±‡æ€»å‡½æ•°
        elif (self.args.distributed_state is not None and self.args.distributed_state.distributed_type != "NO") or (
            self.args.distributed_state is None and self.args.local_rank != -1
        ):
            tensors = distributed_concat(tensors)
        # è¿”å›æ±‡æ€»åçš„å¼ é‡
        return tensors

    # é¢„æµ‹æ­¥éª¤å‡½æ•°ï¼Œç”¨äºæ‰§è¡Œæ¨¡å‹çš„å‰å‘æ¨ç†
    def prediction_step(
        self,
        model: nn.Module,
        inputs: Dict[str, Union[torch.Tensor, Any]],
        prediction_loss_only: bool,
        ignore_keys: Optional[List[str]] = None,
    # æµ®ç‚¹è¿ç®—å‡½æ•°ï¼Œç”¨äºè®¡ç®—æ¯ä¸ªå‰å‘æ¨ç†æ­¥éª¤çš„æµ®ç‚¹è¿ç®—æ•°
    def floating_point_ops(self, inputs: Dict[str, Union[torch.Tensor, Any]]):
        """
        For models that inherit from [`PreTrainedModel`], uses that method to compute the number of floating point
        operations for every backward + forward pass. If using another model, either implement such a method in the
        model or subclass and override this method.

        Args:
            inputs (`Dict[str, Union[torch.Tensor, Any]]`):
                The inputs and targets of the model.

        Returns:
            `int`: The number of floating-point operations.
        """
        # å¦‚æœæ¨¡å‹å…·æœ‰è®¡ç®—æµ®ç‚¹è¿ç®—æ•°çš„æ–¹æ³•ï¼Œåˆ™è°ƒç”¨è¯¥æ–¹æ³•
        if hasattr(self.model, "floating_point_ops"):
            return self.model.floating_point_ops(inputs)
        # å¦åˆ™è¿”å›0ï¼Œè¡¨ç¤ºæ²¡æœ‰æµ®ç‚¹è¿ç®—
        else:
            return 0

    # åˆå§‹åŒ–æ¨¡å‹åœ¨ Hugging Face ä»“åº“ä¸­çš„ä¿¡æ¯
    def init_hf_repo(self):
        """
        Initializes a git repo in `self.args.hub_model_id`.
        """
        # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œä»¥ä¸‹ä»£ç 
        if not self.is_world_process_zero():
            return

        # å¦‚æœæœªæä¾› Hugging Face ä»“åº“æ¨¡å‹ IDï¼Œåˆ™ä½¿ç”¨è¾“å‡ºç›®å½•çš„åç§°ä½œä¸ºä»“åº“åç§°
        if self.args.hub_model_id is None:
            repo_name = Path(self.args.output_dir).absolute().name
        else:
            repo_name = self.args.hub_model_id

        # åˆ›å»ºä»“åº“ï¼Œå¹¶è·å–ä»“åº“ URL
        repo_url = create_repo(repo_name, token=self.args.hub_token, private=self.args.hub_private_repo, exist_ok=True)
        # è®¾ç½®æ¨¡å‹åœ¨ Hugging Face ä»“åº“ä¸­çš„ ID
        self.hub_model_id = repo_url.repo_id
        # åˆå§‹åŒ–æ¨é€çŠ¶æ€
        self.push_in_progress = None
    # åˆ›å»ºæ¨¡å‹å¡ç‰‡çš„æ–¹æ³•
    def create_model_card(
        # è¯­è¨€å‚æ•°ï¼Œå¯é€‰
        self,
        language: Optional[str] = None,
        # è®¸å¯è¯å‚æ•°ï¼Œå¯é€‰
        license: Optional[str] = None,
        # æ ‡ç­¾å‚æ•°ï¼Œå¯é€‰ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨
        tags: Union[str, List[str], None] = None,
        # æ¨¡å‹åç§°å‚æ•°ï¼Œå¯é€‰
        model_name: Optional[str] = None,
        # å¾®è°ƒè‡ªå‚æ•°ï¼Œå¯é€‰
        finetuned_from: Optional[str] = None,
        # ä»»åŠ¡å‚æ•°ï¼Œå¯é€‰ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨
        tasks: Union[str, List[str], None] = None,
        # æ•°æ®é›†æ ‡ç­¾å‚æ•°ï¼Œå¯é€‰ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨
        dataset_tags: Union[str, List[str], None] = None,
        # æ•°æ®é›†å‚æ•°ï¼Œå¯é€‰ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨
        dataset: Union[str, List[str], None] = None,
        # æ•°æ®é›†å‚æ•°å‚æ•°ï¼Œå¯é€‰ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨
        dataset_args: Union[str, List[str], None] = None,
        """
        Creates a draft of a model card using the information available to the `Trainer`.

        Args:
            language (`str`, *optional*):
                The language of the model (if applicable)
            license (`str`, *optional*):
                The license of the model. Will default to the license of the pretrained model used, if the original
                model given to the `Trainer` comes from a repo on the Hub.
            tags (`str` or `List[str]`, *optional*):
                Some tags to be included in the metadata of the model card.
            model_name (`str`, *optional*):
                The name of the model.
            finetuned_from (`str`, *optional*):
                The name of the model used to fine-tune this one (if applicable). Will default to the name of the repo
                of the original model given to the `Trainer` (if it comes from the Hub).
            tasks (`str` or `List[str]`, *optional*):
                One or several task identifiers, to be included in the metadata of the model card.
            dataset_tags (`str` or `List[str]`, *optional*):
                One or several dataset tags, to be included in the metadata of the model card.
            dataset (`str` or `List[str]`, *optional*):
                One or several dataset identifiers, to be included in the metadata of the model card.
            dataset_args (`str` or `List[str]`, *optional*):
               One or several dataset arguments, to be included in the metadata of the model card.
        """
        # æ£€æŸ¥å½“å‰è¿›ç¨‹æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ï¼Œå¦‚æœä¸æ˜¯åˆ™è¿”å›
        if not self.is_world_process_zero():
            return

        # æ‹¼æ¥æ¨¡å‹å¡ç‰‡æ–‡ä»¶è·¯å¾„
        model_card_filepath = os.path.join(self.args.output_dir, "README.md")
        is_peft_library = False
        # å¦‚æœæ¨¡å‹å¡ç‰‡æ–‡ä»¶å­˜åœ¨
        if os.path.exists(model_card_filepath):
            # åŠ è½½æ¨¡å‹å¡ç‰‡æ–‡ä»¶ï¼Œè·å–åº“åç§°
            library_name = ModelCard.load(model_card_filepath).data.get("library_name")
            is_peft_library = library_name == "peft"

            # è¿½åŠ ç°æœ‰çš„æ ‡ç­¾åˆ° `tags`
            existing_tags = ModelCard.load(model_card_filepath).data.tags
            if tags is not None and existing_tags is not None:
                if isinstance(tags, str):
                    tags = [tags]
                for tag in existing_tags:
                    if tag not in tags:
                        tags.append(tag)

        # ä» Trainer ä¸­è·å–è®­ç»ƒæ‘˜è¦ä¿¡æ¯
        training_summary = TrainingSummary.from_trainer(
            self,
            language=language,
            license=license,
            tags=tags,
            model_name=model_name,
            finetuned_from=finetuned_from,
            tasks=tasks,
            dataset_tags=dataset_tags,
            dataset=dataset,
            dataset_args=dataset_args,
        )
        # å°†è®­ç»ƒæ‘˜è¦ä¿¡æ¯è½¬æ¢ä¸ºæ¨¡å‹å¡ç‰‡
        model_card = training_summary.to_model_card()
        # å°†æ¨¡å‹å¡ç‰‡å†™å…¥æ–‡ä»¶
        with open(model_card_filepath, "w") as f:
            f.write(model_card)

        # å¦‚æœæ˜¯ peft åº“ï¼Œåˆ™åˆ›å»ºæˆ–æ›´æ–°æ¨¡å‹å¡ç‰‡
        if is_peft_library:
            unwrap_model(self.model).create_or_update_model_card(self.args.output_dir)
    # ä»æ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹ä¸­æ¨é€æ¨¡å‹æ–‡ä»¶åˆ°æŒ‡å®šçš„ Hub
    def _push_from_checkpoint(self, checkpoint_folder):
        # åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹æ‰§è¡Œæ¨é€æ“ä½œ
        if not self.is_world_process_zero() or self.args.hub_strategy == HubStrategy.END:
            return
        # å¦‚æœä¸Šæ¬¡æ¨é€è¿˜æœªå®Œæˆï¼Œå¹¶ä¸”æœªè®¾ç½® args.hub_always_push=Trueï¼Œåˆ™ä¸æ‰§è¡Œæ­¤æ¬¡æ¨é€
        if not self.args.hub_always_push and self.push_in_progress is not None and not self.push_in_progress.is_done():
            return

        output_dir = self.args.output_dir
        # é¿å…é‡æ–°åŒæ­¥æ‰€æœ‰æ¨¡å‹æƒé‡ï¼Œç›´æ¥ä»æ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹å¤åˆ¶æ–‡ä»¶
        modeling_files = [CONFIG_NAME, WEIGHTS_NAME, SAFE_WEIGHTS_NAME]
        if is_peft_available():
            modeling_files.extend([ADAPTER_CONFIG_NAME, ADAPTER_WEIGHTS_NAME, ADAPTER_SAFE_WEIGHTS_NAME])
        for modeling_file in modeling_files:
            if os.path.isfile(os.path.join(checkpoint_folder, modeling_file)):
                shutil.copy(os.path.join(checkpoint_folder, modeling_file), os.path.join(output_dir, modeling_file))
        # ä¿å­˜åˆ†è¯å™¨å¾ˆå¿«ï¼Œä¸ç¡®å®šå¯èƒ½ç”Ÿæˆå¤šå°‘æ–‡ä»¶ï¼Œå› æ­¤é‡æ–°ä¿å­˜ä»¥ç¡®ä¿
        if self.tokenizer is not None:
            self.tokenizer.save_pretrained(output_dir)
        # ä¿å­˜è®­ç»ƒå‚æ•°åŒæ ·å¾ˆå¿«ï¼Œä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        torch.save(self.args, os.path.join(output_dir, TRAINING_ARGS_NAME))

        if self.args.save_strategy == IntervalStrategy.STEPS:
            commit_message = f"Training in progress, step {self.state.global_step}"
        else:
            commit_message = f"Training in progress, epoch {int(self.state.epoch)}"

        # ä¸Šä¼ æ¨¡å‹æ–‡ä»¶å¤¹åˆ° Hubï¼Œå¹¶è¿”å›ä¸Šä¼ ä»»åŠ¡
        model_push_job = upload_folder(
            repo_id=self.hub_model_id,
            folder_path=output_dir,
            commit_message=commit_message,
            token=self.args.hub_token,
            run_as_future=True,
            ignore_patterns=["_*", f"{PREFIX_CHECKPOINT_DIR}-*"],
        )

        push_jobs = [model_push_job]

        if self.args.hub_strategy in [HubStrategy.CHECKPOINT, HubStrategy.ALL_CHECKPOINTS]:
            path_in_repo = (
                "last-checkpoint" if self.args.hub_strategy == HubStrategy.CHECKPOINT else Path(checkpoint_folder).name
            )
            # ä¸Šä¼ æ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹åˆ° Hubï¼Œå¹¶è¿”å›ä¸Šä¼ ä»»åŠ¡
            checkpoint_push = upload_folder(
                repo_id=self.hub_model_id,
                folder_path=checkpoint_folder,
                path_in_repo=path_in_repo,
                commit_message=commit_message + ", checkpoint",
                token=self.args.hub_token,
                run_as_future=True,
            )
            push_jobs.append(checkpoint_push)

        # å¦‚æœæ²¡æœ‰æ¨é€ä»»åŠ¡è¿›è¡Œä¸­æˆ–å·²å®Œæˆï¼Œåˆ™åˆ›å»ºæ–°çš„æ¨é€ä»»åŠ¡
        if self.push_in_progress is None or self.push_in_progress.is_done():
            self.push_in_progress = PushInProgress(push_jobs)
        else:
            self.push_in_progress.jobs.extend(push_jobs)
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³• `_finish_current_push`ï¼Œç”¨äºå®Œæˆå½“å‰çš„æ¨é€æ“ä½œ
    def _finish_current_push(self):
        # å¦‚æœå¯¹è±¡æ²¡æœ‰å±æ€§ `push_in_progress`ï¼Œåˆ™ç›´æ¥è¿”å›ï¼Œä¸æ‰§è¡Œåç»­æ“ä½œ
        if not hasattr(self, "push_in_progress"):
            return
        # å¦‚æœå½“å‰æ¨é€æ“ä½œä¸ä¸ºç©ºä¸”å°šæœªå®Œæˆ
        if self.push_in_progress is not None and not self.push_in_progress.is_done():
            # è®°å½•æ—¥å¿—ï¼Œæç¤ºå½“å‰æ­£åœ¨ç­‰å¾…å½“å‰æ£€æŸ¥ç‚¹æ¨é€å®Œæˆï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´
            logger.info("Waiting for the current checkpoint push to be finished, this might take a couple of minutes.")
            # ç­‰å¾…å½“å‰æ¨é€æ“ä½œå®Œæˆ
            self.push_in_progress.wait_until_done()
    def push_to_hub(self, commit_message: Optional[str] = "End of training", blocking: bool = True, **kwargs) -> str:
        """
        å°† `self.model` å’Œ `self.tokenizer` ä¸Šä¼ åˆ° ğŸ¤— æ¨¡å‹ä¸­å¿ƒï¼Œå­˜å‚¨åœ¨ `self.args.hub_model_id` æŒ‡å®šçš„ä»“åº“ä¸­ã€‚

        Parameters:
            commit_message (`str`, *optional*, defaults to `"End of training"`):
                æäº¤æ—¶çš„æ¶ˆæ¯ã€‚
            blocking (`bool`, *optional*, defaults to `True`):
                æ˜¯å¦åœ¨ `git push` å®Œæˆåè¿”å›ã€‚
            kwargs (`Dict[str, Any]`, *optional*):
                ä¼ é€’ç»™ [`~Trainer.create_model_card`] çš„é¢å¤–å…³é”®å­—å‚æ•°ã€‚

        Returns:
            å¦‚æœ `blocking=False`ï¼Œåˆ™è¿”å›æ¨¡å‹ä¸Šä¼ çš„ä»“åº“ URLï¼›å¦‚æœ `blocking=True`ï¼Œåˆ™è¿”å›è·Ÿè¸ªæäº¤è¿›åº¦çš„ `Future` å¯¹è±¡ã€‚
        """
        model_name = kwargs.pop("model_name", None)
        # å¦‚æœ `model_name` æœªæŒ‡å®šä¸”åº”ä¿å­˜æ¨¡å‹ï¼Œåˆ™æ ¹æ®æƒ…å†µè®¾å®šé»˜è®¤ `model_name`
        if model_name is None and self.args.should_save:
            if self.args.hub_model_id is None:
                model_name = Path(self.args.output_dir).name
            else:
                model_name = self.args.hub_model_id.split("/")[-1]

        # å¦‚æœ `self.hub_model_id` ä¸ºç©ºï¼Œåˆ™åˆå§‹åŒ–æ¨¡å‹ä¸­å¿ƒçš„ä»“åº“
        if self.hub_model_id is None:
            self.init_hf_repo()

        # åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šæ‰§è¡Œä»¥ä¾¿äº TPU è®­ç»ƒï¼Œä½†åªåœ¨ç”± `self.args.should_save` å†³å®šçš„è¿›ç¨‹ä¸Šä¿å­˜
        self.save_model(_internal_call=True)

        # åªä»ä¸€ä¸ªèŠ‚ç‚¹æ¨é€
        if not self.is_world_process_zero():
            return

        # å¦‚æœæ¨¡å‹å·²ç»å…·æœ‰æŸäº›æ ‡ç­¾ä¸”ç”¨æˆ·ä¼ é€’äº† "tags" å‚æ•°ç»™ `push_to_hub`ï¼Œåˆ™è‡ªåŠ¨å¤„ç†æ‰€æœ‰æ¨¡å‹çš„å†…éƒ¨æ ‡ç­¾
        # ç”±äº Trainer ä¸è°ƒç”¨ `model.push_to_hub`ï¼Œæ‰€ä»¥éœ€è¦æ·»åŠ é¢å¤–çš„æ ‡ç­¾
        if "tags" in kwargs and getattr(self.model, "model_tags", None) is not None:
            # å¦‚æœ `tags` æ˜¯å­—ç¬¦ä¸²ï¼Œåˆ™è½¬æ¢ä¸ºåˆ—è¡¨
            if isinstance(kwargs["tags"], str):
                kwargs["tags"] = [kwargs["tags"]]

            for model_tag in self.model.model_tags:
                if model_tag not in kwargs["tags"]:
                    kwargs["tags"].append(model_tag)

        # åˆ›å»ºæ¨¡å‹å¡
        self.create_model_card(model_name=model_name, **kwargs)

        # ç­‰å¾…å½“å‰ä¸Šä¼ å®Œæˆ
        self._finish_current_push()
        # ä¸Šä¼ æ¨¡å‹æ–‡ä»¶å¤¹
        return upload_folder(
            repo_id=self.hub_model_id,
            folder_path=self.args.output_dir,
            commit_message=commit_message,
            token=self.args.hub_token,
            run_as_future=not blocking,
            ignore_patterns=["_*", f"{PREFIX_CHECKPOINT_DIR}-*"],
        )

    #
    # Deprecated code
    #
```  
    def prediction_loop(
        self,
        dataloader: DataLoader,
        description: str,
        prediction_loss_only: Optional[bool] = None,
        ignore_keys: Optional[List[str]] = None,
        metric_key_prefix: str = "eval",
    ):
        """
        Prediction loop for generating model predictions on a dataset.

        Args:
            dataloader (DataLoader): DataLoader containing the dataset.
            description (str): Description of the prediction loop.
            prediction_loss_only (Optional[bool], optional): Whether to calculate only the prediction loss. Defaults to None.
            ignore_keys (Optional[List[str]], optional): List of keys to ignore when calculating predictions. Defaults to None.
            metric_key_prefix (str, optional): Prefix for metric keys. Defaults to "eval".
        """

    def _gather_and_numpify(self, tensors, name):
        """
        Gather value of `tensors` (tensor or list/tuple of nested tensors) and convert them to numpy before
        concatenating them to `gathered`
        """
        if tensors is None:
            return
        if is_torch_tpu_available():
            # If using TPU, perform a nested XLA mesh reduce operation on tensors
            tensors = nested_xla_mesh_reduce(tensors, name)
        elif is_sagemaker_mp_enabled():
            # If using SageMaker multi-processing, gather tensors
            tensors = smp_gather(tensors)
        elif self.args.parallel_mode == ParallelMode.DISTRIBUTED:
            # If using distributed training, concatenate tensors
            tensors = distributed_concat(tensors)

        # Convert gathered tensors to numpy arrays
        return nested_numpify(tensors)

    def _add_sm_patterns_to_gitignore(self) -> None:
        """Add SageMaker Checkpointing patterns to .gitignore file."""
        # Ensure this function is only executed on the main process
        if not self.is_world_process_zero():
            return

        # Define SageMaker checkpointing patterns
        patterns = ["*.sagemaker-uploading", "*.sagemaker-uploaded"]

        # Get current content of .gitignore file
        if os.path.exists(os.path.join(self.repo.local_dir, ".gitignore")):
            with open(os.path.join(self.repo.local_dir, ".gitignore"), "r") as f:
                current_content = f.read()
        else:
            current_content = ""

        # Add SageMaker patterns to .gitignore if not already present
        content = current_content
        for pattern in patterns:
            if pattern not in content:
                if content.endswith("\n"):
                    content += pattern
                else:
                    content += f"\n{pattern}"

        # Write updated .gitignore file if changes were made
        if content != current_content:
            with open(os.path.join(self.repo.local_dir, ".gitignore"), "w") as f:
                logger.debug(f"Writing .gitignore file. Content: {content}")
                f.write(content)

        # Add .gitignore to git staging area
        self.repo.git_add(".gitignore")

        # Avoid race condition with git status
        time.sleep(0.5)

        # Commit changes to git repository if repository is not clean
        if not self.repo.is_repo_clean():
            self.repo.git_commit("Add *.sagemaker patterns to .gitignore.")
            self.repo.git_push()
    # åˆ›å»ºæ¢¯åº¦ç´¯ç§¯æ’ä»¶çš„å‚æ•°å­—å…¸
    grad_acc_kwargs = {"num_steps": self.args.gradient_accumulation_steps}
    grad_acc_kwargs["sync_with_dataloader"] = False
    # åˆ›å»ºæ¢¯åº¦ç´¯ç§¯æ’ä»¶å¯¹è±¡
    gradient_accumulation_plugin = GradientAccumulationPlugin(**grad_acc_kwargs)

    # åˆ›å»ºåŠ é€Ÿå™¨å¯¹è±¡
    self.accelerator = Accelerator(
        dispatch_batches=self.args.dispatch_batches,
        split_batches=self.args.split_batches,
        deepspeed_plugin=self.args.deepspeed_plugin,
        gradient_accumulation_plugin=gradient_accumulation_plugin,
    )
    # ä¸€äº› Trainer ç±»éœ€è¦ä½¿ç”¨ `gather` è€Œä¸æ˜¯ `gather_for_metrics`ï¼Œå› æ­¤å­˜å‚¨ä¸€ä¸ªæ ‡å¿—
    self.gather_function = self.accelerator.gather_for_metrics

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº† deepspeed å’Œ accelerateï¼ŒåŒ…æ‹¬ Trainer å‚æ•°å’Œ accelerate å¯åŠ¨å™¨
    self.is_deepspeed_enabled = getattr(self.accelerator.state, "deepspeed_plugin", None) is not None
    self.is_fsdp_enabled = getattr(self.accelerator.state, "fsdp_plugin", None) is not None

    # åŠ é€Ÿå™¨åˆ›å»ºåçš„è®¾ç½®
    if self.is_fsdp_enabled:
        fsdp_plugin = self.accelerator.state.fsdp_plugin
        fsdp_plugin.limit_all_gathers = self.args.fsdp_config.get(
            "limit_all_gathers", fsdp_plugin.limit_all_gathers
        )
        if is_accelerate_available("0.23.0"):
            fsdp_plugin.activation_checkpointing = self.args.fsdp_config.get(
                "activation_checkpointing", fsdp_plugin.activation_checkpointing
            )
            if fsdp_plugin.activation_checkpointing and self.args.gradient_checkpointing:
                raise ValueError(
                    "The activation_checkpointing in FSDP config and the gradient_checkpointing in training arg "
                    "can't be set to True simultaneously. Please use FSDP's activation_checkpointing logic "
                    "when using FSDP."
                )

    # å¦‚æœå¯ç”¨äº† deepspeed å¹¶ä¸”æ²¡æœ‰ hf_deepspeed_config å‚æ•°ï¼Œåˆ™å°†å‚æ•°ä¼ æ’­åˆ° deepspeed
    if self.is_deepspeed_enabled and getattr(self.args, "hf_deepspeed_config", None) is None:
        self.propagate_args_to_deepspeed()

def propagate_args_to_deepspeed(self, auto_find_batch_size=False):
    """
    Sets values in the deepspeed plugin based on the Trainer args
    """
    from transformers.integrations.deepspeed import HfTrainerDeepSpeedConfig

    ds_plugin = self.accelerator.state.deepspeed_plugin

    # è®¾ç½® deepspeed æ’ä»¶çš„å€¼åŸºäº Trainer å‚æ•°
    ds_plugin.hf_ds_config = HfTrainerDeepSpeedConfig(ds_plugin.hf_ds_config.config)
    ds_plugin.deepspeed_config = ds_plugin.hf_ds_config.config
    ds_plugin.hf_ds_config.trainer_config_process(self.args, auto_find_batch_size)
```