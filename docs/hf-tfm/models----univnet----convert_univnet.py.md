# `.\models\univnet\convert_univnet.py`

```py
# å¼•å…¥å‘½ä»¤è¡Œå‚æ•°è§£ææ¨¡å—
import argparse

# å¼•å…¥ PyTorch æ¨¡å—
import torch

# ä» transformers åº“ä¸­å¼•å…¥ UnivNetConfigã€UnivNetModel å’Œ logging æ¨¡å—
from transformers import UnivNetConfig, UnivNetModel, logging

# è®¾ç½® logging æ¨¡å—çš„è¯¦ç»†ä¿¡æ¯çº§åˆ«
logging.set_verbosity_info()

# è·å–åä¸º "transformers.models.univnet" çš„æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger("transformers.models.univnet")


# å®šä¹‰å‡½æ•°ï¼šè·å–å†…æ ¸é¢„æµ‹å™¨é”®æ˜ å°„
def get_kernel_predictor_key_mapping(config: UnivNetConfig, old_prefix: str = "", new_prefix: str = ""):
    # åˆ›å»ºç©ºå­—å…¸ mapping ç”¨äºå­˜å‚¨é”®æ˜ å°„å…³ç³»
    mapping = {}

    # åˆå§‹å·ç§¯å±‚æ˜ å°„
    mapping[f"{old_prefix}.input_conv.0.weight_g"] = f"{new_prefix}.input_conv.weight_g"
    mapping[f"{old_prefix}.input_conv.0.weight_v"] = f"{new_prefix}.input_conv.weight_v"
    mapping[f"{old_prefix}.input_conv.0.bias"] = f"{new_prefix}.input_conv.bias"

    # éå†æ ¸é¢„æµ‹å™¨çš„æ®‹å·®å—
    for i in range(config.kernel_predictor_num_blocks):
        # ç¬¬ä¸€ä¸ªå·ç§¯å±‚æ˜ å°„
        mapping[f"{old_prefix}.residual_convs.{i}.1.weight_g"] = f"{new_prefix}.resblocks.{i}.conv1.weight_g"
        mapping[f"{old_prefix}.residual_convs.{i}.1.weight_v"] = f"{new_prefix}.resblocks.{i}.conv1.weight_v"
        mapping[f"{old_prefix}.residual_convs.{i}.1.bias"] = f"{new_prefix}.resblocks.{i}.conv1.bias"

        # ç¬¬äºŒä¸ªå·ç§¯å±‚æ˜ å°„
        mapping[f"{old_prefix}.residual_convs.{i}.3.weight_g"] = f"{new_prefix}.resblocks.{i}.conv2.weight_g"
        mapping[f"{old_prefix}.residual_convs.{i}.3.weight_v"] = f"{new_prefix}.resblocks.{i}.conv2.weight_v"
        mapping[f"{old_prefix}.residual_convs.{i}.3.bias"] = f"{new_prefix}.resblocks.{i}.conv2.bias"

    # æ ¸è¾“å‡ºå·ç§¯å±‚æ˜ å°„
    mapping[f"{old_prefix}.kernel_conv.weight_g"] = f"{new_prefix}.kernel_conv.weight_g"
    mapping[f"{old_prefix}.kernel_conv.weight_v"] = f"{new_prefix}.kernel_conv.weight_v"
    mapping[f"{old_prefix}.kernel_conv.bias"] = f"{new_prefix}.kernel_conv.bias"

    # åç½®è¾“å‡ºå·ç§¯å±‚æ˜ å°„
    mapping[f"{old_prefix}.bias_conv.weight_g"] = f"{new_prefix}.bias_conv.weight_g"
    mapping[f"{old_prefix}.bias_conv.weight_v"] = f"{new_prefix}.bias_conv.weight_v"
    mapping[f"{old_prefix}.bias_conv.bias"] = f"{new_prefix}.bias_conv.bias"

    # è¿”å›æ˜ å°„å­—å…¸
    return mapping


# å®šä¹‰å‡½æ•°ï¼šè·å–é”®æ˜ å°„
def get_key_mapping(config: UnivNetConfig):
    # åˆ›å»ºç©ºå­—å…¸ mapping ç”¨äºå­˜å‚¨é”®æ˜ å°„å…³ç³»
    mapping = {}

    # æ³¨æ„ï¼šåˆå§‹å·ç§¯å±‚é”®ä¿æŒä¸å˜

    # LVC æ®‹å·®å—ï¼ˆæœªå®Œæˆçš„æ³¨é‡Šï¼‰
    # éå†é…ç½®ä¸­çš„æ®‹å·®å—æ­¥å¹…å¤§å°åˆ—è¡¨çš„é•¿åº¦
    for i in range(len(config.resblock_stride_sizes)):
        # è®¾ç½® LVCBlock çš„åˆå§‹å·ç§¯å±‚æƒé‡å’Œåç½®çš„æ˜ å°„å…³ç³»
        mapping[f"res_stack.{i}.convt_pre.1.weight_g"] = f"resblocks.{i}.convt_pre.weight_g"
        mapping[f"res_stack.{i}.convt_pre.1.weight_v"] = f"resblocks.{i}.convt_pre.weight_v"
        mapping[f"res_stack.{i}.convt_pre.1.bias"] = f"resblocks.{i}.convt_pre.bias"

        # è·å–å¹¶æ›´æ–°æ ¸é¢„æµ‹å™¨çš„æ˜ å°„å…³ç³»
        kernel_predictor_mapping = get_kernel_predictor_key_mapping(
            config, old_prefix=f"res_stack.{i}.kernel_predictor", new_prefix=f"resblocks.{i}.kernel_predictor"
        )
        mapping.update(kernel_predictor_mapping)

        # éå†å½“å‰æ®‹å·®å—çš„æ‰©å¼ å¤§å°åˆ—è¡¨çš„é•¿åº¦
        for j in range(len(config.resblock_dilation_sizes[i])):
            # è®¾ç½® LVC æ®‹å·®å—å†…éƒ¨å·ç§¯å±‚æƒé‡å’Œåç½®çš„æ˜ å°„å…³ç³»
            mapping[f"res_stack.{i}.conv_blocks.{j}.1.weight_g"] = f"resblocks.{i}.resblocks.{j}.conv.weight_g"
            mapping[f"res_stack.{i}.conv_blocks.{j}.1.weight_v"] = f"resblocks.{i}.resblocks.{j}.conv.weight_v"
            mapping[f"res_stack.{i}.conv_blocks.{j}.1.bias"] = f"resblocks.{i}.resblocks.{j}.conv.bias"

    # è®¾ç½®è¾“å‡ºå·ç§¯å±‚æƒé‡å’Œåç½®çš„æ˜ å°„å…³ç³»
    mapping["conv_post.1.weight_g"] = "conv_post.weight_g"
    mapping["conv_post.1.weight_v"] = "conv_post.weight_v"
    mapping["conv_post.1.bias"] = "conv_post.bias"

    # è¿”å›æ˜ å°„å­—å…¸
    return mapping
# å®šä¹‰å‡½æ•°ï¼Œç”¨äºä¿®æ”¹çŠ¶æ€å­—å…¸çš„é”®ï¼Œå¹¶ä¸”å¯ä»¥ç§»é™¤æŒ‡å®šçš„é”®
def rename_state_dict(state_dict, keys_to_modify, keys_to_remove):
    # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„æ¨¡å‹çŠ¶æ€å­—å…¸
    model_state_dict = {}
    # éå†åŸå§‹çŠ¶æ€å­—å…¸ä¸­çš„æ¯ä¸ªé”®å€¼å¯¹
    for key, value in state_dict.items():
        # å¦‚æœå½“å‰é”®åœ¨è¦ç§»é™¤çš„é”®é›†åˆä¸­ï¼Œåˆ™è·³è¿‡å¤„ç†
        if key in keys_to_remove:
            continue
        
        # å¦‚æœå½“å‰é”®åœ¨è¦ä¿®æ”¹çš„é”®æ˜ å°„ä¸­
        if key in keys_to_modify:
            # ä½¿ç”¨æ˜ å°„ä¸­çš„æ–°é”®åæ›¿æ¢å½“å‰é”®ï¼Œå¹¶å°†å¯¹åº”çš„å€¼å­˜å…¥æ¨¡å‹çŠ¶æ€å­—å…¸
            new_key = keys_to_modify[key]
            model_state_dict[new_key] = value
        else:
            # å¦åˆ™ç›´æ¥å°†å½“å‰é”®å€¼å¯¹å­˜å…¥æ¨¡å‹çŠ¶æ€å­—å…¸
            model_state_dict[key] = value
    
    # è¿”å›ä¿®æ”¹åçš„æ¨¡å‹çŠ¶æ€å­—å…¸
    return model_state_dict


def convert_univnet_checkpoint(
    checkpoint_path,
    pytorch_dump_folder_path,
    config_path=None,
    repo_id=None,
    safe_serialization=False,
):
    # ä½¿ç”¨ torch åŠ è½½æ¨¡å‹çš„çŠ¶æ€å­—å…¸ï¼ŒæŒ‡å®šåœ¨ CPU ä¸ŠåŠ è½½
    model_state_dict_base = torch.load(checkpoint_path, map_location="cpu")
    # è·å–ç”Ÿæˆå™¨çš„çŠ¶æ€å­—å…¸
    state_dict = model_state_dict_base["model_g"]

    # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä»é¢„è®­ç»ƒé…ç½®æ–‡ä»¶ä¸­åŠ è½½é…ç½®ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    if config_path is not None:
        config = UnivNetConfig.from_pretrained(config_path)
    else:
        config = UnivNetConfig()

    # è·å–éœ€è¦ä¿®æ”¹çš„é”®æ˜ å°„
    keys_to_modify = get_key_mapping(config)
    # åˆå§‹åŒ–è¦ç§»é™¤çš„é”®é›†åˆä¸ºç©º
    keys_to_remove = set()
    # ä½¿ç”¨å®šä¹‰çš„å‡½æ•°é‡å‘½åçŠ¶æ€å­—å…¸ä¸­çš„é”®ï¼Œå¹¶ä¸”åº”ç”¨ä¿®æ”¹åçš„æ˜ å°„
    hf_state_dict = rename_state_dict(state_dict, keys_to_modify, keys_to_remove)

    # åˆ›å»º UnivNetModel çš„å®ä¾‹
    model = UnivNetModel(config)
    # åº”ç”¨æƒé‡è§„èŒƒåŒ–ï¼Œå› ä¸ºåŸå§‹æ£€æŸ¥ç‚¹å·²åº”ç”¨æƒé‡è§„èŒƒåŒ–
    model.apply_weight_norm()
    # åŠ è½½ç»è¿‡é‡å‘½åçš„çŠ¶æ€å­—å…¸
    model.load_state_dict(hf_state_dict)
    # ç§»é™¤æƒé‡è§„èŒƒåŒ–ï¼Œä¸ºæ¨æ–­å‡†å¤‡
    model.remove_weight_norm()

    # å°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ï¼Œæ”¯æŒå®‰å…¨åºåˆ—åŒ–é€‰é¡¹
    model.save_pretrained(pytorch_dump_folder_path, safe_serialization=safe_serialization)

    # å¦‚æœæä¾›äº† repo_idï¼Œåˆ™æ¨é€æ¨¡å‹åˆ° hub
    if repo_id:
        print("Pushing to the hub...")
        model.push_to_hub(repo_id)


def main():
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser()
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°é€‰é¡¹
    parser.add_argument("--checkpoint_path", required=True, default=None, type=str, help="Path to original checkpoint")
    parser.add_argument("--config_path", default=None, type=str, help="Path to hf config.json of model to convert")
    parser.add_argument(
        "--pytorch_dump_folder_path", required=True, default=None, type=str, help="Path to the output PyTorch model."
    )
    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
    )
    parser.add_argument(
        "--safe_serialization", action="store_true", help="Whether to save the model using `safetensors`."
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()

    # è°ƒç”¨è½¬æ¢å‡½æ•°ï¼Œä¼ å…¥å‘½ä»¤è¡Œå‚æ•°è§£æå¾—åˆ°çš„å‚æ•°
    convert_univnet_checkpoint(
        args.checkpoint_path,
        args.pytorch_dump_folder_path,
        args.config_path,
        args.push_to_hub,
        args.safe_serialization,
    )


if __name__ == "__main__":
    main()
```