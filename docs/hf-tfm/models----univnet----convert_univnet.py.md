# `.\transformers\models\univnet\convert_univnet.py`

```
# å¼•å…¥ argparse åº“ï¼Œç”¨äºå¤„ç†å‘½ä»¤è¡Œå‚æ•°
import argparse

# å¼•å…¥ torch åº“
import torch

# ä» transformers åº“ä¸­å¼•å…¥ UnivNetConfig å’Œ UnivNetModel
from transformers import UnivNetConfig, UnivNetModel, logging

# è®¾ç½® logging çš„è¯¦ç»†ç¨‹åº¦ä¸º info
logging.set_verbosity_info()

# è·å–åä¸º "transformers.models.univnet" çš„ logger
logger = logging.get_logger("transformers.models.univnet")


# æ ¹æ®ç»™å®šçš„ config å’Œå‰ç¼€ï¼Œè¿”å›æ—§é”®å’Œæ–°é”®ä¹‹é—´çš„æ˜ å°„å…³ç³»
def get_kernel_predictor_key_mapping(config: UnivNetConfig, old_prefix: str = "", new_prefix: str = ""):
    mapping = {}
    # åˆå§‹å·ç§¯å±‚
    mapping[f"{old_prefix}.input_conv.0.weight_g"] = f"{new_prefix}.input_conv.weight_g"
    mapping[f"{old_prefix}.input_conv.0.weight_v"] = f"{new_prefix}.input_conv.weight_v"
    mapping[f"{old_prefix}.input_conv.0.bias"] = f"{new_prefix}.input_conv.bias"

    # æ ¸å¿ƒé¢„æµ‹å™¨çš„ ResNet å—
    for i in range(config.kernel_predictor_num_blocks):
        mapping[f"{old_prefix}.residual_convs.{i}.1.weight_g"] = f"{new_prefix}.resblocks.{i}.conv1.weight_g"
        mapping[f"{old_prefix}.residual_convs.{i}.1.weight_v"] = f"{new_prefix}.resblocks.{i}.conv1.weight_v"
        mapping[f"{old_prefix}.residual_convs.{i}.1.bias"] = f"{new_prefix}.resblocks.{i}.conv1.bias"

        mapping[f"{old_prefix}.residual_convs.{i}.3.weight_g"] = f"{new_prefix}.resblocks.{i}.conv2.weight_g"
        mapping[f"{old_prefix}.residual_convs.{i}.3.weight_v"] = f"{new_prefix}.resblocks.{i}.conv2.weight_v"
        mapping[f"{old_prefix}.residual_convs.{i}.3.bias"] = f"{new_prefix}.resblocks.{i}.conv2.bias"

    # æ ¸å¿ƒè¾“å‡ºå·ç§¯
    mapping[f"{old_prefix}.kernel_conv.weight_g"] = f"{new_prefix}.kernel_conv.weight_g"
    mapping[f"{old_prefix}.kernel_conv.weight_v"] = f"{new_prefix}.kernel_conv.weight_v"
    mapping[f"{old_prefix}.kernel_conv.bias"] = f"{new_prefix}.kernel_conv.bias"

    # åç½®è¾“å‡ºå·ç§¯
    mapping[f"{old_prefix}.bias_conv.weight_g"] = f"{new_prefix}.bias_conv.weight_g"
    mapping[f"{old_prefix}.bias_conv.weight_v"] = f"{new_prefix}.bias_conv.weight_v"
    mapping[f"{old_prefix}.bias_conv.bias"] = f"{new_prefix}.bias_conv.bias"

    return mapping


# æ ¹æ®ç»™å®šçš„ config è¿”å›é”®æ˜ å°„å…³ç³»
def get_key_mapping(config: UnivNetConfig):
    mapping = {}

    # æ³¨æ„ï¼šåˆå§‹å·ç§¯å±‚çš„é”®æ˜¯ç›¸åŒçš„

    # LVC å‰©ä½™å—
    # éå†æ¯ä¸ª resblock_stride_sizes ä¸­çš„å€¼
    for i in range(len(config.resblock_stride_sizes)):
        # LVCBlock çš„åˆå§‹ convt å±‚å‚æ•°æ˜ å°„
        mapping[f"res_stack.{i}.convt_pre.1.weight_g"] = f"resblocks.{i}.convt_pre.weight_g"
        mapping[f"res_stack.{i}.convt_pre.1.weight_v"] = f"resblocks.{i}.convt_pre.weight_v"
        mapping[f"res_stack.{i}.convt_pre.1.bias"] = f"resblocks.{i}.convt_pre.bias"

        # è·å– Kernel predictor çš„å‚æ•°æ˜ å°„
        kernel_predictor_mapping = get_kernel_predictor_key_mapping(
            config, old_prefix=f"res_stack.{i}.kernel_predictor", new_prefix=f"resblocks.{i}.kernel_predictor"
        )
        # æ›´æ–°å‚æ•°æ˜ å°„å­—å…¸
        mapping.update(kernel_predictor_mapping)

        # éå†æ¯ä¸ª LVC Residual block
        for j in range(len(config.resblock_dilation_sizes[i])):
            # è¿›è¡Œ conv_blocks çš„å‚æ•°æ˜ å°„
            mapping[f"res_stack.{i}.conv_blocks.{j}.1.weight_g"] = f"resblocks.{i}.resblocks.{j}.conv.weight_g"
            mapping[f"res_stack.{i}.conv_blocks.{j}.1.weight_v"] = f"resblocks.{i}.resblocks.{j}.conv.weight_v"
            mapping[f"res_stack.{i}.conv_blocks.{j}.1.bias"] = f"resblocks.{i}.resblocks.{j}.conv.bias"

    # è¾“å‡ºå±‚å‚æ•°çš„æ˜ å°„
    mapping["conv_post.1.weight_g"] = "conv_post.weight_g"
    mapping["conv_post.1.weight_v"] = "conv_post.weight_v"
    mapping["conv_post.1.bias"] = "conv_post.bias"

    # è¿”å›å‚æ•°æ˜ å°„å­—å…¸
    return mapping
# é‡å‘½åçŠ¶æ€å­—å…¸çš„é”®å¹¶ç§»é™¤æŒ‡å®šçš„é”®
def rename_state_dict(state_dict, keys_to_modify, keys_to_remove):
    model_state_dict = {}  # åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸ï¼Œç”¨äºå­˜å‚¨å¤„ç†åçš„çŠ¶æ€å­—å…¸
    for key, value in state_dict.items():  # éå†åŸçŠ¶æ€å­—å…¸çš„é”®å€¼å¯¹
        if key in keys_to_remove:  # å¦‚æœé”®åœ¨è¦ç§»é™¤çš„é”®åˆ—è¡¨ä¸­åˆ™è·³è¿‡å½“å‰å¾ªç¯
            continue

        if key in keys_to_modify:  # å¦‚æœé”®åœ¨è¦ä¿®æ”¹çš„é”®åˆ—è¡¨ä¸­
            new_key = keys_to_modify[key]  # è·å–æ–°çš„é”®å
            model_state_dict[new_key] = value  # å°†æ–°é”®åå’Œå¯¹åº”å€¼æ·»åŠ åˆ°æ–°çŠ¶æ€å­—å…¸ä¸­
        else:
            model_state_dict[key] = value  # å¦åˆ™å°†åŸé”®åå’Œå¯¹åº”å€¼æ·»åŠ åˆ°æ–°çŠ¶æ€å­—å…¸ä¸­
    return model_state_dict  # è¿”å›å¤„ç†åçš„çŠ¶æ€å­—å…¸


def convert_univnet_checkpoint(
    checkpoint_path,
    pytorch_dump_folder_path,
    config_path=None,
    repo_id=None,
    safe_serialization=False,
):
    model_state_dict_base = torch.load(checkpoint_path, map_location="cpu")  # åŠ è½½åŸå§‹æ£€æŸ¥ç‚¹çš„çŠ¶æ€å­—å…¸
    state_dict = model_state_dict_base["model_g"]  # è·å– generator çš„çŠ¶æ€å­—å…¸

    if config_path is not None:  # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶è·¯å¾„
        config = UnivNetConfig.from_pretrained(config_path)  # ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­åŠ è½½é…ç½®
    else:
        config = UnivNetConfig()  # å¦åˆ™ä½¿ç”¨é»˜è®¤é…ç½®

    keys_to_modify = get_key_mapping(config)  # è·å–é”®æ˜ å°„
    keys_to_remove = set()  # åˆ›å»ºä¸€ä¸ªç©ºçš„è¦ç§»é™¤çš„é”®çš„é›†åˆ
    hf_state_dict = rename_state_dict(state_dict, keys_to_modify, keys_to_remove)  # é‡å‘½åçŠ¶æ€å­—å…¸çš„é”®å¹¶ç§»é™¤æŒ‡å®šçš„é”®

    model = UnivNetModel(config)  # åˆ›å»ºæ¨¡å‹å¯¹è±¡
    model.apply_weight_norm()  # åº”ç”¨æƒé‡æ ‡å‡†åŒ–ï¼Œå› ä¸ºåŸå§‹æ£€æŸ¥ç‚¹å·²ç»åº”ç”¨äº†æƒé‡æ ‡å‡†åŒ–
    model.load_state_dict(hf_state_dict)  # åŠ è½½å¤„ç†åçš„çŠ¶æ€å­—å…¸
    model.remove_weight_norm()  # ç§»é™¤æƒé‡æ ‡å‡†åŒ–ï¼Œä¸ºè¿›è¡Œæ¨ç†åšå‡†å¤‡

    model.save_pretrained(pytorch_dump_folder_path, safe_serialization=safe_serialization)  # å°†è½¬æ¢åçš„æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ï¼Œå¹¶å¯é€‰æ‹©æ˜¯å¦ä½¿ç”¨å®‰å…¨åºåˆ—åŒ–

    if repo_id:  # å¦‚æœæä¾›äº† repo_id
        print("Pushing to the hub...")  # æ‰“å°æ¨é€åˆ° hub çš„æ¶ˆæ¯
        model.push_to_hub(repo_id)  # å°†æ¨¡å‹æ¨é€åˆ° hub


def main():
    parser = argparse.ArgumentParser()  # åˆ›å»ºå‚æ•°è§£æå™¨
    parser.add_argument("--checkpoint_path", required=True, default=None, type=str, help="Path to original checkpoint")  # æ·»åŠ åŸå§‹æ£€æŸ¥ç‚¹è·¯å¾„çš„å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument("--config_path", default=None, type=str, help="Path to hf config.json of model to convert")  # æ·»åŠ é…ç½®æ–‡ä»¶è·¯å¾„çš„å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument(
        "--pytorch_dump_folder_path", required=True, default=None, type=str, help="Path to the output PyTorch model."
    )  # æ·»åŠ è¾“å‡º PyTorch æ¨¡å‹è·¯å¾„çš„å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
    )  # æ·»åŠ åœ¨ ğŸ¤— hub ä¸Šä¸Šä¼ è½¬æ¢åçš„æ¨¡å‹çš„å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument(
        "--safe_serialization", action="store_true", help="Whether to save the model using `safetensors`."
    )  # æ·»åŠ æ˜¯å¦ä½¿ç”¨ 'safetensors' ä¿å­˜æ¨¡å‹çš„å‘½ä»¤è¡Œå‚æ•°

    args = parser.parse_args()  # è§£æå‘½ä»¤è¡Œå‚æ•°

    convert_univnet_checkpoint(  # è°ƒç”¨è½¬æ¢ UnivNet æ£€æŸ¥ç‚¹çš„å‡½æ•°
        args.checkpoint_path,  # åŸå§‹æ£€æŸ¥ç‚¹è·¯å¾„
        args.pytorch_dump_folder_path,  # è¾“å‡º PyTorch æ¨¡å‹è·¯å¾„
        args.config_path,  # é…ç½®æ–‡ä»¶è·¯å¾„
        args.push_to_hub,  # åœ¨ hub ä¸Šä¸Šä¼ çš„ä½ç½®
        args.safe_serialization,  # æ˜¯å¦ä½¿ç”¨å®‰å…¨åºåˆ—åŒ–
    )


if __name__ == "__main__":
    main()  # æ‰§è¡Œ main å‡½æ•°
```