# `.\models\pop2piano\tokenization_pop2piano.py`

```
# coding=utf-8
# Copyright 2023 The Pop2Piano Authors and The HuggingFace Inc. team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
Tokenization class for Pop2Piano.
"""

import json
import os
from typing import List, Optional, Tuple, Union

import numpy as np

from ...feature_extraction_utils import BatchFeature
from ...tokenization_utils import AddedToken, BatchEncoding, PaddingStrategy, PreTrainedTokenizer, TruncationStrategy
from ...utils import TensorType, is_pretty_midi_available, logging, requires_backends, to_numpy

if is_pretty_midi_available():
    import pretty_midi

logger = logging.get_logger(__name__)

# 定义词汇文件的名称，"vocab" 对应 "vocab.json"
VOCAB_FILES_NAMES = {
    "vocab": "vocab.json",
}

# 预训练模型所需的词汇文件映射
PRETRAINED_VOCAB_FILES_MAP = {
    "vocab": {
        "sweetcocoa/pop2piano": "https://huggingface.co/sweetcocoa/pop2piano/blob/main/vocab.json",
    },
}


def token_time_to_note(number, cutoff_time_idx, current_idx):
    """
    将时间令牌转换为音符索引。

    Args:
        number (int): 时间令牌的数量。
        cutoff_time_idx (int or None): 时间截止索引（可选）。
        current_idx (int): 当前索引位置。

    Returns:
        int: 更新后的当前索引位置。
    """
    current_idx += number
    if cutoff_time_idx is not None:
        current_idx = min(current_idx, cutoff_time_idx)

    return current_idx


def token_note_to_note(number, current_velocity, default_velocity, note_onsets_ready, current_idx, notes):
    """
    将音符令牌转换为音符。

    Args:
        number (int): 音符令牌的数量。
        current_velocity (int): 当前速度。
        default_velocity (int): 默认速度。
        note_onsets_ready (list or None): 准备好的音符发生时刻的列表或 None。
        current_idx (int): 当前索引位置。
        notes (list): 音符列表。

    Returns:
        list: 更新后的音符列表。
    """
    if note_onsets_ready[number] is not None:
        # 偏移与起始
        onset_idx = note_onsets_ready[number]
        if onset_idx < current_idx:
            # 前一个音符后的时间偏移
            offset_idx = current_idx
            notes.append([onset_idx, offset_idx, number, default_velocity])
            onsets_ready = None if current_velocity == 0 else current_idx
            note_onsets_ready[number] = onsets_ready
    else:
        note_onsets_ready[number] = current_idx
    return notes


class Pop2PianoTokenizer(PreTrainedTokenizer):
    """
    构造 Pop2Piano 分词器。此分词器不需要训练。

    Args:
        vocab (`str`): 包含词汇表的文件路径。
        default_velocity (`int`, *optional*, 默认为 77):
            创建 MIDI 音符时使用的默认速度。
        num_bars (`int`, *optional*, 默认为 2):
            每个令牌的截止时间索引。
    """

    model_input_names = ["token_ids", "attention_mask"]
    vocab_files_names = VOCAB_FILES_NAMES
    # 使用预训练的词汇文件映射
    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP

    def __init__(
        self,
        vocab,
        default_velocity=77,
        num_bars=2,
        unk_token="-1",
        eos_token="1",
        pad_token="0",
        bos_token="2",
        **kwargs,
    ):
        # 初始化未知标记
        unk_token = AddedToken(unk_token, lstrip=False, rstrip=False) if isinstance(unk_token, str) else unk_token
        # 初始化结束标记
        eos_token = AddedToken(eos_token, lstrip=False, rstrip=False) if isinstance(eos_token, str) else eos_token
        # 初始化填充标记
        pad_token = AddedToken(pad_token, lstrip=False, rstrip=False) if isinstance(pad_token, str) else pad_token
        # 初始化开始标记
        bos_token = AddedToken(bos_token, lstrip=False, rstrip=False) if isinstance(bos_token, str) else bos_token

        # 设置默认速度和小节数
        self.default_velocity = default_velocity
        self.num_bars = num_bars

        # 加载词汇表
        with open(vocab, "rb") as file:
            self.encoder = json.load(file)

        # 创建解码器的映射
        self.decoder = {v: k for k, v in self.encoder.items()}

        # 调用父类初始化方法
        super().__init__(
            unk_token=unk_token,
            eos_token=eos_token,
            pad_token=pad_token,
            bos_token=bos_token,
            **kwargs,
        )

    @property
    def vocab_size(self):
        """Returns the vocabulary size of the tokenizer."""
        # 返回词汇表大小
        return len(self.encoder)

    def get_vocab(self):
        """Returns the vocabulary of the tokenizer."""
        # 返回标记器的词汇表，包括新增的标记
        return dict(self.encoder, **self.added_tokens_encoder)

    def _convert_id_to_token(self, token_id: int) -> list:
        """
        Decodes the token ids generated by the transformer into notes.

        Args:
            token_id (`int`):
                This denotes the ids generated by the transformers to be converted to Midi tokens.

        Returns:
            `List`: A list consists of token_type (`str`) and value (`int`).
        """
        # 将转换器生成的标记 ID 解码为音符
        token_type_value = self.decoder.get(token_id, f"{self.unk_token}_TOKEN_TIME")
        token_type_value = token_type_value.split("_")
        token_type, value = "_".join(token_type_value[1:]), int(token_type_value[0])

        return [token_type, value]

    def _convert_token_to_id(self, token, token_type="TOKEN_TIME") -> int:
        """
        Encodes the Midi tokens to transformer generated token ids.

        Args:
            token (`int`):
                This denotes the token value.
            token_type (`str`):
                This denotes the type of the token. There are four types of midi tokens such as "TOKEN_TIME",
                "TOKEN_VELOCITY", "TOKEN_NOTE" and "TOKEN_SPECIAL".

        Returns:
            `int`: returns the id of the token.
        """
        # 将 Midi 标记编码为转换器生成的标记 ID
        return self.encoder.get(f"{token}_{token_type}", int(self.unk_token))

    def relative_batch_tokens_ids_to_notes(
        self,
        tokens: np.ndarray,
        beat_offset_idx: int,
        bars_per_batch: int,
        cutoff_time_idx: int,
    ):
        """
        Converts relative tokens to notes which are then used to generate pretty midi object.

        Args:
            tokens (`numpy.ndarray`):
                Tokens to be converted to notes.
            beat_offset_idx (`int`):
                Denotes beat offset index for each note in generated Midi.
            bars_per_batch (`int`):
                A parameter to control the Midi output generation.
            cutoff_time_idx (`int`):
                Denotes the cutoff time index for each note in generated Midi.
        """

        # Initialize notes to None
        notes = None

        # Iterate through each index in tokens
        for index in range(len(tokens)):
            # Fetch tokens for the current index
            _tokens = tokens[index]
            # Calculate start index for the current batch
            _start_idx = beat_offset_idx + index * bars_per_batch * 4
            # Calculate cutoff time index for the current batch
            _cutoff_time_idx = cutoff_time_idx + _start_idx
            # Convert relative tokens to notes using specified indices
            _notes = self.relative_tokens_ids_to_notes(
                _tokens,
                start_idx=_start_idx,
                cutoff_time_idx=_cutoff_time_idx,
            )

            # Check if _notes is empty
            if len(_notes) == 0:
                pass
            # If notes is None, assign _notes; otherwise concatenate to existing notes
            elif notes is None:
                notes = _notes
            else:
                notes = np.concatenate((notes, _notes), axis=0)

        # If notes is still None, return an empty list; otherwise, return notes
        if notes is None:
            return []
        return notes

    def relative_batch_tokens_ids_to_midi(
        self,
        tokens: np.ndarray,
        beatstep: np.ndarray,
        beat_offset_idx: int = 0,
        bars_per_batch: int = 2,
        cutoff_time_idx: int = 12,
    ):
        """
        Converts tokens to Midi. This method calls `relative_batch_tokens_ids_to_notes` method to convert batch tokens
        to notes then uses `notes_to_midi` method to convert them to Midi.

        Args:
            tokens (`numpy.ndarray`):
                Denotes tokens which alongside beatstep will be converted to Midi.
            beatstep (`np.ndarray`):
                We get beatstep from feature extractor which is also used to get Midi.
            beat_offset_idx (`int`, *optional*, defaults to 0):
                Denotes beat offset index for each note in generated Midi.
            bars_per_batch (`int`, *optional*, defaults to 2):
                A parameter to control the Midi output generation.
            cutoff_time_idx (`int`, *optional*, defaults to 12):
                Denotes the cutoff time index for each note in generated Midi.
        """
        # Set beat_offset_idx to 0 if it's None
        beat_offset_idx = 0 if beat_offset_idx is None else beat_offset_idx
        # Convert tokens to notes using relative_batch_tokens_ids_to_notes method
        notes = self.relative_batch_tokens_ids_to_notes(
            tokens=tokens,
            beat_offset_idx=beat_offset_idx,
            bars_per_batch=bars_per_batch,
            cutoff_time_idx=cutoff_time_idx,
        )
        # Convert notes to Midi using notes_to_midi method
        midi = self.notes_to_midi(notes, beatstep, offset_sec=beatstep[beat_offset_idx])
        return midi

    # Taken from the original code
    # Please see https://github.com/sweetcocoa/pop2piano/blob/fac11e8dcfc73487513f4588e8d0c22a22f2fdc5/midi_tokenizer.py#L257
    def relative_tokens_ids_to_notes(self, tokens: np.ndarray, start_idx: float, cutoff_time_idx: float = None):
        """
        Converts relative tokens to notes which will then be used to create Pretty Midi objects.

        Args:
            tokens (`numpy.ndarray`):
                Relative Tokens which will be converted to notes.
            start_idx (`float`):
                A parameter which denotes the starting index.
            cutoff_time_idx (`float`, *optional*):
                A parameter used while converting tokens to notes.
        """
        # 将 tokens 转换为对应的词汇列表
        words = [self._convert_id_to_token(token) for token in tokens]

        # 初始化当前索引和当前速度
        current_idx = start_idx
        current_velocity = 0

        # 准备音符的起始时间列表，根据已定义的音符种类数量动态生成
        note_onsets_ready = [None for i in range(sum([k.endswith("NOTE") for k in self.encoder.keys()]) + 1)]
        notes = []

        # 遍历 tokens 对应的词汇列表
        for token_type, number in words:
            # 处理特殊 token
            if token_type == "TOKEN_SPECIAL":
                if number == 1:
                    break

            # 处理时间 token
            elif token_type == "TOKEN_TIME":
                current_idx = token_time_to_note(
                    number=number, cutoff_time_idx=cutoff_time_idx, current_idx=current_idx
                )

            # 处理速度 token
            elif token_type == "TOKEN_VELOCITY":
                current_velocity = number

            # 处理音符 token
            elif token_type == "TOKEN_NOTE":
                notes = token_note_to_note(
                    number=number,
                    current_velocity=current_velocity,
                    default_velocity=self.default_velocity,
                    note_onsets_ready=note_onsets_ready,
                    current_idx=current_idx,
                    notes=notes,
                )

            else:
                # 抛出异常，未知的 token 类型
                raise ValueError("Token type not understood!")

        # 对于每个音高和其对应的音符起始时间，若起始时间未定义，则强制定义一个偏移量
        for pitch, note_onset in enumerate(note_onsets_ready):
            if note_onset is not None:
                if cutoff_time_idx is None:
                    cutoff = note_onset + 1
                else:
                    cutoff = max(cutoff_time_idx, note_onset + 1)

                offset_idx = max(current_idx, cutoff)
                notes.append([note_onset, offset_idx, pitch, self.default_velocity])

        # 若 notes 为空则返回空列表，否则对 notes 按照音符起始时间排序并返回
        if len(notes) == 0:
            return []
        else:
            notes = np.array(notes)
            note_order = notes[:, 0] * 128 + notes[:, 1]
            notes = notes[note_order.argsort()]
            return notes
    def notes_to_midi(self, notes: np.ndarray, beatstep: np.ndarray, offset_sec: int = 0.0):
        """
        Converts notes to Midi.

        Args:
            notes (`numpy.ndarray`):
                This is used to create Pretty Midi objects.
            beatstep (`numpy.ndarray`):
                This is the extrapolated beatstep that we get from feature extractor.
            offset_sec (`int`, *optional*, defaults to 0.0):
                This represents the offset seconds which is used while creating each Pretty Midi Note.
        """

        # 检查是否需要 Pretty MIDI 后端支持
        requires_backends(self, ["pretty_midi"])

        # 创建一个新的 PrettyMIDI 对象，设置分辨率为384，初始节奏为120.0 BPM
        new_pm = pretty_midi.PrettyMIDI(resolution=384, initial_tempo=120.0)
        
        # 创建一个新的乐器对象，使用默认音色（program=0）
        new_inst = pretty_midi.Instrument(program=0)
        
        # 存储新创建的音符对象的列表
        new_notes = []

        # 遍历输入的音符数组，并创建相应的 Pretty MIDI 音符对象
        for onset_idx, offset_idx, pitch, velocity in notes:
            # 创建一个新的音符对象
            new_note = pretty_midi.Note(
                velocity=velocity,
                pitch=pitch,
                start=beatstep[onset_idx] - offset_sec,
                end=beatstep[offset_idx] - offset_sec,
            )
            # 将新创建的音符对象添加到列表中
            new_notes.append(new_note)
        
        # 将新创建的音符列表设置为乐器对象的音符列表
        new_inst.notes = new_notes
        
        # 将乐器对象添加到 PrettyMIDI 对象中
        new_pm.instruments.append(new_inst)
        
        # 删除无效的音符（例如持续时间为0的音符）
        new_pm.remove_invalid_notes()
        
        # 返回创建的 PrettyMIDI 对象
        return new_pm

    def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = None) -> Tuple[str]:
        """
        Saves the tokenizer's vocabulary dictionary to the provided save_directory.

        Args:
            save_directory (`str`):
                A path to the directory where to saved. It will be created if it doesn't exist.
            filename_prefix (`Optional[str]`, *optional*):
                A prefix to add to the names of the files saved by the tokenizer.
        """
        # 检查保存目录是否存在，如果不存在则记录错误并返回
        if not os.path.isdir(save_directory):
            logger.error(f"Vocabulary path ({save_directory}) should be a directory")
            return

        # 构建要保存的词汇文件的完整路径
        out_vocab_file = os.path.join(
            save_directory, (filename_prefix + "-" if filename_prefix else "") + VOCAB_FILES_NAMES["vocab"]
        )
        
        # 将编码器的词汇表以 JSON 格式写入到文件中
        with open(out_vocab_file, "w") as file:
            file.write(json.dumps(self.encoder))

        # 返回保存的文件路径的元组形式
        return (out_vocab_file,)

    def encode_plus(
        self,
        notes: Union[np.ndarray, List[pretty_midi.Note]],
        truncation_strategy: Optional[TruncationStrategy] = None,
        max_length: Optional[int] = None,
        **kwargs,
    ):
        """
        Placeholder function for encoding notes into a format suitable for model input.
        This is meant to be overridden by subclasses.
        """
        # 此方法用于将音符编码为模型输入格式，应由子类重写具体实现
        pass

    def batch_encode_plus(
        self,
        notes: Union[np.ndarray, List[pretty_midi.Note]],
        truncation_strategy: Optional[TruncationStrategy] = None,
        max_length: Optional[int] = None,
        **kwargs,
    ):
        """
        Placeholder function for batch encoding notes into a format suitable for model input.
        This is meant to be overridden by subclasses.
        """
        # 此方法用于批量将音符编码为模型输入格式，应由子类重写具体实现
        pass
    ) -> BatchEncoding:
        r"""
        This is the `batch_encode_plus` method for `Pop2PianoTokenizer`. It converts the midi notes to the transformer
        generated token ids. It works on multiple batches by calling `encode_plus` multiple times in a loop.

        Args:
            notes (`numpy.ndarray` of shape `[batch_size, sequence_length, 4]` or `list` of `pretty_midi.Note` objects):
                This represents the midi notes. If `notes` is a `numpy.ndarray`:
                    - Each sequence must have 4 values, they are `onset idx`, `offset idx`, `pitch` and `velocity`.
                If `notes` is a `list` containing `pretty_midi.Note` objects:
                    - Each sequence must have 4 attributes, they are `start`, `end`, `pitch` and `velocity`.
            truncation_strategy ([`~tokenization_utils_base.TruncationStrategy`], *optional*):
                Indicates the truncation strategy that is going to be used during truncation.
            max_length (`int`, *optional*):
                Maximum length of the returned list and optionally padding length (see above).

        Returns:
            `BatchEncoding` containing the tokens ids.
        """

        encoded_batch_token_ids = []
        for i in range(len(notes)):
            encoded_batch_token_ids.append(
                # Call the `encode_plus` method to convert each batch of midi notes into token ids
                self.encode_plus(
                    notes[i],  # Pass each batch of midi notes to the `encode_plus` method
                    truncation_strategy=truncation_strategy,  # Specify the truncation strategy
                    max_length=max_length,  # Specify the maximum length for padding/truncation
                    **kwargs,  # Additional keyword arguments
                )["token_ids"]  # Retrieve the token ids from the returned BatchEncoding
            )

        return BatchEncoding({"token_ids": encoded_batch_token_ids})  # Return BatchEncoding containing token ids

    def __call__(
        self,
        notes: Union[
            np.ndarray,
            List[pretty_midi.Note],
            List[List[pretty_midi.Note]],
        ],
        padding: Union[bool, str, PaddingStrategy] = False,
        truncation: Union[bool, str, TruncationStrategy] = None,
        max_length: Optional[int] = None,
        pad_to_multiple_of: Optional[int] = None,
        return_attention_mask: Optional[bool] = None,
        return_tensors: Optional[Union[str, TensorType]] = None,
        verbose: bool = True,
        **kwargs,
    ):
        """
        This method allows the tokenizer object to be called as a function, enabling batch encoding of midi notes.

        Args:
            notes (Union[np.ndarray, List[pretty_midi.Note], List[List[pretty_midi.Note]]]):
                Midi notes to be tokenized. Can be a numpy array or a nested list of pretty_midi.Note objects.
            padding (Union[bool, str, PaddingStrategy], optional): Whether to pad sequences to the same length. Defaults to False.
            truncation (Union[bool, str, TruncationStrategy], optional): Truncation strategy for sequences longer than `max_length`. Defaults to None.
            max_length (int, optional): Maximum length of the returned sequences after padding/truncation. Defaults to None.
            pad_to_multiple_of (int, optional): Pad the sequence length to a multiple of this value. Defaults to None.
            return_attention_mask (bool, optional): Whether to return attention masks. Defaults to None.
            return_tensors (Union[str, TensorType], optional): Return tensors format. Defaults to None.
            verbose (bool, optional): Whether to print information about encoding. Defaults to True.
            **kwargs: Additional keyword arguments passed to `encode_plus`.

        Returns:
            BatchEncoding: Contains token ids and optionally attention masks and tensor format.
        """
        # Code for __call__ method implementation goes here
        pass

    def batch_decode(
        self,
        token_ids,
        feature_extractor_output: BatchFeature,
        return_midi: bool = True,
        **kwargs,
    ):
        """
        This method decodes a batch of token ids back into MIDI representation.

        Args:
            token_ids (list): List of token ids to be decoded.
            feature_extractor_output (BatchFeature): Output from feature extractor.
            return_midi (bool, optional): Whether to return MIDI objects. Defaults to True.
            **kwargs: Additional keyword arguments.

        Returns:
            Dependent on `return_midi`, returns MIDI objects or other format as specified.
        """
        # Code for batch_decode method implementation goes here
        pass
```