# `.\transformers\models\timesformer\convert_timesformer_to_pytorch.py`

```py
# è®¾ç½®è„šæœ¬æ–‡ä»¶çš„ç¼–ç æ ¼å¼ä¸º UTF-8
# ç‰ˆæƒå£°æ˜
# ä¾æ® Apache License, Version 2.0 è®¸å¯è¯ï¼Œé™¤éç¬¦åˆè®¸å¯è¯è¦æ±‚ï¼Œå¦åˆ™æ‚¨ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶
# æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹é“¾æ¥è·å–è®¸å¯è¯çš„å‰¯æœ¬
#     http://www.apache.org/licenses/LICENSE-2.0
# é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æ˜¯åŸºäºâ€œæŒ‰åŸæ ·â€åŸºç¡€åˆ†å‘çš„ï¼Œæ²¡æœ‰ä»»ä½•å½¢å¼çš„ä¿è¯æˆ–æ¡ä»¶ï¼Œæ— è®ºæ˜¯æ˜ç¤ºçš„è¿˜æ˜¯æš—ç¤ºçš„
# è¯·å‚è§è®¸å¯è¯ä»¥è·å–ç‰¹å®šè¯­è¨€è§„å®šçš„æƒé™å’Œé™åˆ¶

# å¯¼å…¥æ‰€éœ€çš„åº“
import argparse  # ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°
import json  # ç”¨äºå¤„ç† JSON æ ¼å¼çš„æ•°æ®

import gdown  # ç”¨äºä» Google Drive ä¸‹è½½æ–‡ä»¶
import numpy as np  # ç”¨äºè¿›è¡Œæ•°å€¼è®¡ç®—
import torch  # ç”¨äºæ„å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹
from huggingface_hub import hf_hub_download  # ä» Hugging Face Hub ä¸‹è½½æ–‡ä»¶

from transformers import TimesformerConfig, TimesformerForVideoClassification, VideoMAEImageProcessor  # å¯¼å…¥æ·±åº¦å­¦ä¹ æ¨¡å‹ç›¸å…³çš„ç±»


# è·å– TimeSformer æ¨¡å‹çš„é…ç½®ä¿¡æ¯
def get_timesformer_config(model_name):
    # åˆ›å»ºä¸€ä¸ª TimeSformer çš„é…ç½®å¯¹è±¡
    config = TimesformerConfig()

    # å¦‚æœæ¨¡å‹åç§°ä¸­åŒ…å« "large"ï¼Œåˆ™è®¾ç½® num_frames ä¸º 96
    if "large" in model_name:
        config.num_frames = 96

    # å¦‚æœæ¨¡å‹åç§°ä¸­åŒ…å« "hr"ï¼Œåˆ™è®¾ç½® num_frames ä¸º 16ï¼Œimage_size ä¸º 448
    if "hr" in model_name:
        config.num_frames = 16
        config.image_size = 448

    # æ ¹æ®æ¨¡å‹åç§°è®¾ç½®ä¸åŒçš„ num_labels å’ŒåŠ è½½å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
    repo_id = "huggingface/label-files"
    if "k400" in model_name:
        config.num_labels = 400
        filename = "kinetics400-id2label.json"
    elif "k600" in model_name:
        config.num_labels = 600
        filename = "kinetics600-id2label.json"
    elif "ssv2" in model_name:
        config.num_labels = 174
        filename = "something-something-v2-id2label.json"
    else:
        raise ValueError("Model name should either contain 'k400', 'k600' or 'ssv2'.")

    # åŠ è½½ id åˆ° label çš„æ˜ å°„å…³ç³»ï¼Œå¹¶è½¬æ¢ä¸ºå­—å…¸
    id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type="dataset"), "r"))
    id2label = {int(k): v for k, v in id2label.items()}
    config.id2label = id2label
    config.label2id = {v: k for k, v in id2label.items()}

    return config


# é‡å‘½åæ¨¡å‹ä¸­çš„ key
def rename_key(name):
    if "encoder." in name:
        name = name.replace("encoder.", "")
    if "cls_token" in name:
        name = name.replace("cls_token", "timesformer.embeddings.cls_token")
    if "pos_embed" in name:
        name = name.replace("pos_embed", "timesformer.embeddings.position_embeddings")
    if "time_embed" in name:
        name = name.replace("time_embed", "timesformer.embeddings.time_embeddings")
    if "patch_embed.proj" in name:
        name = name.replace("patch_embed.proj", "timesformer.embeddings.patch_embeddings.projection")
    if "patch_embed.norm" in name:
        name = name.replace("patch_embed.norm", "timesformer.embeddings.norm")
    if "blocks" in name:
        name = name.replace("blocks", "timesformer.encoder.layer")
    if "attn.proj" in name:
        name = name.replace("attn.proj", "attention.output.dense")
    if "attn" in name and "bias" not in name and "temporal" not in name:
        name = name.replace("attn", "attention.self")
    if "attn" in name and "temporal" not in name:
        name = name.replace("attn", "attention.attention")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "temporal_norm1"ï¼Œåˆ™æ›¿æ¢ä¸º "temporal_layernorm"
    if "temporal_norm1" in name:
        name = name.replace("temporal_norm1", "temporal_layernorm")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "temporal_attn.proj"ï¼Œåˆ™æ›¿æ¢ä¸º "temporal_attention.output.dense"
    if "temporal_attn.proj" in name:
        name = name.replace("temporal_attn", "temporal_attention.output.dense")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "temporal_fc"ï¼Œåˆ™æ›¿æ¢ä¸º "temporal_dense"
    if "temporal_fc" in name:
        name = name.replace("temporal_fc", "temporal_dense")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "norm1" ä½†ä¸åŒ…å« "temporal"ï¼Œåˆ™æ›¿æ¢ä¸º "layernorm_before"
    if "norm1" in name and "temporal" not in name:
        name = name.replace("norm1", "layernorm_before")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "norm2"ï¼Œåˆ™æ›¿æ¢ä¸º "layernorm_after"
    if "norm2" in name:
        name = name.replace("norm2", "layernorm_after")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "mlp.fc1"ï¼Œåˆ™æ›¿æ¢ä¸º "intermediate.dense"
    if "mlp.fc1" in name:
        name = name.replace("mlp.fc1", "intermediate.dense")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "mlp.fc2"ï¼Œåˆ™æ›¿æ¢ä¸º "output.dense"
    if "mlp.fc2" in name:
        name = name.replace("mlp.fc2", "output.dense")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "norm.weight"ï¼Œä¸”ä¸åŒ…å« "fc" å’Œ "temporal"ï¼Œåˆ™æ›¿æ¢ä¸º "timesformer.layernorm.weight"
    if "norm.weight" in name and "fc" not in name and "temporal" not in name:
        name = name.replace("norm.weight", "timesformer.layernorm.weight")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "norm.bias"ï¼Œä¸”ä¸åŒ…å« "fc" å’Œ "temporal"ï¼Œåˆ™æ›¿æ¢ä¸º "timesformer.layernorm.bias"
    if "norm.bias" in name and "fc" not in name and "temporal" not in name:
        name = name.replace("norm.bias", "timesformer.layernorm.bias")
    # å¦‚æœæ–‡ä»¶åä¸­åŒ…å« "head"ï¼Œåˆ™æ›¿æ¢ä¸º "classifier"
    if "head" in name:
        name = name.replace("head", "classifier")

    # è¿”å›æ›¿æ¢åçš„æ–‡ä»¶å
    return name
``` 
# å°†ç»™å®šçš„ state_dict è½¬æ¢ä¸ºé€‚åˆç‰¹å®šæ¨¡å‹é…ç½®çš„æ–° state_dict
def convert_state_dict(orig_state_dict, config):
    # ä½¿ç”¨ .copy() å¤åˆ¶åŸå§‹ state_dict çš„é”®åˆ—è¡¨ï¼Œä»¥ä¾¿åœ¨è¿­ä»£æ—¶ä¿®æ”¹åŸå§‹ state_dict
    for key in orig_state_dict.copy().keys():
        # å¼¹å‡ºå½“å‰é”®å¯¹åº”çš„å€¼ï¼Œä»åŸå§‹ state_dict ä¸­åˆ é™¤è¯¥é”®
        val = orig_state_dict.pop(key)

        # æ£€æŸ¥é”®æ˜¯å¦ä»¥ "model." å¼€å¤´ï¼Œè‹¥æ˜¯åˆ™å»é™¤è¯¥å‰ç¼€
        if key.startswith("model."):
            key = key.replace("model.", "")

        # æ£€æŸ¥é”®ä¸­æ˜¯å¦åŒ…å« "qkv"ï¼Œå¦‚æœåŒ…å«ï¼Œåˆ™è¿›è¡Œç‰¹å®šå¤„ç†
        if "qkv" in key:
            # æ‹†åˆ†é”®åï¼Œæå–å±‚ç¼–å·
            key_split = key.split(".")
            layer_num = int(key_split[1])
            prefix = "timesformer.encoder.layer."
            
            # æ ¹æ®é”®ä¸­æ˜¯å¦åŒ…å« "temporal" æ„å»ºåç¼€
            if "temporal" in key:
                postfix = ".temporal_attention.attention.qkv."
            else:
                postfix = ".attention.attention.qkv."

            # æ ¹æ®é”®ä¸­æ˜¯å¦åŒ…å« "weight" å†³å®šæ–°é”®çš„æ ¼å¼ï¼Œå¹¶èµ‹å€¼
            if "weight" in key:
                orig_state_dict[f"{prefix}{layer_num}{postfix}weight"] = val
            else:
                orig_state_dict[f"{prefix}{layer_num}{postfix}bias"] = val
        else:
            # å¯¹äºå…¶ä»–é”®ï¼Œåº”ç”¨é‡å‘½åå‡½æ•°å¹¶æ›´æ–° state_dict
            orig_state_dict[rename_key(key)] = val

    # è¿”å›è½¬æ¢åçš„ state_dict
    return orig_state_dict


# å‡†å¤‡è§†é¢‘æ•°æ®ä»¥ä¾›æ¨¡å‹éªŒè¯
# æˆ‘ä»¬å°†ä½¿ç”¨åƒæ„å¤§åˆ©é¢çš„è§†é¢‘è¿›è¡ŒéªŒè¯
# ä½¿ç”¨çš„å¸§ç´¢å¼•ï¼š[164 168 172 176 181 185 189 193 198 202 206 210 215 219 223 227]
def prepare_video():
    # ä» HF Hub ä¸‹è½½æ•°æ®é›†ï¼Œæ­¤å¤„æ˜¯åƒæ„å¤§åˆ©é¢è§†é¢‘çš„ numpy æ•°æ®
    file = hf_hub_download(
        repo_id="hf-internal-testing/spaghetti-video", filename="eating_spaghetti.npy", repo_type="dataset"
    )
    # åŠ è½½è§†é¢‘æ•°æ®
    video = np.load(file)
    return list(video)


# å°† Timesformer æ¨¡å‹çš„æ£€æŸ¥ç‚¹è½¬æ¢ä¸º PyTorch æ¨¡å‹çš„æƒé‡
def convert_timesformer_checkpoint(checkpoint_url, pytorch_dump_folder_path, model_name, push_to_hub):
    # è·å–ç‰¹å®šæ¨¡å‹é…ç½®
    config = get_timesformer_config(model_name)

    # åˆ›å»º Timesformer æ¨¡å‹
    model = TimesformerForVideoClassification(config)

    # ä¸‹è½½åŸå§‹æ£€æŸ¥ç‚¹ï¼Œè¯¥æ£€æŸ¥ç‚¹æ‰˜ç®¡åœ¨ Google Drive ä¸Š
    output = "pytorch_model.bin"
    gdown.cached_download(checkpoint_url, output, quiet=False)
    # åŠ è½½æ£€æŸ¥ç‚¹æ–‡ä»¶å¹¶å¤„ç† state_dict
    files = torch.load(output, map_location="cpu")
    if "model" in files:
        state_dict = files["model"]
    elif "module" in files:
        state_dict = files["module"]
    else:
        state_dict = files["model_state"]
    new_state_dict = convert_state_dict(state_dict, config)

    # åŠ è½½æ¨¡å‹æƒé‡
    model.load_state_dict(new_state_dict)
    model.eval()

    # åˆ›å»ºè§†é¢‘å¤„ç†å™¨ï¼Œå¤„ç†æ¨¡å‹è¾“å…¥æ•°æ®
    image_processor = VideoMAEImageProcessor(image_mean=[0.5, 0.5, 0.5], image_std=[0.5, 0.5, 0.5])
    # å‡†å¤‡è§†é¢‘æ•°æ®
    video = prepare_video()
    # å¤„ç†è§†é¢‘æ•°æ®ï¼Œå‡†å¤‡æ¨¡å‹è¾“å…¥
    inputs = image_processor(video[:8], return_tensors="pt")

    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†
    outputs = model(**inputs)
    logits = outputs.logits

    # å®šä¹‰æ¨¡å‹åç§°åˆ—è¡¨ï¼ŒåŒ…å«äº†ä¸åŒæ•°æ®é›†è®­ç»ƒçš„ Timesformer æ¨¡å‹åç§°
    model_names = [
        "timesformer-base-finetuned-k400",
        "timesformer-large-finetuned-k400",
        "timesformer-hr-finetuned-k400",
        "timesformer-base-finetuned-k600",
        "timesformer-large-finetuned-k600",
        "timesformer-hr-finetuned-k600",
        "timesformer-base-finetuned-ssv2",
        "timesformer-large-finetuned-ssv2",
        "timesformer-hr-finetuned-ssv2",
    ]

    # æ³¨æ„ï¼šlogits ä½¿ç”¨å›¾åƒå‡å€¼å’Œæ ‡å‡†å·®ä¸º [0.5, 0.5, 0.5] çš„æƒ…å†µè¿›è¡Œäº†æµ‹è¯•
    # å¦‚æœæ¨¡å‹åä¸ºæŒ‡å®šçš„å€¼ï¼Œåˆ™è®¾ç½®æœŸæœ›å½¢çŠ¶å’Œåˆ‡ç‰‡
    if model_name == "timesformer-base-finetuned-k400":
        expected_shape = torch.Size([1, 400])
        expected_slice = torch.tensor([-0.3016, -0.7713, -0.4205])
    elif model_name == "timesformer-base-finetuned-k600":
        expected_shape = torch.Size([1, 600])
        expected_slice = torch.tensor([-0.7267, -0.7466, 3.2404])
    elif model_name == "timesformer-base-finetuned-ssv2":
        expected_shape = torch.Size([1, 174])
        expected_slice = torch.tensor([-0.9059, 0.6433, -3.1457])
    elif model_name == "timesformer-large-finetuned-k400":
        expected_shape = torch.Size([1, 400])
        expected_slice = torch.tensor([0, 0, 0])
    elif model_name == "timesformer-large-finetuned-k600":
        expected_shape = torch.Size([1, 600])
        expected_slice = torch.tensor([0, 0, 0])
    elif model_name == "timesformer-large-finetuned-ssv2":
        expected_shape = torch.Size([1, 174])
        expected_slice = torch.tensor([0, 0, 0])
    elif model_name == "timesformer-hr-finetuned-k400":
        expected_shape = torch.Size([1, 400])
        expected_slice = torch.tensor([-0.9617, -3.7311, -3.7708])
    elif model_name == "timesformer-hr-finetuned-k600":
        expected_shape = torch.Size([1, 600])
        expected_slice = torch.tensor([2.5273, 0.7127, 1.8848])
    elif model_name == "timesformer-hr-finetuned-ssv2":
        expected_shape = torch.Size([1, 174])
        expected_slice = torch.tensor([-3.6756, -0.7513, 0.7180])
    else:
        raise ValueError(f"Model name not supported. Should be one of {model_names}")
    
    # æ ¡éªŒlogits
    assert logits.shape == expected_shape
    assert torch.allclose(logits[0, :3], expected_slice, atol=1e-4)
    print("Logits ok!")
    
    # å¦‚æœpytorch_dump_folder_pathä¸ä¸ºç©ºï¼Œåˆ™ä¿å­˜æ¨¡å‹å’Œå›¾åƒå¤„ç†å™¨
    if pytorch_dump_folder_path is not None:
        print(f"Saving model and image processor to {pytorch_dump_folder_path}")
        image_processor.save_pretrained(pytorch_dump_folder_path)
        model.save_pretrained(pytorch_dump_folder_path)
    
    # å¦‚æœpush_to_hubä¸ºTrueï¼Œåˆ™æ¨é€åˆ°hub
    if push_to_hub:
        print("Pushing to the hub...")
        model.push_to_hub(f"fcakyon/{model_name}")
# æ£€æŸ¥å½“å‰æ¨¡å—æ˜¯å¦ä½œä¸ºä¸»ç¨‹åºè¿è¡Œ
if __name__ == "__main__":
    # åˆ›å»ºä¸€ä¸ªå‚æ•°è§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser()
    # æ·»åŠ å¿…éœ€çš„å‚æ•°
    parser.add_argument(
        "--checkpoint_url",
        default="https://drive.google.com/u/1/uc?id=17yvuYp9L4mn-HpIcK5Zo6K3UoOy1kA5l&export=download",
        type=str,
        help=(
            "URL of the original PyTorch checkpoint (on Google Drive) you'd like to convert. Should be a direct"
            " download link."
        ),
    )
    parser.add_argument(
        "--pytorch_dump_folder_path",
        default="",
        type=str,
        help="Path to the output PyTorch model directory.",
    )
    parser.add_argument("--model_name", default="timesformer-base-finetuned-k400", type=str, help="Name of the model.")
    parser.add_argument(
        "--push_to_hub", action="store_true", help="Whether or not to push the converted model to the ğŸ¤— hub."
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    # è°ƒç”¨å‡½æ•°å°† TimesFormer æ¨¡å‹æ£€æŸ¥ç‚¹è½¬æ¢ä¸º PyTorch æ¨¡å‹
    convert_timesformer_checkpoint(
        args.checkpoint_url, args.pytorch_dump_folder_path, args.model_name, args.push_to_hub
    )
```