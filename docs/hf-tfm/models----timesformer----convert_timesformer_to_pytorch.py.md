# `.\models\timesformer\convert_timesformer_to_pytorch.py`

```
# è®¾ç½®ç¼–ç æ ¼å¼ä¸º UTF-8
# ç‰ˆæƒå£°æ˜åŠè®¸å¯ä¿¡æ¯ï¼ŒæŒ‡æ˜ä»£ç ä½¿ç”¨çš„è®¸å¯åè®®å’Œç‰ˆæƒå½’å±
# å¯¼å…¥è½¬æ¢ TimeSformer æ£€æŸ¥ç‚¹æ‰€éœ€çš„åº“å’Œæ¨¡å—

import argparse  # å¯¼å…¥ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°çš„åº“
import json  # å¯¼å…¥å¤„ç† JSON æ ¼å¼æ•°æ®çš„åº“

import gdown  # å¯¼å…¥ç”¨äºä» Google Drive ä¸‹è½½æ–‡ä»¶çš„åº“
import numpy as np  # å¯¼å…¥å¤„ç†æ•°å€¼å’Œæ•°ç»„çš„åº“
import torch  # å¯¼å…¥ PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
from huggingface_hub import hf_hub_download  # å¯¼å…¥ä» Hugging Face Hub ä¸‹è½½èµ„æºçš„å‡½æ•°

from transformers import TimesformerConfig, TimesformerForVideoClassification, VideoMAEImageProcessor  # å¯¼å…¥ TimeSformer æ¨¡å‹æ‰€éœ€çš„é…ç½®ã€æ¨¡å‹å’Œå¤„ç†å™¨ç±»


def get_timesformer_config(model_name):
    config = TimesformerConfig()  # åˆ›å»ºä¸€ä¸ª TimeSformer çš„é…ç½®å¯¹è±¡

    if "large" in model_name:
        config.num_frames = 96  # å¦‚æœæ¨¡å‹ååŒ…å« 'large'ï¼Œè®¾ç½®å¸§æ•°ä¸º 96

    if "hr" in model_name:
        config.num_frames = 16  # å¦‚æœæ¨¡å‹ååŒ…å« 'hr'ï¼Œè®¾ç½®å¸§æ•°ä¸º 16
        config.image_size = 448  # åŒæ—¶è®¾ç½®å›¾åƒå°ºå¯¸ä¸º 448

    repo_id = "huggingface/label-files"
    if "k400" in model_name:
        config.num_labels = 400  # å¦‚æœæ¨¡å‹ååŒ…å« 'k400'ï¼Œè®¾ç½®æ ‡ç­¾æ•°ä¸º 400
        filename = "kinetics400-id2label.json"  # è®¾ç½®è¦ä¸‹è½½çš„æ–‡ä»¶åä¸º kinetics400-id2label.json
    elif "k600" in model_name:
        config.num_labels = 600  # å¦‚æœæ¨¡å‹ååŒ…å« 'k600'ï¼Œè®¾ç½®æ ‡ç­¾æ•°ä¸º 600
        filename = "kinetics600-id2label.json"  # è®¾ç½®è¦ä¸‹è½½çš„æ–‡ä»¶åä¸º kinetics600-id2label.json
    elif "ssv2" in model_name:
        config.num_labels = 174  # å¦‚æœæ¨¡å‹ååŒ…å« 'ssv2'ï¼Œè®¾ç½®æ ‡ç­¾æ•°ä¸º 174
        filename = "something-something-v2-id2label.json"  # è®¾ç½®è¦ä¸‹è½½çš„æ–‡ä»¶åä¸º something-something-v2-id2label.json
    else:
        raise ValueError("Model name should either contain 'k400', 'k600' or 'ssv2'.")  # å¦‚æœæ¨¡å‹åä¸ç¬¦åˆé¢„æœŸï¼Œåˆ™å¼•å‘é”™è¯¯
    id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type="dataset"), "r"))  # ä» Hugging Face Hub ä¸‹è½½å¹¶åŠ è½½ JSON æ ¼å¼çš„æ ‡ç­¾æ˜ å°„æ•°æ®
    id2label = {int(k): v for k, v in id2label.items()}  # å°†æ ‡ç­¾æ˜ å°„æ•°æ®ä¸­çš„é”®è½¬æ¢ä¸ºæ•´æ•°ç±»å‹
    config.id2label = id2label  # å°†åŠ è½½çš„æ ‡ç­¾æ˜ å°„æ•°æ®è®¾ç½®ä¸ºé…ç½®å¯¹è±¡çš„ id2label å±æ€§
    config.label2id = {v: k for k, v in id2label.items()}  # åˆ›å»ºåå‘æ˜ å°„ï¼Œä»æ ‡ç­¾åˆ° ID çš„æ˜ å°„

    return config  # è¿”å›é…ç½®å¯¹è±¡


def rename_key(name):
    if "encoder." in name:
        name = name.replace("encoder.", "")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'encoder.' ä¸º ''
    if "cls_token" in name:
        name = name.replace("cls_token", "timesformer.embeddings.cls_token")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'cls_token' ä¸º 'timesformer.embeddings.cls_token'
    if "pos_embed" in name:
        name = name.replace("pos_embed", "timesformer.embeddings.position_embeddings")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'pos_embed' ä¸º 'timesformer.embeddings.position_embeddings'
    if "time_embed" in name:
        name = name.replace("time_embed", "timesformer.embeddings.time_embeddings")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'time_embed' ä¸º 'timesformer.embeddings.time_embeddings'
    if "patch_embed.proj" in name:
        name = name.replace("patch_embed.proj", "timesformer.embeddings.patch_embeddings.projection")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'patch_embed.proj' ä¸º 'timesformer.embeddings.patch_embeddings.projection'
    if "patch_embed.norm" in name:
        name = name.replace("patch_embed.norm", "timesformer.embeddings.norm")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'patch_embed.norm' ä¸º 'timesformer.embeddings.norm'
    if "blocks" in name:
        name = name.replace("blocks", "timesformer.encoder.layer")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'blocks' ä¸º 'timesformer.encoder.layer'
    if "attn.proj" in name:
        name = name.replace("attn.proj", "attention.output.dense")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'attn.proj' ä¸º 'attention.output.dense'
    if "attn" in name and "bias" not in name and "temporal" not in name:
        name = name.replace("attn", "attention.self")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'attn' ä¸º 'attention.self'ï¼Œæ’é™¤åŒ…å« 'bias' å’Œ 'temporal' çš„æƒ…å†µ
    if "attn" in name and "temporal" not in name:
        name = name.replace("attn", "attention.attention")  # æ›¿æ¢æ¨¡å‹å‚æ•°åä¸­çš„ 'attn' ä¸º 'attention.attention'ï¼Œæ’é™¤åŒ…å« 'temporal' çš„æƒ…å†µ
    # æ£€æŸ¥å­—ç¬¦ä¸² "temporal_norm1" æ˜¯å¦åœ¨å˜é‡ name ä¸­
    if "temporal_norm1" in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "temporal_norm1" æ›¿æ¢ä¸º "temporal_layernorm"
        name = name.replace("temporal_norm1", "temporal_layernorm")

    # æ£€æŸ¥å­—ç¬¦ä¸² "temporal_attn.proj" æ˜¯å¦åœ¨å˜é‡ name ä¸­
    if "temporal_attn.proj" in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "temporal_attn" æ›¿æ¢ä¸º "temporal_attention.output.dense"
        name = name.replace("temporal_attn", "temporal_attention.output.dense")

    # æ£€æŸ¥å­—ç¬¦ä¸² "temporal_fc" æ˜¯å¦åœ¨å˜é‡ name ä¸­
    if "temporal_fc" in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "temporal_fc" æ›¿æ¢ä¸º "temporal_dense"
        name = name.replace("temporal_fc", "temporal_dense")

    # æ£€æŸ¥å­—ç¬¦ä¸² "norm1" æ˜¯å¦åœ¨å˜é‡ name ä¸­ï¼Œå¹¶ä¸”å­—ç¬¦ä¸²ä¸­ä¸åŒ…å« "temporal"
    if "norm1" in name and "temporal" not in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "norm1" æ›¿æ¢ä¸º "layernorm_before"
        name = name.replace("norm1", "layernorm_before")

    # æ£€æŸ¥å­—ç¬¦ä¸² "norm2" æ˜¯å¦åœ¨å˜é‡ name ä¸­
    if "norm2" in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "norm2" æ›¿æ¢ä¸º "layernorm_after"
        name = name.replace("norm2", "layernorm_after")

    # æ£€æŸ¥å­—ç¬¦ä¸² "mlp.fc1" æ˜¯å¦åœ¨å˜é‡ name ä¸­
    if "mlp.fc1" in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "mlp.fc1" æ›¿æ¢ä¸º "intermediate.dense"
        name = name.replace("mlp.fc1", "intermediate.dense")

    # æ£€æŸ¥å­—ç¬¦ä¸² "mlp.fc2" æ˜¯å¦åœ¨å˜é‡ name ä¸­
    if "mlp.fc2" in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "mlp.fc2" æ›¿æ¢ä¸º "output.dense"
        name = name.replace("mlp.fc2", "output.dense")

    # æ£€æŸ¥å­—ç¬¦ä¸² "norm.weight" æ˜¯å¦åœ¨å˜é‡ name ä¸­ï¼Œå¹¶ä¸”å­—ç¬¦ä¸²ä¸­ä¸åŒ…å« "fc" å’Œ "temporal"
    if "norm.weight" in name and "fc" not in name and "temporal" not in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "norm.weight" æ›¿æ¢ä¸º "timesformer.layernorm.weight"
        name = name.replace("norm.weight", "timesformer.layernorm.weight")

    # æ£€æŸ¥å­—ç¬¦ä¸² "norm.bias" æ˜¯å¦åœ¨å˜é‡ name ä¸­ï¼Œå¹¶ä¸”å­—ç¬¦ä¸²ä¸­ä¸åŒ…å« "fc" å’Œ "temporal"
    if "norm.bias" in name and "fc" not in name and "temporal" not in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "norm.bias" æ›¿æ¢ä¸º "timesformer.layernorm.bias"
        name = name.replace("norm.bias", "timesformer.layernorm.bias")

    # æ£€æŸ¥å­—ç¬¦ä¸² "head" æ˜¯å¦åœ¨å˜é‡ name ä¸­
    if "head" in name:
        # å¦‚æœæ˜¯ï¼Œåˆ™å°†å­—ç¬¦ä¸² "head" æ›¿æ¢ä¸º "classifier"
        name = name.replace("head", "classifier")

    # è¿”å›æ›¿æ¢åçš„å˜é‡ name
    return name
# æ ¹æ®ç»™å®šçš„åŸå§‹çŠ¶æ€å­—å…¸å’Œé…ç½®ï¼Œè½¬æ¢æ¨¡å‹çš„çŠ¶æ€å­—å…¸
def convert_state_dict(orig_state_dict, config):
    # éå†åŸå§‹çŠ¶æ€å­—å…¸çš„é”®ï¼ˆéœ€è¦å¤åˆ¶ï¼Œå› ä¸ºåç»­ä¼šä¿®æ”¹åŸå§‹å­—å…¸ï¼‰
    for key in orig_state_dict.copy().keys():
        # å¼¹å‡ºå½“å‰é”®å¯¹åº”çš„å€¼
        val = orig_state_dict.pop(key)

        # å¦‚æœé”®ä»¥"model."å¼€å¤´ï¼Œåˆ™å»é™¤è¯¥å‰ç¼€
        if key.startswith("model."):
            key = key.replace("model.", "")

        # å¦‚æœé”®åŒ…å«"qkv"ï¼Œåˆ™æ ¹æ®ä¸åŒæƒ…å†µé‡æ–°å‘½åé”®
        if "qkv" in key:
            key_split = key.split(".")
            layer_num = int(key_split[1])
            prefix = "timesformer.encoder.layer."
            # æ ¹æ®é”®åä¸­æ˜¯å¦åŒ…å«"temporal"å†³å®šåç¼€
            if "temporal" in key:
                postfix = ".temporal_attention.attention.qkv."
            else:
                postfix = ".attention.attention.qkv."
            # æ ¹æ®é”®åä¸­æ˜¯å¦åŒ…å«"weight"å†³å®šä¿®æ”¹çŠ¶æ€å­—å…¸ä¸­çš„é”®å’Œå¯¹åº”çš„å€¼
            if "weight" in key:
                orig_state_dict[f"{prefix}{layer_num}{postfix}weight"] = val
            else:
                orig_state_dict[f"{prefix}{layer_num}{postfix}bias"] = val
        else:
            # å¦åˆ™ï¼Œå¯¹é”®è¿›è¡Œé‡å‘½å
            orig_state_dict[rename_key(key)] = val

    # è¿”å›è½¬æ¢åçš„åŸå§‹çŠ¶æ€å­—å…¸
    return orig_state_dict


# æˆ‘ä»¬å°†åœ¨ä¸€ä¸ªåƒæ„å¤§åˆ©é¢æ¡çš„è§†é¢‘ä¸ŠéªŒè¯æˆ‘ä»¬çš„ç»“æœ
# ä½¿ç”¨çš„å¸§ç´¢å¼•: [164 168 172 176 181 185 189 193 198 202 206 210 215 219 223 227]
def prepare_video():
    # ä»æŒ‡å®šçš„æ•°æ®é›†ä»“åº“ä¸‹è½½åä¸º"eating_spaghetti.npy"çš„æ–‡ä»¶
    file = hf_hub_download(
        repo_id="hf-internal-testing/spaghetti-video", filename="eating_spaghetti.npy", repo_type="dataset"
    )
    # åŠ è½½è§†é¢‘æ•°æ®å¹¶è½¬æ¢ä¸ºåˆ—è¡¨è¿”å›
    video = np.load(file)
    return list(video)


def convert_timesformer_checkpoint(checkpoint_url, pytorch_dump_folder_path, model_name, push_to_hub):
    # è·å–ç‰¹å®šæ¨¡å‹åç§°çš„é…ç½®ä¿¡æ¯
    config = get_timesformer_config(model_name)

    # ä½¿ç”¨é…ç½®åˆ›å»ºä¸€ä¸ª TimesformerForVideoClassification æ¨¡å‹
    model = TimesformerForVideoClassification(config)

    # ä¸‹è½½æ‰˜ç®¡åœ¨ Google Drive ä¸Šçš„åŸå§‹æ£€æŸ¥ç‚¹æ–‡ä»¶
    output = "pytorch_model.bin"
    gdown.cached_download(checkpoint_url, output, quiet=False)
    # åŠ è½½æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œæ ¹æ®æ–‡ä»¶ä¸­çš„é”®åä¸åŒè¿›è¡Œé€‚é…
    files = torch.load(output, map_location="cpu")
    if "model" in files:
        state_dict = files["model"]
    elif "module" in files:
        state_dict = files["module"]
    else:
        state_dict = files["model_state"]
    # è½¬æ¢åŠ è½½çš„çŠ¶æ€å­—å…¸åˆ°æ–°çš„çŠ¶æ€å­—å…¸æ ¼å¼
    new_state_dict = convert_state_dict(state_dict, config)

    # åŠ è½½æ¨¡å‹çš„æ–°çŠ¶æ€å­—å…¸
    model.load_state_dict(new_state_dict)
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()

    # åœ¨åŸºæœ¬è¾“å…¥ä¸ŠéªŒè¯æ¨¡å‹
    # åˆ›å»ºä¸€ä¸ªå›¾åƒå¤„ç†å™¨å¯¹è±¡ï¼Œç”¨äºè§†é¢‘å¤„ç†
    image_processor = VideoMAEImageProcessor(image_mean=[0.5, 0.5, 0.5], image_std=[0.5, 0.5, 0.5])
    # å‡†å¤‡è§†é¢‘æ•°æ®
    video = prepare_video()
    # ä½¿ç”¨å›¾åƒå¤„ç†å™¨å¤„ç†å‰8å¸§è§†é¢‘ï¼Œå¹¶è¿”å›PyTorchå¼ é‡æ ¼å¼çš„è¾“å…¥
    inputs = image_processor(video[:8], return_tensors="pt")

    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œè·å–è¾“å‡ºç»“æœ
    outputs = model(**inputs)
    logits = outputs.logits

    # å®šä¹‰ä¸€ç»„æ¨¡å‹åç§°åˆ—è¡¨ï¼ŒåŒ…å«ä¸åŒç‰ˆæœ¬å’Œåˆ†è¾¨ç‡çš„é¢„è®­ç»ƒæ£€æŸ¥ç‚¹
    model_names = [
        # Kinetics-400 æ•°æ®é›†æ£€æŸ¥ç‚¹ï¼ˆhr = ä½¿ç”¨448pxé«˜åˆ†è¾¨ç‡è¾“å…¥è€Œé224pxï¼‰
        "timesformer-base-finetuned-k400",
        "timesformer-large-finetuned-k400",
        "timesformer-hr-finetuned-k400",
        # Kinetics-600 æ•°æ®é›†æ£€æŸ¥ç‚¹ï¼ˆhr = ä½¿ç”¨448pxé«˜åˆ†è¾¨ç‡è¾“å…¥è€Œé224pxï¼‰
        "timesformer-base-finetuned-k600",
        "timesformer-large-finetuned-k600",
        "timesformer-hr-finetuned-k600",
        # Something-Something-v2 æ•°æ®é›†æ£€æŸ¥ç‚¹ï¼ˆhr = ä½¿ç”¨448pxé«˜åˆ†è¾¨ç‡è¾“å…¥è€Œé224pxï¼‰
        "timesformer-base-finetuned-ssv2",
        "timesformer-large-finetuned-ssv2",
        "timesformer-hr-finetuned-ssv2",
    ]

    # æ³¨æ„ï¼šlogitsä½¿ç”¨äº†å›¾åƒå‡å€¼å’Œæ ‡å‡†å·® [0.5, 0.5, 0.5] å’Œ [0.5, 0.5, 0.5] è¿›è¡Œäº†æµ‹è¯•
    # æ ¹æ®æ¨¡å‹åç§°è®¾ç½®é¢„æœŸçš„è¾“å‡ºå½¢çŠ¶å’Œé¢„æœŸçš„è¾“å‡ºå€¼
    if model_name == "timesformer-base-finetuned-k400":
        expected_shape = torch.Size([1, 400])
        expected_slice = torch.tensor([-0.3016, -0.7713, -0.4205])
    elif model_name == "timesformer-base-finetuned-k600":
        expected_shape = torch.Size([1, 600])
        expected_slice = torch.tensor([-0.7267, -0.7466, 3.2404])
    elif model_name == "timesformer-base-finetuned-ssv2":
        expected_shape = torch.Size([1, 174])
        expected_slice = torch.tensor([-0.9059, 0.6433, -3.1457])
    elif model_name == "timesformer-large-finetuned-k400":
        expected_shape = torch.Size([1, 400])
        expected_slice = torch.tensor([0, 0, 0])
    elif model_name == "timesformer-large-finetuned-k600":
        expected_shape = torch.Size([1, 600])
        expected_slice = torch.tensor([0, 0, 0])
    elif model_name == "timesformer-large-finetuned-ssv2":
        expected_shape = torch.Size([1, 174])
        expected_slice = torch.tensor([0, 0, 0])
    elif model_name == "timesformer-hr-finetuned-k400":
        expected_shape = torch.Size([1, 400])
        expected_slice = torch.tensor([-0.9617, -3.7311, -3.7708])
    elif model_name == "timesformer-hr-finetuned-k600":
        expected_shape = torch.Size([1, 600])
        expected_slice = torch.tensor([2.5273, 0.7127, 1.8848])
    elif model_name == "timesformer-hr-finetuned-ssv2":
        expected_shape = torch.Size([1, 174])
        expected_slice = torch.tensor([-3.6756, -0.7513, 0.7180])
    else:
        raise ValueError(f"Model name not supported. Should be one of {model_names}")

    # éªŒè¯æ¨¡å‹è¾“å‡ºçš„å½¢çŠ¶æ˜¯å¦ä¸é¢„æœŸä¸€è‡´
    assert logits.shape == expected_shape
    # éªŒè¯æ¨¡å‹è¾“å‡ºçš„å‰ä¸‰ä¸ªå…ƒç´ æ˜¯å¦ä¸é¢„æœŸçš„æ•°å€¼æ¥è¿‘
    assert torch.allclose(logits[0, :3], expected_slice, atol=1e-4)
    # æ‰“å°ç¡®è®¤ä¿¡æ¯
    print("Logits ok!")

    # å¦‚æœæŒ‡å®šäº† PyTorch æ¨¡å‹ä¿å­˜è·¯å¾„ï¼Œåˆ™ä¿å­˜æ¨¡å‹å’Œå›¾åƒå¤„ç†å™¨
    if pytorch_dump_folder_path is not None:
        print(f"Saving model and image processor to {pytorch_dump_folder_path}")
        image_processor.save_pretrained(pytorch_dump_folder_path)
        model.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœéœ€è¦æ¨é€åˆ° hub
    if push_to_hub:
        # æ‰“å°æ¨é€åˆ° hub çš„æ¶ˆæ¯
        print("Pushing to the hub...")
        # å°†æ¨¡å‹æ¨é€åˆ°æŒ‡å®šè·¯å¾„ä¸‹çš„ hub
        model.push_to_hub(f"fcakyon/{model_name}")
if __name__ == "__main__":
    # å¦‚æœä½œä¸ºä¸»ç¨‹åºæ‰§è¡Œï¼Œåˆ™å¼€å§‹è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser()
    
    # æ·»åŠ å¿…éœ€çš„å‚æ•°
    parser.add_argument(
        "--checkpoint_url",
        default="https://drive.google.com/u/1/uc?id=17yvuYp9L4mn-HpIcK5Zo6K3UoOy1kA5l&export=download",
        type=str,
        help=(
            "URL of the original PyTorch checkpoint (on Google Drive) you'd like to convert. Should be a direct"
            " download link."
        ),
    )
    
    parser.add_argument(
        "--pytorch_dump_folder_path",
        default="",
        type=str,
        help="Path to the output PyTorch model directory.",
    )
    
    parser.add_argument(
        "--model_name", 
        default="timesformer-base-finetuned-k400", 
        type=str, 
        help="Name of the model."
    )
    
    parser.add_argument(
        "--push_to_hub", 
        action="store_true", 
        help="Whether or not to push the converted model to the ğŸ¤— hub."
    )
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    
    # è°ƒç”¨å‡½æ•° convert_timesformer_checkpointï¼Œä¼ å…¥è§£æå¾—åˆ°çš„å‚æ•°
    convert_timesformer_checkpoint(
        args.checkpoint_url, args.pytorch_dump_folder_path, args.model_name, args.push_to_hub
    )
```