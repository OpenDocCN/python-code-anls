# `.\models\musicgen_melody\convert_musicgen_melody_transformers.py`

```py
# è®¾ç½®æ–‡ä»¶ç¼–ç æ ¼å¼ä¸º UTF-8
# ç‰ˆæƒå£°æ˜å’Œè®¸å¯ä¿¡æ¯ï¼ŒæŒ‡æ˜æ­¤ä»£ç å— Apache License, Version 2.0 çš„ä¿æŠ¤
# è¯¥è„šæœ¬ç”¨äºå°†åŸå§‹å­˜å‚¨åº“ä¸­çš„ Musicgen Melody æ£€æŸ¥ç‚¹è½¬æ¢
"""Convert Musicgen Melody checkpoints from the original repository."""
# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import argparse  # ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°
from pathlib import Path  # æä¾›å¤„ç†æ–‡ä»¶è·¯å¾„çš„ç±»å’Œæ–¹æ³•
from typing import Dict, OrderedDict, Tuple  # å¼•å…¥ç±»å‹æç¤º

import torch  # PyTorch æ·±åº¦å­¦ä¹ åº“
from audiocraft.models import MusicGen  # å¯¼å…¥è‡ªå®šä¹‰çš„éŸ³ä¹ç”Ÿæˆæ¨¡å‹

# ä» Transformers åº“ä¸­å¯¼å…¥ç›¸å…³æ¨¡å—å’Œç±»
from transformers import (
    AutoTokenizer,  # è‡ªåŠ¨æ¨¡å‹ä»¤ç‰ŒåŒ–
    EncodecModel,  # ç¼–ç å™¨æ¨¡å‹ï¼ˆå¯èƒ½æ˜¯æ‹¼å†™é”™è¯¯ï¼Œåº”ä¸ºEncoderModelï¼‰
    T5EncoderModel,  # T5 ç¼–ç å™¨æ¨¡å‹
)
# å¯¼å…¥ Musicgen Melody çš„é…ç½®ã€ç‰¹å¾æå–ã€æ¨¡å‹å’Œå¤„ç†æ¨¡å—
from transformers.models.musicgen_melody.configuration_musicgen_melody import MusicgenMelodyDecoderConfig
from transformers.models.musicgen_melody.feature_extraction_musicgen_melody import MusicgenMelodyFeatureExtractor
from transformers.models.musicgen_melody.modeling_musicgen_melody import (
    MusicgenMelodyForCausalLM,  # Musicgen Melody çš„å› æœè¯­è¨€å»ºæ¨¡æ¨¡å‹
    MusicgenMelodyForConditionalGeneration,  # Musicgen Melody çš„æ¡ä»¶ç”Ÿæˆæ¨¡å‹
)
from transformers.models.musicgen_melody.processing_musicgen_melody import MusicgenMelodyProcessor  # å¤„ç† Musicgen Melody ç›¸å…³ä»»åŠ¡çš„æ¨¡å—
from transformers.utils import logging  # å¯¼å…¥æ—¥å¿—è®°å½•æ¨¡å—

# è®¾ç½®æ—¥å¿—è®°å½•çº§åˆ«ä¸ºä¿¡æ¯
logging.set_verbosity_info()
# è·å–å½“å‰æ¨¡å—çš„æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger(__name__)

# é¢„æœŸç¼ºå¤±çš„æ¨¡å‹é”®åˆ—è¡¨
EXPECTED_MISSING_KEYS = ["model.decoder.embed_positions.weights"]
# é¢„æœŸé¢å¤–çš„æ¨¡å‹é”®åˆ—è¡¨
EXPECTED_ADDITIONAL_KEYS = ["condition_provider.conditioners.self_wav.chroma.spec.window"]


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ç”¨äºé‡å‘½åæ¨¡å‹å‚æ•°å
def rename_keys(name):
    if "emb" in name:
        name = name.replace("emb", "model.decoder.embed_tokens")
    if "transformer" in name:
        name = name.replace("transformer", "model.decoder")
    if "cross_attention" in name:
        name = name.replace("cross_attention", "encoder_attn")
    if "linear1" in name:
        name = name.replace("linear1", "fc1")
    if "linear2" in name:
        name = name.replace("linear2", "fc2")
    if "norm1" in name:
        name = name.replace("norm1", "self_attn_layer_norm")
    if "norm_cross" in name:
        name = name.replace("norm_cross", "encoder_attn_layer_norm")
    if "norm2" in name:
        name = name.replace("norm2", "final_layer_norm")
    if "out_norm" in name:
        name = name.replace("out_norm", "model.decoder.layer_norm")
    if "linears" in name:
        name = name.replace("linears", "lm_heads")
    if "condition_provider.conditioners.description.output_proj" in name:
        name = name.replace("condition_provider.conditioners.description.output_proj", "enc_to_dec_proj")
    if "condition_provider.conditioners.self_wav.output_proj" in name:
        name = name.replace("condition_provider.conditioners.self_wav.output_proj", "audio_enc_to_dec_proj")
    return name
# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºé‡å‘½åç»™å®šçš„çŠ¶æ€å­—å…¸ï¼Œå¹¶æŒ‰ç…§ç‰¹å®šçš„æ¨¡å—åç§°é‡æ–°å‘½åã€‚
def rename_state_dict(state_dict: OrderedDict, hidden_size: int) -> Tuple[Dict, Dict]:
    """Function that takes the fairseq MusicgenMelody state dict and renames it according to the HF
    module names. It further partitions the state dict into the decoder (LM) state dict, and that for the
    text encoder projection and for the audio encoder projection."""
    
    # è·å–çŠ¶æ€å­—å…¸çš„æ‰€æœ‰é”®
    keys = list(state_dict.keys())
    # åˆå§‹åŒ–ç©ºå­—å…¸ï¼Œç”¨äºå­˜å‚¨ç¼–ç å™¨-è§£ç å™¨æŠ•å½±å’ŒéŸ³é¢‘ç¼–ç å™¨åˆ°è§£ç å™¨æŠ•å½±ä¹‹é—´çš„çŠ¶æ€å­—å…¸
    enc_dec_proj_state_dict = {}
    audio_enc_to_dec_proj_state_dict = {}
    
    # éå†çŠ¶æ€å­—å…¸çš„æ¯ä¸ªé”®
    for key in keys:
        # å¼¹å‡ºå½“å‰é”®å¯¹åº”çš„å€¼
        val = state_dict.pop(key)
        # ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°é‡å‘½åå½“å‰é”®
        key = rename_keys(key)
        
        # å¦‚æœå½“å‰é”®åŒ…å« "in_proj_weight"ï¼Œåˆ™æ‹†åˆ†èåˆçš„qkvæŠ•å½±
        if "in_proj_weight" in key:
            state_dict[key.replace("in_proj_weight", "q_proj.weight")] = val[:hidden_size, :]
            state_dict[key.replace("in_proj_weight", "k_proj.weight")] = val[hidden_size : 2 * hidden_size, :]
            state_dict[key.replace("in_proj_weight", "v_proj.weight")] = val[-hidden_size:, :]
        # å¦‚æœå½“å‰é”®åŒ…å« "audio_enc_to_dec_proj"ï¼Œåˆ™å°†å…¶æ·»åŠ åˆ°éŸ³é¢‘ç¼–ç å™¨åˆ°è§£ç å™¨æŠ•å½±çŠ¶æ€å­—å…¸ä¸­
        elif "audio_enc_to_dec_proj" in key:
            audio_enc_to_dec_proj_state_dict[key[len("audio_enc_to_dec_proj.") :]] = val
        # å¦‚æœå½“å‰é”®åŒ…å« "enc_to_dec_proj"ï¼Œåˆ™å°†å…¶æ·»åŠ åˆ°ç¼–ç å™¨åˆ°è§£ç å™¨æŠ•å½±çŠ¶æ€å­—å…¸ä¸­
        elif "enc_to_dec_proj" in key:
            enc_dec_proj_state_dict[key[len("enc_to_dec_proj.") :]] = val
        # å¦åˆ™ï¼Œå°†å½“å‰é”®å’Œå¯¹åº”çš„å€¼æ·»åŠ å›çŠ¶æ€å­—å…¸ä¸­
        else:
            state_dict[key] = val
    
    # è¿”å›é‡å‘½ååçš„çŠ¶æ€å­—å…¸ï¼Œç¼–ç å™¨-è§£ç å™¨æŠ•å½±çŠ¶æ€å­—å…¸å’ŒéŸ³é¢‘ç¼–ç å™¨åˆ°è§£ç å™¨æŠ•å½±çŠ¶æ€å­—å…¸
    return state_dict, enc_dec_proj_state_dict, audio_enc_to_dec_proj_state_dict


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œä»ç»™å®šçš„æ£€æŸ¥ç‚¹åŠ è½½é…ç½®ä¿¡æ¯å¹¶è¿”å› MusicgenMelodyDecoderConfig å¯¹è±¡
def decoder_config_from_checkpoint(checkpoint: str) -> MusicgenMelodyDecoderConfig:
    # æ ¹æ®ç»™å®šçš„æ£€æŸ¥ç‚¹åç§°ï¼Œè®¾ç½®éšè—å¤§å°ã€éšè—å±‚æ•°ã€æ³¨æ„åŠ›å¤´æ•°ç­‰å‚æ•°
    if checkpoint == "facebook/musicgen-melody" or checkpoint == "facebook/musicgen-stereo-melody":
        hidden_size = 1536
        num_hidden_layers = 48
        num_attention_heads = 24
    elif checkpoint == "facebook/musicgen-melody-large" or checkpoint == "facebook/musicgen-stereo-melody-large":
        hidden_size = 2048
        num_hidden_layers = 48
        num_attention_heads = 32
    else:
        # å¦‚æœæ£€æŸ¥ç‚¹åç§°ä¸åœ¨é¢„æœŸèŒƒå›´å†…ï¼ŒæŠ›å‡º ValueError å¼‚å¸¸
        raise ValueError(
            "Checkpoint should be one of `['facebook/musicgen-melody', 'facebook/musicgen-melody-large']` for the mono checkpoints, "
            "or `['facebook/musicgen-stereo-melody', 'facebook/musicgen-stereo-melody-large']` "
            f"for the stereo checkpoints, got {checkpoint}."
        )
    
    # æ ¹æ®æ£€æŸ¥ç‚¹åç§°ä¸­æ˜¯å¦åŒ…å« "stereo" è®¾ç½®éŸ³é¢‘é€šé“æ•°å’Œç æœ¬æ•°
    if "stereo" in checkpoint:
        audio_channels = 2
        num_codebooks = 8
    else:
        audio_channels = 1
        num_codebooks = 4
    
    # åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ª MusicgenMelodyDecoderConfig å¯¹è±¡ï¼ŒåŒ…å«ä»æ£€æŸ¥ç‚¹åŠ è½½çš„é…ç½®ä¿¡æ¯
    config = MusicgenMelodyDecoderConfig(
        hidden_size=hidden_size,
        ffn_dim=hidden_size * 4,
        num_hidden_layers=num_hidden_layers,
        num_attention_heads=num_attention_heads,
        num_codebooks=num_codebooks,
        audio_channels=audio_channels,
    )
    return config


# å®šä¹‰ä¸€ä¸ªè£…é¥°å™¨ï¼Œç”¨äºå£°æ˜ä¸€ä¸ªæ— éœ€è®¡ç®—æ¢¯åº¦çš„å‡½æ•°
@torch.no_grad()
def convert_musicgen_melody_checkpoint(
    checkpoint, pytorch_dump_folder=None, repo_id=None, device="cpu", test_same_output=False
):
    # ä»é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æŒ‡å®šçš„æ£€æŸ¥ç‚¹ï¼Œå¹¶å°†æ¨¡å‹ç§»è‡³æŒ‡å®šçš„è®¾å¤‡ä¸Š
    fairseq_model = MusicGen.get_pretrained(checkpoint, device=args.device)
    # ä»åŠ è½½çš„æ¨¡å‹ä¸­è·å–è¯­è¨€æ¨¡å‹çš„çŠ¶æ€å­—å…¸
    decoder_state_dict = fairseq_model.lm.state_dict()
    # é‡å‘½åè§£ç å™¨çš„çŠ¶æ€å­—å…¸ï¼Œå¹¶æ ¹æ®éšè—å±‚å¤§å°è°ƒæ•´ç¼–ç -è§£ç æŠ•å½±çš„çŠ¶æ€å­—å…¸
    decoder_state_dict, enc_dec_proj_state_dict, audio_enc_to_dec_proj_state_dict = rename_state_dict(
        decoder_state_dict, hidden_size=decoder_config.hidden_size
    )

    # ä½¿ç”¨é¢„è®­ç»ƒçš„T5æ¨¡å‹åˆå§‹åŒ–æ–‡æœ¬ç¼–ç å™¨
    text_encoder = T5EncoderModel.from_pretrained("t5-base")
    
    # ä½¿ç”¨é¢„è®­ç»ƒçš„éŸ³é¢‘ç¼–ç å™¨åˆå§‹åŒ–éŸ³é¢‘ç¼–ç å™¨
    audio_encoder = EncodecModel.from_pretrained("facebook/encodec_32khz")
    
    # æ ¹æ®ç»™å®šçš„è§£ç å™¨é…ç½®åˆå§‹åŒ–éŸ³ä¹ç”Ÿæˆçš„Melodyè§£ç å™¨ï¼Œå¹¶è®¾ä¸ºè¯„ä¼°æ¨¡å¼
    decoder = MusicgenMelodyForCausalLM(decoder_config).eval()

    # åŠ è½½è§£ç å™¨æƒé‡ï¼Œå…è®¸ç¼ºå°‘åµŒå…¥å’Œç¼–ç -è§£ç æŠ•å½±
    missing_keys, unexpected_keys = decoder.load_state_dict(decoder_state_dict, strict=False)

    # ç§»é™¤ä¸æ–‡æœ¬ç¼–ç å™¨æˆ–éŸ³é¢‘ç¼–ç å™¨ç›¸å…³çš„ç¼ºå¤±é”®åŠæœŸæœ›çš„ç¼ºå¤±é”®
    for key in missing_keys.copy():
        if key.startswith(("text_encoder", "audio_encoder")) or key in EXPECTED_MISSING_KEYS:
            missing_keys.remove(key)

    # ç§»é™¤ä¸æœŸæœ›çš„é¢å¤–é”®ç›¸å¯¹åº”çš„æ„å¤–é”®
    for key in unexpected_keys.copy():
        if key in EXPECTED_ADDITIONAL_KEYS:
            unexpected_keys.remove(key)

    # å¦‚æœå­˜åœ¨ç¼ºå¤±çš„é”®ï¼Œåˆ™å¼•å‘å€¼é”™è¯¯
    if len(missing_keys) > 0:
        raise ValueError(f"Missing key(s) in state_dict: {missing_keys}")

    # å¦‚æœå­˜åœ¨æ„å¤–çš„é”®ï¼Œåˆ™å¼•å‘å€¼é”™è¯¯
    if len(unexpected_keys) > 0:
        raise ValueError(f"Unexpected key(s) in state_dict: {unexpected_keys}")

    # åˆå§‹åŒ–ç»„åˆæ¨¡å‹ï¼ŒåŒ…æ‹¬æ–‡æœ¬ç¼–ç å™¨ã€éŸ³é¢‘ç¼–ç å™¨å’Œè§£ç å™¨
    model = MusicgenMelodyForConditionalGeneration(
        text_encoder=text_encoder, audio_encoder=audio_encoder, decoder=decoder
    ).to(args.device)

    # åŠ è½½é¢„è®­ç»ƒçš„ç¼–ç -è§£ç æŠ•å½±ï¼ˆä»è§£ç å™¨çŠ¶æ€å­—å…¸ä¸­ï¼‰
    model.enc_to_dec_proj.load_state_dict(enc_dec_proj_state_dict)

    # åŠ è½½é¢„è®­ç»ƒçš„éŸ³é¢‘ç¼–ç å™¨æŠ•å½±ï¼ˆä»è§£ç å™¨çŠ¶æ€å­—å…¸ä¸­ï¼‰
    model.audio_enc_to_dec_proj.load_state_dict(audio_enc_to_dec_proj_state_dict)

    # æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›è¡Œå‰å‘ä¼ æ’­
    input_ids = torch.arange(0, 2 * decoder_config.num_codebooks, dtype=torch.long).reshape(2, -1).to(device)
    decoder_input_ids = input_ids.reshape(2 * decoder_config.num_codebooks, -1).to(device)

    # ä½¿ç”¨torch.no_grad()ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ‰§è¡Œå‰å‘ä¼ æ’­ï¼Œè·å–logits
    with torch.no_grad():
        logits = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids).logits

    # è®¡ç®—é¢„æœŸçš„è¾“å‡ºé•¿åº¦ï¼Œå¹¶æ£€æŸ¥logitsçš„å½¢çŠ¶æ˜¯å¦ç¬¦åˆé¢„æœŸ
    output_length = 1 + input_ids.shape[1] + model.config.chroma_length
    if logits.shape != (2 * decoder_config.num_codebooks, output_length, 2048):
        raise ValueError("Incorrect shape for logits")

    # åˆå§‹åŒ–tokenizerï¼Œä½¿ç”¨T5-baseæ¨¡å‹çš„è‡ªåŠ¨tokenizer
    tokenizer = AutoTokenizer.from_pretrained("t5-base")
    
    # åˆå§‹åŒ–ç‰¹å¾æå–å™¨ä¸ºéŸ³ä¹ç”ŸæˆMelodyçš„ç‰¹å¾æå–å™¨
    feature_extractor = MusicgenMelodyFeatureExtractor()

    # åˆå§‹åŒ–processorï¼Œä½¿ç”¨ç‰¹å¾æå–å™¨å’Œtokenizer
    processor = MusicgenMelodyProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)

    # è®¾ç½®é€‚å½“çš„å¼€å§‹/å¡«å……token id
    model.generation_config.decoder_start_token_id = 2048
    model.generation_config.pad_token_id = 2048

    # è®¾ç½®å…¶ä»–é»˜è®¤çš„ç”Ÿæˆé…ç½®å‚æ•°
    model.generation_config.max_length = int(30 * audio_encoder.config.frame_rate)
    model.generation_config.do_sample = True
    model.generation_config.guidance_scale = 3.0
    # å¦‚æœéœ€è¦æµ‹è¯•è¾“å‡ºæ˜¯å¦ä¸åŸå§‹æ¨¡å‹ç›¸åŒ
    if test_same_output:
        # å‡†å¤‡ç”¨äºè§£ç çš„è¾“å…¥å¼ é‡ï¼Œå…¨éƒ¨å¡«å……ä¸ºæ¨¡å‹çš„å¡«å……æ ‡è®°ID
        decoder_input_ids = torch.ones_like(decoder_input_ids).to(device) * model.generation_config.pad_token_id
        
        # ç¦æ­¢æ¢¯åº¦è®¡ç®—çš„ä¸Šä¸‹æ–‡
        with torch.no_grad():
            # é™åˆ¶è§£ç å™¨è¾“å…¥çš„é•¿åº¦ï¼Œä»…ä¿ç•™å‰ decoder_config.num_codebooks ä¸ªä½ç½®
            decoder_input_ids = decoder_input_ids[: decoder_config.num_codebooks]
            
            # ä½¿ç”¨processorå¯¹æ–‡æœ¬è¿›è¡Œå¤„ç†ï¼Œè¿”å›PyTorchå¼ é‡æ ¼å¼çš„è¾“å…¥æ•°æ®
            inputs = processor(text=["gen"], return_tensors="pt", padding=True).to(device)
            
            # ä½¿ç”¨æ¨¡å‹ç”Ÿæˆlogitsï¼Œç»™å®šè§£ç å™¨çš„è¾“å…¥å¼ é‡
            logits = model(**inputs, decoder_input_ids=decoder_input_ids).logits

            # å‡†å¤‡fairseqæ¨¡å‹çš„tokenså’Œattributesç”¨äºç”Ÿæˆ
            attributes, prompt_tokens = fairseq_model._prepare_tokens_and_attributes(["gen"], None)
            
            # ä½¿ç”¨fairseqæ¨¡å‹è¿›è¡Œå‰å‘æ¨æ–­ï¼Œè®¡ç®—åŸå§‹æ¨¡å‹çš„logits
            original_logits = fairseq_model.lm.forward(
                decoder_input_ids.reshape(1, decoder_config.num_codebooks, -1), attributes
            )

            # ä½¿ç”¨torchçš„æµ‹è¯•å·¥å…·æ–­è¨€ï¼Œæ£€æŸ¥ç”Ÿæˆçš„logitsä¸åŸå§‹æ¨¡å‹çš„logitsåœ¨æ•°å€¼ä¸Šçš„æ¥è¿‘åº¦
            torch.testing.assert_close(
                original_logits.squeeze(2).reshape(decoder_config.num_codebooks, -1),
                logits[:, -1],
                rtol=1e-5,
                atol=5e-5,
            )

    # å¦‚æœæä¾›äº†pytorch_dump_folderè·¯å¾„ï¼Œåˆ™ä¿å­˜æ¨¡å‹å’Œprocessorçš„é…ç½®åˆ°æŒ‡å®šç›®å½•
    if pytorch_dump_folder is not None:
        # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºè¯¥ç›®å½•
        Path(pytorch_dump_folder).mkdir(exist_ok=True)
        
        # è®°å½•æ—¥å¿—ï¼ŒæŒ‡ç¤ºå°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šç›®å½•
        logger.info(f"Saving model {checkpoint} to {pytorch_dump_folder}")
        
        # ä¿å­˜æ¨¡å‹çš„é¢„è®­ç»ƒé…ç½®åˆ°æŒ‡å®šç›®å½•
        model.save_pretrained(pytorch_dump_folder)
        
        # ä¿å­˜processorçš„é…ç½®åˆ°æŒ‡å®šç›®å½•
        processor.save_pretrained(pytorch_dump_folder)

    # å¦‚æœæä¾›äº†repo_idï¼Œåˆ™å°†æ¨¡å‹å’Œprocessoræ¨é€åˆ°æŒ‡å®šçš„Hub repoä¸­
    if repo_id:
        # è®°å½•æ—¥å¿—ï¼ŒæŒ‡ç¤ºå°†æ¨¡å‹æ¨é€åˆ°æŒ‡å®šçš„Hub repoä¸­
        logger.info(f"Pushing model {checkpoint} to {repo_id}")
        
        # å°†æ¨¡å‹æ¨é€åˆ°æŒ‡å®šçš„Hub repoä¸­ï¼Œå¹¶åˆ›å»ºpull request
        model.push_to_hub(repo_id, create_pr=True)
        
        # å°†processoræ¨é€åˆ°æŒ‡å®šçš„Hub repoä¸­ï¼Œå¹¶åˆ›å»ºpull request
        processor.push_to_hub(repo_id, create_pr=True)
if __name__ == "__main__":
    # å¦‚æœè„šæœ¬ä½œä¸ºä¸»ç¨‹åºæ‰§è¡Œï¼Œè¿›å…¥ä¸»ç¨‹åºå…¥å£

    parser = argparse.ArgumentParser()
    # åˆ›å»ºä¸€ä¸ªå‚æ•°è§£æå™¨å¯¹è±¡

    # Required parameters
    parser.add_argument(
        "--checkpoint",
        default="facebook/musicgen-melody",
        type=str,
        help="Checkpoint size of the Musicgen Melody model you'd like to convert. Can be one of: "
        "`['facebook/musicgen-melody', 'facebook/musicgen-melody-large']` for the mono checkpoints, or "
        "`['facebook/musicgen-stereo-melody', 'facebook/musicgen-stereo-melody-large']` "
        "for the stereo checkpoints.",
    )
    # æ·»åŠ å¿…é€‰å‚æ•°--checkpointï¼ŒæŒ‡å®šè¦è½¬æ¢çš„ Musicgen Melody æ¨¡å‹çš„æ£€æŸ¥ç‚¹ä½ç½®

    parser.add_argument(
        "--pytorch_dump_folder",
        default=None,
        type=str,
        help="Path to the output PyTorch model directory.",
    )
    # æ·»åŠ å¯é€‰å‚æ•°--pytorch_dump_folderï¼ŒæŒ‡å®šè¾“å‡ºçš„ PyTorch æ¨¡å‹ä¿å­˜è·¯å¾„

    parser.add_argument(
        "--push_to_hub",
        default="musicgen-melody",
        type=str,
        help="Where to upload the converted model on the ğŸ¤— hub.",
    )
    # æ·»åŠ å¯é€‰å‚æ•°--push_to_hubï¼ŒæŒ‡å®šåœ¨ ğŸ¤— hub ä¸Šä¸Šä¼ è½¬æ¢åçš„æ¨¡å‹çš„ä½ç½®æ ‡è¯†

    parser.add_argument(
        "--device", default="cpu", type=str, help="Torch device to run the conversion, either cpu or cuda."
    )
    # æ·»åŠ å¯é€‰å‚æ•°--deviceï¼ŒæŒ‡å®šè½¬æ¢è¿‡ç¨‹ä¸­ä½¿ç”¨çš„ Torch è®¾å¤‡ï¼Œå¯ä»¥æ˜¯ cpu æˆ– cuda

    parser.add_argument("--test_same_output", default=False, type=bool, help="If `True`, test if same output logits.")
    # æ·»åŠ å¯é€‰å‚æ•°--test_same_outputï¼Œå¦‚æœè®¾ç½®ä¸º Trueï¼Œåˆ™æµ‹è¯•æ˜¯å¦è¾“å‡ºç›¸åŒçš„ logits

    args = parser.parse_args()
    # è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶è¿”å›è§£æåçš„å‚æ•°å¯¹è±¡ args

    convert_musicgen_melody_checkpoint(
        args.checkpoint, args.pytorch_dump_folder, args.push_to_hub, args.device, args.test_same_output
    )
    # è°ƒç”¨å‡½æ•° convert_musicgen_melody_checkpointï¼Œä¼ å…¥è§£æåçš„å‚æ•°ï¼Œæ‰§è¡Œ Musicgen Melody æ¨¡å‹çš„è½¬æ¢æ“ä½œ
```