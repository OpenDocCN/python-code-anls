# `.\transformers\models\speecht5\convert_speecht5_original_pytorch_checkpoint_to_pytorch.py`

```
# è®¾ç½®æ–‡æ¡£ç¼–ç ä¸º UTF-8
# ç‰ˆæƒå£°æ˜
#
# å¼•å…¥å‘½ä»¤è¡Œå‚æ•°è§£ææ¨¡å—
import argparse
# å¼•å…¥ PyTorch æ¨¡å—
import torch
# å¼•å…¥ transformers é‡Œçš„ SpeechT5 æœ‰å…³æ¨¡å—
from transformers import (
    SpeechT5Config,
    SpeechT5FeatureExtractor,
    SpeechT5ForSpeechToSpeech,
    SpeechT5ForSpeechToText,
    SpeechT5ForTextToSpeech,
    SpeechT5Processor,
    SpeechT5Tokenizer,
    logging,
)
# å¼•å…¥ transformers é‡Œé€šç”¨çš„ tokenization_utils æ¨¡å—çš„ AddedToken ç±»
from transformers.tokenization_utils import AddedToken
# è®¾ç½®æ—¥å¿—æ‰“å°çº§åˆ«ä¸º info
# è·å–æ—¥å¿—è®°å½•å™¨
# ä¸‹é¢å‡ ä¸ªå­—å…¸ç”¨äºå­˜å‚¨æš‚æ—¶ä¸å…¼å®¹çš„å‚æ•°çš„æ˜ å°„ï¼Œç”¨äºåç»­çš„æ¨¡å‹å‚æ•°è¿ç§»
# MAPPING_SPEECH_ENCODER_PRENET å­—å…¸
# MAPPING_TEXT_ENCODER_PRENET å­—å…¸
# MAPPING_SPEECH_DECODER_PRENET å­—å…¸
# MAPPING_SPEECH_DECODER_POSTNET å­—å…¸
    # å®šä¹‰é”®ä¸º "speech_decoder_postnet.postnet.postnet.3.0"ï¼Œå€¼ä¸º "speech_decoder_postnet.layers.3.conv" çš„æ˜ å°„å…³ç³»
    "speech_decoder_postnet.postnet.postnet.3.0": "speech_decoder_postnet.layers.3.conv",
    # å®šä¹‰é”®ä¸º "speech_decoder_postnet.postnet.postnet.3.1"ï¼Œå€¼ä¸º "speech_decoder_postnet.layers.3.batch_norm" çš„æ˜ å°„å…³ç³»
    "speech_decoder_postnet.postnet.postnet.3.1": "speech_decoder_postnet.layers.3.batch_norm",
    # å®šä¹‰é”®ä¸º "speech_decoder_postnet.postnet.postnet.4.0"ï¼Œå€¼ä¸º "speech_decoder_postnet.layers.4.conv" çš„æ˜ å°„å…³ç³»
    "speech_decoder_postnet.postnet.postnet.4.0": "speech_decoder_postnet.layers.4.conv",
    # å®šä¹‰é”®ä¸º "speech_decoder_postnet.postnet.postnet.4.1"ï¼Œå€¼ä¸º "speech_decoder_postnet.layers.4.batch_norm" çš„æ˜ å°„å…³ç³»
    "speech_decoder_postnet.postnet.postnet.4.1": "speech_decoder_postnet.layers.4.batch_norm",
# å®šä¹‰æ˜ å°„å…³ç³»ï¼Œå°†æ–‡æœ¬åˆ°è¯­éŸ³è§£ç å™¨ä¸­çš„å‚æ•°è½¬æ¢ä¸ºè¯­éŸ³åˆ°æ–‡æœ¬è§£ç å™¨ä¸­çš„å‚æ•°
MAPPING_TEXT_DECODER_PRENET = {
    "text_decoder_prenet.embed_tokens": "speecht5.decoder.prenet.embed_tokens",
}

# å®šä¹‰æ˜ å°„å…³ç³»ï¼Œå°†æ–‡æœ¬åˆ°è¯­éŸ³è§£ç å™¨ä¸­çš„å‚æ•°è½¬æ¢ä¸ºæ–‡æœ¬åˆ°æ–‡æœ¬è§£ç å™¨ä¸­çš„å‚æ•°
MAPPING_TEXT_DECODER_POSTNET = {
    "text_decoder_postnet.output_projection": "text_decoder_postnet.lm_head",
}

# å®šä¹‰æ˜ å°„å…³ç³»ï¼Œå°†ç¼–ç å™¨å‚æ•°è½¬æ¢ä¸ºæ–‡æœ¬åˆ°è¯­éŸ³æˆ–è¯­éŸ³åˆ°æ–‡æœ¬è§£ç å™¨ä¸­çš„å‚æ•°
MAPPING_ENCODER = {
    "encoder.layers.*.self_attn.k_proj": "speecht5.encoder.wrapped_encoder.layers.*.attention.k_proj",
    "encoder.layers.*.self_attn.v_proj": "speecht5.encoder.wrapped_encoder.layers.*.attention.v_proj",
    "encoder.layers.*.self_attn.q_proj": "speecht5.encoder.wrapped_encoder.layers.*.attention.q_proj",
    "encoder.layers.*.self_attn.out_proj": "speecht5.encoder.wrapped_encoder.layers.*.attention.out_proj",
    "encoder.layers.*.self_attn_layer_norm": "speecht5.encoder.wrapped_encoder.layers.*.layer_norm",
    "encoder.layers.*.fc1": "speecht5.encoder.wrapped_encoder.layers.*.feed_forward.intermediate_dense",
    "encoder.layers.*.fc2": "speecht5.encoder.wrapped_encoder.layers.*.feed_forward.output_dense",
    "encoder.layers.*.final_layer_norm": "speecht5.encoder.wrapped_encoder.layers.*.final_layer_norm",
    "encoder.layer_norm": "speecht5.encoder.wrapped_encoder.layer_norm",
    "encoder.pos_emb.pe_k": "speecht5.encoder.wrapped_encoder.embed_positions.pe_k",
}

# å®šä¹‰æ˜ å°„å…³ç³»ï¼Œå°†è§£ç å™¨å‚æ•°è½¬æ¢ä¸ºæ–‡æœ¬åˆ°è¯­éŸ³æˆ–è¯­éŸ³åˆ°æ–‡æœ¬è§£ç å™¨ä¸­çš„å‚æ•°
MAPPING_DECODER = {
    "decoder.layers.*.self_attn.k_proj": "speecht5.decoder.wrapped_decoder.layers.*.self_attn.k_proj",
    "decoder.layers.*.self_attn.v_proj": "speecht5.decoder.wrapped_decoder.layers.*.self_attn.v_proj",
    "decoder.layers.*.self_attn.q_proj": "speecht5.decoder.wrapped_decoder.layers.*.self_attn.q_proj",
    "decoder.layers.*.self_attn.out_proj": "speecht5.decoder.wrapped_decoder.layers.*.self_attn.out_proj",
    "decoder.layers.*.self_attn_layer_norm": "speecht5.decoder.wrapped_decoder.layers.*.self_attn_layer_norm",
    "decoder.layers.*.encoder_attn.k_proj": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn.k_proj",
    "decoder.layers.*.encoder_attn.v_proj": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn.v_proj",
    "decoder.layers.*.encoder_attn.q_proj": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn.q_proj",
    "decoder.layers.*.encoder_attn.out_proj": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn.out_proj",
    "decoder.layers.*.encoder_attn_layer_norm": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn_layer_norm",
    "decoder.layers.*.fc1": "speecht5.decoder.wrapped_decoder.layers.*.feed_forward.intermediate_dense",
    "decoder.layers.*.fc2": "speecht5.decoder.wrapped_decoder.layers.*.feed_forward.output_dense",
    "decoder.layers.*.final_layer_norm": "speecht5.decoder.wrapped_decoder.layers.*.final_layer_norm",
}

# å®šä¹‰æ–‡æœ¬åˆ°è¯­éŸ³è§£ç å™¨çš„æ˜ å°„å…³ç³»ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°è¯­éŸ³ç¼–ç å™¨çš„å‚æ•°å’Œæ–‡æœ¬åˆ°è¯­éŸ³è§£ç å™¨çš„å‚æ•°
MAPPING_S2T = {
    **MAPPING_SPEECH_ENCODER_PRENET,
    **MAPPING_ENCODER,
    **MAPPING_DECODER,
    **MAPPING_TEXT_DECODER_PRENET,
    **MAPPING_TEXT_DECODER_POSTNET,
}

# å®šä¹‰è¯­éŸ³åˆ°æ–‡æœ¬è§£ç å™¨çš„æ˜ å°„å…³ç³»ï¼ŒåŒ…æ‹¬è¯­éŸ³åˆ°æ–‡æœ¬ç¼–ç å™¨çš„å‚æ•°å’Œè¯­éŸ³åˆ°æ–‡æœ¬è§£ç å™¨çš„å‚æ•°
MAPPING_T2S = {
    **MAPPING_TEXT_ENCODER_PRENET,
    **MAPPING_ENCODER,
    **MAPPING_DECODER,
    **MAPPING_SPEECH_DECODER_PRENET,
    **MAPPING_SPEECH_DECODER_POSTNET,
}
# åˆ›å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªå­—å…¸çš„å¤§å­—å…¸ï¼Œå°†MAPPING_SPEECH_ENCODER_PRENETã€MAPPING_ENCODERã€MAPPING_DECODERã€MAPPING_SPEECH_DECODER_PRENETã€MAPPING_SPEECH_DECODER_POSTNETåˆå¹¶
MAPPING_S2S = {
    **MAPPING_SPEECH_ENCODER_PRENET,
    **MAPPING_ENCODER,
    **MAPPING_DECODER,
    **MAPPING_SPEECH_DECODER_PRENET,
    **MAPPING_SPEECH_DECODER_POSTNET,
}

# åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨
TOP_LEVEL_KEYS = []

# åˆ›å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªå­—ç¬¦ä¸²çš„åˆ—è¡¨ï¼ŒæŒ‡æ˜è¦å¿½ç•¥çš„ç‰¹å®šé”®å
IGNORE_KEYS = [
    "encoder.version",
    "encoder.layers.*.norm_k.weight",
    "encoder.layers.*.norm_k.bias",
    "decoder.version",
    "decoder.layers.*.norm_k.weight",
    "decoder.layers.*.norm_k.bias",
    "decoder.pos_emb.pe_k",
    "speech_encoder_prenet.embed_positions._float_tensor",
    "text_decoder_prenet.embed_positions._float_tensor",
]

# åˆ›å»ºä¸€ä¸ªåŒ…å«IGNORE_KEYSçš„åˆ—è¡¨ï¼Œå¹¶æ·»åŠ é¢å¤–çš„å¿½ç•¥é”®
IGNORE_KEYS_S2T = IGNORE_KEYS + [
    "encoder.proj",
    "text_encoder_prenet.*",
    "speech_decoder_prenet.*",
    "speech_decoder_postnet.*",
]

# åˆ›å»ºä¸€ä¸ªåŒ…å«IGNORE_KEYSçš„åˆ—è¡¨ï¼Œå¹¶æ·»åŠ é¢å¤–çš„å¿½ç•¥é”®
IGNORE_KEYS_T2S = IGNORE_KEYS + [
    "encoder.proj",
    "speech_encoder_prenet.*",
    "text_decoder_prenet.*",
    "text_decoder_postnet.*",
]

# åˆ›å»ºä¸€ä¸ªåŒ…å«IGNORE_KEYSçš„åˆ—è¡¨ï¼Œå¹¶æ·»åŠ é¢å¤–çš„å¿½ç•¥é”®
IGNORE_KEYS_S2S = IGNORE_KEYS + [
    "encoder.proj",
    "text_encoder_prenet.*",
    "text_decoder_prenet.*",
    "text_decoder_postnet.*",
]

# é€’å½’è®¾ç½®æƒé‡
def set_recursively(hf_pointer, key, value, full_name, weight_type):
    # é€çº§è·å–å±æ€§
    for attribute in key.split("."):
        hf_pointer = getattr(hf_pointer, attribute)

    # å¦‚æœæƒé‡ç±»å‹ä¸ä¸ºç©ºï¼Œè·å–æƒé‡çš„å½¢çŠ¶
    if weight_type is not None:
        hf_shape = getattr(hf_pointer, weight_type).shape
    else:
        hf_shape = hf_pointer.shape

    # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦ä¸ç»™å®šå€¼çš„å½¢çŠ¶ç›¸ç­‰ï¼Œå¦‚æœä¸ç›¸ç­‰ï¼Œåˆ™æŠ›å‡ºValueError
    if hf_shape != value.shape:
        raise ValueError(
            f"Shape of hf {key + '.' + weight_type if weight_type is not None else ''} is {hf_shape}, but should be"
            f" {value.shape} for {full_name}"
        )

    # æ ¹æ®æƒé‡ç±»å‹è®¾ç½®æƒé‡çš„å€¼
    if weight_type == "weight":
        hf_pointer.weight.data = value
    elif weight_type == "weight_g":
        hf_pointer.weight_g.data = value
    elif weight_type == "weight_v":
        hf_pointer.weight_v.data = value
    elif weight_type == "bias":
        hf_pointer.bias.data = value
    elif weight_type == "running_mean":
        hf_pointer.running_mean.data = value
    elif weight_type == "running_var":
        hf_pointer.running_var.data = value
    elif weight_type == "num_batches_tracked":
        hf_pointer.num_batches_tracked.data = value
    else:
        hf_pointer.data = value

    # è®°å½•æƒé‡åˆå§‹åŒ–çš„ä¿¡æ¯
    logger.info(f"{key + ('.' + weight_type if weight_type is not None else '')} was initialized from {full_name}.")

# æ£€æŸ¥æ˜¯å¦åº”å¿½ç•¥æŒ‡å®šçš„é”®å
def should_ignore(name, ignore_keys):
    for key in ignore_keys:
        if key.endswith(".*"):
            if name.startswith(key[:-1]):
                return True
        elif ".*." in key:
            prefix, suffix = key.split(".*.")
            if prefix in name and suffix in name:
                return True
        elif key in name:
            return True
    return False

# é€’å½’åŠ è½½æƒé‡
def recursively_load_weights(fairseq_dict, hf_model, task):
    # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºè®°å½•æœªä½¿ç”¨çš„æƒé‡
    unused_weights = []

    # å¦‚æœä»»åŠ¡ä¸º"s2t"ï¼Œåˆ™è¿›è¡Œç›¸åº”è®¾ç½®
    if task == "s2t":
        feature_encoder = hf_model.speecht5.encoder.prenet.feature_encoder
        MAPPING = MAPPING_S2T
        IGNORE_KEYS = IGNORE_KEYS_S2T
    # å¦‚æœä»»åŠ¡æ˜¯æ–‡æœ¬è½¬è¯­éŸ³
    elif task == "t2s":
        # ç‰¹å¾ç¼–ç å™¨è®¾ç½®ä¸ºç©º
        feature_encoder = None
        # ä½¿ç”¨æ–‡æœ¬åˆ°è¯­éŸ³çš„æ˜ å°„å’Œå¿½ç•¥çš„é”®
        MAPPING = MAPPING_T2S
        IGNORE_KEYS = IGNORE_KEYS_T2S
    # å¦‚æœä»»åŠ¡æ˜¯è¯­éŸ³åˆ°è¯­éŸ³
    elif task == "s2s":
        # è®¾ç½®ç‰¹å¾ç¼–ç å™¨ä¸ºé¢„è®­ç»ƒç½‘ç»œçš„éŸ³é¢‘t5ç¼–ç å™¨
        feature_encoder = hf_model.speecht5.encoder.prenet.feature_encoder
        # ä½¿ç”¨è¯­éŸ³åˆ°è¯­éŸ³çš„æ˜ å°„å’Œå¿½ç•¥çš„é”®
        MAPPING = MAPPING_S2S
        IGNORE_KEYS = IGNORE_KEYS_S2S
    else:
        # å¦‚æœä»»åŠ¡ä¸æ˜¯æ–‡æœ¬è½¬è¯­éŸ³æˆ–è¯­éŸ³åˆ°è¯­éŸ³ï¼Œåˆ™æŠ¥é”™
        raise ValueError(f"Unsupported task: {task}")

    # éå†fairseq_dictä¸­çš„æ¯ä¸ªé”®å€¼å¯¹
    for name, value in fairseq_dict.items():
        # å¦‚æœåº”è¯¥å¿½ç•¥è¯¥é”®ï¼Œåˆ™è®°å½•æ—¥å¿—å¹¶ä¸”ç»§ç»­ä¸‹ä¸€ä¸ªé”®å€¼å¯¹
        if should_ignore(name, IGNORE_KEYS):
            logger.info(f"{name} was ignored")
            continue

        # æ ‡è®°è¯¥é”®æ˜¯å¦è¢«ä½¿ç”¨
        is_used = False
        # å¦‚æœé”®ååŒ…å«"conv_layers"
        if "conv_layers" in name:
            # è£…è½½å·ç§¯å±‚
            load_conv_layer(
                name,
                value,
                feature_encoder,
                unused_weights,
                hf_model.config.feat_extract_norm == "group",
            )
            # æ ‡è®°è¯¥é”®è¢«ä½¿ç”¨
            is_used = True
        else:
            # éå†MAPPINGä¸­çš„æ¯ä¸ªé”®å€¼å¯¹
            for key, mapped_key in MAPPING.items():
                # å¦‚æœé”®ä¸­åŒ…å«"*"
                if "*" in key:
                    # æ‹†åˆ†keyä¸ºå‰ç¼€å’Œåç¼€
                    prefix, suffix = key.split(".*.")
                    # å¦‚æœåç§°ä¸­åŒ…å«å‰ç¼€å’Œåç¼€
                    if prefix in name and suffix in name:
                        key = suffix
                
                # å¦‚æœé”®åœ¨åç§°ä¸­å­˜åœ¨
                if key in name:
                    # æ ‡è®°è¯¥é”®è¢«ä½¿ç”¨
                    is_used = True
                    # å¦‚æœmapped_keyä¸­åŒ…å«"*"
                    if "*" in mapped_key:
                        # æå–å±‚ç´¢å¼•å¹¶æ›¿æ¢"*"
                        layer_index = name.split(key)[0].split(".")[-2]
                        mapped_key = mapped_key.replace("*", layer_index)
                    # æ ¹æ®åç§°è®¾ç½®æƒé‡ç±»å‹
                    if "weight_g" in name:
                        weight_type = "weight_g"
                    elif "weight_v" in name:
                        weight_type = "weight_v"
                    elif "bias" in name:
                        weight_type = "bias"
                    elif "weight" in name:
                        weight_type = "weight"
                    elif "running_mean" in name:
                        weight_type = "running_mean"
                    elif "running_var" in name:
                        weight_type = "running_var"
                    elif "num_batches_tracked" in name:
                        weight_type = "num_batches_tracked"
                    else:
                        weight_type = None
                    # é€’å½’åœ°è®¾ç½®æƒé‡å€¼
                    set_recursively(hf_model, mapped_key, value, name, weight_type)
                continue
        # å¦‚æœè¯¥é”®æœªè¢«ä½¿ç”¨ï¼Œå°†å…¶æ·»åŠ åˆ°æœªä½¿ç”¨æƒé‡åˆ—è¡¨ä¸­
        if not is_used:
            unused_weights.append(name)

    # è®°å½•æœªä½¿ç”¨çš„æƒé‡
    logger.warning(f"Unused weights: {unused_weights}")
# åŠ è½½å·ç§¯å±‚æƒé‡çš„å‡½æ•°
def load_conv_layer(full_name, value, feature_extractor, unused_weights, use_group_norm):
    # æå–å·ç§¯å±‚åç§°
    name = full_name.split("conv_layers.")[-1]
    # å°†åç§°æ‹†åˆ†æˆåˆ—è¡¨
    items = name.split(".")
    # æå–å±‚ç¼–å·å’Œç±»å‹ç¼–å·
    layer_id = int(items[0])
    type_id = int(items[1])

    # å¤„ç†å·ç§¯å±‚çš„åç½®é¡¹
    if type_id == 0:
        # å¦‚æœåç§°ä¸­åŒ…å«åç½®é¡¹
        if "bias" in name:
            # æ£€æŸ¥å€¼çš„å½¢çŠ¶æ˜¯å¦ä¸æ¨¡å‹ä¸­çš„å½¢çŠ¶ç›¸åŒ¹é…
            if value.shape != feature_extractor.conv_layers[layer_id].conv.bias.data.shape:
                raise ValueError(
                    f"{full_name} has size {value.shape}, but"
                    f" {feature_extractor.conv_layers[layer_id].conv.bias.data.shape} was found."
                )
            # æ›´æ–°æ¨¡å‹çš„åç½®é¡¹
            feature_extractor.conv_layers[layer_id].conv.bias.data = value
            # è®°å½•æ—¥å¿—
            logger.info(f"Feat extract conv layer {layer_id} was initialized from {full_name}.")
        # å¤„ç†å·ç§¯å±‚çš„æƒé‡
        elif "weight" in name:
            # æ£€æŸ¥å€¼çš„å½¢çŠ¶æ˜¯å¦ä¸æ¨¡å‹ä¸­çš„å½¢çŠ¶ç›¸åŒ¹é…
            if value.shape != feature_extractor.conv_layers[layer_id].conv.weight.data.shape:
                raise ValueError(
                    f"{full_name} has size {value.shape}, but"
                    f" {feature_extractor.conv_layers[layer_id].conv.weight.data.shape} was found."
                )
            # æ›´æ–°æ¨¡å‹çš„æƒé‡
            feature_extractor.conv_layers[layer_id].conv.weight.data = value
            # è®°å½•æ—¥å¿—
            logger.info(f"Feat extract conv layer {layer_id} was initialized from {full_name}.")
    # å¤„ç†ç»„å½’ä¸€åŒ–å±‚çš„æƒ…å†µ
    elif (type_id == 2 and not use_group_norm) or (type_id == 2 and layer_id == 0 and use_group_norm):
        # å¤„ç†å½’ä¸€åŒ–å±‚çš„åç½®é¡¹
        if "bias" in name:
            # æ£€æŸ¥å€¼çš„å½¢çŠ¶æ˜¯å¦ä¸æ¨¡å‹ä¸­çš„å½¢çŠ¶ç›¸åŒ¹é…
            if value.shape != feature_extractor.conv_layers[layer_id].layer_norm.bias.data.shape:
                raise ValueError(
                    f"{full_name} has size {value.shape}, but"
                    f" {feature_extractor.conv_layers[layer_id].layer_norm.bias.data.shape} was found."
                )
            # æ›´æ–°æ¨¡å‹çš„åç½®é¡¹
            feature_extractor.conv_layers[layer_id].layer_norm.bias.data = value
            # è®°å½•æ—¥å¿—
            logger.info(f"Feat extract layer norm weight of layer {layer_id} was initialized from {full_name}.")
        # å¤„ç†å½’ä¸€åŒ–å±‚çš„æƒé‡
        elif "weight" in name:
            # æ£€æŸ¥å€¼çš„å½¢çŠ¶æ˜¯å¦ä¸æ¨¡å‹ä¸­çš„å½¢çŠ¶ç›¸åŒ¹é…
            if value.shape != feature_extractor.conv_layers[layer_id].layer_norm.weight.data.shape:
                raise ValueError(
                    f"{full_name} has size {value.shape}, but"
                    f" {feature_extractor.conv_layers[layer_id].layer_norm.weight.data.shape} was found."
                )
            # æ›´æ–°æ¨¡å‹çš„æƒé‡
            feature_extractor.conv_layers[layer_id].layer_norm.weight.data = value
            # è®°å½•æ—¥å¿—
            logger.info(f"Feat extract layer norm weight of layer {layer_id} was initialized from {full_name}.")
    # å¤„ç†å…¶ä»–æƒ…å†µï¼Œå°†æœªä½¿ç”¨çš„æƒé‡æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    else:
        unused_weights.append(full_name)


# ç¦ç”¨æ¢¯åº¦è®¡ç®—çš„è£…é¥°å™¨
@torch.no_grad()
def convert_speecht5_checkpoint(
    task,
    checkpoint_path,
    pytorch_dump_folder_path,
    config_path=None,
    vocab_path=None,
    repo_id=None,
):
    """
    å°†æ¨¡å‹çš„æƒé‡è½¬æ¢åˆ°transformersè®¾è®¡ä¸­ã€‚
    """
    # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œåˆ™åŠ è½½é…ç½®
    if config_path is not None:
        config = SpeechT5Config.from_pretrained(config_path)
    else:
        # å¦åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„é…ç½®å¯¹è±¡
        config = SpeechT5Config()
    # å¦‚æœä»»åŠ¡åç§°ä¸ºâ€œs2tâ€ï¼Œåˆ™å°†æœ€å¤§é•¿åº¦è®¾ç½®ä¸ºæ–‡æœ¬ä½ç½®çš„æœ€å¤§é•¿åº¦ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªç”¨äºè¯­éŸ³åˆ°æ–‡æœ¬çš„æ¨¡å‹å¯¹è±¡
    if task == "s2t":
        config.max_length = config.max_text_positions
        model = SpeechT5ForSpeechToText(config)
    # å¦‚æœä»»åŠ¡åç§°ä¸ºâ€œt2sâ€ï¼Œåˆ™å°†æœ€å¤§è¯­éŸ³ä½ç½®è®¾ç½®ä¸º1876ï¼Œæœ€å¤§æ–‡æœ¬ä½ç½®è®¾ç½®ä¸º600ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªç”¨äºæ–‡æœ¬åˆ°è¯­éŸ³çš„æ¨¡å‹å¯¹è±¡
    elif task == "t2s":
        config.max_speech_positions = 1876
        config.max_text_positions = 600
        config.max_length = config.max_speech_positions
        model = SpeechT5ForTextToSpeech(config)
    # å¦‚æœä»»åŠ¡åç§°ä¸ºâ€œs2sâ€ï¼Œåˆ™å°†æœ€å¤§è¯­éŸ³ä½ç½®è®¾ç½®ä¸º1876ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªç”¨äºè¯­éŸ³åˆ°è¯­éŸ³çš„æ¨¡å‹å¯¹è±¡
    elif task == "s2s":
        config.max_speech_positions = 1876
        config.max_length = config.max_speech_positions
        model = SpeechT5ForSpeechToSpeech(config)
    # å¦‚æœä»»åŠ¡åç§°ä¸ç¬¦åˆä¸Šè¿°æ¡ä»¶ï¼Œåˆ™æŠ›å‡ºæ•°å€¼é”™è¯¯å¹¶æ˜¾ç¤ºä»»åŠ¡åç§°
    else:
        raise ValueError(f"Unknown task name: {task}")

    # å¦‚æœå­˜åœ¨è¯æ±‡è·¯å¾„ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªåŸºäºè¯æ±‡è·¯å¾„çš„tokenizerå¯¹è±¡ï¼Œå¹¶è®¾ç½®æ¨¡å‹çš„æœ€å¤§é•¿åº¦
    if vocab_path:
        tokenizer = SpeechT5Tokenizer(vocab_path, model_max_length=config.max_text_positions)
        # å°†æ©ç æ ‡è®°è®¾ç½®ä¸ºç±»ä¼¼äºæ™®é€šå•è¯çš„è¡Œä¸ºï¼Œå³åŒ…æ‹¬å®ƒå‰é¢çš„ç©ºæ ¼
        mask_token = AddedToken("<mask>", lstrip=True, rstrip=False)
        tokenizer.mask_token = mask_token
        tokenizer.add_special_tokens({"mask_token": mask_token})
        tokenizer.add_tokens(["<ctc_blank>"])

    # åˆ›å»ºä¸€ä¸ªè¯­éŸ³T5ç‰¹å¾æå–å™¨å¯¹è±¡
    feature_extractor = SpeechT5FeatureExtractor()
    # åˆ›å»ºä¸€ä¸ªå¤„ç†å™¨å¯¹è±¡ï¼Œè®¾ç½®tokenizerå’Œç‰¹å¾æå–å™¨ï¼Œç„¶åä¿å­˜åˆ°æŒ‡å®šçš„PyTorchè½¬å‚¨æ–‡ä»¶å¤¹è·¯å¾„
    processor = SpeechT5Processor(tokenizer=tokenizer, feature_extractor=feature_extractor)
    processor.save_pretrained(pytorch_dump_folder_path)

    # åŠ è½½Fairseqæ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œé€’å½’åŠ è½½æƒé‡åˆ°æ¨¡å‹ä¸­çš„å¯¹åº”ä»»åŠ¡ä¸­
    fairseq_checkpoint = torch.load(checkpoint_path)
    recursively_load_weights(fairseq_checkpoint["model"], model, task)

    # å°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šçš„PyTorchè½¬å‚¨æ–‡ä»¶å¤¹è·¯å¾„
    model.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœå­˜åœ¨repo_idï¼Œåˆ™å°†å¤„ç†å™¨å’Œæ¨¡å‹æ¨é€åˆ°hub
    if repo_id:
        print("Pushing to the hub...")
        processor.push_to_hub(repo_id)
        model.push_to_hub(repo_id)
# å¦‚æœè„šæœ¬ä½œä¸ºä¸»ç¨‹åºæ‰§è¡Œ
if __name__ == "__main__":
    # åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser()
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šä»»åŠ¡ç±»å‹ï¼Œé»˜è®¤ä¸º's2t'ï¼Œå¯é€‰å€¼ä¸º's2t', 't2s', 's2s'
    parser.add_argument(
        "--task",
        default="s2t",
        type=str,
        help="Type of the SpeechT5 model you'd like to convert. Should be one of 's2t', 't2s', 's2s'.",
    )
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šfairseqæ¨¡å‹çš„checkpointè·¯å¾„ï¼Œå¿…é¡»æä¾›
    parser.add_argument("--checkpoint_path", required=True, default=None, type=str, help="Path to fairseq checkpoint")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šSentencePieceæ¨¡å‹çš„è·¯å¾„
    parser.add_argument("--vocab_path", default=None, type=str, help="Path to SentencePiece model")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šå¾…è½¬æ¢æ¨¡å‹çš„hfé…ç½®æ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰çš„è·¯å¾„
    parser.add_argument("--config_path", default=None, type=str, help="Path to hf config.json of model to convert")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šè¾“å‡ºPyTorchæ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¿…é¡»æä¾›
    parser.add_argument(
        "--pytorch_dump_folder_path", required=True, default=None, type=str, help="Path to the output PyTorch model."
    )
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šæŒ‡å®šæ˜¯å¦å°†è½¬æ¢åçš„æ¨¡å‹ä¸Šä¼ åˆ°ğŸ¤— hub
    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    # è°ƒç”¨å‡½æ•°convert_speecht5_checkpointï¼Œå°†fairseqæ¨¡å‹è½¬æ¢ä¸ºPyTorchæ¨¡å‹
    convert_speecht5_checkpoint(
        args.task,
        args.checkpoint_path,
        args.pytorch_dump_folder_path,
        args.config_path,
        args.vocab_path,
        args.push_to_hub,
    )
```py  
```