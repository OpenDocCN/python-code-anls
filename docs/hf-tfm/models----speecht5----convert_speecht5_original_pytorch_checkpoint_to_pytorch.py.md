# `.\models\speecht5\convert_speecht5_original_pytorch_checkpoint_to_pytorch.py`

```py
# è®¾ç½®æ–‡ä»¶ç¼–ç ä¸º UTF-8
# ç‰ˆæƒå£°æ˜å’Œè®¸å¯è¯ä¿¡æ¯ï¼ŒæŒ‡å®šè¿™æ®µä»£ç çš„ç‰ˆæƒå½’å±å’Œä½¿ç”¨è®¸å¯
# å¯¼å…¥å‘½ä»¤è¡Œå‚æ•°è§£ææ¨¡å—
import argparse

# å¯¼å…¥ PyTorch åº“
import torch

# å¯¼å…¥ Transformers åº“ä¸­çš„ç›¸å…³ç±»å’Œå‡½æ•°
from transformers import (
    SpeechT5Config,  # å¯¼å…¥ SpeechT5 æ¨¡å‹é…ç½®
    SpeechT5FeatureExtractor,  # å¯¼å…¥ SpeechT5 ç‰¹å¾æå–å™¨
    SpeechT5ForSpeechToSpeech,  # å¯¼å…¥ SpeechT5 è¯­éŸ³åˆ°è¯­éŸ³æ¨¡å‹
    SpeechT5ForSpeechToText,  # å¯¼å…¥ SpeechT5 è¯­éŸ³åˆ°æ–‡æœ¬æ¨¡å‹
    SpeechT5ForTextToSpeech,  # å¯¼å…¥ SpeechT5 æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹
    SpeechT5Processor,  # å¯¼å…¥ SpeechT5 å¤„ç†å™¨
    SpeechT5Tokenizer,  # å¯¼å…¥ SpeechT5 åˆ†è¯å™¨
    logging,  # å¯¼å…¥æ—¥å¿—è®°å½•æ¨¡å—
)
from transformers.tokenization_utils import AddedToken  # å¯¼å…¥ç‰¹å®šçš„åˆ†è¯å·¥å…·ç±»

# è®¾ç½®æ—¥å¿—çš„è¯¦ç»†ç¨‹åº¦ä¸º info
logging.set_verbosity_info()

# è·å–ç‰¹å®šåç§°çš„æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger("transformers.models.speecht5")

# å®šä¹‰æ˜ å°„å­—å…¸ï¼Œå°†æ—§ç‰ˆæœ¬ä¸­çš„æ¨¡å‹å‚æ•°æ˜ å°„åˆ°æ–°ç‰ˆæœ¬ä¸­çš„ç›¸åº”ä½ç½®
MAPPING_SPEECH_ENCODER_PRENET = {
    "speech_encoder_prenet.layer_norm": "speecht5.encoder.prenet.feature_projection.layer_norm",
    "speech_encoder_prenet.post_extract_proj": "speecht5.encoder.prenet.feature_projection.projection",
    "speech_encoder_prenet.pos_conv.0": "speecht5.encoder.prenet.pos_conv_embed.conv",
    "speech_encoder_prenet.mask_emb": "speecht5.encoder.prenet.masked_spec_embed",
}

MAPPING_TEXT_ENCODER_PRENET = {
    "text_encoder_prenet.encoder_prenet.0": "speecht5.encoder.prenet.embed_tokens",
    "text_encoder_prenet.encoder_prenet.1.alpha": "speecht5.encoder.prenet.encode_positions.alpha",
}

MAPPING_SPEECH_DECODER_PRENET = {
    "speech_decoder_prenet.decoder_prenet.0.0.prenet.0.0": "speecht5.decoder.prenet.layers.0",
    "speech_decoder_prenet.decoder_prenet.0.0.prenet.1.0": "speecht5.decoder.prenet.layers.1",
    "speech_decoder_prenet.decoder_prenet.0.1": "speecht5.decoder.prenet.final_layer",
    "speech_decoder_prenet.decoder_prenet.1.alpha": "speecht5.decoder.prenet.encode_positions.alpha",
    "speech_decoder_prenet.spkembs_layer.0": "speecht5.decoder.prenet.speaker_embeds_layer",
}

MAPPING_SPEECH_DECODER_POSTNET = {
    "speech_decoder_postnet.feat_out": "speech_decoder_postnet.feat_out",
    "speech_decoder_postnet.prob_out": "speech_decoder_postnet.prob_out",
    "speech_decoder_postnet.postnet.postnet.0.0": "speech_decoder_postnet.layers.0.conv",
    "speech_decoder_postnet.postnet.postnet.0.1": "speech_decoder_postnet.layers.0.batch_norm",
    "speech_decoder_postnet.postnet.postnet.1.0": "speech_decoder_postnet.layers.1.conv",
    "speech_decoder_postnet.postnet.postnet.1.1": "speech_decoder_postnet.layers.1.batch_norm",
    "speech_decoder_postnet.postnet.postnet.2.0": "speech_decoder_postnet.layers.2.conv",
    "speech_decoder_postnet.postnet.postnet.2.1": "speech_decoder_postnet.layers.2.batch_norm",
}
    # å®šä¹‰ä¸€ä¸ªå­—å…¸ï¼Œå°†æ—§çš„æ¨¡å‹å±‚åç§°æ˜ å°„åˆ°æ–°çš„æ¨¡å‹å±‚åç§°
    "speech_decoder_postnet.postnet.postnet.3.0": "speech_decoder_postnet.layers.3.conv",
    # ç»§ç»­å®šä¹‰å­—å…¸æ˜ å°„
    "speech_decoder_postnet.postnet.postnet.3.1": "speech_decoder_postnet.layers.3.batch_norm",
    # ç»§ç»­å®šä¹‰å­—å…¸æ˜ å°„
    "speech_decoder_postnet.postnet.postnet.4.0": "speech_decoder_postnet.layers.4.conv",
    # ç»§ç»­å®šä¹‰å­—å…¸æ˜ å°„
    "speech_decoder_postnet.postnet.postnet.4.1": "speech_decoder_postnet.layers.4.batch_norm",
}
# æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹çš„æ˜ å°„ï¼Œç”¨äºå°†æ–‡æœ¬è§£ç å™¨çš„é¢„ç½‘ç»œæ˜ å°„åˆ°SpeechT5è§£ç å™¨çš„é¢„ç½‘ç»œ
MAPPING_TEXT_DECODER_PRENET = {
    "text_decoder_prenet.embed_tokens": "speecht5.decoder.prenet.embed_tokens",
}
# æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹çš„æ˜ å°„ï¼Œç”¨äºå°†æ–‡æœ¬è§£ç å™¨çš„åç½‘ç»œæ˜ å°„åˆ°æ–‡æœ¬è§£ç å™¨çš„è¯­è¨€æ¨¡å‹å¤´éƒ¨
MAPPING_TEXT_DECODER_POSTNET = {
    "text_decoder_postnet.output_projection": "text_decoder_postnet.lm_head",
}
# ç¼–ç å™¨çš„æ˜ å°„ï¼Œå°†SpeechT5ç¼–ç å™¨çš„å„ä¸ªå±‚æ˜ å°„åˆ°åŒ…è£…çš„ç¼–ç å™¨çš„å¯¹åº”å±‚
MAPPING_ENCODER = {
    "encoder.layers.*.self_attn.k_proj": "speecht5.encoder.wrapped_encoder.layers.*.attention.k_proj",
    "encoder.layers.*.self_attn.v_proj": "speecht5.encoder.wrapped_encoder.layers.*.attention.v_proj",
    "encoder.layers.*.self_attn.q_proj": "speecht5.encoder.wrapped_encoder.layers.*.attention.q_proj",
    "encoder.layers.*.self_attn.out_proj": "speecht5.encoder.wrapped_encoder.layers.*.attention.out_proj",
    "encoder.layers.*.self_attn_layer_norm": "speecht5.encoder.wrapped_encoder.layers.*.layer_norm",
    "encoder.layers.*.fc1": "speecht5.encoder.wrapped_encoder.layers.*.feed_forward.intermediate_dense",
    "encoder.layers.*.fc2": "speecht5.encoder.wrapped_encoder.layers.*.feed_forward.output_dense",
    "encoder.layers.*.final_layer_norm": "speecht5.encoder.wrapped_encoder.layers.*.final_layer_norm",
    "encoder.layer_norm": "speecht5.encoder.wrapped_encoder.layer_norm",
    "encoder.pos_emb.pe_k": "speecht5.encoder.wrapped_encoder.embed_positions.pe_k",
}
# è§£ç å™¨çš„æ˜ å°„ï¼Œå°†SpeechT5è§£ç å™¨çš„å„ä¸ªå±‚æ˜ å°„åˆ°åŒ…è£…çš„è§£ç å™¨çš„å¯¹åº”å±‚
MAPPING_DECODER = {
    "decoder.layers.*.self_attn.k_proj": "speecht5.decoder.wrapped_decoder.layers.*.self_attn.k_proj",
    "decoder.layers.*.self_attn.v_proj": "speecht5.decoder.wrapped_decoder.layers.*.self_attn.v_proj",
    "decoder.layers.*.self_attn.q_proj": "speecht5.decoder.wrapped_decoder.layers.*.self_attn.q_proj",
    "decoder.layers.*.self_attn.out_proj": "speecht5.decoder.wrapped_decoder.layers.*.self_attn.out_proj",
    "decoder.layers.*.self_attn_layer_norm": "speecht5.decoder.wrapped_decoder.layers.*.self_attn_layer_norm",
    "decoder.layers.*.encoder_attn.k_proj": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn.k_proj",
    "decoder.layers.*.encoder_attn.v_proj": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn.v_proj",
    "decoder.layers.*.encoder_attn.q_proj": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn.q_proj",
    "decoder.layers.*.encoder_attn.out_proj": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn.out_proj",
    "decoder.layers.*.encoder_attn_layer_norm": "speecht5.decoder.wrapped_decoder.layers.*.encoder_attn_layer_norm",
    "decoder.layers.*.fc1": "speecht5.decoder.wrapped_decoder.layers.*.feed_forward.intermediate_dense",
    "decoder.layers.*.fc2": "speecht5.decoder.wrapped_decoder.layers.*.feed_forward.output_dense",
    "decoder.layers.*.final_layer_norm": "speecht5.decoder.wrapped_decoder.layers.*.final_layer_norm",
}
# ä»æ–‡æœ¬åˆ°è¯­éŸ³çš„æ˜ å°„ï¼ŒåŒ…æ‹¬æ–‡æœ¬ç¼–ç å™¨ã€è§£ç å™¨å’Œé¢å¤–çš„é¢„ç½‘ç»œå’Œåç½‘ç»œæ˜ å°„
MAPPING_S2T = {
    **MAPPING_SPEECH_ENCODER_PRENET,
    **MAPPING_ENCODER,
    **MAPPING_DECODER,
    **MAPPING_TEXT_DECODER_PRENET,
    **MAPPING_TEXT_DECODER_POSTNET,
}
# ä»è¯­éŸ³åˆ°æ–‡æœ¬çš„æ˜ å°„ï¼ŒåŒ…æ‹¬æ–‡æœ¬ç¼–ç å™¨ã€è§£ç å™¨å’Œè¯­éŸ³è§£ç å™¨çš„é¢„ç½‘ç»œå’Œåç½‘ç»œæ˜ å°„
MAPPING_T2S = {
    **MAPPING_TEXT_ENCODER_PRENET,
    **MAPPING_ENCODER,
    **MAPPING_DECODER,
    **MAPPING_SPEECH_DECODER_PRENET,
    **MAPPING_SPEECH_DECODER_POSTNET,
}
# å°† MAPPING_SPEECH_ENCODER_PRENET, MAPPING_ENCODER, MAPPING_DECODER,
# MAPPING_SPEECH_DECODER_PRENET, MAPPING_SPEECH_DECODER_POSTNET åˆå¹¶ä¸ºä¸€ä¸ªå­—å…¸
MAPPING_S2S = {
    **MAPPING_SPEECH_ENCODER_PRENET,
    **MAPPING_ENCODER,
    **MAPPING_DECODER,
    **MAPPING_SPEECH_DECODER_PRENET,
    **MAPPING_SPEECH_DECODER_POSTNET,
}

# é¡¶å±‚é”®çš„ç©ºåˆ—è¡¨
TOP_LEVEL_KEYS = []

# å¿½ç•¥çš„é”®åˆ—è¡¨ï¼ŒåŒ…æ‹¬æŸäº›å…·ä½“è·¯å¾„å’Œé€šé…ç¬¦
IGNORE_KEYS = [
    "encoder.version",
    "encoder.layers.*.norm_k.weight",
    "encoder.layers.*.norm_k.bias",
    "decoder.version",
    "decoder.layers.*.norm_k.weight",
    "decoder.layers.*.norm_k.bias",
    "decoder.pos_emb.pe_k",
    "speech_encoder_prenet.embed_positions._float_tensor",
    "text_decoder_prenet.embed_positions._float_tensor",
]

# S2T ä»»åŠ¡ç‰¹å®šçš„å¿½ç•¥é”®åˆ—è¡¨ï¼ŒåŒ…æ‹¬é€šç”¨çš„ IGNORE_KEYS å’Œä¸€äº›é¢å¤–çš„é”®
IGNORE_KEYS_S2T = IGNORE_KEYS + [
    "encoder.proj",
    "text_encoder_prenet.*",
    "speech_decoder_prenet.*",
    "speech_decoder_postnet.*",
]

# T2S ä»»åŠ¡ç‰¹å®šçš„å¿½ç•¥é”®åˆ—è¡¨ï¼ŒåŒ…æ‹¬é€šç”¨çš„ IGNORE_KEYS å’Œä¸€äº›é¢å¤–çš„é”®
IGNORE_KEYS_T2S = IGNORE_KEYS + [
    "encoder.proj",
    "speech_encoder_prenet.*",
    "text_decoder_prenet.*",
    "text_decoder_postnet.*",
]

# S2S ä»»åŠ¡ç‰¹å®šçš„å¿½ç•¥é”®åˆ—è¡¨ï¼ŒåŒ…æ‹¬é€šç”¨çš„ IGNORE_KEYS å’Œä¸€äº›é¢å¤–çš„é”®
IGNORE_KEYS_S2S = IGNORE_KEYS + [
    "encoder.proj",
    "text_encoder_prenet.*",
    "text_decoder_prenet.*",
    "text_decoder_postnet.*",
]

# é€’å½’è®¾ç½®æ¨¡å‹æƒé‡çš„å‡½æ•°
def set_recursively(hf_pointer, key, value, full_name, weight_type):
    # æ ¹æ®é”®å­—ç¬¦ä¸²é€çº§è®¿é—®å¯¹è±¡å±æ€§ï¼Œç›´è‡³æœ€åä¸€çº§
    for attribute in key.split("."):
        hf_pointer = getattr(hf_pointer, attribute)

    # æ ¹æ® weight_type è·å–å½“å‰å±æ€§çš„å½¢çŠ¶
    if weight_type is not None:
        hf_shape = getattr(hf_pointer, weight_type).shape
    else:
        hf_shape = hf_pointer.shape

    # å¦‚æœå½¢çŠ¶ä¸åŒ¹é…ï¼Œåˆ™æŠ›å‡ºå€¼é”™è¯¯å¼‚å¸¸
    if hf_shape != value.shape:
        raise ValueError(
            f"Shape of hf {key + '.' + weight_type if weight_type is not None else ''} is {hf_shape}, but should be"
            f" {value.shape} for {full_name}"
        )

    # æ ¹æ® weight_type è®¾ç½®å±æ€§çš„æ•°æ®å€¼
    if weight_type == "weight":
        hf_pointer.weight.data = value
    elif weight_type == "weight_g":
        hf_pointer.weight_g.data = value
    elif weight_type == "weight_v":
        hf_pointer.weight_v.data = value
    elif weight_type == "bias":
        hf_pointer.bias.data = value
    elif weight_type == "running_mean":
        hf_pointer.running_mean.data = value
    elif weight_type == "running_var":
        hf_pointer.running_var.data = value
    elif weight_type == "num_batches_tracked":
        hf_pointer.num_batches_tracked.data = value
    else:
        hf_pointer.data = value

    # è®°å½•æƒé‡åˆå§‹åŒ–çš„ä¿¡æ¯åˆ°æ—¥å¿—
    logger.info(f"{key + ('.' + weight_type if weight_type is not None else '')} was initialized from {full_name}.")


# åˆ¤æ–­ç»™å®šåç§°æ˜¯å¦åº”è¯¥è¢«å¿½ç•¥çš„å‡½æ•°
def should_ignore(name, ignore_keys):
    for key in ignore_keys:
        if key.endswith(".*"):
            if name.startswith(key[:-1]):
                return True
        elif ".*." in key:
            prefix, suffix = key.split(".*.")
            if prefix in name and suffix in name:
                return True
        elif key in name:
            return True
    return False


# é€’å½’åŠ è½½æƒé‡åˆ°æ¨¡å‹çš„å‡½æ•°
def recursively_load_weights(fairseq_dict, hf_model, task):
    unused_weights = []

    # å¦‚æœä»»åŠ¡æ˜¯ S2T
    if task == "s2t":
        # è·å–ç‰¹å¾ç¼–ç å™¨å¯¹è±¡
        feature_encoder = hf_model.speecht5.encoder.prenet.feature_encoder
        # ä½¿ç”¨ S2T ä»»åŠ¡ç›¸å…³çš„æ˜ å°„å’Œå¿½ç•¥é”®åˆ—è¡¨
        MAPPING = MAPPING_S2T
        IGNORE_KEYS = IGNORE_KEYS_S2T
    elif task == "t2s":
        feature_encoder = None
        MAPPING = MAPPING_T2S  # è®¾ç½®æ˜ å°„è¡¨ä¸º T2S çš„æ˜ å°„è¡¨
        IGNORE_KEYS = IGNORE_KEYS_T2S  # è®¾ç½®å¿½ç•¥åˆ—è¡¨ä¸º T2S çš„å¿½ç•¥åˆ—è¡¨
    elif task == "s2s":
        feature_encoder = hf_model.speecht5.encoder.prenet.feature_encoder  # è·å–ç‰¹å¾ç¼–ç å™¨
        MAPPING = MAPPING_S2S  # è®¾ç½®æ˜ å°„è¡¨ä¸º S2S çš„æ˜ å°„è¡¨
        IGNORE_KEYS = IGNORE_KEYS_S2S  # è®¾ç½®å¿½ç•¥åˆ—è¡¨ä¸º S2S çš„å¿½ç•¥åˆ—è¡¨
    else:
        raise ValueError(f"Unsupported task: {task}")  # æŠ›å‡ºå¼‚å¸¸ï¼Œä»»åŠ¡ä¸æ”¯æŒ

    for name, value in fairseq_dict.items():  # éå† fairseq å­—å…¸çš„æ¯ä¸ªæ¡ç›®
        if should_ignore(name, IGNORE_KEYS):  # åˆ¤æ–­æ˜¯å¦åº”è¯¥å¿½ç•¥å½“å‰æ¡ç›®
            logger.info(f"{name} was ignored")  # è®°å½•æ—¥å¿—ï¼ŒæŒ‡å‡ºè¢«å¿½ç•¥çš„æ¡ç›®
            continue

        is_used = False  # åˆå§‹åŒ–æ˜¯å¦ä½¿ç”¨çš„æ ‡å¿—ä¸º False
        if "conv_layers" in name:  # å¦‚æœæ¡ç›®ååŒ…å« "conv_layers"
            load_conv_layer(
                name,
                value,
                feature_encoder,
                unused_weights,
                hf_model.config.feat_extract_norm == "group",
            )  # è°ƒç”¨åŠ è½½å·ç§¯å±‚å‡½æ•°ï¼ŒåŠ è½½å½“å‰æ¡ç›®
            is_used = True  # è®¾ç½®å·²ä½¿ç”¨æ ‡å¿—ä¸º Trueï¼Œè¡¨ç¤ºå½“å‰æ¡ç›®å·²è¢«ä½¿ç”¨
        else:
            for key, mapped_key in MAPPING.items():  # éå†æ˜ å°„è¡¨ä¸­çš„æ¯ä¸ªæ˜ å°„å…³ç³»
                # mapped_key = "speecht5." + mapped_key if mapped_key not in TOP_LEVEL_KEYS else mapped_key

                if "*" in key:  # å¦‚æœæ˜ å°„é”®ä¸­åŒ…å«é€šé…ç¬¦ *
                    prefix, suffix = key.split(".*.")  # æ‹†åˆ†å‰ç¼€å’Œåç¼€
                    if prefix in name and suffix in name:  # å¦‚æœæ¡ç›®ååŒ…å«å‰ç¼€å’Œåç¼€
                        key = suffix  # ä½¿ç”¨åç¼€ä½œä¸ºå½“å‰é”®

                # if key in name or key.split("w2v_model.")[-1] == name.split(".")[0]:
                if key in name:  # å¦‚æœå½“å‰é”®å­˜åœ¨äºæ¡ç›®åä¸­
                    is_used = True  # è®¾ç½®å·²ä½¿ç”¨æ ‡å¿—ä¸º True
                    if "*" in mapped_key:  # å¦‚æœæ˜ å°„åçš„é”®ä¸­åŒ…å«é€šé…ç¬¦ *
                        layer_index = name.split(key)[0].split(".")[-2]  # æå–å±‚ç´¢å¼•
                        mapped_key = mapped_key.replace("*", layer_index)  # æ›¿æ¢æ˜ å°„é”®ä¸­çš„é€šé…ç¬¦

                    # ç¡®å®šæƒé‡ç±»å‹
                    if "weight_g" in name:
                        weight_type = "weight_g"
                    elif "weight_v" in name:
                        weight_type = "weight_v"
                    elif "bias" in name:
                        weight_type = "bias"
                    elif "weight" in name:
                        weight_type = "weight"
                    elif "running_mean" in name:
                        weight_type = "running_mean"
                    elif "running_var" in name:
                        weight_type = "running_var"
                    elif "num_batches_tracked" in name:
                        weight_type = "num_batches_tracked"
                    else:
                        weight_type = None

                    set_recursively(hf_model, mapped_key, value, name, weight_type)  # é€’å½’è®¾ç½®æ¨¡å‹å‚æ•°

                continue  # ç»§ç»­ä¸‹ä¸€ä¸ªæ˜ å°„å…³ç³»çš„å¤„ç†

        if not is_used:  # å¦‚æœå½“å‰æ¡ç›®æœªè¢«ä½¿ç”¨
            unused_weights.append(name)  # å°†å½“å‰æ¡ç›®åæ·»åŠ åˆ°æœªä½¿ç”¨çš„æƒé‡åˆ—è¡¨ä¸­

    logger.warning(f"Unused weights: {unused_weights}")  # è®°å½•æœªä½¿ç”¨çš„æƒé‡åˆ—è¡¨åˆ°æ—¥å¿—ä¸­
# åŠ è½½å·ç§¯å±‚æ•°æ®åˆ°ç‰¹å¾æå–å™¨ä¸­
def load_conv_layer(full_name, value, feature_extractor, unused_weights, use_group_norm):
    # æ ¹æ®ç‚¹å·åˆ†å‰²å…¨åè·å–å±‚å’Œç±»å‹
    name = full_name.split("conv_layers.")[-1]
    items = name.split(".")
    layer_id = int(items[0])  # æå–å±‚çš„æ ‡è¯†å·
    type_id = int(items[1])   # æå–ç±»å‹çš„æ ‡è¯†å·

    # å¦‚æœç±»å‹æ ‡è¯†ä¸º0ï¼Œå¤„ç†åç½®é¡¹æˆ–æƒé‡é¡¹
    if type_id == 0:
        if "bias" in name:
            # æ£€æŸ¥å€¼çš„å½¢çŠ¶æ˜¯å¦åŒ¹é…ç‰¹å¾æå–å™¨ä¸­å¯¹åº”å·ç§¯å±‚çš„åç½®é¡¹å½¢çŠ¶
            if value.shape != feature_extractor.conv_layers[layer_id].conv.bias.data.shape:
                raise ValueError(
                    f"{full_name} has size {value.shape}, but"
                    f" {feature_extractor.conv_layers[layer_id].conv.bias.data.shape} was found."
                )
            feature_extractor.conv_layers[layer_id].conv.bias.data = value  # è®¾ç½®åç½®é¡¹æ•°æ®
            logger.info(f"Feat extract conv layer {layer_id} was initialized from {full_name}.")  # è®°å½•æ—¥å¿—
        elif "weight" in name:
            # æ£€æŸ¥å€¼çš„å½¢çŠ¶æ˜¯å¦åŒ¹é…ç‰¹å¾æå–å™¨ä¸­å¯¹åº”å·ç§¯å±‚çš„æƒé‡å½¢çŠ¶
            if value.shape != feature_extractor.conv_layers[layer_id].conv.weight.data.shape:
                raise ValueError(
                    f"{full_name} has size {value.shape}, but"
                    f" {feature_extractor.conv_layers[layer_id].conv.weight.data.shape} was found."
                )
            feature_extractor.conv_layers[layer_id].conv.weight.data = value  # è®¾ç½®æƒé‡æ•°æ®
            logger.info(f"Feat extract conv layer {layer_id} was initialized from {full_name}.")  # è®°å½•æ—¥å¿—
    # å¦‚æœç±»å‹æ ‡è¯†ä¸º2ä¸”ä¸ä½¿ç”¨ç»„å½’ä¸€åŒ–ï¼Œæˆ–è€…ç±»å‹æ ‡è¯†ä¸º2ä¸”æ˜¯ç¬¬ä¸€å±‚ä¸”ä½¿ç”¨äº†ç»„å½’ä¸€åŒ–
    elif (type_id == 2 and not use_group_norm) or (type_id == 2 and layer_id == 0 and use_group_norm):
        if "bias" in name:
            # æ£€æŸ¥å€¼çš„å½¢çŠ¶æ˜¯å¦åŒ¹é…ç‰¹å¾æå–å™¨ä¸­å¯¹åº”å±‚å½’ä¸€åŒ–çš„åç½®é¡¹å½¢çŠ¶
            if value.shape != feature_extractor.conv_layers[layer_id].layer_norm.bias.data.shape:
                raise ValueError(
                    f"{full_name} has size {value.shape}, but"
                    f" {feature_extractor.conv_layers[layer_id].layer_norm.bias.data.shape} was found."
                )
            feature_extractor.conv_layers[layer_id].layer_norm.bias.data = value  # è®¾ç½®å±‚å½’ä¸€åŒ–åç½®é¡¹æ•°æ®
            logger.info(f"Feat extract layer norm weight of layer {layer_id} was initialized from {full_name}.")  # è®°å½•æ—¥å¿—
        elif "weight" in name:
            # æ£€æŸ¥å€¼çš„å½¢çŠ¶æ˜¯å¦åŒ¹é…ç‰¹å¾æå–å™¨ä¸­å¯¹åº”å±‚å½’ä¸€åŒ–çš„æƒé‡å½¢çŠ¶
            if value.shape != feature_extractor.conv_layers[layer_id].layer_norm.weight.data.shape:
                raise ValueError(
                    f"{full_name} has size {value.shape}, but"
                    f" {feature_extractor.conv_layers[layer_id].layer_norm.weight.data.shape} was found."
                )
            feature_extractor.conv_layers[layer_id].layer_norm.weight.data = value  # è®¾ç½®å±‚å½’ä¸€åŒ–æƒé‡æ•°æ®
            logger.info(f"Feat extract layer norm weight of layer {layer_id} was initialized from {full_name}.")  # è®°å½•æ—¥å¿—
    else:
        unused_weights.append(full_name)  # å°†æœªä½¿ç”¨çš„æƒé‡åç§°æ·»åŠ åˆ°åˆ—è¡¨ä¸­


@torch.no_grad()
def convert_speecht5_checkpoint(
    task,
    checkpoint_path,
    pytorch_dump_folder_path,
    config_path=None,
    vocab_path=None,
    repo_id=None,
):
    """
    å°†æ¨¡å‹çš„æƒé‡å¤åˆ¶/ç²˜è´´/è°ƒæ•´åˆ°transformersè®¾è®¡ä¸­ã€‚
    """
    if config_path is not None:
        config = SpeechT5Config.from_pretrained(config_path)  # ä»é¢„è®­ç»ƒé…ç½®æ–‡ä»¶åŠ è½½é…ç½®
    else:
        config = SpeechT5Config()  # åˆ›å»ºä¸€ä¸ªé»˜è®¤é…ç½®å¯¹è±¡
    # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©é…ç½®å‚æ•°å’Œæ¨¡å‹
    if task == "s2t":
        config.max_length = config.max_text_positions
        # ä½¿ç”¨ç»™å®šçš„é…ç½®åˆ›å»ºè¯­éŸ³åˆ°æ–‡æœ¬ä»»åŠ¡çš„æ¨¡å‹å¯¹è±¡
        model = SpeechT5ForSpeechToText(config)
    elif task == "t2s":
        config.max_speech_positions = 1876
        config.max_text_positions = 600
        config.max_length = config.max_speech_positions
        # ä½¿ç”¨ç»™å®šçš„é…ç½®åˆ›å»ºæ–‡æœ¬åˆ°è¯­éŸ³ä»»åŠ¡çš„æ¨¡å‹å¯¹è±¡
        model = SpeechT5ForTextToSpeech(config)
    elif task == "s2s":
        config.max_speech_positions = 1876
        config.max_length = config.max_speech_positions
        # ä½¿ç”¨ç»™å®šçš„é…ç½®åˆ›å»ºè¯­éŸ³åˆ°è¯­éŸ³ä»»åŠ¡çš„æ¨¡å‹å¯¹è±¡
        model = SpeechT5ForSpeechToSpeech(config)
    else:
        # å¦‚æœä»»åŠ¡åæœªçŸ¥ï¼Œåˆ™æŠ›å‡ºå€¼é”™è¯¯å¼‚å¸¸
        raise ValueError(f"Unknown task name: {task}")

    if vocab_path:
        # ä½¿ç”¨ç»™å®šçš„è¯æ±‡è¡¨è·¯å¾„å’Œæ¨¡å‹æœ€å¤§é•¿åº¦åˆ›å»ºè¯­éŸ³T5åˆ†è¯å™¨å¯¹è±¡
        tokenizer = SpeechT5Tokenizer(vocab_path, model_max_length=config.max_text_positions)

        # æ·»åŠ ä¸€ä¸ªç‰¹æ®Šçš„æ©ç æ ‡è®°ï¼Œè¡¨ç°å¾—åƒæ™®é€šè¯æ±‡ï¼Œå³åœ¨å…¶å‰é¢åŒ…å«ç©ºæ ¼
        mask_token = AddedToken("<mask>", lstrip=True, rstrip=False)
        tokenizer.mask_token = mask_token
        tokenizer.add_special_tokens({"mask_token": mask_token})  # æ·»åŠ ç‰¹æ®Šæ ‡è®°åˆ°åˆ†è¯å™¨ä¸­
        tokenizer.add_tokens(["<ctc_blank>"])  # æ·»åŠ ç‰¹æ®Šæ ‡è®°åˆ°åˆ†è¯å™¨ä¸­

    # åˆ›å»ºè¯­éŸ³T5ç‰¹å¾æå–å™¨å¯¹è±¡
    feature_extractor = SpeechT5FeatureExtractor()
    # ä½¿ç”¨åˆ†è¯å™¨å’Œç‰¹å¾æå–å™¨åˆ›å»ºè¯­éŸ³T5å¤„ç†å™¨å¯¹è±¡
    processor = SpeechT5Processor(tokenizer=tokenizer, feature_extractor=feature_extractor)
    # å°†å¤„ç†å™¨å¯¹è±¡ä¿å­˜åˆ°æŒ‡å®šçš„PyTorchæ¨¡å‹è½¬å‚¨æ–‡ä»¶å¤¹è·¯å¾„
    processor.save_pretrained(pytorch_dump_folder_path)

    # åŠ è½½Fairseqæ£€æŸ¥ç‚¹ä¸­çš„æƒé‡åˆ°æ¨¡å‹å¯¹è±¡ä¸­
    fairseq_checkpoint = torch.load(checkpoint_path)
    recursively_load_weights(fairseq_checkpoint["model"], model, task)

    # å°†æ¨¡å‹å¯¹è±¡ä¿å­˜åˆ°æŒ‡å®šçš„PyTorchæ¨¡å‹è½¬å‚¨æ–‡ä»¶å¤¹è·¯å¾„
    model.save_pretrained(pytorch_dump_folder_path)

    if repo_id:
        # å¦‚æœå­˜åœ¨repo_idï¼Œåˆ™æ¨é€å¤„ç†å™¨å’Œæ¨¡å‹åˆ°Hubä¸Š
        print("Pushing to the hub...")
        processor.push_to_hub(repo_id)
        model.push_to_hub(repo_id)
if __name__ == "__main__":
    # å¦‚æœå½“å‰è„šæœ¬ä½œä¸ºä¸»ç¨‹åºè¿è¡Œï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹ä»£ç å—

    parser = argparse.ArgumentParser()
    # åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡

    parser.add_argument(
        "--task",
        default="s2t",
        type=str,
        help="Type of the SpeechT5 model you'd like to convert. Should be one of 's2t', 't2s', 's2s'.",
    )
    # æ·»åŠ åä¸º "--task" çš„å‘½ä»¤è¡Œå‚æ•°ï¼ŒæŒ‡å®šé»˜è®¤å€¼ä¸º "s2t"ï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œç”¨äºæŒ‡å®šè¦è½¬æ¢çš„æ¨¡å‹ç±»å‹

    parser.add_argument("--checkpoint_path", required=True, default=None, type=str, help="Path to fairseq checkpoint")
    # æ·»åŠ åä¸º "--checkpoint_path" çš„å¿…éœ€å‘½ä»¤è¡Œå‚æ•°ï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œç”¨äºæŒ‡å®š fairseq æ¨¡å‹çš„æ£€æŸ¥ç‚¹è·¯å¾„

    parser.add_argument("--vocab_path", default=None, type=str, help="Path to SentencePiece model")
    # æ·»åŠ åä¸º "--vocab_path" çš„å¯é€‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œç”¨äºæŒ‡å®š SentencePiece æ¨¡å‹çš„è·¯å¾„

    parser.add_argument("--config_path", default=None, type=str, help="Path to hf config.json of model to convert")
    # æ·»åŠ åä¸º "--config_path" çš„å¯é€‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œç”¨äºæŒ‡å®šè¦è½¬æ¢æ¨¡å‹çš„ HF (Hugging Face) é…ç½®æ–‡ä»¶è·¯å¾„

    parser.add_argument(
        "--pytorch_dump_folder_path", required=True, default=None, type=str, help="Path to the output PyTorch model."
    )
    # æ·»åŠ åä¸º "--pytorch_dump_folder_path" çš„å¿…éœ€å‘½ä»¤è¡Œå‚æ•°ï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œç”¨äºæŒ‡å®šè¾“å‡º PyTorch æ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„

    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
    )
    # æ·»åŠ åä¸º "--push_to_hub" çš„å¯é€‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œç”¨äºæŒ‡å®šåœ¨ ğŸ¤— hub ä¸Šä¸Šä¼ è½¬æ¢åçš„æ¨¡å‹çš„ä½ç½®

    args = parser.parse_args()
    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨ args å˜é‡ä¸­

    convert_speecht5_checkpoint(
        args.task,
        args.checkpoint_path,
        args.pytorch_dump_folder_path,
        args.config_path,
        args.vocab_path,
        args.push_to_hub,
    )
    # è°ƒç”¨å‡½æ•° convert_speecht5_checkpointï¼Œå¹¶ä¼ é€’è§£æåçš„å‘½ä»¤è¡Œå‚æ•°ä½œä¸ºå‡½æ•°çš„å‚æ•°
```