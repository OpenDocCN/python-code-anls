# `.\models\speecht5\convert_hifigan.py`

```py
# è®¾ç½®ç¼–ç æ ¼å¼ä¸º UTF-8

# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import argparse  # ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°

import numpy as np  # ç”¨äºæ•°å€¼è®¡ç®—
import torch  # PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶

from transformers import SpeechT5HifiGan, SpeechT5HifiGanConfig, logging  # å¯¼å…¥ Transformers åº“ä¸­çš„ç›¸å…³æ¨¡å—å’Œç±»

# è®¾ç½®æ—¥å¿—çš„è¯¦ç»†ç¨‹åº¦ä¸º info
logging.set_verbosity_info()

# è·å–åä¸º "transformers.models.speecht5" çš„æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger("transformers.models.speecht5")


def load_weights(checkpoint, hf_model, config):
    # å¯¹æ¨¡å‹åº”ç”¨æƒé‡å½’ä¸€åŒ–æ“ä½œ
    hf_model.apply_weight_norm()

    # åŠ è½½è¾“å…¥å·ç§¯å±‚çš„æƒé‡å’Œåç½®
    hf_model.conv_pre.weight_g.data = checkpoint["input_conv.weight_g"]
    hf_model.conv_pre.weight_v.data = checkpoint["input_conv.weight_v"]
    hf_model.conv_pre.bias.data = checkpoint["input_conv.bias"]

    # åŠ è½½æ¯ä¸ªä¸Šé‡‡æ ·å±‚çš„æƒé‡å’Œåç½®
    for i in range(len(config.upsample_rates)):
        hf_model.upsampler[i].weight_g.data = checkpoint[f"upsamples.{i}.1.weight_g"]
        hf_model.upsampler[i].weight_v.data = checkpoint[f"upsamples.{i}.1.weight_v"]
        hf_model.upsampler[i].bias.data = checkpoint[f"upsamples.{i}.1.bias"]

    # åŠ è½½æ¯ä¸ªæ®‹å·®å—çš„æƒé‡å’Œåç½®
    for i in range(len(config.upsample_rates) * len(config.resblock_kernel_sizes)):
        for j in range(len(config.resblock_dilation_sizes)):
            hf_model.resblocks[i].convs1[j].weight_g.data = checkpoint[f"blocks.{i}.convs1.{j}.1.weight_g"]
            hf_model.resblocks[i].convs1[j].weight_v.data = checkpoint[f"blocks.{i}.convs1.{j}.1.weight_v"]
            hf_model.resblocks[i].convs1[j].bias.data = checkpoint[f"blocks.{i}.convs1.{j}.1.bias"]

            hf_model.resblocks[i].convs2[j].weight_g.data = checkpoint[f"blocks.{i}.convs2.{j}.1.weight_g"]
            hf_model.resblocks[i].convs2[j].weight_v.data = checkpoint[f"blocks.{i}.convs2.{j}.1.weight_v"]
            hf_model.resblocks[i].convs2[j].bias.data = checkpoint[f"blocks.{i}.convs2.{j}.1.bias"]

    # åŠ è½½è¾“å‡ºå·ç§¯å±‚çš„æƒé‡å’Œåç½®
    hf_model.conv_post.weight_g.data = checkpoint["output_conv.1.weight_g"]
    hf_model.conv_post.weight_v.data = checkpoint["output_conv.1.weight_v"]
    hf_model.conv_post.bias.data = checkpoint["output_conv.1.bias"]

    # ç§»é™¤æ¨¡å‹çš„æƒé‡å½’ä¸€åŒ–
    hf_model.remove_weight_norm()


@torch.no_grad()
def convert_hifigan_checkpoint(
    checkpoint_path,
    stats_path,
    pytorch_dump_folder_path,
    config_path=None,
    repo_id=None,
):
    # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä½¿ç”¨é¢„è®­ç»ƒé…ç½®åˆ›å»ºé…ç½®å¯¹è±¡ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    if config_path is not None:
        config = SpeechT5HifiGanConfig.from_pretrained(config_path)
    else:
        config = SpeechT5HifiGanConfig()

    # åˆ›å»º SpeechT5HifiGan æ¨¡å‹å¯¹è±¡
    model = SpeechT5HifiGan(config)

    # åŠ è½½åŸå§‹æ£€æŸ¥ç‚¹æ–‡ä»¶
    orig_checkpoint = torch.load(checkpoint_path)

    # åŠ è½½æƒé‡åˆ°æ¨¡å‹ä¸­
    load_weights(orig_checkpoint["model"]["generator"], model, config)
    # åŠ è½½ä¿å­˜çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œè¿™é‡Œå‡è®¾ stats_path æ˜¯ä¿å­˜çš„ numpy æ•°ç»„çš„æ–‡ä»¶è·¯å¾„
    stats = np.load(stats_path)
    
    # ä»ç»Ÿè®¡ä¿¡æ¯ä¸­æå–å¹³å‡å€¼ï¼Œå¹¶é‡å¡‘ä¸ºä¸€ç»´æ•°ç»„
    mean = stats[0].reshape(-1)
    
    # ä»ç»Ÿè®¡ä¿¡æ¯ä¸­æå–æ ‡åº¦ï¼Œå¹¶é‡å¡‘ä¸ºä¸€ç»´æ•°ç»„
    scale = stats[1].reshape(-1)
    
    # å°†å¹³å‡å€¼è½¬æ¢ä¸º PyTorch çš„ float å¼ é‡ï¼Œå¹¶è®¾ç½®ä¸ºæ¨¡å‹çš„å¹³å‡å€¼å±æ€§
    model.mean = torch.from_numpy(mean).float()
    
    # å°†æ ‡åº¦è½¬æ¢ä¸º PyTorch çš„ float å¼ é‡ï¼Œå¹¶è®¾ç½®ä¸ºæ¨¡å‹çš„æ ‡åº¦å±æ€§
    model.scale = torch.from_numpy(scale).float()
    
    # å°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šçš„ PyTorch è½¬å‚¨æ–‡ä»¶å¤¹è·¯å¾„
    model.save_pretrained(pytorch_dump_folder_path)
    
    # å¦‚æœ repo_id å­˜åœ¨ï¼Œåˆ™å°†æ¨¡å‹æ¨é€åˆ°æŒ‡å®šçš„å­˜å‚¨åº“
    if repo_id:
        print("Pushing to the hub...")
        model.push_to_hub(repo_id)
# å¦‚æœå½“å‰è„šæœ¬è¢«ä½œä¸ºä¸»ç¨‹åºæ‰§è¡Œï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹ä»£ç å—
if __name__ == "__main__":
    # åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser()
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šåŸå§‹æ£€æŸ¥ç‚¹çš„è·¯å¾„ï¼Œå¿…å¡«å‚æ•°
    parser.add_argument("--checkpoint_path", required=True, default=None, type=str, help="Path to original checkpoint")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šstats.npy æ–‡ä»¶çš„è·¯å¾„ï¼Œå¿…å¡«å‚æ•°
    parser.add_argument("--stats_path", required=True, default=None, type=str, help="Path to stats.npy file")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šå¾…è½¬æ¢æ¨¡å‹çš„ HF é…ç½®æ–‡ä»¶ï¼ˆconfig.jsonï¼‰çš„è·¯å¾„ï¼Œå¯é€‰å‚æ•°
    parser.add_argument("--config_path", default=None, type=str, help="Path to hf config.json of model to convert")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šè¾“å‡º PyTorch æ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¿…å¡«å‚æ•°
    parser.add_argument(
        "--pytorch_dump_folder_path", required=True, default=None, type=str, help="Path to the output PyTorch model."
    )
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šæŒ‡å®šæ˜¯å¦å°†è½¬æ¢åçš„æ¨¡å‹ä¸Šä¼ åˆ° ğŸ¤— hub çš„è·¯å¾„ï¼Œå¯é€‰å‚æ•°
    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ args å¯¹è±¡ä¸­
    args = parser.parse_args()
    
    # è°ƒç”¨å‡½æ•° convert_hifigan_checkpoint è¿›è¡Œæ¨¡å‹æ£€æŸ¥ç‚¹çš„è½¬æ¢
    convert_hifigan_checkpoint(
        args.checkpoint_path,     # åŸå§‹æ£€æŸ¥ç‚¹çš„è·¯å¾„
        args.stats_path,          # stats.npy æ–‡ä»¶çš„è·¯å¾„
        args.pytorch_dump_folder_path,   # è¾“å‡º PyTorch æ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„
        args.config_path,         # HF é…ç½®æ–‡ä»¶çš„è·¯å¾„
        args.push_to_hub          # æ˜¯å¦ä¸Šä¼ åˆ° ğŸ¤— hub çš„è·¯å¾„
    )
```