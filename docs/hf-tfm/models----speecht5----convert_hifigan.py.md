# `.\transformers\models\speecht5\convert_hifigan.py`

```
# è®¾ç½®ä»£ç æ–‡ä»¶çš„ç¼–ç æ ¼å¼ä¸ºutf-8
# ç‰ˆæƒå£°æ˜ï¼Œä¿ç•™æ‰€æœ‰æƒåˆ©
# æ ¹æ® Apache è®¸å¯è¯ç‰ˆæœ¬ 2.0 è¿›è¡Œè®¸å¯
# åœ¨éµå®ˆè®¸å¯è¯çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨æ­¤æ–‡ä»¶
# å¯ä»¥åœ¨ä»¥ä¸‹ç½‘å€è·å–è®¸å¯è¯çš„å‰¯æœ¬
# http://www.apache.org/licenses/LICENSE-2.0
# é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æŒ‰"åŸæ ·"åˆ†å‘
# ä¸æä¾›ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿æˆ–æ¡ä»¶
# è¯·å‚é˜…è®¸å¯è¯ä»¥äº†è§£ç‰¹å®šè¯­è¨€è§„å®šçš„æƒé™å’Œ
# é™åˆ¶

"""å°† SpeechT5 HiFi-GAN æ£€æŸ¥ç‚¹è½¬æ¢ä¸ºæ¨¡å‹æƒé‡"""

import argparse  # å¯¼å…¥ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°çš„æ¨¡å—

import numpy as np  # å¯¼å…¥ numpy æ¨¡å—å¹¶å°†å…¶å‘½åä¸º np
import torch  # å¯¼å…¥ torch æ¨¡å—

from transformers import SpeechT5HifiGan, SpeechT5HifiGanConfig, logging  # ä» transformers åº“ä¸­å¯¼å…¥ SpeechT5HifiGanã€SpeechT5HifiGanConfig å’Œ logging

logging.set_verbosity_info()  # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º info
logger = logging.get_logger("transformers.models.speecht5")  # è·å– transformers æ¨¡å—ä¸­ speecht5 æ¨¡å‹çš„æ—¥å¿—è®°å½•å™¨


def load_weights(checkpoint, hf_model, config):
    hf_model.apply_weight_norm()  # åº”ç”¨æƒé‡è§„èŒƒåŒ–

    hf_model.conv_pre.weight_g.data = checkpoint["input_conv.weight_g"]  # è®¾ç½®æ¨¡å‹é¢„å·ç§¯æƒé‡çš„æ•°æ®
    hf_model.conv_pre.weight_v.data = checkpoint["input_conv.weight_v"]  # è®¾ç½®æ¨¡å‹é¢„å·ç§¯æƒé‡çš„æ•°æ®
    hf_model.conv_pre.bias.data = checkpoint["input_conv.bias"]  # è®¾ç½®æ¨¡å‹é¢„å·ç§¯åå·®çš„æ•°æ®

    for i in range(len(config.upsample_rates)):
        hf_model.upsampler[i].weight_g.data = checkpoint[f"upsamples.{i}.1.weight_g"]  # è®¾ç½®æ¨¡å‹ä¸Šé‡‡æ ·æƒé‡çš„æ•°æ®
        hf_model.upsampler[i].weight_v.data = checkpoint[f"upsamples.{i}.1.weight_v"]  # è®¾ç½®æ¨¡å‹ä¸Šé‡‡æ ·æƒé‡çš„æ•°æ®
        hf_model.upsampler[i].bias.data = checkpoint[f"upsamples.{i}.1.bias"]  # è®¾ç½®æ¨¡å‹ä¸Šé‡‡æ ·åå·®çš„æ•°æ®

    for i in range(len(config.upsample_rates) * len(config.resblock_kernel_sizes)):
        for j in range(len(config.resblock_dilation_sizes)):
            hf_model.resblocks[i].convs1[j].weight_g.data = checkpoint[f"blocks.{i}.convs1.{j}.1.weight_g"]  # è®¾ç½®æ¨¡å‹æ®‹å·®å—æƒé‡çš„æ•°æ®
            hf_model.resblocks[i].convs1[j].weight_v.data = checkpoint[f"blocks.{i}.convs1.{j}.1.weight_v"]  # è®¾ç½®æ¨¡å‹æ®‹å·®å—æƒé‡çš„æ•°æ®
            hf_model.resblocks[i].convs1[j].bias.data = checkpoint[f"blocks.{i}.convs1.{j}.1.bias"]  # è®¾ç½®æ¨¡å‹æ®‹å·®å—åå·®çš„æ•°æ®

            hf_model.resblocks[i].convs2[j].weight_g.data = checkpoint[f"blocks.{i}.convs2.{j}.1.weight_g"]  # è®¾ç½®æ¨¡å‹æ®‹å·®å—æƒé‡çš„æ•°æ®
            hf_model.resblocks[i].convs2[j].weight_v.data = checkpoint[f"blocks.{i}.convs2.{j}.1.weight_v"]  # è®¾ç½®æ¨¡å‹æ®‹å·®å—æƒé‡çš„æ•°æ®
            hf_model.resblocks[i].convs2[j].bias.data = checkpoint[f"blocks.{i}.convs2.{j}.1.bias"]  # è®¾ç½®æ¨¡å‹æ®‹å·®å—åå·®çš„æ•°æ®

    hf_model.conv_post.weight_g.data = checkpoint["output_conv.1.weight_g"]  # è®¾ç½®æ¨¡å‹åå·ç§¯æƒé‡çš„æ•°æ®
    hf_model.conv_post.weight_v.data = checkpoint["output_conv.1.weight_v"]  # è®¾ç½®æ¨¡å‹åå·ç§¯æƒé‡çš„æ•°æ®
    hf_model.conv_post.bias.data = checkpoint["output_conv.1.bias"]  # è®¾ç½®æ¨¡å‹åå·ç§¯åå·®çš„æ•°æ®

    hf_model.remove_weight_norm()  # ç§»é™¤æƒé‡è§„èŒƒåŒ–


@torch.no_grad()  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
def convert_hifigan_checkpoint(
    checkpoint_path,
    stats_path,
    pytorch_dump_folder_path,
    config_path=None,
    repo_id=None,
):
    if config_path is not None:
        config = SpeechT5HifiGanConfig.from_pretrained(config_path)  # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä»é¢„è®­ç»ƒæ¨¡å‹åˆ›å»ºé…ç½®
    else:
        config = SpeechT5HifiGanConfig()  # å¦åˆ™ï¼Œä½¿ç”¨é»˜è®¤é…ç½®

    model = SpeechT5HifiGan(config)  # åˆ›å»º SpeechT5HifiGan æ¨¡å‹å¯¹è±¡

    orig_checkpoint = torch.load(checkpoint_path)  # åŠ è½½åŸå§‹æ£€æŸ¥ç‚¹
    load_weights(orig_checkpoint["model"]["generator"], model, config)  # è½¬æ¢æƒé‡
    # ä»æŒ‡å®šè·¯å¾„åŠ è½½ç»Ÿè®¡æ•°æ®æ–‡ä»¶
    stats = np.load(stats_path)
    # è·å–ç»Ÿè®¡æ•°æ®ä¸­çš„å¹³å‡å€¼ï¼Œå¹¶å°†å…¶é‡å¡‘ä¸ºä¸€ç»´æ•°ç»„
    mean = stats[0].reshape(-1)
    # è·å–ç»Ÿè®¡æ•°æ®ä¸­çš„æ ‡å‡†å·®ï¼Œå¹¶å°†å…¶é‡å¡‘ä¸ºä¸€ç»´æ•°ç»„
    scale = stats[1].reshape(-1)
    # å°†å¹³å‡å€¼è½¬æ¢ä¸º Torch å¼ é‡å¹¶è®¾ç½®ä¸ºæ¨¡å‹çš„å¹³å‡å€¼
    model.mean = torch.from_numpy(mean).float()
    # å°†æ ‡å‡†å·®è½¬æ¢ä¸º Torch å¼ é‡å¹¶è®¾ç½®ä¸ºæ¨¡å‹çš„æ ‡å‡†å·®
    model.scale = torch.from_numpy(scale).float()

    # å°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
    model.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœæœ‰ repo_id æä¾›ï¼Œåˆ™å°†æ¨¡å‹æ¨é€åˆ°å¹³å°
    if repo_id:
        print("Pushing to the hub...")
        # æ¨é€æ¨¡å‹åˆ°å¹³å°
        model.push_to_hub(repo_id)
# å¦‚æœå½“å‰è„šæœ¬ä½œä¸ºä¸»ç¨‹åºè¿è¡Œ
if __name__ == "__main__":
    # åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser()
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼ŒæŒ‡å®šåŸå§‹æ£€æŸ¥ç‚¹çš„è·¯å¾„ï¼Œå¿…éœ€å‚æ•°
    parser.add_argument("--checkpoint_path", required=True, default=None, type=str, help="Path to original checkpoint")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼ŒæŒ‡å®šstats.npyæ–‡ä»¶çš„è·¯å¾„ï¼Œå¿…éœ€å‚æ•°
    parser.add_argument("--stats_path", required=True, default=None, type=str, help="Path to stats.npy file")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼ŒæŒ‡å®šæ¨¡å‹è½¬æ¢çš„é…ç½®æ–‡ä»¶config.jsonçš„è·¯å¾„ï¼Œå¯é€‰å‚æ•°
    parser.add_argument("--config_path", default=None, type=str, help="Path to hf config.json of model to convert")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼ŒæŒ‡å®šè¾“å‡ºPyTorchæ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¿…éœ€å‚æ•°
    parser.add_argument(
        "--pytorch_dump_folder_path", required=True, default=None, type=str, help="Path to the output PyTorch model."
    )
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼ŒæŒ‡å®šæ˜¯å¦å°†è½¬æ¢åçš„æ¨¡å‹ä¸Šä¼ åˆ°ğŸ¤— hubçš„ä½ç½®ï¼Œå¯é€‰å‚æ•°
    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    # è°ƒç”¨å‡½æ•°ï¼Œå°† HiFi-GAN æ£€æŸ¥ç‚¹è½¬æ¢ä¸º PyTorch æ¨¡å‹
    convert_hifigan_checkpoint(
        args.checkpoint_path,  # åŸå§‹æ£€æŸ¥ç‚¹è·¯å¾„
        args.stats_path,  # stats.npy æ–‡ä»¶è·¯å¾„
        args.pytorch_dump_folder_path,  # è¾“å‡º PyTorch æ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„
        args.config_path,  # æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
        args.push_to_hub,  # æ˜¯å¦ä¸Šä¼ è‡³ğŸ¤— hubçš„ä½ç½®
    )
```