# `.\models\seggpt\convert_seggpt_to_hf.py`

```py
# coding=utf-8
# Copyright 2024 The HuggingFace Inc. team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Convert SegGPT checkpoints from the original repository.

URL: https://github.com/baaivision/Painter/tree/main/SegGPT
"""


import argparse  # å¯¼å…¥å‘½ä»¤è¡Œå‚æ•°è§£ææ¨¡å—

import requests  # å¯¼å…¥å¤„ç† HTTP è¯·æ±‚çš„æ¨¡å—
import torch  # å¯¼å…¥ PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
from PIL import Image  # å¯¼å…¥å¤„ç†å›¾åƒçš„æ¨¡å—

from transformers import SegGptConfig, SegGptForImageSegmentation, SegGptImageProcessor  # å¯¼å…¥ SegGPT ç›¸å…³æ¨¡å—
from transformers.utils import logging  # å¯¼å…¥æ—¥å¿—æ¨¡å—

logging.set_verbosity_info()  # è®¾ç½®æ—¥å¿—çš„è¯¦ç»†ç¨‹åº¦ä¸º info çº§åˆ«
logger = logging.get_logger(__name__)  # è·å–å½“å‰æ¨¡å—çš„æ—¥å¿—è®°å½•å™¨


# here we list all keys to be renamed (original name on the left, our name on the right)
# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œåˆ—å‡ºéœ€è¦é‡å‘½åçš„æ‰€æœ‰é”®å€¼å¯¹ï¼ˆå·¦è¾¹æ˜¯åŸå§‹åç§°ï¼Œå³è¾¹æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„åç§°ï¼‰
def create_rename_keys(config):
    rename_keys = []  # åˆå§‹åŒ–ç©ºçš„é‡å‘½åé”®å€¼å¯¹åˆ—è¡¨

    # fmt: off

    # rename embedding and its parameters
    # é‡å‘½ååµŒå…¥å’Œå…¶å‚æ•°
    rename_keys.append(("patch_embed.proj.weight", "model.embeddings.patch_embeddings.projection.weight"))
    rename_keys.append(("patch_embed.proj.bias", "model.embeddings.patch_embeddings.projection.bias"))
    rename_keys.append(("mask_token", "model.embeddings.mask_token"))
    rename_keys.append(("segment_token_x", "model.embeddings.segment_token_input"))
    rename_keys.append(("segment_token_y", "model.embeddings.segment_token_prompt"))
    rename_keys.append(("type_token_cls", "model.embeddings.type_token_semantic"))
    rename_keys.append(("type_token_ins", "model.embeddings.type_token_instance"))
    rename_keys.append(("pos_embed", "model.embeddings.position_embeddings"))

    # rename decoder and other
    # é‡å‘½åè§£ç å™¨å’Œå…¶ä»–éƒ¨åˆ†
    rename_keys.append(("norm.weight", "model.encoder.layernorm.weight"))
    rename_keys.append(("norm.bias", "model.encoder.layernorm.bias"))
    rename_keys.append(("decoder_embed.weight", "decoder.decoder_embed.weight"))
    rename_keys.append(("decoder_embed.bias", "decoder.decoder_embed.bias"))
    rename_keys.append(("decoder_pred.0.weight", "decoder.decoder_pred.conv.weight"))
    rename_keys.append(("decoder_pred.0.bias", "decoder.decoder_pred.conv.bias"))
    rename_keys.append(("decoder_pred.1.weight", "decoder.decoder_pred.layernorm.weight"))
    rename_keys.append(("decoder_pred.1.bias", "decoder.decoder_pred.layernorm.bias"))
    rename_keys.append(("decoder_pred.3.weight", "decoder.decoder_pred.head.weight"))
    rename_keys.append(("decoder_pred.3.bias", "decoder.decoder_pred.head.bias"))

    # rename blocks

    # fmt: on
    # éå†ä» 0 åˆ° config.num_hidden_layers-1 çš„èŒƒå›´ï¼Œè¿›è¡Œé‡å‘½åé”®çš„æ·»åŠ 
    for i in range(config.num_hidden_layers):
        # æ·»åŠ æ³¨æ„åŠ›å±‚çš„æƒé‡é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.attn.qkv.weight", f"model.encoder.layers.{i}.attention.qkv.weight"))
        # æ·»åŠ æ³¨æ„åŠ›å±‚çš„åç½®é¡¹é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.attn.qkv.bias", f"model.encoder.layers.{i}.attention.qkv.bias"))
        # æ·»åŠ æ³¨æ„åŠ›å±‚æŠ•å½±å±‚æƒé‡çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.attn.proj.weight", f"model.encoder.layers.{i}.attention.proj.weight"))
        # æ·»åŠ æ³¨æ„åŠ›å±‚æŠ•å½±å±‚åç½®é¡¹çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.attn.proj.bias", f"model.encoder.layers.{i}.attention.proj.bias"))
        # æ·»åŠ æ³¨æ„åŠ›å±‚ç›¸å¯¹ä½ç½®ç¼–ç ï¼ˆæ°´å¹³æ–¹å‘ï¼‰çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.attn.rel_pos_h", f"model.encoder.layers.{i}.attention.rel_pos_h"))
        # æ·»åŠ æ³¨æ„åŠ›å±‚ç›¸å¯¹ä½ç½®ç¼–ç ï¼ˆå‚ç›´æ–¹å‘ï¼‰çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.attn.rel_pos_w", f"model.encoder.layers.{i}.attention.rel_pos_w"))

        # æ·»åŠ å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰çš„ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚æƒé‡çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.mlp.fc1.weight", f"model.encoder.layers.{i}.mlp.lin1.weight"))
        # æ·»åŠ å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰çš„ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚åç½®é¡¹çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.mlp.fc1.bias", f"model.encoder.layers.{i}.mlp.lin1.bias"))
        # æ·»åŠ å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰çš„ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚æƒé‡çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.mlp.fc2.weight", f"model.encoder.layers.{i}.mlp.lin2.weight"))
        # æ·»åŠ å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰çš„ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚åç½®é¡¹çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.mlp.fc2.bias", f"model.encoder.layers.{i}.mlp.lin2.bias"))

        # æ·»åŠ æ³¨æ„åŠ›å±‚å‰å±‚å½’ä¸€åŒ–æƒé‡çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.norm1.weight", f"model.encoder.layers.{i}.layernorm_before.weight"))
        # æ·»åŠ æ³¨æ„åŠ›å±‚å‰å±‚å½’ä¸€åŒ–åç½®é¡¹çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.norm1.bias", f"model.encoder.layers.{i}.layernorm_before.bias"))
        # æ·»åŠ æ³¨æ„åŠ›å±‚åå±‚å½’ä¸€åŒ–æƒé‡çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.norm2.weight", f"model.encoder.layers.{i}.layernorm_after.weight"))
        # æ·»åŠ æ³¨æ„åŠ›å±‚åå±‚å½’ä¸€åŒ–åç½®é¡¹çš„é‡å‘½åé”®
        rename_keys.append((f"blocks.{i}.norm2.bias", f"model.encoder.layers.{i}.layernorm_after.bias"))

    # è¿”å›æ‰€æœ‰æ·»åŠ çš„é‡å‘½åé”®åˆ—è¡¨
    return rename_keys
# ä»å­—å…¸ä¸­ç§»é™¤æ—§é”®ï¼Œå¹¶å°†å…¶å¯¹åº”çš„å€¼å­˜å‚¨åœ¨å˜é‡valä¸­
def rename_key(dct, old, new):
    val = dct.pop(old)
    # å°†æ—§é”®çš„å€¼å­˜å‚¨åœ¨æ–°é”®ä¸‹
    dct[new] = val


# å‡†å¤‡è¾“å…¥æ•°æ®ï¼ŒåŒ…æ‹¬å›¾åƒå’Œæ©æ¨¡
def prepare_input():
    # å®šä¹‰è¾“å…¥å›¾åƒçš„URL
    image_input_url = (
        "https://raw.githubusercontent.com/baaivision/Painter/main/SegGPT/SegGPT_inference/examples/hmbb_2.jpg"
    )
    # å®šä¹‰æç¤ºå›¾åƒçš„URL
    image_prompt_url = (
        "https://raw.githubusercontent.com/baaivision/Painter/main/SegGPT/SegGPT_inference/examples/hmbb_1.jpg"
    )
    # å®šä¹‰æ©æ¨¡å›¾åƒçš„URL
    mask_prompt_url = (
        "https://raw.githubusercontent.com/baaivision/Painter/main/SegGPT/SegGPT_inference/examples/hmbb_1_target.png"
    )

    # ä½¿ç”¨requestsåº“è·å–å¹¶æ‰“å¼€è¾“å…¥å›¾åƒã€æç¤ºå›¾åƒå’Œæ©æ¨¡å›¾åƒçš„äºŒè¿›åˆ¶æ•°æ®
    image_input = Image.open(requests.get(image_input_url, stream=True).raw)
    image_prompt = Image.open(requests.get(image_prompt_url, stream=True).raw)
    mask_prompt = Image.open(requests.get(mask_prompt_url, stream=True).raw)

    # è¿”å›å‡†å¤‡å¥½çš„å›¾åƒå’Œæ©æ¨¡
    return image_input, image_prompt, mask_prompt


# ä½¿ç”¨torch.no_grad()è£…é¥°å™¨ï¼Œä»¥ç¡®ä¿åœ¨æ¨ç†æ—¶ä¸ä¼šè®¡ç®—æ¢¯åº¦
@torch.no_grad()
def convert_seggpt_checkpoint(args):
    # ä»å‚æ•°ä¸­è·å–æ¨¡å‹åç§°ã€PyTorchæ¨¡å‹ä¿å­˜è·¯å¾„ã€æ˜¯å¦éªŒè¯logitsä»¥åŠæ˜¯å¦æ¨é€åˆ°Hub
    model_name = args.model_name
    pytorch_dump_folder_path = args.pytorch_dump_folder_path
    verify_logits = args.verify_logits
    push_to_hub = args.push_to_hub

    # å®šä¹‰SegGPTæ¨¡å‹çš„é…ç½®ï¼Œé»˜è®¤ä½¿ç”¨SegGptConfig()
    config = SegGptConfig()

    # åŠ è½½åŸå§‹çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œä»Hugging Faceæ¨¡å‹ä¸­å¿ƒåŠ è½½
    checkpoint_url = "https://huggingface.co/BAAI/SegGpt/blob/main/seggpt_vit_large.pth"
    original_state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location="cpu")["model"]

    # åˆ›å»ºæ–°çš„çŠ¶æ€å­—å…¸å‰¯æœ¬
    new_state_dict = original_state_dict.copy()

    # è°ƒç”¨create_rename_keyså‡½æ•°åˆ›å»ºéœ€è¦é‡å‘½åçš„é”®åˆ—è¡¨
    rename_keys = create_rename_keys(config)

    # éå†é‡å‘½åé”®åˆ—è¡¨ï¼Œå°†æ–°æ—§é”®æ˜ å°„åº”ç”¨äºnew_state_dict
    for src, dest in rename_keys:
        rename_key(new_state_dict, src, dest)

    # å®ä¾‹åŒ–SegGptForImageSegmentationæ¨¡å‹
    model = SegGptForImageSegmentation(config)
    model.eval()

    # åŠ è½½æ–°çš„çŠ¶æ€å­—å…¸åˆ°æ¨¡å‹ä¸­ï¼Œstrict=Falseè¡¨ç¤ºå…è®¸ç¼ºå¤±é”®å’Œå¤šä½™é”®
    missing_keys, unexpected_keys = model.load_state_dict(new_state_dict, strict=False)
    # æ‰“å°ç¼ºå¤±çš„é”®å’Œå¤šä½™çš„é”®
    print("Missing keys:", missing_keys)
    print("Unexpected keys:", unexpected_keys)

    # å‡†å¤‡è¾“å…¥æ•°æ®ï¼Œè·å–è¾“å…¥å›¾åƒã€æç¤ºå›¾åƒå’Œæ©æ¨¡
    input_img, prompt_img, prompt_mask = prepare_input()

    # å®ä¾‹åŒ–SegGptImageProcessor
    image_processor = SegGptImageProcessor()

    # ä½¿ç”¨image_processorå¤„ç†è¾“å…¥å›¾åƒã€æç¤ºå›¾åƒå’Œæ©æ¨¡ï¼Œè¿”å›PyTorchå¼ é‡
    inputs = image_processor(images=input_img, prompt_images=prompt_img, prompt_masks=prompt_mask, return_tensors="pt")

    # é¢„æœŸçš„æç¤ºåƒç´ å€¼å¼ é‡ï¼Œç”¨äºéªŒè¯ç»“æœ
    expected_prompt_pixel_values = torch.tensor(
        [
            [[-0.6965, -0.6965, -0.6965], [-0.6965, -0.6965, -0.6965], [-0.6965, -0.6965, -0.6965]],
            [[1.6583, 1.6583, 1.6583], [1.6583, 1.6583, 1.6583], [1.6583, 1.6583, 1.6583]],
            [[2.3088, 2.3088, 2.3088], [2.3088, 2.3088, 2.3088], [2.3088, 2.3088, 2.3088]],
        ]
    )

    # é¢„æœŸçš„åƒç´ å€¼å¼ é‡ï¼Œç”¨äºéªŒè¯ç»“æœ
    expected_pixel_values = torch.tensor(
        [
            [[1.6324, 1.6153, 1.5810], [1.6153, 1.5982, 1.5810], [1.5810, 1.5639, 1.5639]],
            [[1.2731, 1.2556, 1.2206], [1.2556, 1.2381, 1.2031], [1.2206, 1.2031, 1.1681]],
            [[1.6465, 1.6465, 1.6465], [1.6465, 1.6465, 1.6465], [1.6291, 1.6291, 1.6291]],
        ]
    )
    # å®šä¹‰æœŸæœ›çš„åƒç´ å€¼ï¼Œè¿™é‡Œä½¿ç”¨ torch.tensor åˆ›å»ºå¼ é‡
    expected_prompt_masks = torch.tensor(
        [
            [[-2.1179, -2.1179, -2.1179], [-2.1179, -2.1179, -2.1179], [-2.1179, -2.1179, -2.1179]],
            [[-2.0357, -2.0357, -2.0357], [-2.0357, -2.0357, -2.0357], [-2.0357, -2.0357, -2.0357]],
            [[-1.8044, -1.8044, -1.8044], [-1.8044, -1.8044, -1.8044], [-1.8044, -1.8044, -1.8044]],
        ]
    )

    # æ£€æŸ¥æ¨¡å‹è¾“å…¥çš„åƒç´ å€¼æ˜¯å¦ä¸æœŸæœ›çš„åƒç´ å€¼æ¥è¿‘ï¼Œè®¾ç½®å®¹å¿åº¦ä¸º 1e-4
    assert torch.allclose(inputs.pixel_values[0, :, :3, :3], expected_pixel_values, atol=1e-4)
    # æ£€æŸ¥æ¨¡å‹è¾“å…¥çš„æç¤ºåƒç´ å€¼æ˜¯å¦ä¸æœŸæœ›çš„åƒç´ å€¼æ¥è¿‘ï¼Œè®¾ç½®å®¹å¿åº¦ä¸º 1e-4
    assert torch.allclose(inputs.prompt_pixel_values[0, :, :3, :3], expected_prompt_values, atol=1e-4)
    # æ£€æŸ¥æ¨¡å‹è¾“å…¥çš„æç¤ºæ©ç æ˜¯å¦ä¸æœŸæœ›çš„æ©ç æ¥è¿‘ï¼Œè®¾ç½®å®¹å¿åº¦ä¸º 1e-4
    assert torch.allclose(inputs.prompt_masks[0, :, :3, :3], expected_prompt_masks, atol=1e-4)

    # è®¾ç½®éšæœºç§å­ä¸º 2
    torch.manual_seed(2)
    # ä½¿ç”¨æ¨¡å‹å¤„ç†ç»™å®šçš„è¾“å…¥
    outputs = model(**inputs)
    # æ‰“å°æ¨¡å‹è¾“å‡º
    print(outputs)

    # å¦‚æœéœ€è¦éªŒè¯ logitsï¼Œæ£€æŸ¥æ¨¡å‹è¾“å‡ºçš„é¢„æµ‹æ©ç æ˜¯å¦ä¸æœŸæœ›çš„è¾“å‡ºæ¥è¿‘ï¼Œè®¾ç½®å®¹å¿åº¦ä¸º 1e-4
    if verify_logits:
        expected_output = torch.tensor(
            [
                [[-2.1208, -2.1190, -2.1198], [-2.1237, -2.1228, -2.1227], [-2.1232, -2.1226, -2.1228]],
                [[-2.0405, -2.0396, -2.0403], [-2.0434, -2.0434, -2.0433], [-2.0428, -2.0432, -2.0434]],
                [[-1.8102, -1.8088, -1.8099], [-1.8131, -1.8126, -1.8129], [-1.8130, -1.8128, -1.8131]],
            ]
        )
        # æ£€æŸ¥æ¨¡å‹è¾“å‡ºçš„é¢„æµ‹æ©ç æ˜¯å¦ä¸æœŸæœ›çš„è¾“å‡ºæ¥è¿‘ï¼Œè®¾ç½®å®¹å¿åº¦ä¸º 1e-4
        assert torch.allclose(outputs.pred_masks[0, :, :3, :3], expected_output, atol=1e-4)
        # æ‰“å°éªŒè¯é€šè¿‡ä¿¡æ¯
        print("Looks good!")
    else:
        # å¦‚æœä¸éœ€è¦éªŒè¯ logitsï¼Œåˆ™æ‰“å°è½¬æ¢å®Œæˆä¿¡æ¯
        print("Converted without verifying logits")

    # å¦‚æœæŒ‡å®šäº† PyTorch å¯¼å‡ºæ–‡ä»¶å¤¹è·¯å¾„
    if pytorch_dump_folder_path is not None:
        # æ‰“å°ä¿å­˜æ¨¡å‹å’Œå¤„ç†å™¨çš„ä¿¡æ¯
        print(f"Saving model and processor for {model_name} to {pytorch_dump_folder_path}")
        # å°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        model.save_pretrained(pytorch_dump_folder_path)
        # å°†å›¾åƒå¤„ç†å™¨ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        image_processor.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœéœ€è¦æ¨é€åˆ° Hub
    if push_to_hub:
        # æ‰“å°æ¨é€æ¨¡å‹å’Œå¤„ç†å™¨åˆ° Hub çš„ä¿¡æ¯
        print(f"Pushing model and processor for {model_name} to hub")
        # æ¨é€æ¨¡å‹åˆ° Hub
        model.push_to_hub(f"EduardoPacheco/{model_name}")
        # æ¨é€å›¾åƒå¤„ç†å™¨åˆ° Hub
        image_processor.push_to_hub(f"EduardoPacheco/{model_name}")
if __name__ == "__main__":
    # åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser()
    
    # æ·»åŠ å¿…éœ€çš„å‚æ•°
    parser.add_argument(
        "--model_name",
        default="seggpt-vit-large",
        type=str,
        choices=["seggpt-vit-large"],
        help="Name of the SegGpt model you'd like to convert.",
    )
    
    parser.add_argument(
        "--pytorch_dump_folder_path",
        default=None,
        type=str,
        help="Path to the output PyTorch model directory."
    )
    
    # æ·»åŠ å¯é€‰çš„å‚æ•°
    parser.add_argument(
        "--verify_logits",
        action="store_false",
        help="Whether or not to verify the logits against the original implementation.",
    )
    
    parser.add_argument(
        "--push_to_hub",
        action="store_true",
        help="Whether or not to push the converted model to the ğŸ¤— hub."
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    
    # è°ƒç”¨å‡½æ•° convert_seggpt_checkpointï¼Œä¼ å…¥è§£æåçš„å‚æ•°å¯¹è±¡ args
    convert_seggpt_checkpoint(args)
```