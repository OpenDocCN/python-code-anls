# `.\models\mask2former\convert_mask2former_original_pytorch_checkpoint_to_pytorch.py`

```
# coding=utf-8
# Copyright 2022 Meta Platforms, Inc. and The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import json
import sys
from argparse import ArgumentParser
from dataclasses import dataclass
from pathlib import Path
from pprint import pformat
from typing import Any, Dict, Iterator, List, Set, Tuple

import requests
import torch
import torchvision.transforms as T
from detectron2.checkpoint import DetectionCheckpointer
from detectron2.config import get_cfg
from detectron2.projects.deeplab import add_deeplab_config
from huggingface_hub import hf_hub_download
from PIL import Image
from torch import Tensor, nn

# å¯¼å…¥ transformers ç›¸å…³æ¨¡å—å’Œç±»
from transformers import (
    Mask2FormerConfig,
    Mask2FormerForUniversalSegmentation,
    Mask2FormerImageProcessor,
    Mask2FormerModel,
    SwinConfig,
)
from transformers.models.mask2former.modeling_mask2former import (
    Mask2FormerForUniversalSegmentationOutput,
    Mask2FormerModelOutput,
)
from transformers.utils import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º info
logging.set_verbosity_info()
# è·å–æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger()

# è®¾å®šéšæœºæ•°ç§å­ä¸º 0
torch.manual_seed(0)


class TrackedStateDict:
    def __init__(self, to_track: Dict):
        """This class "tracks" a python dictionary by keeping track of which item is accessed.

        Args:
            to_track (Dict): The dictionary we wish to track
        """
        self.to_track = to_track
        self._seen: Set[str] = set()

    def __getitem__(self, key: str) -> Any:
        return self.to_track[key]

    def __setitem__(self, key: str, item: Any):
        self._seen.add(key)
        self.to_track[key] = item

    def diff(self) -> List[str]:
        """This method returns a set difference between the keys in the tracked state dict and the one we have access so far.
        This is an effective method to check if we have update all the keys

        Returns:
            List[str]: List of keys not yet updated
        """
        return set(self.to_track.keys()) - self._seen

    def copy(self) -> Dict:
        # proxy the call to the internal dictionary
        return self.to_track.copy()


# å‡†å¤‡ä¸€ä¸ªå›¾ç‰‡æ•°æ®ï¼Œç”¨äºåç»­éªŒè¯ç»“æœ
def prepare_img():
    url = "http://images.cocodataset.org/val2017/000000039769.jpg"
    # é€šè¿‡ URL è·å–å›¾ç‰‡æ•°æ®æµ
    img_data = requests.get(url, stream=True).raw
    # æ‰“å¼€å¹¶è¿”å›å›¾åƒå¯¹è±¡
    im = Image.open(img_data)
    return im


@dataclass
class Args:
    """Fake command line arguments needed by mask2former/detectron implementation"""

    config_file: str
# ä»å‚æ•° `args` ä¸­è·å–é…ç½®ï¼ŒåŠ è½½é…ç½®æ–‡ä»¶å’Œå‘½ä»¤è¡Œå‚æ•°
def setup_cfg(args: Args):
    # è°ƒç”¨ `get_cfg()` å‡½æ•°åˆ›å»ºé…ç½®å¯¹è±¡ `cfg`
    cfg = get_cfg()
    # æ·»åŠ  DeepLab ç›¸å…³çš„é…ç½®åˆ° `cfg` ä¸­
    add_deeplab_config(cfg)
    # æ·»åŠ  MaskFormer2 ç›¸å…³çš„é…ç½®åˆ° `cfg` ä¸­
    add_maskformer2_config(cfg)
    # ä»æŒ‡å®šçš„é…ç½®æ–‡ä»¶ `args.config_file` ä¸­åˆå¹¶é…ç½®åˆ° `cfg` ä¸­
    cfg.merge_from_file(args.config_file)
    # å†»ç»“é…ç½®ï¼Œé˜²æ­¢ä¿®æ”¹
    cfg.freeze()
    # è¿”å›é…ç½®å¯¹è±¡ `cfg`
    return cfg


# å°†åŸå§‹ Mask2Former é…ç½®è½¬æ¢ä¸ºæˆ‘ä»¬å®šä¹‰çš„ ImageProcessor
class OriginalMask2FormerConfigToOursConverter:
# å°†åŸå§‹ Mask2Former é…ç½®è½¬æ¢ä¸ºæˆ‘ä»¬å®šä¹‰çš„ ImageProcessor
class OriginalMask2FormerConfigToImageProcessorConverter:
    # å°†åŸå§‹é…ç½®å¯¹è±¡è½¬æ¢ä¸º Mask2FormerImageProcessor å®ä¾‹
    def __call__(self, original_config: object) -> Mask2FormerImageProcessor:
        # è·å–åŸå§‹é…ç½®ä¸­çš„æ¨¡å‹å’Œè¾“å…¥ä¿¡æ¯
        model = original_config.MODEL
        model_input = original_config.INPUT

        # è¿”å›ä¸€ä¸ª Mask2FormerImageProcessor å®ä¾‹ï¼Œä½¿ç”¨æ ‡å‡†åŒ–åçš„åƒç´ å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä»¥åŠå…¶ä»–ç›¸å…³é…ç½®
        return Mask2FormerImageProcessor(
            image_mean=(torch.tensor(model.PIXEL_MEAN) / 255).tolist(),
            image_std=(torch.tensor(model.PIXEL_STD) / 255).tolist(),
            size=model_input.MIN_SIZE_TEST,
            max_size=model_input.MAX_SIZE_TEST,
            num_labels=model.SEM_SEG_HEAD.NUM_CLASSES,
            ignore_index=model.SEM_SEG_HEAD.IGNORE_VALUE,
            size_divisibility=32,
        )


# å°†åŸå§‹ Mask2Former æ£€æŸ¥ç‚¹è½¬æ¢ä¸ºæˆ‘ä»¬å®šä¹‰çš„æ£€æŸ¥ç‚¹
class OriginalMask2FormerCheckpointToOursConverter:
    # åˆå§‹åŒ–è½¬æ¢å™¨ï¼Œæ¥æ”¶åŸå§‹æ¨¡å‹å’Œé…ç½®
    def __init__(self, original_model: nn.Module, config: Mask2FormerConfig):
        self.original_model = original_model
        self.config = config

    # ä»æºçŠ¶æ€å­—å…¸ä¸­å¼¹å‡ºæ‰€æœ‰æŒ‡å®šçš„é‡å‘½åé”®ï¼Œå°†å…¶æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
    def pop_all(self, renamed_keys: List[Tuple[str, str]], dst_state_dict: StateDict, src_state_dict: StateDict):
        for src_key, dst_key in renamed_keys:
            dst_state_dict[dst_key] = src_state_dict.pop(src_key)

    # æ›¿æ¢ MaskFormer Swin Transformer çš„éª¨å¹²éƒ¨åˆ†
    def replace_maskformer_swin_backbone(
        self, dst_state_dict: StateDict, src_state_dict: StateDict, config: Mask2FormerConfig
    ):
        # å£°æ˜ç›®æ ‡å‰ç¼€å’Œæºå‰ç¼€
        dst_prefix: str = "transformer_module.decoder"
        src_prefix: str = "sem_seg_head.predictor"

        # é‡å‘½åé”®åˆ—è¡¨åœ¨ `dst_state_dict` å’Œ `src_state_dict` ä¹‹é—´è¿›è¡Œè½¬æ¢
        renamed_keys = self.rename_keys_in_masked_attention_decoder(dst_state_dict, src_state_dict)

        # æ·»åŠ æ›´å¤šçš„é‡å‘½åé”®
        renamed_keys.extend(
            [
                (f"{src_prefix}.decoder_norm.weight", f"{dst_prefix}.layernorm.weight"),
                (f"{src_prefix}.decoder_norm.bias", f"{dst_prefix}.layernorm.bias"),
            ]
        )

        mlp_len = 3
        # éå† MLP å±‚ï¼Œå¹¶æ·»åŠ ç›¸åº”çš„é‡å‘½åé”®
        for i in range(mlp_len):
            renamed_keys.extend(
                [
                    (
                        f"{src_prefix}.mask_embed.layers.{i}.weight",
                        f"{dst_prefix}.mask_predictor.mask_embedder.{i}.0.weight",
                    ),
                    (
                        f"{src_prefix}.mask_embed.layers.{i}.bias",
                        f"{dst_prefix}.mask_predictor.mask_embedder.{i}.0.bias",
                    ),
                ]
            )

        # å¼¹å‡ºæ‰€æœ‰çš„é‡å‘½åé”®ï¼Œå¹¶æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
        self.pop_all(renamed_keys, dst_state_dict, src_state_dict)
    # å°† Transformer è§£ç å™¨çš„è‡ªæ³¨æ„åŠ›å±‚çš„æƒé‡å’Œåç½®ä»æºçŠ¶æ€å­—å…¸ä¸­å¼¹å‡ºå¹¶æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
    def replace_keys_qkv_transformer_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict):
        # ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­çš„é”®å‰ç¼€
        dst_prefix: str = "transformer_module.decoder.layers"
        # æºçŠ¶æ€å­—å…¸ä¸­çš„é”®å‰ç¼€
        src_prefix: str = "sem_seg_head.predictor"
        
        # éå† Transformer è§£ç å™¨çš„æ¯ä¸€å±‚
        for i in range(self.config.decoder_layers - 1):
            # è¯»å–è‡ªæ³¨æ„åŠ›å±‚çš„è¾“å…¥æŠ•å½±å±‚çš„æƒé‡å’Œåç½®
            in_proj_weight = src_state_dict.pop(
                f"{src_prefix}.transformer_self_attention_layers.{i}.self_attn.in_proj_weight"
            )
            in_proj_bias = src_state_dict.pop(
                f"{src_prefix}.transformer_self_attention_layers.{i}.self_attn.in_proj_bias"
            )
            
            # å°†æŸ¥è¯¢ã€é”®å’Œå€¼çš„æŠ•å½±æƒé‡å’Œåç½®æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
            dst_state_dict[f"{dst_prefix}.{i}.self_attn.q_proj.weight"] = in_proj_weight[:256, :]
            dst_state_dict[f"{dst_prefix}.{i}.self_attn.q_proj.bias"] = in_proj_bias[:256]
            dst_state_dict[f"{dst_prefix}.{i}.self_attn.k_proj.weight"] = in_proj_weight[256:512, :]
            dst_state_dict[f"{dst_prefix}.{i}.self_attn.k_proj.bias"] = in_proj_bias[256:512]
            dst_state_dict[f"{dst_prefix}.{i}.self_attn.v_proj.weight"] = in_proj_weight[-256:, :]
            dst_state_dict[f"{dst_prefix}.{i}.self_attn.v_proj.bias"] = in_proj_bias[-256:]

    # æ›¿æ¢ Transformer æ¨¡å—çš„é”®åç§°ï¼Œå¹¶å°†å…¶ä»æºçŠ¶æ€å­—å…¸ç§»åŠ¨åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
    def replace_transformer_module(self, dst_state_dict: StateDict, src_state_dict: StateDict):
        # ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­çš„é”®å‰ç¼€
        dst_prefix: str = "transformer_module"
        # æºçŠ¶æ€å­—å…¸ä¸­çš„é”®å‰ç¼€
        src_prefix: str = "sem_seg_head.predictor"

        # è°ƒç”¨æ›¿æ¢æ©è”½æ³¨æ„åŠ›è§£ç å™¨çš„æ–¹æ³•
        self.replace_masked_attention_decoder(dst_state_dict, src_state_dict)

        # å®šä¹‰è¦é‡å‘½åçš„é”®å¯¹
        renamed_keys = [
            (f"{src_prefix}.query_embed.weight", f"{dst_prefix}.queries_embedder.weight"),
            (f"{src_prefix}.query_feat.weight", f"{dst_prefix}.queries_features.weight"),
            (f"{src_prefix}.level_embed.weight", f"{dst_prefix}.level_embed.weight"),
        ]

        # ä»æºçŠ¶æ€å­—å…¸ä¸­ç§»é™¤æ‰€æœ‰é‡å‘½åçš„é”®ï¼Œå¹¶å°†å®ƒä»¬æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
        self.pop_all(renamed_keys, dst_state_dict, src_state_dict)
        
        # è°ƒç”¨æ›¿æ¢ Transformer è§£ç å™¨ä¸­æŸ¥è¯¢ã€é”®ã€å€¼çš„æŠ•å½±æƒé‡å’Œåç½®çš„æ–¹æ³•
        self.replace_keys_qkv_transformer_decoder(dst_state_dict, src_state_dict)

    # æ›¿æ¢é€šç”¨åˆ†å‰²æ¨¡å—çš„é”®åç§°ï¼Œå¹¶å°†å…¶ä»æºçŠ¶æ€å­—å…¸ç§»åŠ¨åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
    def replace_universal_segmentation_module(self, dst_state_dict: StateDict, src_state_dict: StateDict):
        # ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­çš„é”®å‰ç¼€ï¼ˆç©ºå­—ç¬¦ä¸²è¡¨ç¤ºç›´æ¥æ›¿æ¢ï¼‰
        dst_prefix: str = ""
        # æºçŠ¶æ€å­—å…¸ä¸­çš„é”®å‰ç¼€
        src_prefix: str = "sem_seg_head.predictor"

        # å®šä¹‰è¦é‡å‘½åçš„é”®å¯¹
        renamed_keys = [
            (f"{src_prefix}.class_embed.weight", f"{dst_prefix}class_predictor.weight"),
            (f"{src_prefix}.class_embed.bias", f"{dst_prefix}class_predictor.bias"),
        ]

        # è®°å½•æ—¥å¿—ï¼ŒæŒ‡ç¤ºæ­£åœ¨æ›¿æ¢çš„é”®
        logger.info(f"Replacing keys {pformat(renamed_keys)}")
        
        # ä»æºçŠ¶æ€å­—å…¸ä¸­ç§»é™¤æ‰€æœ‰é‡å‘½åçš„é”®ï¼Œå¹¶å°†å®ƒä»¬æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
        self.pop_all(renamed_keys, dst_state_dict, src_state_dict)
    # å°†ä¼ å…¥çš„ mask2former å¯¹è±¡çš„çŠ¶æ€å­—å…¸è½¬æ¢ä¸ºå¯è¿½è¸ªçš„çŠ¶æ€å­—å…¸å¯¹è±¡
    dst_state_dict = TrackedStateDict(mask2former.state_dict())
    # è·å–åŸå§‹æ¨¡å‹çš„çŠ¶æ€å­—å…¸
    src_state_dict = self.original_model.state_dict()

    # æ›¿æ¢ç›®æ ‡æ¨¡å‹ä¸­çš„åƒç´ æ¨¡å—
    self.replace_pixel_module(dst_state_dict, src_state_dict)
    # æ›¿æ¢ç›®æ ‡æ¨¡å‹ä¸­çš„ Transformer æ¨¡å—
    self.replace_transformer_module(dst_state_dict, src_state_dict)

    # è®°å½•å¹¶è¾“å‡ºæœªå¤åˆ¶æˆåŠŸçš„é”®çš„ä¿¡æ¯
    logger.info(f"Missed keys are {pformat(dst_state_dict.diff())}")
    # è®°å½•å¹¶è¾“å‡ºæœªå¤åˆ¶çš„é”®çš„ä¿¡æ¯
    logger.info(f"Not copied keys are {pformat(src_state_dict.keys())}")
    # è¾“å‡ºè½¬æ¢å®Œæˆçš„ä¿¡æ¯
    logger.info("ğŸ™Œ Done")

    # ä»è¿½è¸ªçš„çŠ¶æ€å­—å…¸ä¸­é€‰å–éœ€è¦è¿½è¸ªçš„é”®ï¼Œæ„æˆæ–°çš„çŠ¶æ€å­—å…¸
    state_dict = {key: dst_state_dict[key] for key in dst_state_dict.to_track.keys()}
    # åŠ è½½æ–°çš„çŠ¶æ€å­—å…¸åˆ° mask2former å¯¹è±¡ä¸­
    mask2former.load_state_dict(state_dict)
    # è¿”å›æ›´æ–°åçš„ mask2former å¯¹è±¡
    return mask2former

def convert_universal_segmentation(
    self, mask2former: Mask2FormerForUniversalSegmentation
) -> Mask2FormerForUniversalSegmentation:
    # å°†ä¼ å…¥çš„ mask2former å¯¹è±¡çš„çŠ¶æ€å­—å…¸è½¬æ¢ä¸ºå¯è¿½è¸ªçš„çŠ¶æ€å­—å…¸å¯¹è±¡
    dst_state_dict = TrackedStateDict(mask2former.state_dict())
    # è·å–åŸå§‹æ¨¡å‹çš„çŠ¶æ€å­—å…¸
    src_state_dict = self.original_model.state_dict()

    # æ›¿æ¢é€šç”¨åˆ†å‰²æ¨¡å—
    self.replace_universal_segmentation_module(dst_state_dict, src_state_dict)

    # ä»è¿½è¸ªçš„çŠ¶æ€å­—å…¸ä¸­é€‰å–éœ€è¦è¿½è¸ªçš„é”®ï¼Œæ„æˆæ–°çš„çŠ¶æ€å­—å…¸
    state_dict = {key: dst_state_dict[key] for key in dst_state_dict.to_track.keys()}
    # åŠ è½½æ–°çš„çŠ¶æ€å­—å…¸åˆ° mask2former å¯¹è±¡ä¸­
    mask2former.load_state_dict(state_dict)

    # è¿”å›æ›´æ–°åçš„ mask2former å¯¹è±¡
    return mask2former

@staticmethod
def using_dirs(checkpoints_dir: Path, config_dir: Path) -> Iterator[Tuple[object, Path, Path]]:
    # è·å– checkpoints_dir ç›®å½•ä¸‹æ‰€æœ‰åç¼€ä¸º .pkl çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    checkpoints: List[Path] = checkpoints_dir.glob("**/*.pkl")

    # éå†æ¯ä¸ª checkpoint è·¯å¾„
    for checkpoint in checkpoints:
        # è¾“å‡ºæ­£åœ¨è½¬æ¢çš„ä¿¡æ¯åŠå…¶æ–‡ä»¶åï¼ˆä¸å¸¦åç¼€ï¼‰
        logger.info(f"ğŸ’ª Converting {checkpoint.stem}")

        # æŸ¥æ‰¾å…³è”çš„é…ç½®æ–‡ä»¶

        # æ•°æ®é›†åç§°ï¼Œä¾‹å¦‚ 'coco'
        dataset_name = checkpoint.parents[2].stem
        # å¦‚æœæ•°æ®é›†åç§°ä¸º "ade"ï¼Œåˆ™æ›¿æ¢ä¸º "ade20k"
        if dataset_name == "ade":
            dataset_name = dataset_name.replace("ade", "ade20k")

        # åˆ†å‰²ä»»åŠ¡ç±»å‹ï¼Œä¾‹å¦‚ 'instance-segmentation'
        segmentation_task = checkpoint.parents[1].stem

        # ä¸ checkpoint ç›¸å…³è”çš„é…ç½®æ–‡ä»¶å
        config_file_name = f"{checkpoint.parents[0].stem}.yaml"

        # æ„å»ºé…ç½®æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        config: Path = config_dir / dataset_name / segmentation_task / "swin" / config_file_name
        # è¿”å›é…ç½®æ–‡ä»¶è·¯å¾„å’Œç›¸åº”çš„ checkpoint è·¯å¾„çš„è¿­ä»£å™¨
        yield config, checkpoint
# å®šä¹‰ä¸€ä¸ªæµ‹è¯•å‡½æ•°ï¼Œç”¨äºæ¯”è¾ƒåŸå§‹æ¨¡å‹å’Œæˆ‘ä»¬çš„æ¨¡å‹çš„æ€§èƒ½
def test(
    original_model,  # åŸå§‹æ¨¡å‹
    our_model: Mask2FormerForUniversalSegmentation,  # æˆ‘ä»¬çš„æ¨¡å‹ï¼Œç‰¹å®šç±»å‹ä¸º Mask2FormerForUniversalSegmentation
    image_processor: Mask2FormerImageProcessor,  # å›¾åƒå¤„ç†å™¨ï¼Œç”¨äºå‡†å¤‡å›¾åƒæ•°æ®
    tolerance: float,  # å®¹å¿åº¦ï¼Œç”¨äºæ¯”è¾ƒæ•°å€¼æ—¶çš„è¯¯å·®å…è®¸èŒƒå›´
):
    with torch.no_grad():  # ä½¿ç”¨ torch.no_grad() ç¦ç”¨æ¢¯åº¦è®¡ç®—
        original_model = original_model.eval()  # å°†åŸå§‹æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        our_model = our_model.eval()  # å°†æˆ‘ä»¬çš„æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

        im = prepare_img()  # å‡†å¤‡å›¾åƒæ•°æ®
        x = image_processor(images=im, return_tensors="pt")["pixel_values"]  # ä½¿ç”¨å›¾åƒå¤„ç†å™¨å¤„ç†å›¾åƒå¹¶è¿”å›åƒç´ å€¼å¼ é‡

        original_model_backbone_features = original_model.backbone(x.clone())  # æå–åŸå§‹æ¨¡å‹çš„éª¨å¹²ç‰¹å¾
        our_model_output: Mask2FormerModelOutput = our_model.model(x.clone(), output_hidden_states=True)  # ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹ï¼Œè·å–è¾“å‡ºå¹¶åŒ…æ‹¬éšè—çŠ¶æ€

        # æµ‹è¯•éª¨å¹²ç‰¹å¾
        for original_model_feature, our_model_feature in zip(
            original_model_backbone_features.values(), our_model_output.encoder_hidden_states
        ):
            assert torch.allclose(
                original_model_feature, our_model_feature, atol=tolerance
            ), "The backbone features are not the same."

        # æµ‹è¯•åƒç´ è§£ç å™¨
        mask_features, _, multi_scale_features = original_model.sem_seg_head.pixel_decoder.forward_features(
            original_model_backbone_features
        )

        for original_model_feature, our_model_feature in zip(
            multi_scale_features, our_model_output.pixel_decoder_hidden_states
        ):
            assert torch.allclose(
                original_model_feature, our_model_feature, atol=tolerance
            ), "The pixel decoder feature are not the same"

        # æµ‹è¯•å®Œæ•´æ¨¡å‹
        tr_complete = T.Compose(
            [T.Resize((384, 384)), T.ToTensor()],
        )
        y = (tr_complete(im) * 255.0).to(torch.int).float()  # è½¬æ¢å›¾åƒæ•°æ®åˆ°æŒ‡å®šç±»å‹å’ŒèŒƒå›´

        # ä¿®æ”¹åŸå§‹çš„ Mask2Former ä»£ç ä»¥è¿”å›æ©ç å’Œç±»åˆ« logits
        original_class_logits, original_mask_logits = original_model([{"image": y.clone().squeeze(0)}])

        our_model_out: Mask2FormerForUniversalSegmentationOutput = our_model(x.clone())
        our_mask_logits = our_model_out.masks_queries_logits  # è·å–æˆ‘ä»¬æ¨¡å‹çš„æ©ç  logits
        our_class_logits = our_model_out.class_queries_logits  # è·å–æˆ‘ä»¬æ¨¡å‹çš„ç±»åˆ« logits

        assert original_mask_logits.shape == our_mask_logits.shape, "Output masks shapes are not matching."
        assert original_class_logits.shape == our_class_logits.shape, "Output class logits shapes are not matching."
        assert torch.allclose(
            original_class_logits, our_class_logits, atol=tolerance
        ), "The class logits are not the same."
        assert torch.allclose(
            original_mask_logits, our_mask_logits, atol=tolerance
        ), "The predicted masks are not the same."

        logger.info("âœ… Test passed!")  # è®°å½•æµ‹è¯•é€šè¿‡ä¿¡æ¯


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºä»æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ä¸­è·å–æ¨¡å‹åç§°
def get_model_name(checkpoint_file: Path):
    # model_name_raw æ˜¯æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„çš„çˆ¶ç›®å½•å
    model_name_raw: str = checkpoint_file.parents[0].stem

    # segmentation_task_name å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼šinstance-segmentationã€panoptic-segmentationã€semantic-segmentation
    segmentation_task_name: str = checkpoint_file.parents[1].stem
    # æ£€æŸ¥åˆ†å‰²ä»»åŠ¡åç§°æ˜¯å¦åœ¨é¢„å®šä¹‰çš„åˆ—è¡¨ä¸­ï¼Œå¦‚æœä¸åœ¨åˆ™å¼•å‘å€¼é”™è¯¯å¼‚å¸¸
    if segmentation_task_name not in ["instance-segmentation", "panoptic-segmentation", "semantic-segmentation"]:
        raise ValueError(
            f"{segmentation_task_name} must be wrong since acceptable values are: instance-segmentation,"
            " panoptic-segmentation, semantic-segmentation."
        )

    # æå–æ•°æ®é›†åç§°ï¼Œåº”ä¸ºä»¥ä¸‹ä¹‹ä¸€ï¼š`coco`, `ade`, `cityscapes`, `mapillary-vistas`
    dataset_name: str = checkpoint_file.parents[2].stem
    if dataset_name not in ["coco", "ade", "cityscapes", "mapillary-vistas"]:
        raise ValueError(
            f"{dataset_name} must be wrong since we didn't find 'coco' or 'ade' or 'cityscapes' or 'mapillary-vistas'"
            " in it "
        )

    # è®¾ç½®æ¨¡å‹çš„éª¨å¹²ç½‘ç»œç±»å‹ä¸º "swin"
    backbone = "swin"

    # å®šä¹‰å¯æ¥å—çš„éª¨å¹²ç½‘ç»œç±»å‹åˆ—è¡¨
    backbone_types = ["tiny", "small", "base_IN21k", "base", "large"]

    # ä»æ¨¡å‹åç§°ä¸­ç­›é€‰å‡ºå­˜åœ¨äºéª¨å¹²ç½‘ç»œç±»å‹åˆ—è¡¨ä¸­çš„ç±»å‹ï¼Œå¹¶ç”¨è¿å­—ç¬¦æ›¿æ¢ä¸‹åˆ’çº¿
    backbone_type = list(filter(lambda x: x in model_name_raw, backbone_types))[0].replace("_", "-")

    # ç»„è£…æ¨¡å‹åç§°ï¼Œæ ¼å¼ä¸º "mask2former-{backbone}-{backbone_type}-{dataset_name}-{segmentation_task_name.split('-')[0]}"
    model_name = f"mask2former-{backbone}-{backbone_type}-{dataset_name}-{segmentation_task_name.split('-')[0]}"

    # è¿”å›ç”Ÿæˆçš„æ¨¡å‹åç§°
    return model_name
if __name__ == "__main__":
    # åˆ›å»ºå‘½ä»¤è¡Œè§£æå™¨å¯¹è±¡ï¼Œè®¾ç½®æè¿°ä¿¡æ¯
    parser = ArgumentParser(
        description="Command line to convert the original mask2formers (with swin backbone) to our implementations."
    )

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•° --checkpoints_dirï¼Œç±»å‹ä¸º Pathï¼Œç”¨äºæŒ‡å®šæ¨¡å‹æ£€æŸ¥ç‚¹æ‰€åœ¨çš„ç›®å½•è·¯å¾„
    parser.add_argument(
        "--checkpoints_dir",
        type=Path,
        help=(
            "A directory containing the model's checkpoints. The directory has to have the following structure:"
            " <DIR_NAME>/<DATASET_NAME>/<SEGMENTATION_TASK_NAME>/<CONFIG_NAME>.pkl"
        ),
    )

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•° --configs_dirï¼Œç±»å‹ä¸º Pathï¼Œç”¨äºæŒ‡å®šæ¨¡å‹é…ç½®æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•è·¯å¾„
    parser.add_argument(
        "--configs_dir",
        type=Path,
        help=(
            "A directory containing the model's configs, see detectron2 doc. The directory has to have the following"
            " structure: <DIR_NAME>/<DATASET_NAME>/<SEGMENTATION_TASK_NAME>/<CONFIG_NAME>.yaml"
        ),
    )

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•° --mask2former_dirï¼Œç±»å‹ä¸º Pathï¼Œå¿…é€‰å‚æ•°ï¼Œç”¨äºæŒ‡å®š Mask2Former çš„åŸå§‹å®ç°ä»£ç æ‰€åœ¨çš„ç›®å½•è·¯å¾„
    parser.add_argument(
        "--mask2former_dir",
        required=True,
        type=Path,
        help=(
            "A path to Mask2Former's original implementation directory. You can download from here:"
            " https://github.com/facebookresearch/Mask2Former"
        ),
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()

    # å°†å‘½ä»¤è¡Œå‚æ•°èµ‹å€¼ç»™ç›¸åº”å˜é‡
    checkpoints_dir: Path = args.checkpoints_dir
    config_dir: Path = args.configs_dir
    mask2former_dir: Path = args.mask2former_dir

    # å°† Mask2Former çš„çˆ¶ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­ï¼Œä»¥ä¾¿å¯¼å…¥åŸå§‹ Mask2Former çš„é…ç½®å’Œæ¨¡å‹
    sys.path.append(str(mask2former_dir.parent))

    # ä»åŸå§‹æºä»£ç ä»“åº“å¯¼å…¥åŸå§‹ Mask2Former çš„é…ç½®å’Œæ¨¡å‹
    from Mask2Former.mask2former.config import add_maskformer2_config
    from Mask2Former.mask2former.maskformer_model import MaskFormer as OriginalMask2Former

    # ä½¿ç”¨å¾ªç¯å¤„ç†æ¯å¯¹é…ç½®æ–‡ä»¶å’Œæ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œè½¬æ¢æˆæˆ‘ä»¬çš„å®ç°æ ¼å¼
    for config_file, checkpoint_file in OriginalMask2FormerCheckpointToOursConverter.using_dirs(
        checkpoints_dir, config_dir
        ):
            # ä»æ£€æŸ¥ç‚¹æ–‡ä»¶è·å–æ¨¡å‹åç§°
            model_name = get_model_name(checkpoint_file)
            # ä½¿ç”¨åŸå§‹é…ç½®æ–‡ä»¶åˆ›å»ºå›¾åƒå¤„ç†å™¨ï¼Œå¹¶è¿›è¡Œè®¾ç½®
            image_processor = OriginalMask2FormerConfigToImageProcessorConverter()(
                setup_cfg(Args(config_file=config_file))
            )
            # è®¾ç½®å›¾åƒå¤„ç†å™¨çš„å°ºå¯¸ä¸ºå›ºå®šå€¼
            image_processor.size = {"height": 384, "width": 384}

            # ä½¿ç”¨åŸå§‹é…ç½®æ–‡ä»¶åˆ›å»ºé…ç½®å¯¹è±¡
            original_config = setup_cfg(Args(config_file=config_file))
            # ä»åŸå§‹é…ç½®åˆ›å»º Mask2Former æ¨¡å‹çš„å‚æ•°
            mask2former_kwargs = OriginalMask2Former.from_config(original_config)
            # åˆ›å»ºå¹¶åˆå§‹åŒ–åŸå§‹ Mask2Former æ¨¡å‹
            original_model = OriginalMask2Former(**mask2former_kwargs).eval()

            # åŠ è½½æ¨¡å‹çš„æ£€æŸ¥ç‚¹
            DetectionCheckpointer(original_model).load(str(checkpoint_file))

            # å°†åŸå§‹é…ç½®è½¬æ¢ä¸ºæˆ‘ä»¬çš„ Mask2Former é…ç½®å¯¹è±¡
            config: Mask2FormerConfig = OriginalMask2FormerConfigToOursConverter()(original_config)
            # åˆ›å»ºå¹¶åˆå§‹åŒ–æˆ‘ä»¬çš„ Mask2Former æ¨¡å‹
            mask2former = Mask2FormerModel(config=config).eval()

            # å°†åŸå§‹ Mask2Former æ¨¡å‹å’Œé…ç½®è½¬æ¢ä¸ºæˆ‘ä»¬çš„æ¨¡å‹å’Œé…ç½®
            converter = OriginalMask2FormerCheckpointToOursConverter(original_model, config)
            mask2former = converter.convert(mask2former)

            # åˆ›å»ºç”¨äºé€šç”¨åˆ†å‰²çš„ Mask2FormerForUniversalSegmentation æ¨¡å‹å¹¶åˆå§‹åŒ–
            mask2former_for_segmentation = Mask2FormerForUniversalSegmentation(config=config).eval()
            # å°†æˆ‘ä»¬çš„ Mask2Former æ¨¡å‹åº”ç”¨äºé€šç”¨åˆ†å‰²æ¨¡å‹
            mask2former_for_segmentation.model = mask2former

            # å°†é€šç”¨åˆ†å‰²æ¨¡å‹ä»åŸå§‹æ ¼å¼è½¬æ¢ä¸ºæˆ‘ä»¬çš„æ ¼å¼
            mask2former_for_segmentation = converter.convert_universal_segmentation(mask2former_for_segmentation)

            # è®¾ç½®å®¹å·®é˜ˆå€¼
            tolerance = 3e-1
            # éœ€è¦é«˜å®¹å·®çš„æ¨¡å‹åˆ—è¡¨
            high_tolerance_models = [
                "mask2former-swin-base-IN21k-coco-instance",
                "mask2former-swin-base-coco-instance",
                "mask2former-swin-small-cityscapes-semantic",
            ]

            # å¦‚æœæ¨¡å‹åç§°åœ¨é«˜å®¹å·®æ¨¡å‹åˆ—è¡¨ä¸­ï¼Œåˆ™è®¾ç½®æ›´é«˜çš„å®¹å·®é˜ˆå€¼
            if model_name in high_tolerance_models:
                tolerance = 3e-1

            # è®°å½•å½“å‰æ­£åœ¨æµ‹è¯•çš„æ¨¡å‹åç§°
            logger.info(f"ğŸª„ Testing {model_name}...")
            # æ‰§è¡Œæµ‹è¯•ï¼Œè¯„ä¼°æ¨¡å‹æ€§èƒ½
            test(original_model, mask2former_for_segmentation, image_processor, tolerance)
            # è®°å½•å½“å‰æ­£åœ¨æ¨é€çš„æ¨¡å‹åç§°
            logger.info(f"ğŸª„ Pushing {model_name} to hub...")

            # å°†å›¾åƒå¤„ç†å™¨æ¨é€è‡³æ¨¡å‹ä¸­å¿ƒ
            image_processor.push_to_hub(model_name)
            # å°†é€šç”¨åˆ†å‰²æ¨¡å‹æ¨é€è‡³æ¨¡å‹ä¸­å¿ƒ
            mask2former_for_segmentation.push_to_hub(model_name)
```