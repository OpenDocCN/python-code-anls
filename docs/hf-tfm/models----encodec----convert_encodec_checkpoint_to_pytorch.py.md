# `.\models\encodec\convert_encodec_checkpoint_to_pytorch.py`

```py
# è®¾ç½®ç¼–ç æ–¹å¼ä¸º UTF-8
# ç‰ˆæƒå£°æ˜ï¼ŒæŒ‡å‡ºç‰ˆæƒå±äº 2023 å¹´çš„ HuggingFace Inc. å›¢é˜Ÿæ‰€æœ‰
# æ ¹æ® Apache è®¸å¯è¯ç‰ˆæœ¬ 2.0 ä½¿ç”¨æœ¬æ–‡ä»¶ï¼Œè¯¦ç»†ä¿¡æ¯å¯ä»¥è®¿é—®æŒ‡å®šç½‘å€è·å–
# é™¤éæ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™ä¸å¾—ä½¿ç”¨æœ¬æ–‡ä»¶
# æ ¹æ® Apache è®¸å¯è¯ç‰ˆæœ¬ 2.0ï¼Œæœ¬è½¯ä»¶åŸºäºâ€œåŸæ ·â€åˆ†å‘ï¼Œä¸æä¾›ä»»ä½•å½¢å¼çš„æ‹…ä¿æˆ–æ¡ä»¶
# è¯·æŸ¥çœ‹è®¸å¯è¯ï¼Œäº†è§£å…·ä½“è¯­è¨€ç‰ˆæœ¬çš„ç»†èŠ‚

"""Convert EnCodec checkpoints."""

# å¯¼å…¥å¿…è¦çš„åº“
import argparse  # ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°

import torch  # PyTorch åº“

from transformers import (  # å¯¼å…¥ transformers åº“ä¸­çš„ç›¸å…³æ¨¡å—
    EncodecConfig,  # EnCodec çš„é…ç½®ç±»
    EncodecFeatureExtractor,  # EnCodec çš„ç‰¹å¾æå–å™¨ç±»
    EncodecModel,  # EnCodec çš„æ¨¡å‹ç±»
    logging,  # æ—¥å¿—è®°å½•æ¨¡å—
)

# è®¾ç½®æ—¥å¿—è®°å½•çš„è¯¦ç»†ç¨‹åº¦ä¸º info çº§åˆ«
logging.set_verbosity_info()
# è·å–åä¸º "transformers.models.encodec" çš„æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger("transformers.models.encodec")

# å®šä¹‰æ˜ å°„å­—å…¸ï¼Œç”¨äºé‡å‘½åé‡åŒ–å™¨ï¼ˆquantizerï¼‰ä¸­çš„æ¨¡å‹å‚æ•°
MAPPING_QUANTIZER = {
    "quantizer.vq.layers.*._codebook.inited": "quantizer.layers.*.codebook.inited",
    "quantizer.vq.layers.*._codebook.cluster_size": "quantizer.layers.*.codebook.cluster_size",
    "quantizer.vq.layers.*._codebook.embed": "quantizer.layers.*.codebook.embed",
    "quantizer.vq.layers.*._codebook.embed_avg": "quantizer.layers.*.codebook.embed_avg",
}

# å®šä¹‰æ˜ å°„å­—å…¸ï¼Œç”¨äºé‡å‘½åç¼–ç å™¨ï¼ˆencoderï¼‰ä¸­çš„æ¨¡å‹å‚æ•°
MAPPING_ENCODER = {
    "encoder.model.0.conv.conv": "encoder.layers.0.conv",
    "encoder.model.1.block.1.conv.conv": "encoder.layers.1.block.1.conv",
    "encoder.model.1.block.3.conv.conv": "encoder.layers.1.block.3.conv",
    "encoder.model.1.shortcut.conv.conv": "encoder.layers.1.shortcut.conv",
    "encoder.model.3.conv.conv": "encoder.layers.3.conv",
    "encoder.model.4.block.1.conv.conv": "encoder.layers.4.block.1.conv",
    "encoder.model.4.block.3.conv.conv": "encoder.layers.4.block.3.conv",
    "encoder.model.4.shortcut.conv.conv": "encoder.layers.4.shortcut.conv",
    "encoder.model.6.conv.conv": "encoder.layers.6.conv",
    "encoder.model.7.block.1.conv.conv": "encoder.layers.7.block.1.conv",
    "encoder.model.7.block.3.conv.conv": "encoder.layers.7.block.3.conv",
    "encoder.model.7.shortcut.conv.conv": "encoder.layers.7.shortcut.conv",
    "encoder.model.9.conv.conv": "encoder.layers.9.conv",
    "encoder.model.10.block.1.conv.conv": "encoder.layers.10.block.1.conv",
    "encoder.model.10.block.3.conv.conv": "encoder.layers.10.block.3.conv",
    "encoder.model.10.shortcut.conv.conv": "encoder.layers.10.shortcut.conv",
    "encoder.model.12.conv.conv": "encoder.layers.12.conv",
    "encoder.model.13.lstm": "encoder.layers.13.lstm",
    "encoder.model.15.conv.conv": "encoder.layers.15.conv",
}

# å®šä¹‰æ˜ å°„å­—å…¸ï¼Œç”¨äºé‡å‘½å 48kHz ç¼–ç å™¨ï¼ˆencoderï¼‰ä¸­çš„æ¨¡å‹å‚æ•°
MAPPING_ENCODER_48K = {
    "encoder.model.0.conv.norm": "encoder.layers.0.norm",
    # è¿™é‡Œå¯ä»¥ç»§ç»­æ·»åŠ å…¶ä»–çš„æ˜ å°„å…³ç³»
}
    # å®šä¹‰ä¸€ä¸ªå­—å…¸ï¼Œæ˜ å°„æ—§æ¨¡å‹ä¸­çš„å±‚æ ‡å‡†åŒ–å±‚åˆ°æ–°æ¨¡å‹ä¸­å¯¹åº”çš„æ ‡å‡†åŒ–å±‚
    {
        "encoder.model.1.block.1.conv.norm": "encoder.layers.1.block.1.norm",
        "encoder.model.1.block.3.conv.norm": "encoder.layers.1.block.3.norm",
        "encoder.model.1.shortcut.conv.norm": "encoder.layers.1.shortcut.norm",
        "encoder.model.3.conv.norm": "encoder.layers.3.norm",
        "encoder.model.4.block.1.conv.norm": "encoder.layers.4.block.1.norm",
        "encoder.model.4.block.3.conv.norm": "encoder.layers.4.block.3.norm",
        "encoder.model.4.shortcut.conv.norm": "encoder.layers.4.shortcut.norm",
        "encoder.model.6.conv.norm": "encoder.layers.6.norm",
        "encoder.model.7.block.1.conv.norm": "encoder.layers.7.block.1.norm",
        "encoder.model.7.block.3.conv.norm": "encoder.layers.7.block.3.norm",
        "encoder.model.7.shortcut.conv.norm": "encoder.layers.7.shortcut.norm",
        "encoder.model.9.conv.norm": "encoder.layers.9.norm",
        "encoder.model.10.block.1.conv.norm": "encoder.layers.10.block.1.norm",
        "encoder.model.10.block.3.conv.norm": "encoder.layers.10.block.3.norm",
        "encoder.model.10.shortcut.conv.norm": "encoder.layers.10.shortcut.norm",
        "encoder.model.12.conv.norm": "encoder.layers.12.norm",
        "encoder.model.15.conv.norm": "encoder.layers.15.norm",
    }
}
# é—­åˆä¸Šä¸€ä¸ªå­—å…¸çš„å®šä¹‰ï¼Œè¡¨ç¤ºå­—å…¸å®šä¹‰çš„ç»“æŸ

MAPPING_DECODER = {
    "decoder.model.0.conv.conv": "decoder.layers.0.conv",
    "decoder.model.1.lstm": "decoder.layers.1.lstm",
    "decoder.model.3.convtr.convtr": "decoder.layers.3.conv",
    "decoder.model.4.block.1.conv.conv": "decoder.layers.4.block.1.conv",
    "decoder.model.4.block.3.conv.conv": "decoder.layers.4.block.3.conv",
    "decoder.model.4.shortcut.conv.conv": "decoder.layers.4.shortcut.conv",
    "decoder.model.6.convtr.convtr": "decoder.layers.6.conv",
    "decoder.model.7.block.1.conv.conv": "decoder.layers.7.block.1.conv",
    "decoder.model.7.block.3.conv.conv": "decoder.layers.7.block.3.conv",
    "decoder.model.7.shortcut.conv.conv": "decoder.layers.7.shortcut.conv",
    "decoder.model.9.convtr.convtr": "decoder.layers.9.conv",
    "decoder.model.10.block.1.conv.conv": "decoder.layers.10.block.1.conv",
    "decoder.model.10.block.3.conv.conv": "decoder.layers.10.block.3.conv",
    "decoder.model.10.shortcut.conv.conv": "decoder.layers.10.shortcut.conv",
    "decoder.model.12.convtr.convtr": "decoder.layers.12.conv",
    "decoder.model.13.block.1.conv.conv": "decoder.layers.13.block.1.conv",
    "decoder.model.13.block.3.conv.conv": "decoder.layers.13.block.3.conv",
    "decoder.model.13.shortcut.conv.conv": "decoder.layers.13.shortcut.conv",
    "decoder.model.15.conv.conv": "decoder.layers.15.conv",
}
# æ˜ å°„å­—å…¸ï¼Œå°†æ¨¡å‹ä¸­çš„ç¼–ç å™¨å±‚å‘½åæ˜ å°„åˆ°è§£ç å™¨å±‚å‘½åï¼Œç”¨äºå¯¹æ¨¡å‹è¿›è¡Œç»“æ„æ˜ å°„

MAPPING_DECODER_48K = {
    "decoder.model.0.conv.norm": "decoder.layers.0.norm",
    "decoder.model.3.convtr.norm": "decoder.layers.3.norm",
    "decoder.model.4.block.1.conv.norm": "decoder.layers.4.block.1.norm",
    "decoder.model.4.block.3.conv.norm": "decoder.layers.4.block.3.norm",
    "decoder.model.4.shortcut.conv.norm": "decoder.layers.4.shortcut.norm",
    "decoder.model.6.convtr.norm": "decoder.layers.6.norm",
    "decoder.model.7.block.1.conv.norm": "decoder.layers.7.block.1.norm",
    "decoder.model.7.block.3.conv.norm": "decoder.layers.7.block.3.norm",
    "decoder.model.7.shortcut.conv.norm": "decoder.layers.7.shortcut.norm",
    "decoder.model.9.convtr.norm": "decoder.layers.9.norm",
    "decoder.model.10.block.1.conv.norm": "decoder.layers.10.block.1.norm",
    "decoder.model.10.block.3.conv.norm": "decoder.layers.10.block.3.norm",
    "decoder.model.10.shortcut.conv.norm": "decoder.layers.10.shortcut.norm",
    "decoder.model.12.convtr.norm": "decoder.layers.12.norm",
    "decoder.model.13.block.1.conv.norm": "decoder.layers.13.block.1.norm",
    "decoder.model.13.block.3.conv.norm": "decoder.layers.13.block.3.norm",
    "decoder.model.13.shortcut.conv.norm": "decoder.layers.13.shortcut.norm",
    "decoder.model.15.conv.norm": "decoder.layers.15.norm",
}
# æ˜ å°„å­—å…¸ï¼Œå°†æ¨¡å‹ä¸­çš„ç¼–ç å™¨å±‚çš„å½’ä¸€åŒ–å‘½åæ˜ å°„åˆ°è§£ç å™¨å±‚çš„å½’ä¸€åŒ–å‘½å

MAPPING_24K = {
    **MAPPING_QUANTIZER,
    **MAPPING_ENCODER,
    **MAPPING_DECODER,
}
# å°†é‡åŒ–å™¨ã€ç¼–ç å™¨å’Œè§£ç å™¨çš„æ˜ å°„åˆå¹¶åˆ°ä¸€ä¸ªå­—å…¸ä¸­ï¼Œç”¨äº24Ké…ç½®

MAPPING_48K = {
    **MAPPING_QUANTIZER,
    **MAPPING_ENCODER,
    **MAPPING_ENCODER_48K,
    **MAPPING_DECODER,
    **MAPPING_DECODER_48K,
}
# å°†é‡åŒ–å™¨ã€ç¼–ç å™¨ã€è§£ç å™¨48Ké…ç½®çš„æ˜ å°„åˆå¹¶åˆ°ä¸€ä¸ªå­—å…¸ä¸­ï¼Œç”¨äº48Ké…ç½®

TOP_LEVEL_KEYS = []
# åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨é¡¶å±‚é”®

IGNORE_KEYS = []
# åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨éœ€è¦å¿½ç•¥çš„é”®

def set_recursively(hf_pointer, key, value, full_name, weight_type):
    # å°† key æŒ‰ "." åˆ†å‰²æˆå±æ€§åˆ—è¡¨ï¼Œé€çº§è·å– hf_pointer çš„å±æ€§å€¼
    for attribute in key.split("."):
        hf_pointer = getattr(hf_pointer, attribute)

    # å¦‚æœæŒ‡å®šäº† weight_typeï¼Œåˆ™è·å– hf_pointer å¯¹åº”å±æ€§çš„å½¢çŠ¶
    if weight_type is not None:
        hf_shape = getattr(hf_pointer, weight_type).shape
    else:
        # å¦åˆ™è·å– hf_pointer è‡ªèº«çš„å½¢çŠ¶
        hf_shape = hf_pointer.shape

    # æ£€æŸ¥è·å–çš„å½¢çŠ¶æ˜¯å¦ä¸ value çš„å½¢çŠ¶ç›¸åŒ¹é…ï¼Œå¦‚æœä¸åŒ¹é…åˆ™æŠ›å‡º ValueError å¼‚å¸¸
    if hf_shape != value.shape:
        raise ValueError(
            f"Shape of hf {key + '.' + weight_type if weight_type is not None else ''} is {hf_shape}, but should be"
            f" {value.shape} for {full_name}"
        )

    # æ ¹æ® weight_type ç±»å‹è®¾ç½® hf_pointer å¯¹åº”çš„æ•°æ®å€¼
    if weight_type == "weight":
        hf_pointer.weight.data = value
    elif weight_type == "weight_g":
        hf_pointer.weight_g.data = value
    elif weight_type == "weight_v":
        hf_pointer.weight_v.data = value
    elif weight_type == "bias":
        hf_pointer.bias.data = value
    elif weight_type == "running_mean":
        hf_pointer.running_mean.data = value
    elif weight_type == "running_var":
        hf_pointer.running_var.data = value
    elif weight_type == "num_batches_tracked":
        hf_pointer.num_batches_tracked.data = value
    elif weight_type == "weight_ih_l0":
        hf_pointer.weight_ih_l0.data = value
    elif weight_type == "weight_hh_l0":
        hf_pointer.weight_hh_l0.data = value
    elif weight_type == "bias_ih_l0":
        hf_pointer.bias_ih_l0.data = value
    elif weight_type == "bias_hh_l0":
        hf_pointer.bias_hh_l0.data = value
    elif weight_type == "weight_ih_l1":
        hf_pointer.weight_ih_l1.data = value
    elif weight_type == "weight_hh_l1":
        hf_pointer.weight_hh_l1.data = value
    elif weight_type == "bias_ih_l1":
        hf_pointer.bias_ih_l1.data = value
    elif weight_type == "bias_hh_l1":
        hf_pointer.bias_hh_l1.data = value
    else:
        # å¦‚æœ weight_type æœªæŒ‡å®šæˆ–æœªåŒ¹é…åˆ°ç‰¹å®šç±»å‹ï¼Œç›´æ¥è®¾ç½® hf_pointer çš„æ•°æ®å€¼
        hf_pointer.data = value

    # è®°å½•æ—¥å¿—ï¼ŒæŒ‡ç¤ºæˆåŠŸåˆå§‹åŒ–çš„å±æ€§å’Œå…¶æ¥æº
    logger.info(f"{key + ('.' + weight_type if weight_type is not None else '')} was initialized from {full_name}.")
# åˆ¤æ–­ç»™å®šçš„æ–‡ä»¶åæ˜¯å¦åº”è¯¥è¢«å¿½ç•¥ï¼Œæ ¹æ® ignore_keys ä¸­çš„è§„åˆ™è¿›è¡ŒåŒ¹é…
def should_ignore(name, ignore_keys):
    # éå† ignore_keys åˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªå…³é”®å­—
    for key in ignore_keys:
        # å¦‚æœå…³é”®å­—ä»¥ ".*" ç»“å°¾ï¼Œæ£€æŸ¥ name æ˜¯å¦ä»¥ key[:-1] å¼€å¤´ï¼Œå¦‚æœæ˜¯åˆ™è¿”å› True
        if key.endswith(".*"):
            if name.startswith(key[:-1]):
                return True
        # å¦‚æœå…³é”®å­—åŒ…å« ".*."ï¼Œåˆ™å°† key æ‹†åˆ†æˆå‰ç¼€ prefix å’Œåç¼€ suffixï¼Œå¦‚æœ name åŒæ—¶åŒ…å«è¿™ä¸¤éƒ¨åˆ†åˆ™è¿”å› True
        elif ".*." in key:
            prefix, suffix = key.split(".*.")
            if prefix in name and suffix in name:
                return True
        # å¦åˆ™ï¼Œå¦‚æœå…³é”®å­— key ç›´æ¥åœ¨ name ä¸­å‡ºç°åˆ™è¿”å› True
        elif key in name:
            return True
    # å¦‚æœéƒ½æ²¡æœ‰åŒ¹é…æˆåŠŸï¼Œåˆ™è¿”å› Falseï¼Œè¡¨ç¤ºä¸å¿½ç•¥è¯¥æ–‡ä»¶å
    return False


# æ ¹æ®ç»™å®šçš„æ¨¡å‹åå’ŒåŸå§‹å­—å…¸ orig_dictï¼ŒåŠ è½½å¯¹åº”æ¨¡å‹çš„æƒé‡åˆ° hf_model ä¸­ï¼Œå¹¶è¿”å›æœªä½¿ç”¨çš„æƒé‡åˆ—è¡¨
def recursively_load_weights(orig_dict, hf_model, model_name):
    # åˆå§‹åŒ–æœªä½¿ç”¨çš„æƒé‡åˆ—è¡¨
    unused_weights = []

    # æ ¹æ®ä¸åŒçš„æ¨¡å‹åé€‰æ‹©ç›¸åº”çš„æ˜ å°„å…³ç³»
    if model_name == "encodec_24khz" or "encodec_32khz":
        MAPPING = MAPPING_24K
    elif model_name == "encodec_48khz":
        MAPPING = MAPPING_48K
    else:
        # å¦‚æœæ¨¡å‹åä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­ï¼ŒæŠ›å‡º ValueError å¼‚å¸¸
        raise ValueError(f"Unsupported model: {model_name}")
    # éå†åŸå§‹å­—å…¸çš„é”®å€¼å¯¹
    for name, value in orig_dict.items():
        # å¦‚æœåº”è¯¥å¿½ç•¥è¯¥é”®åï¼Œåˆ™è®°å½•æ—¥å¿—å¹¶è·³è¿‡å½“å‰å¾ªç¯
        if should_ignore(name, IGNORE_KEYS):
            logger.info(f"{name} was ignored")
            continue

        # æ ‡å¿—ï¼šç”¨äºæ£€æŸ¥æ˜¯å¦åœ¨åç»­å¤„ç†ä¸­ä½¿ç”¨äº†è¯¥é”®åå¯¹åº”çš„æ•°å€¼
        is_used = False

        # éå†æ˜ å°„å­—å…¸ä¸­çš„é”®å€¼å¯¹
        for key, mapped_key in MAPPING.items():
            # å¦‚æœå½“å‰æ˜ å°„é”®åŒ…å«é€šé…ç¬¦"*"
            if "*" in key:
                # æ‹†åˆ†é€šé…ç¬¦å‰ç¼€å’Œåç¼€
                prefix, suffix = key.split(".*.")
                # å¦‚æœé”®ååŒæ—¶åŒ…å«å‰ç¼€å’Œåç¼€ï¼Œåˆ™ä½¿ç”¨åç¼€ä½œä¸ºæ–°çš„é”®å
                if prefix in name and suffix in name:
                    key = suffix

            # å¦‚æœå½“å‰æ˜ å°„é”®åœ¨é”®åä¸­æ‰¾åˆ°åŒ¹é…
            if key in name:
                # ç‰¹å®šæƒ…å†µä¸‹çš„å¤„ç†ï¼šé˜²æ­¢ ".embed_avg" åˆå§‹åŒ–ä¸º ".embed"
                if key.endswith("embed") and name.endswith("embed_avg"):
                    continue

                # è®¾ç½®æ ‡å¿—è¡¨æ˜è¯¥é”®åå·²è¢«ä½¿ç”¨
                is_used = True

                # å¦‚æœæ˜ å°„å€¼ä¸­å­˜åœ¨é€šé…ç¬¦"*"ï¼Œåˆ™æ ¹æ®å±‚ç´¢å¼•æ›¿æ¢é€šé…ç¬¦
                if "*" in mapped_key:
                    layer_index = name.split(key)[0].split(".")[-2]
                    mapped_key = mapped_key.replace("*", layer_index)

                # æ ¹æ®ç‰¹å®šçš„æƒé‡ç±»å‹ä¸ºæƒé‡é”®èµ‹å€¼
                if "weight_g" in name:
                    weight_type = "weight_g"
                elif "weight_v" in name:
                    weight_type = "weight_v"
                elif "weight_ih_l0" in name:
                    weight_type = "weight_ih_l0"
                elif "weight_hh_l0" in name:
                    weight_type = "weight_hh_l0"
                elif "bias_ih_l0" in name:
                    weight_type = "bias_ih_l0"
                elif "bias_hh_l0" in name:
                    weight_type = "bias_hh_l0"
                elif "weight_ih_l1" in name:
                    weight_type = "weight_ih_l1"
                elif "weight_hh_l1" in name:
                    weight_type = "weight_hh_l1"
                elif "bias_ih_l1" in name:
                    weight_type = "bias_ih_l1"
                elif "bias_hh_l1" in name:
                    weight_type = "bias_hh_l1"
                elif "bias" in name:
                    weight_type = "bias"
                elif "weight" in name:
                    weight_type = "weight"
                elif "running_mean" in name:
                    weight_type = "running_mean"
                elif "running_var" in name:
                    weight_type = "running_var"
                elif "num_batches_tracked" in name:
                    weight_type = "num_batches_tracked"
                else:
                    weight_type = None

                # é€’å½’åœ°è®¾ç½®æ–°æ¨¡å‹çš„æ˜ å°„é”®å¯¹åº”çš„å€¼
                set_recursively(hf_model, mapped_key, value, name, weight_type)

            # ç»§ç»­ä¸‹ä¸€ä¸ªæ˜ å°„é”®çš„å¤„ç†
            continue
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•æ˜ å°„é”®è¢«ä½¿ç”¨ï¼Œåˆ™å°†è¯¥é”®åæ·»åŠ åˆ°æœªä½¿ç”¨çš„æƒé‡åˆ—è¡¨ä¸­
        if not is_used:
            unused_weights.append(name)

    # è®°å½•æœªä½¿ç”¨çš„æƒé‡åˆ—è¡¨åˆ°è­¦å‘Šæ—¥å¿—ä¸­
    logger.warning(f"Unused weights: {unused_weights}")
# ç”¨è£…é¥°å™¨ @torch.no_grad() æ ‡è®°è¯¥å‡½æ•°ï¼Œç¦æ­¢åœ¨å‡½æ•°å†…éƒ¨è¿›è¡Œæ¢¯åº¦è®¡ç®—
def convert_checkpoint(
    model_name,
    checkpoint_path,
    pytorch_dump_folder_path,
    config_path=None,
    repo_id=None,
):
    """
    Copy/paste/tweak model's weights to transformers design.
    """
    # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä»é¢„è®­ç»ƒæ¨¡å‹åŠ è½½é…ç½®
    if config_path is not None:
        config = EncodecConfig.from_pretrained(config_path)
    else:
        # å¦åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„é…ç½®å¯¹è±¡
        config = EncodecConfig()

    # æ ¹æ®æ¨¡å‹åç§°è®¾ç½®é…ç½®å¯¹è±¡çš„å‚æ•°
    if model_name == "encodec_24khz":
        pass  # å¯¹äº "encodec_24khz" æ¨¡å‹ï¼Œé…ç½®å·²ç»æ˜¯æ­£ç¡®çš„
    elif model_name == "encodec_32khz":
        # æ ¹æ®æ¨¡å‹åç§°è°ƒæ•´é…ç½®å¯¹è±¡çš„å‚æ•°
        config.upsampling_ratios = [8, 5, 4, 4]
        config.target_bandwidths = [2.2]
        config.num_filters = 64
        config.sampling_rate = 32_000
        config.codebook_size = 2048
        config.use_causal_conv = False
        config.normalize = False
        config.use_conv_shortcut = False
    elif model_name == "encodec_48khz":
        # æ ¹æ®æ¨¡å‹åç§°è°ƒæ•´é…ç½®å¯¹è±¡çš„å‚æ•°
        config.upsampling_ratios = [8, 5, 4, 2]
        config.target_bandwidths = [3.0, 6.0, 12.0, 24.0]
        config.sampling_rate = 48_000
        config.audio_channels = 2
        config.use_causal_conv = False
        config.norm_type = "time_group_norm"
        config.normalize = True
        config.chunk_length_s = 1.0
        config.overlap = 0.01
    else:
        # å¦‚æœæ¨¡å‹åç§°ä¸åœ¨å·²çŸ¥åˆ—è¡¨ä¸­ï¼ŒæŠ›å‡ºå¼‚å¸¸
        raise ValueError(f"Unknown model name: {model_name}")

    # æ ¹æ®é…ç½®å¯¹è±¡åˆ›å»ºæ¨¡å‹
    model = EncodecModel(config)

    # æ ¹æ®é…ç½®å¯¹è±¡åˆ›å»ºç‰¹å¾æå–å™¨
    feature_extractor = EncodecFeatureExtractor(
        feature_size=config.audio_channels,
        sampling_rate=config.sampling_rate,
        chunk_length_s=config.chunk_length_s,
        overlap=config.overlap,
    )

    # å°†ç‰¹å¾æå–å™¨ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
    feature_extractor.save_pretrained(pytorch_dump_folder_path)

    # åŠ è½½åŸå§‹ PyTorch æ£€æŸ¥ç‚¹
    original_checkpoint = torch.load(checkpoint_path)
    
    # å¦‚æœåŸå§‹æ£€æŸ¥ç‚¹ä¸­åŒ…å« "best_state" é”®ï¼Œåªä¿ç•™æƒé‡ä¿¡æ¯
    if "best_state" in original_checkpoint:
        original_checkpoint = original_checkpoint["best_state"]

    # é€’å½’åŠ è½½æƒé‡åˆ°æ¨¡å‹ä¸­
    recursively_load_weights(original_checkpoint, model, model_name)

    # å°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
    model.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœæä¾›äº† repo_idï¼Œå°†ç‰¹å¾æå–å™¨å’Œæ¨¡å‹æ¨é€åˆ°æŒ‡å®šçš„ hub
    if repo_id:
        print("Pushing to the hub...")
        feature_extractor.push_to_hub(repo_id)
        model.push_to_hub(repo_id)


if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--model",
        default="encodec_24khz",
        type=str,
        help="The model to convert. Should be one of 'encodec_24khz', 'encodec_32khz', 'encodec_48khz'.",
    )
    parser.add_argument("--checkpoint_path", required=True, default=None, type=str, help="Path to original checkpoint")
    parser.add_argument("--config_path", default=None, type=str, help="Path to hf config.json of model to convert")
    parser.add_argument(
        "--pytorch_dump_folder_path", required=True, default=None, type=str, help="Path to the output PyTorch model."
    )
    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
    )

    # è§£æå‚æ•°
    args = parser.parse_args()
    # è°ƒç”¨å‡½æ•° convert_checkpointï¼Œç”¨äºè½¬æ¢æ¨¡å‹çš„æ£€æŸ¥ç‚¹æ–‡ä»¶æ ¼å¼
    convert_checkpoint(
        args.model,                     # æŒ‡å®šæ¨¡å‹åç§°å‚æ•°
        args.checkpoint_path,           # æŒ‡å®šæ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„å‚æ•°
        args.pytorch_dump_folder_path,  # æŒ‡å®šè½¬æ¢åçš„ PyTorch æ¨¡å‹è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„å‚æ•°
        args.config_path,               # æŒ‡å®šæ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„å‚æ•°
        args.push_to_hub,               # æŒ‡å®šæ˜¯å¦å°†è½¬æ¢åçš„æ¨¡å‹æ¨é€åˆ° Hub çš„å‚æ•°
    )
```