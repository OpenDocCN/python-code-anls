# `.\models\encodec\convert_encodec_checkpoint_to_pytorch.py`

```
# è®¾ç½®æ–‡ä»¶ç¼–ç 
# ç‰ˆæƒå£°æ˜
# è®¸å¯è¯è¯´æ˜
"""è½¬æ¢ EnCodec æ£€æŸ¥ç‚¹ã€‚"""
# å¯¼å…¥æ¨¡å—
import argparse
# å¯¼å…¥ torch
import torch
# ä» transformers æ¨¡å—ä¸­å¯¼å…¥ EncodecConfig, EncodecFeatureExtractor, EncodecModel, logging
from transformers import (
    EncodecConfig,
    EncodecFeatureExtractor,
    EncodecModel,
    logging,
)

# å®šä¹‰æ—¥å¿—è®°å½•çš„è¯¦ç»†ç¨‹åº¦
logging.set_verbosity_info()
# è·å–æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger("transformers.models.encodec")

# æ˜ å°„å™¨ - é‡åŒ–å™¨
MAPPING_QUANTIZER = {
    "quantizer.vq.layers.*._codebook.inited": "quantizer.layers.*.codebook.inited",
    "quantizer.vq.layers.*._codebook.cluster_size": "quantizer.layers.*.codebook.cluster_size",
    "quantizer.vq.layers.*._codebook.embed": "quantizer.layers.*.codebook.embed",
    "quantizer.vq.layers.*._codebook.embed_avg": "quantizer.layers.*.codebook.embed_avg",
}
# æ˜ å°„å™¨ - ç¼–ç å™¨
MAPPING_ENCODER = {
    "encoder.model.0.conv.conv": "encoder.layers.0.conv",
    "encoder.model.1.block.1.conv.conv": "encoder.layers.1.block.1.conv",
    ...
}
# æ˜ å°„å™¨ - 48K ç¼–ç å™¨
MAPPING_ENCODER_48K = {
    "encoder.model.0.conv.norm": "encoder.layers.0.norm",
    # å®šä¹‰ä¸€ä¸ªå­—å…¸ï¼Œå°†æ¨¡å‹æƒé‡ä¸­çš„è§„èŒƒåŒ–å±‚åç§°æ˜ å°„åˆ°ç›¸åº”çš„ç¼–ç å™¨å±‚è§„èŒƒåŒ–å±‚åç§°
    "encoder.model.1.block.1.conv.norm": "encoder.layers.1.block.1.norm",
    "encoder.model.1.block.3.conv.norm": "encoder.layers.1.block.3.norm",
    "encoder.model.1.shortcut.conv.norm": "encoder.layers.1.shortcut.norm",
    "encoder.model.3.conv.norm": "encoder.layers.3.norm",
    "encoder.model.4.block.1.conv.norm": "encoder.layers.4.block.1.norm",
    "encoder.model.4.block.3.conv.norm": "encoder.layers.4.block.3.norm",
    "encoder.model.4.shortcut.conv.norm": "encoder.layers.4.shortcut.norm",
    "encoder.model.6.conv.norm": "encoder.layers.6.norm",
    "encoder.model.7.block.1.conv.norm": "encoder.layers.7.block.1.norm",
    "encoder.model.7.block.3.conv.norm": "encoder.layers.7.block.3.norm",
    "encoder.model.7.shortcut.conv.norm": "encoder.layers.7.shortcut.norm",
    "encoder.model.9.conv.norm": "encoder.layers.9.norm",
    "encoder.model.10.block.1.conv.norm": "encoder.layers.10.block.1.norm",
    "encoder.model.10.block.3.conv.norm": "encoder.layers.10.block.3.norm",
    "encoder.model.10.shortcut.conv.norm": "encoder.layers.10.shortcut.norm",
    "encoder.model.12.conv.norm": "encoder.layers.12.norm",
    "encoder.model.15.conv.norm": "encoder.layers.15.norm",
# å®šä¹‰å­—å…¸ï¼Œå°†è§£ç å™¨çš„å±‚åç§°æ˜ å°„åˆ°ç›¸åº”çš„è§£ç å™¨å±‚ä¸Š
MAPPING_DECODER = {
    "decoder.model.0.conv.conv": "decoder.layers.0.conv",
    "decoder.model.1.lstm": "decoder.layers.1.lstm",
    "decoder.model.3.convtr.convtr": "decoder.layers.3.conv",
    "decoder.model.4.block.1.conv.conv": "decoder.layers.4.block.1.conv",
    "decoder.model.4.block.3.conv.conv": "decoder.layers.4.block.3.conv",
    "decoder.model.4.shortcut.conv.conv": "decoder.layers.4.shortcut.conv",
    "decoder.model.6.convtr.convtr": "decoder.layers.6.conv",
    "decoder.model.7.block.1.conv.conv": "decoder.layers.7.block.1.conv",
    "decoder.model.7.block.3.conv.conv": "decoder.layers.7.block.3.conv",
    "decoder.model.7.shortcut.conv.conv": "decoder.layers.7.shortcut.conv",
    "decoder.model.9.convtr.convtr": "decoder.layers.9.conv",
    "decoder.model.10.block.1.conv.conv": "decoder.layers.10.block.1.conv",
    "decoder.model.10.block.3.conv.conv": "decoder.layers.10.block.3.conv",
    "decoder.model.10.shortcut.conv.conv": "decoder.layers.10.shortcut.conv",
    "decoder.model.12.convtr.convtr": "decoder.layers.12.conv",
    "decoder.model.13.block.1.conv.conv": "decoder.layers.13.block.1.conv",
    "decoder.model.13.block.3.conv.conv": "decoder.layers.13.block.3.conv",
    "decoder.model.13.shortcut.conv.conv": "decoder.layers.13.shortcut.conv",
    "decoder.model.15.conv.conv": "decoder.layers.15.conv",
}

# å®šä¹‰å­—å…¸ï¼Œå°† 48K è§£ç å™¨çš„å±‚åç§°æ˜ å°„åˆ°ç›¸åº”çš„è§£ç å™¨å±‚ä¸Š
MAPPING_DECODER_48K = {
    "decoder.model.0.conv.norm": "decoder.layers.0.norm",
    "decoder.model.3.convtr.norm": "decoder.layers.3.norm",
    "decoder.model.4.block.1.conv.norm": "decoder.layers.4.block.1.norm",
    "decoder.model.4.block.3.conv.norm": "decoder.layers.4.block.3.norm",
    "decoder.model.4.shortcut.conv.norm": "decoder.layers.4.shortcut.norm",
    "decoder.model.6.convtr.norm": "decoder.layers.6.norm",
    "decoder.model.7.block.1.conv.norm": "decoder.layers.7.block.1.norm",
    "decoder.model.7.block.3.conv.norm": "decoder.layers.7.block.3.norm",
    "decoder.model.7.shortcut.conv.norm": "decoder.layers.7.shortcut.norm",
    "decoder.model.9.convtr.norm": "decoder.layers.9.norm",
    "decoder.model.10.block.1.conv.norm": "decoder.layers.10.block.1.norm",
    "decoder.model.10.block.3.conv.norm": "decoder.layers.10.block.3.norm",
    "decoder.model.10.shortcut.conv.norm": "decoder.layers.10.shortcut.norm",
    "decoder.model.12.convtr.norm": "decoder.layers.12.norm",
    "decoder.model.13.block.1.conv.norm": "decoder.layers.13.block.1.norm",
    "decoder.model.13.block.3.conv.norm": "decoder.layers.13.block.3.norm",
    "decoder.model.13.shortcut.conv.norm": "decoder.layers.13.shortcut.norm",
    "decoder.model.15.conv.norm": "decoder.layers.15.norm",
}

# åˆå¹¶é‡åŒ–å™¨ã€ç¼–ç å™¨å’Œè§£ç å™¨çš„å±‚æ˜ å°„å­—å…¸ï¼Œå½¢æˆ 24K æ¨¡å‹çš„æ˜ å°„å­—å…¸
MAPPING_24K = {
    **MAPPING_QUANTIZER,
    **MAPPING_ENCODER,
    **MAPPING_DECODER,
}

# åˆå¹¶é‡åŒ–å™¨ã€48K ç¼–ç å™¨ã€48K è§£ç å™¨çš„å±‚æ˜ å°„å­—å…¸ï¼Œå½¢æˆ 48K æ¨¡å‹çš„æ˜ å°„å­—å…¸
MAPPING_48K = {
    **MAPPING_QUANTIZER,
    **MAPPING_ENCODER,
    **MAPPING_ENCODER_48K,
    **MAPPING_DECODER,
    **MAPPING_DECODER_48K,
}

# å®šä¹‰ç©ºåˆ—è¡¨ TOP_LEVEL_KEYS
TOP_LEVEL_KEYS = []

# å®šä¹‰ç©ºåˆ—è¡¨ IGNORE_KEYS
IGNORE_KEYS = []

# å®šä¹‰å‡½æ•° set_recursivelyï¼Œç”¨äºé€’å½’è®¾ç½®æŸä¸ªå˜é‡
def set_recursively(hf_pointer, key, value, full_name, weight_type):
    # å°†è¾“å…¥çš„é”®æŒ‰ç‚¹åˆ†éš”ï¼Œé€çº§è·å–å¯¹è±¡å±æ€§
    for attribute in key.split("."):
        hf_pointer = getattr(hf_pointer, attribute)

    # å¦‚æœæƒé‡ç±»å‹ä¸ä¸ºç©ºï¼Œåˆ™è·å–ç›¸åº”å±æ€§çš„å½¢çŠ¶
    if weight_type is not None:
        hf_shape = getattr(hf_pointer, weight_type).shape
    else:
        # å¦åˆ™è·å–æ•´ä¸ªå¯¹è±¡çš„å½¢çŠ¶
        hf_shape = hf_pointer.shape

    # å¦‚æœè·å–çš„å½¢çŠ¶ä¸ç»™å®šå€¼çš„å½¢çŠ¶ä¸ç›¸ç­‰ï¼Œåˆ™å¼•å‘ ValueError å¼‚å¸¸
    if hf_shape != value.shape:
        raise ValueError(
            f"Shape of hf {key + '.' + weight_type if weight_type is not None else ''} is {hf_shape}, but should be"
            f" {value.shape} for {full_name}"
        )

    # æ ¹æ®æƒé‡ç±»å‹è®¾ç½®å¯¹åº”å±æ€§çš„å€¼
    if weight_type == "weight":
        hf_pointer.weight.data = value
    elif weight_type == "weight_g":
        hf_pointer.weight_g.data = value
    elif weight_type == "weight_v":
        hf_pointer.weight_v.data = value
    elif weight_type == "bias":
        hf_pointer.bias.data = value
    elif weight_type == "running_mean":
        hf_pointer.running_mean.data = value
    elif weight_type == "running_var":
        hf_pointer.running_var.data = value
    elif weight_type == "num_batches_tracked":
        hf_pointer.num_batches_tracked.data = value
    elif weight_type == "weight_ih_l0":
        hf_pointer.weight_ih_l0.data = value
    elif weight_type == "weight_hh_l0":
        hf_pointer.weight_hh_l0.data = value
    elif weight_type == "bias_ih_l0":
        hf_pointer.bias_ih_l0.data = value
    elif weight_type == "bias_hh_l0":
        hf_pointer.bias_hh_l0.data = value
    elif weight_type == "weight_ih_l1":
        hf_pointer.weight_ih_l1.data = value
    elif weight_type == "weight_hh_l1":
        hf_pointer.weight_hh_l1.data = value
    elif weight_type == "bias_ih_l1":
        hf_pointer.bias_ih_l1.data = value
    elif weight_type == "bias_hh_l1":
        hf_pointer.bias_hh_l1.data = value
    else:
        # å¦‚æœæƒé‡ç±»å‹ä¸ºç©ºæˆ–ä¸åœ¨å·²çŸ¥ç±»å‹ä¸­ï¼Œåˆ™ç›´æ¥è®¾ç½®å¯¹è±¡çš„æ•°æ®
        hf_pointer.data = value

    # è®°å½•åˆå§‹åŒ–ä¿¡æ¯
    logger.info(f"{key + ('.' + weight_type if weight_type is not None else '')} was initialized from {full_name}.")
# åˆ¤æ–­ç»™å®šçš„æ–‡ä»¶åæ˜¯å¦åº”è¯¥è¢«å¿½ç•¥ï¼Œæ ¹æ®å¿½ç•¥å…³é”®å­—åˆ—è¡¨
def should_ignore(name, ignore_keys):
    # éå†å¿½ç•¥å…³é”®å­—åˆ—è¡¨
    for key in ignore_keys:
        # å¦‚æœå¿½ç•¥å…³é”®å­—ä»¥".*"ç»“å°¾
        if key.endswith(".*"):
            # å¦‚æœæ–‡ä»¶åä»¥å»æ‰æœ€åä¸€ä¸ªå­—ç¬¦çš„å¿½ç•¥å…³é”®å­—å¼€å¤´ï¼Œè¯´æ˜éœ€è¦å¿½ç•¥è¯¥æ–‡ä»¶
            if name.startswith(key[:-1]):
                return True
        # å¦‚æœå¿½ç•¥å…³é”®å­—ä¸­åŒ…å«".*."
        elif ".*." in key:
            # å°†å¿½ç•¥å…³é”®å­—æŒ‰".*."åˆ†å‰²æˆå‰ç¼€å’Œåç¼€
            prefix, suffix = key.split(".*.")
            # å¦‚æœæ–‡ä»¶åä¸­åŒ…å«å‰ç¼€å’Œåç¼€ï¼Œè¯´æ˜éœ€è¦å¿½ç•¥è¯¥æ–‡ä»¶
            if prefix in name and suffix in name:
                return True
        # å¦‚æœå¿½ç•¥å…³é”®å­—åœ¨æ–‡ä»¶åä¸­å‡ºç°ï¼Œè¯´æ˜éœ€è¦å¿½ç•¥è¯¥æ–‡ä»¶
        elif key in name:
            return True
    # å¦‚æœä»¥ä¸Šæ¡ä»¶éƒ½ä¸æ»¡è¶³ï¼Œåˆ™ä¸éœ€è¦å¿½ç•¥è¯¥æ–‡ä»¶
    return False

# æ ¹æ®æ¨¡å‹åç§°å’ŒåŠ è½½çš„æƒé‡è¿›è¡Œé€’å½’åŠ è½½æƒé‡
def recursively_load_weights(orig_dict, hf_model, model_name):
    # åˆå§‹åŒ–æœªä½¿ç”¨çš„æƒé‡åˆ—è¡¨
    unused_weights = []

    # æ ¹æ®æ¨¡å‹åç§°é€‰æ‹©æ˜ å°„è¡¨
    if model_name == "encodec_24khz" or "encodec_32khz":
        MAPPING = MAPPING_24K
    elif model_name == "encodec_48khz":
        MAPPING = MAPPING_48K
    else:
        # å¦‚æœæ¨¡å‹åç§°ä¸æ”¯æŒï¼ŒæŠ›å‡ºæ•°å€¼é”™è¯¯
        raise ValueError(f"Unsupported model: {model_name}")
    # éå†åŸå§‹å­—å…¸ä¸­çš„é”®å€¼å¯¹
    for name, value in orig_dict.items():
        # åˆ¤æ–­æ˜¯å¦åº”è¯¥å¿½ç•¥è¯¥é”®ï¼Œå¦‚æœæ˜¯åˆ™è®°å½•æ—¥å¿—å¹¶ç»§ç»­ä¸‹ä¸€ä¸ªé”®å€¼å¯¹
        if should_ignore(name, IGNORE_KEYS):
            logger.info(f"{name} was ignored")
            continue

        # æ£€æŸ¥æ˜¯å¦è¯¥é”®è¢«ä½¿ç”¨
        is_used = False
        # éå†æ˜ å°„å­—å…¸ä¸­çš„é”®å€¼å¯¹
        for key, mapped_key in MAPPING.items():
            # å¦‚æœé”®ä¸­åŒ…å«é€šé…ç¬¦"*"ï¼Œåˆ™è¿›è¡ŒåŒ¹é…å¤„ç†
            if "*" in key:
                prefix, suffix = key.split(".*.")
                if prefix in name and suffix in name:
                    key = suffix

            # å¦‚æœè¯¥é”®è¢«ä½¿ç”¨
            if key in name:
                # Hackï¼šé¿å… .embed è¢«åˆå§‹åŒ–ä¸º .embed_avg
                if key.endswith("embed") and name.endswith("embed_avg"):
                    continue

                is_used = True
                # å¦‚æœæ˜ å°„çš„é”®åŒ…å«é€šé…ç¬¦"*"ï¼Œåˆ™è¿›è¡Œæ›¿æ¢å¤„ç†
                if "*" in mapped_key:
                    layer_index = name.split(key)[0].split(".")[-2]
                    mapped_key = mapped_key.replace("*", layer_index)
                # æ ¹æ®é”®å€¼åç§°åˆ¤æ–­æƒé‡ç±»å‹
                if "weight_g" in name:
                    weight_type = "weight_g"
                elif "weight_v" in name:
                    weight_type = "weight_v"
                # ... å…¶ä»–æƒé‡ç±»å‹çš„åˆ¤æ–­
                else:
                    weight_type = None
                # é€’å½’è®¾ç½®æ¨¡å‹ä¸­çš„å‚æ•°å€¼
                set_recursively(hf_model, mapped_key, value, name, weight_type)
            continue
        # å¦‚æœæœªä½¿ç”¨è¯¥é”®ï¼Œæ·»åŠ åˆ°æœªä½¿ç”¨æƒé‡åˆ—è¡¨ä¸­
        if not is_used:
            unused_weights.append(name)

    # è¾“å‡ºæœªä½¿ç”¨çš„æƒé‡åˆ—è¡¨
    logger.warning(f"Unused weights: {unused_weights}")
# ä½¿ç”¨torch.no_grad()ä¿®é¥°å™¨ï¼Œç¦æ­¢è¿›è¡Œæ¢¯åº¦è®¡ç®—
@torch.no_grad()
# å°†æ¨¡å‹çš„æƒé‡å¤åˆ¶/ç²˜è´´/è°ƒæ•´åˆ°transformersè®¾è®¡ä¸­
def convert_checkpoint(
    model_name,
    checkpoint_path,
    pytorch_dump_folder_path,
    config_path=None,
    repo_id=None,
):
    """
    å¤åˆ¶/ç²˜è´´/è°ƒæ•´æ¨¡å‹çš„æƒé‡åˆ°transformersè®¾è®¡ä¸­ã€‚
    """
    # å¦‚æœé…ç½®è·¯å¾„ä¸ä¸ºç©ºï¼Œåˆ™ä»é¢„è®­ç»ƒé…ç½®è·¯å¾„ä¸­åŠ è½½é…ç½®ä¿¡æ¯
    if config_path is not None:
        config = EncodecConfig.from_pretrained(config_path)
    else:
        # å¦åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„é…ç½®å¯¹è±¡
        config = EncodecConfig()

    # æ ¹æ®æ¨¡å‹åç§°è¿›è¡Œæ¡ä»¶åˆ¤æ–­
    if model_name == "encodec_24khz":
        # å¦‚æœæ¨¡å‹åç§°æ˜¯"encodec_24khz"ï¼Œåˆ™ä¸åšä»»ä½•æ”¹å˜
        pass  # é…ç½®å·²ç»æ˜¯æ­£ç¡®çš„
    elif model_name == "encodec_32khz":
        # å¦‚æœæ¨¡å‹åç§°æ˜¯"encodec_32khz"ï¼Œåˆ™è®¾ç½®ç‰¹å®šçš„é…ç½®å‚æ•°
        config.upsampling_ratios = [8, 5, 4, 4]
        config.target_bandwidths = [2.2]
        config.num_filters = 64
        config.sampling_rate = 32_000
        config.codebook_size = 2048
        config.use_causal_conv = False
        config.normalize = False
        config.use_conv_shortcut = False
    elif model_name == "encodec_48khz":
        # å¦‚æœæ¨¡å‹åç§°æ˜¯"encodec_48khz"ï¼Œåˆ™è®¾ç½®ç‰¹å®šçš„é…ç½®å‚æ•°
        config.upsampling_ratios = [8, 5, 4, 2]
        config.target_bandwidths = [3.0, 6.0, 12.0, 24.0]
        config.sampling_rate = 48_000
        config.audio_channels = 2
        config.use_causal_conv = False
        config.norm_type = "time_group_norm"
        config.normalize = True
        config.chunk_length_s = 1.0
        config.overlap = 0.01
    else:
        # æ¨¡å‹åç§°æœªçŸ¥åˆ™æŠ›å‡ºæ•°å€¼é”™è¯¯
        raise ValueError(f"Unknown model name: {model_name}")

    # æ ¹æ®é…ç½®åˆ›å»ºæ¨¡å‹
    model = EncodecModel(config)

    # åˆ›å»ºç‰¹å¾æå–å™¨
    feature_extractor = EncodecFeatureExtractor(
        feature_size=config.audio_channels,
        sampling_rate=config.sampling_rate,
        chunk_length_s=config.chunk_length_s,
        overlap=config.overlap,
    )
    # å°†ç‰¹å¾æå–å™¨ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
    feature_extractor.save_pretrained(pytorch_dump_folder_path)

    # åŠ è½½åŸå§‹æ£€æŸ¥ç‚¹
    original_checkpoint = torch.load(checkpoint_path)
    if "best_state" in original_checkpoint:
        # å¦‚æœåŸå§‹æ£€æŸ¥ç‚¹ä¸­åŒ…å«"best_state"ï¼Œåˆ™å¯èƒ½æœ‰ä¿å­˜çš„è®­ç»ƒçŠ¶æ€ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ä¸¢å¼ƒyamlç»“æœï¼Œä»…ä¿ç•™æƒé‡
        original_checkpoint = original_checkpoint["best_state"]
    # é€’å½’åŠ è½½æƒé‡
    recursively_load_weights(original_checkpoint, model, model_name)
    # å°†æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
    model.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœå­˜åœ¨repo_idï¼Œåˆ™å°†ç‰¹å¾æå–å™¨å’Œæ¨¡å‹æ¨é€åˆ°hub
    if repo_id:
        print("Pushing to the hub...")
        feature_extractor.push_to_hub(repo_id)
        model.push_to_hub(repo_id)


if __name__ == "__main__":
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--model",
        default="encodec_24khz",
        type=str,
        help="è¦è½¬æ¢çš„æ¨¡å‹ã€‚åº”ä¸º'encodec_24khz'ã€'encodec_32khz'ã€'encodec_48khz'ä¹‹ä¸€ã€‚"
    )
    parser.add_argument("--checkpoint_path", required=True, default=None, type=str, help="åŸå§‹æ£€æŸ¥ç‚¹çš„è·¯å¾„")
    parser.add_argument("--config_path", default=None, type=str, help="è¦è½¬æ¢çš„æ¨¡å‹çš„hf config.jsonçš„è·¯å¾„")
    parser.add_argument(
        "--pytorch_dump_folder_path", required=True, default=None, type=str, help="è¾“å‡ºPyTorchæ¨¡å‹çš„è·¯å¾„ã€‚"
    )
    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="å°†è½¬æ¢åçš„æ¨¡å‹ä¸Šä¼ åˆ°ğŸ¤— hubçš„ä½ç½®ã€‚"
    )
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    # è°ƒç”¨ convert_checkpoint å‡½æ•°ï¼Œä¼ å…¥å‚æ•°ï¼šæ¨¡å‹åç§°ã€æ£€æŸ¥ç‚¹è·¯å¾„ã€PyTorchè½¬å‚¨æ–‡ä»¶å¤¹è·¯å¾„ã€é…ç½®æ–‡ä»¶è·¯å¾„ã€æ˜¯å¦æ¨é€åˆ°Hub
    convert_checkpoint(
        args.model,  # æ¨¡å‹åç§°
        args.checkpoint_path,  # æ£€æŸ¥ç‚¹è·¯å¾„
        args.pytorch_dump_folder_path,  # PyTorchè½¬å‚¨æ–‡ä»¶å¤¹è·¯å¾„
        args.config_path,  # é…ç½®æ–‡ä»¶è·¯å¾„
        args.push_to_hub,  # æ˜¯å¦æ¨é€åˆ°Hub
    )
```