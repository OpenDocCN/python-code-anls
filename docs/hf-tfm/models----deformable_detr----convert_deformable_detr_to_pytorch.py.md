# `.\models\deformable_detr\convert_deformable_detr_to_pytorch.py`

```
# ä»çŠ¶æ€å­—å…¸ä¸­é‡å‘½åé”®ï¼Œæ ¹æ®ç‰¹å®šè§„åˆ™è¿›è¡Œæ›¿æ¢
def rename_key(orig_key):
    if "backbone.0.body" in orig_key:
        orig_key = orig_key.replace("backbone.0.body", "backbone.conv_encoder.model")
    if "transformer" in orig_key:
        orig_key = orig_key.replace("transformer.", "")
    if "norm1" in orig_key:
        # æ ¹æ®ä¸Šä¸‹æ–‡æ›¿æ¢å±‚æ¬¡è§„èŒƒåŒ–çš„é”®åï¼ŒåŒºåˆ†ç¼–ç å™¨å’Œè§£ç å™¨çš„æƒ…å†µ
        if "encoder" in orig_key:
            orig_key = orig_key.replace("norm1", "self_attn_layer_norm")
        else:
            orig_key = orig_key.replace("norm1", "encoder_attn_layer_norm")
    if "norm2" in orig_key:
        # æ ¹æ®ä¸Šä¸‹æ–‡æ›¿æ¢å±‚æ¬¡è§„èŒƒåŒ–çš„é”®åï¼ŒåŒºåˆ†ç¼–ç å™¨å’Œè§£ç å™¨çš„æƒ…å†µ
        if "encoder" in orig_key:
            orig_key = orig_key.replace("norm2", "final_layer_norm")
        else:
            orig_key = orig_key.replace("norm2", "self_attn_layer_norm")
    if "norm3" in orig_key:
        # æ›¿æ¢æœ€ç»ˆå±‚æ¬¡è§„èŒƒåŒ–çš„é”®å
        orig_key = orig_key.replace("norm3", "final_layer_norm")
    if "linear1" in orig_key:
        # æ›¿æ¢ç¬¬ä¸€ä¸ªçº¿æ€§å±‚çš„é”®å
        orig_key = orig_key.replace("linear1", "fc1")
    if "linear2" in orig_key:
        # æ›¿æ¢ç¬¬äºŒä¸ªçº¿æ€§å±‚çš„é”®å
        orig_key = orig_key.replace("linear2", "fc2")
    if "query_embed" in orig_key:
        # æ›¿æ¢æŸ¥è¯¢ä½ç½®åµŒå…¥çš„é”®å
        orig_key = orig_key.replace("query_embed", "query_position_embeddings")
    if "cross_attn" in orig_key:
        # æ›¿æ¢äº¤å‰æ³¨æ„åŠ›çš„é”®å
        orig_key = orig_key.replace("cross_attn", "encoder_attn")

    return orig_key


# ä»çŠ¶æ€å­—å…¸ä¸­è¯»å–æŸ¥è¯¢ã€é”®å’Œå€¼
def read_in_q_k_v(state_dict):
    # å¾ªç¯éå†èŒƒå›´ä¸º0åˆ°5ï¼Œå…±6æ¬¡ï¼Œå¤„ç†æ¯ä¸ªè‡ªæ³¨æ„åŠ›å±‚çš„æƒé‡å’Œåç½®
    for i in range(6):
        # ä»çŠ¶æ€å­—å…¸ä¸­å¼¹å‡ºå½“å‰è‡ªæ³¨æ„åŠ›å±‚è¾“å…¥æŠ•å½±å±‚çš„æƒé‡å’Œåç½®
        in_proj_weight = state_dict.pop(f"decoder.layers.{i}.self_attn.in_proj_weight")
        in_proj_bias = state_dict.pop(f"decoder.layers.{i}.self_attn.in_proj_bias")
        
        # å°†æƒé‡åˆ‡ç‰‡åˆ†é…ç»™æŸ¥è¯¢ã€é”®å’Œå€¼æŠ•å½±å±‚çš„æƒé‡
        state_dict[f"decoder.layers.{i}.self_attn.q_proj.weight"] = in_proj_weight[:256, :]
        # å°†åç½®åˆ‡ç‰‡åˆ†é…ç»™æŸ¥è¯¢æŠ•å½±å±‚çš„åç½®
        state_dict[f"decoder.layers.{i}.self_attn.q_proj.bias"] = in_proj_bias[:256]
        # å°†æƒé‡åˆ‡ç‰‡åˆ†é…ç»™é”®æŠ•å½±å±‚çš„æƒé‡
        state_dict[f"decoder.layers.{i}.self_attn.k_proj.weight"] = in_proj_weight[256:512, :]
        # å°†åç½®åˆ‡ç‰‡åˆ†é…ç»™é”®æŠ•å½±å±‚çš„åç½®
        state_dict[f"decoder.layers.{i}.self_attn.k_proj.bias"] = in_proj_bias[256:512]
        # å°†æƒé‡åˆ‡ç‰‡åˆ†é…ç»™å€¼æŠ•å½±å±‚çš„æƒé‡
        state_dict[f"decoder.layers.{i}.self_attn.v_proj.weight"] = in_proj_weight[-256:, :]
        # å°†åç½®åˆ‡ç‰‡åˆ†é…ç»™å€¼æŠ•å½±å±‚çš„åç½®
        state_dict[f"decoder.layers.{i}.self_attn.v_proj.bias"] = in_proj_bias[-256:]
# æˆ‘ä»¬å°†åœ¨ä¸€å¼ å¯çˆ±çŒ«å’ªçš„å›¾ç‰‡ä¸ŠéªŒè¯æˆ‘ä»¬çš„ç»“æœ
def prepare_img():
    # å›¾ç‰‡çš„ URL åœ°å€
    url = "http://images.cocodataset.org/val2017/000000039769.jpg"
    # é€šè¿‡è¯·æ±‚è·å–å›¾ç‰‡çš„åŸå§‹äºŒè¿›åˆ¶æ•°æ®æµï¼Œå¹¶ç”¨ PIL æ‰“å¼€è¿™ä¸ªå›¾ç‰‡
    im = Image.open(requests.get(url, stream=True).raw)

    return im


@torch.no_grad()
def convert_deformable_detr_checkpoint(
    checkpoint_path,
    single_scale,
    dilation,
    with_box_refine,
    two_stage,
    pytorch_dump_folder_path,
    push_to_hub,
):
    """
    å¤åˆ¶/ç²˜è´´/è°ƒæ•´æ¨¡å‹çš„æƒé‡ä»¥é€‚åº”æˆ‘ä»¬çš„ Deformable DETR ç»“æ„ã€‚
    """

    # åŠ è½½é»˜è®¤é…ç½®
    config = DeformableDetrConfig()
    # è®¾ç½®é…ç½®å±æ€§
    if single_scale:
        config.num_feature_levels = 1  # è®¾ç½®ç‰¹å¾å±‚çº§æ•°ä¸º1
    config.dilation = dilation  # è®¾ç½®è†¨èƒ€å‚æ•°
    config.with_box_refine = with_box_refine  # è®¾ç½®æ˜¯å¦è¿›è¡Œæ¡†è°ƒæ•´
    config.two_stage = two_stage  # è®¾ç½®æ˜¯å¦ä¸ºä¸¤é˜¶æ®µæ¨¡å‹
    # è®¾ç½®æ ‡ç­¾æ•°ç›®
    config.num_labels = 91
    repo_id = "huggingface/label-files"
    filename = "coco-detection-id2label.json"
    # ä» HuggingFace Hub ä¸‹è½½å¹¶åŠ è½½ COCO æ£€æµ‹æ ‡ç­¾æ˜ å°„æ–‡ä»¶
    id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type="dataset")), "r"))
    id2label = {int(k): v for k, v in id2label.items()}
    config.id2label = id2label  # è®¾ç½® ID åˆ°æ ‡ç­¾çš„æ˜ å°„
    config.label2id = {v: k for k, v in id2label.items()}  # è®¾ç½®æ ‡ç­¾åˆ° ID çš„æ˜ å°„

    # åŠ è½½å›¾åƒå¤„ç†å™¨
    image_processor = DeformableDetrImageProcessor(format="coco_detection")

    # å‡†å¤‡å›¾ç‰‡
    img = prepare_img()  # è°ƒç”¨å‡†å¤‡å›¾ç‰‡å‡½æ•°è·å–å›¾ç‰‡å¯¹è±¡
    encoding = image_processor(images=img, return_tensors="pt")  # å¯¹å›¾ç‰‡è¿›è¡Œç¼–ç å¤„ç†
    pixel_values = encoding["pixel_values"]  # è·å–åƒç´ æ•°å€¼

    logger.info("Converting model...")  # è®°å½•æ—¥å¿—ï¼Œè¡¨ç¤ºæ­£åœ¨è½¬æ¢æ¨¡å‹

    # åŠ è½½åŸå§‹çš„çŠ¶æ€å­—å…¸
    state_dict = torch.load(checkpoint_path, map_location="cpu")["model"]
    # é‡å‘½åé”®å
    for key in state_dict.copy().keys():
        val = state_dict.pop(key)
        state_dict[rename_key(key)] = val
    # æŸ¥è¯¢ã€é”®ã€å€¼çŸ©é˜µéœ€è¦ç‰¹æ®Šå¤„ç†
    read_in_q_k_v(state_dict)
    # é‡è¦ï¼šéœ€è¦åœ¨æ¯ä¸ªåŸºç¡€æ¨¡å‹é”®åå‰æ·»åŠ å‰ç¼€ï¼Œå› ä¸ºå¤´éƒ¨æ¨¡å‹ä½¿ç”¨ä¸åŒçš„å±æ€§
    prefix = "model."
    for key in state_dict.copy().keys():
        if not key.startswith("class_embed") and not key.startswith("bbox_embed"):
            val = state_dict.pop(key)
            state_dict[prefix + key] = val
    # æœ€åï¼Œåˆ›å»º HuggingFace æ¨¡å‹å¹¶åŠ è½½çŠ¶æ€å­—å…¸
    model = DeformableDetrForObjectDetection(config)
    model.load_state_dict(state_dict)
    model.eval()

    device = "cuda" if torch.cuda.is_available() else "cpu"  # æ£€æµ‹è®¾å¤‡æ˜¯å¦æ”¯æŒ CUDA
    model.to(device)  # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
    # éªŒè¯è½¬æ¢ç»“æœ
    outputs = model(pixel_values.to(device))

    expected_logits = torch.tensor(
        [[-9.6645, -4.3449, -5.8705], [-9.7035, -3.8504, -5.0724], [-10.5634, -5.3379, -7.5116]]
    )
    expected_boxes = torch.tensor([[0.8693, 0.2289, 0.2492], [0.3150, 0.5489, 0.5845], [0.5563, 0.7580, 0.8518]])

    if single_scale:
        expected_logits = torch.tensor(
            [[-9.9051, -4.2541, -6.4852], [-9.6947, -4.0854, -6.8033], [-10.0665, -5.8470, -7.7003]]
        )
        expected_boxes = torch.tensor([[0.7292, 0.4991, 0.5532], [0.7959, 0.2426, 0.4236], [0.7582, 0.3518, 0.4451]])
    # å¦‚æœé€‰æ‹©äº†å•å°ºåº¦å’Œæ‰©å¼ æ“ä½œï¼Œåˆ™è®¾å®šé¢„æœŸçš„åˆ†ç±» logits å’Œè¾¹ç•Œæ¡†
    if single_scale and dilation:
        expected_logits = torch.tensor(
            [[-8.9652, -4.1074, -5.6635], [-9.0596, -4.9447, -6.6075], [-10.1178, -4.5275, -6.2671]]
        )
        expected_boxes = torch.tensor([[0.7665, 0.4130, 0.4769], [0.8364, 0.1841, 0.3391], [0.6261, 0.3895, 0.7978]])

    # å¦‚æœéœ€è¦è¿›è¡Œè¾¹ç•Œæ¡†ç»†åŒ–ï¼Œåˆ™è®¾å®šé¢„æœŸçš„åˆ†ç±» logits å’Œè¾¹ç•Œæ¡†
    if with_box_refine:
        expected_logits = torch.tensor(
            [[-8.8895, -5.4187, -6.8153], [-8.4706, -6.1668, -7.6184], [-9.0042, -5.5359, -6.9141]]
        )
        expected_boxes = torch.tensor([[0.7828, 0.2208, 0.4323], [0.0892, 0.5996, 0.1319], [0.5524, 0.6389, 0.8914]])

    # å¦‚æœåŒæ—¶éœ€è¦è¾¹ç•Œæ¡†ç»†åŒ–å’Œä¸¤é˜¶æ®µæ“ä½œï¼Œåˆ™è®¾å®šé¢„æœŸçš„åˆ†ç±» logits å’Œè¾¹ç•Œæ¡†
    if with_box_refine and two_stage:
        expected_logits = torch.tensor(
            [[-6.7108, -4.3213, -6.3777], [-8.9014, -6.1799, -6.7240], [-6.9315, -4.4735, -6.2298]]
        )
        expected_boxes = torch.tensor([[0.2583, 0.5499, 0.4683], [0.7652, 0.9068, 0.4882], [0.5490, 0.2763, 0.0564]])

    # æ‰“å°æ¨¡å‹è¾“å‡ºçš„å‰ä¸‰è¡Œä¸‰åˆ—çš„ logits
    print("Logits:", outputs.logits[0, :3, :3])

    # æ–­è¨€æ¨¡å‹è¾“å‡ºçš„å‰ä¸‰è¡Œä¸‰åˆ—çš„ logits å’Œé¢„æœŸçš„ logits åœ¨ç»™å®šçš„è¯¯å·®èŒƒå›´å†…ç›¸ä¼¼
    assert torch.allclose(outputs.logits[0, :3, :3], expected_logits.to(device), atol=1e-4)
    # æ–­è¨€æ¨¡å‹è¾“å‡ºçš„å‰ä¸‰è¡Œä¸‰åˆ—çš„é¢„æµ‹è¾¹ç•Œæ¡†å’Œé¢„æœŸçš„è¾¹ç•Œæ¡†åœ¨ç»™å®šçš„è¯¯å·®èŒƒå›´å†…ç›¸ä¼¼
    assert torch.allclose(outputs.pred_boxes[0, :3, :3], expected_boxes.to(device), atol=1e-4)

    # æ‰“å°ä¿¡æ¯ï¼Œè¡¨æ˜ä¸€åˆ‡æ­£å¸¸
    print("Everything ok!")

    # ä¿å­˜ PyTorch æ¨¡å‹å’Œå›¾åƒå¤„ç†å™¨åˆ°æŒ‡å®šè·¯å¾„
    logger.info(f"Saving PyTorch model and image processor to {pytorch_dump_folder_path}...")
    # ç¡®ä¿ä¿å­˜æ¨¡å‹å’Œå¤„ç†å™¨çš„æ–‡ä»¶å¤¹å­˜åœ¨
    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)
    # è°ƒç”¨æ¨¡å‹çš„ä¿å­˜æ–¹æ³•å’Œå›¾åƒå¤„ç†å™¨çš„ä¿å­˜æ–¹æ³•
    model.save_pretrained(pytorch_dump_folder_path)
    image_processor.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœéœ€è¦å°†æ¨¡å‹æ¨é€åˆ° Hub ä¸Šï¼Œåˆ™è¿›è¡Œç›¸åº”æ“ä½œ
    if push_to_hub:
        # æ„é€ æ¨¡å‹çš„åç§°ï¼Œæ ¹æ®é€‰æ‹©çš„å‚æ•°æ·»åŠ åç¼€
        model_name = "deformable-detr"
        model_name += "-single-scale" if single_scale else ""
        model_name += "-dc5" if dilation else ""
        model_name += "-with-box-refine" if with_box_refine else ""
        model_name += "-two-stage" if two_stage else ""
        # æ‰“å°æç¤ºä¿¡æ¯ï¼Œè¡¨æ˜æ­£åœ¨å°†æ¨¡å‹æ¨é€åˆ° Hub ä¸Š
        print("Pushing model to hub...")
        # è°ƒç”¨æ¨¡å‹å¯¹è±¡çš„æ¨é€åˆ° Hub çš„æ–¹æ³•
        model.push_to_hub(repo_path_or_name=model_name, organization="nielsr", commit_message="Add model")
# å¦‚æœå½“å‰è„šæœ¬ä½œä¸ºä¸»ç¨‹åºæ‰§è¡Œï¼ˆè€Œä¸æ˜¯è¢«å¯¼å…¥ä¸ºæ¨¡å—ï¼‰ï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹ä»£ç å—
if __name__ == "__main__":
    # åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser()

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šcheckpoint_pathï¼Œç”¨äºæŒ‡å®š PyTorch checkpoint æ–‡ä»¶çš„è·¯å¾„
    parser.add_argument(
        "--checkpoint_path",
        type=str,
        default="/home/niels/checkpoints/deformable_detr/r50_deformable_detr-checkpoint.pth",
        help="Path to Pytorch checkpoint (.pth file) you'd like to convert.",
    )

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šsingle_scaleï¼Œè®¾ç½®ä¸º True åˆ™è®¾ç½® config.num_features_levels = 1
    parser.add_argument("--single_scale", action="store_true", help="Whether to set config.num_features_levels = 1.")

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šdilationï¼Œè®¾ç½®ä¸º True åˆ™è®¾ç½® config.dilation=True
    parser.add_argument("--dilation", action="store_true", help="Whether to set config.dilation=True.")

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šwith_box_refineï¼Œè®¾ç½®ä¸º True åˆ™è®¾ç½® config.with_box_refine=True
    parser.add_argument("--with_box_refine", action="store_true", help="Whether to set config.with_box_refine=True.")

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼štwo_stageï¼Œè®¾ç½®ä¸º True åˆ™è®¾ç½® config.two_stage=True
    parser.add_argument("--two_stage", action="store_true", help="Whether to set config.two_stage=True.")

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼špytorch_dump_folder_pathï¼Œå¿…éœ€çš„å‚æ•°ï¼ŒæŒ‡å®šè¾“å‡º PyTorch æ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„
    parser.add_argument(
        "--pytorch_dump_folder_path",
        default=None,
        type=str,
        required=True,
        help="Path to the folder to output PyTorch model.",
    )

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼špush_to_hubï¼Œè®¾ç½®ä¸º True åˆ™è¡¨ç¤ºè¦å°†è½¬æ¢åçš„æ¨¡å‹æ¨é€åˆ° ğŸ¤— hub
    parser.add_argument(
        "--push_to_hub", action="store_true", help="Whether or not to push the converted model to the ğŸ¤— hub."
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å°†å…¶ä¿å­˜åˆ° args å˜é‡ä¸­
    args = parser.parse_args()

    # è°ƒç”¨å‡½æ•° convert_deformable_detr_checkpointï¼Œå¹¶ä¼ å…¥å‘½ä»¤è¡Œå‚æ•°ä¸­çš„ç›¸åº”å€¼
    convert_deformable_detr_checkpoint(
        args.checkpoint_path,
        args.single_scale,
        args.dilation,
        args.with_box_refine,
        args.two_stage,
        args.pytorch_dump_folder_path,
        args.push_to_hub,
    )
```