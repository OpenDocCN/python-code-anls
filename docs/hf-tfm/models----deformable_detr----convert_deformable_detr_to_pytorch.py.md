# `.\models\deformable_detr\convert_deformable_detr_to_pytorch.py`

```
def read_in_q_k_v(state_dict):
    # è¯»å–å˜é‡ state_dict ä¸­çš„é”®ï¼Œéå†æ¯ä¸ªé”®
    for key in state_dict.keys():
        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å« 'cross_attn'ï¼Œè¡¨ç¤ºäº¤å‰æ³¨æ„åŠ›
        if "cross_attn" in key:
            # å¦‚æœæ˜¯äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œå°†é”®åä¸­çš„ 'cross_attn' æ›¿æ¢ä¸º 'encoder_attn'ï¼Œè¡¨ç¤ºç¼–ç å™¨æ³¨æ„åŠ›
            state_dict[key.replace("cross_attn", "encoder_attn")] = state_dict.pop(key)
        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å« 'query_embed'ï¼Œè¡¨ç¤ºæŸ¥è¯¢åµŒå…¥
        elif "query_embed" in key:
            # å¦‚æœæ˜¯æŸ¥è¯¢åµŒå…¥ï¼Œå°†é”®åä¸­çš„ 'query_embed' æ›¿æ¢ä¸º 'query_position_embeddings'ï¼Œè¡¨ç¤ºæŸ¥è¯¢ä½ç½®åµŒå…¥
            state_dict[key.replace("query_embed", "query_position_embeddings")] = state_dict.pop(key)
        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å« 'linear2'ï¼Œè¡¨ç¤ºç¬¬äºŒä¸ªçº¿æ€§å±‚
        elif "linear2" in key:
            # å¦‚æœæ˜¯ç¬¬äºŒä¸ªçº¿æ€§å±‚ï¼Œå°†é”®åä¸­çš„ 'linear2' æ›¿æ¢ä¸º 'fc2'ï¼Œè¡¨ç¤ºå…¨è¿æ¥å±‚2
            state_dict[key.replace("linear2", "fc2")] = state_dict.pop(key)
        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å« 'linear1'ï¼Œè¡¨ç¤ºç¬¬ä¸€ä¸ªçº¿æ€§å±‚
        elif "linear1" in key:
            # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªçº¿æ€§å±‚ï¼Œå°†é”®åä¸­çš„ 'linear1' æ›¿æ¢ä¸º 'fc1'ï¼Œè¡¨ç¤ºå…¨è¿æ¥å±‚1
            state_dict[key.replace("linear1", "fc1")] = state_dict.pop(key)
        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å« 'norm3'ï¼Œè¡¨ç¤ºç¬¬ä¸‰ä¸ªå½’ä¸€åŒ–å±‚
        elif "norm3" in key:
            # å¦‚æœæ˜¯ç¬¬ä¸‰ä¸ªå½’ä¸€åŒ–å±‚ï¼Œå°†é”®åä¸­çš„ 'norm3' æ›¿æ¢ä¸º 'final_layer_norm'ï¼Œè¡¨ç¤ºæœ€ç»ˆå½’ä¸€åŒ–å±‚
            state_dict[key.replace("norm3", "final_layer_norm")] = state_dict.pop(key)
        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å« 'norm2'ï¼Œè¡¨ç¤ºç¬¬äºŒä¸ªå½’ä¸€åŒ–å±‚
        elif "norm2" in key:
            # å¦‚æœæ˜¯ç¬¬äºŒä¸ªå½’ä¸€åŒ–å±‚ï¼Œæ£€æŸ¥æ˜¯å¦å±äºç¼–ç å™¨
            if "encoder" in key:
                # å¦‚æœæ˜¯ç¼–ç å™¨çš„å½’ä¸€åŒ–å±‚ï¼Œå°†é”®åä¸­çš„ 'norm2' æ›¿æ¢ä¸º 'final_layer_norm'ï¼Œè¡¨ç¤ºæœ€ç»ˆå½’ä¸€åŒ–å±‚
                state_dict[key.replace("norm2", "final_layer_norm")] = state_dict.pop(key)
            else:
                # å¦‚æœä¸æ˜¯ç¼–ç å™¨çš„å½’ä¸€åŒ–å±‚ï¼Œå°†é”®åä¸­çš„ 'norm2' æ›¿æ¢ä¸º 'self_attn_layer_norm'ï¼Œè¡¨ç¤ºè‡ªæ³¨æ„åŠ›å½’ä¸€åŒ–å±‚
                state_dict[key.replace("norm2", "self_attn_layer_norm")] = state_dict.pop(key)
        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å« 'norm1'ï¼Œè¡¨ç¤ºç¬¬ä¸€ä¸ªå½’ä¸€åŒ–å±‚
        elif "norm1" in key:
            # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªå½’ä¸€åŒ–å±‚ï¼Œæ£€æŸ¥æ˜¯å¦å±äºç¼–ç å™¨
            if "encoder" in key:
                # å¦‚æœæ˜¯ç¼–ç å™¨çš„å½’ä¸€åŒ–å±‚ï¼Œå°†é”®åä¸­çš„ 'norm1' æ›¿æ¢ä¸º 'self_attn_layer_norm'ï¼Œè¡¨ç¤ºè‡ªæ³¨æ„åŠ›å½’ä¸€åŒ–å±‚
                state_dict[key.replace("norm1", "self_attn_layer_norm")] = state_dict.pop(key)
            else:
                # å¦‚æœä¸æ˜¯ç¼–ç å™¨çš„å½’ä¸€åŒ–å±‚ï¼Œå°†é”®åä¸­çš„ 'norm1' æ›¿æ¢ä¸º 'encoder_attn_layer_norm'ï¼Œè¡¨ç¤ºç¼–ç å™¨æ³¨æ„åŠ›å½’ä¸€åŒ–å±‚
                state_dict[key.replace("norm1", "encoder_attn_layer_norm")] = state_dict.pop(key)
        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å« 'transformer'ï¼Œè¡¨ç¤ºå˜æ¢å™¨
        elif "transformer" in key:
            # å¦‚æœæ˜¯å˜æ¢å™¨å±‚ï¼Œå°†é”®åä¸­çš„ 'transformer' æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
            state_dict[key.replace("transformer.", "")] = state_dict.pop(key)
        # æ£€æŸ¥é”®åæ˜¯å¦åŒ…å« 'backbone.0.body'ï¼Œè¡¨ç¤ºéª¨å¹²ç½‘ç»œ
        elif "backbone.0.body" in key:
            # å¦‚æœæ˜¯éª¨å¹²ç½‘ç»œï¼Œå°†é”®åä¸­çš„ 'backbone.0.body' æ›¿æ¢ä¸º 'backbone.conv_encoder.model'ï¼Œè¡¨ç¤ºå·ç§¯ç¼–ç å™¨æ¨¡å‹
            state_dict[key.replace("backbone.0.body", "backbone.conv_encoder.model")] = state_dict.pop(key)
    # è¿”å›å¤„ç†åçš„ state_dict
    return state_dict
    # éå†èŒƒå›´ä¸º0åˆ°5çš„æ•´æ•°ï¼Œè¡¨ç¤ºè¦å¤„ç†è§£ç å™¨ä¸­çš„æ¯ä¸€å±‚
    for i in range(6):
        # å¼¹å‡ºå­˜å‚¨åœ¨çŠ¶æ€å­—å…¸ä¸­çš„è‡ªæ³¨æ„åŠ›å±‚çš„è¾“å…¥æŠ•å½±å±‚çš„æƒé‡å’Œåç½®é¡¹
        in_proj_weight = state_dict.pop(f"decoder.layers.{i}.self_attn.in_proj_weight")
        in_proj_bias = state_dict.pop(f"decoder.layers.{i}.self_attn.in_proj_bias")
        
        # å°†æƒé‡æŒ‰ç…§ç‰¹å®šè§„åˆ™åˆ†é…ç»™æŸ¥è¯¢ã€é”®å’Œå€¼çš„æŠ•å½±å±‚
        # æŸ¥è¯¢æŠ•å½±å±‚æƒé‡ï¼šå–in_proj_weightçš„å‰256è¡Œï¼ˆå¯¹åº”æŸ¥è¯¢éƒ¨åˆ†ï¼‰ï¼Œæ‰€æœ‰åˆ—
        state_dict[f"decoder.layers.{i}.self_attn.q_proj.weight"] = in_proj_weight[:256, :]
        # æŸ¥è¯¢æŠ•å½±å±‚åç½®ï¼šå–in_proj_biasçš„å‰256ä¸ªå…ƒç´ ï¼ˆå¯¹åº”æŸ¥è¯¢éƒ¨åˆ†ï¼‰
        state_dict[f"decoder.layers.{i}.self_attn.q_proj.bias"] = in_proj_bias[:256]
        # é”®æŠ•å½±å±‚æƒé‡ï¼šå–in_proj_weightçš„ç¬¬256åˆ°511è¡Œï¼ˆå¯¹åº”é”®éƒ¨åˆ†ï¼‰ï¼Œæ‰€æœ‰åˆ—
        state_dict[f"decoder.layers.{i}.self_attn.k_proj.weight"] = in_proj_weight[256:512, :]
        # é”®æŠ•å½±å±‚åç½®ï¼šå–in_proj_biasçš„ç¬¬256åˆ°511ä¸ªå…ƒç´ ï¼ˆå¯¹åº”é”®éƒ¨åˆ†ï¼‰
        state_dict[f"decoder.layers.{i}.self_attn.k_proj.bias"] = in_proj_bias[256:512]
        # å€¼æŠ•å½±å±‚æƒé‡ï¼šå–in_proj_weightçš„æœ€å256è¡Œï¼ˆå¯¹åº”å€¼éƒ¨åˆ†ï¼‰ï¼Œæ‰€æœ‰åˆ—
        state_dict[f"decoder.layers.{i}.self_attn.v_proj.weight"] = in_proj_weight[-256:, :]
        # å€¼æŠ•å½±å±‚åç½®ï¼šå–in_proj_biasçš„æœ€å256ä¸ªå…ƒç´ ï¼ˆå¯¹åº”å€¼éƒ¨åˆ†ï¼‰
        state_dict[f"decoder.layers.{i}.self_attn.v_proj.bias"] = in_proj_bias[-256:]
# å¯¼å…¥æ‰€éœ€æ¨¡å—
from PIL import Image
import requests
import torch
import json
import logging

# å‡†å¤‡å¾…å¤„ç†çš„å›¾åƒ
def prepare_img():
    # å›¾åƒåœ°å€
    url = "http://images.cocodataset.org/val2017/000000039769.jpg"
    # ä½¿ç”¨ requests æ¨¡å—è·å–å›¾åƒï¼Œå¹¶å°è£…æˆ PIL.Image å¯¹è±¡
    im = Image.open(requests.get(url, stream=True).raw)

    return im

# ç”¨äºæ¨¡å‹æƒé‡è½¬æ¢çš„å‡½æ•°
@torch.no_grad()
def convert_deformable_detr_checkpoint(
    checkpoint_path,  # æºæ¨¡å‹çš„è·¯å¾„
    single_scale,  # æ˜¯å¦ä¸ºå•å°ºåº¦æ¨¡å‹
    dilation,  # æ˜¯å¦ä½¿ç”¨ç©ºæ´å·ç§¯
    with_box_refine,  # æ˜¯å¦è¿›è¡Œè¾¹ç•Œæ¡†å¾®è°ƒ
    two_stage,  # æ˜¯å¦è¿›è¡Œä¸¤é˜¶æ®µç›®æ ‡æ£€æµ‹
    pytorch_dump_folder_path,  # å¯¼å‡ºè½¬æ¢åæ¨¡å‹çš„è·¯å¾„
    push_to_hub  # æ˜¯å¦æ¨é€æ¨¡å‹åˆ° HuggingFace Hub
):
    """
    å°†æ¨¡å‹çš„æƒé‡å¤åˆ¶/ç²˜è´´/è°ƒæ•´ä»¥é€‚åº”æˆ‘ä»¬çš„ Deformable DETR ç»“æ„ã€‚
    """

    # åŠ è½½é»˜è®¤é…ç½®
    config = DeformableDetrConfig()
    # è®¾ç½®é…ç½®å±æ€§
    if single_scale:
        config.num_feature_levels = 1
    config.dilation = dilation
    config.with_box_refine = with_box_refine
    config.two_stage = two_stage
    # è®¾ç½®æ ‡ç­¾
    config.num_labels = 91
    # ä» HuggingFace Hub ä¸‹è½½æ ‡ç­¾æ–‡ä»¶ï¼Œå¹¶åŠ è½½ä¸º id åˆ° label çš„æ˜ å°„å…³ç³»
    repo_id = "huggingface/label-files"
    filename = "coco-detection-id2label.json"
    id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type="dataset")), "r"))
    id2label = {int(k): v for k, v in id2label.items()}
    config.id2label = id2label
    config.label2id = {v: k for k, v in id2label.items()}

    # åŠ è½½å›¾åƒå¤„ç†å™¨
    image_processor = DeformableDetrImageProcessor(format="coco_detection")

    # å‡†å¤‡å›¾åƒ
    img = prepare_img()
    # ä½¿ç”¨å›¾åƒå¤„ç†å™¨å°†å›¾åƒç¼–ç ä¸º Tensor
    encoding = image_processor(images=img, return_tensors="pt")
    pixel_values = encoding["pixel_values"]

    logger.info("Converting model...")

    # åŠ è½½åŸå§‹æ¨¡å‹çš„æƒé‡
    state_dict = torch.load(checkpoint_path, map_location="cpu")["model"]
    # é‡å‘½åé”®
    for key in state_dict.copy().keys():
        val = state_dict.pop(key)
        state_dict[rename_key(key)] = val
    # å¯¹æŸ¥è¯¢ã€é”®å’Œå€¼çŸ©é˜µè¿›è¡Œç‰¹æ®Šå¤„ç†
    read_in_q_k_v(state_dict)
    # éœ€è¦ä¸ºåŸºç¡€æ¨¡å‹çš„æ¯ä¸ªé”®æ·»åŠ å‰ç¼€ï¼Œå› ä¸ºå¤´æ¨¡å‹ä½¿ç”¨ä¸åŒçš„å±æ€§
    prefix = "model."
    for key in state_dict.copy().keys():
        if not key.startswith("class_embed") and not key.startswith("bbox_embed"):
            val = state_dict.pop(key)
            state_dict[prefix + key] = val
    # åˆ›å»º HuggingFace æ¨¡å‹å¹¶åŠ è½½æƒé‡
    model = DeformableDetrForObjectDetection(config)
    model.load_state_dict(state_dict)
    model.eval()

    # ï¿½ï¿½ï¿½åŠ¨æ¨¡å‹åˆ° GPU æˆ– CPU
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    # éªŒè¯æ¨¡å‹æ˜¯å¦è½¬æ¢æˆåŠŸ
    outputs = model(pixel_values.to(device))

    # é¢„æœŸçš„ logits å’Œ boxes çš„å€¼
    expected_logits = torch.tensor(
        [[-9.6645, -4.3449, -5.8705], [-9.7035, -3.8504, -5.0724], [-10.5634, -5.3379, -7.5116]]
    )
    expected_boxes = torch.tensor([[0.8693, 0.2289, 0.2492], [0.3150, 0.5489, 0.5845], [0.5563, 0.7580, 0.8518]])
    
    # å¦‚æœä½¿ç”¨å•ä¸€å°ºåº¦å¹¶ä¸”æœ‰æ‰©å¼ æ“ä½œ
    if single_scale and dilation:
        # é¢„æœŸçš„logitså€¼
        expected_logits = torch.tensor(
            [[-8.9652, -4.1074, -5.6635], [-9.0596, -4.9447, -6.6075], [-10.1178, -4.5275, -6.2671]]
        )
        # é¢„æœŸçš„ç›’å­åæ ‡å€¼
        expected_boxes = torch.tensor([[0.7665, 0.4130, 0.4769], [0.8364, 0.1841, 0.3391], [0.6261, 0.3895, 0.7978]])

    # å¦‚æœéœ€è¦ç›’å­ç»†åŒ–
    if with_box_refine:
        # é¢„æœŸçš„logitså€¼
        expected_logits = torch.tensor(
            [[-8.8895, -5.4187, -6.8153], [-8.4706, -6.1668, -7.6184], [-9.0042, -5.5359, -6.9141]]
        )
        # é¢„æœŸçš„ç›’å­åæ ‡å€¼
        expected_boxes = torch.tensor([[0.7828, 0.2208, 0.4323], [0.0892, 0.5996, 0.1319], [0.5524, 0.6389, 0.8914]])

    # å¦‚æœéœ€è¦ç›’å­ç»†åŒ–ä¸”æ˜¯ä¸¤é˜¶æ®µæ“ä½œ
    if with_box_refine and two_stage:
        # é¢„æœŸçš„logitså€¼
        expected_logits = torch.tensor(
            [[-6.7108, -4.3213, -6.3777], [-8.9014, -6.1799, -6.7240], [-6.9315, -4.4735, -6.2298]]
        )
        # é¢„æœŸçš„ç›’å­åæ ‡å€¼
        expected_boxes = torch.tensor([[0.2583, 0.5499, 0.4683], [0.7652, 0.9068, 0.4882], [0.5490, 0.2763, 0.0564]])

    # æ‰“å°logitsçš„éƒ¨åˆ†æ•°æ®å†…å®¹
    print("Logits:", outputs.logits[0, :3, :3])

    # æ–­è¨€è¾“å‡ºçš„logitså€¼å’Œé¢„æœŸçš„logitså€¼åœ¨ç»™å®šå®¹å·®å†…ç›¸ç­‰
    assert torch.allclose(outputs.logits[0, :3, :3], expected_logits.to(device), atol=1e-4)
    # æ–­è¨€è¾“å‡ºçš„ç›’å­åæ ‡å€¼å’Œé¢„æœŸçš„ç›’å­åæ ‡å€¼åœ¨ç»™å®šå®¹å·®å†…ç›¸ç­‰
    assert torch.allclose(outputs.pred_boxes[0, :3, :3], expected_boxes.to(device), atol=1e-4)

    # æ‰“å°æç¤ºä¿¡æ¯
    print("Everything ok!")

    # ä¿å­˜æ¨¡å‹å’Œå›¾åƒå¤„ç†å™¨
    logger.info(f"Saving PyTorch model and image processor to {pytorch_dump_folder_path}...")
    Path(pytorch_dump_folder_path).mkdir(exist_ok=True)
    model.save_pretrained(pytorch_dump_folder_path)
    image_processor.save_pretrained(pytorch_dump_folder_path)

    # æ¨é€åˆ°Hub
    if push_to_hub:
        model_name = "deformable-detr"
        model_name += "-single-scale" if single_scale else ""
        model_name += "-dc5" if dilation else ""
        model_name += "-with-box-refine" if with_box_refine else ""
        model_name += "-two-stage" if two_stage else ""
        print("Pushing model to hub...")
        model.push_to_hub(repo_path_or_name=model_name, organization="nielsr", commit_message="Add model")
# å¦‚æœå½“å‰è„šæœ¬æ˜¯ç›´æ¥æ‰§è¡Œçš„ä¸»è„šæœ¬ï¼Œè€Œä¸æ˜¯è¢«å¯¼å…¥çš„æ¨¡å—ï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹ä»£ç å—
if __name__ == "__main__":
    # åˆ›å»ºä¸€ä¸ªå‚æ•°è§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser()

    # æ·»åŠ ä¸€ä¸ªå‘½ä»¤è¡Œå‚æ•°ï¼Œç”¨äºæŒ‡å®šè¦è½¬æ¢çš„ PyTorch æ¨¡å‹çš„æ£€æŸ¥ç‚¹è·¯å¾„
    parser.add_argument(
        "--checkpoint_path",
        type=str,
        default="/home/niels/checkpoints/deformable_detr/r50_deformable_detr-checkpoint.pth",
        help="Path to Pytorch checkpoint (.pth file) you'd like to convert.",
    )
    
    # æ·»åŠ ä¸€ä¸ªå‘½ä»¤è¡Œå‚æ•°ï¼Œç”¨äºè®¾ç½® config.num_features_levels = 1
    parser.add_argument("--single_scale", action="store_true", help="Whether to set config.num_features_levels = 1.")
    
    # æ·»åŠ ä¸€ä¸ªå‘½ä»¤è¡Œå‚æ•°ï¼Œç”¨äºè®¾ç½® config.dilation=True
    parser.add_argument("--dilation", action="store_true", help="Whether to set config.dilation=True.")
    
    # æ·»åŠ ä¸€ä¸ªå‘½ä»¤è¡Œå‚æ•°ï¼Œç”¨äºè®¾ç½® config.with_box_refine=True
    parser.add_argument("--with_box_refine", action="store_true", help="Whether to set config.with_box_refine=True.")
    
    # æ·»åŠ ä¸€ä¸ªå‘½ä»¤è¡Œå‚æ•°ï¼Œç”¨äºè®¾ç½® config.two_stage=True
    parser.add_argument("--two_stage", action="store_true", help="Whether to set config.two_stage=True.")
    
    # æ·»åŠ ä¸€ä¸ªå‘½ä»¤è¡Œå‚æ•°ï¼Œç”¨äºæŒ‡å®šè¾“å‡º PyTorch æ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„
    parser.add_argument(
        "--pytorch_dump_folder_path",
        default=None,
        type=str,
        required=True,
        help="Path to the folder to output PyTorch model.",
    )
    
    # æ·»åŠ ä¸€ä¸ªå‘½ä»¤è¡Œå‚æ•°ï¼Œç”¨äºæ˜¯å¦å°†è½¬æ¢åçš„æ¨¡å‹æ¨é€åˆ° ğŸ¤— hub ä¸Š
    parser.add_argument(
        "--push_to_hub", action="store_true", help="Whether or not to push the converted model to the ğŸ¤— hub."
    )
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨ args å¯¹è±¡ä¸­
    args = parser.parse_args()
    
    # è°ƒç”¨ convert_deformable_detr_checkpoint å‡½æ•°ï¼Œå°†è§£æå¾—åˆ°çš„å‚æ•°ä¼ é€’ç»™å®ƒ
    convert_deformable_detr_checkpoint(
        args.checkpoint_path,
        args.single_scale,
        args.dilation,
        args.with_box_refine,
        args.two_stage,
        args.pytorch_dump_folder_path,
        args.push_to_hub,
    )
```