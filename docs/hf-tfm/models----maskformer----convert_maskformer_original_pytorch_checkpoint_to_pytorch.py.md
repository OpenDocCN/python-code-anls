# `.\models\maskformer\convert_maskformer_original_pytorch_checkpoint_to_pytorch.py`

```py
# coding=utf-8
# Copyright 2022 Meta Platforms, Inc. and The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import sys  # å¯¼å…¥ç³»ç»Ÿæ¨¡å—
from argparse import ArgumentParser  # å¯¼å…¥å‘½ä»¤è¡Œå‚æ•°è§£ææ¨¡å—
from dataclasses import dataclass  # å¯¼å…¥æ•°æ®ç±»è£…é¥°å™¨
from pathlib import Path  # å¯¼å…¥å¤„ç†è·¯å¾„çš„æ¨¡å—
from pprint import pformat  # å¯¼å…¥æ ¼å¼åŒ–è¾“å‡ºæ¨¡å—
from typing import Any, Dict, Iterator, List, Set, Tuple  # å¯¼å…¥ç±»å‹æç¤ºæ¨¡å—

import requests  # å¯¼å…¥å¤„ç† HTTP è¯·æ±‚çš„æ¨¡å—
import torch  # å¯¼å…¥ PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
import torchvision.transforms as T  # å¯¼å…¥å›¾åƒè½¬æ¢æ¨¡å—
from detectron2.checkpoint import DetectionCheckpointer  # å¯¼å…¥æ£€æŸ¥ç‚¹æ¨¡å—
from detectron2.config import get_cfg  # å¯¼å…¥é…ç½®è·å–å‡½æ•°
from detectron2.data import MetadataCatalog  # å¯¼å…¥å…ƒæ•°æ®ç›®å½•æ¨¡å—
from detectron2.projects.deeplab import add_deeplab_config  # å¯¼å…¥ DeepLab é…ç½®æ¨¡å—
from PIL import Image  # å¯¼å…¥ Python å›¾åƒå¤„ç†åº“
from torch import Tensor, nn  # å¯¼å…¥å¼ é‡å’Œç¥ç»ç½‘ç»œæ¨¡å—

# å¯¼å…¥ MaskFormer ç›¸å…³æ¨¡å—
from transformers.models.maskformer.feature_extraction_maskformer import MaskFormerImageProcessor
from transformers.models.maskformer.modeling_maskformer import (
    MaskFormerConfig,
    MaskFormerForInstanceSegmentation,
    MaskFormerForInstanceSegmentationOutput,
    MaskFormerModel,
    MaskFormerModelOutput,
)
from transformers.utils import logging  # å¯¼å…¥æ—¥å¿—æ¨¡å—

StateDict = Dict[str, Tensor]  # å®šä¹‰çŠ¶æ€å­—å…¸ç±»å‹åˆ«å

logging.set_verbosity_info()  # è®¾ç½®æ—¥å¿—è¾“å‡ºè¯¦ç»†ç¨‹åº¦ä¸ºä¿¡æ¯çº§åˆ«
logger = logging.get_logger()  # è·å–æ—¥å¿—è®°å½•å™¨å¯¹è±¡

torch.manual_seed(0)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å®éªŒç»“æœå¯å¤ç°


class TrackedStateDict:
    def __init__(self, to_track: Dict):
        """This class "tracks" a python dictionary by keeping track of which item is accessed.

        Args:
            to_track (Dict): The dictionary we wish to track
        """
        self.to_track = to_track  # åˆå§‹åŒ–è¦è·Ÿè¸ªçš„å­—å…¸
        self._seen: Set[str] = set()  # åˆå§‹åŒ–ä¸€ä¸ªé›†åˆï¼Œç”¨äºè®°å½•å·²ç»è®¿é—®çš„é”®å

    def __getitem__(self, key: str) -> Any:
        return self.to_track[key]  # è¿”å›æŒ‡å®šé”®åå¯¹åº”çš„å€¼

    def __setitem__(self, key: str, item: Any):
        self._seen.add(key)  # å°†è®¿é—®è¿‡çš„é”®åæ·»åŠ åˆ°é›†åˆä¸­
        self.to_track[key] = item  # æ›´æ–°å­—å…¸ä¸­æŒ‡å®šé”®åçš„å€¼

    def diff(self) -> List[str]:
        """This method returns a set difference between the keys in the tracked state dict and the one we have access so far.
        This is an effective method to check if we have update all the keys

        Returns:
            List[str]: List of keys not yet updated
        """
        return set(self.to_track.keys()) - self._seen  # è¿”å›æœªæ›´æ–°çš„é”®ååˆ—è¡¨

    def copy(self) -> Dict:
        # proxy the call to the internal dictionary
        return self.to_track.copy()  # è¿”å›å­—å…¸çš„æµ…æ‹·è´


# We will verify our results on an image of cute cats
def prepare_img():
    url = "http://images.cocodataset.org/val2017/000000039769.jpg"  # å®šä¹‰å›¾åƒçš„ URL
    img_data = requests.get(url, stream=True).raw  # ä» URL è·å–å›¾åƒæ•°æ®
    im = Image.open(img_data)  # æ‰“å¼€å›¾åƒæ•°æ®
    return im  # è¿”å›å›¾åƒå¯¹è±¡


@dataclass
class Args:
    """Fake command line arguments needed by maskformer/detectron implementation"""

    config_file: str  # å‘½ä»¤è¡Œå‚æ•°ç±»çš„å±æ€§ï¼šé…ç½®æ–‡ä»¶è·¯å¾„
# ä»æ–‡ä»¶å’Œå‘½ä»¤è¡Œå‚æ•°ä¸­åŠ è½½é…ç½®ä¿¡æ¯
def setup_cfg(args: Args):
    # è·å–ä¸€ä¸ªæ–°çš„é…ç½®å¯¹è±¡
    cfg = get_cfg()
    # æ·»åŠ  DeepLab é…ç½®åˆ°é…ç½®å¯¹è±¡
    add_deeplab_config(cfg)
    # æ·»åŠ  MaskFormer é…ç½®åˆ°é…ç½®å¯¹è±¡
    add_mask_former_config(cfg)
    # ä»é…ç½®æ–‡ä»¶ä¸­åŠ è½½æ›´å¤šé…ç½®åˆ°å½“å‰é…ç½®å¯¹è±¡
    cfg.merge_from_file(args.config_file)
    # å†»ç»“é…ç½®å¯¹è±¡ï¼Œé˜²æ­¢åç»­ä¿®æ”¹
    cfg.freeze()
    # è¿”å›é…ç½®å¯¹è±¡
    return cfg


class OriginalMaskFormerConfigToOursConverter:
    def __call__(self, original_config: object) -> MaskFormerConfig:
        # è·å–åŸå§‹é…ç½®å¯¹è±¡çš„æ¨¡å‹éƒ¨åˆ†
        model = original_config.MODEL
        # è·å–æ¨¡å‹ä¸­çš„ MASK_FORMER éƒ¨åˆ†
        mask_former = model.MASK_FORMER
        # è·å–æ¨¡å‹ä¸­çš„ SWIN éƒ¨åˆ†
        swin = model.SWIN

        # ä»å…ƒæ•°æ®ç›®å½•ä¸­è·å–æµ‹è¯•æ•°æ®é›†çš„ç±»åˆ«ä¿¡æ¯
        dataset_catalog = MetadataCatalog.get(original_config.DATASETS.TEST[0])
        # åˆ›å»ºä»ç±»åˆ« ID åˆ°ç±»åˆ«åç§°çš„æ˜ å°„å­—å…¸
        id2label = dict(enumerate(dataset_catalog.stuff_classes))
        # åˆ›å»ºä»ç±»åˆ«åç§°åˆ°ç±»åˆ« ID çš„æ˜ å°„å­—å…¸
        label2id = {label: idx for idx, label in id2label.items()}

        # åˆ›å»º MaskFormerConfig å¯¹è±¡ï¼Œå¹¶å¡«å……å…¶å±æ€§å€¼
        config: MaskFormerConfig = MaskFormerConfig(
            fpn_feature_size=model.SEM_SEG_HEAD.CONVS_DIM,
            mask_feature_size=model.SEM_SEG_HEAD.MASK_DIM,
            num_labels=model.SEM_SEG_HEAD.NUM_CLASSES,
            no_object_weight=mask_former.NO_OBJECT_WEIGHT,
            num_queries=mask_former.NUM_OBJECT_QUERIES,
            backbone_config={
                "pretrain_img_size": swin.PRETRAIN_IMG_SIZE,
                "image_size": swin.PRETRAIN_IMG_SIZE,
                "in_channels": 3,
                "patch_size": swin.PATCH_SIZE,
                "embed_dim": swin.EMBED_DIM,
                "depths": swin.DEPTHS,
                "num_heads": swin.NUM_HEADS,
                "window_size": swin.WINDOW_SIZE,
                "drop_path_rate": swin.DROP_PATH_RATE,
                "model_type": "swin",
            },
            dice_weight=mask_former.DICE_WEIGHT,
            ce_weight=1.0,
            mask_weight=mask_former.MASK_WEIGHT,
            decoder_config={
                "model_type": "detr",
                "max_position_embeddings": 1024,
                "encoder_layers": 6,
                "encoder_ffn_dim": 2048,
                "encoder_attention_heads": 8,
                "decoder_layers": mask_former.DEC_LAYERS,
                "decoder_ffn_dim": mask_former.DIM_FEEDFORWARD,
                "decoder_attention_heads": mask_former.NHEADS,
                "encoder_layerdrop": 0.0,
                "decoder_layerdrop": 0.0,
                "d_model": mask_former.HIDDEN_DIM,
                "dropout": mask_former.DROPOUT,
                "attention_dropout": 0.0,
                "activation_dropout": 0.0,
                "init_std": 0.02,
                "init_xavier_std": 1.0,
                "scale_embedding": False,
                "auxiliary_loss": False,
                "dilation": False,
                # é»˜è®¤çš„é¢„è®­ç»ƒé…ç½®æ•°å€¼
            },
            id2label=id2label,
            label2id=label2id,
        )

        # è¿”å›é…ç½®å¯¹è±¡
        return config


class OriginalMaskFormerConfigToImageProcessorConverter:
    # ç­‰å¾…å®ç°çš„ç±»ï¼Œç”¨äºå°†åŸå§‹çš„ MaskFormer é…ç½®è½¬æ¢ä¸ºå›¾åƒå¤„ç†å™¨é…ç½®
    pass
    # å®šä¹‰ä¸€ä¸ªç‰¹æ®Šæ–¹æ³•ï¼Œä½¿å¾—å¯¹è±¡å¯ä»¥è¢«è°ƒç”¨ï¼Œå¹¶è¿”å›ä¸€ä¸ª MaskFormerImageProcessor å®ä¾‹
    def __call__(self, original_config: object) -> MaskFormerImageProcessor:
        # ä»é…ç½®ä¸­è·å–æ¨¡å‹å¯¹è±¡
        model = original_config.MODEL
        # ä»é…ç½®ä¸­è·å–è¾“å…¥è®¾ç½®
        model_input = original_config.INPUT
        # è·å–æµ‹è¯•æ•°æ®é›†çš„å…ƒæ•°æ®ç›®å½•
        dataset_catalog = MetadataCatalog.get(original_config.DATASETS.TEST[0])

        # è¿”å›ä¸€ä¸ª MaskFormerImageProcessor å®ä¾‹ï¼Œå¹¶ä¼ å…¥ä»¥ä¸‹å‚æ•°ï¼š
        return MaskFormerImageProcessor(
            # è®¡ç®—å¹¶è½¬æ¢åƒç´ å‡å€¼ä¸ºåˆ—è¡¨å½¢å¼
            image_mean=(torch.tensor(model.PIXEL_MEAN) / 255).tolist(),
            # è®¡ç®—å¹¶è½¬æ¢åƒç´ æ ‡å‡†å·®ä¸ºåˆ—è¡¨å½¢å¼
            image_std=(torch.tensor(model.PIXEL_STD) / 255).tolist(),
            # è®¾ç½®æµ‹è¯•å›¾åƒçš„æœ€å°å°ºå¯¸
            size=model_input.MIN_SIZE_TEST,
            # è®¾ç½®æµ‹è¯•å›¾åƒçš„æœ€å¤§å°ºå¯¸
            max_size=model_input.MAX_SIZE_TEST,
            # è®¾ç½®è¯­ä¹‰åˆ†å‰²å¤´éƒ¨çš„ç±»åˆ«æ•°ç›®
            num_labels=model.SEM_SEG_HEAD.NUM_CLASSES,
            # è®¾ç½®å¿½ç•¥ç´¢å¼•ï¼Œé€šå¸¸ç”¨äºæ ‡æ³¨ä¸­çš„èƒŒæ™¯ç±»åˆ«
            ignore_index=dataset_catalog.ignore_label,
            # è®¾ç½®å°ºå¯¸å¯åˆ†å‰²æ€§ï¼Œé€šå¸¸ä¸ºæ¨¡å‹è¦æ±‚çš„å€æ•°ï¼Œè¿™é‡Œä¸º32ï¼Œé€‚ç”¨äº Swin æ¨¡å‹
            size_divisibility=32,
        )
# å®šä¹‰ä¸€ä¸ªç±»ç”¨äºå°†åŸå§‹æ¨¡å‹çš„æ£€æŸ¥ç‚¹è½¬æ¢ä¸ºæ–°æ¨¡å‹çš„æ£€æŸ¥ç‚¹
class OriginalMaskFormerCheckpointToOursConverter:
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œæ¥æ”¶åŸå§‹æ¨¡å‹å’Œé…ç½®å¯¹è±¡ä½œä¸ºå‚æ•°
    def __init__(self, original_model: nn.Module, config: MaskFormerConfig):
        self.original_model = original_model  # å­˜å‚¨åŸå§‹æ¨¡å‹
        self.config = config  # å­˜å‚¨é…ç½®å¯¹è±¡

    # å¼¹å‡ºå¹¶é‡å‘½åæ‰€æœ‰ç»™å®šé”®å¯¹åº”çš„å€¼ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
    def pop_all(self, renamed_keys: List[Tuple[str, str]], dst_state_dict: StateDict, src_state_dict: StateDict):
        for src_key, dst_key in renamed_keys:
            dst_state_dict[dst_key] = src_state_dict.pop(src_key)

    # æ›¿æ¢åƒç´ æ¨¡å—çš„ç‰¹å®šéƒ¨åˆ†ï¼Œå¹¶æ ¹æ®é…ç½®æ›´æ–°ç›¸åº”çš„ç›®æ ‡çŠ¶æ€å­—å…¸
    def replace_pixel_module(self, dst_state_dict: StateDict, src_state_dict: StateDict):
        dst_prefix: str = "pixel_level_module.decoder"  # ç›®æ ‡çŠ¶æ€å­—å…¸çš„å‰ç¼€
        src_prefix: str = "sem_seg_head.pixel_decoder"  # æºçŠ¶æ€å­—å…¸çš„å‰ç¼€

        # ä½¿ç”¨ç»™å®šé…ç½®æ›´æ–°èƒŒæ™¯æ¨¡å‹
        self.replace_backbone(dst_state_dict, src_state_dict, self.config)

        # å®šä¹‰ä¸€ä¸ªå‡½æ•°ç”¨äºä¸ºå·ç§¯å±‚é‡å‘½åé”®
        def rename_keys_for_conv(detectron_conv: str, mine_conv: str):
            return [
                (f"{detectron_conv}.weight", f"{mine_conv}.0.weight"),
                (f"{detectron_conv}.norm.weight", f"{mine_conv}.1.weight"),
                (f"{detectron_conv}.norm.bias", f"{mine_conv}.1.bias"),
            ]

        # æ·»åŠ ç”¨äºè½¬æ¢çš„ç‰¹å®šé”®å¯¹ï¼Œå¦‚æ©ç ç‰¹å¾çš„æƒé‡å’Œåç½®
        renamed_keys = [
            (f"{src_prefix}.mask_features.weight", f"{dst_prefix}.mask_projection.weight"),
            (f"{src_prefix}.mask_features.bias", f"{dst_prefix}.mask_projection.bias"),
        ]
        
        # æ·»åŠ ç”¨äºè½¬æ¢çš„å·ç§¯å±‚çš„é”®å¯¹ï¼Œä¾‹å¦‚ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼ˆFPNï¼‰çš„stemå±‚
        renamed_keys.extend(rename_keys_for_conv(f"{src_prefix}.layer_4", f"{dst_prefix}.fpn.stem"))

        # å¾ªç¯æ·»åŠ FPNçš„å„å±‚ï¼Œæ ¹æ®é…ç½®å‚æ•°ç¡®å®šå±‚æ•°
        for src_i, dst_i in zip(range(3, 0, -1), range(0, 3)):
            renamed_keys.extend(
                rename_keys_for_conv(f"{src_prefix}.adapter_{src_i}", f"{dst_prefix}.fpn.layers.{dst_i}.proj")
            )
            renamed_keys.extend(
                rename_keys_for_conv(f"{src_prefix}.layer_{src_i}", f"{dst_prefix}.fpn.layers.{dst_i}.block")
            )

        # è°ƒç”¨pop_allæ–¹æ³•ï¼Œå°†æ‰€æœ‰é‡å‘½åçš„é”®å¯¹åº”çš„å€¼ä»æºçŠ¶æ€å­—å…¸ä¸­å¼¹å‡ºï¼Œå¹¶æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
        self.pop_all(renamed_keys, dst_state_dict, src_state_dict)
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºé‡å‘½å DETR è§£ç å™¨çš„çŠ¶æ€å­—å…¸ä¸­çš„é”®
    def rename_keys_in_detr_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict):
        # ç›®æ ‡çŠ¶æ€å­—å…¸çš„é”®å‰ç¼€
        dst_prefix: str = "transformer_module.decoder"
        # æºçŠ¶æ€å­—å…¸çš„é”®å‰ç¼€
        src_prefix: str = "sem_seg_head.predictor.transformer.decoder"
        
        # not sure why we are not popping direcetly here!
        # ä¸ç¡®å®šä¸ºä»€ä¹ˆè¿™é‡Œæ²¡æœ‰ç›´æ¥å¼¹å‡ºï¼ˆåˆ é™¤ï¼‰ï¼
        
        # åœ¨ä¸‹é¢åˆ—å‡ºéœ€è¦é‡å‘½åçš„æ‰€æœ‰é”®ï¼ˆå·¦ä¾§ä¸ºåŸå§‹åç§°ï¼Œå³ä¾§ä¸ºæˆ‘ä»¬çš„åç§°ï¼‰
        rename_keys = []
        
        # å¾ªç¯éå†è§£ç å™¨é…ç½®ä¸­çš„æ¯ä¸€å±‚
        for i in range(self.config.decoder_config.decoder_layers):
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„è¾“å‡ºæŠ•å½±æƒé‡
            rename_keys.append(
                (
                    f"{src_prefix}.layers.{i}.self_attn.out_proj.weight",
                    f"{dst_prefix}.layers.{i}.self_attn.out_proj.weight",
                )
            )
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„è¾“å‡ºæŠ•å½±åç½®
            rename_keys.append(
                (
                    f"{src_prefix}.layers.{i}.self_attn.out_proj.bias",
                    f"{dst_prefix}.layers.{i}.self_attn.out_proj.bias",
                )
            )
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„è¾“å‡ºæŠ•å½±æƒé‡
            rename_keys.append(
                (
                    f"{src_prefix}.layers.{i}.multihead_attn.out_proj.weight",
                    f"{dst_prefix}.layers.{i}.encoder_attn.out_proj.weight",
                )
            )
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„è¾“å‡ºæŠ•å½±åç½®
            rename_keys.append(
                (
                    f"{src_prefix}.layers.{i}.multihead_attn.out_proj.bias",
                    f"{dst_prefix}.layers.{i}.encoder_attn.out_proj.bias",
                )
            )
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šçº¿æ€§å±‚1çš„æƒé‡
            rename_keys.append((f"{src_prefix}.layers.{i}.linear1.weight", f"{dst_prefix}.layers.{i}.fc1.weight"))
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šçº¿æ€§å±‚1çš„åç½®
            rename_keys.append((f"{src_prefix}.layers.{i}.linear1.bias", f"{dst_prefix}.layers.{i}.fc1.bias"))
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šçº¿æ€§å±‚2çš„æƒé‡
            rename_keys.append((f"{src_prefix}.layers.{i}.linear2.weight", f"{dst_prefix}.layers.{i}.fc2.weight"))
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šçº¿æ€§å±‚2çš„åç½®
            rename_keys.append((f"{src_prefix}.layers.{i}.linear2.bias", f"{dst_prefix}.layers.{i}.fc2.bias"))
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šå±‚å½’ä¸€åŒ–1çš„æƒé‡
            rename_keys.append(
                (f"{src_prefix}.layers.{i}.norm1.weight", f"{dst_prefix}.layers.{i}.self_attn_layer_norm.weight")
            )
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šå±‚å½’ä¸€åŒ–1çš„åç½®
            rename_keys.append(
                (f"{src_prefix}.layers.{i}.norm1.bias", f"{dst_prefix}.layers.{i}.self_attn_layer_norm.bias")
            )
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šå±‚å½’ä¸€åŒ–2çš„æƒé‡
            rename_keys.append(
                (f"{src_prefix}.layers.{i}.norm2.weight", f"{dst_prefix}.layers.{i}.encoder_attn_layer_norm.weight")
            )
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šå±‚å½’ä¸€åŒ–2çš„åç½®
            rename_keys.append(
                (f"{src_prefix}.layers.{i}.norm2.bias", f"{dst_prefix}.layers.{i}.encoder_attn_layer_norm.bias")
            )
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šå±‚å½’ä¸€åŒ–3çš„æƒé‡
            rename_keys.append(
                (f"{src_prefix}.layers.{i}.norm3.weight", f"{dst_prefix}.layers.{i}.final_layer_norm.weight")
            )
            # æ·»åŠ é‡å‘½åè§„åˆ™ï¼šå±‚å½’ä¸€åŒ–3çš„åç½®
            rename_keys.append(
                (f"{src_prefix}.layers.{i}.norm3.bias", f"{dst_prefix}.layers.{i}.final_layer_norm.bias")
            )

        # è¿”å›åŒ…å«æ‰€æœ‰é‡å‘½åè§„åˆ™çš„åˆ—è¡¨
        return rename_keys
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ç”¨äºæ›¿æ¢ DETR è§£ç å™¨ä¸­çš„æƒé‡å’Œåç½®
    def replace_q_k_v_in_detr_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict):
        # è®¾ç½®ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­çš„é”®å‰ç¼€
        dst_prefix: str = "transformer_module.decoder"
        # è®¾ç½®æºçŠ¶æ€å­—å…¸ä¸­çš„é”®å‰ç¼€
        src_prefix: str = "sem_seg_head.predictor.transformer.decoder"
        # å¾ªç¯éå†è§£ç å™¨å±‚æ•°é‡æ¬¡æ•°
        for i in range(self.config.decoder_config.decoder_layers):
            # ä»æºçŠ¶æ€å­—å…¸ä¸­å¼¹å‡ºè‡ªæ³¨æ„åŠ›å±‚çš„è¾“å…¥æŠ•å½±å±‚çš„æƒé‡å’Œåç½®
            in_proj_weight = src_state_dict.pop(f"{src_prefix}.layers.{i}.self_attn.in_proj_weight")
            in_proj_bias = src_state_dict.pop(f"{src_prefix}.layers.{i}.self_attn.in_proj_bias")
            # å°†è‡ªæ³¨æ„åŠ›å±‚çš„æŸ¥è¯¢ã€é”®å’Œå€¼ï¼ˆæŒ‰é¡ºåºï¼‰æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
            dst_state_dict[f"{dst_prefix}.layers.{i}.self_attn.q_proj.weight"] = in_proj_weight[:256, :]
            dst_state_dict[f"{dst_prefix}.layers.{i}.self_attn.q_proj.bias"] = in_proj_bias[:256]
            dst_state_dict[f"{dst_prefix}.layers.{i}.self_attn.k_proj.weight"] = in_proj_weight[256:512, :]
            dst_state_dict[f"{dst_prefix}.layers.{i}.self_attn.k_proj.bias"] = in_proj_bias[256:512]
            dst_state_dict[f"{dst_prefix}.layers.{i}.self_attn.v_proj.weight"] = in_proj_weight[-256:, :]
            dst_state_dict[f"{dst_prefix}.layers.{i}.self_attn.v_proj.bias"] = in_proj_bias[-256:]
            # ä»æºçŠ¶æ€å­—å…¸ä¸­è¯»å–è·¨æ³¨æ„åŠ›å±‚çš„è¾“å…¥æŠ•å½±å±‚çš„æƒé‡å’Œåç½®
            in_proj_weight_cross_attn = src_state_dict.pop(f"{src_prefix}.layers.{i}.multihead_attn.in_proj_weight")
            in_proj_bias_cross_attn = src_state_dict.pop(f"{src_prefix}.layers.{i}.multihead_attn.in_proj_bias")
            # å°†è·¨æ³¨æ„åŠ›å±‚çš„æŸ¥è¯¢ã€é”®å’Œå€¼ï¼ˆæŒ‰é¡ºåºï¼‰æ·»åŠ åˆ°ç›®æ ‡çŠ¶æ€å­—å…¸ä¸­
            dst_state_dict[f"{dst_prefix}.layers.{i}.encoder_attn.q_proj.weight"] = in_proj_weight_cross_attn[:256, :]
            dst_state_dict[f"{dst_prefix}.layers.{i}.encoder_attn.q_proj.bias"] = in_proj_bias_cross_attn[:256]
            dst_state_dict[f"{dst_prefix}.layers.{i}.encoder_attn.k_proj.weight"] = in_proj_weight_cross_attn[256:512, :]
            dst_state_dict[f"{dst_prefix}.layers.{i}.encoder_attn.k_proj.bias"] = in_proj_bias_cross_attn[256:512]
            dst_state_dict[f"{dst_prefix}.layers.{i}.encoder_attn.v_proj.weight"] = in_proj_weight_cross_attn[-256:, :]
            dst_state_dict[f"{dst_prefix}.layers.{i}.encoder_attn.v_proj.bias"] = in_proj_bias_cross_attn[-256:]
    # ç”¨äºæ›¿æ¢`detr`æ¨¡å‹çš„è§£ç å™¨éƒ¨åˆ†çš„æƒé‡å’Œåç½®
    def replace_detr_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict):
        # ç›®æ ‡æ¨¡å‹æƒé‡å‰ç¼€
        dst_prefix: str = "transformer_module.decoder"
        # æºæ¨¡å‹æƒé‡å‰ç¼€
        src_prefix: str = "sem_seg_head.predictor.transformer.decoder"
        
        # é‡å‘½åä¸¤ä¸ªæ¨¡å‹æƒé‡çš„é”®ååˆ—è¡¨
        renamed_keys = self.rename_keys_in_detr_decoder(dst_state_dict, src_state_dict)
        
        # æ·»åŠ æ›´å¤šçš„é”®åæ˜ å°„ï¼Œä¾‹å¦‚å±‚å½’ä¸€åŒ–çš„æƒé‡å’Œåç½®
        renamed_keys.extend(
            [
                (f"{src_prefix}.norm.weight", f"{dst_prefix}.layernorm.weight"),
                (f"{src_prefix}.norm.bias", f"{dst_prefix}.layernorm.bias"),
            ]
        )

        # æ ¹æ®æ˜ å°„å…³ç³»ä»æºæ¨¡å‹ä¸­ç§»é™¤å¯¹åº”çš„é”®å€¼å¯¹
        self.pop_all(renamed_keys, dst_state_dict, src_state_dict)

        # æ›¿æ¢`detr`æ¨¡å‹è§£ç å™¨çš„queryã€keyå’Œvalueæƒé‡
        self.replace_q_k_v_in_detr_decoder(dst_state_dict, src_state_dict)

    # æ›¿æ¢`transformer_module`ä¸­çš„æƒé‡å’Œåç½®
    def replace_transformer_module(self, dst_state_dict: StateDict, src_state_dict: StateDict):
        # ç›®æ ‡æ¨¡å‹æƒé‡å‰ç¼€
        dst_prefix: str = "transformer_module"
        # æºæ¨¡å‹æƒé‡å‰ç¼€
        src_prefix: str = "sem_seg_head.predictor"

        # è°ƒç”¨`replace_detr_decoder`å‡½æ•°ï¼Œæ›¿æ¢è§£ç å™¨éƒ¨åˆ†çš„æƒé‡å’Œåç½®
        self.replace_detr_decoder(dst_state_dict, src_state_dict)

        # é‡å‘½å`transformer_module`ä¸­çš„ç‰¹å®šæƒé‡å’Œåç½®
        renamed_keys = [
            (f"{src_prefix}.query_embed.weight", f"{dst_prefix}.queries_embedder.weight"),
            (f"{src_prefix}.input_proj.weight", f"{dst_prefix}.input_projection.weight"),
            (f"{src_prefix}.input_proj.bias", f"{dst_prefix}.input_projection.bias"),
        ]

        # æ ¹æ®æ˜ å°„å…³ç³»ä»æºæ¨¡å‹ä¸­ç§»é™¤å¯¹åº”çš„é”®å€¼å¯¹
        self.pop_all(renamed_keys, dst_state_dict, src_state_dict)

    # æ›¿æ¢å®ä¾‹åˆ†å‰²æ¨¡å—ä¸­çš„æƒé‡å’Œåç½®
    def replace_instance_segmentation_module(self, dst_state_dict: StateDict, src_state_dict: StateDict):
        # æ³¨æ„ï¼šæˆ‘ä»¬çš„æƒ…å†µä¸­æ²¡æœ‰å‰ç¼€ï¼Œå› æ­¤æˆ‘ä»¬åœ¨åç»­å¤„ç†ä¸­ç§»é™¤äº†é”®åä¸­çš„â€œ.â€
        dst_prefix: str = ""
        # æºæ¨¡å‹æƒé‡å‰ç¼€
        src_prefix: str = "sem_seg_head.predictor"

        # å®šä¹‰è¦é‡å‘½åçš„é”®åæ˜ å°„åˆ—è¡¨
        renamed_keys = [
            (f"{src_prefix}.class_embed.weight", f"{dst_prefix}class_predictor.weight"),
            (f"{src_prefix}.class_embed.bias", f"{dst_prefix}class_predictor.bias"),
        ]

        # å¾ªç¯å¤„ç†MLPå±‚ï¼Œæ„å»ºæ˜ å°„åˆ—è¡¨
        mlp_len = 3
        for i in range(mlp_len):
            renamed_keys.extend(
                [
                    (f"{src_prefix}.mask_embed.layers.{i}.weight", f"{dst_prefix}mask_embedder.{i}.0.weight"),
                    (f"{src_prefix}.mask_embed.layers.{i}.bias", f"{dst_prefix}mask_embedder.{i}.0.bias"),
                ]
            )
        
        # è®°å½•æ—¥å¿—ï¼Œæ˜¾ç¤ºæ›¿æ¢çš„é”®åæ˜ å°„åˆ—è¡¨
        logger.info(f"Replacing keys {pformat(renamed_keys)}")
        
        # æ ¹æ®æ˜ å°„å…³ç³»ä»æºæ¨¡å‹ä¸­ç§»é™¤å¯¹åº”çš„é”®å€¼å¯¹
        self.pop_all(renamed_keys, dst_state_dict, src_state_dict)

    # æ‰§è¡Œæ¨¡å‹æƒé‡çš„è½¬æ¢
    def convert(self, mask_former: MaskFormerModel) -> MaskFormerModel:
        # åˆ›å»ºç›®æ ‡æ¨¡å‹çŠ¶æ€å­—å…¸ï¼ŒåŸºäºè¾“å…¥æ¨¡å‹çš„çŠ¶æ€å­—å…¸
        dst_state_dict = TrackedStateDict(mask_former.state_dict())
        # è·å–åŸå§‹æ¨¡å‹çš„çŠ¶æ€å­—å…¸
        src_state_dict = self.original_model.state_dict()

        # æ›¿æ¢åƒç´ æ¨¡å—ä¸­çš„æƒé‡å’Œåç½®
        self.replace_pixel_module(dst_state_dict, src_state_dict)
        
        # æ›¿æ¢`transformer_module`ä¸­çš„æƒé‡å’Œåç½®
        self.replace_transformer_module(dst_state_dict, src_state_dict)

        # è®°å½•æœªåŒ¹é…çš„é”®åå·®å¼‚
        logger.info(f"Missed keys are {pformat(dst_state_dict.diff())}")
        # è®°å½•æœªå¤åˆ¶çš„æºæ¨¡å‹é”®ååˆ—è¡¨
        logger.info(f"Not copied keys are {pformat(src_state_dict.keys())}")
        # æ—¥å¿—è®°å½•ï¼šæ“ä½œå®Œæˆ
        logger.info("ğŸ™Œ Done")

        # ä½¿ç”¨æ›´æ–°åçš„ç›®æ ‡çŠ¶æ€å­—å…¸åŠ è½½æ¨¡å‹æƒé‡
        mask_former.load_state_dict(dst_state_dict)

        # è¿”å›æ›´æ–°åçš„æ¨¡å‹
        return mask_former
    # å°†ç»™å®šçš„å®ä¾‹åˆ†å‰²æ¨¡å‹è½¬æ¢ä¸ºå¦ä¸€ç§å®ä¾‹åˆ†å‰²æ¨¡å‹ç±»å‹ï¼Œå¹¶è¿”å›è½¬æ¢åçš„æ¨¡å‹
    def convert_instance_segmentation(
        self, mask_former: MaskFormerForInstanceSegmentation
    ) -> MaskFormerForInstanceSegmentation:
        # åˆ›å»ºç›®æ ‡æ¨¡å‹çš„çŠ¶æ€å­—å…¸ï¼Œå¤åˆ¶è¾“å…¥æ¨¡å‹çš„çŠ¶æ€å­—å…¸
        dst_state_dict = TrackedStateDict(mask_former.state_dict())
        # è·å–åŸå§‹æ¨¡å‹çš„çŠ¶æ€å­—å…¸
        src_state_dict = self.original_model.state_dict()

        # ç”¨åŸå§‹æ¨¡å‹çš„çŠ¶æ€å­—å…¸æ›¿æ¢ç›®æ ‡æ¨¡å‹ä¸­çš„å®ä¾‹åˆ†å‰²æ¨¡å—
        self.replace_instance_segmentation_module(dst_state_dict, src_state_dict)

        # å°†æ›´æ–°åçš„çŠ¶æ€å­—å…¸åŠ è½½åˆ°è¾“å…¥çš„å®ä¾‹åˆ†å‰²æ¨¡å‹ä¸­
        mask_former.load_state_dict(dst_state_dict)

        # è¿”å›æ›´æ–°åçš„å®ä¾‹åˆ†å‰²æ¨¡å‹
        return mask_former

    @staticmethod
    # è¿”å›ä¸€ä¸ªè¿­ä»£å™¨ï¼Œè¯¥è¿­ä»£å™¨ç”Ÿæˆä¸€ç³»åˆ—å…ƒç»„ï¼Œæ¯ä¸ªå…ƒç»„åŒ…å«ä¸€ä¸ªé…ç½®æ–‡ä»¶è·¯å¾„ã€ä¸€ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„å’Œä¸€ä¸ªé…ç½®ç›®å½•è·¯å¾„
    def using_dirs(checkpoints_dir: Path, config_dir: Path) -> Iterator[Tuple[object, Path, Path]]:
        # è·å–æ£€æŸ¥ç‚¹ç›®å½•ä¸‹æ‰€æœ‰çš„.pklæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        checkpoints: List[Path] = checkpoints_dir.glob("**/*.pkl")

        # éå†æ¯ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        for checkpoint in checkpoints:
            # è®°å½•ä¿¡æ¯ï¼šè½¬æ¢æ­£åœ¨å¤„ç†çš„æ£€æŸ¥ç‚¹æ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
            logger.info(f"ğŸ’ª Converting {checkpoint.stem}")
            # æŸ¥æ‰¾ä¸å½“å‰æ£€æŸ¥ç‚¹æ–‡ä»¶å…³è”çš„é…ç½®æ–‡ä»¶è·¯å¾„
            config: Path = config_dir / checkpoint.parents[0].stem / "swin" / f"{checkpoint.stem}.yaml"

            # è¿”å›å½“å‰é…ç½®æ–‡ä»¶è·¯å¾„ã€æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„å’Œé…ç½®ç›®å½•è·¯å¾„çš„å…ƒç»„
            yield config, checkpoint
def test(original_model, our_model: MaskFormerForInstanceSegmentation, image_processor: MaskFormerImageProcessor):
    # ä½¿ç”¨torch.no_grad()ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå…³é—­æ¢¯åº¦è®¡ç®—ä»¥åŠ å¿«æ¨æ–­é€Ÿåº¦
    with torch.no_grad():
        # å°†åŸå§‹æ¨¡å‹å’Œæˆ‘ä»¬çš„æ¨¡å‹è®¾ä¸ºè¯„ä¼°æ¨¡å¼
        original_model = original_model.eval()
        our_model = our_model.eval()

        # å‡†å¤‡å›¾åƒæ•°æ®
        im = prepare_img()

        # å›¾åƒè½¬æ¢çš„ç»„åˆæ“ä½œï¼ŒåŒ…æ‹¬è°ƒæ•´å¤§å°ã€è½¬æ¢ä¸ºTensorã€å½’ä¸€åŒ–
        tr = T.Compose(
            [
                T.Resize((384, 384)),  # è°ƒæ•´å›¾åƒå¤§å°ä¸º384x384
                T.ToTensor(),  # è½¬æ¢ä¸ºTensor
                T.Normalize(  # å½’ä¸€åŒ–æ“ä½œ
                    mean=torch.tensor([123.675, 116.280, 103.530]) / 255.0,
                    std=torch.tensor([58.395, 57.120, 57.375]) / 255.0,
                ),
            ],
        )

        # å¯¹è¾“å…¥å›¾åƒåº”ç”¨è½¬æ¢æ“ä½œï¼Œå¹¶æ‰©å±•ç»´åº¦ä»¥åŒ¹é…æ¨¡å‹çš„è¾“å…¥è¦æ±‚
        x = tr(im).unsqueeze(0)

        # ä½¿ç”¨åŸå§‹æ¨¡å‹çš„backboneæå–ç‰¹å¾
        original_model_backbone_features = original_model.backbone(x.clone())

        # ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼ŒåŒæ—¶è¯·æ±‚è¾“å‡ºéšè—çŠ¶æ€
        our_model_output: MaskFormerModelOutput = our_model.model(x.clone(), output_hidden_states=True)

        # å¯¹æ¯”åŸå§‹æ¨¡å‹å’Œæˆ‘ä»¬çš„æ¨¡å‹çš„backboneç‰¹å¾æ˜¯å¦æ¥è¿‘
        for original_model_feature, our_model_feature in zip(
            original_model_backbone_features.values(), our_model_output.encoder_hidden_states
        ):
            assert torch.allclose(
                original_model_feature, our_model_feature, atol=1e-3
            ), "The backbone features are not the same."

        # ä½¿ç”¨åŸå§‹æ¨¡å‹çš„è¯­ä¹‰åˆ†å‰²å¤´éƒ¨è¿›è¡Œåƒç´ è§£ç 
        original_model_pixel_out = original_model.sem_seg_head.pixel_decoder.forward_features(
            original_model_backbone_features
        )

        # å¯¹æ¯”åŸå§‹æ¨¡å‹å’Œæˆ‘ä»¬çš„æ¨¡å‹çš„åƒç´ è§£ç å™¨çš„æœ€åéšè—çŠ¶æ€æ˜¯å¦æ¥è¿‘
        assert torch.allclose(
            original_model_pixel_out[0], our_model_output.pixel_decoder_last_hidden_state, atol=1e-4
        ), "The pixel decoder feature are not the same"

        # æµ‹è¯•å®Œæ•´æ¨¡å‹çš„è¾“å‡º
        original_model_out = original_model([{"image": x.squeeze(0)}])

        # è·å–åŸå§‹æ¨¡å‹çš„è¯­ä¹‰åˆ†å‰²ç»“æœ
        original_segmentation = original_model_out[0]["sem_seg"]

        # ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼Œå¹¶åå¤„ç†åˆ†å‰²ç»“æœ
        our_model_out: MaskFormerForInstanceSegmentationOutput = our_model(x)

        our_segmentation = image_processor.post_process_segmentation(our_model_out, target_size=(384, 384))

        # å¯¹æ¯”åŸå§‹æ¨¡å‹å’Œæˆ‘ä»¬çš„æ¨¡å‹çš„è¯­ä¹‰åˆ†å‰²ç»“æœæ˜¯å¦æ¥è¿‘
        assert torch.allclose(
            original_segmentation, our_segmentation, atol=1e-3
        ), "The segmentation image is not the same."

        # è®°å½•æµ‹è¯•é€šè¿‡çš„ä¿¡æ¯
        logger.info("âœ… Test passed!")


def get_name(checkpoint_file: Path):
    # ä»æ£€æŸ¥ç‚¹æ–‡ä»¶åä¸­æå–æ¨¡å‹åç§°
    model_name_raw: str = checkpoint_file.stem
    # model_name_raw çš„æ ¼å¼ç±»ä¼¼äº maskformer_panoptic_swin_base_IN21k_384_bs64_554k
    parent_name: str = checkpoint_file.parents[0].stem
    backbone = "swin"
    dataset = ""
    
    # æ ¹æ®çˆ¶æ–‡ä»¶å¤¹åç§°ç¡®å®šæ•°æ®é›†ç±»å‹
    if "coco" in parent_name:
        dataset = "coco"
    elif "ade" in parent_name:
        dataset = "ade"
    else:
        raise ValueError(f"{parent_name} must be wrong since we didn't find 'coco' or 'ade' in it ")

    # æ”¯æŒçš„backboneç±»å‹åˆ—è¡¨
    backbone_types = ["tiny", "small", "base", "large"]

    # ä»æ¨¡å‹åç§°ä¸­åŒ¹é…backboneç±»å‹
    backbone_type = list(filter(lambda x: x in model_name_raw, backbone_types))[0]

    # ç»„åˆæœ€ç»ˆçš„æ¨¡å‹åç§°
    model_name = f"maskformer-{backbone}-{backbone_type}-{dataset}"

    return model_name


if __name__ == "__main__":
    # å‘½ä»¤è¡Œè§£æå™¨ï¼Œç”¨äºè½¬æ¢åŸå§‹çš„MaskFormersæ¨¡å‹åˆ°æˆ‘ä»¬çš„å®ç°
    parser = ArgumentParser(
        description="Command line to convert the original maskformers (with swin backbone) to our implementations."
    )
    parser.add_argument(
        "--checkpoints_dir",
        type=Path,
        help=(
            "A directory containing the model's checkpoints. The directory has to have the following structure:"
            " <DIR_NAME>/<DATASET_NAME>/<CONFIG_NAME>.pkl"
        ),
    )
    parser.add_argument(
        "--configs_dir",
        type=Path,
        help=(
            "A directory containing the model's configs, see detectron2 doc. The directory has to have the following"
            " structure: <DIR_NAME>/<DATASET_NAME>/<CONFIG_NAME>.yaml"
        ),
    )
    parser.add_argument(
        "--pytorch_dump_folder_path",
        required=True,
        type=Path,
        help="Path to the folder to output PyTorch models.",
    )
    parser.add_argument(
        "--maskformer_dir",
        required=True,
        type=Path,
        help=(
            "A path to MaskFormer's original implementation directory. You can download from here:"
            " https://github.com/facebookresearch/MaskFormer"
        ),
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()

    # å°†å‘½ä»¤è¡Œå‚æ•°è½¬æ¢ä¸ºå¯¹åº”çš„å˜é‡
    checkpoints_dir: Path = args.checkpoints_dir
    config_dir: Path = args.configs_dir
    save_directory: Path = args.pytorch_dump_folder_path
    maskformer_dir: Path = args.maskformer_dir

    # å°† MaskFormer çš„çˆ¶ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­
    sys.path.append(str(maskformer_dir.parent))
    
    # å¯¼å…¥æ‰€éœ€çš„æ¨¡å—å’Œç±»
    from MaskFormer.mask_former import add_mask_former_config
    from MaskFormer.mask_former.mask_former_model import MaskFormer as OriginalMaskFormer

    # å¦‚æœä¿å­˜æ¨¡å‹çš„ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå®ƒåŠå…¶çˆ¶ç›®å½•
    if not save_directory.exists():
        save_directory.mkdir(parents=True)

    # å¾ªç¯éå†åŸå§‹ MaskFormer çš„é…ç½®æ–‡ä»¶å’Œæ£€æŸ¥ç‚¹æ–‡ä»¶
    for config_file, checkpoint_file in OriginalMaskFormerCheckpointToOursConverter.using_dirs(
        checkpoints_dir, config_dir
    ):
        ):
            # åˆ›å»ºä¸€ä¸ªç”¨äºå¤„ç†åŸå§‹æ©æ¨¡å½¢çŠ¶é…ç½®åˆ°å›¾åƒå¤„ç†å™¨è½¬æ¢çš„å®ä¾‹ï¼Œå¹¶è°ƒç”¨å…¶æ–¹æ³•
            image_processor = OriginalMaskFormerConfigToImageProcessorConverter()(setup_cfg(Args(config_file=config_file)))

        # ä½¿ç”¨ç»™å®šçš„é…ç½®æ–‡ä»¶è®¾ç½®é…ç½®å¯¹è±¡
        original_config = setup_cfg(Args(config_file=config_file))

        # æ ¹æ®åŸå§‹é…ç½®åˆ›å»ºåŸå§‹æ©æ¨¡å½¢çŠ¶å¯¹è±¡çš„å‚æ•°
        mask_former_kwargs = OriginalMaskFormer.from_config(original_config)

        # åˆ›å»ºåŸå§‹æ©æ¨¡å½¢çŠ¶æ¨¡å‹çš„å®ä¾‹å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        original_model = OriginalMaskFormer(**mask_former_kwargs).eval()

        # åŠ è½½é¢„è®­ç»ƒæ£€æŸ¥ç‚¹æ–‡ä»¶åˆ°åŸå§‹æ¨¡å‹
        DetectionCheckpointer(original_model).load(str(checkpoint_file))

        # å°†åŸå§‹é…ç½®è½¬æ¢ä¸ºæˆ‘ä»¬çš„æ©æ¨¡å½¢çŠ¶é…ç½®å¯¹è±¡
        config: MaskFormerConfig = OriginalMaskFormerConfigToOursConverter()(original_config)

        # åˆ›å»ºæˆ‘ä»¬çš„æ©æ¨¡å½¢çŠ¶æ¨¡å‹çš„å®ä¾‹å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        mask_former = MaskFormerModel(config=config).eval()

        # åˆ›å»ºç”¨äºå°†åŸå§‹æ©æ¨¡å½¢çŠ¶æ£€æŸ¥ç‚¹è½¬æ¢ä¸ºæˆ‘ä»¬çš„å½¢å¼çš„è½¬æ¢å™¨
        converter = OriginalMaskFormerCheckpointToOursConverter(original_model, config)

        # å°†åŸå§‹æ¨¡å‹è½¬æ¢ä¸ºæˆ‘ä»¬çš„æ©æ¨¡å½¢çŠ¶æ¨¡å‹
        maskformer = converter.convert(mask_former)

        # åˆ›å»ºç”¨äºå®ä¾‹åˆ†å‰²çš„æ©æ¨¡å½¢çŠ¶æ¨¡å‹çš„å®ä¾‹å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        mask_former_for_instance_segmentation = MaskFormerForInstanceSegmentation(config=config).eval()

        # è®¾ç½®å®ä¾‹åˆ†å‰²æ¨¡å‹çš„å½¢çŠ¶æ¨¡å‹
        mask_former_for_instance_segmentation.model = mask_former

        # å°†å®ä¾‹åˆ†å‰²æ¨¡å‹è½¬æ¢ä¸ºæˆ‘ä»¬çš„å½¢å¼
        mask_former_for_instance_segmentation = converter.convert_instance_segmentation(
            mask_former_for_instance_segmentation
        )

        # è¿è¡Œæµ‹è¯•å‡½æ•°ï¼Œä¼ å…¥åŸå§‹æ¨¡å‹ã€å®ä¾‹åˆ†å‰²æ¨¡å‹å’Œå›¾åƒå¤„ç†å™¨
        test(original_model, mask_former_for_instance_segmentation, image_processor)

        # è·å–æ£€æŸ¥ç‚¹æ–‡ä»¶çš„åç§°
        model_name = get_name(checkpoint_file)

        # è®°å½•ä¿å­˜æ“ä½œä¿¡æ¯
        logger.info(f"ğŸª„ Saving {model_name}")

        # ä¿å­˜å›¾åƒå¤„ç†å™¨é¢„è®­ç»ƒæ¨¡å‹åˆ°æŒ‡å®šç›®å½•
        image_processor.save_pretrained(save_directory / model_name)

        # ä¿å­˜å®ä¾‹åˆ†å‰²æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
        mask_former_for_instance_segmentation.save_pretrained(save_directory / model_name)

        # å°†å›¾åƒå¤„ç†å™¨æ¨é€åˆ° Hub ä¸Š
        image_processor.push_to_hub(
            repo_path_or_name=save_directory / model_name,
            commit_message="Add model",
            use_temp_dir=True,
        )

        # å°†å®ä¾‹åˆ†å‰²æ¨¡å‹æ¨é€åˆ° Hub ä¸Š
        mask_former_for_instance_segmentation.push_to_hub(
            repo_path_or_name=save_directory / model_name,
            commit_message="Add model",
            use_temp_dir=True,
        )
```