# `.\models\musicgen\convert_musicgen_transformers.py`

```py
# è®¾ç½®æ–‡ä»¶ç¼–ç ä¸º UTF-8ï¼Œç¡®ä¿æ”¯æŒä¸­æ–‡ç­‰é ASCII å­—ç¬¦
# ç‰ˆæƒå£°æ˜å’Œè®¸å¯ä¿¡æ¯ï¼ŒæŒ‡æ˜æ­¤ä»£ç çš„ç‰ˆæƒå½’å±å’Œä½¿ç”¨è®¸å¯
# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import argparse  # ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°
from pathlib import Path  # ç”¨äºå¤„ç†æ–‡ä»¶è·¯å¾„çš„ç±»
from typing import Dict, OrderedDict, Tuple  # å¼•å…¥ç±»å‹æç¤ºï¼Œç”¨äºé™æ€ç±»å‹æ£€æŸ¥

import torch  # å¼•å…¥ PyTorch åº“
from audiocraft.models import MusicGen  # å¯¼å…¥æœ¬åœ°å®šä¹‰çš„ MusicGen æ¨¡å‹

# ä» transformers åº“ä¸­å¯¼å…¥å¿…è¦çš„ç±»å’Œå‡½æ•°
from transformers import (
    AutoFeatureExtractor,  # è‡ªåŠ¨ç‰¹å¾æå–å™¨
    AutoTokenizer,  # è‡ªåŠ¨åˆ†è¯å™¨
    EncodecModel,  # ç¼–ç æ¨¡å‹ï¼ˆå¯èƒ½æ˜¯æ‹¼å†™é”™è¯¯ï¼Œåº”ä¸º EncoderModelï¼‰
    MusicgenDecoderConfig,  # Musicgen è§£ç å™¨é…ç½®
    MusicgenForConditionalGeneration,  # ç”¨äºæ¡ä»¶ç”Ÿæˆçš„ Musicgen æ¨¡å‹
    MusicgenProcessor,  # Musicgen å¤„ç†å™¨
    T5EncoderModel,  # T5 ç¼–ç æ¨¡å‹
)
# ä» transformers åº“çš„ musicgen æ¨¡å—ä¸­å¯¼å…¥ç‰¹å®šçš„ç±»
from transformers.models.musicgen.modeling_musicgen import MusicgenForCausalLM  # ç”¨äºå› æœè¯­è¨€æ¨¡å‹çš„ Musicgen
from transformers.utils import logging  # å¯¼å…¥æ—¥å¿—è®°å½•å·¥å…·

# è®¾ç½®æ—¥å¿—çš„è¯¦ç»†ç¨‹åº¦ä¸º info
logging.set_verbosity_info()
# è·å–å½“å‰æ¨¡å—çš„æ—¥å¿—è®°å½•å™¨
logger = logging.get_logger(__name__)

# é¢„æœŸç¼ºå¤±çš„æ¨¡å‹é”®åˆ—è¡¨
EXPECTED_MISSING_KEYS = ["model.decoder.embed_positions.weights"]


def rename_keys(name):
    """æ ¹æ®é¢„å®šä¹‰è§„åˆ™é‡å‘½åæ¨¡å‹çŠ¶æ€å­—å…¸ä¸­çš„é”®åã€‚

    Args:
        name (str): åŸå§‹çš„é”®åå­—ç¬¦ä¸²ã€‚

    Returns:
        str: é‡å‘½ååçš„é”®åå­—ç¬¦ä¸²ã€‚
    """
    if "emb" in name:
        name = name.replace("emb", "model.decoder.embed_tokens")
    if "transformer" in name:
        name = name.replace("transformer", "model.decoder")
    if "cross_attention" in name:
        name = name.replace("cross_attention", "encoder_attn")
    if "linear1" in name:
        name = name.replace("linear1", "fc1")
    if "linear2" in name:
        name = name.replace("linear2", "fc2")
    if "norm1" in name:
        name = name.replace("norm1", "self_attn_layer_norm")
    if "norm_cross" in name:
        name = name.replace("norm_cross", "encoder_attn_layer_norm")
    if "norm2" in name:
        name = name.replace("norm2", "final_layer_norm")
    if "out_norm" in name:
        name = name.replace("out_norm", "model.decoder.layer_norm")
    if "linears" in name:
        name = name.replace("linears", "lm_heads")
    if "condition_provider.conditioners.description.output_proj" in name:
        name = name.replace("condition_provider.conditioners.description.output_proj", "enc_to_dec_proj")
    return name


def rename_state_dict(state_dict: OrderedDict, hidden_size: int) -> Tuple[Dict, Dict]:
    """æ ¹æ® Hugging Face æ¨¡å—åç§°è§„åˆ™é‡å‘½å fairseq Musicgen çš„çŠ¶æ€å­—å…¸ï¼Œå¹¶å°†å…¶åˆ†æˆè§£ç å™¨ï¼ˆLMï¼‰çŠ¶æ€å­—å…¸å’Œç¼–ç å™¨-è§£ç å™¨æŠ•å½±çš„çŠ¶æ€å­—å…¸ã€‚

    Args:
        state_dict (OrderedDict): åŸå§‹çš„ fairseq Musicgen çŠ¶æ€å­—å…¸ã€‚
        hidden_size (int): éšè—å±‚å¤§å°ã€‚

    Returns:
        Tuple[Dict, Dict]: é‡å‘½ååçš„è§£ç å™¨çŠ¶æ€å­—å…¸å’Œç¼–ç å™¨-è§£ç å™¨æŠ•å½±çŠ¶æ€å­—å…¸çš„å…ƒç»„ã€‚
    """
    keys = list(state_dict.keys())
    enc_dec_proj_state_dict = {}  # ç”¨äºå­˜å‚¨ç¼–ç å™¨-è§£ç å™¨æŠ•å½±çš„çŠ¶æ€å­—å…¸
    # å¯¹äºç»™å®šçš„æ¯ä¸ªé”®è¿›è¡Œè¿­ä»£å¤„ç†
    for key in keys:
        # å¼¹å‡ºå½“å‰çŠ¶æ€å­—å…¸ä¸­çš„é”®ï¼Œå¹¶å°†å…¶å¯¹åº”çš„å€¼èµ‹ç»™å˜é‡val
        val = state_dict.pop(key)
        # ä½¿ç”¨æŒ‡å®šå‡½æ•°é‡å‘½åå½“å‰çš„é”®å€¼
        key = rename_keys(key)
        # å¦‚æœå½“å‰é”®ååŒ…å«'in_proj_weight'å­—ç¬¦ä¸²
        if "in_proj_weight" in key:
            # æ‹†åˆ†èåˆçš„qkvæŠ•å½±æƒé‡
            # æ›´æ–°çŠ¶æ€å­—å…¸ï¼Œæ›¿æ¢é”®åä¸­çš„'in_proj_weight'ä¸º'q_proj.weight'ï¼Œå¹¶èµ‹äºˆå¯¹åº”çš„å€¼
            state_dict[key.replace("in_proj_weight", "q_proj.weight")] = val[:hidden_size, :]
            # æ›´æ–°çŠ¶æ€å­—å…¸ï¼Œæ›¿æ¢é”®åä¸­çš„'in_proj_weight'ä¸º'k_proj.weight'ï¼Œå¹¶èµ‹äºˆå¯¹åº”çš„å€¼
            state_dict[key.replace("in_proj_weight", "k_proj.weight")] = val[hidden_size : 2 * hidden_size, :]
            # æ›´æ–°çŠ¶æ€å­—å…¸ï¼Œæ›¿æ¢é”®åä¸­çš„'in_proj_weight'ä¸º'v_proj.weight'ï¼Œå¹¶èµ‹äºˆå¯¹åº”çš„å€¼
            state_dict[key.replace("in_proj_weight", "v_proj.weight")] = val[-hidden_size:, :]
        # å¦‚æœå½“å‰é”®ååŒ…å«'enc_to_dec_proj'å­—ç¬¦ä¸²
        elif "enc_to_dec_proj" in key:
            # å°†å½“å‰é”®å€¼å¯¹å­˜å…¥enc_dec_proj_state_dictå­—å…¸ä¸­ï¼Œå»é™¤é”®åä¸­'enc_to_dec_proj.'éƒ¨åˆ†
            enc_dec_proj_state_dict[key[len("enc_to_dec_proj.") :]] = val
        else:
            # å¦åˆ™ï¼Œç›´æ¥å°†å½“å‰é”®å€¼å¯¹å­˜å›çŠ¶æ€å­—å…¸ä¸­
            state_dict[key] = val
    # è¿”å›æ›´æ–°åçš„çŠ¶æ€å­—å…¸åŠenc_dec_proj_state_dictå­—å…¸
    return state_dict, enc_dec_proj_state_dict
# æ ¹æ®ç»™å®šçš„æ£€æŸ¥ç‚¹åç§°è¿”å›MusicgenDecoderConfigé…ç½®å¯¹è±¡
def decoder_config_from_checkpoint(checkpoint: str) -> MusicgenDecoderConfig:
    # æ ¹æ®ä¸åŒçš„æ£€æŸ¥ç‚¹åç§°è®¾ç½®ä¸åŒçš„éšè—å±‚å¤§å°ã€éšè—å±‚æ•°å’Œæ³¨æ„åŠ›å¤´æ•°
    if checkpoint == "small" or checkpoint == "facebook/musicgen-stereo-small":
        hidden_size = 1024
        num_hidden_layers = 24
        num_attention_heads = 16
    elif checkpoint == "medium" or checkpoint == "facebook/musicgen-stereo-medium":
        hidden_size = 1536
        num_hidden_layers = 48
        num_attention_heads = 24
    elif checkpoint == "large" or checkpoint == "facebook/musicgen-stereo-large":
        hidden_size = 2048
        num_hidden_layers = 48
        num_attention_heads = 32
    else:
        # å¦‚æœæ£€æŸ¥ç‚¹åç§°ä¸ç¬¦åˆé¢„æœŸï¼Œåˆ™æŠ›å‡ºæ•°å€¼é”™è¯¯å¼‚å¸¸
        raise ValueError(
            "Checkpoint should be one of `['small', 'medium', 'large']` for the mono checkpoints, "
            "or `['facebook/musicgen-stereo-small', 'facebook/musicgen-stereo-medium', 'facebook/musicgen-stereo-large']` "
            f"for the stereo checkpoints, got {checkpoint}."
        )

    # æ ¹æ®æ£€æŸ¥ç‚¹åç§°ä¸­æ˜¯å¦åŒ…å«"stereo"å…³é”®è¯è®¾ç½®éŸ³é¢‘é€šé“æ•°å’Œç ä¹¦æ•°
    if "stereo" in checkpoint:
        audio_channels = 2
        num_codebooks = 8
    else:
        audio_channels = 1
        num_codebooks = 4

    # åˆ›å»ºMusicgenDecoderConfigå¯¹è±¡ï¼Œä½¿ç”¨ä¹‹å‰è®¾ç½®çš„å‚æ•°
    config = MusicgenDecoderConfig(
        hidden_size=hidden_size,
        ffn_dim=hidden_size * 4,
        num_hidden_layers=num_hidden_layers,
        num_attention_heads=num_attention_heads,
        num_codebooks=num_codebooks,
        audio_channels=audio_channels,
    )
    return config


@torch.no_grad()
# ä»Fairseqæ¨¡å‹çš„é¢„è®­ç»ƒæ£€æŸ¥ç‚¹è½¬æ¢MusicGenæ¨¡å‹çš„å‡½æ•°
def convert_musicgen_checkpoint(
    checkpoint, pytorch_dump_folder=None, repo_id=None, device="cpu", safe_serialization=False
):
    # ä»Fairseqåº“ä¸­è·å–é¢„è®­ç»ƒçš„MusicGenæ¨¡å‹
    fairseq_model = MusicGen.get_pretrained(checkpoint, device=device)
    # æ ¹æ®æ£€æŸ¥ç‚¹åç§°è·å–è§£ç å™¨çš„é…ç½®ä¿¡æ¯
    decoder_config = decoder_config_from_checkpoint(checkpoint)

    # è·å–Fairseqæ¨¡å‹çš„è¯­è¨€æ¨¡å‹çŠ¶æ€å­—å…¸
    decoder_state_dict = fairseq_model.lm.state_dict()
    # é‡å‘½åè§£ç å™¨çš„çŠ¶æ€å­—å…¸ï¼ŒåŒæ—¶è·å–ç¼–ç å™¨åˆ°è§£ç å™¨æŠ•å½±çš„çŠ¶æ€å­—å…¸
    decoder_state_dict, enc_dec_proj_state_dict = rename_state_dict(
        decoder_state_dict, hidden_size=decoder_config.hidden_size
    )

    # ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­åŠ è½½T5æ–‡æœ¬ç¼–ç å™¨å’Œ32kHzéŸ³é¢‘ç¼–ç å™¨
    text_encoder = T5EncoderModel.from_pretrained("google-t5/t5-base")
    audio_encoder = EncodecModel.from_pretrained("facebook/encodec_32khz")
    # åˆ›å»ºMusicgenForCausalLMå¯¹è±¡ä½œä¸ºè§£ç å™¨
    decoder = MusicgenForCausalLM(decoder_config).eval()

    # åŠ è½½è§£ç å™¨çš„æ‰€æœ‰æƒé‡ï¼Œä½†å¯èƒ½ç¼ºå°‘åµŒå…¥å±‚å’Œç¼–ç å™¨åˆ°è§£ç å™¨çš„æŠ•å½±
    missing_keys, unexpected_keys = decoder.load_state_dict(decoder_state_dict, strict=False)

    # å¯¹äºç¬¦åˆé¢„æœŸç¼ºå¤±çš„é”®ï¼Œç§»é™¤å…¶åœ¨ç¼ºå¤±åˆ—è¡¨ä¸­
    for key in missing_keys.copy():
        if key.startswith(("text_encoder", "audio_encoder")) or key in EXPECTED_MISSING_KEYS:
            missing_keys.remove(key)

    # å¦‚æœä»æœ‰ç¼ºå¤±çš„é”®å­˜åœ¨ï¼Œåˆ™æŠ›å‡ºæ•°å€¼é”™è¯¯å¼‚å¸¸
    if len(missing_keys) > 0:
        raise ValueError(f"Missing key(s) in state_dict: {missing_keys}")

    # å¦‚æœå­˜åœ¨ä¸é¢„æœŸçš„é”®ï¼Œåˆ™æŠ›å‡ºæ•°å€¼é”™è¯¯å¼‚å¸¸
    if len(unexpected_keys) > 0:
        raise ValueError(f"Unexpected key(s) in state_dict: {unexpected_keys}")

    # åˆå§‹åŒ–ç»„åˆæ¨¡å‹ï¼ŒåŒ…æ‹¬æ–‡æœ¬ç¼–ç å™¨ã€éŸ³é¢‘ç¼–ç å™¨å’Œè§£ç å™¨
    model = MusicgenForConditionalGeneration(text_encoder=text_encoder, audio_encoder=audio_encoder, decoder=decoder)

    # åŠ è½½é¢„è®­ç»ƒçš„ç¼–ç å™¨åˆ°è§£ç å™¨æŠ•å½±æƒé‡
    model.enc_to_dec_proj.load_state_dict(enc_dec_proj_state_dict)
    # æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›è¡Œå‰å‘ä¼ æ’­

    # åˆ›å»ºä¸€ä¸ªé•¿ä¸º 2*decoder_config.num_codebooks çš„é•¿æ•´å‹å¼ é‡ï¼Œå¹¶é‡å¡‘ä¸ºå½¢çŠ¶ä¸º (2, -1)
    input_ids = torch.arange(0, 2 * decoder_config.num_codebooks, dtype=torch.long).reshape(2, -1)
    # å°† input_ids é‡å¡‘ä¸ºå½¢çŠ¶ä¸º (2*decoder_config.num_codebooks, -1) çš„å¼ é‡ä½œä¸º decoder_input_ids
    decoder_input_ids = input_ids.reshape(2 * decoder_config.num_codebooks, -1)

    # ç¦ç”¨æ¢¯åº¦è®¡ç®—
    with torch.no_grad():
        # ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼Œä¼ å…¥ input_ids å’Œ decoder_input_idsï¼Œè·å–logits
        logits = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids).logits

    # æ£€æŸ¥ logits çš„å½¢çŠ¶æ˜¯å¦ä¸º (2*decoder_config.num_codebooks, 1, 2048)ï¼Œå¦åˆ™å¼•å‘ ValueError å¼‚å¸¸
    if logits.shape != (2 * decoder_config.num_codebooks, 1, 2048):
        raise ValueError("Incorrect shape for logits")

    # å®ä¾‹åŒ–ä¸€ä¸ª T5 tokenizerï¼Œä»é¢„è®­ç»ƒæ¨¡å‹ "google-t5/t5-base" åŠ è½½
    tokenizer = AutoTokenizer.from_pretrained("google-t5/t5-base")
    # å®ä¾‹åŒ–ä¸€ä¸ªç‰¹å¾æå–å™¨ï¼Œä»é¢„è®­ç»ƒæ¨¡å‹ "facebook/encodec_32khz" åŠ è½½ï¼Œè®¾ç½®å¡«å……åœ¨å·¦ä¾§ï¼Œç‰¹å¾å¤§å°ä¸º decoder_config.audio_channels
    feature_extractor = AutoFeatureExtractor.from_pretrained(
        "facebook/encodec_32khz", padding_side="left", feature_size=decoder_config.audio_channels
    )

    # å®ä¾‹åŒ–ä¸€ä¸ªéŸ³ä¹ç”Ÿæˆå¤„ç†å™¨ï¼Œä¼ å…¥ç‰¹å¾æå–å™¨å’Œ tokenizer
    processor = MusicgenProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)

    # è®¾ç½®é€‚å½“çš„å¼€å§‹å’Œå¡«å……æ ‡è®°çš„ ID
    model.generation_config.decoder_start_token_id = 2048
    model.generation_config.pad_token_id = 2048

    # è®¾ç½®å…¶ä»–é»˜è®¤çš„ç”Ÿæˆé…ç½®å‚æ•°
    model.generation_config.max_length = int(30 * audio_encoder.config.frame_rate)
    model.generation_config.do_sample = True
    model.generation_config.guidance_scale = 3.0

    # å¦‚æœæŒ‡å®šäº† pytorch_dump_folderï¼Œåˆ™ä¿å­˜æ¨¡å‹å’Œå¤„ç†å™¨åˆ°è¯¥æ–‡ä»¶å¤¹
    if pytorch_dump_folder is not None:
        # åˆ›å»ºç›®å½•ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™ä¸åšä»»ä½•æ“ä½œ
        Path(pytorch_dump_folder).mkdir(exist_ok=True)
        # è®°å½•æ—¥å¿—ï¼Œæ˜¾ç¤ºæ­£åœ¨ä¿å­˜æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
        logger.info(f"Saving model {checkpoint} to {pytorch_dump_folder}")
        # ä¿å­˜æ¨¡å‹åˆ° pytorch_dump_folderï¼Œä½¿ç”¨å®‰å…¨åºåˆ—åŒ–è¿›è¡Œä¿å­˜
        model.save_pretrained(pytorch_dump_folder, safe_serialization=safe_serialization)
        # ä¿å­˜å¤„ç†å™¨åˆ° pytorch_dump_folder
        processor.save_pretrained(pytorch_dump_folder)

    # å¦‚æœæä¾›äº† repo_idï¼Œåˆ™æ¨é€æ¨¡å‹åˆ°æŒ‡å®šçš„ Hub ä»“åº“
    if repo_id:
        # è®°å½•æ—¥å¿—ï¼Œæ˜¾ç¤ºæ­£åœ¨æ¨é€æ¨¡å‹åˆ°æŒ‡å®š repo_id
        logger.info(f"Pushing model {checkpoint} to {repo_id}")
        # å°†æ¨¡å‹æ¨é€åˆ°æŒ‡å®šçš„ repo_idï¼Œä½¿ç”¨å®‰å…¨åºåˆ—åŒ–è¿›è¡Œä¿å­˜
        model.push_to_hub(repo_id, safe_serialization=safe_serialization)
        # å°†å¤„ç†å™¨æ¨é€åˆ°æŒ‡å®šçš„ repo_id
        processor.push_to_hub(repo_id)
if __name__ == "__main__":
    # å¦‚æœè„šæœ¬ç›´æ¥æ‰§è¡Œè€Œéè¢«å¯¼å…¥ï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹ä»£ç å—

    parser = argparse.ArgumentParser()
    # åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡

    # å¿…å¡«å‚æ•°
    parser.add_argument(
        "--checkpoint",
        default="small",
        type=str,
        help="Checkpoint size of the MusicGen model you'd like to convert. Can be one of: "
             "`['small', 'medium', 'large']` for the mono checkpoints, or "
             "`['facebook/musicgen-stereo-small', 'facebook/musicgen-stereo-medium', 'facebook/musicgen-stereo-large']` "
             "for the stereo checkpoints.",
    )

    # å¿…å¡«å‚æ•°
    parser.add_argument(
        "--pytorch_dump_folder",
        required=True,
        default=None,
        type=str,
        help="Path to the output PyTorch model directory.",
    )

    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
    )

    parser.add_argument(
        "--device", default="cpu", type=str, help="Torch device to run the conversion, either cpu or cuda."
    )

    parser.add_argument(
        "--safe_serialization",
        action="store_true",
        help="Whether to save the model using `safetensors` or the traditional PyTorch way (that uses `pickle`).",
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()

    # è°ƒç”¨å‡½æ•°è¿›è¡ŒéŸ³ä¹ç”Ÿæˆæ¨¡å‹çš„è½¬æ¢
    convert_musicgen_checkpoint(args.checkpoint, args.pytorch_dump_folder, args.push_to_hub)
```