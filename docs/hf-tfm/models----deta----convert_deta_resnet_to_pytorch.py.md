# `.\models\deta\convert_deta_resnet_to_pytorch.py`

```
# coding=utf-8
# ç‰ˆæƒå£°æ˜ï¼Œä½¿ç”¨ Apache License 2.0 åè®®
# å¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œåº“
import argparse   # ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°
import json   # ç”¨äºå¤„ç† JSON æ•°æ®
from pathlib import Path   # ç”¨äºå¤„ç†æ–‡ä»¶è·¯å¾„

import requests   # ç”¨äºå‘é€ HTTP è¯·æ±‚ï¼Œä¸‹è½½æ–‡ä»¶
import torch   # PyTorch æ·±åº¦å­¦ä¹ åº“
from huggingface_hub import cached_download, hf_hub_download, hf_hub_url   # ç”¨äºä» Hugging Face æ¨¡å‹åº“ä¸‹è½½å’Œç¼“å­˜æ¨¡å‹
from PIL import Image   # Python å›¾åƒå¤„ç†åº“

from transformers import DetaConfig, DetaForObjectDetection, DetaImageProcessor   # å¯¼å…¥ DETA ç›¸å…³ç±»å’Œå‡½æ•°
from transformers.utils import logging   # å¯¼å…¥æ—¥å¿—æ¨¡å—

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.set_verbosity_info()
# å®ä¾‹åŒ– logger å¯¹è±¡
logger = logging.get_logger(__name__)

# è·å– DETA çš„é…ç½®
def get_deta_config():
    # åˆå§‹åŒ– DETA é…ç½®å¯¹è±¡
    config = DetaConfig(
        num_queries=900,
        encoder_ffn_dim=2048,
        decoder_ffn_dim=2048,
        num_feature_levels=5,
        assign_first_stage=True,
        with_box_refine=True,
        two_stage=True,
    )

    # è®¾ç½®æ ‡ç­¾
    config.num_labels = 91
    # è®¾ç½®æ¨¡å‹æ‰€ä½¿ç”¨çš„æ ‡ç­¾å¯¹åº”çš„ JSON æ–‡ä»¶è·¯å¾„
    repo_id = "huggingface/label-files"
    filename = "coco-detection-id2label.json"
    # ä» Hugging Face æ¨¡å‹åº“ä¸­ç¼“å­˜è¯¥æ–‡ä»¶
    id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type="dataset")), "r"))
    # å°†æ ‡ç­¾å­—å…¸ä¸­çš„é”®è½¬æ¢ä¸ºæ•´æ•°ç±»å‹
    id2label = {int(k): v for k, v in id2label.items()}
    # è®¾ç½® DETA é…ç½®å¯¹è±¡ä¸­çš„ id2label å’Œ label2id å±æ€§
    config.id2label = id2label
    config.label2id = {v: k for k, v in id2label.items()}

    return config

# è¿™é‡Œåˆ—å‡ºäº†æ‰€æœ‰è¦é‡å‘½åçš„é”®ï¼ˆåŸå§‹åç§°åœ¨å·¦è¾¹ï¼Œæˆ‘ä»¬çš„åç§°åœ¨å³è¾¹ï¼‰
def create_rename_keys(config):
    rename_keys = []

    # stem
    # fmt: off
    rename_keys.append(("backbone.0.body.conv1.weight", "model.backbone.model.embedder.embedder.convolution.weight"))
    rename_keys.append(("backbone.0.body.bn1.weight", "model.backbone.model.embedder.embedder.normalization.weight"))
    rename_keys.append(("backbone.0.body.bn1.bias", "model.backbone.model.embedder.embedder.normalization.bias"))
    rename_keys.append(("backbone.0.body.bn1.running_mean", "model.backbone.model.embedder.embedder.normalization.running_mean"))
    rename_keys.append(("backbone.0.body.bn1.running_var", "model.backbone.model.embedder.embedder.normalization.running_var"))
    # stages
    # transformer encoder


è¯¥éƒ¨åˆ†ä»£ç ä¸»è¦å®ç°äº†ä»¥ä¸‹åŠŸèƒ½ï¼š
- å¯¼å…¥æ‰€éœ€çš„æ¨¡å—å’Œåº“
- è®¾ç½®æ—¥å¿—çº§åˆ«å’Œè·å–æ—¥å¿—è®°å½•å™¨
- å®šä¹‰è·å– DETA é…ç½®çš„å‡½æ•°
- å®šä¹‰é‡å‘½åé”®çš„å‡½æ•°

å…¶ä¸­ï¼Œ`get_deta_config` å‡½æ•°ç”¨äºè¯»å–å’Œè®¾ç½®æ ‡ç­¾ã€‚å®ƒä» Hugging Face æ¨¡å‹åº“ä¸­ä¸‹è½½ç¼“å­˜äº†ä¸€ä¸ª JSON æ–‡ä»¶ï¼Œå°†å…¶ä¸­çš„æ ‡ç­¾ä¿¡æ¯åŠ è½½åˆ° DETA é…ç½®å¯¹è±¡ä¸­ï¼Œå¹¶å°†æ ‡ç­¾å­—å…¸çš„é”®çš„æ•°æ®ç±»å‹è½¬æ¢ä¸ºæ•´æ•°ç±»å‹ã€‚

`create_rename_keys` å‡½æ•°ç”¨äºåˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«éœ€è¦é‡å‘½åçš„é”®ã€‚åœ¨è¿™é‡Œï¼Œåˆ—å‡ºäº†è¦æ›´æ”¹çš„ä¸€äº›æ¨¡å‹æƒé‡çš„é”®åã€‚
    # å¯¹äºé…ç½®ä¸­ç¼–ç å™¨å±‚æ•°çš„æ¯ä¸€å±‚ï¼Œå°†é”®é‡å‘½åå¹¶æ·»åŠ åˆ°é‡å‘½ååˆ—è¡¨ä¸­
    for i in range(config.encoder_layers):
        rename_keys.append((f"transformer.encoder.layers.{i}.self_attn.sampling_offsets.weight", f"model.encoder.layers.{i}.self_attn.sampling_offsets.weight"))
        # å°†æƒé‡çš„é”®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚i
        rename_keys.append((f"transformer.encoder.layers.{i}.self_attn.sampling_offsets.bias", f"model.encoder.layers.{i}.self_attn.sampling_offsets.bias"))
        # å°†åç½®çš„é”®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚i
        rename_keys.append((f"transformer.encoder.layers.{i}.self_attn.attention_weights.weight", f"model.encoder.layers.{i}.self_attn.attention_weights.weight"))
        # å°†æ³¨æ„åŠ›æƒé‡çš„é”®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚i
        rename_keys.append((f"transformer.encoder.layers.{i}.self_attn.attention_weights.bias", f"model.encoder.layers.{i}.self_attn.attention_weights.bias"))
        # å°†æ³¨æ„åŠ›æƒé‡çš„åç½®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚i
        rename_keys.append((f"transformer.encoder.layers.{i}.self_attn.value_proj.weight", f"model.encoder.layers.{i}.self_attn.value_proj.weight"))
        # å°†å€¼æŠ•å½±çš„æƒé‡ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚i
        rename_keys.append((f"transformer.encoder.layers.{i}.self_attn.value_proj.bias", f"model.encoder.layers.{i}.self_attn.value_proj.bias"))
        # å°†å€¼æŠ•å½±çš„åç½®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚i
        rename_keys.append((f"transformer.encoder.layers.{i}.self_attn.output_proj.weight", f"model.encoder.layers.{i}.self_attn.output_proj.weight"))
        # å°†è¾“å‡ºæŠ•å½±çš„æƒé‡ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚i
        rename_keys.append((f"transformer.encoder.layers.{i}.self_attn.output_proj.bias", f"model.encoder.layers.{i}.self_attn.output_proj.bias"))
        # å°†è¾“å‡ºæŠ•å½±çš„åç½®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚i
        rename_keys.append((f"transformer.encoder.layers.{i}.norm1.weight", f"model.encoder.layers.{i}.self_attn_layer_norm.weight"))
        # å°†norm1çš„æƒé‡ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚içš„self_attn_layer_normçš„æƒé‡
        rename_keys.append((f"transformer.encoder.layers.{i}.norm1.bias", f"model.encoder.layers.{i}.self_attn_layer_norm.bias"))
        # å°†norm1çš„åç½®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚içš„self_attn_layer_normçš„åç½®
        rename_keys.append((f"transformer.encoder.layers.{i}.linear1.weight", f"model.encoder.layers.{i}.fc1.weight"))
        # å°†linear1çš„æƒé‡ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚içš„fc1çš„æƒé‡
        rename_keys.append((f"transformer.encoder.layers.{i}.linear1.bias", f"model.encoder.layers.{i}.fc1.bias"))
        # å°†linear1çš„åç½®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚içš„fc1çš„åç½®
        rename_keys.append((f"transformer.encoder.layers.{i}.linear2.weight", f"model.encoder.layers.{i}.fc2.weight"))
        # å°†linear2çš„æƒé‡ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚içš„fc2çš„æƒé‡
        rename_keys.append((f"transformer.encoder.layers.{i}.linear2.bias", f"model.encoder.layers.{i}.fc2.bias"))
        # å°†linear2çš„åç½®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚içš„fc2çš„åç½®
        rename_keys.append((f"transformer.encoder.layers.{i}.norm2.weight", f"model.encoder.layers.{i}.final_layer_norm.weight"))
        # å°†norm2çš„æƒé‡ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚içš„final_layer_normçš„æƒé‡
        rename_keys.append((f"transformer.encoder.layers.{i}.norm2.bias", f"model.encoder.layers.{i}.final_layer_norm.bias"))
        # å°†norm2çš„åç½®ä»transformerçš„ç¼–ç å™¨å±‚iè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹ç¼–ç å™¨å±‚içš„final_layer_normçš„åç½®

    # transformerè§£ç å™¨
    # å¾ªç¯éå†decoder_layersæ¬¡ï¼Œé€ä¸ªå¤„ç†å±‚
    for i in range(config.decoder_layers):
        # å°†è¡¨ç¤ºè½¬æ¢å‚æ•°çš„é”®å€¼å¯¹æ·»åŠ åˆ°rename_keysåˆ—è¡¨ä¸­ï¼Œç”¨äºé‡å‘½åæ¨¡å‹å‚æ•°
        rename_keys.append((f"transformer.decoder.layers.{i}.cross_attn.sampling_offsets.weight", f"model.decoder.layers.{i}.encoder_attn.sampling_offsets.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.cross_attn.sampling_offsets.bias", f"model.decoder.layers.{i}.encoder_attn.sampling_offsets.bias"))
        rename_keys.append((f"transformer.decoder.layers.{i}.cross_attn.attention_weights.weight", f"model.decoder.layers.{i}.encoder_attn.attention_weights.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.cross_attn.attention_weights.bias", f"model.decoder.layers.{i}.encoder_attn.attention_weights.bias"))
        rename_keys.append((f"transformer.decoder.layers.{i}.cross_attn.value_proj.weight", f"model.decoder.layers.{i}.encoder_attn.value_proj.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.cross_attn.value_proj.bias", f"model.decoder.layers.{i}.encoder_attn.value_proj.bias"))
        rename_keys.append((f"transformer.decoder.layers.{i}.cross_attn.output_proj.weight", f"model.decoder.layers.{i}.encoder_attn.output_proj.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.cross_attn.output_proj.bias", f"model.decoder.layers.{i}.encoder_attn.output_proj.bias"))
        rename_keys.append((f"transformer.decoder.layers.{i}.norm1.weight", f"model.decoder.layers.{i}.encoder_attn_layer_norm.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.norm1.bias", f"model.decoder.layers.{i}.encoder_attn_layer_norm.bias"))
        rename_keys.append((f"transformer.decoder.layers.{i}.self_attn.out_proj.weight", f"model.decoder.layers.{i}.self_attn.out_proj.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.self_attn.out_proj.bias", f"model.decoder.layers.{i}.self_attn.out_proj.bias"))
        rename_keys.append((f"transformer.decoder.layers.{i}.norm2.weight", f"model.decoder.layers.{i}.self_attn_layer_norm.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.norm2.bias", f"model.decoder.layers.{i}.self_attn_layer_norm.bias"))
        rename_keys.append((f"transformer.decoder.layers.{i}.linear1.weight", f"model.decoder.layers.{i}.fc1.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.linear1.bias", f"model.decoder.layers.{i}.fc1.bias"))
        rename_keys.append((f"transformer.decoder.layers.{i}.linear2.weight", f"model.decoder.layers.{i}.fc2.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.linear2.bias", f"model.decoder.layers.{i}.fc2.bias"))
        rename_keys.append((f"transformer.decoder.layers.{i}.norm3.weight", f"model.decoder.layers.{i}.final_layer_norm.weight"))
        rename_keys.append((f"transformer.decoder.layers.{i}.norm3.bias", f"model.decoder.layers.{i}.final_layer_norm.bias"))
    
    # è¿”å›é‡å‘½ååçš„é”®å€¼å¯¹åˆ—è¡¨
    return rename_keys
# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºé‡å‘½åå­—å…¸ä¸­çš„é”®
def rename_key(dct, old, new):
    # å¼¹å‡ºæ—§é”®å¯¹åº”çš„å€¼
    val = dct.pop(old)
    # å°†å€¼ä¸æ–°é”®å…³è”èµ·æ¥
    dct[new] = val


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè¯»å–æ¨¡å‹çš„æƒé‡å¹¶å°†å…¶å¯¼å…¥åˆ°æŒ‡å®šç»“æ„ä¸­
def read_in_decoder_q_k_v(state_dict, config):
    # è·å– Transformer è§£ç å™¨çš„éšè—å±‚å¤§å°
    hidden_size = config.d_model
    # éå† Transformer è§£ç å™¨çš„æ¯ä¸€å±‚
    for i in range(config.decoder_layers):
        # è¯»å–è‡ªæ³¨æ„åŠ›å±‚çš„è¾“å…¥æŠ•å½±å±‚çš„æƒé‡å’Œåç½®
        in_proj_weight = state_dict.pop(f"transformer.decoder.layers.{i}.self_attn.in_proj_weight")
        in_proj_bias = state_dict.pop(f"transformer.decoder.layers.{i}.self_attn.in_proj_bias")
        # å°†æƒé‡å’Œåç½®åˆ†é…åˆ°æŸ¥è¯¢ã€é”®å’Œå€¼çš„æŠ•å½±å±‚ä¸­
        state_dict[f"model.decoder.layers.{i}.self_attn.q_proj.weight"] = in_proj_weight[:hidden_size, :]
        state_dict[f"model.decoder.layers.{i}.self_attn.q_proj.bias"] = in_proj_bias[:hidden_size]
        state_dict[f"model.decoder.layers.{i}.self_attn.k_proj.weight"] = in_proj_weight[hidden_size : hidden_size * 2, :]
        state_dict[f"model.decoder.layers.{i}.self_attn.k_proj.bias"] = in_proj_bias[hidden_size : hidden_size * 2]
        state_dict[f"model.decoder.layers.{i}.self_attn.v_proj.weight"] = in_proj_weight[-hidden_size:, :]
        state_dict[f"model.decoder.layers.{i}.self_attn.v_proj.bias"] = in_proj_bias[-hidden_size:]


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå‡†å¤‡å›¾åƒæ•°æ®
# æˆ‘ä»¬å°†åœ¨ä¸€ç»„å¯çˆ±çš„çŒ«çš„å›¾åƒä¸ŠéªŒè¯æˆ‘ä»¬çš„ç»“æœ
def prepare_img():
    # å›¾ç‰‡çš„ URL åœ°å€
    url = "http://images.cocodataset.org/val2017/000000039769.jpg"
    # ä½¿ç”¨ requests è·å–å›¾ç‰‡çš„åŸå§‹æµæ•°æ®ï¼Œå¹¶ä½¿ç”¨ PIL æ‰“å¼€å›¾ç‰‡
    im = Image.open(requests.get(url, stream=True).raw)

    return im


# ä½¿ç”¨ torch.no_grad() ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç¡®ä¿åœ¨æ¨¡å‹æ¨ç†æ—¶ä¸è¿›è¡Œæ¢¯åº¦è®¡ç®—
@torch.no_grad()
# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå°† Delta æ¨¡å‹çš„æƒé‡è½¬æ¢ä¸º DETA ç»“æ„
def convert_deta_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub):
    """
    Copy/paste/tweak model's weights to our DETA structure.
    """

    # åŠ è½½é…ç½®ä¿¡æ¯
    config = get_deta_config()

    # åŠ è½½åŸå§‹çš„çŠ¶æ€å­—å…¸
    if model_name == "deta-resnet-50":
        filename = "adet_checkpoint0011.pth"
    elif model_name == "deta-resnet-50-24-epochs":
        filename = "adet_2x_checkpoint0023.pth"
    else:
        raise ValueError(f"Model name {model_name} not supported")
    # ä¸‹è½½æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶å¹¶åŠ è½½çŠ¶æ€å­—å…¸
    checkpoint_path = hf_hub_download(repo_id="nielsr/deta-checkpoints", filename=filename)
    state_dict = torch.load(checkpoint_path, map_location="cpu")["model"]

    # é‡å‘½åé”®
    rename_keys = create_rename_keys(config)
    for src, dest in rename_keys:
        rename_key(state_dict, src, dest)
    # è¯»å–è‡ªæ³¨æ„åŠ›å±‚çš„æŸ¥è¯¢ã€é”®å’Œå€¼
    read_in_decoder_q_k_v(state_dict, config)

    # ä¿®æ­£ä¸€äº›å‰ç¼€
    for key in state_dict.copy().keys():
        if "transformer.decoder.class_embed" in key or "transformer.decoder.bbox_embed" in key:
            val = state_dict.pop(key)
            state_dict[key.replace("transformer.decoder", "model.decoder")] = val
        if "input_proj" in key:
            val = state_dict.pop(key)
            state_dict["model." + key] = val
        if "level_embed" in key or "pos_trans" in key or "pix_trans" in key or "enc_output" in key:
            val = state_dict.pop(key)
            state_dict[key.replace("transformer", "model")] = val
    # æœ€åï¼Œåˆ›å»º HuggingFace æ¨¡å‹å¹¶åŠ è½½çŠ¶æ€å­—å…¸
    model = DetaForObjectDetection(config)
    model.load_state_dict(state_dict)
    model.eval()
    
    # å¦‚æœ GPU å¯ç”¨ï¼Œåˆ™å°†æ¨¡å‹ç§»åˆ° GPU ä¸Šï¼Œå¦åˆ™ç§»åˆ° CPU ä¸Š
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    
    # åŠ è½½å›¾åƒå¤„ç†å™¨
    processor = DetaImageProcessor(format="coco_detection")
    
    # æ£€æŸ¥å›¾åƒå¤„ç†å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ
    img = prepare_img()
    encoding = processor(images=img, return_tensors="pt")
    pixel_values = encoding["pixel_values"]
    outputs = model(pixel_values.to(device))
    
    # æ£€æŸ¥è¾“å‡ºçš„é€»è¾‘å€¼ï¼ˆlogitsï¼‰
    if model_name == "deta-resnet-50":
        expected_logits = torch.tensor(
            [[-7.3978, -2.5406, -4.1668], [-8.2684, -3.9933, -3.8096], [-7.0515, -3.7973, -5.8516]]
        )
        expected_boxes = torch.tensor([[0.5043, 0.4973, 0.9998], [0.2542, 0.5489, 0.4748], [0.5490, 0.2765, 0.0570]])
    elif model_name == "deta-resnet-50-24-epochs":
        expected_logits = torch.tensor(
            [[-7.1688, -2.4857, -4.8669], [-7.8630, -3.8154, -4.2674], [-7.2730, -4.1865, -5.5323]]
        )
        expected_boxes = torch.tensor([[0.5021, 0.4971, 0.9994], [0.2546, 0.5486, 0.4731], [0.1686, 0.1986, 0.2142]])
    
    # æ£€æŸ¥æ¨¡å‹çš„è¾“å‡ºé€»è¾‘å€¼å’Œè¾¹ç•Œæ¡†æ˜¯å¦ä¸é¢„æœŸå€¼ç›¸ç¬¦
    assert torch.allclose(outputs.logits[0, :3, :3], expected_logits.to(device), atol=1e-4)
    assert torch.allclose(outputs.pred_boxes[0, :3, :3], expected_boxes.to(device), atol=1e-4)
    print("Everything ok!")
    
    # å¦‚æœæŒ‡å®šäº† pytorch_dump_folder_pathï¼Œåˆ™ä¿å­˜æ¨¡å‹å’Œå¤„ç†å™¨
    if pytorch_dump_folder_path:
        logger.info(f"Saving PyTorch model and processor to {pytorch_dump_folder_path}...")
        Path(pytorch_dump_folder_path).mkdir(exist_ok=True)
        model.save_pretrained(pytorch_dump_folder_path)
        processor.save_pretrained(pytorch_dump_folder_path)
    
    # å¦‚æœæŒ‡å®šäº† push_to_hubï¼Œåˆ™å°†æ¨¡å‹å’Œå¤„ç†å™¨æ¨é€åˆ° Hub
    if push_to_hub:
        print("Pushing model and processor to hub...")
        model.push_to_hub(f"jozhang97/{model_name}")
        processor.push_to_hub(f"jozhang97/{model_name}")
# å¦‚æœè¯¥è„šæœ¬ä½œä¸ºç‹¬ç«‹è¿è¡Œçš„ç¨‹åºï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹ä»£ç 
if __name__ == "__main__":
    # åˆ›å»ºä¸€ä¸ªå‚æ•°è§£æå™¨å¯¹è±¡
    parser = argparse.ArgumentParser()

    # æ·»åŠ ä¸€ä¸ªå‚æ•°ï¼Œç”¨äºæŒ‡å®šæ¨¡å‹çš„åç§°
    parser.add_argument(
        "--model_name",
        type=str,
        default="deta-resnet-50",
        choices=["deta-resnet-50", "deta-resnet-50-24-epochs"],
        help="Name of the model you'd like to convert.",
    )
    # æ·»åŠ ä¸€ä¸ªå‚æ•°ï¼Œç”¨äºæŒ‡å®šå¯¼å‡º PyTorch æ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„
    parser.add_argument(
        "--pytorch_dump_folder_path",
        default=None,
        type=str,
        help="Path to the folder to output PyTorch model.",
    )
    # æ·»åŠ ä¸€ä¸ªå‚æ•°ï¼Œç”¨äºæŒ‡å®šæ˜¯å¦å°†è½¬æ¢åçš„æ¨¡å‹æ¨é€åˆ° ğŸ¤— hub
    parser.add_argument(
        "--push_to_hub", action="store_true", help="Whether or not to push the converted model to the ğŸ¤— hub."
    )
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    # è°ƒç”¨è½¬æ¢å‡½æ•°ï¼Œä¼ å…¥å‚æ•°æ¨¡å‹åç§°ã€PyTorch æ¨¡å‹è¾“å‡ºè·¯å¾„ã€æ˜¯å¦æ¨é€åˆ° hub
    convert_deta_checkpoint(args.model_name, args.pytorch_dump_folder_path, args.push_to_hub)
```