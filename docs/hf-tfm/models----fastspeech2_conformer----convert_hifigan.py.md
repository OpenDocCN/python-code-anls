# `.\models\fastspeech2_conformer\convert_hifigan.py`

```
# è®¾ç½®æ–‡ä»¶ç¼–ç ä¸º UTF-8
# ç‰ˆæƒå£°æ˜åŠè®¸å¯è¯ä¿¡æ¯
"""Convert FastSpeech2Conformer HiFi-GAN checkpoint."""

# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import argparse
from pathlib import Path

# å¯¼å…¥ PyTorch åº“
import torch
import yaml

# å¯¼å…¥ Hugging Face çš„ Transformers åº“
from transformers import FastSpeech2ConformerHifiGan, FastSpeech2ConformerHifiGanConfig, logging

# è®¾ç½®æ—¥å¿—è®°å½•çº§åˆ«ä¸º info
logging.set_verbosity_info()
# è·å–è®°å½•å™¨
logger = logging.get_logger("transformers.models.FastSpeech2Conformer")

# å®šä¹‰å‡½æ•°ä»¥åŠ è½½æƒé‡
def load_weights(checkpoint, hf_model, config):
    # å®šä¹‰å£°ç å™¨çš„é”®å‰ç¼€
    vocoder_key_prefix = "tts.generator.vocoder."
    # ä»æ£€æŸ¥ç‚¹ä¸­æå–å£°ç å™¨ç›¸å…³é”®å€¼å¯¹ï¼Œå¹¶å»é™¤å‰ç¼€
    checkpoint = {k.replace(vocoder_key_prefix, ""): v for k, v in checkpoint.items() if vocoder_key_prefix in k}

    # å¯¹ HF æ¨¡å‹åº”ç”¨æƒé‡å½’ä¸€åŒ–
    hf_model.apply_weight_norm()

    # è®¾ç½®è¾“å…¥å·ç§¯å±‚çš„æƒé‡å’Œåç½®
    hf_model.conv_pre.weight_g.data = checkpoint["input_conv.weight_g"]
    hf_model.conv_pre.weight_v.data = checkpoint["input_conv.weight_v"]
    hf_model.conv_pre.bias.data = checkpoint["input_conv.bias"]

    # éå†å¹¶è®¾ç½®ä¸Šé‡‡æ ·å±‚çš„æƒé‡å’Œåç½®
    for i in range(len(config.upsample_rates)):
        hf_model.upsampler[i].weight_g.data = checkpoint[f"upsamples.{i}.1.weight_g"]
        hf_model.upsampler[i].weight_v.data = checkpoint[f"upsamples.{i}.1.weight_v"]
        hf_model.upsampler[i].bias.data = checkpoint[f"upsamples.{i}.1.bias"]

    # éå†å¹¶è®¾ç½®æ®‹å·®å—çš„æƒé‡å’Œåç½®
    for i in range(len(config.upsample_rates) * len(config.resblock_kernel_sizes)):
        for j in range(len(config.resblock_dilation_sizes)):
            hf_model.resblocks[i].convs1[j].weight_g.data = checkpoint[f"blocks.{i}.convs1.{j}.1.weight_g"]
            hf_model.resblocks[i].convs1[j].weight_v.data = checkpoint[f"blocks.{i}.convs1.{j}.1.weight_v"]
            hf_model.resblocks[i].convs1[j].bias.data = checkpoint[f"blocks.{i}.convs1.{j}.1.bias"]

            hf_model.resblocks[i].convs2[j].weight_g.data = checkpoint[f"blocks.{i}.convs2.{j}.1.weight_g"]
            hf_model.resblocks[i].convs2[j].weight_v.data = checkpoint[f"blocks.{i}.convs2.{j}.1.weight_v"]
            hf_model.resblocks[i].convs2[j].bias.data = checkpoint[f"blocks.{i}.convs2.{j}.1.bias"]

    # è®¾ç½®è¾“å‡ºå·ç§¯å±‚çš„æƒé‡å’Œåç½®
    hf_model.conv_post.weight_g.data = checkpoint["output_conv.1.weight_g"]
    hf_model.conv_post.weight_v.data = checkpoint["output_conv.1.weight_v"]
    hf_model.conv_post.bias.data = checkpoint["output_conv.1.bias"]

    # ç§»é™¤ HF æ¨¡å‹çš„æƒé‡å½’ä¸€åŒ–
    hf_model.remove_weight_norm()

# é‡æ–°æ˜ å°„ Hifigan çš„ YAML é…ç½®
def remap_hifigan_yaml_config(yaml_config_path):
    # ä» YAML æ–‡ä»¶ä¸­åŠ è½½é…ç½®å‚æ•°
    with Path(yaml_config_path).open("r", encoding="utf-8") as f:
        args = yaml.safe_load(f)
        args = argparse.Namespace(**args)

    # è·å–å£°ç å™¨ç±»å‹
    vocoder_type = args.tts_conf["vocoder_type"]
    # å¦‚æœ vocoder_type ä¸æ˜¯ "hifigan_generator"ï¼Œåˆ™æŠ›å‡ºç±»å‹é”™è¯¯å¼‚å¸¸ï¼ŒæŒ‡ç¤ºå¿…é¡»ä½¿ç”¨ `hifigan_generator` çš„å£°ç å™¨é…ç½®
    if vocoder_type != "hifigan_generator":
        raise TypeError(f"Vocoder config must be for `hifigan_generator`, but got {vocoder_type}")

    # åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸ï¼Œç”¨äºå­˜å‚¨é‡æ–°æ˜ å°„åçš„å‚æ•°
    remapped_dict = {}
    # è·å– vocoder_params
    vocoder_params = args.tts_conf["vocoder_params"]

    # å®šä¹‰å­—å…¸ï¼ŒæŒ‡å®šå‚æ•°ä¹‹é—´çš„é”®æ˜ å°„å…³ç³»
    # espnet_config_key -> hf_config_key
    key_mappings = {
        "channels": "upsample_initial_channel",
        "in_channels": "model_in_dim",
        "resblock_dilations": "resblock_dilation_sizes",
        "resblock_kernel_sizes": "resblock_kernel_sizes",
        "upsample_kernel_sizes": "upsample_kernel_sizes",
        "upsample_scales": "upsample_rates",
    }
    # éå†é”®æ˜ å°„å…³ç³»å­—å…¸ï¼Œå°†å‚æ•°ä» espnet_config_key æ˜ å°„åˆ° hf_config_key
    for espnet_config_key, hf_config_key in key_mappings.items():
        remapped_dict[hf_config_key] = vocoder_params[espnet_config_key]
    # å°†é‡‡æ ·ç‡æ·»åŠ åˆ°é‡æ–°æ˜ å°„çš„å­—å…¸ä¸­
    remapped_dict["sampling_rate"] = args.tts_conf["sampling_rate"]
    # è®¾ç½® normalize_before å‚æ•°ä¸º False
    remapped_dict["normalize_before"] = False
    # ä» vocoder_params ä¸­è·å–éçº¿æ€§æ¿€æ´»å‚æ•°ä¸­çš„ negative_slopeï¼Œå¹¶æ·»åŠ åˆ°é‡æ–°æ˜ å°„çš„å­—å…¸ä¸­
    remapped_dict["leaky_relu_slope"] = vocoder_params["nonlinear_activation_params"]["negative_slope"]

    # è¿”å›é‡æ–°æ˜ å°„åçš„å­—å…¸
    return remapped_dict
# ç¦ç”¨æ¢¯åº¦æ›´æ–°ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä»¥ç¡®ä¿åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸ä¼šè¿›è¡Œæ¢¯åº¦æ›´æ–°
@torch.no_grad()
# å°† HiFi-GAN æ¨¡å‹æ£€æŸ¥ç‚¹è½¬æ¢ä¸º PyTorch æ¨¡å‹
def convert_hifigan_checkpoint(
    # æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
    checkpoint_path,
    # è½¬æ¢åçš„ PyTorch æ¨¡å‹ä¿å­˜è·¯å¾„
    pytorch_dump_folder_path,
    # å¯é€‰å‚æ•°ï¼ŒHiFi-GAN æ¨¡å‹çš„é…ç½®æ–‡ä»¶è·¯å¾„
    yaml_config_path=None,
    # å¯é€‰å‚æ•°ï¼Œæ¨¡å‹åœ¨ ğŸ¤— hub ä¸­çš„å­˜å‚¨åº“ ID
    repo_id=None,
):
    # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œåˆ™æ ¹æ®é…ç½®æ–‡ä»¶åˆ›å»º HiFi-GAN æ¨¡å‹é…ç½®å¯¹è±¡
    if yaml_config_path is not None:
        # é€šè¿‡é…ç½®æ–‡ä»¶è·¯å¾„è·å–é…ç½®å‚æ•°
        config_kwargs = remap_hifigan_yaml_config(yaml_config_path)
        # ä½¿ç”¨é…ç½®å‚æ•°åˆå§‹åŒ– FastSpeech2ConformerHifiGanConfig é…ç½®å¯¹è±¡
        config = FastSpeech2ConformerHifiGanConfig(**config_kwargs)
    # å¦‚æœæœªæä¾›é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä½¿ç”¨é»˜è®¤å‚æ•°åˆå§‹åŒ– HiFi-GAN æ¨¡å‹é…ç½®å¯¹è±¡
    else:
        config = FastSpeech2ConformerHifiGanConfig()
    
    # æ ¹æ®é…ç½®å¯¹è±¡åˆå§‹åŒ– FastSpeech2ConformerHifiGan æ¨¡å‹
    model = FastSpeech2ConformerHifiGan(config)

    # åŠ è½½åŸå§‹æ£€æŸ¥ç‚¹
    orig_checkpoint = torch.load(checkpoint_path)
    # å°†åŸå§‹æ£€æŸ¥ç‚¹åŠ è½½åˆ°æ¨¡å‹ä¸­
    load_weights(orig_checkpoint, model, config)

    # ä¿å­˜è½¬æ¢åçš„æ¨¡å‹ä¸º PyTorch æ¨¡å‹
    model.save_pretrained(pytorch_dump_folder_path)

    # å¦‚æœæä¾›äº†å­˜å‚¨åº“ IDï¼Œå°†æ¨¡å‹æ¨é€åˆ° ğŸ¤— hub
    if repo_id:
        print("Pushing to the hub...")
        model.push_to_hub(repo_id)


# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    # åˆ›å»ºå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser()
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šåŸå§‹æ£€æŸ¥ç‚¹è·¯å¾„
    parser.add_argument("--checkpoint_path", required=True, default=None, type=str, help="Path to original checkpoint")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šé…ç½®æ–‡ä»¶è·¯å¾„
    parser.add_argument("--yaml_config_path", default=None, type=str, help="Path to config.yaml of model to convert")
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šè½¬æ¢åçš„ PyTorch æ¨¡å‹ä¿å­˜è·¯å¾„
    parser.add_argument(
        "--pytorch_dump_folder_path", required=True, default=None, type=str, help="Path to the output PyTorch model."
    )
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼šæ¨¡å‹æ¨é€åˆ° ğŸ¤— hub çš„å­˜å‚¨åº“ ID
    parser.add_argument(
        "--push_to_hub", default=None, type=str, help="Where to upload the converted model on the ğŸ¤— hub."
    )

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    # è°ƒç”¨å‡½æ•°ï¼Œå°† HiFi-GAN æ¨¡å‹æ£€æŸ¥ç‚¹è½¬æ¢ä¸º PyTorch æ¨¡å‹
    convert_hifigan_checkpoint(
        args.checkpoint_path,
        args.pytorch_dump_folder_path,
        args.yaml_config_path,
        args.push_to_hub,
    )
```