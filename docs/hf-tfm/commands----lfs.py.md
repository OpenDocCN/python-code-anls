# `.\commands\lfs.py`

```
"""
Implementation of a custom transfer agent for the transfer type "multipart" for git-lfs.

Inspired by: github.com/cbartz/git-lfs-swift-transfer-agent/blob/master/git_lfs_swift_transfer.py

Spec is: github.com/git-lfs/git-lfs/blob/master/docs/custom-transfers.md


To launch debugger while developing:

``` [lfs "customtransfer.multipart"]
path = /path/to/transformers/.env/bin/python args = -m debugpy --listen 5678 --wait-for-client
/path/to/transformers/src/transformers/commands/transformers_cli.py lfs-multipart-upload ```"""

import json  # å¯¼å…¥å¤„ç† JSON çš„æ¨¡å—
import os  # å¯¼å…¥æ“ä½œç³»ç»ŸåŠŸèƒ½çš„æ¨¡å—
import subprocess  # å¯¼å…¥è¿è¡Œå¤–éƒ¨å‘½ä»¤çš„æ¨¡å—
import sys  # å¯¼å…¥ä¸ Python è§£é‡Šå™¨äº¤äº’çš„æ¨¡å—
import warnings  # å¯¼å…¥è­¦å‘Šå¤„ç†çš„æ¨¡å—
from argparse import ArgumentParser  # ä» argparse æ¨¡å—ä¸­å¯¼å…¥ ArgumentParser ç±»
from contextlib import AbstractContextManager  # ä» contextlib æ¨¡å—ä¸­å¯¼å…¥ AbstractContextManager ç±»
from typing import Dict, List, Optional  # å¯¼å…¥ç±»å‹æç¤ºç›¸å…³çš„æ¨¡å—

import requests  # å¯¼å…¥å¤„ç† HTTP è¯·æ±‚çš„æ¨¡å—

from ..utils import logging  # ä»ç›¸å¯¹è·¯å¾„ä¸­å¯¼å…¥ logging æ¨¡å—
from . import BaseTransformersCLICommand  # ä»å½“å‰ç›®å½•ä¸­å¯¼å…¥ BaseTransformersCLICommand ç±»

logger = logging.get_logger(__name__)  # è·å–å½“å‰æ¨¡å—çš„æ—¥å¿—è®°å½•å™¨å¯¹è±¡ï¼Œå¹¶èµ‹å€¼ç»™ logger å˜é‡  # pylint: disable=invalid-name

LFS_MULTIPART_UPLOAD_COMMAND = "lfs-multipart-upload"  # å®šä¹‰ä¸€ä¸ªå¸¸é‡ï¼ŒæŒ‡å®š LFS å¤šéƒ¨åˆ†ä¸Šä¼ å‘½ä»¤çš„åç§°

class LfsCommands(BaseTransformersCLICommand):
    """
    Implementation of a custom transfer agent for the transfer type "multipart" for git-lfs. This lets users upload
    large files >5GB ğŸ”¥. Spec for LFS custom transfer agent is:
    https://github.com/git-lfs/git-lfs/blob/master/docs/custom-transfers.md

    This introduces two commands to the CLI:

    1. $ transformers-cli lfs-enable-largefiles

    This should be executed once for each model repo that contains a model file >5GB. It's documented in the error
    message you get if you just try to git push a 5GB file without having enabled it before.

    2. $ transformers-cli lfs-multipart-upload

    This command is called by lfs directly and is not meant to be called by the user.
    """

    @staticmethod
    def register_subcommand(parser: ArgumentParser):
        enable_parser = parser.add_parser(
            "lfs-enable-largefiles",
            help=(
                "Deprecated: use `huggingface-cli` instead. Configure your repository to enable upload of files > 5GB."
            ),
        )
        enable_parser.add_argument("path", type=str, help="Local path to repository you want to configure.")
        enable_parser.set_defaults(func=lambda args: LfsEnableCommand(args))  # è®¾ç½®é»˜è®¤çš„å‘½ä»¤å¤„ç†å‡½æ•°ä¸º LfsEnableCommand ç±»çš„å®ä¾‹åŒ–

        upload_parser = parser.add_parser(
            LFS_MULTIPART_UPLOAD_COMMAND,
            help=(
                "Deprecated: use `huggingface-cli` instead. "
                "Command will get called by git-lfs, do not call it directly."
            ),
        )
        upload_parser.set_defaults(func=lambda args: LfsUploadCommand(args))  # è®¾ç½®é»˜è®¤çš„å‘½ä»¤å¤„ç†å‡½æ•°ä¸º LfsUploadCommand ç±»çš„å®ä¾‹åŒ–

class LfsEnableCommand:
    def __init__(self, args):
        self.args = args  # åˆå§‹åŒ–ç±»å®ä¾‹æ—¶ï¼Œå°†å‚æ•°ä¿å­˜åˆ°å®ä¾‹å±æ€§ä¸­
    def run(self):
        # å‘å‡ºè­¦å‘Šä¿¡æ¯ï¼Œæç¤ºä½¿ç”¨ `huggingface-cli` å–ä»£ `transformers-cli` ç®¡ç†ä»“åº“
        warnings.warn(
            "Managing repositories through transformers-cli is deprecated. Please use `huggingface-cli` instead."
        )
        # è·å–æŒ‡å®šè·¯å¾„çš„ç»å¯¹è·¯å¾„
        local_path = os.path.abspath(self.args.path)
        # å¦‚æœæŒ‡å®šè·¯å¾„ä¸æ˜¯ä¸€ä¸ªç›®å½•ï¼Œåˆ™è¾“å‡ºé”™è¯¯ä¿¡æ¯å¹¶é€€å‡ºç¨‹åº
        if not os.path.isdir(local_path):
            print("This does not look like a valid git repo.")
            exit(1)
        # è®¾ç½® git-lfs çš„è‡ªå®šä¹‰ä¼ è¾“ç¨‹åºè·¯å¾„ä¸º `transformers-cli`ï¼Œåœ¨æŒ‡å®šè·¯å¾„ä¸‹æ‰§è¡Œ
        subprocess.run(
            "git config lfs.customtransfer.multipart.path transformers-cli".split(), check=True, cwd=local_path
        )
        # è®¾ç½® git-lfs çš„è‡ªå®šä¹‰ä¼ è¾“ç¨‹åºå‚æ•°ä¸ºé¢„å®šä¹‰çš„ `LFS_MULTIPART_UPLOAD_COMMAND` å€¼ï¼Œåœ¨æŒ‡å®šè·¯å¾„ä¸‹æ‰§è¡Œ
        subprocess.run(
            f"git config lfs.customtransfer.multipart.args {LFS_MULTIPART_UPLOAD_COMMAND}".split(),
            check=True,
            cwd=local_path,
        )
        # è¾“å‡ºä¿¡æ¯ï¼Œè¡¨ç¤ºæœ¬åœ°ä»“åº“å·²è®¾ç½®å¥½ä»¥å¤„ç†å¤§æ–‡ä»¶
        print("Local repo set up for largefiles")
# å°†å­—å…¸æ¶ˆæ¯è½¬æ¢ä¸º JSON æ ¼å¼å¹¶å†™å…¥æ ‡å‡†è¾“å‡º
def write_msg(msg: Dict):
    msg = json.dumps(msg) + "\n"  # è½¬æ¢å­—å…¸æ¶ˆæ¯ä¸º JSON å­—ç¬¦ä¸²ï¼Œå¹¶æ·»åŠ æ¢è¡Œç¬¦
    sys.stdout.write(msg)  # å°† JSON å­—ç¬¦ä¸²å†™å…¥æ ‡å‡†è¾“å‡º
    sys.stdout.flush()  # åˆ·æ–°æ ‡å‡†è¾“å‡ºç¼“å†²åŒºï¼Œç¡®ä¿æ¶ˆæ¯è¢«å†™å…¥

# ä»æ ‡å‡†è¾“å…¥è¯»å–ä¸€è¡Œ JSON æ ¼å¼çš„æ¶ˆæ¯
def read_msg() -> Optional[Dict]:
    msg = json.loads(sys.stdin.readline().strip())  # è¯»å–å¹¶è§£æ JSON æ ¼å¼çš„æ¶ˆæ¯

    if "terminate" in (msg.get("type"), msg.get("event")):
        # å¦‚æœæ¶ˆæ¯ä¸­åŒ…å« "terminate" ç±»å‹æˆ–äº‹ä»¶ï¼Œè¡¨ç¤ºç»ˆæ­¢æ¶ˆæ¯å·²æ¥æ”¶
        return None

    if msg.get("event") not in ("download", "upload"):
        logger.critical("Received unexpected message")  # è®°å½•å…³é”®é”™è¯¯æ—¥å¿—ï¼Œè¡¨ç¤ºæ¥æ”¶åˆ°æ„å¤–çš„æ¶ˆæ¯
        sys.exit(1)  # éé¢„æœŸæ¶ˆæ¯æ—¶é€€å‡ºç¨‹åº

    return msg  # è¿”å›è§£æåçš„æ¶ˆæ¯å­—å…¸

# ç”¨äºä»æ–‡ä»¶ä¸­è¯»å–æŒ‡å®šèŒƒå›´çš„æ•°æ®çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç±»
class FileSlice(AbstractContextManager):
    """
    File-like object that only reads a slice of a file

    Inspired by stackoverflow.com/a/29838711/593036
    """

    def __init__(self, filepath: str, seek_from: int, read_limit: int):
        self.filepath = filepath  # æ–‡ä»¶è·¯å¾„
        self.seek_from = seek_from  # è¯»å–èµ·å§‹ä½ç½®
        self.read_limit = read_limit  # è¯»å–æ•°æ®é™åˆ¶å¤§å°
        self.n_seen = 0  # å·²è¯»å–çš„å­—èŠ‚æ•°

    def __enter__(self):
        self.f = open(self.filepath, "rb")  # æ‰“å¼€æ–‡ä»¶ä»¥ä¾›è¯»å–
        self.f.seek(self.seek_from)  # è®¾ç½®æ–‡ä»¶è¯»å–çš„èµ·å§‹ä½ç½®
        return self  # è¿”å› FileSlice å¯¹è±¡æœ¬èº«ä½œä¸ºä¸Šä¸‹æ–‡ç®¡ç†å™¨

    def __len__(self):
        total_length = os.fstat(self.f.fileno()).st_size  # è·å–æ–‡ä»¶æ€»å¤§å°
        return min(self.read_limit, total_length - self.seek_from)  # è¿”å›å®é™…å¯è¯»å–çš„æ•°æ®é•¿åº¦

    def read(self, n=-1):
        if self.n_seen >= self.read_limit:
            return b""  # å¦‚æœå·²è¯»å–æ•°æ®è¶…å‡ºé™åˆ¶ï¼Œåˆ™è¿”å›ç©ºå­—èŠ‚ä¸²

        remaining_amount = self.read_limit - self.n_seen  # å‰©ä½™å¯è¯»å–çš„æ•°æ®é‡
        # è¯»å–æ•°æ®ï¼Œä¸è¶…è¿‡å‰©ä½™å¯è¯»å–çš„æ•°æ®é‡æˆ–æŒ‡å®šçš„ n å­—èŠ‚
        data = self.f.read(remaining_amount if n < 0 else min(n, remaining_amount))
        self.n_seen += len(data)  # æ›´æ–°å·²è¯»å–çš„å­—èŠ‚æ•°
        return data  # è¿”å›è¯»å–çš„æ•°æ®

    def __iter__(self):
        yield self.read(n=4 * 1024 * 1024)  # ä»¥è¿­ä»£å™¨æ–¹å¼è¿”å›æ¯æ¬¡æœ€å¤š 4MB çš„æ•°æ®

    def __exit__(self, *args):
        self.f.close()  # å…³é—­æ–‡ä»¶

# LFS ä¸Šä¼ å‘½ä»¤ç±»ï¼Œåˆå§‹åŒ–æ—¶æ¥æ”¶å‚æ•°
class LfsUploadCommand:
    def __init__(self, args):
        self.args = args  # åˆå§‹åŒ– LFS ä¸Šä¼ å‘½ä»¤çš„å‚æ•°
    def run(self):
        # ç«‹å³åœ¨è°ƒç”¨è‡ªå®šä¹‰ä¼ è¾“è¿‡ç¨‹åï¼Œgit-lfsé€šè¿‡æ ‡å‡†è¾“å…¥å‘é€åˆå§‹åŒ–æ•°æ®åˆ°è¿›ç¨‹ä¸­ã€‚
        # è¿™å‘è¿›ç¨‹æä¾›äº†å…³äºé…ç½®çš„æœ‰ç”¨ä¿¡æ¯ã€‚
        init_msg = json.loads(sys.stdin.readline().strip())
        # å¦‚æœåˆå§‹åŒ–æ¶ˆæ¯ä¸æ˜¯"init"äº‹ä»¶ä¸”æ“ä½œä¸æ˜¯"upload"ï¼Œåˆ™å†™å…¥é”™è¯¯æ¶ˆæ¯å¹¶é€€å‡ºç¨‹åºã€‚
        if not (init_msg.get("event") == "init" and init_msg.get("operation") == "upload"):
            write_msg({"error": {"code": 32, "message": "Wrong lfs init operation"}})
            sys.exit(1)

        # ä¼ è¾“è¿‡ç¨‹åº”ä½¿ç”¨åˆå§‹åŒ–ç»“æ„ä¸­çš„ä¿¡æ¯ï¼Œå¹¶æ‰§è¡Œä»»ä½•ä¸€æ¬¡æ€§è®¾ç½®ä»»åŠ¡ã€‚
        # ç„¶åé€šè¿‡æ ‡å‡†è¾“å‡ºå“åº”ä¸€ä¸ªç®€å•çš„ç©ºç¡®è®¤ç»“æ„ã€‚
        write_msg({})

        # åˆå§‹åŒ–äº¤æ¢åï¼Œgit-lfså°†æŒ‰åºåˆ—å‘é€ä»»æ„æ•°é‡çš„ä¼ è¾“è¯·æ±‚åˆ°ä¼ è¾“è¿›ç¨‹çš„æ ‡å‡†è¾“å…¥ã€‚
        while True:
            msg = read_msg()
            if msg is None:
                # å½“æ‰€æœ‰ä¼ è¾“éƒ½å·²å¤„ç†å®Œæ¯•æ—¶ï¼Œgit-lfså°†å‘ä¼ è¾“è¿›ç¨‹çš„æ ‡å‡†è¾“å…¥å‘é€ç»ˆæ­¢äº‹ä»¶ã€‚
                # æ”¶åˆ°æ­¤æ¶ˆæ¯åï¼Œä¼ è¾“è¿›ç¨‹åº”æ¸…ç†å¹¶ç»ˆæ­¢ã€‚ä¸éœ€è¦å“åº”ã€‚
                sys.exit(0)

            oid = msg["oid"]
            filepath = msg["path"]
            completion_url = msg["action"]["href"]
            header = msg["action"]["header"]
            chunk_size = int(header.pop("chunk_size"))
            presigned_urls: List[str] = list(header.values())

            parts = []
            for i, presigned_url in enumerate(presigned_urls):
                # ä½¿ç”¨FileSliceä»æ–‡ä»¶ä¸­è¯»å–æ•°æ®ç‰‡æ®µï¼Œæ ¹æ®chunk_sizeå’Œåç§»é‡è¿›è¡Œè¯»å–ã€‚
                with FileSlice(filepath, seek_from=i * chunk_size, read_limit=chunk_size) as data:
                    # å‘é€PUTè¯·æ±‚ä¸Šä¼ æ•°æ®ç‰‡æ®µåˆ°é¢„ç­¾åçš„URLã€‚
                    r = requests.put(presigned_url, data=data)
                    r.raise_for_status()
                    # æ·»åŠ ä¸Šä¼ ç‰‡æ®µçš„ETagå’Œåºå·åˆ°partsåˆ—è¡¨ã€‚
                    parts.append(
                        {
                            "etag": r.headers.get("etag"),
                            "partNumber": i + 1,
                        }
                    )
                    # ä¸ºäº†æ”¯æŒæ•°æ®ä¸Šä¼ /ä¸‹è½½è¿‡ç¨‹ä¸­çš„è¿›åº¦æŠ¥å‘Šï¼Œ
                    # ä¼ è¾“è¿›ç¨‹åº”å‘æ ‡å‡†è¾“å‡ºå‘é€æ¶ˆæ¯ã€‚
                    write_msg(
                        {
                            "event": "progress",
                            "oid": oid,
                            "bytesSoFar": (i + 1) * chunk_size,
                            "bytesSinceLast": chunk_size,
                        }
                    )
                    # ä¸æ˜¯ç²¾ç¡®çš„è¿›åº¦æŠ¥å‘Šï¼Œä½†å¯ä»¥æ¥å—ã€‚

            # å‘é€åŒ…å«oidå’Œå·²ä¸Šä¼ éƒ¨åˆ†ä¿¡æ¯çš„POSTè¯·æ±‚åˆ°å®ŒæˆURLã€‚
            r = requests.post(
                completion_url,
                json={
                    "oid": oid,
                    "parts": parts,
                },
            )
            r.raise_for_status()

            # å‘é€å®Œæˆäº‹ä»¶åˆ°æ ‡å‡†è¾“å‡ºã€‚
            write_msg({"event": "complete", "oid": oid})
```