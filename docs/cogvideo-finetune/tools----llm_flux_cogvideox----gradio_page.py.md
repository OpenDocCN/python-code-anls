# `.\cogvideo-finetune\tools\llm_flux_cogvideox\gradio_page.py`

```
# å¯¼å…¥æ“ä½œç³»ç»Ÿæ¨¡å—
import os
# å¯¼å…¥ Gradio åº“ï¼Œç”¨äºæ„å»ºç”¨æˆ·ç•Œé¢
import gradio as gr
# å¯¼å…¥åƒåœ¾å›æ”¶æ¨¡å—
import gc
# å¯¼å…¥éšæœºæ•°ç”Ÿæˆæ¨¡å—
import random
# å¯¼å…¥ PyTorch åº“
import torch
# å¯¼å…¥ NumPy åº“
import numpy as np
# å¯¼å…¥å›¾åƒå¤„ç†åº“
from PIL import Image
# å¯¼å…¥ Transformers åº“
import transformers
# ä» Diffusers åº“å¯¼å…¥è§†é¢‘ç”Ÿæˆç›¸å…³çš„ç±»
from diffusers import CogVideoXImageToVideoPipeline, CogVideoXDPMScheduler, DiffusionPipeline
# ä» Diffusers åº“å¯¼å…¥å¯¼å‡ºè§†é¢‘çš„å·¥å…·
from diffusers.utils import export_to_video
# ä» Transformers åº“å¯¼å…¥è‡ªåŠ¨åˆ†è¯å™¨
from transformers import AutoTokenizer
# å¯¼å…¥æ—¥æœŸå’Œæ—¶é—´å¤„ç†æ¨¡å—
from datetime import datetime, timedelta
# å¯¼å…¥å¤šçº¿ç¨‹æ¨¡å—
import threading
# å¯¼å…¥æ—¶é—´æ¨¡å—
import time
# å¯¼å…¥ MoviePy åº“è¿›è¡Œè§†é¢‘ç¼–è¾‘
import moviepy.editor as mp

# è®¾ç½®æµ®ç‚¹æ•°çŸ©é˜µä¹˜æ³•çš„ç²¾åº¦ä¸ºé«˜
torch.set_float32_matmul_precision("high")

# è®¾ç½®é»˜è®¤å€¼
caption_generator_model_id = "/share/home/zyx/Models/Meta-Llama-3.1-8B-Instruct"  # ç”Ÿæˆè§†é¢‘æè¿°çš„æ¨¡å‹è·¯å¾„
image_generator_model_id = "/share/home/zyx/Models/FLUX.1-dev"  # ç”Ÿæˆå›¾åƒçš„æ¨¡å‹è·¯å¾„
video_generator_model_id = "/share/official_pretrains/hf_home/CogVideoX-5b-I2V"  # ç”Ÿæˆè§†é¢‘çš„æ¨¡å‹è·¯å¾„
seed = 1337  # éšæœºæ•°ç§å­

# åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œè‹¥å·²å­˜åœ¨åˆ™ä¸æŠ¥é”™
os.makedirs("./output", exist_ok=True)
# åˆ›å»ºä¸´æ—¶ç›®å½•ï¼Œç”¨äº Gradio
os.makedirs("./gradio_tmp", exist_ok=True)

# ä»æŒ‡å®šæ¨¡å‹åŠ è½½è‡ªåŠ¨åˆ†è¯å™¨
tokenizer = AutoTokenizer.from_pretrained(caption_generator_model_id, trust_remote_code=True)
# åˆ›å»ºæ–‡æœ¬ç”Ÿæˆç®¡é“ï¼Œç”¨äºç”Ÿæˆè§†é¢‘æè¿°
caption_generator = transformers.pipeline(
    "text-generation",  # æŒ‡å®šä»»åŠ¡ä¸ºæ–‡æœ¬ç”Ÿæˆ
    model=caption_generator_model_id,  # æŒ‡å®šæ¨¡å‹
    device_map="balanced",  # è®¾ç½®è®¾å¤‡æ˜ å°„ä¸ºå¹³è¡¡æ¨¡å¼
    model_kwargs={  # æ¨¡å‹å‚æ•°
        "local_files_only": True,  # ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
        "torch_dtype": torch.bfloat16,  # è®¾ç½®å¼ é‡æ•°æ®ç±»å‹
    },
    trust_remote_code=True,  # å…è®¸ä½¿ç”¨è¿œç¨‹ä»£ç 
    tokenizer=tokenizer  # ä½¿ç”¨åŠ è½½çš„åˆ†è¯å™¨
)

# ä»æŒ‡å®šæ¨¡å‹åŠ è½½å›¾åƒç”Ÿæˆç®¡é“
image_generator = DiffusionPipeline.from_pretrained(
    image_generator_model_id,  # æŒ‡å®šå›¾åƒç”Ÿæˆæ¨¡å‹
    torch_dtype=torch.bfloat16,  # è®¾ç½®å¼ é‡æ•°æ®ç±»å‹
    device_map="balanced"  # è®¾ç½®è®¾å¤‡æ˜ å°„ä¸ºå¹³è¡¡æ¨¡å¼
)
# image_generator.to("cuda")  # å¯é€‰æ‹©å°†ç”Ÿæˆå™¨ç§»åŠ¨åˆ° GPUï¼ˆè¢«æ³¨é‡Šæ‰ï¼‰

# ä»æŒ‡å®šæ¨¡å‹åŠ è½½è§†é¢‘ç”Ÿæˆç®¡é“
video_generator = CogVideoXImageToVideoPipeline.from_pretrained(
    video_generator_model_id,  # æŒ‡å®šè§†é¢‘ç”Ÿæˆæ¨¡å‹
    torch_dtype=torch.bfloat16,  # è®¾ç½®å¼ é‡æ•°æ®ç±»å‹
    device_map="balanced"  # è®¾ç½®è®¾å¤‡æ˜ å°„ä¸ºå¹³è¡¡æ¨¡å¼
)

# å¯ç”¨è§†é¢‘ç”Ÿæˆå™¨çš„ VAE åˆ‡ç‰‡åŠŸèƒ½
video_generator.vae.enable_slicing()
# å¯ç”¨è§†é¢‘ç”Ÿæˆå™¨çš„ VAE å¹³é“ºåŠŸèƒ½
video_generator.vae.enable_tiling()

# è®¾ç½®è§†é¢‘ç”Ÿæˆå™¨çš„è°ƒåº¦å™¨ï¼Œä½¿ç”¨è‡ªå®šä¹‰é…ç½®
video_generator.scheduler = CogVideoXDPMScheduler.from_config(
    video_generator.scheduler.config, timestep_spacing="trailing"  # è®¾ç½®æ—¶é—´æ­¥é•¿ä¸ºåç»­æ¨¡å¼
)

# å®šä¹‰ç³»ç»Ÿæç¤º
SYSTEM_PROMPT = """
# ç³»ç»Ÿæç¤ºå†…å®¹ï¼Œè¯´æ˜è§†é¢‘ç”Ÿæˆä»»åŠ¡å’Œè§„åˆ™
You are part of a team of people that create videos using generative models. You use a video-generation model that can generate a video about anything you describe.

For example, if you respond with "A beautiful morning in the woods with the sun peaking through the trees", the video generation model will create a video of exactly as described. Your task is to summarize the descriptions of videos provided by users and create detailed prompts to feed into the generative model.

There are a few rules to follow:
- You will only ever output a single video description per request.
- If the user mentions to summarize the prompt in [X] words, make sure not to exceed the limit.

Your responses should just be the video generation prompt. Here are examples:
# å®šä¹‰åŒ…å«è¯¦ç»†æè¿°çš„å­—ç¬¦ä¸²ï¼Œæè¿°ç©å…·èˆ¹åœ¨è“è‰²åœ°æ¯¯ä¸Šçš„åœºæ™¯
- "A detailed wooden toy ship with intricately carved masts and sails is seen gliding smoothly over a plush, blue carpet that mimics the waves of the sea. The ship's hull is painted a rich brown, with tiny windows. The carpet, soft and textured, provides a perfect backdrop, resembling an oceanic expanse. Surrounding the ship are various other toys and children's items, hinting at a playful environment. The scene captures the innocence and imagination of childhood, with the toy ship's journey symbolizing endless adventures in a whimsical, indoor setting."
# å®šä¹‰åŒ…å«è¡—å¤´è‰ºæœ¯å®¶çš„å­—ç¬¦ä¸²ï¼Œæè¿°å…¶åœ¨åŸå¸‚å¢™å£ä¸Šå–·æ¶‚çš„æƒ…æ™¯
- "A street artist, clad in a worn-out denim jacket and a colorful bandana, stands before a vast concrete wall in the heart of the city, holding a can of spray paint, spray-painting a colorful bird on a mottled wall."
# å»é™¤å¤šä½™çš„ç©ºæ ¼å¹¶ä¿å­˜ä¸ºç”¨æˆ·æç¤º
""".strip()

# å®šä¹‰ç”¨æˆ·æç¤ºæ¨¡æ¿ï¼Œç”¨äºç”Ÿæˆè§†é¢‘ç”Ÿæˆæ¨¡å‹çš„æç¤º
USER_PROMPT = """
Could you generate a prompt for a video generation model? Please limit the prompt to [{0}] words.
""".strip()

# å®šä¹‰ç”Ÿæˆå­—å¹•çš„å‡½æ•°ï¼Œæ¥å—ä¸€ä¸ªæç¤ºå‚æ•°
def generate_caption(prompt):
    # éšæœºé€‰æ‹©å­—æ•°ï¼ˆ25ã€50ã€75æˆ–100ï¼‰ä»¥é™åˆ¶ç”Ÿæˆçš„å­—å¹•é•¿åº¦
    num_words = random.choice([25, 50, 75, 100])
    # æ ¼å¼åŒ–ç”¨æˆ·æç¤ºï¼Œå°†éšæœºå­—æ•°æ’å…¥æç¤ºæ¨¡æ¿ä¸­
    user_prompt = USER_PROMPT.format(num_words)

    # åˆ›å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç³»ç»Ÿè§’è‰²å’Œç”¨æˆ·è§’è‰²çš„å†…å®¹
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": prompt + "\n" + user_prompt},
    ]

    # è°ƒç”¨å­—å¹•ç”Ÿæˆå™¨ç”Ÿæˆå­—å¹•ï¼ŒæŒ‡å®šæœ€å¤§æ–°ä»¤ç‰Œæ•°å’Œæ˜¯å¦è¿”å›å®Œæ•´æ–‡æœ¬
    response = caption_generator(
        messages,
        max_new_tokens=226,
        return_full_text=False
    )
    # è·å–ç”Ÿæˆçš„å­—å¹•æ–‡æœ¬
    caption = response[0]["generated_text"]
    # å¦‚æœå­—å¹•ä»¥åŒå¼•å·å¼€å¤´å’Œç»“å°¾ï¼Œå»æ‰è¿™ä¸¤ä¸ªå¼•å·
    if caption.startswith("\"") and caption.endswith("\""):
        caption = caption[1:-1]
    # è¿”å›ç”Ÿæˆçš„å­—å¹•
    return caption

# å®šä¹‰ç”Ÿæˆå›¾åƒçš„å‡½æ•°ï¼Œæ¥å—å­—å¹•å’Œè¿›åº¦å‚æ•°
def generate_image(caption, progress=gr.Progress(track_tqdm=True)):
    # è°ƒç”¨å›¾åƒç”Ÿæˆå™¨ç”Ÿæˆå›¾åƒï¼ŒæŒ‡å®šç›¸å…³å‚æ•°
    image = image_generator(
        prompt=caption,
        height=480,
        width=720,
        num_inference_steps=30,
        guidance_scale=3.5,
    ).images[0]
    # è¿”å›ç”Ÿæˆçš„å›¾åƒï¼Œé‡å¤ä¸€æ¬¡ä»¥ä¾¿äºåç»­å¤„ç†
    return image, image  # One for output One for State

# å®šä¹‰ç”Ÿæˆè§†é¢‘çš„å‡½æ•°ï¼Œæ¥å—å­—å¹•ã€å›¾åƒå’Œè¿›åº¦å‚æ•°
def generate_video(
        caption,
        image,
        progress=gr.Progress(track_tqdm=True)
):
    # åˆ›å»ºä¸€ä¸ªéšæœºç§å­ç”Ÿæˆå™¨
    generator = torch.Generator().manual_seed(seed)
    # è°ƒç”¨è§†é¢‘ç”Ÿæˆå™¨ç”Ÿæˆè§†é¢‘å¸§ï¼ŒæŒ‡å®šç›¸å…³å‚æ•°
    video_frames = video_generator(
        image=image,
        prompt=caption,
        height=480,
        width=720,
        num_frames=49,
        num_inference_steps=50,
        guidance_scale=6,
        use_dynamic_cfg=True,
        generator=generator,
    ).frames[0]
    # ä¿å­˜ç”Ÿæˆçš„è§†é¢‘å¹¶è·å–è§†é¢‘è·¯å¾„
    video_path = save_video(video_frames)
    # å°†è§†é¢‘è½¬æ¢ä¸º GIF å¹¶è·å– GIF è·¯å¾„
    gif_path = convert_to_gif(video_path)
    # è¿”å›è§†é¢‘è·¯å¾„å’Œ GIF è·¯å¾„
    return video_path, gif_path

# å®šä¹‰ä¿å­˜è§†é¢‘çš„å‡½æ•°ï¼Œæ¥å—å¼ é‡ä½œä¸ºå‚æ•°
def save_video(tensor):
    # è·å–å½“å‰æ—¶é—´æˆ³ä»¥å‘½åè§†é¢‘æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    # åˆ›å»ºè§†é¢‘æ–‡ä»¶è·¯å¾„
    video_path = f"./output/{timestamp}.mp4"
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(os.path.dirname(video_path), exist_ok=True)
    # å¯¼å‡ºå¼ é‡ä¸ºè§†é¢‘æ–‡ä»¶ï¼ŒæŒ‡å®šå¸§ç‡
    export_to_video(tensor, video_path, fps=8)
    # è¿”å›è§†é¢‘æ–‡ä»¶è·¯å¾„
    return video_path

# å®šä¹‰å°†è§†é¢‘è½¬æ¢ä¸º GIF çš„å‡½æ•°ï¼Œæ¥å—è§†é¢‘è·¯å¾„ä½œä¸ºå‚æ•°
def convert_to_gif(video_path):
    # åŠ è½½è§†é¢‘æ–‡ä»¶
    clip = mp.VideoFileClip(video_path)
    # è®¾ç½®è§†é¢‘çš„å¸§ç‡
    clip = clip.set_fps(8)
    # è°ƒæ•´è§†é¢‘çš„é«˜åº¦ä»¥è¿›è¡Œ GIF è¾“å‡º
    clip = clip.resize(height=240)
    # åˆ›å»º GIF æ–‡ä»¶è·¯å¾„
    gif_path = video_path.replace(".mp4", ".gif")
    # å°†è§†é¢‘å†™å…¥ GIF æ–‡ä»¶ï¼ŒæŒ‡å®šå¸§ç‡
    clip.write_gif(gif_path, fps=8)
    # è¿”å› GIF æ–‡ä»¶è·¯å¾„
    return gif_path

# å®šä¹‰åˆ é™¤æ—§æ–‡ä»¶çš„å‡½æ•°ï¼ŒåŠŸèƒ½å°šæœªå®ç°
def delete_old_files():
    # æ— é™å¾ªç¯ï¼ŒæŒç»­æ‰§è¡Œæ–‡ä»¶æ¸…ç†æ“ä½œ
        while True:
            # è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´
            now = datetime.now()
            # è®¡ç®—æˆªæ­¢æ—¶é—´ï¼Œå½“å‰æ—¶é—´å‡å»10åˆ†é’Ÿ
            cutoff = now - timedelta(minutes=10)
            # å®šä¹‰è¦æ¸…ç†çš„ç›®å½•åˆ—è¡¨
            directories = ["./output", "./gradio_tmp"]
    
            # éå†ç›®å½•åˆ—è¡¨
            for directory in directories:
                # éå†å½“å‰ç›®å½•ä¸­çš„æ–‡ä»¶å
                for filename in os.listdir(directory):
                    # æ„é€ æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
                    file_path = os.path.join(directory, filename)
                    # æ£€æŸ¥è·¯å¾„æ˜¯å¦ä¸ºæ–‡ä»¶
                    if os.path.isfile(file_path):
                        # è·å–æ–‡ä»¶çš„æœ€åä¿®æ”¹æ—¶é—´
                        file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                        # å¦‚æœæ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´æ—©äºæˆªæ­¢æ—¶é—´ï¼Œåˆ é™¤è¯¥æ–‡ä»¶
                        if file_mtime < cutoff:
                            os.remove(file_path)
            # æš‚åœ600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰ï¼Œç„¶åç»§ç»­å¾ªç¯
            time.sleep(600)
# å¯åŠ¨ä¸€ä¸ªæ–°çº¿ç¨‹æ¥åˆ é™¤æ—§æ–‡ä»¶ï¼Œè®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹ä»¥ä¾¿ä¸»ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸ
threading.Thread(target=delete_old_files, daemon=True).start()

# åˆ›å»ºä¸€ä¸ª Gradio åº”ç”¨ç¨‹åºçš„ç•Œé¢
with gr.Blocks() as demo:
    # æ·»åŠ ä¸€ä¸ª Markdown ç»„ä»¶ï¼Œæ˜¾ç¤ºæ ‡é¢˜
    gr.Markdown("""
           <div style="text-align: center; font-size: 32px; font-weight: bold; margin-bottom: 20px;">
               LLM + FLUX + CogVideoX-I2V Space ğŸ¤—
            </div>
    """)
    # åˆ›å»ºä¸€ä¸ªè¡Œå¸ƒå±€ä»¥æ’åˆ—ç»„ä»¶
    with gr.Row():
        # åˆ›å»ºç¬¬ä¸€åˆ—å¸ƒå±€
        with gr.Column():
            # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç”¨äºè¾“å…¥æç¤º
            prompt = gr.Textbox(label="Prompt", placeholder="Enter your prompt here", lines=5)
            # åˆ›å»ºä¸€ä¸ªæŒ‰é’®ç”¨äºç”Ÿæˆå­—å¹•
            generate_caption_button = gr.Button("Generate Caption")
            # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç”¨äºæ˜¾ç¤ºç”Ÿæˆçš„å­—å¹•
            caption = gr.Textbox(label="Caption", placeholder="Caption will appear here", lines=5)
            # åˆ›å»ºä¸€ä¸ªæŒ‰é’®ç”¨äºç”Ÿæˆå›¾åƒ
            generate_image_button = gr.Button("Generate Image")
            # åˆ›å»ºä¸€ä¸ªå›¾åƒç»„ä»¶ç”¨äºæ˜¾ç¤ºç”Ÿæˆçš„å›¾åƒ
            image_output = gr.Image(label="Generated Image")
            # åˆ›å»ºä¸€ä¸ªçŠ¶æ€ç»„ä»¶ï¼Œç”¨äºä¿å­˜å›¾åƒçŠ¶æ€
            state_image = gr.State()
            # è®¾ç½®ç”Ÿæˆå­—å¹•æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨ç”Ÿæˆå­—å¹•å‡½æ•°
            generate_caption_button.click(fn=generate_caption, inputs=prompt, outputs=caption)
            # è®¾ç½®ç”Ÿæˆå›¾åƒæŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨ç”Ÿæˆå›¾åƒå‡½æ•°
            generate_image_button.click(fn=generate_image, inputs=caption, outputs=[image_output, state_image])
        # åˆ›å»ºç¬¬äºŒåˆ—å¸ƒå±€
        with gr.Column():
            # åˆ›å»ºä¸€ä¸ªè§†é¢‘ç»„ä»¶ç”¨äºæ˜¾ç¤ºç”Ÿæˆçš„è§†é¢‘
            video_output = gr.Video(label="Generated Video", width=720, height=480)
            # åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ç»„ä»¶ç”¨äºä¸‹è½½è§†é¢‘ï¼Œåˆå§‹è®¾ç½®ä¸ºä¸å¯è§
            download_video_button = gr.File(label="ğŸ“¥ Download Video", visible=False)
            # åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ç»„ä»¶ç”¨äºä¸‹è½½ GIFï¼Œåˆå§‹è®¾ç½®ä¸ºä¸å¯è§
            download_gif_button = gr.File(label="ğŸ“¥ Download GIF", visible=False)
            # åˆ›å»ºä¸€ä¸ªæŒ‰é’®ç”¨äºä»å›¾åƒç”Ÿæˆè§†é¢‘
            generate_video_button = gr.Button("Generate Video from Image")
            # è®¾ç½®ç”Ÿæˆè§†é¢‘æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨ç”Ÿæˆè§†é¢‘å‡½æ•°
            generate_video_button.click(fn=generate_video, inputs=[caption, state_image],
                                        outputs=[video_output, download_gif_button])

# å¦‚æœå½“å‰æ¨¡å—æ˜¯ä¸»ç¨‹åºï¼Œåˆ™å¯åŠ¨ Gradio åº”ç”¨ç¨‹åº
if __name__ == "__main__":
    demo.launch()
```