<!--yml
category: æ¸¸æˆ
date: 2023-09-17 14:44:22
-->

# YOLOv5-6.xæºç åˆ†æï¼ˆä¸ƒï¼‰---- æ•°æ®å¢å¼ºä¹‹augmentations.py

> æ¥æºï¼š[https://blog.csdn.net/weixin_51322383/article/details/130409656](https://blog.csdn.net/weixin_51322383/article/details/130409656)

### æ–‡ç« ç›®å½•

*   [å‰è¨€](#_1)
*   [ğŸš€YOLOv5-6.xæºç åˆ†æï¼ˆä¸ƒï¼‰---- æ•°æ®å¢å¼ºä¹‹augmentations.py](#YOLOv56x_augmentationspy_11)
*   *   [1\. å¯¼åŒ…](#1__24)
    *   [2\. è‡ªå®šä¹‰Albumentations](#2__Albumentations_43)
    *   [3\. å½’ä¸€åŒ–å’Œåè§„èŒƒåŒ–](#3__90)
    *   [4\. hsv è‰²è°ƒ-é¥±å’Œåº¦-äº®åº¦çš„å›¾åƒå¢å¼º](#4_hsv__110)
    *   [5\. ç›´æ–¹å›¾å‡è¡¡åŒ–å¢å¼º](#5__133)
    *   [6\. å›¾åƒæ¡†çš„å¹³ç§»å¤åˆ¶å¢å¼º](#6__153)
    *   [7\. å›¾ç‰‡ç¼©æ”¾letterbox](#7_letterbox_173)
    *   [8\. éšæœºé€è§†å˜æ¢](#8__220)
    *   [9\. cutout](#9_cutout_343)
    *   [10\. mixup](#10_mixup_385)
    *   [11\. box_candidates](#11_box_candidates_400)
    *   [æ€»ç»“](#_413)

# å‰è¨€

**ä»Šå¤©ä¸Šåˆåˆšå›å—å±±æœ¬æ ¡åŠäº†ç‚¹äº‹æƒ…ï¼Œæ¥å›ä¸€è¶Ÿå°±èŠ±äº†æ•´æ•´ä¸€ä¸Šåˆï¼Œå¤ªç´¯äº†ï¼Œå›åˆ°å®éªŒå®¤å°±æˆ´ä¸Šçœ¼ç½©ç¡äº†åå‡ åˆ†é’Ÿã€‚åˆšåˆšä¸Šè¾…å¯¼å‘˜çš„èŒè§„è¯¾ï¼Œå¥¹è®²çš„ä¸€äº›ä¸œè¥¿ï¼Œæˆ‘ä¹Ÿä¸çŸ¥é“ç®—ä¸ç®—æœ‰ç”¨å§ï¼Œæ— éå°±æ˜¯ä¸€äº›ä¼ä¸šèµ°è®¿ï¼Œæˆ‘æ„Ÿè§‰æ²¡å¤šå°‘ç”¨å¤„ï¼Œä¸‹é¢çš„åŒå­¦ä¹Ÿæ²¡å‡ ä¸ªå¬çš„ã€‚åŒ…æ‹¬ä¸Šå‘¨å­¦é™¢å¸¦æˆ‘ä»¬ç­å»å‚è§‚å…¬å¸ä¹Ÿæ˜¯ï¼Œæˆ‘è§‰å¾—çœŸæ˜¯çº¯ç²¹æµªè´¹æ—¶é—´ï¼Œæ¯æ¬¡ä¸€å»å°±æ˜¯ä»‹ç»å…¬å¸æ–‡åŒ–ï¼Œæ„Ÿè§‰å­¦ç”Ÿå»å°±æ˜¯å‡‘æ•°çš„ã€‚åè§‚ï¼Œæˆ‘æ„Ÿè§‰ç°åœ¨å¤§å­¦é‡Œé¢æœ‰ç”¨çš„è¯¾çœŸçš„å¤ªå°‘äº†ï¼Œå°±æ‹¿æ±‚èŒè¿™æ–¹é¢æ¥è¯´ï¼Œå¤§å­¦é‡Œé¢æ ¹æœ¬æ²¡æœ‰æ•™ä½ å¦‚ä½•ç­¾åˆåŒï¼Œè€Œè¿™äº›æ‰æ˜¯æˆ‘ä»¬å¤§å­¦ç”Ÿæœ€è¯¥ä¸Šçš„ä¹Ÿæœ€è¯¥å­¦çš„ä¸€äº›æŠ€èƒ½ï¼Œè¿™ä¹ˆé‡è¦çš„ä¸œè¥¿å±…ç„¶ä»…ä»…æƒ³é€šè¿‡ä¸€èŠ‚è¯¾å°±ç»™æˆ‘ä»¬è®²æ¸…æ¥šï¼›åŒ…æ‹¬æˆ‘ä»¬å¦‚æœé‡åˆ°ä¸€äº›åŠ³åŠ¡çº çº·å¦‚ä½•è§£å†³ï¼Œè¿™äº›éƒ½æ²¡æœ‰ã€‚åå€’ä»å¤§ä¸€å¼€å§‹çš„æ€æ”¿è¯¾ï¼Œå°±æœ‰3~4å­¦åˆ†ï¼Œè€Œå¤§ä¸€ä¸€é—¨Cè¯­è¨€ä¸“ä¸šè¯¾æ‰åªæœ‰3åˆ†ã€‚ä»Šå¤©è·ŸåŒå­¦è°ˆåˆ°ï¼Œå¤§å­¦æ•™ä¼šæˆ‘ä»¬çš„å”¯ä¸€ä¸œè¥¿å°±æ˜¯å‘Šè¯‰æˆ‘ä»¬ä»€ä¹ˆä¸œè¥¿éƒ½å¾—è¦è‡ªå­¦ï¼Œå­¦æ ¡é‡Œæ ¹æœ¬æ•™ä¸äº†ä»€ä¹ˆä¸œè¥¿ã€‚è¿™æˆ–è®¸ä¹Ÿæ˜¯æˆ‘é€‰æ‹©è¦å‡å­¦çš„ç›®çš„ï¼Œä¸€æ–¹é¢æ˜¯å¦‚ä»Šè¡Œæƒ…å¤ªå·®äº†ï¼Œ å¦ä¸€æ–¹é¢æˆ‘ä¹Ÿæƒ³é€šè¿‡è‡ªå·±å¤šèŠ±ç‚¹æ—¶é—´å¤šå­¦ç‚¹çŸ¥è¯†ï¼Œå¹¶ä¸”å…ˆå¤šæ¥è§¦ä¸‹ç¤¾ä¼šï¼Œä»¥å…åˆ°æ—¶å€™ä¸€è¿›å…¥ç¤¾ä¼šå°±è¢«ç°å®æ•²å¾—ç²‰ç¢ã€‚**

* * *

**è¯´å›ä¸»é¢˜ï¼Œä»Šå¤©å‡†å¤‡å‰–æçš„æ˜¯æ•°æ®å¢å¼ºéƒ¨åˆ†ã€‚**

**æˆ‘ä»¬çŸ¥é“ï¼Œè¦å®Œæˆå¾ˆå¤šå®é™…çš„é¡¹ç›®ï¼Œæˆ‘ä»¬éƒ½è¦å……è¶³çš„æ•°æ®æ¥å®Œæˆä»»åŠ¡ï¼Œè¿™æ ·æ‰èƒ½é€‚åº”å¤šåœºæ™¯çš„ä»»åŠ¡ã€‚ä½†æ˜¯æˆ‘ä»¬çš„ç›®æ ‡åº”ç”¨å¯èƒ½å­˜åœ¨äºä¸åŒçš„æ¡ä»¶ï¼Œæ¯”å¦‚åœ¨ä¸åŒçš„æ–¹å‘ã€ä½ç½®ã€ç¼©æ”¾æ¯”ä¾‹ã€äº®åº¦ç­‰ã€‚è€Œå•é è‡ªå·±å¯»æ‰¾æ•°æ®è¿œè¿œä¸å¤Ÿï¼Œè¿™ä¸ªæ—¶å€™å°±éœ€è¦æ•°æ®å¢å¼ºã€‚å…¶å®å°±æ˜¯å°†æ•°æ®ï¼Œé€šè¿‡é¢å¤–åˆæˆçš„æ•°æ®æ¥è®­ç»ƒç¥ç»ç½‘ç»œæ¥è§£é‡Šè¿™äº›æƒ…å†µã€‚**

**ä»€ä¹ˆæ˜¯æ•°æ®å¢å¼ºå‘¢ï¼Ÿæ•°æ®å¢å¼ºä¹Ÿå«æ•°æ®æ‰©å¢ï¼Œæ„æ€æ˜¯åœ¨ä¸å®è´¨æ€§çš„å¢åŠ æ•°æ®çš„æƒ…å†µä¸‹ï¼Œè®©æœ‰é™çš„æ•°æ®äº§ç”Ÿç­‰ä»·äºæ›´å¤šæ•°æ®çš„ä»·å€¼ã€‚æ•°æ®å¢å¼ºæœ‰å¾ˆå¤šç§æ–¹æ³•ï¼ŒYOLOv5ä¸­å°±æœ‰åå‡ ç§ï¼Œä¸‹é¢æˆ‘ä¼šä»‹ç»ç”¨å¾—æ¯”è¾ƒå¤šçš„ï¼Œletâ€™s get it~**

# ğŸš€YOLOv5-6.xæºç åˆ†æï¼ˆä¸ƒï¼‰---- æ•°æ®å¢å¼ºä¹‹augmentations.py

æ€»çš„æ¥è¯´ï¼ŒYOLOv5-6.1æ¶‰åŠåˆ°çš„æ•°æ®å¢å¼ºæ–¹æ³•ä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ï¼š

*   å¯¹åŸå›¾åšæ•°æ®å¢å¼º
    *   åƒç´ çº§ï¼šHSVå¢å¼ºã€æ—‹è½¬ã€ç¼©æ”¾ã€å¹³ç§»ã€å‰ªåˆ‡ã€é€è§†ã€ç¿»è½¬ç­‰
    *   å›¾ç‰‡çº§ï¼šMixUpã€Cutoutã€CutMixã€Mosaicã€Copy-Paste(Segment)ç­‰
*   å¯¹æ ‡ç­¾åšåŒæ ·çš„å¢å¼º
    *   å˜æ¢åçš„åæ ‡åç§»é‡
    *   é˜²æ­¢æ ‡ç­¾åæ ‡è¶Šç•Œ

å¯¼èˆªï¼š[YOLOv5-6.xæºç åˆ†æ å…¨æµç¨‹è®°å½•](https://blog.csdn.net/weixin_51322383/article/details/130353834?spm=1001.2014.3001.5502)

* * *

## 1\. å¯¼åŒ…

```py
import math
import random

import cv2
import numpy as np
import torch
import torchvision.transforms as T  # å›¾åƒé¢„å¤„ç†å·¥å…·åŒ…
import torchvision.transforms.functional as TF  # å›¾åƒå˜æ¢çš„å‡½æ•°åº“

from utils.general import LOGGER, check_version, colorstr, resample_segments, segment2box, xywhn2xyxy   # å¸¸ç”¨å·¥å…·å‡½æ•°
from utils.metrics import bbox_ioa  # è®¡ç®—IoUä¸box2é¢ç§¯çš„æ¯”å€¼

IMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean RGBå‡å€¼
IMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation RGBæ ‡å‡†åå·® 
```

## 2\. è‡ªå®šä¹‰Albumentations

```py
class Albumentations:
    # YOLOv5 Albumentations class (optional, only used if package is installed)
    def __init__(self, size=640):
        self.transform = None
        prefix = colorstr('albumentations: ')
        try:
            import albumentations as A
            check_version(A.__version__, '1.0.3', hard=True)  # version requirement

            T = [
                A.RandomResizedCrop(height=size, width=size, scale=(0.8, 1.0), ratio=(0.9, 1.11), p=0.0),
                A.Blur(p=0.01),
                A.MedianBlur(p=0.01),
                A.ToGray(p=0.01),
                A.CLAHE(p=0.01),
                A.RandomBrightnessContrast(p=0.0),
                A.RandomGamma(p=0.0),
                A.ImageCompression(quality_lower=75, p=0.0)]  # transforms
            # A.Compose ç”¨äºå›¾åƒå¢å¼ºå’Œæ•°æ®å¢å¼º
            # https://blog.csdn.net/u014264373/article/details/114144303 æœ€å¿«æœ€å¥½ç”¨çš„æ•°æ®å¢å¼ºåº“ã€Œalbumentationsã€ ä¸€æ–‡çœ‹æ‡‚ç”¨æ³•
            # bbox_paramså‚æ•°å®šä¹‰äº†æ ¼å¼ format; label_fileds:è¡¨ç¤ºè‡ªå®šä¹‰çš„ç±»æ ‡ç­¾å˜é‡çš„åå­—ï¼Œæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå¯ä»¥æ”¾ç½®å¤šä¸ªå‚æ•°åç§°ï¼Œè¡¨ç¤ºå¤šæ ‡ç­¾ã€‚
            self.transform = A.Compose(T, bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))

            LOGGER.info(prefix + ', '.join(f'{x}'.replace('always_apply=False, ', '') for x in T if x.p))
        # å¦‚æœæ²¡æœ‰å®‰è£…ä¼šè·³è¿‡
        except ImportError:  # package not installed, skip
            pass
        except Exception as e:
            LOGGER.info(f'{prefix}{e}')

    # ç›¸å½“äºC++çš„ä»¿å‡½æ•°ï¼Œå¯ä»¥åƒå‡½æ•°ä¸€æ ·è°ƒç”¨è¯¥ç±»ï¼Œæ¥æ”¶å‚æ•°å¹¶è¿”å›å€¼
    def __call__(self, im, labels, p=1.0):
        if self.transform and random.random() < p:
            # ä¼ å…¥å›¾ç‰‡ï¼Œè·å–åˆ°æ•°æ®å¢å¼ºåçš„å›¾ç‰‡
            new = self.transform(image=im, bboxes=labels[:, 1:], class_labels=labels[:, 0])  # transformed
            im, labels = new['image'], np.array([[c, *b] for c, b in zip(new['class_labels'], new['bboxes'])])
        return im, labels 
```

**è¿™ä¸ªç±»åªä¼šåœ¨ä½ å®‰è£…äº†albumentationsè¿™ä¸ªåº“çš„æ—¶å€™ä½¿ç”¨ï¼Œå¦‚æœæ²¡æœ‰å®‰è£…çš„è¯ï¼Œä¹Ÿä¸ä¼šæŠ¥é”™,ä¸è¿‡éƒ½ç”¨torchvision.transformsé‡Œé¢çš„å†…å®¹ï¼ŒI guess**

è¿™ä¸ªç±»ä¸»è¦æ˜¯é‡æ–°å®šä¹‰äº†ä¸€ä¸‹YOLOæ ¼å¼çš„æ•°æ®å¢å¼ºï¼ŒåŠ å…¥äº†`format`ä¸ºyoloæ ¼å¼ã€‚å¹¶ä¸”è¿˜å®šä¹‰äº†`__call__`æ–¹æ³•ï¼Œè¿™ä¸ªç›¸å½“äºC++çš„ä»¿å‡½æ•°ï¼Œå¯ä»¥åƒå‡½æ•°ä¸€æ ·è°ƒç”¨è¯¥ç±»ï¼Œå®é™…ä¸Šå°±æ˜¯è¿”å›å›¾ç‰‡å’Œæ ‡ç­¾ï¼Œä¸è¿‡æ²¡åšä»€ä¹ˆæ•°æ®å¢å¼ºã€‚é‡ç‚¹æ˜¯`A.Compose`ï¼Œå®é™…ä¸Šå†…éƒ¨è¿˜æ˜¯è°ƒç”¨`albumentations`è¿™ä¸ªç±»çš„ã€‚

> å…·ä½“ä½¿ç”¨æ–¹æ³•å¯çœ‹ï¼š[æœ€å¿«æœ€å¥½ç”¨çš„æ•°æ®å¢å¼ºåº“ã€Œalbumentationsã€ ä¸€æ–‡çœ‹æ‡‚ç”¨æ³•](https://blog.csdn.net/u014264373/article/details/114144303)

## 3\. å½’ä¸€åŒ–å’Œåè§„èŒƒåŒ–

```py
# å½’ä¸€åŒ–
def normalize(x, mean=IMAGENET_MEAN, std=IMAGENET_STD, inplace=False):
    # Denormalize RGB images x per ImageNet stats in BCHW format, i.e. = (x - mean) / std
    return TF.normalize(x, mean, std, inplace=inplace)

# åè§„èŒƒåŒ–
def denormalize(x, mean=IMAGENET_MEAN, std=IMAGENET_STD):
    # Denormalize RGB images x per ImageNet stats in BCHW format, i.e. = x * std + mean
    for i in range(3):
        x[:, i] = x[:, i] * std[i] + mean[i]
    return x 
```

**å½’ä¸€åŒ–å°±æ˜¯ç›´æ¥è°ƒç”¨TFçš„å‡½æ•°ï¼Œè¾“å…¥å‚æ•°meanå‡å€¼å’Œstdæ–¹å·®ï¼Œinplace:æ˜¯å¦å°±åœ°è®¡ç®— (ç›¸å½“äºx += bå’Œy = x+b,x=yçš„åŒºåˆ«) é»˜è®¤ä¸ºFalse**

**åè§„èŒƒåŒ–å°±æ˜¯å€¼ä¹˜ä»¥æ–¹å·®å†åŠ ä¸Šå‡å€¼**

## 4\. hsv è‰²è°ƒ-é¥±å’Œåº¦-äº®åº¦çš„å›¾åƒå¢å¼º

```py
def augment_hsv(im, hgain=0.5, sgain=0.5, vgain=0.5):   # åšh-è‰²è°ƒï¼Œ s-é¥±å’Œåº¦ï¼Œ v-äº®åº¦ä¸Šé¢çš„éšæœºå¢å¼º
    # HSV color-space augmentation
    if hgain or sgain or vgain: # random gains ç”Ÿæˆ3ä¸ª[-1, 1)ä¹‹é—´çš„éšæœºæ•°ï¼Œåˆ†åˆ«ä¸hsvç›¸ä¹˜å+1 [0,2]ä¹‹é—´
        r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains
        hue, sat, val = cv2.split(cv2.cvtColor(im, cv2.COLOR_BGR2HSV))
        dtype = im.dtype  # uint8

        x = np.arange(0, 256, dtype=r.dtype)    # [0,1,...,255]
        lut_hue = ((x * r[0]) % 180).astype(dtype)  # 0~180
        lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)   # å°†æ•°ç»„æˆªæ–­è‡³[0, 255]
        lut_val = np.clip(x * r[2], 0, 255).astype(dtype)

        im_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)))
        # cv2.LUT lookup-table æŸ¥æ‰¾è¡¨æ–¹å¼ï¼Œå³é€šè¿‡lut_hue è¿™ä¸ªè¡¨å¯¹ä¹‹å‰hueæ•°å€¼åšä¿®æ­£ï¼Œè¿”å›0-255å¯¹åº”ä½ç½®çš„lut_hueå€¼  å…·ä½“ï¼š https://blog.csdn.net/Dontla/article/details/103963085
        # cv2.merge åˆå¹¶ä¸‰ä¸ªé€šé“
        cv2.cvtColor(im_hsv, cv2.COLOR_HSV2BGR, dst=im)  # no return needed 
```

**åšä¸€ä¸ªéšæœºçš„è‰²è°ƒã€é¥±å’Œåº¦ã€äº®åº¦äº®åº¦å¢å¼º**

## 5\. ç›´æ–¹å›¾å‡è¡¡åŒ–å¢å¼º

```py
def hist_equalize(im, clahe=True, bgr=False):   # ç›´æ–¹å›¾å‡è¡¡åŒ–å¢å¼º å‚è€ƒ https://www.cnblogs.com/my-love-is-python/p/10405811.html
    # Equalize histogram on BGR image 'im' with im.shape(n,m,3) and range 0-255
    yuv = cv2.cvtColor(im, cv2.COLOR_BGR2YUV if bgr else cv2.COLOR_RGB2YUV) # bgr -> YUV
    if clahe:
        c = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        # cv2.createCLAHE å®ä¾‹åŒ–è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–å‡½æ•° å±€éƒ¨ç›´æ–¹å›¾å‡è¡¡åŒ– ï¼Œä¸ä¼šä½¿å¾—ç»†èŠ‚æ¶ˆå¤±
        # c.apply è¿›è¡Œè‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
        yuv[:, :, 0] = c.apply(yuv[:, :, 0])
    else:
        # cv2.equalizeHist è¿›è¡Œåƒç´ ç‚¹çš„å‡è¡¡åŒ– ï¼Œå³å…¨å±€å‡è¡¡åŒ– ï¼Œä½¿å¾—æ•´ä½“äº®åº¦æå‡ï¼Œä½†æ˜¯å±€éƒ¨ä¼šæ¨¡ç³Š 
        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])  # equalize Y channel histogram
    return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR if bgr else cv2.COLOR_YUV2RGB)  # convert YUV image to RGB 
```

**å…ˆåˆ¤æ–­claheæ˜¯å¦ä¸ºtrueï¼Œå¦‚æœæ˜¯å°±å…ˆå°†å›¾ç‰‡è½¬åŒ–ä¸ºYUVæ ¼å¼ï¼Œç„¶åé‡‡ç”¨`cv.createCLAHE`,è¿™ä¸ªæ–¹æ³•æ˜¯å®ä¾‹åŒ–è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–å‡½æ•° å±€éƒ¨ç›´æ–¹å›¾å‡è¡¡åŒ– ï¼Œä¸ä¼šä½¿å¾—ç»†èŠ‚æ¶ˆå¤±ï¼Œç„¶åå†ç”¨`c.apply`è¿›è¡Œè‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ã€‚**

å…·ä½“å¯çœ‹[ç›´æ–¹å›¾å‡è¡¡åŒ–](https://www.cnblogs.com/my-love-is-python/p/10405811.html)

## 6\. å›¾åƒæ¡†çš„å¹³ç§»å¤åˆ¶å¢å¼º

```py
def replicate(im, labels):  # å¤åˆ¶ï¼Œå®é™…ä¸ŠæŒ‡çš„æ˜¯æ¡†çš„å¹³ç§»
    # Replicate labels
    h, w = im.shape[:2] # è·å–å›¾åƒé•¿å®½
    boxes = labels[:, 1:].astype(int)   # è·å–æ¡†çš„ä½ç½®å’Œå¤§å°
    x1, y1, x2, y2 = boxes.T    # æ¡†çš„å·¦å³å’Œä¸Šä¸‹ä½ç½®
    s = ((x2 - x1) + (y2 - y1)) / 2  # side length (pixels)
    for i in s.argsort()[:round(s.size * 0.5)]:  # smallest indices
        x1b, y1b, x2b, y2b = boxes[i]
        bh, bw = y2b - y1b, x2b - x1b
        yc, xc = int(random.uniform(0, h - bh)), int(random.uniform(0, w - bw))  # offset x, y
        x1a, y1a, x2a, y2a = [xc, yc, xc + bw, yc + bh]
        im[y1a:y2a, x1a:x2a] = im[y1b:y2b, x1b:x2b]  # im4[ymin:ymax, xmin:xmax]
        labels = np.append(labels, [[labels[i, 0], x1a, y1a, x2a, y2a]], axis=0)

    return im, labels 
```

## 7\. å›¾ç‰‡ç¼©æ”¾letterbox

```py
def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):
    # Resize and pad image while meeting stride-multiple constraints
    shape = im.shape[:2]  # current shape [height, width]
    if isinstance(new_shape, int):  # å¦‚æœæ˜¯1ä¸ªæ•°å­—ï¼Œé»˜è®¤é•¿å®½ç›¸ç­‰
        new_shape = (new_shape, new_shape)

    # Scale ratio (new / old) è®¡ç®—æ”¶ç¼©æ¯”ï¼Œé€‰æ‹©è¾ƒå°çš„
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    if not scaleup:  # only scale down, do not scale up (for better val mAP)
        r = min(r, 1.0)

    # Compute padding
    ratio = r, r  # width, height ratios
    # è®¡ç®—æ”¶ç¼©åå›¾ç‰‡çš„é•¿å®½
    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
    # è®¡ç®—éœ€è¦å¡«å……çš„è¾¹çš„åƒç´ 
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding
    if auto:  # minimum rectangle
        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding
    elif scaleFill:  # stretch
        dw, dh = 0.0, 0.0
        new_unpad = (new_shape[1], new_shape[0])
        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios

    # é™¤ä»¥2å³æœ€ç»ˆæ¯è¾¹å¡«å……çš„åƒç´ 
    dw /= 2  # divide padding into 2 sides
    dh /= 2

    if shape[::-1] != new_unpad:  # resize
        # å…ˆå°†å›¾ç‰‡æŒ‰æ¯”ä¾‹ç¼©æ”¾åˆ°æŒ‡å®šå¤§å°
        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))    # ä¸Šä¸‹ä½ç½®
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))    # å·¦å³ä½ç½®
    # cv2.copyMakeBorder å¯¹imè®¾ç½®è¾¹ç•Œæ¡†
    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border
    return im, ratio, (dw, dh) 
```

**è¿™ä¸ªå‡½æ•°æŒºé‡è¦çš„ã€‚**

**letterboxçš„ä¸»è¦æ€æƒ³æ˜¯å°½å¯èƒ½çš„åˆ©ç”¨ç½‘ç»œæ„Ÿå—é‡çš„ä¿¡æ¯ç‰¹å¾ã€‚æ¯”å¦‚åœ¨YOLOv5ä¸­æœ€åä¸€å±‚çš„Stride=5ï¼Œå³æœ€åä¸€å±‚çš„ç‰¹å¾å›¾ä¸­æ¯ä¸ªç‚¹ï¼Œå¯ä»¥å¯¹åº”åŸå›¾ä¸­32X32çš„åŒºåŸŸä¿¡æ¯**ï¼Œé‚£ä¹ˆåªè¦åœ¨ä¿è¯æ•´ä½“å›¾ç‰‡å˜æ¢æ¯”ä¾‹ä¸€è‡´çš„æƒ…å†µä¸‹ï¼Œé•¿å®½å‡å¯ä»¥è¢«32æ•´é™¤ï¼Œé‚£ä¹ˆå°±å¯ä»¥æœ‰æ•ˆçš„åˆ©ç”¨æ„Ÿå—é‡çš„ä¿¡æ¯ã€‚

å‡è®¾å›¾ç‰‡åŸæ¥å°ºå¯¸ä¸ºï¼ˆ1080ï¼Œ 1920ï¼‰ï¼Œæˆ‘ä»¬æƒ³è¦resizeçš„å°ºå¯¸ä¸ºï¼ˆ640ï¼Œ640ï¼‰ã€‚è¦æƒ³æ»¡è¶³æ”¶ç¼©çš„è¦æ±‚ï¼Œåº”è¯¥é€‰å–æ”¶ç¼©æ¯”ä¾‹640/1920 = 0.33.åˆ™å›¾ç‰‡è¢«ç¼©æ”¾ä¸ºï¼ˆ360ï¼Œ640ï¼‰.ä¸‹ä¸€æ­¥åˆ™è¦å¡«å……ç°ç™½è¾¹è‡³360å¯ä»¥è¢«32æ•´é™¤ï¼Œåˆ™åº”è¯¥å¡«å……è‡³384ï¼Œæœ€ç»ˆå¾—åˆ°å›¾ç‰‡å°ºå¯¸ï¼ˆ384ï¼Œ640ï¼‰

## 8\. éšæœºé€è§†å˜æ¢

```py
def random_perspective(im,          # mosaicæ•´åˆåçš„å›¾ç‰‡img4 [2*img_size, 2*img_size]
                       targets=(),  # mosaicæ•´åˆåå›¾ç‰‡çš„æ‰€æœ‰æ­£å¸¸labelæ ‡ç­¾labels4(ä¸æ­£å¸¸çš„ä¼šé€šè¿‡segments2boxeså°†å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºæ­£å¸¸æ ‡ç­¾) [N, cls+xyxy]
                       segments=(),  # mosaicæ•´åˆåå›¾ç‰‡çš„æ‰€æœ‰ä¸æ­£å¸¸labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢ä¹ŸåŒ…å«æ­£å¸¸gt)  [m, x1y1....]
                       degrees=10,  # æ—‹è½¬å’Œç¼©æ”¾çŸ©é˜µå‚æ•°
                       translate=.1,    # å¹³ç§»çŸ©é˜µå‚æ•°
                       scale=.1,    # ç¼©æ”¾çŸ©é˜µå‚æ•°
                       shear=10,    # å‰ªåˆ‡çŸ©é˜µå‚æ•°
                       perspective=0.0, # é€è§†å˜æ¢å‚æ•°
                       border=(0, 0)):  # ç”¨äºç¡®å®šæœ€åè¾“å‡ºçš„å›¾ç‰‡å¤§å° ä¸€èˆ¬ç­‰äº[-img_size, -img_size] é‚£ä¹ˆæœ€åè¾“å‡ºçš„å›¾ç‰‡å¤§å°ä¸º [img_size, img_size]
    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(0.1, 0.1), scale=(0.9, 1.1), shear=(-10, 10))
    # targets = [cls, xyxy]

    height = im.shape[0] + border[0] * 2  # shape(h,w,c)
    width = im.shape[1] + border[1] * 2

    # Center è®¡ç®—ä¸­å¿ƒç‚¹
    C = np.eye(3)   # ç”Ÿæˆ3*3çš„å¯¹è§’ä¸º1çš„å¯¹è§’çŸ©é˜µ
    C[0, 2] = -im.shape[1] / 2  # x translation (pixels)
    C[1, 2] = -im.shape[0] / 2  # y translation (pixels)

    # Perspective
    # é€è§†
    P = np.eye(3)
    P[2, 0] = random.uniform(-perspective, perspective)  # x perspective (about y)
    P[2, 1] = random.uniform(-perspective, perspective)  # y perspective (about x)

    # Rotation and Scale
    # æ—‹è½¬å’Œç¼©æ”¾
    R = np.eye(3)
    a = random.uniform(-degrees, degrees)
    # a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations
    s = random.uniform(1 - scale, 1 + scale) #éšæœºç”Ÿæˆç¼©æ”¾æ¯”ä¾‹
    # s = 2 ** random.uniform(-scale, scale)
    # å›¾ç‰‡æ—‹è½¬å¾—åˆ°ä»¿å°„å˜åŒ–çŸ©é˜µèµ‹ç»™Rçš„å‰ä¸¤è¡Œ
    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)

    # Shear
    # å¼¯æ›²è§’åº¦
    S = np.eye(3)
    S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)
    S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)

    # Translation
    T = np.eye(3)
    T[0, 2] = random.uniform(0.5 - translate, 0.5 + translate) * width  # x translation (pixels)
    T[1, 2] = random.uniform(0.5 - translate, 0.5 + translate) * height  # y translation (pixels)

    # Combined rotation matrix
    # ç»„åˆæ—‹è½¬çŸ©é˜µ
    M = T @ S @ R @ P @ C  # order of operations (right to left) is IMPORTANT
    # é€šè¿‡çŸ©é˜µä¹˜æ³•ç»„åˆ
    if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any():  # image changed
        if perspective: # å¦‚æœé€è§†
            # cv2.warpPerspectiveé€è§†å˜æ¢å‡½æ•°ï¼Œå¯ä¿æŒç›´çº¿ä¸å˜å½¢ï¼Œä½†æ˜¯å¹³è¡Œçº¿å¯èƒ½ä¸å†å¹³è¡Œ
            im = cv2.warpPerspective(im, M, dsize=(width, height), borderValue=(114, 114, 114))
        else:  # affine
            # cv2.warpAffineæ”¾å°„å˜æ¢å‡½æ•°ï¼Œå¯å®ç°æ—‹è½¬ï¼Œå¹³ç§»ï¼Œç¼©æ”¾ï¼Œå¹¶ä¸”å˜æ¢åçš„å¹³è¡Œçº¿ä¾æ—§å¹³è¡Œ
            im = cv2.warpAffine(im, M[:2], dsize=(width, height), borderValue=(114, 114, 114))

    # Visualize
    # import matplotlib.pyplot as plt
    # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel()
    # ax[0].imshow(im[:, :, ::-1])  # base
    # ax[1].imshow(im2[:, :, ::-1])  # warped

    # Transform label coordinates
    # å˜æ¢æ ‡ç­¾åæ ‡
    n = len(targets)
    if n:
        # åˆ¤æ–­segmentsæ˜¯å¦ä¸ºç©ºæˆ–æ˜¯å¦å…¨ä¸º0ï¼ˆç›®æ ‡åƒç´ æ®µï¼‰
        use_segments = any(x.any() for x in segments) and len(segments) == n
        new = np.zeros((n, 4))
        # å¦‚æœä½¿ç”¨çš„æ˜¯segmentsæ ‡ç­¾(æ ‡ç­¾ä¸­å«æœ‰å¤šè¾¹å½¢gt)
        if use_segments:  # warp segments
            #ä¸Šé‡‡æ ·
            segments = resample_segments(segments)  # upsample
            for i, segment in enumerate(segments):
                xy = np.ones((len(segment), 3))
                xy[:, :2] = segment
                xy = xy @ M.T  # transform
                xy = xy[:, :2] / xy[:, 2:3] if perspective else xy[:, :2]  # perspective rescale or affine

                # clip
                new[i] = segment2box(xy, width, height)

        else:  # warp boxes
            xy = np.ones((n * 4, 3))
            xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1
            xy = xy @ M.T  # transform
            xy = (xy[:, :2] / xy[:, 2:3] if perspective else xy[:, :2]).reshape(n, 8)  # perspective rescale or affine

            # create new boxes
            x = xy[:, [0, 2, 4, 6]]
            y = xy[:, [1, 3, 5, 7]]
            new = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T

            # clip
            new[:, [0, 2]] = new[:, [0, 2]].clip(0, width)
            new[:, [1, 3]] = new[:, [1, 3]].clip(0, height)

        # filter candidates
        i = box_candidates(box1=targets[:, 1:5].T * s, box2=new.T, area_thr=0.01 if use_segments else 0.10)
        targets = targets[i]
        targets[:, 1:5] = new[i]

    return im, targets 
```

**è¿™ä¸ªå‡½æ•°ä¼šç”¨äº`load_mosaic`ä¸­ç”¨åœ¨mosaicæ“ä½œä¹‹åï¼Œè¿˜æ˜¯è›®é‡è¦çš„ã€‚**

**è¿™æ®µä»£ç åŒ…æ‹¬å¯¹å›¾ç‰‡çš„æ—‹è½¬ã€ç¼©æ”¾ã€é€è§†ã€å¼¯æ›²ã€æ”¾å¤§ç¼©å°çš„éšæœºå˜åŒ–ï¼Œæ¯ä¸€ä¸ªæ“ä½œéƒ½é€šè¿‡åˆ›å»ºä¸€ä¸ª`3*3`çš„çŸ©é˜µï¼Œæœ€åç›¸ä¹˜ï¼Œè¿›è¡Œå˜æ¢**

**æœ€åè¿˜è¦è°ƒæ•´æ ‡ç­¾ä¿¡æ¯ï¼Œåªæœ‰å¤šè¾¹å½¢gtæ—¶æ‰æœ‰ã€‚**

**Mosaic**
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/4d7f4b6545d69835383c6c75982d53ad.png)
**ç»è¿‡mosaic + random_perspective**
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/488208f432d24cf9d35001d45ba1328f.png)

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/91ac6b698910da1f413c65243b1b9ebe.png)

## 9\. cutout

```py
def cutout(im, labels, p=0.5):
    # Applies image cutout augmentation https://arxiv.org/abs/1708.04552
    """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—ä¸­çš„__getitem__å‡½æ•°è¿›è¡Œcutoutå¢å¼º  v5æºç ä½œè€…é»˜è®¤æ˜¯æ²¡ç”¨ç”¨è¿™ä¸ªçš„ æ„Ÿå…´è¶£çš„å¯ä»¥æµ‹è¯•ä¸€ä¸‹
        cutoutæ•°æ®å¢å¼º, ç»™å›¾ç‰‡éšæœºæ·»åŠ éšæœºå¤§å°çš„æ–¹å—å™ªå£°  ç›®çš„æ˜¯æé«˜æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§
        å®ç°ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªå›ºå®šå¤§å°çš„æ­£æ–¹å½¢åŒºåŸŸï¼Œç„¶åé‡‡ç”¨å…¨0å¡«å……å°±OKäº†ï¼Œå½“ç„¶ä¸ºäº†é¿å…å¡«å……0å€¼å¯¹è®­ç»ƒçš„å½±å“ï¼Œåº”è¯¥è¦å¯¹æ•°æ®è¿›è¡Œä¸­å¿ƒå½’ä¸€åŒ–æ“ä½œï¼Œnormåˆ°0ã€‚
        è®ºæ–‡: https://arxiv.org/abs/1708.04552
        :params image: ä¸€å¼ å›¾ç‰‡ [640, 640, 3] numpy
        :params labels: è¿™å¼ å›¾ç‰‡çš„æ ‡ç­¾ [N, 5]=[N, cls+x1y1x2y2]
        :return labels: ç­›é€‰åçš„è¿™å¼ å›¾ç‰‡çš„æ ‡ç­¾ [M, 5]=[M, cls+x1y1x2y2]  M<N
                        ç­›é€‰: å¦‚æœéšæœºç”Ÿæˆçš„å™ªå£°å’ŒåŸå§‹çš„gtæ¡†ç›¸äº¤åŒºåŸŸå gtæ¡†å¤ªå¤§ å°±ç­›å‡ºè¿™ä¸ªgtæ¡†label
        """
    if random.random() < p:
        h, w = im.shape[:2]
        scales = [0.5] * 1 + [0.25] * 2 + [0.125] * 4 + [0.0625] * 8 + [0.03125] * 16  # image size fraction
        for s in scales:
            mask_h = random.randint(1, int(h * s))  # create random masks
            mask_w = random.randint(1, int(w * s))

            # box éšæœºç”Ÿæˆå™ªå£°
            xmin = max(0, random.randint(0, w) - mask_w // 2)
            ymin = max(0, random.randint(0, h) - mask_h // 2)
            xmax = min(w, xmin + mask_w)
            ymax = min(h, ymin + mask_h)

            # apply random color mask æ·»åŠ éšæœºé¢œè‰²çš„å™ªå£° 
            im[ymin:ymax, xmin:xmax] = [random.randint(64, 191) for _ in range(3)]

            # return unobscured labels è¿”å›æ²¡æœ‰å™ªå£°çš„label
            if len(labels) and s > 0.03:
                box = np.array([xmin, ymin, xmax, ymax], dtype=np.float32)
                ioa = bbox_ioa(box, xywhn2xyxy(labels[:, 1:5], w, h))  # intersection over area
                labels = labels[ioa < 0.60]  # remove >60% obscured labels

    return labels 
```

**cutoutæ•°æ®å¢å¼ºï¼Œç”¨åœ¨LoadImagesAndLabelsæ¨¡å—ä¸­çš„__getitem__å‡½æ•°è¿›è¡Œcutoutå¢å¼ºã€‚ç»™å›¾ç‰‡éšæœºæ·»åŠ éšæœºå¤§å°çš„æ–¹å—å™ªå£° ï¼Œç›®çš„æ˜¯æé«˜æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚**

**ä½œè€…æ²¡æœ‰ä½¿ç”¨è¿™ä¸ªï¼Œå¯ä»¥è‡ªå·±è¯•ä¸€è¯•ã€‚**

## 10\. mixup

```py
def mixup(im, labels, im2, labels2):
    # Applies MixUp augmentation https://arxiv.org/pdf/1710.09412.pdf
    r = np.random.beta(32.0, 32.0)  # mixup ratio, alpha=beta=32.0
    im = (im * r + im2 * (1 - r)).astype(np.uint8)
    labels = np.concatenate((labels, labels2), 0)
    return im, labels 
```

**å°†ä¸¤å¼ å›¾ç‰‡æŒ‰æ¯”ä¾‹èåˆèµ·æ¥ï¼Œlabelså°±ç›¸åŒç»´åº¦concatèµ·æ¥**

**ä¹Ÿç”¨åœ¨`LoadImagesAndLabels`çš„`__getitem__`ä¸­ï¼Œè¿›è¡Œæ•°æ®å¢å¼º**
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/f602b3b524b3cbb7779e3109019e5681.png)

## 11\. box_candidates

```py
def box_candidates(box1, box2, wh_thr=2, ar_thr=100, area_thr=0.1, eps=1e-16):  # box1(4,n), box2(4,n)
    # Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio
    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]
    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]
    ar = np.maximum(w2 / (h2 + eps), h2 / (w2 + eps))  # aspect ratio
    return (w2 > wh_thr) & (h2 > wh_thr) & (w2 * h2 / (w1 * h1 + eps) > area_thr) & (ar < ar_thr)  # candidates 
```

**è¿™ä¸ªå‡½æ•°ç”¨åœ¨random_perspectiveä¸­ï¼Œæ˜¯å¯¹é€è§†å˜æ¢åçš„å›¾ç‰‡çš„labelè¿›è¡Œç­›é€‰ï¼Œå¢å¼ºåwã€hè¦å¤§äº2 å¢å¼ºåå›¾åƒä¸å¢å¼ºå‰å›¾åƒé¢ç§¯æ¯”å€¼å¤§äºarea_thr å®½é«˜æ¯”å¤§äºar_thr**

## æ€»ç»“

**è¿™ç¯‡ä¸»è¦è®²äº†YOLOv5ä¸­çš„å„ç§æ•°æ®å¢å¼ºæ–¹æ³•ã€‚å…¶ä¸­[å›¾ç‰‡ç¼©æ”¾](#7_letterbox_171)å’Œ[éšæœºé€è§†](#8__218)å˜æ¢ç‰¹åˆ«é‡è¦ï¼Œå°¤å…¶æ˜¯åè€…ä¼šåœ¨`Mosaic`è¿‡åç”¨åˆ°ã€‚å…¶ä»–çš„äº†è§£ä¸‹å³å¯ã€‚**

**References**

> CSDN å—œç¡çš„ç¯ é¾™[ã€YOLOv5-6.xã€‘æ•°æ®å¢å¼ºä»£ç è§£æ](https://blog.csdn.net/weixin_43799388/article/details/123830587)
> CSDN Tinaå§ [æœ€å¿«æœ€å¥½ç”¨çš„æ•°æ®å¢å¼ºåº“ã€Œalbumentationsã€ ä¸€æ–‡çœ‹æ‡‚ç”¨æ³•](https://blog.csdn.net/u014264373/article/details/114144303)
> CSDN æ»¡èˆ¹æ¸…æ¢¦å‹æ˜Ÿæ²³HK[ã€YOLOV5-5.x æºç è§£è¯»ã€‘datasets.py](https://blog.csdn.net/qq_38253797/article/details/119904518)