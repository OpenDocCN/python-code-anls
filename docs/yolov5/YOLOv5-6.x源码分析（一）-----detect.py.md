<!--yml
category: æ¸¸æˆ
date: 2023-09-17 14:45:23
-->

# YOLOv5-6.xæºç åˆ†æï¼ˆä¸€ï¼‰---- detect.py

> æ¥æºï¼š[https://blog.csdn.net/weixin_51322383/article/details/130306871](https://blog.csdn.net/weixin_51322383/article/details/130306871)

### æ–‡ç« ç›®å½•

*   [å‰å¼•](#_1)
*   [ğŸš€YOLOv5-6.xæºç åˆ†æï¼ˆä¸€ï¼‰---- detect.py](#YOLOv56x_detectpy_17)
*   *   [1\. å¯¼å…¥éœ€è¦çš„åŒ…](#1__19)
    *   [2\. æ‰§è¡Œmainå‡½æ•°](#2_main_70)
    *   [3\. è®¾ç½®optå‚æ•°](#3_opt_86)
    *   [4\. æ‰§è¡Œrunå‡½æ•°](#4_run_124)
    *   *   [4.1 åˆå§‹åŒ–ä¸€äº›é…ç½®](#41__125)
        *   [4.2 è½½å…¥æ¨¡å‹](#42__142)
        *   [4.3 åŠ è½½æ•°æ®](#43__156)
        *   [4.4 æ¨ç†éƒ¨åˆ†](#44__172)
        *   *   [4.4.1 çƒ­èº«éƒ¨åˆ†](#441__174)
            *   [4.4.2 å¯¹æ¯å¼ å›¾ç‰‡/è§†é¢‘è¿›è¡Œå‰å‘æ¨ç†](#442__203)
            *   [4.4.3 NMSåå¤„ç†é™¤å»å¤šä½™çš„æ¡†](#443_NMS_216)
            *   [4.4.4 é¢„æµ‹è¿‡ç¨‹](#444__225)
            *   [4.4.5 æ‰“å°ç›®æ ‡æ£€æµ‹ç»“æœ](#445__277)

# å‰å¼•

è¿™ç®—æ˜¯æˆ‘çš„ç¬¬ä¸€ä¸ªæ­£å¼åšå®¢æ–‡ç« å§ï¼Œåœ¨å‡†å¤‡åŠ¨æ‰‹å†™å†…å®¹çš„æ—¶å€™ï¼Œéƒ½æœ‰ç‚¹æ— ä»ä¸‹æ‰‹çš„æ„Ÿè§‰ã€‚anywayï¼Œä»¥ååº”è¯¥ä¼šå†™çš„è¶Šæ¥è¶Šå¨´ç†Ÿçš„ã€‚

YOLOç³»åˆ—æˆ‘å·²ç»ç”¨äº†æ¥è¿‘ä¸€å¹´äº†å§ï¼Œä»å»å¹´æš‘å‡å¼€å§‹å­¦ä¹ ï¼Œæ‰“ç®—å…¥å‘æ·±åº¦å­¦ä¹ ï¼Œå…¶ä¸­è·‘è¿‡demoï¼Œè‡ªå·±ç”¨Flaskæ­é…YOLOv5å†™è¿‡ç½‘é¡µç«¯å®æ—¶æ£€æµ‹ï¼Œè¿˜çœ‹è¿‡æºç ï¼Œå¯ä»¥è¯´å·²ç»æŠŠYOLOç³»åˆ—ç©å¾—å·²ç»æ¯”è¾ƒ6äº†ã€‚

YOLOç³»åˆ—æ—¥æ–°æœˆå¼‚ï¼Œå¦‚ä»Šå·²ç»æ›´æ–°åˆ°äº†ç¬¬8ä»£ï¼Œä½†ç”¨å¾—æœ€å¤šçš„è¿˜æ˜¯ç¬¬äº”ä»£ï¼Œè€Œç¬¬äº”ä»£ä¹Ÿå·²ç»æ›´æ–°åˆ°äº†v7.0ï¼Œå› ä¸ºæ›´æ–°å¤šï¼Œæ‰€ä»¥ä¹Ÿç›¸å¯¹æ›´åŠ ç¨³å®šï¼Œä½¿ç”¨çš„äººä¹Ÿæ›´å¤šã€‚

æˆ‘å¼€å§‹å­¦ä¹ æ·±åº¦å­¦ä¹ å…¶å®åˆ°ç°åœ¨ä¹Ÿæ²¡æœ‰ä¸€å¹´ï¼Œæˆ‘è¿™ç§åŠè·¯å‡ºå®¶çš„ï¼Œå¦‚æœä¸å¥½å¥½èµ°æ¯ä¸€æ­¥ï¼ŒçœŸçš„å¾ˆå®¹æ˜“å‡ºå²”å­ã€‚åƒä¸Šé¢æåˆ°ï¼Œæˆ‘ç”¨YOLOä¹Ÿå·²ç»ç”¨å¾—æ¯”è¾ƒå¤šäº†ï¼Œé¡¹ç›®é‡Œé¢ä¸‰ä¸ªæœ‰ä¸¤ä¸ªéƒ½æ˜¯ç”¨çš„YOLOï¼Œæ‰€ä»¥åœ¨åˆ°æ—¶å€™é¢è¯•çš„æ—¶å€™è‚¯å®šä¹Ÿæ˜¯é‡ç‚¹è¯¢é—®é¡¹ç›®ï¼Œè¿™æ ·æˆ‘å°±æ›´å¾—æŠŠYOLOçš„æ¯ä¸€ä¸ªpartç†Ÿæ‚‰äº†ã€‚

æ‰€ä»¥æ­£å¼å› ä¸ºè¿™æ ·ï¼Œæˆ‘æ‰ä¼šå†™ä¸‹è¿™ç¯‡åšå®¢ï¼Œå¹¶ç”±æ­¤ä½œä¸ºèµ·ç‚¹æ¥è®°å½•ï¼Œåˆ°æœ€åæŠŠæ¯ä¸€éƒ¨åˆ†éƒ½ç†è§£é€šé€ã€‚å†™åšå®¢çœŸçš„å¾ˆå ç”¨æ—¶é—´ï¼Œä½†ä¸ºäº†ä¸è®©ç¢ç‰‡åŒ–ä¿¡æ¯ç»‘æ¶æˆ‘ï¼Œæˆ‘ä¸€å®šå¯ä»¥åšæŒå†™å®Œçš„ï¼

å†å®šä¸ªå°ç›®æ ‡ï¼Œè¿™ä¸€å‘¨ä¹‹å†…æŠŠYOLOv5çš„æºç è§£æå†™å®Œã€‚

Letâ€™s begin!ğŸš€ğŸš€ğŸš€

**å¯¼èˆªï¼š**[YOLOv5-6.xæºç åˆ†æ å…¨æµç¨‹è®°å½•](https://blog.csdn.net/weixin_51322383/article/details/130353834)

# ğŸš€YOLOv5-6.xæºç åˆ†æï¼ˆä¸€ï¼‰---- detect.py

è¿™ä¸ªå‡½æ•°æ˜¯æ¨ç†è„šæœ¬ï¼Œå¯ä»¥è¾“å…¥å›¾ç‰‡ã€è§†é¢‘ã€streamsç­‰è¿›è¡Œæ£€æµ‹ã€‚æ‰§è¡Œçš„ç»“æœä¼šä¿å­˜åœ¨runs/detect/xxxä¸‹ã€‚

## 1\. å¯¼å…¥éœ€è¦çš„åŒ…

```py
import argparse
import os
import platform
import sys
from pathlib import Path

import torch
import torch.backends.cudnn as cudnn 
```

é¦–å…ˆæ˜¯å¯¼å…¥çš„å¸¸ç”¨pythonåº“ï¼š

*   `argparseï¼š`å®ƒæ˜¯ä¸€ä¸ªç”¨äºå‘½ä»¤é¡¹é€‰é¡¹ä¸å‚æ•°è§£æçš„æ¨¡å—ï¼Œé€šè¿‡åœ¨ç¨‹åºä¸­å®šä¹‰å¥½æˆ‘ä»¬éœ€è¦çš„å‚æ•°ï¼Œargparse å°†ä¼šä» sys.argv ä¸­è§£æå‡ºè¿™äº›å‚æ•°ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆå¸®åŠ©å’Œä½¿ç”¨ä¿¡æ¯
*   osï¼š å®ƒæä¾›äº†å¤šç§æ“ä½œç³»ç»Ÿçš„æ¥å£ã€‚é€šè¿‡osæ¨¡å—æä¾›çš„æ“ä½œç³»ç»Ÿæ¥å£ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ“ä½œç³»ç»Ÿé‡Œæ–‡ä»¶ã€ç»ˆç«¯ã€è¿›ç¨‹ç­‰è¿›è¡Œæ“ä½œ
*   `sys`ï¼š å®ƒæ˜¯ä¸pythonè§£é‡Šå™¨äº¤äº’çš„ä¸€ä¸ªæ¥å£ï¼Œè¯¥æ¨¡å—æä¾›å¯¹è§£é‡Šå™¨ä½¿ç”¨æˆ–ç»´æŠ¤çš„ä¸€äº›å˜é‡çš„è®¿é—®å’Œè·å–ï¼Œå®ƒæä¾›äº†è®¸å¤šå‡½æ•°å’Œå˜é‡æ¥å¤„ç† Python è¿è¡Œæ—¶ç¯å¢ƒçš„ä¸åŒéƒ¨åˆ†
*   `pathlib`ï¼š è¿™ä¸ªåº“æä¾›äº†ä¸€ç§é¢å‘å¯¹è±¡çš„æ–¹å¼æ¥ä¸æ–‡ä»¶ç³»ç»Ÿäº¤äº’ï¼Œå¯ä»¥è®©ä»£ç æ›´ç®€æ´ã€æ›´æ˜“è¯»
*   `torch`ï¼š è¿™æ˜¯ä¸»è¦çš„Pytorchåº“ã€‚å®ƒæä¾›äº†æ„å»ºã€è®­ç»ƒå’Œè¯„ä¼°ç¥ç»ç½‘ç»œçš„å·¥å…·
*   `torch.backends. cudnn`ï¼š å®ƒæä¾›äº†ä¸€ä¸ªæ¥å£ï¼Œç”¨äºä½¿ç”¨cuDNNåº“ï¼Œåœ¨NVIDIA GPUä¸Šé«˜æ•ˆåœ°è¿›è¡Œæ·±åº¦å­¦ä¹ ã€‚cudnnæ¨¡å—æ˜¯ä¸€ä¸ªPytorchåº“çš„æ‰©å±•

```py
FILE = Path(__file__).resolve() # å¾—åˆ°ç»å¯¹è·¯å¾„ ./yolov5/detect.py
ROOT = FILE.parents[0]  # YOLOv5 root directory çˆ¶ç›®å½• ./yolov5
if str(ROOT) not in sys.path:   # sys.path æ¨¡å—çš„æŸ¥è¯¢è·¯å¾„åˆ—è¡¨,ç¡®ä¿ROOTå­˜åœ¨sys.pathä¸­
    sys.path.append(str(ROOT))  # add ROOT to PATH
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relativeï¼Œç»å¯¹è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ 
```

æ¥ç€å®šä¹‰äº†ä¸€äº›æ–‡ä»¶è·¯å¾„ã€‚
è¿™ä¸€éƒ¨åˆ†çš„ä¸»è¦ä½œç”¨æœ‰ä¸¤ä¸ªï¼š

*   å°†å½“å‰é¡¹ç›®æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸Šï¼Œä»¥ä½¿å¾—é¡¹ç›®ä¸­çš„æ¨¡å—å¯ä»¥è°ƒç”¨ã€‚
*   å°†å½“å‰é¡¹ç›®çš„ç›¸å¯¹è·¯å¾„ä¿å­˜åœ¨ROOTä¸­ï¼Œä¾¿äºå¯»æ‰¾é¡¹ç›®ä¸­çš„æ–‡ä»¶ã€‚

```py
# ----------------- å¯¼å…¥è‡ªå®šä¹‰çš„å…¶ä»–åŒ… -------------------
from models.common import DetectMultiBackend
from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams
from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,
                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)
from utils.plots import Annotator, colors, save_one_box
from utils.torch_utils import select_device, time_sync 
```

æœ€ååˆ™æ˜¯ä¸€äº›è‡ªå®šä¹‰æ¨¡å—ï¼Œå…¶ä¸­ä¸»è¦åŒ…æ‹¬äº†ï¼š

*   `models/common.pyï¼š`å®šä¹‰äº†ä¸€äº›é€šç”¨çš„ç±»æ¨¡å—ï¼Œæ¯”å¦‚å„ç§å·ç§¯æ¨¡å—ã€‚
*   `utils.dataloaders.pyï¼š`è¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†ä¸¤ä¸ªç±»ï¼ŒLoadImageså’ŒLoadStreamsï¼Œå®ƒä»¬å¯ä»¥åŠ è½½å›¾åƒæˆ–è§†é¢‘å¸§ï¼Œå¹¶å¯¹å®ƒä»¬è¿›è¡Œä¸€äº›é¢„å¤„ç†ï¼Œä»¥ä¾¿è¿›è¡Œç‰©ä½“æ£€æµ‹æˆ–è¯†åˆ«ã€‚
*   `utils.general.pyï¼š`å®šä¹‰ä¸€äº›å·¥å…·å‡½æ•°ï¼Œæ¯”å¦‚æ—¥å¿—ã€åæ ‡è½¬æ¢ç­‰ã€‚
*   `utils.plot.pyï¼š`ç”»å›¾ï¼Œæ ‡æ¡†ã€‚
*   `utils.torch_utils.py:`å®šä¹‰äº†ä¸€äº›ä¸pytorchç›¸å…³çš„å·¥å…·å‡½æ•°ï¼Œæ¯”å¦‚è®¾å¤‡é€‰æ‹©ç­‰ã€‚

é€šè¿‡å¯¼å…¥è¿™äº›æ¨¡å—ï¼Œå¯ä»¥å‡å°‘ä»£ç çš„å¤æ‚åº¦ã€è€¦åˆæ€§ã€å†—ä½™ç¨‹åº¦ã€‚

## 2\. æ‰§è¡Œmainå‡½æ•°

```py
def main(opt):
    check_requirements(exclude=('tensorboard', 'thop')) # æ£€æµ‹å„ç§åŒ…æœ‰æ²¡æœ‰æˆåŠŸå®‰è£…;æ‰“å°å‚æ•°
    run(**vars(opt))

if __name__ == "__main__":
    opt = parse_opt()
    main(opt) 
```

ä¸»å‡½æ•°ä¸»è¦å°±æ˜¯è°ƒç”¨äº†`run()`å‡½æ•°ï¼Œå°†å‘½ä»¤è¡Œå‚æ•°optä½œä¸ºå­—å…¸å‚æ•°ä¼ é€’ç»™`run()`å‡½æ•°ã€‚

> `if name == mainï¼š`çš„ä½œç”¨ï¼š
> ä¸€ä¸ªpythonæ–‡ä»¶é€šå¸¸æœ‰ä¸¤ç§ä½¿ç”¨æ–¹æ³•ï¼Œç¬¬ä¸€æ˜¯ä½œä¸ºè„šæœ¬ç›´æ¥æ‰§è¡Œï¼Œç¬¬äºŒæ˜¯ import åˆ°å…¶ä»–çš„ python è„šæœ¬ä¸­è¢«è°ƒç”¨ï¼ˆæ¨¡å—é‡ç”¨ï¼‰æ‰§è¡Œã€‚å› æ­¤ if name == â€˜mainâ€™:çš„ä½œç”¨å°±æ˜¯æ§åˆ¶è¿™ä¸¤ç§æƒ…å†µæ‰§è¡Œä»£ç çš„è¿‡ç¨‹ï¼Œåœ¨ if name == â€˜mainâ€™: ä¸‹çš„ä»£ç åªæœ‰åœ¨ç¬¬ä¸€ç§æƒ…å†µä¸‹ï¼ˆå³æ–‡ä»¶ä½œä¸ºè„šæœ¬ç›´æ¥æ‰§è¡Œï¼‰æ‰ä¼šè¢«æ‰§è¡Œï¼Œè€Œ import åˆ°å…¶ä»–è„šæœ¬ä¸­æ˜¯ä¸ä¼šè¢«æ‰§è¡Œçš„ã€‚

## 3\. è®¾ç½®optå‚æ•°

```py
def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT/'runs/train/strawberry/weights/best.pt', help='model path(s)')    # æƒé‡æ–‡ä»¶
    # parser.add_argument('--source', type=str, default='http://admin:admin@192.168.43.1:8081', help='file/dir/URL/glob, 0 for webcam')
    parser.add_argument('--source', type=str, default=ROOT / "data/strawberry", help='file/dir/URL/glob, 0 for webcam') # æµ‹è¯•æ•°æ®
    parser.add_argument('--data', type=str, default=ROOT/'data/strawberry.yaml', help='(optional) dataset.yaml path')    # å‚æ•°æ–‡ä»¶
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w') # é«˜ã€å®½
    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')              # ç½®ä¿¡åº¦é˜ˆå€¼
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')                  # éæå¤§æŠ‘åˆ¶çš„ioué˜ˆå€¼
    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')           # æ¯å¼ å›¾ç‰‡æœ€å¤§çš„ç›®æ ‡ä¸ªæ•°
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')               # GPUåŠ é€Ÿ
    parser.add_argument('--view-img', action='store_true', help='show results')                             # æ˜¯å¦å±•ç¤ºé¢„æµ‹åçš„å›¾ç‰‡/è§†é¢‘ï¼Œé»˜è®¤false
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')                    # æ˜¯å¦å°†é¢„æµ‹çš„æ¡†åæ ‡ä»¥txtæ–‡ä»¶æ ¼å¼ä¿å­˜ é»˜è®¤True ä¼šåœ¨runs/detect/expn/labelsä¸‹ç”Ÿæˆæ¯å¼ å›¾ç‰‡é¢„æµ‹çš„txtæ–‡ä»¶
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')   # æ˜¯å¦ä¿å­˜é¢„æµ‹æ¯ä¸ªç›®æ ‡ç½®ä¿¡åº¦åˆ°é¢„æµ‹txæ–‡ä»¶ä¸­
    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')           # æ˜¯å¦éœ€è¦å°†é¢„æµ‹åˆ°çš„ç›®æ ‡ä»åŸå›¾ä¸­æ‰£å‡ºæ¥ å‰ªåˆ‡å¥½ å¹¶ä¿å­˜ ä¼šåœ¨runs/detect/expnä¸‹ç”Ÿæˆcropsæ–‡ä»¶ï¼Œå°†å‰ªåˆ‡çš„å›¾ç‰‡ä¿å­˜åœ¨é‡Œé¢  é»˜è®¤False
    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')                  # æ˜¯å¦ä¸è¦ä¿å­˜é¢„æµ‹åçš„å›¾ç‰‡  é»˜è®¤False å°±æ˜¯é»˜è®¤è¦ä¿å­˜é¢„æµ‹åçš„å›¾ç‰‡
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')  # åœ¨nmsä¸­æ˜¯å¦æ˜¯åªä¿ç•™æŸäº›ç‰¹å®šçš„ç±» é»˜è®¤æ˜¯None å°±æ˜¯æ‰€æœ‰ç±»åªè¦æ»¡è¶³æ¡ä»¶éƒ½å¯ä»¥ä¿ç•™
    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')                   # è¿›è¡Œnmsæ˜¯å¦ä¹Ÿé™¤å»ä¸åŒç±»åˆ«ä¹‹é—´çš„æ¡† é»˜è®¤False
    parser.add_argument('--augment', action='store_true', help='augmented inference')                       # é¢„æµ‹æ˜¯å¦ä¹Ÿè¦é‡‡ç”¨æ•°æ®åŠ å¼º
    parser.add_argument('--visualize', action='store_true', help='visualize features')                      # æ˜¯å¦å°†optimizerä»ckptä¸­åˆ é™¤  æ›´æ–°æ¨¡å‹  é»˜è®¤False
    parser.add_argument('--update', action='store_true', help='update all models')
    parser.add_argument('--project', default=ROOT / 'runs/detect', help='save results to project/name')     # ä¿å­˜è·¯å¾„
    parser.add_argument('--name', default='exp', help='save results to project/name')                       # ä¿å­˜çš„æ–‡ä»¶åå­—
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')   # å¦‚æœå­˜åœ¨æ–‡ä»¶å¤¹ï¼Œæ˜¯å¦è¦†ç›–
    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)')        # æ£€æµ‹æ¡†çš„çº¿æ¡å®½åº¦
    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')                # æ˜¯å¦éšè—label
    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')             # æ˜¯å¦éšè—ç½®ä¿¡åº¦
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')
    opt = parser.parse_args()
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand [640,640]
    print_args(vars(opt))   # æ‰“å°æ‰€æœ‰å‚æ•°ä¿¡æ¯
    return opt 
```

è¿™éƒ¨åˆ†ä»£ç ä¸»è¦æ˜¯è®¾ç½®äº†ä¸€äº›åˆ—å‚æ•°ï¼Œè¿™äº›å‚æ•°åœ¨`run()`ä¸­ä»¥å­—å…¸å½¢å¼ä¼ é€’ã€‚

## 4\. æ‰§è¡Œrunå‡½æ•°

### 4.1 åˆå§‹åŒ–ä¸€äº›é…ç½®

```py
# ===================================== 1ã€åˆå§‹åŒ–ä¸€äº›é…ç½® =====================================
    # æ˜¯å¦ä¿å­˜é¢„æµ‹åçš„å›¾ç‰‡ é»˜è®¤nosave=False æ‰€ä»¥åªè¦ä¼ å…¥çš„æ–‡ä»¶åœ°å€ä¸æ˜¯ä»¥.txtç»“å°¾ å°±éƒ½æ˜¯è¦ä¿å­˜é¢„æµ‹åçš„å›¾ç‰‡çš„
    save_img = not nosave and not source.endswith('.txt')  # save inference images  æ˜¯å¦ä»¥.txtç»“å°¾;ä¸ºtrue
    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)    # æ˜¯å¦æ˜¯æ–‡ä»¶åœ°å€ suffix:åç¼€(1:ä»jå¼€å¤´)
    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))   # æ˜¯å¦æ˜¯ç½‘ç»œæµåœ°å€ false
    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)  # æ˜¯å¦æ˜¯æ•°å€¼(æ‘„åƒå¤´)ã€.txtã€ç½‘ç»œæµä¸”ä¸æ˜¯æ–‡ä»¶åœ°å€
    if is_url and is_file:
        source = check_file(source)  # download

    # Directories ä¿å­˜è·¯å¾„
    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run å¢é‡è·¯å¾„ï¼ˆæ£€æµ‹ä¿å­˜è·¯å¾„ä¸‹çš„æ•°å­—åˆ°å‡ äº†ï¼‰
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir 
```

è¿™æ®µä»£ç åŒ…æ‹¬äº†ä¸€äº›ä¿å­˜è·¯å¾„ä¹‹ç±»çš„å®šä¹‰ã€‚

### 4.2 è½½å…¥æ¨¡å‹

```py
# ===================================== 2ã€è½½å…¥æ¨¡å‹ =====================================
    # Load model æ¨¡å‹åŠ è½½
    device = select_device(device)  # è®¾å¤‡é€‰æ‹©
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)   # æƒé‡ã€è®¾å¤‡ã€falseã€.yamlã€åŠç²¾åº¦æ¨ç†è¿‡ç¨‹
    stride, names, pt = model.stride, model.names, model.pt # æ­¥é•¿ã€ç±»åˆ«åã€æ˜¯å¦ä¸ºpytorch
    imgsz = check_img_size(imgsz, s=stride)  # check image size 640æ˜¯32çš„å€æ•° 
```

å‰é¢ä¸¤è¡Œä»£ç éƒ½æ˜¯åœ¨è‡ªå·±å®šä¹‰çš„åŒ…ä¸­ï¼Œåœ¨åé¢å†å…·ä½“è®²è§£å§ï¼Œè¿™é‡Œå¤§è‡´åªéœ€è¦äº†è§£åˆ°ä»–æ˜¯é€‰æ‹©è®¾å¤‡ï¼ˆcpuè¿˜æ˜¯cudaï¼‰ã€è½½å…¥æ¨¡å‹ã€‚
æ¥ç€ä¸‹é¢è·å–äº†æ¨¡å‹çš„**strideã€nameã€pt**ç­‰å‚æ•°ã€‚
æœ€åè°ƒç”¨`check_img_size`æ£€æŸ¥å›¾ç‰‡æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Œä¸ç¬¦åˆåˆ™éœ€è¦è°ƒæ•´ã€‚

### 4.3 åŠ è½½æ•°æ®

```py
# ===================================== 3ã€åŠ è½½æ•°æ® =====================================
    # Dataloader
    if webcam:  # false
        view_img = check_imshow()
        cudnn.benchmark = True  # set True to speed up constant image size inference
        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)
        bs = len(dataset)  # batch_size
    else:
        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt) # åŠ è½½å›¾ç‰‡æ–‡ä»¶
        bs = 1  # batch_size    æ¯æ¬¡è¾“å…¥ä¸€å¼ å›¾ç‰‡
    vid_path, vid_writer = [None] * bs, [None] * bs 
```

è¿™é‡Œçš„ä¸»è¦å‡½æ•°æ˜¯`LoadImages()`ï¼Œè½½å…¥æ•°æ®ã€‚

### 4.4 æ¨ç†éƒ¨åˆ†

è¿™ä¸ªpartæ˜¯æ•´ä¸ªç®—æ³•çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œé€šè¿‡forå¾ªç¯å¯¹åŠ è½½çš„æ•°æ®è¿›è¡Œéå†ï¼Œå¦‚æœæ˜¯è§†é¢‘æµåˆ™ä¸€å¸§ä¸€å¸§åœ°æ¨ç†ï¼Œç„¶åè¿›è¡ŒNMSï¼Œæœ€åç”»æ¡†ï¼Œé¢„æµ‹ç±»åˆ«ã€‚

#### 4.4.1 çƒ­èº«éƒ¨åˆ†

```py
# Run inference æ¨¡å‹æ¨ç†è¿‡ç¨‹
    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup(çƒ­èº«åˆå§‹åŒ–)
    seen, windows, dt = 0, [], [0.0, 0.0, 0.0]  # dtï¼šå¯¸å°ºæ—¶é—´
    for path, im, im0s, vid_cap, s in dataset:
        t1 = time_sync()
        # 1ã€å¤„ç†æ¯ä¸€å¼ å›¾ç‰‡/è§†é¢‘çš„æ ¼å¼
        im = torch.from_numpy(im).to(device)    #ä»numpyè½¬æˆtensoræ ¼å¼ï¼Œæ”¾åˆ°deviceä¸Š
        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32  åˆ¤æ–­æœ‰æ²¡æœ‰ç”¨åŠç²¾åº¦
        im /= 255  # 0 - 255 to 0.0 - 1.0   å½’ä¸€åŒ–
        if len(im.shape) == 3:  # æ˜¯å¦æ˜¯3é€šé“
            im = im[None]  # expand for batch dim [1,3,640,480]
        t2 = time_sync()
        dt[0] += t2 - t1 
```

**çƒ­èº«**æ“ä½œï¼Œå³å¯¹æ¨¡å‹è¿›è¡Œä¸€äº›é¢„å¤„ç†ä»¥åŠ é€Ÿåç»­çš„æ¨ç†è¿‡ç¨‹ã€‚

> ä½œç”¨ï¼šæ¥è‡ªChitGPTçš„ç­”æ¡ˆï¼š**æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒçƒ­èº«çš„ä½œç”¨æ˜¯ä¸ºäº†ä½¿åˆå§‹æƒé‡æ›´å¥½åœ°é€‚åº”æ•°æ®åˆ†å¸ƒï¼Œæé«˜æœ€ç»ˆæ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡çƒ­èº«è®­ç»ƒï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘æ¢¯åº¦ä¸‹é™çš„éœ‡è¡ï¼ŒåŠ é€Ÿæ”¶æ•›é€Ÿåº¦ï¼Œå¹¶é™ä½å±€éƒ¨æå°å€¼çš„å½±å“ã€‚**

è¯´ç®€å•ç‚¹å°±æ˜¯åœ¨æ¨¡å‹è®­ç»ƒåˆæœŸç»™ä»–ä¸€ä¸ªè¾ƒå¤§çš„å­¦ä¹ ç‡ï¼Œ**å› ä¸ºè¾ƒå¤§çš„å­¦ä¹ ç‡å°±ä¸é‚£ä¹ˆå®¹æ˜“ä¼šä½¿æ¨¡å‹å­¦å**ï¼Œç„¶ååœ¨è®­ç»ƒçš„åæœŸå†å‡å°å­¦ä¹ ç‡ï¼Œä½¿å…¶æ”¶æ•›ã€‚
å…·ä½“å¯çœ‹[æ·±åº¦å­¦ä¹ ä¹‹â€œè®­ç»ƒçƒ­èº«â€ï¼ˆwarm upï¼‰â€“å­¦ä¹ ç‡çš„è®¾ç½®](https://blog.csdn.net/weixin_40051325/article/details/107465843)

åœ¨è¿™ä¸ªé˜¶æ®µï¼Œè¿˜å®šä¹‰äº†ä¸€äº›å˜é‡ï¼ŒåŒ…æ‹¬`seen`ã€`windows`å’Œ`dt`ï¼Œåˆ†åˆ«è¡¨ç¤ºå·²å¤„ç†çš„å›¾ç‰‡æ•°é‡ã€çª—å£åˆ—è¡¨å’Œæ—¶é—´æ¶ˆè€—åˆ—è¡¨ã€‚éå†datasetï¼Œæ•´ç†å›¾ç‰‡ä¿¡æ¯ã€‚

æ¥ç€æ˜¯å¯¹æ•°æ®é›†çš„å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†ï¼š

*   å°†å›¾ç‰‡è½¬åŒ–ä¸ºtensoræ ¼å¼ï¼Œæ”¾åˆ°deviceä¸Šï¼Œå¹¶è½¬æ¢ä¸ºFP16/32ã€‚
*   å°†åƒç´ å€¼0 ~ 255å½’ä¸€åŒ–ï¼Œå˜ä¸º0 ~ 1ï¼Œå¹¶ä¸ºæ‰¹å¤„ç†å¢åŠ ä¸€ç»´åº¦ï¼ˆbatchï¼‰ã€‚
*   è®°å½•æ—¶é—´æ¶ˆè€—å¹¶æ›´æ–°dt

#### 4.4.2 å¯¹æ¯å¼ å›¾ç‰‡/è§†é¢‘è¿›è¡Œå‰å‘æ¨ç†

```py
# Inference     é»˜è®¤False
        visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False
        # 2ã€å¯¹æ¯å¼ å›¾ç‰‡/è§†é¢‘è¿›è¡Œå‰å‘æ¨ç†
        pred = model(im, augment=augment, visualize=visualize)  # augmentï¼šæ•°æ®å¢å¼º pred:å¾—åˆ°æ£€æµ‹æ¡†
        t3 = time_sync()
        dt[1] += t3 - t2 
```

**è¿™é‡Œå¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œå‰å‘æ¨ç†ã€‚**
ç¬¬äºŒè¡Œä»£ç ï¼Œä½¿ç”¨`model`å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹ï¼Œ`augment`å’Œ`visualize`å‚æ•°æ˜¯ç”¨äºæŒ‡ç¤ºæ˜¯å¦åœ¨é¢„æµ‹æ—¶ä½¿ç”¨æ•°æ®å¢å¼ºå’Œå¯è§†åŒ–ã€‚
åé¢çš„ä»£ç è®°å½•äº†å½“å‰æ—¶é—´ï¼Œå¹¶è®¡ç®—**ä»ä¸Šä¸€ä¸ªæ—¶é—´ç‚¹åˆ°è¿™ä¸ªæ—¶é—´ç‚¹çš„æ—¶é—´å·®**ï¼Œç„¶åå°†è¿™ä¸ªæ—¶é—´å·®**åŠ åˆ°ä¸€ä¸ªåä¸ºdtçš„æ—¶é—´å·®åˆ—è¡¨ä¸­çš„ç¬¬äºŒä¸ªå…ƒç´ ä¸Š**ã€‚

#### 4.4.3 NMSåå¤„ç†é™¤å»å¤šä½™çš„æ¡†

```py
# NMS å»é™¤å¤šä½™çš„æ¡†
        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det) # 1,5ï¼ˆ5ä¸ªæ£€æµ‹æ¡†ï¼‰,6(å‰å››ä¸ªä¸ºåæ ‡ï¼Œç½®ä¿¡åº¦ï¼Œç±»åˆ«ï¼‰
        dt[2] += time_sync() - t3 
```

è¿™æ®µæ˜¯YOLOçš„ç»å…¸ä»£ç ï¼š**éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰**ï¼Œç”¨äºç­›é€‰é¢„æµ‹ç»“æœã€‚
å†æ¬¡æ›´æ–°è®¡æ—¶å™¨ï¼Œè®°å½•NMSæ‰€è€—è´¹çš„æ—¶é—´ã€‚

#### 4.4.4 é¢„æµ‹è¿‡ç¨‹

```py
# Process predictions  åç»­ä¿å­˜æˆ–è€…æ‰“å°é¢„æµ‹ä¿¡æ¯
        # å¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œå¤„ç†  å°†pred(ç›¸å¯¹img_size 640)æ˜ å°„å›åŸå›¾img0 size
        for i, det in enumerate(pred):  # per image
            seen += 1   # è®¡æ•°
            if webcam:  # batch_size >= 1
                p, im0, frame = path[i], im0s[i].copy(), dataset.count
                s += f'{i}: '
            else:
                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0) # å¦‚æœæœ‰frameåˆ™ä¸º0 
```

å¯¹ç­›é€‰åçš„ç»“æœè¿›è¡Œforå¾ªç¯éå†ï¼Œè¿™ä¸€æ®µä¸»è¦æ˜¯åˆ¤æ–­æ˜¯å¦é‡‡ç”¨ç½‘ç»œæ‘„åƒå¤´ã€‚

*   **å¦‚æœä½¿ç”¨çš„æ˜¯ç½‘ç»œæ‘„åƒå¤´**ï¼Œåˆ™ä»£ç ä¼šéå†æ¯ä¸ªå›¾åƒå¹¶å¤åˆ¶ä¸€ä»½å¤‡ä»½åˆ°å˜é‡`im0`ä¸­ï¼ŒåŒæ—¶å°†å½“å‰å›¾åƒçš„è·¯å¾„å’Œè®¡æ•°å™¨è®°å½•åˆ°å˜é‡`p`å’Œ`frame`ä¸­ã€‚æœ€åï¼Œå°†å½“å‰å¤„ç†çš„ç‰©ä½“ç´¢å¼•å’Œç›¸å…³ä¿¡æ¯è®°å½•åˆ°å­—ç¬¦ä¸²å˜é‡`s`ä¸­ã€‚

*   **å¦‚æœæ²¡æœ‰ä½¿ç”¨ç½‘ç»œæ‘„åƒå¤´**ï¼Œåˆ™ä¼šç›´æ¥ä½¿ç”¨`im0`å˜é‡ä¸­çš„å›¾åƒï¼Œå°†å›¾åƒè·¯å¾„å’Œè®¡æ•°å™¨è®°å½•åˆ°å˜é‡`p`å’Œ`frame`ä¸­ã€‚åŒæ—¶ï¼Œè¿˜ä¼šæ£€æŸ¥æ•°æ®é›†ä¸­æ˜¯å¦æœ‰"frame"å±æ€§ï¼Œå¦‚æœæœ‰ï¼Œåˆ™å°†å…¶å€¼è®°å½•åˆ°å˜é‡`frame`ä¸­ã€‚
    `det`æ˜¯predçš„æ¯ä¸€å¼ å›¾ç‰‡å†…å®¹ï¼Œdetå°±æ˜¯ä¸€å¼ å›¾ç‰‡çš„ä¸œè¥¿ï¼Œåœ¨åç»­çš„ä»£ç ä¸­ä¼šç”¨åˆ°ï¼Œè¿™é‡Œå…ˆæŒ‰ä¸‹ä¸è¡¨ã€‚

```py
p = Path(p)  # to Path
            save_path = str(save_dir / p.name)  # im.jpg
            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt
            s += '%gx%g ' % im.shape[2:]  # print string æ‰“å°å›¾ç‰‡ä¿¡æ¯
            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh   è·å¾—å®½å’Œé«˜çš„å¤§å°
            imc = im0.copy() if save_crop else im0  # for save_crop æ˜¯å¦æŠŠæ£€æµ‹æ¡†è£å‰ªä¸‹æ¥ä¿å­˜æˆä¸€å¼ å›¾ç‰‡
            annotator = Annotator(im0, line_width=line_thickness, example=str(names))	# ä»¥ä¾¿äºåœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ 
```

è¿™ä¸€éƒ¨åˆ†ä¸»è¦æ˜¯è·¯å¾„è½¬æ¢ï¼Œ`save_crop`æ¥é€‰æ‹©æ˜¯å¦æŠŠæ£€æµ‹æ¡†è£å‰ªä¸‹æ¥ä¿å­˜æˆä¸€å¼ å›¾ç‰‡ã€‚
æœ€ååˆ›å»ºäº†ä¸€ä¸ª`annotator`å¯¹è±¡ï¼Œä»¥ä¾¿äºåœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœã€‚

```py
 if len(det):
                # Rescale boxes from img_size to im0 size
                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()

                # Print results
                for c in det[:, -1].unique():   # ç»Ÿè®¡æ‰€æœ‰æ¡†çš„ç±»åˆ«
                    # è‹¥ä¸ºè¿™å‡ ä¸ªç±»åˆ«æ‰è¿›è¡Œç»“æœæ‰“å°
                    # if names[int(c)] == 'person' or names[int(c)] == 'bicycle' or names[int(c)] == 'car' or names[int(c)] == 'motorcycle' \
                    # or names[int(c)] == 'bus' or names[int(c)] == 'truck':
                        n = (det[:, -1] == c).sum()  # detections per class
                        s += f"{n}  {names[int(c)]}{'s' * (n > 1)}, "  # add to string
                    # else:   # å¦‚æœä¸æ˜¯ï¼Œåˆ™continue
                    #     continue 
```

è¿™ä¸€éƒ¨åˆ†æ˜¯åˆ¤æ–­æœ‰æ²¡æœ‰æ¡†ï¼Œå¦‚æœæœ‰ç‰©ä½“ï¼Œåˆ™ä¼šæ‰§è¡Œæ“ä½œã€‚

æˆ‘æ‰“æ³¨é‡Šçš„ä»£ç å¯ä»¥åªæ£€æµ‹éƒ¨åˆ†ç‰©ä½“ã€‚

é¦–å…ˆï¼Œ`scale_coords`ä¼šå°†æ£€æµ‹ç»“æœä¸­çš„ç‰©ä½“åæ ‡ä»ç¼©æ”¾çš„å›¾ç‰‡å¤§å°å˜å›å»ã€‚
ç„¶åéå†`det`çš„å†…å®¹ï¼Œå‰é¢è¯´äº†`det`å°±æ˜¯ä¸€å¼ å›¾ç‰‡çš„ä¿¡æ¯ï¼Œå…¶å®`det`é‡Œé¢åŒ…å«äº†æ¯ä¸€ä¸ªç‰©ä½“çš„ä¿¡æ¯ï¼Œå°†å…¶**ç±»åˆ«å’Œæ•°é‡**
æ·»åŠ åˆ°`s`å­—ç¬¦ä¸²ä¸­ã€‚æ–¹ä¾¿åé¢æ‰“å°ã€‚

#### 4.4.5 æ‰“å°ç›®æ ‡æ£€æµ‹ç»“æœ

```py
# Write results ä¿å­˜ç»“æœ
                for *xyxy, conf, cls in reversed(det):  # ä¿å­˜.txt    # reversedï¼šé€†åº
                    if save_txt:  # Write to file
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format
                        with open(f'{txt_path}.txt', 'a') as f:
                            f.write(('%g ' * len(line)).rstrip() % line + '\n')

                    if save_img or save_crop or view_img:  # Add bbox to image  ç”»åˆ°åŸå›¾ä¸Š
                        c = int(cls)  # integer class

                        # # # åªæ£€æµ‹å‡ ä¸ªç±»åˆ«:personã€bicycleã€carã€motorcycleã€busã€truck
                        # if names[int(cls)] == 'person' or names[int(cls)] == 'bicycle' or names[int(cls)] == 'car' or names[int(cls)] == 'motorcycle' \
                        #         or names[int(cls)] == 'bus' or names[int(cls)] == 'truck':
                        #
                        label = None if hide_labels else (names[c] if hide_conf else f'{names[c]}  {conf:.2f}')  # hide_labelséšè—æ ‡ç­¾   hide_conféšè—ç½®ä¿¡åº¦
                        annotator.box_label(xyxy, label, color=colors(c, True))
                        # else:
                        #     continue
                    if save_crop:   # æ˜¯å¦æˆªå–ç›®æ ‡æ¡†ä¸ºå›¾ç‰‡
                        save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True) 
```

å¦‚æœå­˜åœ¨ç›®æ ‡æ£€æµ‹ç»“æœï¼Œå°±ä¼šæ‰§è¡Œä¸‹ä¸€æ­¥æ“ä½œã€‚

è¿™é‡Œå°†detä¸­æ¯ä¸€ä¸ªç‰©ä½“çš„åæ ‡ä¿¡æ¯è¿›è¡Œè½¬æ¢ï¼Œé‡‡ç”¨çš„å‡½æ•°æ—¶`xyxy2xywh()`ï¼›
å¹¶å°†labelç”»åˆ°å›¾ç‰‡`annotator`ä¸Šï¼Œè°ƒç”¨çš„å‡½æ•°æ˜¯`box_label`ã€‚

* * *

å‰©ä¸‹çš„å°±æ˜¯ä¿å­˜å›¾ç‰‡çš„åŠŸèƒ½å’Œæ‰“å°åŠŸèƒ½çš„å®ç°äº†ï¼Œä¸æ˜¯å¾ˆéš¾ï¼Œå°±ä¸æƒ³å†™äº†ã€‚ä¸»è¦æ˜¯æˆ‘å†™è¿™ç¯‡åšå®¢çš„æ—¶å€™ï¼Œç”µè„‘å¤ªå¡äº†ï¼Œæˆ‘éƒ½é‡å¯ç½‘é¡µäº†å¥½å¤šæ¬¡äº†ã€‚è¿™ç”µè„‘çœŸå¾—æ¢äº†ï¼Œæ•£çƒ­æ˜¯çœŸçš„ä¸è¡Œï¼Œæ‰“æ¸¸æˆä¸è¡Œå°±ç®—äº†ï¼Œç°åœ¨è¿æœ€åŸºæœ¬çš„åŠå…¬ä¹Ÿéš¾ä»¥å®ç°ã€‚ä¸‹åŠå¹´å°±æ¢ï¼

* * *

`detect.py`ç®—æ˜¯å¤§æ¦‚å†™å®Œäº†å§ã€‚

è¿›è¡Œä¸€ä¸ªæ€»ç»“ï¼š

**è¿™ä¸€æ®µä»£ç å°±æ˜¯ç›®æ ‡æ£€æµ‹ç®—æ³•ä¸­çš„inferenceæ¨ç†é˜¶æ®µï¼Œå¤§è‡´æµç¨‹å°±æ˜¯1\. è½½å…¥æ•°æ®ï¼›2\. æ¨ç†ï¼›3\. NMSåå¤„ç†ï¼›4\. ç”»æ¡†ï¼›5\. ä¿å­˜ç»“æœã€æ‰“å°ä¿¡æ¯ã€‚**

ç°åœ¨æ˜¯20ï¼š01ï¼Œæ­£å¥½åˆ°äº†ä¸‹ç­æ—¶é—´ï¼Œå¥èº«å»äº†~
æ˜å¤©ç»§ç»­è‚ ~