<!--yml
category: æ¸¸æˆ
date: 2023-09-17 14:43:57
-->

# YOLOv5-6.xæºç åˆ†æï¼ˆä¹ï¼‰---- general.py

> æ¥æºï¼š[https://blog.csdn.net/weixin_51322383/article/details/130447757](https://blog.csdn.net/weixin_51322383/article/details/130447757)

### æ–‡ç« ç›®å½•

*   [å‰è¨€](#_1)
*   [ğŸš€YOLOv5-6.xæºç åˆ†æï¼ˆä¹ï¼‰---- general.py](#YOLOv56x_generalpy_7)
*   *   [0\. å¯¼åŒ…å’ŒåŸºæœ¬é…ç½®](#0__8)
    *   [1\. set_logging](#1_set_logging_69)
    *   [2\. init_seeds](#2_init_seeds_92)
    *   [3\. get_latest_run](#3_get_latest_run_117)
    *   [4\. colorstr](#4_colorstr_133)
    *   [5\. make_divisible](#5_make_divisible_164)
    *   [6\. one_cycle](#6_one_cycle_176)
    *   [7\. labels_to_class_weights](#7__labels_to_class_weights_193)
    *   [8\. labels_to_image_weights](#8_labels_to_image_weights_233)
    *   [9\. clip_coords](#9_clip_coords_249)
    *   [10\. scale_coords](#10_font_colorred_scale_coords_font_269)
    *   [11\. non_max_suppression](#11_font_colorred_non_max_suppression_font_296)
    *   [12\. increment_path](#12_increment_path_442)
    *   [æ€»ç»“](#_474)

# å‰è¨€

**è¿™ä¸ªæ–‡ä»¶æ˜¯YOLOv5çš„é€šç”¨å·¥å…·ç±»ï¼Œæ€»å…±æœ‰1Kå¤šè¡Œçš„ä»£ç ï¼Œéå¸¸åºå¤§ï¼Œæˆ‘ä¼šåˆ—å‡ºå¤§éƒ¨åˆ†å¸¸ç”¨çš„ï¼Œæœ€ä¸»è¦çš„æ˜¯è¦æŒæ¡NMSï¼Œè¿™æ˜¯åå¤„ç†çš„æ ¸å¿ƒä»£ç ã€‚**

**å¯¼èˆª**ï¼š[YOLOv5-6.xæºç åˆ†æ å…¨æµç¨‹è®°å½•](https://blog.csdn.net/weixin_51322383/article/details/130353834?spm=1001.2014.3001.5502)

* * *

# ğŸš€YOLOv5-6.xæºç åˆ†æï¼ˆä¹ï¼‰---- general.py

## 0\. å¯¼åŒ…å’ŒåŸºæœ¬é…ç½®

```py
import contextlib   # pythonä¸Šä¸‹æ–‡ç®¡ç†å™¨   æ‰§è¡Œwithâ€¦asâ€¦çš„æ—¶å€™è°ƒç”¨contextlib
import glob         # ä»…æ”¯æŒéƒ¨åˆ†é€šé…ç¬¦çš„æ–‡ä»¶æœç´¢æ¨¡å—
import inspect
import logging      # æ—¥å¿—æ¨¡å—
import math         # æ•°å­¦å…¬å¼
import os           # æ“ä½œç³»ç»Ÿäº¤äº’
import platform     # æä¾›è·å–æ“ä½œç³»ç»Ÿç›¸å…³ä¿¡æ¯çš„æ¨¡å—
import random       # éšæœºæ•°
import re           # ç”¨æ¥åŒ¹é…å­—ç¬¦ä¸²ï¼ˆåŠ¨æ€ã€æ¨¡ç³Šï¼‰çš„æ¨¡å—
import shutil       # æ–‡ä»¶æ“ä½œæ¨¡å—
import signal       # ä¿¡å·å¤„ç†æ¨¡å—
import threading    # å¤šçº¿ç¨‹
import time         # æ—¶é—´æ¨¡å—
import urllib       # ç”¨äºæ“ä½œç½‘é¡µURL, å¹¶å¯¹ç½‘é¡µçš„å†…å®¹è¿›è¡ŒæŠ“å–å¤„ç†  å¦‚urllib.parse: è§£æurl
from datetime import datetime
from itertools import repeat     # å¾ªç¯å™¨æ¨¡å—  åˆ›å»ºä¸€ä¸ªè¿­ä»£å™¨ï¼Œé‡å¤ç”Ÿæˆobject
from multiprocessing.pool import ThreadPool # çº¿ç¨‹æ± 
from pathlib import Path                    # Pathå°†strè½¬æ¢ä¸ºPathå¯¹è±¡ ä½¿å­—ç¬¦ä¸²è·¯å¾„æ˜“äºæ“ä½œçš„æ¨¡å—
from subprocess import check_output         # åˆ›å»ºä¸€ä¸ªå­è¿›ç¨‹å†å‘½ä»¤è¡Œæ‰§è¡Œ..., æœ€åè¿”å›æ‰§è¡Œç»“æœ(æ–‡ä»¶)
from typing import Optional
from zipfile import ZipFile

import cv2
import numpy as np
import pandas as pd
import pkg_resources as pkg # æŸ¥æ‰¾
import torch        # pytorchæ¡†æ¶
import torchvision  # pytorchè¾…åŠ©å·¥å…·
import yaml     # yamlé…ç½®æ–‡ä»¶è¯»å†™æ¨¡å—

from utils.downloads import gsutil_getsize
from utils.metrics import box_iou, fitness

FILE = Path(__file__).resolve()
ROOT = FILE.parents[1]  # YOLOv5 root directory
RANK = int(os.getenv('RANK', -1))

# Settings
DATASETS_DIR = ROOT.parent / 'datasets'  # YOLOv5 datasets directory
NUM_THREADS = min(8, max(1, os.cpu_count() - 1))  # number of YOLOv5 multiprocessing threads
AUTOINSTALL = str(os.getenv('YOLOv5_AUTOINSTALL', True)).lower() == 'true'  # global auto-install mode
VERBOSE = str(os.getenv('YOLOv5_VERBOSE', True)).lower() == 'true'  # global verbose mode
FONT = 'Arial.ttf'  # https://ultralytics.com/assets/Arial.ttf

# è®¾ç½®è¿è¡Œç›¸å…³çš„ä¸€äº›åŸºæœ¬çš„é…ç½®  Settings
# æ§åˆ¶printæ‰“å°torch.tensoræ ¼å¼è®¾ç½®  tensorç²¾åº¦ä¸º5(å°æ•°ç‚¹å5ä½)  æ¯è¡Œå­—ç¬¦æ•°ä¸º320ä¸ª  æ˜¾ç¤ºæ–¹æ³•ä¸ºlong
torch.set_printoptions(linewidth=320, precision=5, profile='long')
# æ§åˆ¶printæ‰“å°np.arrayæ ¼å¼è®¾ç½®  ç²¾åº¦ä¸º5  æ¯è¡Œå­—ç¬¦æ•°ä¸º320ä¸ª  format short g, %precision=5
np.set_printoptions(linewidth=320, formatter={'float_kind': '{:11.5g}'.format})  # format short g, %precision=5
# pandasçš„æœ€å¤§æ˜¾ç¤ºè¡Œæ•°æ˜¯10
pd.options.display.max_columns = 10
# é˜»æ­¢opencvå‚ä¸å¤šçº¿ç¨‹(ä¸ Pytorchçš„ Dataloaderä¸å…¼å®¹)
cv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader) ä½¿ç”¨ä¸€ä¸ªçº¿ç¨‹
# ç¡®å®šæœ€å¤§çš„çº¿ç¨‹æ•° è¿™é‡Œè¢«é™åˆ¶åœ¨äº†8
os.environ['NUMEXPR_MAX_THREADS'] = str(NUM_THREADS)  # NumExpr max threads
os.environ['OMP_NUM_THREADS'] = '1' if platform.system() == 'darwin' else str(NUM_THREADS)  # OpenMP (PyTorch and SciPy) 
```

## 1\. set_logging

```py
# è®¾ç½®æ—¥å¿—ä¿å­˜ # å¯¹æ—¥å¿—çš„è®¾ç½®(formatã€level)ç­‰è¿›è¡Œåˆå§‹åŒ–
def set_logging(name=None, verbose=VERBOSE):
    # Sets level and returns logger
    # å…ˆåˆ¤æ–­æ˜¯å¦æ˜¯kaggleç¯å¢ƒ
    if is_kaggle():
        for h in logging.root.handlers:
            logging.root.removeHandler(h)  # remove all handlers associated with the root logger object
    rank = int(os.getenv('RANK', -1))  # rank in world for Multi-GPU trainings
    # è®¾ç½®æ—¥å¿—çº§åˆ«  rankä¸ä¸º-1æˆ–0æ—¶è®¾ç½®è¾“å‡ºçº§åˆ«levelä¸ºWARN  ä¸º-1æˆ–0æ—¶è®¾ç½®çº§åˆ«ä¸ºINFO
    level = logging.INFO if verbose and rank in {-1, 0} else logging.ERROR
    log = logging.getLogger(name)
    log.setLevel(level)
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter("%(message)s"))
    handler.setLevel(level)
    log.addHandler(handler) 
```

**è¿™ä¸ªå‡½æ•°ä¸€èˆ¬ç”¨åœ¨`train.py`ã€`val.py`ç­‰æ–‡ä»¶çš„mainå‡½æ•°ç¬¬ä¸€æ­¥ï¼Œè¿›è¡Œæ—¥å¿—ç­‰çº§ã€æ ¼å¼çš„åˆå§‹åŒ–ã€‚**

## 2\. init_seeds

```py
# åˆå§‹åŒ–éšæœºç§å­
def init_seeds(seed=0, deterministic=False):
    # Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html
    # cudnn seed 0 settings are slower and more reproducible, else faster and less reproducible
    import torch.backends.cudnn as cudnn
    # cudnn.deterministic=True å¯é¿å…éšæœºæ€§
    if deterministic and check_version(torch.__version__, '1.12.0'):  # https://github.com/ultralytics/yolov5/pull/8213
        torch.use_deterministic_algorithms(True)
        os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
        os.environ['PYTHONHASHSEED'] = str(seed)

    random.seed(seed)           # è®¾ç½®éšæœºæ•° é’ˆå¯¹ä½¿ç”¨random.random()ç”Ÿæˆéšæœºæ•°çš„æ—¶å€™ç›¸åŒ
    np.random.seed(seed)        # è®¾ç½®éšæœºæ•° é’ˆå¯¹ä½¿ç”¨np.random.rand()ç”Ÿæˆéšæœºæ•°çš„æ—¶å€™ç›¸åŒ
    torch.manual_seed(seed)
    # cudnn.benchmark =True éšæœºæ¨¡å¼
    cudnn.benchmark, cudnn.deterministic = (False, True) if seed == 0 else (True, False)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # for Multi-GPU, exception safe 
```

**è¿™ä¸ªå‡½æ•°æ˜¯ä½¿ç”¨random.random()ã€np.random.rand()ã€init_torch_seedsï¼ˆè°ƒç”¨torch_utils.pyä¸­çš„å‡½æ•°ï¼‰ç­‰ç”Ÿæˆä¸€ç³»åˆ—çš„éšæœºæ•°ç§å­ï¼Œä»¥ä¿è¯ç»“æœçš„å¯å¤ç°æ€§ã€‚**

## 3\. get_latest_run

```py
# è·å–æœ€è¿‘è®­ç»ƒçš„æƒé‡ä¿¡æ¯ last.pt  # è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯æŸ¥æ‰¾æœ€è¿‘ä¿å­˜çš„æƒé‡æ–‡ä»¶ last*.ptï¼Œç”¨ä»¥è¿›è¡Œæ–­ç‚¹ç»­è®­ã€‚
def get_latest_run(search_dir='.'):
    """ç”¨åœ¨train.pyæŸ¥æ‰¾æœ€è¿‘çš„ptæ–‡ä»¶è¿›è¡Œæ–­ç‚¹ç»­è®­
       ç”¨äºè¿”å›è¯¥é¡¹ç›®ä¸­æœ€è¿‘çš„æ¨¡å‹ 'last.pt'å¯¹åº”çš„è·¯å¾„
       :params search_dir: è¦æœç´¢çš„æ–‡ä»¶çš„æ ¹ç›®å½• é»˜è®¤æ˜¯ '.'  è¡¨ç¤ºæœç´¢è¯¥é¡¹ç›®ä¸­çš„æ–‡ä»¶
    """
    # Return path to most recent 'last.pt' in /runs (i.e. to --resume from)
    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)  # ä¸ºTrueä¼šé€’å½’åŒ¹é…è·¯å¾„
    return max(last_list, key=os.path.getctime) if last_list else '' 
```

è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯è·å–æœ€è¿‘è®­ç»ƒçš„æƒé‡ä¿¡æ¯ last.pt ï¼Œä»¥è¿›è¡Œæ–­ç‚¹ç»­è®­ã€‚ç”¨åœ¨`train.py`ä¸­ã€‚

## 4\. colorstr

```py
def colorstr(*input):
    # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e.  colorstr('blue', 'hello world')
    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # color arguments, string
    colors = {
        'black': '\033[30m',  # basic colors
        'red': '\033[31m',
        'green': '\033[32m',
        'yellow': '\033[33m',
        'blue': '\033[34m',
        'magenta': '\033[35m',
        'cyan': '\033[36m',
        'white': '\033[37m',
        'bright_black': '\033[90m',  # bright colors
        'bright_red': '\033[91m',
        'bright_green': '\033[92m',
        'bright_yellow': '\033[93m',
        'bright_blue': '\033[94m',
        'bright_magenta': '\033[95m',
        'bright_cyan': '\033[96m',
        'bright_white': '\033[97m',
        'end': '\033[0m',  # misc
        'bold': '\033[1m',
        'underline': '\033[4m'}
    return ''.join(colors[x] for x in args) + f'{string}' + colors['end'] 
```

**è¿™ä¸ªå‡½æ•°æ˜¯å°†è¾“å‡ºçš„å¼€å¤´å’Œç»“å°¾åŠ ä¸Šé¢œè‰²ï¼Œä½¿å‘½ä»¤è¡Œè¾“å‡ºæ˜¾ç¤ºä¼šæ›´åŠ å¥½çœ‹ã€‚**

## 5\. make_divisible

```py
def make_divisible(x, divisor):
    # Returns nearest x divisible by divisor
    if isinstance(divisor, torch.Tensor):
        divisor = int(divisor.max())  # to int
    return math.ceil(x / divisor) * divisor 
```

è¿™ä¸ªå‡½æ•°ç”¨æ¥å–å¤§äºç­‰äºxä¸”æ˜¯divisorçš„æœ€å°å€æ•°ï¼Œä¿è¯è¾“å…¥çš„xï¼ˆä¸€èˆ¬æ˜¯é•¿å®½ï¼‰æ˜¯ç®—æ³•çš„æœ€å¤§ä¸‹é‡‡æ ·ç‡çš„å€æ•°ã€‚

## 6\. one_cycle

```py
def one_cycle(y1=0.0, y2=1.0, steps=100):
    """ç”¨åœ¨train.pyçš„å­¦ä¹ ç‡è¡°å‡ç­–ç•¥æ¨¡å—
        one_cycle lr  lrå…ˆå¢åŠ , å†å‡å°‘, å†ä»¥æ›´å°çš„æ–œç‡å‡å°‘
        è®ºæ–‡: https://arxiv.org/pdf/1803.09820.pdf
        """
    # lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf
    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1 
```

**è¿™ä¸ªå‡½æ•°æ˜¯ä¸€ç§ç‰¹æ®Šçš„å­¦ä¹ ç‡è¡°å‡ç­–ç•¥ï¼Œåœ¨train.pyçš„å­¦ä¹ ç‡è¡°å‡ç­–ç•¥æ¨¡å—ä¸­ä½¿ç”¨ã€‚ï¼ˆä½™å¼¦é€€ç«å­¦ä¹ ç‡ï¼‰**

è®ºæ–‡ï¼š [one_cycle](https://arxiv.org/pdf/1803.09820.pdf)

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/1136b2ac7db9754e681744f8cf78abe0.png)

## 7\. labels_to_class_weights

```py
def labels_to_class_weights(labels, nc=80):
    """ç”¨åœ¨train.pyä¸­  å¾—åˆ°æ¯ä¸ªç±»åˆ«çš„æƒé‡   æ ‡ç­¾é¢‘ç‡é«˜çš„ç±»æƒé‡ä½
        ä»è®­ç»ƒ(gt)æ ‡ç­¾è·å¾—æ¯ä¸ªç±»çš„æƒé‡  æ ‡ç­¾é¢‘ç‡é«˜çš„ç±»æƒé‡ä½
        Get class weights (inverse frequency) from training labels
        :params labels: gtæ¡†çš„æ‰€æœ‰çœŸå®æ ‡ç­¾labels
        :params nc: æ•°æ®é›†çš„ç±»åˆ«æ•°
        :return torch.from_numpy(weights): æ¯ä¸€ä¸ªç±»åˆ«æ ¹æ®labelså¾—åˆ°çš„å æ¯”(æ¬¡æ•°è¶Šå¤šæƒé‡è¶Šå°) tensor
        """
    # Get class weights (inverse frequency) from training labels
    if labels[0] is None:  # no labels loaded
        return torch.Tensor()

    labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) for COCO
    # classes: æ‰€æœ‰æ ‡ç­¾å¯¹åº”çš„ç±»åˆ«labels   labels[:, 0]: ç±»åˆ«   .astype(np.int): å–æ•´
    classes = labels[:, 0].astype(int)  # labels = [class xywh]
    # weight: è¿”å›æ¯ä¸ªç±»åˆ«å‡ºç°çš„æ¬¡æ•° [1, nc]
    weights = np.bincount(classes, minlength=nc)  # occurrences per class

    # Prepend gridpoint count (for uCE training)
    # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # gridpoints per image
    # weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # prepend gridpoints to start

    # å°†å‡ºç°æ¬¡æ•°ä¸º0çš„ç±»åˆ«æƒé‡å…¨éƒ¨å–1
    weights[weights == 0] = 1  # replace empty bins with 1
    # å…¶ä»–æ‰€æœ‰çš„ç±»åˆ«çš„æƒé‡å…¨éƒ¨å–æ¬¡æ•°çš„å€’æ•°  number of targets per class
    weights = 1 / weights  # number of targets per class
    # normalize æ±‚å‡ºæ¯ä¸€ç±»åˆ«çš„å æ¯”
    weights /= weights.sum()  # normalize
    return torch.from_numpy(weights).float() 
```

**è¿™ä¸ªå‡½æ•°å°±æ˜¯å †labelsä¸­çš„æ¯ä¸€ä¸ªç±»åˆ«æ±‚ä¸€ä¸ªæƒé‡ï¼Œæ ‡ç­¾é¢‘ç‡è¶Šé«˜çš„ï¼Œæƒé‡è¶Šä½ã€‚å¦‚æœæŸä¸ªç±»åˆ«æ•°é‡ä¸º0ï¼Œåˆ™ç½®ä¸º1**

æ¯”å¦‚è¯´ï¼š

classesä¸º[2 1 3 4 4 3]ï¼Œweightsä¸º[0 1 1 2 2]ï¼Œå³å°†æ¯ä¸ªç±»åˆ«çš„æ•°é‡ä½œä¸ºåˆå§‹åŒ–æƒé‡ï¼Œæ¥ä¸‹æ¥å°†æ‰€æœ‰çš„0ç½®æ¢ä¸º1ï¼Œweightsä¸º[1 1 1 2 2]ï¼Œå†å–å€’æ•°[1 1 1 0.5 0.5]ï¼Œå½’ä¸€åŒ–æƒé‡å¹¶è¿”å›ã€‚

## 8\. labels_to_image_weights

```py
def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):
    # Produces image weights based on class_weights and image contents
    # Usage: index = random.choices(range(n), weights=image_weights, k=1)  # weighted image sample
    # [80] -> [1, 80]
    # æ•´ä¸ªæ•°æ®é›†çš„æ¯ä¸ªç±»åˆ«æƒé‡[1, 80] *  æ¯å¼ å›¾ç‰‡çš„æ¯ä¸ªç±»åˆ«å‡ºç°çš„æ¬¡æ•°[num_labels, 80] = å¾—åˆ°æ¯ä¸€å¼ å›¾ç‰‡æ¯ä¸ªç±»å¯¹åº”çš„æƒé‡[128, 80]
    # å¦å¤–æ³¨æ„: è¿™é‡Œä¸æ˜¯çŸ©é˜µç›¸ä¹˜, æ˜¯å…ƒç´ ç›¸ä¹˜ [1, 80] å’Œæ¯ä¸€è¡Œå›¾ç‰‡çš„æ¯ä¸ªç±»åˆ«å‡ºç°çš„æ¬¡æ•° [1, 80] åˆ†åˆ«æŒ‰å…ƒç´ ç›¸ä¹˜
    # å†sum(1): æŒ‰è¡Œç›¸åŠ   å¾—åˆ°æœ€ç»ˆimage_weights: å¾—åˆ°æ¯ä¸€å¼ å›¾ç‰‡å¯¹åº”çš„é‡‡æ ·æƒé‡[128]
    class_counts = np.array([np.bincount(x[:, 0].astype(int), minlength=nc) for x in labels])
    return (class_weights.reshape(1, nc) * class_counts).sum(1) 
```

è¿™ä¸ªå‡½æ•°æ˜¯åˆ©ç”¨æ¯å¼ å›¾ç‰‡çœŸå®gtæ¡†çš„çœŸå®æ ‡ç­¾labelså’Œä¸Šä¸€æ­¥labels_to_class_weightså¾—åˆ°çš„æ¯ä¸ªç±»åˆ«çš„æƒé‡å¾—åˆ°æ•°æ®é›†ä¸­æ¯å¼ å›¾ç‰‡å¯¹åº”çš„æƒé‡ã€‚

## 9\. clip_coords

```py
def clip_coords(boxes, shape):
    # Clip bounding xyxy bounding boxes to image shape (height, width)
    if isinstance(boxes, torch.Tensor):  # faster individually
        # .clamp_(min, max): å°†å–æ•´é™å®šåœ¨(min, max)ä¹‹é—´, è¶…å‡ºè¿™ä¸ªèŒƒå›´è‡ªåŠ¨åˆ’åˆ°è¾¹ç•Œä¸Š
        boxes[:, 0].clamp_(0, shape[1])  # x1
        boxes[:, 1].clamp_(0, shape[0])  # y1
        boxes[:, 2].clamp_(0, shape[1])  # x2
        boxes[:, 3].clamp_(0, shape[0])  # y2
    else:  # np.array (faster grouped)  è¶…å‡ºè¿™ä¸ªèŒƒå›´è‡ªåŠ¨åˆ’åˆ°è¾¹ç•Œä¸Š
        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, shape[1])  # x1, x2
        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, shape[0])  # y1, y2 
```

**è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯ï¼šå°†boxesçš„åæ ‡(x1y1x2y2 å·¦ä¸Šè§’å³ä¸‹è§’)é™å®šåœ¨å›¾åƒçš„å°ºå¯¸(img_shape hw)å†…ï¼Œé˜²æ­¢å‡ºç•Œã€‚**

**è¿™ä¸ªå‡½æ•°ä¼šç”¨åœ¨ä¸‹é¢çš„xyxy2xywhnã€save_one_boxdç­‰å‡½æ•°ä¸­ï¼Œå¾ˆé‡è¦ï¼Œå¿…é¡»æŒæ¡ã€‚**

## 10\. scale_coords

```py
def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):
    # Rescale coords (xyxy) from img1_shape to img0_shape
    # ratio_padä¸ºç©ºå°±å…ˆç®—æ”¾ç¼©æ¯”ä¾‹gainå’Œpadå€¼ calculate from img0_shape
    if ratio_pad is None:  # calculate from img0_shape
        # gain  = old / new  å–é«˜å®½ç¼©æ”¾æ¯”ä¾‹ä¸­è¾ƒå°çš„,ä¹‹åè¿˜å¯ä»¥å†pad  å¦‚æœç›´æ¥å–å¤§çš„, è£å‰ªå°±å¯èƒ½å‡å»ç›®æ ‡
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new
        # wh padding  whä¸­æœ‰ä¸€ä¸ªä¸º0  ä¸»è¦æ˜¯padå¦ä¸€ä¸ª
        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding
    else:
        gain = ratio_pad[0][0]
        pad = ratio_pad[1]

    coords[:, [0, 2]] -= pad[0]  # x padding
    coords[:, [1, 3]] -= pad[1]  # y padding
    coords[:, :4] /= gain
    # é˜²æ­¢æ”¾ç¼©åçš„åæ ‡è¿‡ç•Œ è¾¹ç•Œå¤„ç›´æ¥å‰ªåˆ‡
    clip_coords(coords, img0_shape)
    return coords 
```

**è¿™ä¸ªå‡½æ•°æ˜¯å°†åæ ‡coords(x1y1x2y2)ä»img1_shapeå°ºå¯¸ç¼©å›åˆ°img0_shapeå°ºå¯¸ã€‚xçš„æ­£åæ ‡æ˜¯å‘å³ï¼Œyçš„æ­£åæ ‡æ˜¯å‘ä¸‹ã€‚è¿™ä¸ªå‡½æ•°ä¹Ÿæ˜¯å¾ˆé‡è¦çš„ã€‚**

**å…ˆå°†æ¨ªçºµåæ ‡å‡å»åç§»é‡ï¼Œå†ç»Ÿä¸€é™¤ä»¥gainè·å–æ–°çš„å€¼ï¼Œæœ€åå†é™å®šåœ¨img0çš„å¤§å°å†…ã€‚**

## 11\. non_max_suppression

NMSï¼Œéæå¤§å€¼æŠ‘åˆ¶ï¼Œæ˜¯ç›®æ ‡æ£€æµ‹é¢†åŸŸæœ€åŸºæœ¬çš„ç®—æ³•æ“ä½œäº†ã€‚è¿™ç¯‡åšå®¢ï¼Œå…¶ä»–çš„å‡½æ•°å¯ä»¥éƒ½åªæ˜¯çœ‹çœ‹ï¼Œä½†è¿™ä¸ªå‡½æ•°å¿…é¡»å¿…é¡»å¿…é¡»æŒæ¡ï¼

**è¿™é‡Œå€Ÿå¦ä¸€ä½åšä¸»çš„ä¸€å¼ æ•´ä½“æµç¨‹å›¾ï¼š**

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/b4b38a085256b46dcc77dbc566e393e5.png)

åœ¨æ¨ç†é˜¶æ®µï¼Œåå¤„ç†æˆ‘ä»¬ä¼šç”¨åˆ°å››ä¸ªå‡½æ•°ï¼Œåˆ†åˆ«æ˜¯

*   `letterbox`ï¼šå°†å›¾ç‰‡ç¼©æ”¾åˆ°æŒ‡å®šå¤§å°
*   `NMS`ï¼šå»é™¤å¤šä½™çš„æ¡†
*   `scale_coords`ï¼šå°†å›¾ç‰‡è¿˜åŸå›åŸå¤§å°
*   `draw_box`ï¼šå°†é¢„æµ‹æ¡†ç”»å‡ºæ¥

è€ŒNMSçš„æ“ä½œæµç¨‹æ˜¯ï¼š

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/f501eadfc1ef3798f3de50545c21a21c.png)

æ­¥éª¤ä¸€ï¼šå°†æ‰€æœ‰çŸ©å½¢æ¡†æŒ‰ç…§ä¸åŒçš„ç±»åˆ«æ ‡ç­¾åˆ†ç»„ï¼Œç»„å†…æŒ‰ç…§ç½®ä¿¡åº¦é«˜ä½å¾—åˆ†è¿›è¡Œæ’åºï¼›
æ­¥éª¤äºŒï¼šå°†æ­¥éª¤ä¸€ä¸­å¾—åˆ†æœ€é«˜çš„çŸ©å½¢æ¡†æ‹¿å‡ºæ¥ï¼Œéå†å‰©ä½™çŸ©å½¢æ¡†ï¼Œè®¡ç®—ä¸å½“å‰å¾—åˆ†æœ€é«˜çš„çŸ©å½¢æ¡†çš„äº¤å¹¶æ¯”ï¼Œå°†å‰©ä½™çŸ©å½¢æ¡†ä¸­å¤§äºè®¾å®šçš„IOUé˜ˆå€¼çš„æ¡†åˆ é™¤ï¼›
æ­¥éª¤ä¸‰ï¼šå°†æ­¥éª¤äºŒç»“æœä¸­ï¼Œå¯¹å‰©ä½™çš„çŸ©å½¢æ¡†é‡å¤æ­¥éª¤äºŒæ“ä½œï¼Œç›´åˆ°å¤„ç†å®Œæ‰€æœ‰çŸ©å½¢æ¡†ï¼›

```py
def non_max_suppression(prediction,
                        conf_thres=0.25,
                        iou_thres=0.45,
                        classes=None,
                        agnostic=False, # è¿›è¡Œnmsæ˜¯å¦ä¹Ÿå»é™¤ä¸åŒç±»åˆ«ä¹‹é—´çš„æ¡† é»˜è®¤False
                        multi_label=False,
                        labels=(),
                        max_det=300):
    """Non-Maximum Suppression (NMS) on inference results to reject overlapping bounding boxes
    Params:
        prediction: [batch, num_anchors(3ä¸ªyoloé¢„æµ‹å±‚), (x+y+w+h+1+num_classes)] = [1, 18900, 25]  3ä¸ªanchorçš„é¢„æµ‹ç»“æœæ€»å’Œ
    Returns:
         list of detections, on (n,6) tensor per image [xyxy, conf, cls]
    """

    bs = prediction.shape[0]  # batch size
    nc = prediction.shape[2] - 5  # number of classes
    xc = prediction[..., 4] > conf_thres  # candidates é€‰å‡ºå¤§äºé˜ˆå€¼çš„æ¡†

    # Checks æ£€æŸ¥ä¼ å…¥çš„conf_threså’Œiou_thresä¸¤ä¸ªé˜ˆå€¼æ˜¯å¦ç¬¦åˆèŒƒå›´
    assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'
    assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'

    # Settings è®¾ç½®ä¸€äº›å˜é‡
    # min_wh = 2  # (pixels) minimum box width and height
    max_wh = 7680  # (pixels) maximum box width and height  é¢„æµ‹ç‰©ä½“å®½åº¦å’Œé«˜åº¦çš„å¤§å°èŒƒå›´
    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms() # æ¯ä¸ªå›¾åƒæœ€å¤šæ£€æµ‹ç‰©ä½“çš„ä¸ªæ•°
    time_limit = 0.3 + 0.03 * bs  # seconds to quit after       nmsæ‰§è¡Œæ—¶é—´é˜ˆå€¼ è¶…è¿‡è¿™ä¸ªæ—¶é—´å°±é€€å‡ºäº†
    redundant = True  # require redundant detections        æ˜¯å¦éœ€è¦å†—ä½™çš„detections
    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)
    merge = False  # use merge-NMS  use merge-NMS å¤šä¸ªbounding boxç»™å®ƒä»¬ä¸€ä¸ªæƒé‡è¿›è¡Œèåˆ  é»˜è®¤False

    t = time.time()     # å½“å‰æ—¶é—´
    # å­˜æ”¾æœ€ç»ˆç­›é€‰åçš„é¢„æµ‹æ¡†ç»“æœ
    output = [torch.zeros((0, 6), device=prediction.device)] * bs
    for xi, x in enumerate(prediction):  # image index, image inference éå†æ‰€æœ‰æ¡†
        # Apply constraints
        # ç¬¬ä¸€å±‚è¿‡æ»¤ è™‘é™¤è¶…å°anchoræ ‡å’Œè¶…å¤§anchor   x=[18900, 25]
        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height

        # ç¬¬äºŒå±‚è¿‡æ»¤ æ ¹æ®conf_thresè™‘é™¤èƒŒæ™¯ç›®æ ‡(obj_conf<conf_thres 0.1çš„ç›®æ ‡ ç½®ä¿¡åº¦æä½çš„ç›®æ ‡)  x=[59, 25]
        x = x[xc[xi]]  # confidence

        # {list: bs} ç¬¬ä¸€å¼ å›¾ç‰‡çš„target[17, 5] ç¬¬äºŒå¼ [1, 5] ç¬¬ä¸‰å¼ [7, 5] ç¬¬å››å¼ [6, 5]
        # Cat apriori labels if autolabelling   è‡ªåŠ¨æ ‡æ³¨labelæ—¶è°ƒç”¨  ä¸€èˆ¬ä¸ç”¨
        if labels and len(labels[xi]):
            lb = labels[xi]
            v = torch.zeros((len(lb), nc + 5), device=x.device)
            v[:, :4] = lb[:, 1:5]  # box
            v[:, 4] = 1.0  # conf
            v[range(len(lb)), lb[:, 0].long() + 5] = 1.0  # cls
            x = torch.cat((x, v), 0)

        # If none remain process next image  ç»è¿‡å‰ä¸¤å±‚è¿‡æ»¤åå¦‚æœè¯¥feature mapæ²¡æœ‰ç›®æ ‡æ¡†äº†ï¼Œå°±ç»“æŸè¿™è½®ç›´æ¥è¿›è¡Œä¸‹ä¸€å¼ å›¾
        if not x.shape[0]:
            continue

        # Compute conf è®¡ç®—conf_score
        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf

        # Box (center x, center y, width, height) to (x1, y1, x2, y2)   å·¦ä¸Šè§’ å³ä¸‹è§’   [59, 4]
        box = xywh2xyxy(x[:, :4])

        # Detections matrix nx6 (xyxy, conf, cls)
        if multi_label:
            # ç¬¬ä¸‰è½®è¿‡æ»¤:é’ˆå¯¹æ¯ä¸ªç±»åˆ«score(obj_conf * cls_conf) > conf_thres    [59, 6] -> [51, 6]
            # è¿™é‡Œä¸€ä¸ªæ¡†æ˜¯æœ‰å¯èƒ½æœ‰å¤šä¸ªç‰©ä½“çš„ï¼Œæ‰€ä»¥è¦ç­›é€‰
            # nonzero: è·å¾—çŸ©é˜µä¸­çš„é0(True)æ•°æ®çš„ä¸‹æ ‡  a.t(): å°†açŸ©é˜µæ‹†å¼€
            # i: ä¸‹æ ‡ [43]   j: ç±»åˆ«index [43] è¿‡æ»¤äº†ä¸¤ä¸ªscoreå¤ªä½çš„
            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T  # as_tuple = Falseï¼š è¾“å‡ºçš„æ¯ä¸€è¡Œä¸ºéé›¶å…ƒç´ çš„ç´¢å¼•
            # pred = [43, xyxy+score+class] [43, 6]
            # unsqueeze(1): [43] => [43, 1] add batch dimension
            # box[i]: [43,4] xyxy
            # pred[i, j + 5].unsqueeze(1): [43,1] score  å¯¹æ¯ä¸ªi,å–ç¬¬ï¼ˆj+5ï¼‰ä¸ªä½ç½®çš„å€¼ï¼ˆç¬¬jä¸ªclassçš„å€¼cla_confï¼‰
            # j.float().unsqueeze(1): [43,1] class
            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)
        else:  # best class only
            conf, j = x[:, 5:].max(1, keepdim=True) # ä¸€ä¸ªç±»åˆ«ç›´æ¥å–åˆ†æ•°æœ€å¤§ç±»çš„å³å¯
            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]

        # Filter by class   æ˜¯å¦åªä¿ç•™ç‰¹å®šçš„ç±»åˆ«  é»˜è®¤None  ä¸æ‰§è¡Œè¿™é‡Œ
        if classes is not None:
            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]

        # Apply finite constraint
        # if not torch.isfinite(x).all():
        #     x = x[torch.isfinite(x).all(1)]

        # Check shape
        n = x.shape[0]  # number of boxes
        if not n:  # no boxes å¦‚æœç»è¿‡ç¬¬ä¸‰è½®è¿‡æ»¤è¯¥feature mapæ²¡æœ‰ç›®æ ‡æ¡†äº†ï¼Œå°±ç»“æŸè¿™è½®ç›´æ¥è¿›è¡Œä¸‹ä¸€å¼ å›¾
            continue
        elif n > max_nms:  # excess boxes å¦‚æœç»è¿‡ç¬¬ä¸‰è½®è¿‡æ»¤è¯¥feature mapè¿˜æœ‰å¾ˆå¤šæ¡†(>max_nms)   å°±éœ€è¦æ’åº
            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence ç½®ä¿¡åº¦æ’åº

        # ç¬¬4è½®è¿‡æ»¤ Batched NMS [51, 6] -> [5, 6]
        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes
        # åšä¸ªåˆ‡ç‰‡ å¾—åˆ°boxeså’Œscores   ä¸åŒç±»åˆ«çš„boxä½ç½®ä¿¡æ¯åŠ ä¸Šä¸€ä¸ªå¾ˆå¤§çš„æ•°ä½†åˆä¸åŒçš„æ•°c
        # è¿™æ ·ä½œéæå¤§æŠ‘åˆ¶çš„æ—¶å€™ä¸åŒç±»åˆ«çš„æ¡†å°±ä¸ä¼šæºå’Œåˆ°ä¸€å—äº†  è¿™æ˜¯ä¸€ä¸ªä½œnmsæŒºå·§å¦™çš„æŠ€å·§
        boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores
        # è¿”å›nmsè¿‡æ»¤åçš„bounding box(boxes)çš„ç´¢å¼•ï¼ˆé™åºæ’åˆ—ï¼‰
        # i=tensor([18, 19, 32, 25, 27])   nmsååªå‰©ä¸‹5ä¸ªé¢„æµ‹æ¡†äº†
        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS    è¿”å›å€¼ï¼škeepï¼šNMSè¿‡æ»¤åçš„bounding boxç´¢å¼•ï¼ˆé™åºï¼‰ å»é™¤å†—ä½™çš„æ¡†
        if i.shape[0] > max_det:  # limit detections
            i = i[:max_det]
        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)
            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)
            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix
            weights = iou * scores[None]  # box weights
            # bounding boxåˆå¹¶  å…¶å®å°±æ˜¯æŠŠæƒé‡å’Œæ¡†ç›¸ä¹˜å†é™¤ä»¥æƒé‡ä¹‹å’Œ
            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes
            if redundant:
                i = i[iou.sum(1) > 1]  # require redundancy

        output[xi] = x[i]   # æœ€ç»ˆè¾“å‡º   [5, 6]
        # çœ‹ä¸‹æ—¶é—´è¶…æ²¡è¶…æ—¶  è¶…æ—¶æ²¡åšå®Œçš„å°±ä¸åšäº†
        if (time.time() - t) > time_limit:
            LOGGER.warning(f'WARNING: NMS time limit {time_limit:.3f}s exceeded')
            break  # time limit exceeded

    return output 
```

## 12\. increment_path

```py
def increment_path(path, exist_ok=False, sep='', mkdir=False):
    # Increment file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc.
    path = Path(path)  # os-agnostic  # string/winè·¯å¾„ -> winè·¯å¾„

    # å¦‚æœè¯¥æ–‡ä»¶å¤¹å·²ç»å­˜åœ¨ åˆ™å°†è·¯å¾„run/train/expä¿®æ”¹ä¸º runs/train/exp1
    if path.exists() and not exist_ok:
        path, suffix = (path.with_suffix(''), path.suffix) if path.is_file() else (path, '')    # with_suffix:æ›´æ”¹è·¯å¾„åç¼€ suffixæ–‡ä»¶åç¼€

        # Method 1
        for n in range(2, 9999):
            p = f'{path}{sep}{n}{suffix}'  # increment path
            if not os.path.exists(p):  #
                break
        path = Path(p)

        # Method 2 (deprecated)
        # dirs = glob.glob(f"{path}{sep}*")  # similar paths
        # matches = [re.search(rf"{path.stem}{sep}(\d+)", d) for d in dirs]
        # i = [int(m.groups()[0]) for m in matches if m]  # indices
        # n = max(i) + 1 if i else 2  # increment number
        # path = Path(f"{path}{sep}{n}{suffix}")  # increment path

    if mkdir:
        path.mkdir(parents=True, exist_ok=True)  # make directory

    return path 
```

**ç”¨äºé€’å¢è·¯å¾„ã€‚æ¯”å¦‚æˆ‘è¾“å…¥è·¯å¾„æ˜¯run/train/expï¼Œä½†æ˜¯å‘ç°æ–‡ä»¶å¤¹é‡Œé¢å·²ç»æœ‰è¿™ä¸ªæ–‡ä»¶äº†ï¼Œé‚£ä¹ˆå°±å°†æ–‡ä»¶è·¯å¾„æ‰©å±•å›´ä¸ºï¼šruns/train/exp{sep}0, runs/exp{sep}1 etcã€‚**

## æ€»ç»“

**è¿™ä¸ªè„šæœ¬æ–‡ä»¶æ€»å…±æœ‰1Kå¤šè¡Œï¼Œæˆ‘æ²¡æœ‰å…¨éƒ¨å†™å®Œï¼Œæˆ‘åªæŒ‘äº†éƒ¨åˆ†é‡ç‚¹çš„æ¥å†™ï¼ˆå·æ‡’äº†ï¼‰ï¼Œé‡ç‚¹æŒæ¡[NMS](#11_font_colorred_non_max_suppression_font_296)å’Œ[scale_coords](#10_font_colorred_scale_coords_font_269)ï¼Œè¿™æ˜¯åå¤„ç†ä¸­æå…¶é‡è¦çš„å‡½æ•°ã€‚**

**References**

> CSDN xjunjinï¼š [2021SC@SDUSCå±±ä¸œå¤§å­¦è½¯ä»¶å­¦é™¢è½¯ä»¶å·¥ç¨‹åº”ç”¨ä¸å®è·µâ€“YOLOV5ä»£ç åˆ†æï¼ˆäº”ï¼‰general.py-3](https://blog.csdn.net/xjunjin/article/details/120828464)
> 
> CSDN çŒ«çŒ«ä¸æ©™å­ï¼š[YOLOV5ç›®æ ‡æ£€æµ‹-åå¤„ç†NMS(éæå¤§å€¼æŠ‘åˆ¶)](