<!--yml
category: æ¸¸æˆ
date: 2023-09-17 14:43:46
-->

# YOLOv5-6.xæºç åˆ†æï¼ˆåï¼‰---- metrics.py

> æ¥æºï¼š[https://blog.csdn.net/weixin_51322383/article/details/130454335](https://blog.csdn.net/weixin_51322383/article/details/130454335)

### æ–‡ç« ç›®å½•

*   [å‰è¨€](#_1)
*   [ğŸš€YOLOv5-6.xæºç åˆ†æï¼ˆåï¼‰---- metrics.py](#YOLOv56x_metricspy_6)
*   *   [0\. å¯¼åŒ…](#0__9)
    *   [1\. fitness](#1_fitness_23)
    *   [2\. smooth](#2_smooth_38)
    *   [3\. ap_per_class](#3_ap_per_class_51)
    *   [4\. compute_ap](#4_compute_ap_168)
    *   [5\. ConfusionMatrix](#5_ConfusionMatrix_225)
    *   [6\. bbox_iou](#6_bbox_iou_357)
    *   [7\. plot_pr_curve](#7_plot_pr_curve_407)
    *   [8\. plot_mc_curve](#8_plot_mc_curve_442)
    *   [æ€»ç»“](#_481)

# å‰è¨€

è¿™ä¸ªæ–‡ä»¶åŒ…å«äº†å„ç§ç›®æ ‡æ£€æµ‹çš„è¯„ä»·æŒ‡æ ‡ï¼ŒåŒ…æ‹¬è®¡ç®—mAPã€æ··æ·†çŸ©é˜µã€IOUç›¸å…³çš„å‡½æ•°ï¼Œéš¾åº¦ä¹Ÿéå¸¸çš„å¤§ï¼Œåœ¨çœ‹æºç ä¹‹å‰éœ€è¦å¯¹è¿™äº›å®šä¹‰æœ‰ä¸ªäº†è§£ã€‚

**å¯¼èˆª**ï¼š[YOLOv5-6.xæºç åˆ†æ å…¨æµç¨‹è®°å½•](https://blog.csdn.net/weixin_51322383/article/details/130353834)

* * *

# ğŸš€YOLOv5-6.xæºç åˆ†æï¼ˆåï¼‰---- metrics.py

## 0\. å¯¼åŒ…

```py
import math
import warnings
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import torch 
```

**åŸºæœ¬å°±æ˜¯äº›ç»˜å›¾ã€æ•°å­¦ã€çŸ©é˜µç›¸å…³çš„åŒ…**

## 1\. fitness

```py
def fitness(x):
    w = [0.0, 0.0, 0.1, 0.9]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]
    # (torch.tensor).sum(1)
    return (x[:, :4] * w).sum(1)    # æ¯ä¸€è¡Œæ±‚å’Œtensorä¸ºäºŒç»´æ—¶è¿”å›ä¸€ä¸ªä»¥æ¯ä¸€è¡Œæ±‚å’Œä¸ºç»“æœ(å¸¸æ•°)çš„è¡Œå‘é‡  1:è¡Œæ±‚å’Œ 
```

**è¿™ä¸ªå‡½æ•°æ˜¯é€šè¿‡æŒ‡æ ‡åŠ æƒçš„å½¢å¼è¿”å›é€‚åº”åº¦(æœ€ç»ˆmAP)ï¼Œåˆ¤æ–­æ¨¡å‹å¥½åçš„æŒ‡æ ‡ä¸æ˜¯mAP@0.5ä¹Ÿä¸æ˜¯mAP@0.5:0.95 è€Œæ˜¯[P, R, mAP@0.5, mAP@0.5:0.95]4è€…çš„åŠ æƒã€‚ä¸è¿‡è¿™é‡Œçš„På’ŒRçš„æƒé‡éƒ½æ˜¯0ï¼Œç›¸å½“äºæœ€ç»ˆç»“æœè¿˜æ˜¯mAPçš„è¯„ä»·æŒ‡æ ‡**

è¯¥å‡½æ•°åœ¨`train.py`ä¸­çš„è°ƒç”¨ç”¨æ¥è¯„ä»·æ¨¡å‹å¥½å

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/ebaede21f59ebe58397c65fd5d131b68.png)

## 2\. smooth

```py
def smooth(y, f=0.05):
    # Box filter of fraction f
    nf = round(len(y) * f * 2) // 2 + 1  # number of filter elements (must be odd)
    p = np.ones(nf // 2)  # ones padding
    yp = np.concatenate((p * y[0], y, p * y[-1]), 0)  # y padded
    return np.convolve(yp, np.ones(nf) / nf, mode='valid')  # y-smoothed 
```

**ç”¨æ¥è®¡ç®—é¢„æµ‹æ¡†å’ŒçœŸå®æ¡†ä¹‹é—´çš„å·®å¼‚çš„å¹³æ»‘å€¼ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒé€šè¿‡å°†æ¯ä¸ªé¢„æµ‹æ¡†çš„ç½®ä¿¡åº¦ä¸ä¸å…¶é‡å åº¦æœ€é«˜çš„çœŸå®æ¡†çš„é‡å åº¦è¿›è¡ŒåŠ æƒå¹³å‡æ¥è®¡ç®—å¹³æ»‘å€¼ã€‚è¿™ä¸ªå¹³æ»‘å€¼å¯ä»¥ç”¨æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œä¾‹å¦‚ï¼Œå®ƒå¯ä»¥ç”¨æ¥è®¡ç®—æ¨¡å‹åœ¨æ£€æµ‹ä»»åŠ¡ä¸­çš„å¹³å‡å‡†ç¡®åº¦å’Œå¬å›ç‡ç­‰æŒ‡æ ‡ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¹³æ»‘å€¼å¯ä»¥ä½œä¸ºæŸå¤±å‡½æ•°çš„ä¸€éƒ¨åˆ†ï¼Œå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ é¢„æµ‹æ¡†å’ŒçœŸå®æ¡†ä¹‹é—´çš„å·®å¼‚ã€‚**

## 3\. ap_per_class

ç¬¬ä¸€ä¸ªéš¾ç‚¹æ¥äº†ï¼Œåœ¨çœ‹è¿™ä¸ªå‡½æ•°ä¹‹å‰ï¼Œå»ºè®®å…ˆçœ‹ä¸€ä¸‹è¿™å‡ ç¯‡æ–‡ç« ã€‚[ç›®æ ‡æ£€æµ‹ä¸­çš„mAPæ˜¯ä»€ä¹ˆå«ä¹‰ï¼Ÿ](https://www.zhihu.com/question/53405779/answer/399478988)

[YOLO æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡â€”â€”IOUã€Precisionã€Recallã€F1-scoreã€mAP](https://blog.csdn.net/qq_63708623/article/details/128508776)

[ã€python numpyã€‘a.cumsum()ã€np.interp()ã€np.maximum.accumulate()ã€np.trapz()](https://blog.csdn.net/qq_38253797/article/details/119706121)

è®¡ç®—mAPçš„æ–¹å¼ï¼š[è¯¦è§£å¯¹è±¡æ£€æµ‹ç½‘ç»œæ€§èƒ½è¯„ä»·æŒ‡æ ‡mAPè®¡ç®—](https://mp.weixin.qq.com/s/5kzWL6rCKZGX1xfQ71-gfQ)

> APçš„å®šä¹‰å°±æ˜¯PRå–çº¿ä¸åæ ‡è½´å›´æˆçš„é¢ç§¯

**å…·ä½“è®¡ç®—æ­¥éª¤ï¼š**

1.  å…ˆæ‰¾å‡ºæ¯ä¸ªç±»åˆ«çš„TP
2.  å°†æ‰€æœ‰ç±»åˆ«çš„TPæŒ‰ç…§confé™åºæ’åº
3.  for æ¯ä¸€ä¸ªç±»åˆ«
    1.  è®¡ç®—è¿™ä¸ªç±»åˆ«çš„Recallå’ŒPrecision
    2.  for 10ä¸ªIOUé˜ˆå€¼ï¼Œè®¡ç®—mAPï¼ˆè°ƒç”¨compute_ap)å‡½æ•°

> è¿™é‡Œçš„FP = 1-TP
> 
> è€ŒTPçš„è®¡ç®—æ­¥éª¤ä¸ºï¼š
> 
> ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/3ae4244799be2f7bbf3e2520a0a2c4fa.png)

```py
def ap_per_class(tp, conf, pred_cls, target_cls, plot=False, save_dir='.', names=(), eps=1e-16):
    """ç”¨äºval.pyä¸­è®¡ç®—æ¯ä¸ªç±»çš„mAP
        è®¡ç®—æ¯ä¸€ä¸ªç±»çš„APæŒ‡æ ‡(average precision)è¿˜å¯ä»¥ ç»˜åˆ¶P-Ræ›²çº¿
        mAPåŸºæœ¬æ¦‚å¿µ: https://www.bilibili.com/video/BV1ez4y1X7g2
        Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.
        :params tp(correct): [pred_sum, 10]=[1905, 10] bool æ•´ä¸ªæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ‰€æœ‰é¢„æµ‹æ¡†åœ¨æ¯ä¸€ä¸ªiouæ¡ä»¶ä¸‹(0.5~0.95)10ä¸ªæ˜¯å¦æ˜¯TP
        :params conf: [img_sum]=[1905] æ•´ä¸ªæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡çš„æ‰€æœ‰é¢„æµ‹æ¡†çš„conf
        :params pred_cls: [img_sum]=[1905] æ•´ä¸ªæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡çš„æ‰€æœ‰é¢„æµ‹æ¡†çš„ç±»åˆ«
                è¿™é‡Œçš„tpã€confã€pred_clsæ˜¯ä¸€ä¸€å¯¹åº”çš„
        :params target_cls: [gt_sum]=[929] æ•´ä¸ªæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡çš„æ‰€æœ‰gtæ¡†çš„class
        :params plot: bool
        :params save_dir: runs\train\exp30
        :params names: dict{key(class_index):value(class_name)} è·å–æ•°æ®é›†æ‰€æœ‰ç±»åˆ«çš„indexå’Œå¯¹åº”ç±»å
        :return p[:, i]: [nc] æœ€å¤§å¹³å‡f1æ—¶æ¯ä¸ªç±»åˆ«çš„precision
        :return r[:, i]: [nc] æœ€å¤§å¹³å‡f1æ—¶æ¯ä¸ªç±»åˆ«çš„recall
        :return ap: [71, 10] æ•°æ®é›†æ¯ä¸ªç±»åˆ«åœ¨10ä¸ªioué˜ˆå€¼ä¸‹çš„mAP
        :return f1[:, i]: [nc] æœ€å¤§å¹³å‡f1æ—¶æ¯ä¸ªç±»åˆ«çš„f1
        :return unique_classes.astype('int32'): [nc] è¿”å›æ•°æ®é›†ä¸­æ‰€æœ‰çš„ç±»åˆ«index
        """
    # è®¡ç®—mAP éœ€è¦å°†tpæŒ‰ç…§confé™åºæ’åˆ—
    # Sort by objectness  æŒ‰confä»å¤§åˆ°å°æ’åº è¿”å›æ•°æ®å¯¹åº”çš„ç´¢å¼•
    i = np.argsort(-conf)
    # å¾—åˆ°é‡æ–°æ’åºåå¯¹åº”çš„ tp, conf, pre_cls
    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]

    # Find unique classes  å¯¹ç±»åˆ«å»é‡, å› ä¸ºè®¡ç®—apæ˜¯å¯¹æ¯ç±»è¿›è¡Œ
    unique_classes, nt = np.unique(target_cls, return_counts=True)  # å»é™¤å…¶ä¸­é‡å¤çš„å…ƒç´ ï¼Œå¹¶æŒ‰å…ƒç´ ç”±å¤§åˆ°å°è¿”å›ä¸€ä¸ªæ–°çš„æ— å…ƒç´ é‡å¤çš„å…ƒç»„æˆ–è€…åˆ—è¡¨
    # px: [0, 1] ä¸­é—´é—´éš”1000ä¸ªç‚¹ xåæ ‡(ç”¨äºç»˜åˆ¶P-Confã€R-Confã€F1-Conf)
    # py: yåæ ‡[] ç”¨äºç»˜åˆ¶IOU=0.5æ—¶çš„PRæ›²çº¿
    nc = unique_classes.shape[0]  # æ•°æ®é›†ç±»åˆ«æ•° number of classes, number of detections nc:71

    # Create Precision-Recall curve and compute AP for each class
    px, py = np.linspace(0, 1, 1000), []  # for plotting ç»˜å›¾
    ap, p, r = np.zeros((nc, tp.shape[1])), np.zeros((nc, 1000)), np.zeros((nc, 1000))
    for ci, c in enumerate(unique_classes):
        # i: è®°å½•ç€æ‰€æœ‰é¢„æµ‹æ¡†æ˜¯å¦æ˜¯cç±»åˆ«æ¡†   æ˜¯cç±»å¯¹åº”ä½ç½®ä¸ºTrue, å¦åˆ™ä¸ºFalse
        i = pred_cls == c
        # n_l: gtæ¡†ä¸­çš„cç±»åˆ«æ¡†æ•°é‡  = tp+fn   254
        n_l = nt[ci]  # number of labels
        # n_p: é¢„æµ‹æ¡†ä¸­cç±»åˆ«çš„æ¡†æ•°é‡   695
        n_p = i.sum()  # number of predictions
        if n_p == 0 or n_l == 0:
            continue

        # Accumulate FPs and TPs
        fpc = (1 - tp[i]).cumsum(0) # æ²¿ç€æŒ‡å®šè½´çš„å…ƒç´ ç´¯åŠ å’Œæ‰€ç»„æˆçš„æ•°ç»„ï¼Œå…¶å½¢çŠ¶åº”ä¸è¾“å…¥æ•°ç»„aä¸€è‡´
        tpc = tp[i].cumsum(0)   # fp[i] = 1 - tp[i]

        # Recall=TP/(TP+FN)  åŠ ä¸€ä¸ª1e-16çš„ç›®çš„æ˜¯é˜²æ­¢åˆ†æ¯ä¸º0
        # n_l=TP+FN=num_gt: cç±»çš„gtä¸ªæ•°=é¢„æµ‹æ˜¯cç±»è€Œä¸”é¢„æµ‹æ­£ç¡®+é¢„æµ‹ä¸æ˜¯cç±»ä½†æ˜¯é¢„æµ‹é”™è¯¯
        # recall: ç±»åˆ«ä¸ºc é¡ºåºæŒ‰ç½®ä¿¡åº¦æ’åˆ— æˆªè‡³æ¯ä¸€ä¸ªé¢„æµ‹æ¡†çš„å„ä¸ªioué˜ˆå€¼ä¸‹çš„å¬å›ç‡
        recall = tpc / (n_l + eps)  # recall curve
        # è¿”å›æ‰€æœ‰ç±»åˆ«, æ¨ªåæ ‡ä¸ºconf(å€¼ä¸ºpx=[0, 1, 1000] 0~1 1000ä¸ªç‚¹)å¯¹åº”çš„recallå€¼  r=[nc, 1000]  æ¯ä¸€è¡Œä»å°åˆ°å¤§
        # np.interpï¼šè¿™æ˜¯ä¸€ä¸ªçº¿æ€§æ’å€¼å‡½æ•°
        r[ci] = np.interp(-px, -conf[i], recall[:, 0], left=0)  # negative x, xp because xp decreases

        # Precision=TP/(TP+FP)
        # precision: ç±»åˆ«ä¸ºc é¡ºåºæŒ‰ç½®ä¿¡åº¦æ’åˆ— æˆªè‡³æ¯ä¸€ä¸ªé¢„æµ‹æ¡†çš„å„ä¸ªioué˜ˆå€¼ä¸‹çš„ç²¾ç¡®ç‡
        precision = tpc / (tpc + fpc)  # precision curve
        # è¿”å›æ‰€æœ‰ç±»åˆ«, æ¨ªåæ ‡ä¸ºconf(å€¼ä¸ºpx=[0, 1, 1000] 0~1 1000ä¸ªç‚¹)å¯¹åº”çš„precisionå€¼  p=[nc, 1000]
        # æ€»ä½“ä¸Šæ˜¯ä»å°åˆ°å¤§ ä½†æ˜¯ç»†èŠ‚ä¸Šæœ‰ç‚¹èµ·ä¼ å¦‚: 0.91503 0.91558 0.90968 0.91026 0.90446 0.90506
        p[ci] = np.interp(-px, -conf[i], precision[:, 0], left=1)  # p at pr_score

        # AP from recall-precision curve
        # è¿™é‡Œæ‰§è¡Œ10æ¬¡è®¡ç®—ciè¿™ä¸ªç±»åˆ«åœ¨æ‰€æœ‰mAPé˜ˆå€¼ä¸‹çš„å¹³å‡mAP  ap[nc, 10]
        for j in range(tp.shape[1]):
            ap[ci, j], mpre, mrec = compute_ap(recall[:, j], precision[:, j])
            if plot and j == 0:
                py.append(np.interp(px, mrec, mpre))  # precision at mAP@0.5

    # Compute F1 (harmonic mean of precision and recall)
    # è®¡ç®—F1åˆ†æ•° På’ŒRçš„è°ƒå’Œå¹³å‡å€¼  ç»¼åˆè¯„ä»·æŒ‡æ ‡
    f1 = 2 * p * r / (p + r + eps)
    names = [v for k, v in names.items() if k in unique_classes]  # list: only classes that have data
    names = dict(enumerate(names))  # to dict
    if plot:
        plot_pr_curve(px, py, ap, Path(save_dir) / 'PR_curve.png', names)   # prå›¾
        plot_mc_curve(px, f1, Path(save_dir) / 'F1_curve.png', names, ylabel='F1')  # f1
        plot_mc_curve(px, p, Path(save_dir) / 'P_curve.png', names, ylabel='Precision') # P_conf
        plot_mc_curve(px, r, Path(save_dir) / 'R_curve.png', names, ylabel='Recall')    # R_conf

    i = smooth(f1.mean(0), 0.1).argmax()  # max F1 index
    p, r, f1 = p[:, i], r[:, i], f1[:, i]
    tp = (r * nt).round()  # true positives
    fp = (tp / (p + eps) - tp).round()  # false positives
    return tp, fp, p, r, f1, ap, unique_classes.astype(int) 
```

**è¿™ä¸ªå‡½æ•°ä¼šåœ¨`val.py`ä¸­ç”¨åˆ°ï¼Œç”¨äºç»˜åˆ¶å„ç§æ›²çº¿**

## 4\. compute_ap

```py
def compute_ap(recall, precision):
    """ Compute the average precision, given the recall and precision curves
    # Arguments
        recall:    The recall curve (list)
        precision: The precision curve (list)
    # Returns
        Average precision, precision curve, recall curve
    """

    # åœ¨å¼€å¤´å’Œæœ«å°¾æ·»åŠ ä¿æŠ¤å€¼ é˜²æ­¢å…¨é›¶çš„æƒ…å†µå‡ºç° value Append sentinel values to beginning and end
    mrec = np.concatenate(([0.0], recall, [1.0]))
    mpre = np.concatenate(([1.0], precision, [0.0]))

    # Compute the precision envelope
    '''
        np.maximum.accumulate:è®¡ç®—æ•°ç»„ï¼ˆæˆ–æ•°ç»„çš„ç‰¹å®šè½´ï¼‰çš„ç´¯ç§¯æœ€å¤§å€¼
        ä¿è¯mpreæ˜¯ä»å¤§åˆ°å°å•è°ƒçš„(å·¦å³å¯ä»¥ç›¸åŒ)
        eg:
            d = np.array([2, 0, 3, -4, -2, 7, 9])
            c = np.maximum.accumulate(d)
            print(c)   # array([2, 2, 3, 3, 3, 7, 9])
        è¿™æ ·å¯èƒ½æ˜¯ä¸ºäº†æ›´å¥½è®¡ç®—mAP å› ä¸ºå¦‚æœä¸€ç›´èµ·èµ·ä¼ä¼å¤ªéš¾ç®—äº†(xé—´éš”å¾ˆå°å°±æ˜¯ä¸€ä¸ªçŸ©å½¢) è€Œä¸”è¿™æ ·åšè¯¯å·®ä¹Ÿä¸ä¼šå¾ˆå¤§ ä¸¤ä¸ªä¹‹é—´çš„æ•°éƒ½æ˜¯é—´éš”å¾ˆå°çš„
    '''

    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))    # np.flipç¿»è½¬é¡ºåº

    # Integrate area under curve
    method = 'interp'  # methods: 'continuous', 'interp'
    if method == 'interp':  # ç”¨ä¸€äº›å…¸å‹çš„é—´æ–­ç‚¹æ¥è®¡ç®—AP
        x = np.linspace(0, 1, 101)  # 101-point interp (COCO)
        ap = np.trapz(np.interp(x, mrec, mpre), x)  # integrate è®¡ç®—ä¸¤ä¸ªlistå¯¹åº”ç‚¹ä¸ç‚¹ä¹‹é—´å››è¾¹å½¢çš„é¢ç§¯ ä»¥å®šç§¯åˆ†å½¢å¼ä¼°ç®—AP ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯y ç¬¬äºŒä¸ªå‚æ•°æ˜¯x
    else:  # 'continuous'
        # é€šè¿‡é”™ä½çš„æ–¹å¼ åˆ¤æ–­å“ªä¸ªç‚¹å½“å‰ä½ç½®åˆ°ä¸‹ä¸€ä¸ªä½ç½®å€¼å‘ç”Ÿæ”¹å˜ å¹¶é€šè¿‡ï¼=åˆ¤æ–­ è¿”å›ä¸€ä¸ªå¸ƒå°”æ•°ç»„
        i = np.where(mrec[1:] != mrec[:-1])[0]  # points where x axis (recall) changes
        # å€¼æ”¹å˜äº†å°±æ±‚å‡ºå½“å‰çŸ©é˜µçš„é¢ç§¯  å€¼æ²¡å˜å°±è¯´æ˜å½“å‰çŸ©é˜µå’Œä¸‹ä¸€ä¸ªçŸ©é˜µçš„é«˜ç›¸ç­‰æ‰€æœ‰å¯ä»¥åˆå¹¶è®¡ç®—
        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  # area under curve

    return ap, mpre, mrec 
```

**è¿™ä¸ªå‡½æ•°å°±æ˜¯è®¡ç®—æŸä¸ªç±»åˆ«åœ¨æŸä¸ªIOUä¸‹çš„mAPï¼Œä¼šåœ¨ä¸Šé¢çš„å‡½æ•°ä¸­ç”¨åˆ°ã€‚**

å‚æ•°ï¼š

*   **precision:** (list) [1635] åœ¨æŸä¸ªioué˜ˆå€¼ä¸‹æŸä¸ªç±»åˆ«æ‰€æœ‰çš„é¢„æµ‹æ¡†çš„precision
    æ€»ä½“ä¸Šæ˜¯ä»å¤§åˆ°å° ä½†æ˜¯ç»†èŠ‚ä¸Šæœ‰ç‚¹èµ·ä¼ å¦‚: 0.91503 0.91558 0.90968 0.91026 0.90446 0.90506(æ¯ä¸ªé¢„æµ‹æ¡†çš„precisionéƒ½æ˜¯æˆªè‡³åˆ°è¿™ä¸ªé¢„æµ‹æ¡†ä¸ºæ­¢çš„æ€»precision)
*   **recall:**(list) [1635] åœ¨æŸä¸ªioué˜ˆå€¼ä¸‹æŸä¸ªç±»åˆ«æ‰€æœ‰çš„é¢„æµ‹æ¡†çš„recall ä»å°åˆ°å¤§ (æ¯ä¸ªé¢„æµ‹æ¡†çš„recalléƒ½æ˜¯æˆªè‡³åˆ°è¿™ä¸ªé¢„æµ‹æ¡†ä¸ºæ­¢çš„æ€»recall)

è¿”å›å€¼ï¼š

*   **ap:** Average precision è¿”å›æŸç±»åˆ«åœ¨æŸä¸ªiouä¸‹çš„mAP(å‡å€¼) [1]
*   **mpre:** precision curve [1637] è¿”å› å¼€å¤´ + è¾“å…¥precision(æ’åºå) + æœ«å°¾
*   **mrec:** recall curve [1637] è¿”å› å¼€å¤´ + è¾“å…¥recall + æœ«å°¾

## 5\. ConfusionMatrix

```py
class ConfusionMatrix:
    # Updated version of https://github.com/kaanakan/object_detection_confusion_matrix
    # ç±»åˆ«ã€é¢„æµ‹æ¡†ç½®ä¿¡åº¦é˜ˆå€¼ã€ioué˜ˆå€¼
    def __init__(self, nc, conf=0.25, iou_thres=0.45):
        # èƒŒæ™¯ä¹Ÿç®—ä¸€ç±»
        # å¦‚æœæŸä¸ªgt[j]æ²¡ç”¨ä»»ä½•predæ­£æ ·æœ¬åŒ¹é…åˆ° é‚£ä¹ˆ[nc, gt[j]_class] += 1
        # å¦‚æœæŸä¸ªpred[i]è´Ÿæ ·æœ¬ä¸”æ²¡æœ‰å“ªä¸ªgtä¸ä¹‹å¯¹åº” é‚£ä¹ˆ[pred[i]_class nc] += 1
        self.matrix = np.zeros((nc + 1, nc + 1))
        self.nc = nc  # number of classes
        self.conf = conf
        self.iou_thres = iou_thres

    def process_batch(self, detections, labels):
        """
        :params detections: [N, 6] = [pred_obj_num, x1y1x2y2+object_conf+cls] = [300, 6]
                            ä¸€ä¸ªbatchä¸­ä¸€å¼ å›¾çš„é¢„æµ‹ä¿¡æ¯  å…¶ä¸­x1y1x2y2æ˜¯æ˜ å°„åˆ°åŸå›¾imgçš„
        :params labels: [M, 5] = [gt_num, class+x1y1x2y2] = [17, 5] å…¶ä¸­x1y1x2y2æ˜¯æ˜ å°„åˆ°åŸå›¾imgçš„
        :return: None, updates confusion matrix accordingly
        """
        # [10, 6] ç­›é™¤ç½®ä¿¡åº¦è¿‡ä½çš„é¢„æµ‹æ¡†(å’Œnmså·®ä¸å¤š)
        if detections is None:
            gt_classes = labels.int()
            for i, gc in enumerate(gt_classes):
                self.matrix[self.nc, gc] += 1  # background FN
            return

        detections = detections[detections[:, 4] > self.conf]
        gt_classes = labels[:, 0].int()
        detection_classes = detections[:, 5].int()
        # æ±‚å‡ºæ‰€æœ‰gtæ¡†å’Œæ‰€æœ‰predæ¡†çš„iou [17, x1y1x2y2] + [10, x1y1x2y2] => [17, 10] [i, j] ç¬¬iä¸ªgtæ¡†å’Œç¬¬jä¸ªpredçš„iou
        iou = box_iou(labels[:, 1:], detections[:, :4])

        x = torch.where(iou > self.iou_thres)
        if x[0].shape[0]:
            # 1ã€matches: [10, gt_index+pred_index+iou] = [10, 3]
            matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()
            if x[0].shape[0] > 1:
                # 2ã€matchesæŒ‰ç¬¬ä¸‰åˆ—iouä»å¤§åˆ°å°é‡æ’åº
                matches = matches[matches[:, 2].argsort()[::-1]]
                # 3ã€å–ç¬¬äºŒåˆ—ä¸­å„ä¸ªæ¡†é¦–æ¬¡å‡ºç°(ä¸åŒé¢„æµ‹çš„æ¡†)çš„è¡Œ(å³æ¯ä¸€ç§é¢„æµ‹çš„æ¡†ä¸­iouæœ€å¤§çš„é‚£ä¸ª)
                matches = matches[np.unique(matches[:, 1], return_index=True)[1]]
                # 4ã€matcheså†æŒ‰ç¬¬ä¸‰åˆ—iouä»å¤§åˆ°å°é‡æ’åº
                matches = matches[matches[:, 2].argsort()[::-1]]
                # 5ã€å–ç¬¬ä¸€åˆ—ä¸­å„ä¸ªæ¡†é¦–æ¬¡å‡ºç°(ä¸åŒgtçš„æ¡†)çš„è¡Œ(å³æ¯ä¸€ç§gtæ¡†ä¸­iouæœ€å¤§çš„é‚£ä¸ª)
                matches = matches[np.unique(matches[:, 0], return_index=True)[1]]
                # ç»è¿‡è¿™æ ·çš„å¤„ç† æœ€ç»ˆå¾—åˆ°æ¯ä¸€ç§é¢„æµ‹æ¡†ä¸æ‰€æœ‰gtæ¡†ä¸­iouæœ€å¤§çš„é‚£ä¸ª(åœ¨å¤§äºé˜ˆå€¼çš„å‰æä¸‹)
                # é¢„æµ‹æ¡†å”¯ä¸€  gtæ¡†ä¹Ÿå”¯ä¸€  è¿™æ ·å¾—åˆ°çš„matcheså¯¹åº”çš„Predéƒ½æ˜¯æ­£æ ·æœ¬Positive
        else:
            matches = np.zeros((0, 3))

        n = matches.shape[0] > 0
        m0, m1, _ = matches.transpose().astype(int)
        for i, gc in enumerate(gt_classes):
            j = m0 == i
            if n and sum(j) == 1:
                self.matrix[detection_classes[m1[j]], gc] += 1  # correct
            else:
                self.matrix[self.nc, gc] += 1  # background FP

        if n:
            for i, dc in enumerate(detection_classes):
                if not any(m1 == i):
                    self.matrix[dc, self.nc] += 1  # background FN

    def matrix(self):
        return self.matrix

    # ç§»é™¤èƒŒæ™¯
    def tp_fp(self):
        tp = self.matrix.diagonal()  # true positives
        fp = self.matrix.sum(1) - tp  # false positives
        # fn = self.matrix.sum(0) - tp  # false negatives (missed detections)
        return tp[:-1], fp[:-1]  # remove background class

    def plot(self, normalize=True, save_dir='', names=()):
        """
        :params normalize: æ˜¯å¦å°†æ··æ·†çŸ©é˜µå½’ä¸€åŒ– é»˜è®¤True
        :params save_dir: runs/train/expn æ··æ·†çŸ©é˜µä¿å­˜åœ°å€
        :params names: æ•°æ®é›†çš„æ‰€æœ‰ç±»åˆ«å
        :return None
        """
        try:
            import seaborn as sn

            array = self.matrix / ((self.matrix.sum(0).reshape(1, -1) + 1E-9) if normalize else 1)  # normalize columns
            array[array < 0.005] = np.nan  # don't annotate (would appear as 0.00)

            fig = plt.figure(figsize=(12, 9), tight_layout=True)
            nc, nn = self.nc, len(names)  # number of classes, names
            sn.set(font_scale=1.0 if nc < 50 else 0.8)  # for label size
            labels = (0 < nn < 99) and (nn == nc)  # apply names to ticklabels
            # ç»˜åˆ¶çƒ­åŠ›å›¾ å³æ··æ·†çŸ©é˜µå¯è§†åŒ–
            with warnings.catch_warnings():
                warnings.simplefilter('ignore')  # suppress empty matrix RuntimeWarning: All-NaN slice encountered
                # sean.heatmap: çƒ­åŠ›å›¾  data: æ•°æ®çŸ©é˜µ  annot: ä¸ºTrueæ—¶ä¸ºæ¯ä¸ªå•å…ƒæ ¼å†™å…¥æ•°æ®å€¼ Falseç”¨é¢œè‰²æ·±æµ…è¡¨ç¤º
                # annot_kws: æ ¼å­å¤–æ¡†å®½åº¦  fmt: æ·»åŠ æ³¨é‡Šæ—¶è¦ä½¿ç”¨çš„å­—ç¬¦ä¸²æ ¼å¼ä»£ç  cmap: æŒ‡è‰²å½©é¢œè‰²çš„é€‰æ‹©
                # square: æ˜¯å¦æ˜¯æ­£æ–¹å½¢  xticklabelsã€yticklabels: xyæ ‡ç­¾
                sn.heatmap(array,
                           annot=nc < 30,
                           annot_kws={
                               "size": 8},
                           cmap='Blues',
                           fmt='.2f',
                           square=True,
                           vmin=0.0,
                           xticklabels=names + ['background FP'] if labels else "auto",
                           yticklabels=names + ['background FN'] if labels else "auto").set_facecolor((1, 1, 1))
            fig.axes[0].set_xlabel('True')
            fig.axes[0].set_ylabel('Predicted')
            fig.savefig(Path(save_dir) / 'confusion_matrix.png', dpi=250)
            plt.close()
        except Exception as e:
            print(f'WARNING: ConfusionMatrix plot failure: {e}')

    def print(self):
        for i in range(self.nc + 1):
            print(' '.join(map(str, self.matrix[i]))) 
```

æ²¡çœ‹æ‡‚ã€‚ã€‚ã€‚

çœ‹è¿™æ®µä»£ç åº”è¯¥æ˜¯éœ€è¦debugçš„ï¼Œä¸ç„¶å®Œå…¨ä¸çŸ¥é“åœ¨å¹²å˜›ï¼Œäº”ä¸€å‡æœŸçš„æˆ‘æ•ˆç‡å¤ªä½äº†ï¼Œåªæƒ³å·æ‡’å®Œæˆä»»åŠ¡ï¼Œåé¢å†è¡¥å§ã€‚ã€‚ã€‚

è¿™ä¸ªç±»ä¼šåœ¨`val.py`ä¸­è°ƒç”¨ï¼Œç”¨äºç”»å‡ºæ··æ·†çŸ©é˜µ

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/e3c89c99999bc83a27b5bfdd892f387c.png)

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](img/0434fa6375126e0076da71018607c20c.png)

## 6\. bbox_iou

```py
def bbox_iou(box1, box2, xywh=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):
    # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4)

    # Get the coordinates of bounding boxes
    if xywh:  # transform from xywh to xyxy
        (x1, y1, w1, h1), (x2, y2, w2, h2) = box1.chunk(4, 1), box2.chunk(4, 1) # åˆ†å‰²æˆchunk_numä¸ªtensorå—,è¿”å›ä¸€ä¸ªå…ƒç»„
        w1_, h1_, w2_, h2_ = w1 / 2, h1 / 2, w2 / 2, h2 / 2
        b1_x1, b1_x2, b1_y1, b1_y2 = x1 - w1_, x1 + w1_, y1 - h1_, y1 + h1_
        b2_x1, b2_x2, b2_y1, b2_y2 = x2 - w2_, x2 + w2_, y2 - h2_, y2 + h2_
    else:  # x1, y1, x2, y2 = box1
        b1_x1, b1_y1, b1_x2, b1_y2 = box1.chunk(4, 1)
        b2_x1, b2_y1, b2_x2, b2_y2 = box2.chunk(4, 1)
        w1, h1 = b1_x2 - b1_x1, b1_y2 - b1_y1
        w2, h2 = b2_x2 - b2_x1, b2_y2 - b2_y1

    # Intersection area
    inter = (torch.min(b1_x2, b2_x2) - torch.max(b1_x1, b2_x1)).clamp(0) * \
            (torch.min(b1_y2, b2_y2) - torch.max(b1_y1, b2_y1)).clamp(0)

    # Union Area
    union = w1 * h1 + w2 * h2 - inter + eps

    # IoU
    iou = inter / union
    if CIoU or DIoU or GIoU:
        # ä¸¤ä¸ªæ¡†çš„æœ€å°é—­åŒ…åŒºåŸŸçš„width
        cw = torch.max(b1_x2, b2_x2) - torch.min(b1_x1, b2_x1)  # convex (smallest enclosing box) width
        # ä¸¤ä¸ªæ¡†çš„æœ€å°é—­åŒ…åŒºåŸŸçš„height
        ch = torch.max(b1_y2, b2_y2) - torch.min(b1_y1, b2_y1)  # convex height
        if CIoU or DIoU:  # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1
            c2 = cw ** 2 + ch ** 2 + eps  # convex diagonal squared
            rho2 = ((b2_x1 + b2_x2 - b1_x1 - b1_x2) ** 2 + (b2_y1 + b2_y2 - b1_y1 - b1_y2) ** 2) / 4  # center dist ** 2
            if CIoU:  # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47
                v = (4 / math.pi ** 2) * torch.pow(torch.atan(w2 / (h2 + eps)) - torch.atan(w1 / (h1 + eps)), 2)
                with torch.no_grad():
                    alpha = v / (v - iou + (1 + eps))
                return iou - (rho2 / c2 + v * alpha)  # CIoU
            return iou - rho2 / c2  # DIoU
        c_area = cw * ch + eps  # convex area
        return iou - (c_area - union) / c_area  # GIoU https://arxiv.org/pdf/1902.09630.pdf
    return iou  # IoU 
```

è¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥è®¡ç®—çŸ©é˜µæ¡†é—´çš„IOUçš„ï¼Œç°åœ¨æœ‰å¾ˆå¤šç§iouå˜ç§ï¼Œå¦‚ï¼šiou/Giou/Diou/Ciouã€‚

è¿™ä¸ªå‡½æ•°é€šå¸¸ç”¨æ¥åœ¨`ComputeLoss`ä¸­è®¡ç®—å›å½’æŸå¤±ï¼ˆbboxæŸå¤±ï¼‰

## 7\. plot_pr_curve

```py
def plot_pr_curve(px, py, ap, save_dir=Path('pr_curve.png'), names=()):
    """ç”¨äºap_per_classå‡½æ•°
        Precision-recall curve  ç»˜åˆ¶PRæ›²çº¿
        :params px: [1000] æ¨ªåæ ‡ recall å€¼ä¸º0~1ç›´æ¥å–1000ä¸ªæ•°
        :params py: list{nc} ncä¸ª[1000] æ‰€æœ‰ç±»åˆ«åœ¨IOU=0.5,æ¨ªåæ ‡ä¸ºpx(recall)æ—¶çš„precision
        :params ap: [nc, 10] æ‰€æœ‰ç±»åˆ«åœ¨æ¯ä¸ªIOUé˜ˆå€¼ä¸‹çš„å¹³å‡mAP
        :params save_dir: runs\test\exp54\PR_curve.png  PRæ›²çº¿å­˜å‚¨ä½ç½®
        :params names: {dict:80} æ•°æ®é›†æ‰€æœ‰ç±»åˆ«çš„å­—å…¸ key:value
        """
    # Precision-recall curve
    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)
    py = np.stack(py, axis=1)

    # ç”»å‡ºæ‰€æœ‰ç±»åˆ«åœ¨10ä¸ªIOUé˜ˆå€¼ä¸‹çš„PRæ›²çº¿
    if 0 < len(names) < 21:  # å¦‚æœ<21 classeså°±ä¸€ä¸ªä¸ªç±»ç”» å› ä¸ºè¦æ˜¾ç¤ºå›¾ä¾‹å°±å¿…é¡»ä¸€ä¸ªä¸ªç”»
        for i, y in enumerate(py.T):
            ax.plot(px, y, linewidth=1, label=f'{names[i]}  {ap[i, 0]:.3f}')  # plot(recall, precision)
    else:   # å¦‚æœ>=21 classes æ˜¾ç¤ºå›¾ä¾‹å°±ä¼šå¾ˆä¹± æ‰€ä»¥å°±ä¸æ˜¾ç¤ºå›¾ä¾‹äº† å¯ä»¥ç›´æ¥è¾“å…¥æ•°ç»„ x[1000] y[1000, 71]
        ax.plot(px, py, linewidth=1, color='grey')  # plot(recall, precision)

    ax.plot(px, py.mean(1), linewidth=3, color='blue', label='all classes %.3f mAP@0.5' % ap[:, 0].mean())
    ax.set_xlabel('Recall')
    ax.set_ylabel('Precision')
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    plt.legend(bbox_to_anchor=(1.04, 1), loc="upper left")
    fig.savefig(save_dir, dpi=250)
    plt.close() 
```

**è¿™ä¸ªå‡½æ•°ç”¨äºç»˜åˆ¶PRå–çº¿ï¼Œä¼šåœ¨`ap_per_class`ä¸­è°ƒç”¨**

## 8\. plot_mc_curve

```py
def plot_mc_curve(px, py, save_dir=Path('mc_curve.png'), names=(), xlabel='Confidence', ylabel='Metric'):
    """ç”¨äºap_per_classå‡½æ•°
        Metric-Confidence curve å¯ç”¨äºç»˜åˆ¶ F1-Confidence/P-Confidence/R-Confidenceæ›²çº¿
        :params px: [0, 1, 1000] æ¨ªåæ ‡ 0-1 1000ä¸ªç‚¹ conf   [1000]
        :params py: å¯¹æ¯ä¸ªç±», é’ˆå¯¹æ¨ªåæ ‡ä¸ºconf=[0, 1, 1000] å¯¹åº”çš„f1/p/rå€¼ çºµåæ ‡ [71, 1000]
        :params save_dir: å›¾ç‰‡ä¿å­˜åœ°å€
        :parmas names: æ•°æ®é›†names
        :params xlabel: xè½´æ ‡ç­¾
        :params ylabel: yè½´æ ‡ç­¾
        """
    # Metric-confidence curve
    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)

    # ç”»å‡ºæ‰€æœ‰ç±»åˆ«çš„F1-Confidence/P-Confidence/R-Confidenceæ›²çº¿
    if 0 < len(names) < 21:  # display per-class legend if < 21 classes
        for i, y in enumerate(py):
            ax.plot(px, y, linewidth=1, label=f'{names[i]}')  # plot(confidence, metric)
    else:
        ax.plot(px, py.T, linewidth=1, color='grey')  # plot(confidence, metric)

    y = smooth(py.mean(0), 0.05)
    ax.plot(px, y, linewidth=3, color='blue', label=f'all classes {y.max():.2f} at {px[y.argmax()]:.3f}')
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    plt.legend(bbox_to_anchor=(1.04, 1), loc="upper left")
    fig.savefig(save_dir, dpi=250)
    plt.close() 
```

**ç»˜åˆ¶F1å–çº¿ï¼ŒF1-scoreå°±æ˜¯ç”¨æ¥ç”¨æ¥æƒè¡¡Precisionå’ŒRecallçš„å¹³å‡å€¼ã€‚**

æ ¹æ®F1-scoreçš„å®šä¹‰å¼å¯çŸ¥ï¼Œ**F1-scoreä¹Ÿæ˜¯å–å¹³å‡å€¼ï¼Œåªä¸è¿‡å¼ºè°ƒçš„æ˜¯äºŒè€…ä¹‹é—´çš„è¾ƒå°å€¼ã€‚é€šè¿‡F1-scoreçš„æ–¹å¼æ¥æƒè¡¡Precisionä¸Recallï¼Œå¯ä»¥æœ‰æ•ˆçš„é¿å…çŸ­æ¿æ•ˆåº”**ï¼Œè¿™åœ¨æ•°å­¦ä¸Šè¢«ç§°ä¸ºè°ƒå’Œå¹³å‡æ•°ã€‚

## æ€»ç»“

**è¿™ä¸ªè„šæœ¬çš„ä»£ç é‡ä¸å¤šï¼Œä½†æ˜¯æ¯ä¸€ä¸ªå‡½æ•°éƒ½éå¸¸çš„å¤æ‚ï¼Œè¿™ä¸ªè„šæœ¬è¦å’Œ`val.py`ä¸€èµ·çœ‹ï¼Œçºµè§‚æ•´ä¸ªä¸“æ ï¼Œæˆ‘æŒæ¡çš„æœ€ä¸é€å½»çš„å°±æ˜¯è¿™ä¸ªæ–‡ä»¶å’Œ`val.py`äº†ï¼Œå¾ˆå¤šå‡½æ•°ä¹Ÿåªæ˜¯äº†è§£å®ƒçš„ä½œç”¨ï¼Œå¹¶æ²¡æœ‰çœ‹æ‡‚å®ƒçš„æºç ã€‚**

* * *

**æœ‰æ—¶å€™æˆ‘ç»å¸¸åœ¨æƒ³ï¼Œæœ‰å¿…è¦çœ‹é‚£ä¹ˆç»†å—ï¼Ÿè¿™å¯¹æˆ‘æœ‰ä»€ä¹ˆå¸®åŠ©å—ï¼ŸåŒ…æ‹¬æˆ‘ä¹Ÿé—®äº†æˆ‘çš„è€å¸ˆå’Œå­¦é•¿ï¼Œæœ‰å¿…è¦å»æŒ–YOLOv5çš„æºç å—ï¼Œè€å¸ˆä¹Ÿè¯´æ²¡æœ‰å¿…è¦ã€‚ä½†æ˜¯å¯¹äºæˆ‘æ¥è¯´ï¼Œæˆ‘æ˜¯åœ¨è¿™æ–¹é¢å–œæ¬¢åˆ¨æ ¹é—®åº•çš„äººï¼Œå°½ç®¡æˆ‘ç”¨äº†è¿™ä¹ˆä¹…çš„YOLOv5ï¼Œä½†æˆ‘æ€»å¯¹ä»–çš„å¾ˆå¤šæ‰§è¡Œè¿‡ç¨‹äº‘é‡Œé›¾é‡Œï¼Œè®©æˆ‘å»æŒ–ä¸€éæºç ï¼ŒçœŸçš„èƒ½è§£å†³æˆ‘å¾ˆå¤šçš„ç–‘æƒ‘ã€‚æ¯”å¦‚æˆ‘ä¹‹å‰ä¸€ç›´æ²¡ææ¸…bboxæŸå¤±å’Œç½®ä¿¡åº¦æŸå¤±ä¹‹é—´çš„å…³ç³»ï¼Œç»è¿‡è¿™æ¬¡çš„å­¦ä¹ åï¼Œè®©æˆ‘å¤§å½»å¤§æ‚Ÿã€‚**

**è¿™æ®µæ—¶é—´çœ‹äº†å¾ˆå¤šåšä¸»çš„æºç å‰–æï¼Œä¸å¾—ä¸è¯´ï¼Œä»–ä»¬åšçš„éƒ½éå¸¸çš„å¥½ï¼Œè®²çš„ä¹Ÿéå¸¸çš„é€šé€ï¼Œè€Œæˆ‘è®¸å¤šåœ°æ–¹çœ‹ä¸æ‡‚ä»ç„¶è¿˜æ˜¯å†™äº†ä¸Šå»ï¼Œç®—æ˜¯ä¸ºäº†ç»™è¿™ä¸ªåšå®¢ä¸“æ åšå¾—æ›´åŠ å®Œå–„å§ï¼Œæ‰€ä»¥å¦‚æœä½ çœ‹åˆ°æˆ‘çš„å¾ˆå¤šåœ°æ–¹è®²çš„ä¸é€å½»ï¼Œä½ å¯ä»¥å†çœ‹çœ‹æˆ‘æœ€ä¸‹æ–¹Referencesï¼Œæˆ–è€…å»æœæœåˆ«çš„åšä¸»ï¼Œè‚¯å®šèƒ½è§£å†³ä½ çš„ç–‘æƒ‘ã€‚å½“ç„¶ï¼Œæˆ‘ä¹Ÿéå¸¸æ¬¢è¿ä½ èƒ½å’Œæˆ‘è¿›è¡Œè®¨è®ºã€‚å¦‚æœä½ ä¹Ÿèƒ½åƒæˆ‘ä¸€æ ·å»å†™ä¸€ä¸ªå±äºä½ è‡ªå·±çš„ä¸“æ è§£æï¼Œé‚£æˆ‘è§‰å¾—è¿™ä»¶äº‹æƒ…ã€‚ã€‚ã€‚æ³°è£¤è¾£ï¼ï¼ï¼**