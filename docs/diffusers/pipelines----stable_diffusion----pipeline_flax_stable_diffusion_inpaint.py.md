# `.\diffusers\pipelines\stable_diffusion\pipeline_flax_stable_diffusion_inpaint.py`

```py
# ç‰ˆæƒå£°æ˜ï¼ŒæŒ‡æ˜è¯¥æ–‡ä»¶çš„ç‰ˆæƒä¿¡æ¯
# Copyright 2024 The HuggingFace Team. All rights reserved.
#
# æŒ‰ç…§ Apache è®¸å¯è¯ç¬¬ 2.0 ç‰ˆè®¸å¯ä½¿ç”¨æœ¬æ–‡ä»¶
# Licensed under the Apache License, Version 2.0 (the "License");
# é™¤ééµå¾ªè®¸å¯è¯ï¼Œå¦åˆ™ä¸å¾—ä½¿ç”¨æœ¬æ–‡ä»¶
# you may not use this file except in compliance with the License.
# å¯ä»¥é€šè¿‡ä»¥ä¸‹ç½‘å€è·å–è®¸å¯è¯å‰¯æœ¬
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# é™¤éé€‚ç”¨æ³•å¾‹æˆ–ä¹¦é¢åè®®è§„å®šï¼Œå¦åˆ™æ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶
# Unless required by applicable law or agreed to in writing, software
# æ˜¯æŒ‰â€œåŸæ ·â€åŸºç¡€åˆ†å‘çš„ï¼Œä¸æä¾›ä»»ä½•å½¢å¼çš„æ‹…ä¿æˆ–æ¡ä»¶
# distributed under the License is distributed on an "AS IS" BASIS,
# ä¸è®ºæ˜¯æ˜ç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿æˆ–æ¡ä»¶
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# å‚è§è®¸å¯è¯ä»¥äº†è§£é€‚ç”¨æƒé™å’Œé™åˆ¶
# See the License for the specific language governing permissions and
# limitations under the License.

import warnings  # å¯¼å…¥ warnings æ¨¡å—ä»¥å¤„ç†è­¦å‘Š
from functools import partial  # ä» functools å¯¼å…¥ partialï¼Œç”¨äºéƒ¨åˆ†åº”ç”¨å‡½æ•°
from typing import Dict, List, Optional, Union  # å¯¼å…¥ç±»å‹æ³¨è§£å·¥å…·

import jax  # å¯¼å…¥ jax åº“ï¼Œç”¨äºé«˜æ€§èƒ½æ•°å€¼è®¡ç®—
import jax.numpy as jnp  # å¯¼å…¥ jax çš„ numpy ä½œä¸º jnp
import numpy as np  # å¯¼å…¥ numpy åº“ä»¥è¿›è¡Œæ•°ç»„æ“ä½œ
from flax.core.frozen_dict import FrozenDict  # ä» flax å¯¼å…¥ FrozenDict ç”¨äºä¸å¯å˜å­—å…¸
from flax.jax_utils import unreplicate  # ä» flax å¯¼å…¥ unreplicateï¼Œç”¨äºå»é™¤å¤åˆ¶
from flax.training.common_utils import shard  # ä» flax å¯¼å…¥ shardï¼Œç”¨äºæ•°æ®åˆ†ç‰‡
from packaging import version  # å¯¼å…¥ version ç”¨äºç‰ˆæœ¬æ¯”è¾ƒ
from PIL import Image  # ä» PIL å¯¼å…¥ Image ç”¨äºå›¾åƒå¤„ç†
from transformers import CLIPImageProcessor, CLIPTokenizer, FlaxCLIPTextModel  # å¯¼å…¥ transformers åº“çš„ç›¸å…³ç»„ä»¶

from ...models import FlaxAutoencoderKL, FlaxUNet2DConditionModel  # å¯¼å…¥è‡ªå®šä¹‰æ¨¡å‹
from ...schedulers import (  # ä»è‡ªå®šä¹‰è°ƒåº¦å™¨å¯¼å…¥å„ç±»è°ƒåº¦å™¨
    FlaxDDIMScheduler,
    FlaxDPMSolverMultistepScheduler,
    FlaxLMSDiscreteScheduler,
    FlaxPNDMScheduler,
)
from ...utils import PIL_INTERPOLATION, deprecate, logging, replace_example_docstring  # å¯¼å…¥å·¥å…·å‡½æ•°
from ..pipeline_flax_utils import FlaxDiffusionPipeline  # å¯¼å…¥ FlaxDiffusionPipeline ç±»
from .pipeline_output import FlaxStableDiffusionPipelineOutput  # å¯¼å…¥è¾“å‡ºç±»
from .safety_checker_flax import FlaxStableDiffusionSafetyChecker  # å¯¼å…¥å®‰å…¨æ£€æŸ¥å™¨ç±»

logger = logging.get_logger(__name__)  # åˆ›å»ºæ—¥å¿—è®°å½•å™¨ï¼Œä½¿ç”¨å½“å‰æ¨¡å—åç§°

# è®¾ç½®ä¸º True æ—¶ä½¿ç”¨ Python çš„ for å¾ªç¯è€Œä¸æ˜¯ jax.fori_loopï¼Œä»¥ä¾¿äºè°ƒè¯•
DEBUG = False

EXAMPLE_DOC_STRING = """  # å®šä¹‰ç¤ºä¾‹æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œé€šå¸¸ç”¨äºæ–‡æ¡£ç”Ÿæˆ
```  
    # ç¤ºä¾‹ä»£ç å—ï¼Œç”¨äºå±•ç¤ºå¦‚ä½•ä½¿ç”¨ JAX å’Œ Flax è¿›è¡Œå›¾åƒå¤„ç†
        Examples:
            ```py
            # å¯¼å…¥å¿…è¦çš„åº“
            >>> import jax
            >>> import numpy as np
            >>> from flax.jax_utils import replicate
            >>> from flax.training.common_utils import shard
            >>> import PIL
            >>> import requests
            >>> from io import BytesIO
            >>> from diffusers import FlaxStableDiffusionInpaintPipeline
    
            # å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºä¸‹è½½å›¾åƒå¹¶è½¬æ¢ä¸º RGB æ ¼å¼
            >>> def download_image(url):
            ...     # å‘é€ GET è¯·æ±‚ä»¥è·å–å›¾åƒå†…å®¹
            ...     response = requests.get(url)
            ...     # æ‰“å¼€ä¸‹è½½çš„å†…å®¹å¹¶è½¬æ¢ä¸º RGB å›¾åƒ
            ...     return PIL.Image.open(BytesIO(response.content)).convert("RGB")
    
            # å®šä¹‰å›¾åƒå’Œæ©ç çš„ URL
            >>> img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
            >>> mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
    
            # ä¸‹è½½å¹¶è°ƒæ•´åˆå§‹å›¾åƒå’Œæ©ç å›¾åƒçš„å¤§å°
            >>> init_image = download_image(img_url).resize((512, 512))
            >>> mask_image = download_image(mask_url).resize((512, 512))
    
            # ä»é¢„è®­ç»ƒæ¨¡å‹åŠ è½½ç®¡é“å’Œå‚æ•°
            >>> pipeline, params = FlaxStableDiffusionInpaintPipeline.from_pretrained(
            ...     "xvjiarui/stable-diffusion-2-inpainting"
            ... )
    
            # å®šä¹‰å¤„ç†å›¾åƒæ—¶ä½¿ç”¨çš„æç¤º
            >>> prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
            # åˆå§‹åŒ–éšæœºç§å­
            >>> prng_seed = jax.random.PRNGKey(0)
            # å®šä¹‰æ¨ç†æ­¥éª¤çš„æ•°é‡
            >>> num_inference_steps = 50
    
            # è·å–è®¾å¤‡æ•°é‡ä»¥ä¾¿å¹¶è¡Œå¤„ç†
            >>> num_samples = jax.device_count()
            # å°†æç¤ºã€åˆå§‹å›¾åƒå’Œæ©ç å›¾åƒæ‰©å±•ä¸ºè®¾å¤‡æ•°é‡çš„åˆ—è¡¨
            >>> prompt = num_samples * [prompt]
            >>> init_image = num_samples * [init_image]
            >>> mask_image = num_samples * [mask_image]
            # å‡†å¤‡è¾“å…¥ï¼Œå¾—åˆ°æç¤º ID å’Œå¤„ç†åçš„å›¾åƒ
            >>> prompt_ids, processed_masked_images, processed_masks = pipeline.prepare_inputs(
            ...     prompt, init_image, mask_image
            ... )
            # åˆ†å‰²è¾“å…¥å’Œéšæœºæ•°ç”Ÿæˆå™¨
    
            # å¤åˆ¶å‚æ•°ä»¥é€‚åº”æ¯ä¸ªè®¾å¤‡
            >>> params = replicate(params)
            # æ ¹æ®è®¾å¤‡æ•°é‡åˆ†å‰²éšæœºç§å­
            >>> prng_seed = jax.random.split(prng_seed, jax.device_count())
            # å°†æç¤º ID å’Œå¤„ç†åçš„å›¾åƒåˆ†å‰²ä»¥é€‚åº”æ¯ä¸ªè®¾å¤‡
            >>> prompt_ids = shard(prompt_ids)
            >>> processed_masked_images = shard(processed_masked_images)
            >>> processed_masks = shard(processed_masks)
    
            # è¿è¡Œç®¡é“ä»¥ç”Ÿæˆå›¾åƒ
            >>> images = pipeline(
            ...     prompt_ids, processed_masks, processed_masked_images, params, prng_seed, num_inference_steps, jit=True
            ... ).images
            # å°†ç”Ÿæˆçš„å›¾åƒæ•°ç»„è½¬æ¢ä¸º PIL å›¾åƒæ ¼å¼
            >>> images = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))
            ```  
# FlaxStableDiffusionInpaintPipeline ç±»å®šä¹‰ï¼Œç»§æ‰¿è‡ª FlaxDiffusionPipeline
class FlaxStableDiffusionInpaintPipeline(FlaxDiffusionPipeline):
    r"""
    Flax åŸºäº Stable Diffusion çš„æ–‡æœ¬å¼•å¯¼å›¾åƒä¿®è¡¥çš„ç®¡é“ã€‚

    <Tip warning={true}>
    
    ğŸ§ª è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ï¼

    </Tip>

    è¯¥æ¨¡å‹ç»§æ‰¿è‡ª [`FlaxDiffusionPipeline`]ã€‚æœ‰å…³æ‰€æœ‰ç®¡é“é€šç”¨æ–¹æ³•ï¼ˆä¸‹è½½ã€ä¿å­˜ã€åœ¨ç‰¹å®šè®¾å¤‡ä¸Šè¿è¡Œç­‰ï¼‰çš„å®ç°ï¼Œè¯·æŸ¥çœ‹çˆ¶ç±»æ–‡æ¡£ã€‚

    å‚æ•°:
        vae ([`FlaxAutoencoderKL`]):
            ç”¨äºå°†å›¾åƒç¼–ç å’Œè§£ç ä¸ºæ½œåœ¨è¡¨ç¤ºçš„å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ã€‚
        text_encoder ([`~transformers.FlaxCLIPTextModel`]):
            å†»ç»“çš„æ–‡æœ¬ç¼–ç å™¨ ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14))ã€‚
        tokenizer ([`~transformers.CLIPTokenizer`]):
            ç”¨äºæ ‡è®°åŒ–æ–‡æœ¬çš„ `CLIPTokenizer`ã€‚
        unet ([`FlaxUNet2DConditionModel`]):
            ç”¨äºå»å™ªç¼–ç å›¾åƒæ½œåœ¨è¡¨ç¤ºçš„ `FlaxUNet2DConditionModel`ã€‚
        scheduler ([`SchedulerMixin`]):
            ä¸ `unet` ç»“åˆä½¿ç”¨ä»¥å»å™ªç¼–ç å›¾åƒæ½œåœ¨è¡¨ç¤ºçš„è°ƒåº¦å™¨ã€‚å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€
            [`FlaxDDIMScheduler`], [`FlaxLMSDiscreteScheduler`], [`FlaxPNDMScheduler`] æˆ–
            [`FlaxDPMSolverMultistepScheduler`]ã€‚
        safety_checker ([`FlaxStableDiffusionSafetyChecker`]):
            ä¼°è®¡ç”Ÿæˆå›¾åƒæ˜¯å¦å¯èƒ½è¢«è®¤ä¸ºæ˜¯å†’çŠ¯æ€§æˆ–æœ‰å®³çš„åˆ†ç±»æ¨¡å—ã€‚
            è¯·å‚è€ƒ [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5) ä»¥è·å–æœ‰å…³æ¨¡å‹æ½œåœ¨å±å®³çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
        feature_extractor ([`~transformers.CLIPImageProcessor`]):
            ä»ç”Ÿæˆå›¾åƒä¸­æå–ç‰¹å¾çš„ `CLIPImageProcessor`ï¼›ç”¨ä½œ `safety_checker` çš„è¾“å…¥ã€‚
    """

    # æ„é€ å‡½æ•°åˆå§‹åŒ–
    def __init__(
        # å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹å®ä¾‹
        vae: FlaxAutoencoderKL,
        # æ–‡æœ¬ç¼–ç å™¨æ¨¡å‹å®ä¾‹
        text_encoder: FlaxCLIPTextModel,
        # æ ‡è®°å™¨å®ä¾‹
        tokenizer: CLIPTokenizer,
        # å»å™ªæ¨¡å‹å®ä¾‹
        unet: FlaxUNet2DConditionModel,
        # è°ƒåº¦å™¨å®ä¾‹ï¼ŒæŒ‡å®šå¯ç”¨çš„è°ƒåº¦å™¨ç±»å‹
        scheduler: Union[
            FlaxDDIMScheduler, FlaxPNDMScheduler, FlaxLMSDiscreteScheduler, FlaxDPMSolverMultistepScheduler
        ],
        # å®‰å…¨æ£€æŸ¥æ¨¡å—å®ä¾‹
        safety_checker: FlaxStableDiffusionSafetyChecker,
        # ç‰¹å¾æå–å™¨å®ä¾‹
        feature_extractor: CLIPImageProcessor,
        # æ•°æ®ç±»å‹ï¼Œé»˜è®¤ä¸º float32
        dtype: jnp.dtype = jnp.float32,
    # å®šä¹‰åˆå§‹åŒ–æ–¹æ³•ï¼Œæ¥æ”¶å¤šä¸ªå‚æ•°
        ):
            # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
            super().__init__()
            # è®¾ç½®æ•°æ®ç±»å‹å±æ€§
            self.dtype = dtype
    
            # æ£€æŸ¥å®‰å…¨æ£€æŸ¥å™¨æ˜¯å¦ä¸º None
            if safety_checker is None:
                # è®°å½•è­¦å‘Šä¿¡æ¯ï¼Œæé†’ç”¨æˆ·ç¦ç”¨å®‰å…¨æ£€æŸ¥å™¨çš„é£é™©
                logger.warning(
                    f"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure"
                    " that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered"
                    " results in services or applications open to the public. Both the diffusers team and Hugging Face"
                    " strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling"
                    " it only for use-cases that involve analyzing network behavior or auditing its results. For more"
                    " information, please have a look at https://github.com/huggingface/diffusers/pull/254 ."
                )
    
            # æ£€æŸ¥ UNet ç‰ˆæœ¬æ˜¯å¦å°äº 0.9.0
            is_unet_version_less_0_9_0 = hasattr(unet.config, "_diffusers_version") and version.parse(
                version.parse(unet.config._diffusers_version).base_version
            ) < version.parse("0.9.0.dev0")
            # æ£€æŸ¥ UNet çš„æ ·æœ¬å¤§å°æ˜¯å¦å°äº 64
            is_unet_sample_size_less_64 = hasattr(unet.config, "sample_size") and unet.config.sample_size < 64
            # å¦‚æœæ»¡è¶³ä¸¤ä¸ªæ¡ä»¶ï¼Œæ„é€ å¼ƒç”¨è­¦å‘Šä¿¡æ¯
            if is_unet_version_less_0_9_0 and is_unet_sample_size_less_64:
                deprecation_message = (
                    "The configuration file of the unet has set the default `sample_size` to smaller than"
                    " 64 which seems highly unlikely .If you're checkpoint is a fine-tuned version of any of the"
                    " following: \n- CompVis/stable-diffusion-v1-4 \n- CompVis/stable-diffusion-v1-3 \n-"
                    " CompVis/stable-diffusion-v1-2 \n- CompVis/stable-diffusion-v1-1 \n- runwayml/stable-diffusion-v1-5"
                    " \n- runwayml/stable-diffusion-inpainting \n you should change 'sample_size' to 64 in the"
                    " configuration file. Please make sure to update the config accordingly as leaving `sample_size=32`"
                    " in the config might lead to incorrect results in future versions. If you have downloaded this"
                    " checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for"
                    " the `unet/config.json` file"
                )
                # è°ƒç”¨å¼ƒç”¨å‡½æ•°ï¼Œä¼ é€’è­¦å‘Šä¿¡æ¯
                deprecate("sample_size<64", "1.0.0", deprecation_message, standard_warn=False)
                # åˆ›å»ºæ–°é…ç½®å­—å…¸ï¼Œå¹¶æ›´æ–°æ ·æœ¬å¤§å°ä¸º 64
                new_config = dict(unet.config)
                new_config["sample_size"] = 64
                # å°†æ–°é…ç½®èµ‹å€¼ç»™ UNet çš„å†…éƒ¨å­—å…¸
                unet._internal_dict = FrozenDict(new_config)
    
            # æ³¨å†Œå¤šä¸ªæ¨¡å—ä»¥ä¾›ä½¿ç”¨
            self.register_modules(
                vae=vae,
                text_encoder=text_encoder,
                tokenizer=tokenizer,
                unet=unet,
                scheduler=scheduler,
                safety_checker=safety_checker,
                feature_extractor=feature_extractor,
            )
            # è®¡ç®— VAE çš„ç¼©æ”¾å› å­
            self.vae_scale_factor = 2 ** (len(self.vae.config.block_out_channels) - 1)
    
        # å®šä¹‰å‡†å¤‡è¾“å…¥çš„æ–¹æ³•ï¼Œæ¥æ”¶å¤šä¸ªå‚æ•°
        def prepare_inputs(
            self,
            # è¾“å…¥æç¤ºï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨
            prompt: Union[str, List[str]],
            # è¾“å…¥å›¾åƒï¼Œå¯ä»¥æ˜¯å•å¼ å›¾åƒæˆ–å›¾åƒåˆ—è¡¨
            image: Union[Image.Image, List[Image.Image]],
            # è¾“å…¥æ©ç ï¼Œå¯ä»¥æ˜¯å•å¼ æ©ç æˆ–æ©ç åˆ—è¡¨
            mask: Union[Image.Image, List[Image.Image]],
    ):
        # æ£€æŸ¥ prompt æ˜¯å¦ä¸ºå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ç±»å‹ï¼Œä¸ç¬¦åˆåˆ™æŠ›å‡ºå¼‚å¸¸
        if not isinstance(prompt, (str, list)):
            raise ValueError(f"`prompt` has to be of type `str` or `list` but is {type(prompt)}")

        # æ£€æŸ¥ image æ˜¯å¦ä¸º PIL å›¾åƒæˆ–åˆ—è¡¨ç±»å‹ï¼Œä¸ç¬¦åˆåˆ™æŠ›å‡ºå¼‚å¸¸
        if not isinstance(image, (Image.Image, list)):
            raise ValueError(f"image has to be of type `PIL.Image.Image` or list but is {type(image)}")

        # å¦‚æœ image æ˜¯å•ä¸ª PIL å›¾åƒï¼Œåˆ™å°†å…¶è½¬ä¸ºåˆ—è¡¨
        if isinstance(image, Image.Image):
            image = [image]

        # æ£€æŸ¥ mask æ˜¯å¦ä¸º PIL å›¾åƒæˆ–åˆ—è¡¨ç±»å‹ï¼Œä¸ç¬¦åˆåˆ™æŠ›å‡ºå¼‚å¸¸
        if not isinstance(mask, (Image.Image, list)):
            raise ValueError(f"image has to be of type `PIL.Image.Image` or list but is {type(image)}")

        # å¦‚æœ mask æ˜¯å•ä¸ª PIL å›¾åƒï¼Œåˆ™å°†å…¶è½¬ä¸ºåˆ—è¡¨
        if isinstance(mask, Image.Image):
            mask = [mask]

        # å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶åˆå¹¶ä¸ºä¸€ä¸ªæ•°ç»„
        processed_images = jnp.concatenate([preprocess_image(img, jnp.float32) for img in image])
        # å¯¹æ©è†œè¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶åˆå¹¶ä¸ºä¸€ä¸ªæ•°ç»„
        processed_masks = jnp.concatenate([preprocess_mask(m, jnp.float32) for m in mask])
        # å°†å¤„ç†åçš„æ©è†œä¸­å°äº0.5çš„å€¼è®¾ä¸º0
        processed_masks = processed_masks.at[processed_masks < 0.5].set(0)
        # å°†å¤„ç†åçš„æ©è†œä¸­å¤§äºç­‰äº0.5çš„å€¼è®¾ä¸º1
        processed_masks = processed_masks.at[processed_masks >= 0.5].set(1)

        # æ ¹æ®æ©è†œå¯¹å›¾åƒè¿›è¡Œé®ç½©å¤„ç†
        processed_masked_images = processed_images * (processed_masks < 0.5)

        # å°† prompt è¿›è¡Œç¼–ç ï¼Œå¹¶è®¾ç½®æœ€å¤§é•¿åº¦ã€å¡«å……å’Œæˆªæ–­
        text_input = self.tokenizer(
            prompt,
            padding="max_length",
            max_length=self.tokenizer.model_max_length,
            truncation=True,
            return_tensors="np",
        )
        # è¿”å›ç¼–ç åçš„è¾“å…¥ IDã€å¤„ç†åçš„å›¾åƒå’Œæ©è†œ
        return text_input.input_ids, processed_masked_images, processed_masks

    def _get_has_nsfw_concepts(self, features, params):
        # ä½¿ç”¨å®‰å…¨æ£€æŸ¥å™¨æ£€æŸ¥ç‰¹å¾ä¸­æ˜¯å¦å­˜åœ¨ NSFW æ¦‚å¿µ
        has_nsfw_concepts = self.safety_checker(features, params)
        # è¿”å› NSFW æ¦‚å¿µçš„æ£€æµ‹ç»“æœ
        return has_nsfw_concepts

    def _run_safety_checker(self, images, safety_model_params, jit=False):
        # å°†ä¼ å…¥çš„å›¾åƒæ•°ç»„è½¬æ¢ä¸º PIL å›¾åƒ
        pil_images = [Image.fromarray(image) for image in images]
        # æå–å›¾åƒç‰¹å¾å¹¶è¿”å›å¼ é‡å½¢å¼çš„åƒç´ å€¼
        features = self.feature_extractor(pil_images, return_tensors="np").pixel_values

        # å¦‚æœå¼€å¯ JIT ä¼˜åŒ–ï¼Œåˆ™å¯¹ç‰¹å¾è¿›è¡Œåˆ†ç‰‡
        if jit:
            features = shard(features)
            # ä½¿ç”¨ NSFW æ¦‚å¿µæ£€æµ‹å‡½æ•°è·å–ç»“æœ
            has_nsfw_concepts = _p_get_has_nsfw_concepts(self, features, safety_model_params)
            # å¯¹ç»“æœè¿›è¡Œååˆ†ç‰‡å¤„ç†
            has_nsfw_concepts = unshard(has_nsfw_concepts)
            safety_model_params = unreplicate(safety_model_params)
        else:
            # å¦åˆ™ç›´æ¥è°ƒç”¨è·å– NSFW æ¦‚å¿µçš„å‡½æ•°
            has_nsfw_concepts = self._get_has_nsfw_concepts(features, safety_model_params)

        images_was_copied = False
        # éå†æ¯ä¸ª NSFW æ¦‚å¿µçš„æ£€æµ‹ç»“æœ
        for idx, has_nsfw_concept in enumerate(has_nsfw_concepts):
            if has_nsfw_concept:
                # å¦‚æœå‘ç° NSFW æ¦‚å¿µä¸”å°šæœªå¤åˆ¶å›¾åƒï¼Œåˆ™è¿›è¡Œå¤åˆ¶
                if not images_was_copied:
                    images_was_copied = True
                    images = images.copy()

                # å°†å¯¹åº”å›¾åƒæ›¿æ¢ä¸ºé»‘è‰²å›¾åƒ
                images[idx] = np.zeros(images[idx].shape, dtype=np.uint8)  # black image

            # å¦‚æœæ£€æµ‹åˆ°ä»»ä½• NSFW æ¦‚å¿µï¼Œåˆ™å‘å‡ºè­¦å‘Š
            if any(has_nsfw_concepts):
                warnings.warn(
                    "Potential NSFW content was detected in one or more images. A black image will be returned"
                    " instead. Try again with a different prompt and/or seed."
                )

        # è¿”å›å¤„ç†åçš„å›¾åƒå’Œ NSFW æ¦‚å¿µçš„æ£€æµ‹ç»“æœ
        return images, has_nsfw_concepts
    # å®šä¹‰ä¸€ä¸ªç”Ÿæˆå‡½æ•°ï¼Œå¤„ç†å›¾åƒç”Ÿæˆçš„ç›¸å…³æ“ä½œ
        def _generate(
            # è¾“å…¥çš„æç¤ºIDæ•°ç»„ï¼Œé€šå¸¸ç”¨äºæ¨¡å‹è¾“å…¥
            self,
            prompt_ids: jnp.ndarray,
            # è¾“å…¥çš„æ©ç æ•°ç»„ï¼ŒæŒ‡ç¤ºå“ªäº›éƒ¨åˆ†éœ€è¦å¤„ç†
            mask: jnp.ndarray,
            # è¢«æ©ç çš„å›¾åƒæ•°ç»„ï¼Œä½œä¸ºç”Ÿæˆè¿‡ç¨‹çš„åŸºç¡€
            masked_image: jnp.ndarray,
            # æ¨¡å‹å‚æ•°ï¼Œå¯ä»¥æ˜¯å­—å…¸æˆ–å†»ç»“å­—å…¸ç±»å‹
            params: Union[Dict, FrozenDict],
            # éšæœºæ•°ç§å­ï¼Œç”¨äºç”Ÿæˆå¯é‡å¤çš„ç»“æœ
            prng_seed: jax.Array,
            # æ¨ç†æ­¥éª¤çš„æ•°é‡ï¼Œæ§åˆ¶ç”Ÿæˆçš„ç»†è‡´ç¨‹åº¦
            num_inference_steps: int,
            # ç”Ÿæˆå›¾åƒçš„é«˜åº¦
            height: int,
            # ç”Ÿæˆå›¾åƒçš„å®½åº¦
            width: int,
            # æŒ‡å¯¼æ¯”ä¾‹ï¼Œç”¨äºè°ƒæ•´ç”Ÿæˆå›¾åƒä¸æç¤ºçš„ç›¸å…³æ€§
            guidance_scale: float,
            # å¯é€‰çš„æ½œåœ¨è¡¨ç¤ºï¼Œç”¨äºè¿›ä¸€æ­¥æ§åˆ¶ç”Ÿæˆè¿‡ç¨‹
            latents: Optional[jnp.ndarray] = None,
            # å¯é€‰çš„è´Ÿæç¤ºIDæ•°ç»„ï¼Œç”¨äºå¢å¼ºç”Ÿæˆæ•ˆæœ
            neg_prompt_ids: Optional[jnp.ndarray] = None,
        # ä½¿ç”¨è£…é¥°å™¨æ›¿æ¢ç¤ºä¾‹æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæä¾›å‡½æ•°çš„æ–‡æ¡£è¯´æ˜
        @replace_example_docstring(EXAMPLE_DOC_STRING)
        # å®šä¹‰è°ƒç”¨å‡½æ•°ï¼Œè¿›è¡Œå›¾åƒç”Ÿæˆæ“ä½œ
        def __call__(
            # è¾“å…¥çš„æç¤ºIDæ•°ç»„
            self,
            prompt_ids: jnp.ndarray,
            # è¾“å…¥çš„æ©ç æ•°ç»„
            mask: jnp.ndarray,
            # è¢«æ©ç çš„å›¾åƒæ•°ç»„
            masked_image: jnp.ndarray,
            # æ¨¡å‹å‚æ•°
            params: Union[Dict, FrozenDict],
            # éšæœºæ•°ç§å­
            prng_seed: jax.Array,
            # æ¨ç†æ­¥éª¤çš„æ•°é‡ï¼Œé»˜è®¤ä¸º50
            num_inference_steps: int = 50,
            # ç”Ÿæˆå›¾åƒçš„é«˜åº¦ï¼Œé»˜è®¤ä¸ºNoneï¼ˆå¯é€‰ï¼‰
            height: Optional[int] = None,
            # ç”Ÿæˆå›¾åƒçš„å®½åº¦ï¼Œé»˜è®¤ä¸ºNoneï¼ˆå¯é€‰ï¼‰
            width: Optional[int] = None,
            # æŒ‡å¯¼æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º7.5
            guidance_scale: Union[float, jnp.ndarray] = 7.5,
            # å¯é€‰çš„æ½œåœ¨è¡¨ç¤ºï¼Œé»˜è®¤ä¸ºNone
            latents: jnp.ndarray = None,
            # å¯é€‰çš„è´Ÿæç¤ºIDæ•°ç»„ï¼Œé»˜è®¤ä¸ºNone
            neg_prompt_ids: jnp.ndarray = None,
            # è¿”å›å­—å…¸æ ¼å¼çš„ç»“æœï¼Œé»˜è®¤ä¸ºTrue
            return_dict: bool = True,
            # æ˜¯å¦ä½¿ç”¨JITç¼–è¯‘ï¼Œé»˜è®¤ä¸ºFalse
            jit: bool = False,
# é™æ€å‚æ•°ä¸ºç®¡é“ã€æ¨ç†æ­¥éª¤æ•°ã€é«˜åº¦å’Œå®½åº¦ã€‚æ›´æ”¹ä¼šè§¦å‘é‡æ–°ç¼–è¯‘ã€‚
# éé™æ€å‚æ•°ä¸ºåœ¨å…¶ç¬¬ä¸€ç»´åº¦ï¼ˆå› æ­¤ä¸º`0`ï¼‰æ˜ å°„çš„ï¼ˆåˆ†ç‰‡ï¼‰è¾“å…¥å¼ é‡ã€‚
@partial(
    jax.pmap,  # ä½¿ç”¨ JAX çš„å¹¶è¡Œæ˜ å°„åŠŸèƒ½
    in_axes=(None, 0, 0, 0, 0, 0, None, None, None, 0, 0, 0),  # æŒ‡å®šè¾“å…¥å¼ é‡çš„ç»´åº¦æ˜ å°„
    static_broadcasted_argnums=(0, 6, 7, 8),  # é™æ€å¹¿æ’­å‚æ•°çš„ç´¢å¼•
)
def _p_generate(
    pipe,  # ç®¡é“å¯¹è±¡
    prompt_ids,  # æç¤º ID
    mask,  # æ©ç 
    masked_image,  # è¢«æ©ç çš„å›¾åƒ
    params,  # å‚æ•°
    prng_seed,  # éšæœºç§å­
    num_inference_steps,  # æ¨ç†æ­¥éª¤æ•°
    height,  # å›¾åƒé«˜åº¦
    width,  # å›¾åƒå®½åº¦
    guidance_scale,  # å¼•å¯¼æ¯”ä¾‹
    latents,  # æ½œåœ¨è¡¨ç¤º
    neg_prompt_ids,  # è´Ÿæç¤º ID
):
    return pipe._generate(  # è°ƒç”¨ç®¡é“çš„ç”Ÿæˆæ–¹æ³•
        prompt_ids,  # æç¤º ID
        mask,  # æ©ç 
        masked_image,  # è¢«æ©ç çš„å›¾åƒ
        params,  # å‚æ•°
        prng_seed,  # éšæœºç§å­
        num_inference_steps,  # æ¨ç†æ­¥éª¤æ•°
        height,  # å›¾åƒé«˜åº¦
        width,  # å›¾åƒå®½åº¦
        guidance_scale,  # å¼•å¯¼æ¯”ä¾‹
        latents,  # æ½œåœ¨è¡¨ç¤º
        neg_prompt_ids,  # è´Ÿæç¤º ID
    )


@partial(jax.pmap, static_broadcasted_argnums=(0,))  # ä½¿ç”¨ JAX çš„å¹¶è¡Œæ˜ å°„åŠŸèƒ½
def _p_get_has_nsfw_concepts(pipe, features, params):  # æ£€æŸ¥ç‰¹å¾æ˜¯å¦åŒ…å« NSFW æ¦‚å¿µ
    return pipe._get_has_nsfw_concepts(features, params)  # è°ƒç”¨ç®¡é“çš„æ–¹æ³•


def unshard(x: jnp.ndarray):  # å®šä¹‰ unshard å‡½æ•°ï¼Œæ¥å—ä¸€ä¸ª ndarray
    # einops.rearrange(x, 'd b ... -> (d b) ...')  # ç”¨äºè°ƒæ•´å¼ é‡çš„å½¢çŠ¶
    num_devices, batch_size = x.shape[:2]  # è·å–è®¾å¤‡æ•°é‡å’Œæ‰¹æ¬¡å¤§å°
    rest = x.shape[2:]  # è·å–å…¶ä½™ç»´åº¦
    return x.reshape(num_devices * batch_size, *rest)  # é‡æ–°è°ƒæ•´å½¢çŠ¶ä¸º (d*b, ...)


def preprocess_image(image, dtype):  # å®šä¹‰é¢„å¤„ç†å›¾åƒçš„å‡½æ•°
    w, h = image.size  # è·å–å›¾åƒçš„å®½åº¦å’Œé«˜åº¦
    w, h = (x - x % 32 for x in (w, h))  # è°ƒæ•´å®½åº¦å’Œé«˜åº¦ä¸º 32 çš„æ•´æ•°å€
    image = image.resize((w, h), resample=PIL_INTERPOLATION["lanczos"])  # æŒ‰æ–°å¤§å°è°ƒæ•´å›¾åƒ
    image = jnp.array(image).astype(dtype) / 255.0  # è½¬æ¢ä¸º ndarray å¹¶å½’ä¸€åŒ–
    image = image[None].transpose(0, 3, 1, 2)  # è°ƒæ•´ç»´åº¦é¡ºåº
    return 2.0 * image - 1.0  # å°†å›¾åƒå€¼èŒƒå›´è°ƒæ•´åˆ° [-1, 1]


def preprocess_mask(mask, dtype):  # å®šä¹‰é¢„å¤„ç†æ©ç çš„å‡½æ•°
    w, h = mask.size  # è·å–æ©ç çš„å®½åº¦å’Œé«˜åº¦
    w, h = (x - x % 32 for x in (w, h))  # è°ƒæ•´å®½åº¦å’Œé«˜åº¦ä¸º 32 çš„æ•´æ•°å€
    mask = mask.resize((w, h))  # æŒ‰æ–°å¤§å°è°ƒæ•´æ©ç 
    mask = jnp.array(mask.convert("L")).astype(dtype) / 255.0  # è½¬æ¢ä¸ºç°åº¦å¹¶å½’ä¸€åŒ–
    mask = jnp.expand_dims(mask, axis=(0, 1))  # æ‰©å±•ç»´åº¦ä»¥é€‚åº”æ¨¡å‹è¾“å…¥

    return mask  # è¿”å›å¤„ç†åçš„æ©ç 
```