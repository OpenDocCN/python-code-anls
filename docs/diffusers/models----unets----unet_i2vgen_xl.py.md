# `.\diffusers\models\unets\unet_i2vgen_xl.py`

```
# ç‰ˆæƒå£°æ˜ï¼Œè¡¨æ˜ç‰ˆæƒå½’2024å¹´é˜¿é‡Œå·´å·´DAMO-VILABå’ŒHuggingFaceå›¢é˜Ÿæ‰€æœ‰
# æä¾›Apacheè®¸å¯è¯2.0ç‰ˆæœ¬çš„ä½¿ç”¨æ¡æ¬¾
# è¯´æ˜åªèƒ½åœ¨éµå¾ªè®¸å¯è¯çš„æƒ…å†µä¸‹ä½¿ç”¨æ­¤æ–‡ä»¶
# å¯åœ¨æŒ‡å®šç½‘å€è·å–è®¸å¯è¯å‰¯æœ¬
#
# é™¤éé€‚ç”¨æ³•å¾‹æˆ–ä¹¦é¢åè®®å¦æœ‰çº¦å®šï¼Œå¦åˆ™è½¯ä»¶æŒ‰â€œåŸæ ·â€åˆ†å‘
# ä¸æä¾›ä»»ä½•å½¢å¼çš„æ‹…ä¿æˆ–æ¡ä»¶
# è¯·å‚è§è®¸å¯è¯ä»¥è·å–ä¸æƒé™å’Œé™åˆ¶ç›¸å…³çš„å…·ä½“ä¿¡æ¯

from typing import Any, Dict, Optional, Tuple, Union  # å¯¼å…¥ç±»å‹æç¤ºå·¥å…·ï¼Œç”¨äºç±»å‹æ³¨è§£

import torch  # å¯¼å…¥PyTorchåº“
import torch.nn as nn  # å¯¼å…¥PyTorchçš„ç¥ç»ç½‘ç»œæ¨¡å—
import torch.utils.checkpoint  # å¯¼å…¥PyTorchçš„æ£€æŸ¥ç‚¹å·¥å…·

from ...configuration_utils import ConfigMixin, register_to_config  # ä»é…ç½®å·¥å…·å¯¼å…¥ç±»å’Œå‡½æ•°
from ...loaders import UNet2DConditionLoadersMixin  # å¯¼å…¥2Dæ¡ä»¶åŠ è½½å™¨æ··åˆç±»
from ...utils import logging  # å¯¼å…¥æ—¥å¿—å·¥å…·
from ..activations import get_activation  # å¯¼å…¥æ¿€æ´»å‡½æ•°è·å–å·¥å…·
from ..attention import Attention, FeedForward  # å¯¼å…¥æ³¨æ„åŠ›æœºåˆ¶å’Œå‰é¦ˆç½‘ç»œ
from ..attention_processor import (  # ä»æ³¨æ„åŠ›å¤„ç†å™¨æ¨¡å—å¯¼å…¥å¤šä¸ªå¤„ç†å™¨
    ADDED_KV_ATTENTION_PROCESSORS,
    CROSS_ATTENTION_PROCESSORS,
    AttentionProcessor,
    AttnAddedKVProcessor,
    AttnProcessor,
    FusedAttnProcessor2_0,
)
from ..embeddings import TimestepEmbedding, Timesteps  # å¯¼å…¥æ—¶é—´æ­¥åµŒå…¥å’Œæ—¶é—´æ­¥ç±»
from ..modeling_utils import ModelMixin  # å¯¼å…¥æ¨¡å‹æ··åˆç±»
from ..transformers.transformer_temporal import TransformerTemporalModel  # å¯¼å…¥æ—¶é—´å˜æ¢å™¨æ¨¡å‹
from .unet_3d_blocks import (  # ä»3D U-Netå—æ¨¡å—å¯¼å…¥å¤šä¸ªç±»
    CrossAttnDownBlock3D,
    CrossAttnUpBlock3D,
    DownBlock3D,
    UNetMidBlock3DCrossAttn,
    UpBlock3D,
    get_down_block,
    get_up_block,
)
from .unet_3d_condition import UNet3DConditionOutput  # å¯¼å…¥3Dæ¡ä»¶è¾“å‡ºç±»

logger = logging.get_logger(__name__)  # åˆ›å»ºæ—¥å¿—è®°å½•å™¨ï¼Œç”¨äºè®°å½•å½“å‰æ¨¡å—çš„ä¿¡æ¯

class I2VGenXLTransformerTemporalEncoder(nn.Module):  # å®šä¹‰ä¸€ä¸ªåä¸ºI2VGenXLTransformerTemporalEncoderçš„ç±»ï¼Œç»§æ‰¿è‡ªnn.Module
    def __init__(  # æ„é€ å‡½æ•°ï¼Œç”¨äºåˆå§‹åŒ–ç±»çš„å®ä¾‹
        self,
        dim: int,  # è¾“å…¥çš„ç‰¹å¾ç»´åº¦
        num_attention_heads: int,  # æ³¨æ„åŠ›å¤´çš„æ•°é‡
        attention_head_dim: int,  # æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦
        activation_fn: str = "geglu",  # æ¿€æ´»å‡½æ•°ç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨geglu
        upcast_attention: bool = False,  # æ˜¯å¦æå‡æ³¨æ„åŠ›è®¡ç®—çš„ç²¾åº¦
        ff_inner_dim: Optional[int] = None,  # å‰é¦ˆç½‘ç»œçš„å†…éƒ¨ç»´åº¦ï¼Œé»˜è®¤ä¸ºNone
        dropout: int = 0.0,  # dropoutæ¦‚ç‡ï¼Œé»˜è®¤ä¸º0.0
    ):
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        self.norm1 = nn.LayerNorm(dim, elementwise_affine=True, eps=1e-5)  # åˆå§‹åŒ–å±‚å½’ä¸€åŒ–å±‚
        self.attn1 = Attention(  # åˆå§‹åŒ–æ³¨æ„åŠ›å±‚
            query_dim=dim,  # æŸ¥è¯¢ç»´åº¦
            heads=num_attention_heads,  # æ³¨æ„åŠ›å¤´æ•°é‡
            dim_head=attention_head_dim,  # æ¯ä¸ªå¤´çš„ç»´åº¦
            dropout=dropout,  # dropoutæ¦‚ç‡
            bias=False,  # ä¸ä½¿ç”¨åç½®
            upcast_attention=upcast_attention,  # æ˜¯å¦æå‡æ³¨æ„åŠ›è®¡ç®—ç²¾åº¦
            out_bias=True,  # è¾“å‡ºä½¿ç”¨åç½®
        )
        self.ff = FeedForward(  # åˆå§‹åŒ–å‰é¦ˆç½‘ç»œ
            dim,  # è¾“å…¥ç»´åº¦
            dropout=dropout,  # dropoutæ¦‚ç‡
            activation_fn=activation_fn,  # æ¿€æ´»å‡½æ•°ç±»å‹
            final_dropout=False,  # æœ€åå±‚ä¸ä½¿ç”¨dropout
            inner_dim=ff_inner_dim,  # å†…éƒ¨ç»´åº¦
            bias=True,  # ä½¿ç”¨åç½®
        )

    def forward(  # å®šä¹‰å‰å‘ä¼ æ’­æ–¹æ³•
        self,
        hidden_states: torch.Tensor,  # è¾“å…¥çš„éšè—çŠ¶æ€
    # è¯¥æ–¹æ³•è¿”å›å¤„ç†åçš„éšè—çŠ¶æ€å¼ é‡
    ) -> torch.Tensor:
        # å¯¹éšè—çŠ¶æ€è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
        norm_hidden_states = self.norm1(hidden_states)
        # è®¡ç®—æ³¨æ„åŠ›è¾“å‡ºï¼Œä½¿ç”¨å½’ä¸€åŒ–åçš„éšè—çŠ¶æ€
        attn_output = self.attn1(norm_hidden_states, encoder_hidden_states=None)
        # å°†æ³¨æ„åŠ›è¾“å‡ºä¸åŸå§‹éšè—çŠ¶æ€ç›¸åŠ ï¼Œæ›´æ–°éšè—çŠ¶æ€
        hidden_states = attn_output + hidden_states
        # å¦‚æœéšè—çŠ¶æ€æ˜¯å››ç»´ï¼Œåˆ™å»æ‰ç¬¬ä¸€ç»´
        if hidden_states.ndim == 4:
            hidden_states = hidden_states.squeeze(1)
    
        # é€šè¿‡å‰é¦ˆç½‘ç»œå¤„ç†éšè—çŠ¶æ€
        ff_output = self.ff(hidden_states)
        # å°†å‰é¦ˆè¾“å‡ºä¸å½“å‰éšè—çŠ¶æ€ç›¸åŠ ï¼Œæ›´æ–°éšè—çŠ¶æ€
        hidden_states = ff_output + hidden_states
        # å¦‚æœéšè—çŠ¶æ€æ˜¯å››ç»´ï¼Œåˆ™å»æ‰ç¬¬ä¸€ç»´
        if hidden_states.ndim == 4:
            hidden_states = hidden_states.squeeze(1)
    
        # è¿”å›æœ€ç»ˆçš„éšè—çŠ¶æ€
        return hidden_states
# å®šä¹‰ I2VGenXL UNet ç±»ï¼Œç»§æ‰¿å¤šä¸ªæ··å…¥ç±»ä»¥å¢åŠ åŠŸèƒ½
class I2VGenXLUNet(ModelMixin, ConfigMixin, UNet2DConditionLoadersMixin):
    r"""
    I2VGenXL UNetã€‚ä¸€ä¸ªæ¡ä»¶3D UNetæ¨¡å‹ï¼Œæ¥æ”¶å™ªå£°æ ·æœ¬ã€æ¡ä»¶çŠ¶æ€å’Œæ—¶é—´æ­¥ï¼Œ
    è¿”å›ä¸æ ·æœ¬å½¢çŠ¶ç›¸åŒçš„è¾“å‡ºã€‚

    è¯¥æ¨¡å‹ç»§æ‰¿è‡ª [`ModelMixin`]ã€‚æœ‰å…³æ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ï¼‰ï¼Œ
    è¯·æŸ¥çœ‹è¶…ç±»æ–‡æ¡£ã€‚

    å‚æ•°ï¼š
        sample_size (`int` æˆ– `Tuple[int, int]`, *å¯é€‰*, é»˜è®¤å€¼ä¸º `None`):
            è¾“å…¥/è¾“å‡ºæ ·æœ¬çš„é«˜åº¦å’Œå®½åº¦ã€‚
        in_channels (`int`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 4): è¾“å…¥æ ·æœ¬çš„é€šé“æ•°ã€‚
        out_channels (`int`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 4): è¾“å‡ºæ ·æœ¬çš„é€šé“æ•°ã€‚
        down_block_types (`Tuple[str]`, *å¯é€‰*, é»˜è®¤å€¼ä¸º `("CrossAttnDownBlock2D", "CrossAttnDownBlock2D", "CrossAttnDownBlock2D", "DownBlock2D")`):
            ä½¿ç”¨çš„ä¸‹é‡‡æ ·å—çš„å…ƒç»„ã€‚
        up_block_types (`Tuple[str]`, *å¯é€‰*, é»˜è®¤å€¼ä¸º `("UpBlock2D", "CrossAttnUpBlock2D", "CrossAttnUpBlock2D", "CrossAttnUpBlock2D")`):
            ä½¿ç”¨çš„ä¸Šé‡‡æ ·å—çš„å…ƒç»„ã€‚
        block_out_channels (`Tuple[int]`, *å¯é€‰*, é»˜è®¤å€¼ä¸º `(320, 640, 1280, 1280)`):
            æ¯ä¸ªå—çš„è¾“å‡ºé€šé“å…ƒç»„ã€‚
        layers_per_block (`int`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 2): æ¯ä¸ªå—çš„å±‚æ•°ã€‚
        norm_num_groups (`int`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 32): ç”¨äºå½’ä¸€åŒ–çš„ç»„æ•°ã€‚
            å¦‚æœä¸º `None`ï¼Œåˆ™è·³è¿‡åå¤„ç†ä¸­çš„å½’ä¸€åŒ–å’Œæ¿€æ´»å±‚ã€‚
        cross_attention_dim (`int`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 1280): è·¨æ³¨æ„åŠ›ç‰¹å¾çš„ç»´åº¦ã€‚
        attention_head_dim (`int`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 64): æ³¨æ„åŠ›å¤´çš„ç»´åº¦ã€‚
        num_attention_heads (`int`, *å¯é€‰*): æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€‚
    """

    # è®¾ç½®ä¸æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹çš„å±æ€§ä¸º False
    _supports_gradient_checkpointing = False

    @register_to_config
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œæ¥å—å¤šç§å¯é€‰å‚æ•°ä»¥è®¾ç½®æ¨¡å‹é…ç½®
    def __init__(
        self,
        sample_size: Optional[int] = None,  # è¾“å…¥/è¾“å‡ºæ ·æœ¬å¤§å°ï¼Œé»˜è®¤ä¸º None
        in_channels: int = 4,  # è¾“å…¥æ ·æœ¬çš„é€šé“æ•°ï¼Œé»˜è®¤ä¸º 4
        out_channels: int = 4,  # è¾“å‡ºæ ·æœ¬çš„é€šé“æ•°ï¼Œé»˜è®¤ä¸º 4
        down_block_types: Tuple[str, ...] = (  # ä¸‹é‡‡æ ·å—çš„ç±»å‹ï¼Œé»˜è®¤ä¸ºæŒ‡å®šçš„å…ƒç»„
            "CrossAttnDownBlock3D",
            "CrossAttnDownBlock3D",
            "CrossAttnDownBlock3D",
            "DownBlock3D",
        ),
        up_block_types: Tuple[str, ...] = (  # ä¸Šé‡‡æ ·å—çš„ç±»å‹ï¼Œé»˜è®¤ä¸ºæŒ‡å®šçš„å…ƒç»„
            "UpBlock3D",
            "CrossAttnUpBlock3D",
            "CrossAttnUpBlock3D",
            "CrossAttnUpBlock3D",
        ),
        block_out_channels: Tuple[int, ...] = (320, 640, 1280, 1280),  # æ¯ä¸ªå—çš„è¾“å‡ºé€šé“ï¼Œé»˜è®¤ä¸ºæŒ‡å®šçš„å…ƒç»„
        layers_per_block: int = 2,  # æ¯ä¸ªå—çš„å±‚æ•°ï¼Œé»˜è®¤ä¸º 2
        norm_num_groups: Optional[int] = 32,  # å½’ä¸€åŒ–ç»„æ•°ï¼Œé»˜è®¤ä¸º 32
        cross_attention_dim: int = 1024,  # è·¨æ³¨æ„åŠ›ç‰¹å¾çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º 1024
        attention_head_dim: Union[int, Tuple[int]] = 64,  # æ³¨æ„åŠ›å¤´çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º 64
        num_attention_heads: Optional[Union[int, Tuple[int]]] = None,  # æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼Œé»˜è®¤ä¸º None
    @property
    # è¯¥å±æ€§ä» UNet2DConditionModel çš„ attn_processors å¤åˆ¶
    # å®šä¹‰è¿”å›æ³¨æ„åŠ›å¤„ç†å™¨çš„å‡½æ•°ï¼Œè¿”å›ç±»å‹ä¸ºå­—å…¸ï¼Œé”®ä¸ºå­—ç¬¦ä¸²ï¼Œå€¼ä¸º AttentionProcessor å¯¹è±¡
    def attn_processors(self) -> Dict[str, AttentionProcessor]:
        r"""
        Returns:
            `dict` of attention processors: A dictionary containing all attention processors used in the model with
            indexed by its weight name.
        """
        # åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸ï¼Œç”¨äºå­˜å‚¨å¤„ç†å™¨
        processors = {}

        # å®šä¹‰ä¸€ä¸ªé€’å½’å‡½æ•°ï¼Œç”¨äºæ·»åŠ å¤„ç†å™¨åˆ°å­—å…¸
        def fn_recursive_add_processors(name: str, module: torch.nn.Module, processors: Dict[str, AttentionProcessor]):
            # æ£€æŸ¥æ¨¡å—æ˜¯å¦æœ‰ get_processor æ–¹æ³•
            if hasattr(module, "get_processor"):
                # å°†å¤„ç†å™¨æ·»åŠ åˆ°å­—å…¸ä¸­ï¼Œé”®ä¸ºåç§°åŠ ä¸Š ".processor"
                processors[f"{name}.processor"] = module.get_processor()

            # éå†æ¨¡å—çš„å­æ¨¡å—
            for sub_name, child in module.named_children():
                # é€’å½’è°ƒç”¨ï¼Œå¤„ç†å­æ¨¡å—
                fn_recursive_add_processors(f"{name}.{sub_name}", child, processors)

            # è¿”å›æ›´æ–°åçš„å¤„ç†å™¨å­—å…¸
            return processors

        # éå†å½“å‰å¯¹è±¡çš„æ‰€æœ‰å­æ¨¡å—
        for name, module in self.named_children():
            # è°ƒç”¨é€’å½’å‡½æ•°ï¼Œå°†å¤„ç†å™¨æ·»åŠ åˆ°å­—å…¸ä¸­
            fn_recursive_add_processors(name, module, processors)

        # è¿”å›åŒ…å«æ‰€æœ‰å¤„ç†å™¨çš„å­—å…¸
        return processors

    # ä» diffusers.models.unets.unet_2d_condition ä¸­å¤åˆ¶çš„è®¾ç½®æ³¨æ„åŠ›å¤„ç†å™¨çš„å‡½æ•°
    def set_attn_processor(self, processor: Union[AttentionProcessor, Dict[str, AttentionProcessor]]):
        r"""
        Sets the attention processor to use to compute attention.

        Parameters:
            processor (`dict` of `AttentionProcessor` or only `AttentionProcessor`):
                The instantiated processor class or a dictionary of processor classes that will be set as the processor
                for **all** `Attention` layers.

                If `processor` is a dict, the key needs to define the path to the corresponding cross attention
                processor. This is strongly recommended when setting trainable attention processors.

        """
        # è·å–å½“å‰æ³¨æ„åŠ›å¤„ç†å™¨çš„æ•°é‡
        count = len(self.attn_processors.keys())

        # å¦‚æœä¼ å…¥çš„æ˜¯å­—å…¸ä¸”æ•°é‡ä¸åŒ¹é…ï¼Œåˆ™å¼•å‘é”™è¯¯
        if isinstance(processor, dict) and len(processor) != count:
            raise ValueError(
                f"A dict of processors was passed, but the number of processors {len(processor)} does not match the"
                f" number of attention layers: {count}. Please make sure to pass {count} processor classes."
            )

        # å®šä¹‰ä¸€ä¸ªé€’å½’å‡½æ•°ï¼Œç”¨äºè®¾ç½®å¤„ç†å™¨
        def fn_recursive_attn_processor(name: str, module: torch.nn.Module, processor):
            # æ£€æŸ¥æ¨¡å—æ˜¯å¦æœ‰ set_processor æ–¹æ³•
            if hasattr(module, "set_processor"):
                # å¦‚æœä¼ å…¥çš„å¤„ç†å™¨ä¸æ˜¯å­—å…¸ï¼Œç›´æ¥è®¾ç½®
                if not isinstance(processor, dict):
                    module.set_processor(processor)
                else:
                    # ä»å­—å…¸ä¸­ç§»é™¤å¹¶è®¾ç½®å¯¹åº”çš„å¤„ç†å™¨
                    module.set_processor(processor.pop(f"{name}.processor"))

            # éå†æ¨¡å—çš„å­æ¨¡å—
            for sub_name, child in module.named_children():
                # é€’å½’è°ƒç”¨ï¼Œè®¾ç½®å­æ¨¡å—çš„å¤„ç†å™¨
                fn_recursive_attn_processor(f"{name}.{sub_name}", child, processor)

        # éå†å½“å‰å¯¹è±¡çš„æ‰€æœ‰å­æ¨¡å—
        for name, module in self.named_children():
            # è°ƒç”¨é€’å½’å‡½æ•°ï¼Œä¸ºæ¯ä¸ªæ¨¡å—è®¾ç½®å¤„ç†å™¨
            fn_recursive_attn_processor(name, module, processor)

    # ä» diffusers.models.unets.unet_3d_condition ä¸­å¤åˆ¶çš„å¯ç”¨å‰å‘åˆ†å—çš„å‡½æ•°
    # å¯ç”¨å‰é¦ˆå±‚çš„åˆ†å—å¤„ç†
    def enable_forward_chunking(self, chunk_size: Optional[int] = None, dim: int = 0) -> None:
        """
        è®¾ç½®æ³¨æ„åŠ›å¤„ç†å™¨ä½¿ç”¨[å‰é¦ˆåˆ†å—](https://huggingface.co/blog/reformer#2-chunked-feed-forward-layers)ã€‚

        å‚æ•°:
            chunk_size (`int`, *å¯é€‰*):
                å‰é¦ˆå±‚çš„å—å¤§å°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†å¯¹ç»´åº¦ä¸º`dim`çš„æ¯ä¸ªå¼ é‡å•ç‹¬è¿è¡Œå‰é¦ˆå±‚ã€‚
            dim (`int`, *å¯é€‰*, é»˜è®¤ä¸º`0`):
                å‰é¦ˆè®¡ç®—åº”åˆ†å—çš„ç»´åº¦ã€‚å¯ä»¥é€‰æ‹©dim=0ï¼ˆæ‰¹æ¬¡ï¼‰æˆ–dim=1ï¼ˆåºåˆ—é•¿åº¦ï¼‰ã€‚
        """
        # æ£€æŸ¥ç»´åº¦æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
        if dim not in [0, 1]:
            # æŠ›å‡ºé”™è¯¯ï¼Œç¡®ä¿dimåªä¸º0æˆ–1
            raise ValueError(f"Make sure to set `dim` to either 0 or 1, not {dim}")

        # é»˜è®¤å—å¤§å°ä¸º1
        chunk_size = chunk_size or 1

        # å®šä¹‰é€’å½’å‡½æ•°ï¼Œç”¨äºè®¾ç½®æ¯ä¸ªæ¨¡å—çš„å‰é¦ˆåˆ†å—
        def fn_recursive_feed_forward(module: torch.nn.Module, chunk_size: int, dim: int):
            # å¦‚æœæ¨¡å—æœ‰è®¾ç½®åˆ†å—å‰é¦ˆçš„æ–¹æ³•ï¼Œè°ƒç”¨è¯¥æ–¹æ³•
            if hasattr(module, "set_chunk_feed_forward"):
                module.set_chunk_feed_forward(chunk_size=chunk_size, dim=dim)

            # é€’å½’éå†å­æ¨¡å—
            for child in module.children():
                fn_recursive_feed_forward(child, chunk_size, dim)

        # å¯¹å½“å‰å¯¹è±¡çš„æ‰€æœ‰å­æ¨¡å—åº”ç”¨å‰é¦ˆåˆ†å—è®¾ç½®
        for module in self.children():
            fn_recursive_feed_forward(module, chunk_size, dim)

    # ä»diffusers.models.unets.unet_3d_condition.UNet3DConditionModelå¤åˆ¶çš„ç¦ç”¨å‰é¦ˆåˆ†å—çš„æ–¹æ³•
    def disable_forward_chunking(self):
        # å®šä¹‰é€’å½’å‡½æ•°ï¼Œç”¨äºç¦ç”¨æ¨¡å—çš„å‰é¦ˆåˆ†å—
        def fn_recursive_feed_forward(module: torch.nn.Module, chunk_size: int, dim: int):
            # å¦‚æœæ¨¡å—æœ‰è®¾ç½®åˆ†å—å‰é¦ˆçš„æ–¹æ³•ï¼Œè°ƒç”¨è¯¥æ–¹æ³•
            if hasattr(module, "set_chunk_feed_forward"):
                module.set_chunk_feed_forward(chunk_size=chunk_size, dim=dim)

            # é€’å½’éå†å­æ¨¡å—
            for child in module.children():
                fn_recursive_feed_forward(child, chunk_size, dim)

        # å¯¹å½“å‰å¯¹è±¡çš„æ‰€æœ‰å­æ¨¡å—åº”ç”¨ç¦ç”¨å‰é¦ˆåˆ†å—è®¾ç½®
        for module in self.children():
            fn_recursive_feed_forward(module, None, 0)

    # ä»diffusers.models.unets.unet_2d_condition.UNet2DConditionModelå¤åˆ¶çš„è®¾ç½®é»˜è®¤æ³¨æ„åŠ›å¤„ç†å™¨çš„æ–¹æ³•
    def set_default_attn_processor(self):
        """
        ç¦ç”¨è‡ªå®šä¹‰æ³¨æ„åŠ›å¤„ç†å™¨å¹¶è®¾ç½®é»˜è®¤çš„æ³¨æ„åŠ›å®ç°ã€‚
        """
        # æ£€æŸ¥æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨æ˜¯å¦å±äºå·²æ·»åŠ çš„KVæ³¨æ„åŠ›å¤„ç†å™¨ç±»
        if all(proc.__class__ in ADDED_KV_ATTENTION_PROCESSORS for proc in self.attn_processors.values()):
            # å¦‚æœæ˜¯ï¼Œåˆ™è®¾ç½®ä¸ºå·²æ·»åŠ KVå¤„ç†å™¨
            processor = AttnAddedKVProcessor()
        # æ£€æŸ¥æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨æ˜¯å¦å±äºäº¤å‰æ³¨æ„åŠ›å¤„ç†å™¨ç±»
        elif all(proc.__class__ in CROSS_ATTENTION_PROCESSORS for proc in self.attn_processors.values()):
            # å¦‚æœæ˜¯ï¼Œåˆ™è®¾ç½®ä¸ºæ ‡å‡†æ³¨æ„åŠ›å¤„ç†å™¨
            processor = AttnProcessor()
        else:
            # æŠ›å‡ºé”™è¯¯ï¼Œè¯´æ˜å½“å‰çš„æ³¨æ„åŠ›å¤„ç†å™¨ç±»å‹ä¸è¢«æ”¯æŒ
            raise ValueError(
                f"Cannot call `set_default_attn_processor` when attention processors are of type {next(iter(self.attn_processors.values()))}"
            )

        # è®¾ç½®å½“å‰å¯¹è±¡çš„æ³¨æ„åŠ›å¤„ç†å™¨ä¸ºé€‰æ‹©çš„å¤„ç†å™¨
        self.set_attn_processor(processor)

    # ä»diffusers.models.unets.unet_3d_condition.UNet3DConditionModelå¤åˆ¶çš„è®¾ç½®æ¢¯åº¦æ£€æŸ¥ç‚¹çš„æ–¹æ³•
    # è®¾ç½®æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ŒæŒ‡å®šæ¨¡å—å’Œå¸ƒå°”å€¼
    def _set_gradient_checkpointing(self, module, value: bool = False) -> None:
        # æ£€æŸ¥æ¨¡å—æ˜¯å¦ä¸ºæŒ‡å®šçš„ç±»å‹ä¹‹ä¸€
        if isinstance(module, (CrossAttnDownBlock3D, DownBlock3D, CrossAttnUpBlock3D, UpBlock3D)):
            # è®¾ç½®æ¨¡å—çš„æ¢¯åº¦æ£€æŸ¥ç‚¹å±æ€§ä¸ºæŒ‡å®šå€¼
            module.gradient_checkpointing = value

    # ä» UNet2DConditionModel ä¸­å¤åˆ¶çš„å¯ç”¨ FreeU æ–¹æ³•
    def enable_freeu(self, s1, s2, b1, b2):
        r"""å¯ç”¨ FreeU æœºåˆ¶ï¼Œè¯¦æƒ…è§ https://arxiv.org/abs/2309.11497.

        åç¼€è¡¨ç¤ºç¼©æ”¾å› å­åº”ç”¨çš„é˜¶æ®µå—ã€‚

        è¯·å‚è€ƒ [å®˜æ–¹åº“](https://github.com/ChenyangSi/FreeU) ä»¥è·å–é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚ Stable Diffusion v1, v2 å’Œ Stable Diffusion XLï¼‰çš„æœ‰æ•ˆå€¼ç»„åˆã€‚

        å‚æ•°ï¼š
            s1 (`float`):
                é˜¶æ®µ 1 çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾çš„è´¡çŒ®ï¼Œä»¥ç¼“è§£å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡å¹³æ»‘æ•ˆåº”â€ã€‚
            s2 (`float`):
                é˜¶æ®µ 2 çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾çš„è´¡çŒ®ï¼Œä»¥ç¼“è§£å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡å¹³æ»‘æ•ˆåº”â€ã€‚
            b1 (`float`): é˜¶æ®µ 1 çš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§ä¸»å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚
            b2 (`float`): é˜¶æ®µ 2 çš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§ä¸»å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚
        """
        # éå†ä¸Šé‡‡æ ·å—ï¼Œç´¢å¼• i å’Œå—å¯¹è±¡ upsample_block
        for i, upsample_block in enumerate(self.up_blocks):
            # è®¾ç½®ä¸Šé‡‡æ ·å—çš„å±æ€§ s1 ä¸ºç»™å®šå€¼ s1
            setattr(upsample_block, "s1", s1)
            # è®¾ç½®ä¸Šé‡‡æ ·å—çš„å±æ€§ s2 ä¸ºç»™å®šå€¼ s2
            setattr(upsample_block, "s2", s2)
            # è®¾ç½®ä¸Šé‡‡æ ·å—çš„å±æ€§ b1 ä¸ºç»™å®šå€¼ b1
            setattr(upsample_block, "b1", b1)
            # è®¾ç½®ä¸Šé‡‡æ ·å—çš„å±æ€§ b2 ä¸ºç»™å®šå€¼ b2
            setattr(upsample_block, "b2", b2)

    # ä» UNet2DConditionModel ä¸­å¤åˆ¶çš„ç¦ç”¨ FreeU æ–¹æ³•
    def disable_freeu(self):
        """ç¦ç”¨ FreeU æœºåˆ¶ã€‚"""
        # å®šä¹‰ FreeU ç›¸å…³çš„å±æ€§é”®
        freeu_keys = {"s1", "s2", "b1", "b2"}
        # éå†ä¸Šé‡‡æ ·å—ï¼Œç´¢å¼• i å’Œå—å¯¹è±¡ upsample_block
        for i, upsample_block in enumerate(self.up_blocks):
            # éå† FreeU å±æ€§é”®
            for k in freeu_keys:
                # å¦‚æœä¸Šé‡‡æ ·å—å…·æœ‰è¯¥å±æ€§æˆ–å±æ€§å€¼ä¸ä¸º None
                if hasattr(upsample_block, k) or getattr(upsample_block, k, None) is not None:
                    # å°†ä¸Šé‡‡æ ·å—çš„è¯¥å±æ€§è®¾ç½®ä¸º None
                    setattr(upsample_block, k, None)

    # ä» UNet2DConditionModel ä¸­å¤åˆ¶çš„èåˆ QKV æŠ•å½±æ–¹æ³•
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºå¯ç”¨èåˆçš„ QKV æŠ•å½±
    def fuse_qkv_projections(self):
        # æä¾›æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæè¿°å…¶åŠŸèƒ½å’Œè­¦å‘Šä¿¡æ¯
        """
        Enables fused QKV projections. For self-attention modules, all projection matrices (i.e., query, key, value)
        are fused. For cross-attention modules, key and value projection matrices are fused.
    
        <Tip warning={true}>
    
        This API is ğŸ§ª experimental.
    
        </Tip>
        """
        # åˆå§‹åŒ–åŸå§‹æ³¨æ„åŠ›å¤„ç†å™¨ä¸º None
        self.original_attn_processors = None
    
        # éå†å½“å‰å¯¹è±¡çš„æ³¨æ„åŠ›å¤„ç†å™¨
        for _, attn_processor in self.attn_processors.items():
            # æ£€æŸ¥å¤„ç†å™¨ç±»åä¸­æ˜¯å¦åŒ…å« "Added"
            if "Added" in str(attn_processor.__class__.__name__):
                # å¦‚æœåŒ…å«ï¼ŒæŠ›å‡ºå¼‚å¸¸æç¤ºä¸æ”¯æŒ
                raise ValueError("`fuse_qkv_projections()` is not supported for models having added KV projections.")
    
        # ä¿å­˜å½“å‰çš„æ³¨æ„åŠ›å¤„ç†å™¨ä»¥å¤‡åç”¨
        self.original_attn_processors = self.attn_processors
    
        # éå†å½“å‰å¯¹è±¡çš„æ‰€æœ‰æ¨¡å—
        for module in self.modules():
            # æ£€æŸ¥æ¨¡å—æ˜¯å¦ä¸º Attention ç±»å‹
            if isinstance(module, Attention):
                # è°ƒç”¨æ¨¡å—çš„æ–¹æ³•ï¼Œå¯ç”¨èåˆæŠ•å½±
                module.fuse_projections(fuse=True)
    
        # è®¾ç½®æ³¨æ„åŠ›å¤„ç†å™¨ä¸º FusedAttnProcessor2_0 çš„å®ä¾‹
        self.set_attn_processor(FusedAttnProcessor2_0())
    
    # ä» UNet2DConditionModel å¤åˆ¶çš„æ–¹æ³•ï¼Œç”¨äºç¦ç”¨èåˆçš„ QKV æŠ•å½±
    def unfuse_qkv_projections(self):
        # æä¾›æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæè¿°å…¶åŠŸèƒ½å’Œè­¦å‘Šä¿¡æ¯
        """Disables the fused QKV projection if enabled.
    
        <Tip warning={true}>
    
        This API is ğŸ§ª experimental.
    
        </Tip>
    
        """
        # æ£€æŸ¥åŸå§‹æ³¨æ„åŠ›å¤„ç†å™¨æ˜¯å¦ä¸ä¸º None
        if self.original_attn_processors is not None:
            # å¦‚æœä¸ä¸º Noneï¼Œæ¢å¤åŸå§‹çš„æ³¨æ„åŠ›å¤„ç†å™¨
            self.set_attn_processor(self.original_attn_processors)
    
    # å®šä¹‰å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œæ¥å—å¤šä¸ªè¾“å…¥å‚æ•°
    def forward(
        self,
        sample: torch.Tensor,
        timestep: Union[torch.Tensor, float, int],
        fps: torch.Tensor,
        image_latents: torch.Tensor,
        image_embeddings: Optional[torch.Tensor] = None,
        encoder_hidden_states: Optional[torch.Tensor] = None,
        timestep_cond: Optional[torch.Tensor] = None,
        cross_attention_kwargs: Optional[Dict[str, Any]] = None,
        return_dict: bool = True,
```