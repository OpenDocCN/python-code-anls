# `.\diffusers\pipelines\deprecated\versatile_diffusion\modeling_text_unet.py`

```
# ä» typing æ¨¡å—å¯¼å…¥å„ç§ç±»å‹æ³¨è§£
from typing import Any, Dict, List, Optional, Tuple, Union

# å¯¼å…¥ numpy åº“ï¼Œç”¨äºæ•°ç»„å’ŒçŸ©é˜µæ“ä½œ
import numpy as np
# å¯¼å…¥ PyTorch åº“ï¼Œè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ„å»ºå’Œè®­ç»ƒ
import torch
# å¯¼å…¥ PyTorch çš„ç¥ç»ç½‘ç»œæ¨¡å—
import torch.nn as nn
# å¯¼å…¥ PyTorch çš„åŠŸèƒ½æ€§æ¨¡å—ï¼Œæä¾›å¸¸ç”¨æ“ä½œ
import torch.nn.functional as F

# ä» diffusers.utils æ¨¡å—å¯¼å…¥ deprecate å‡½æ•°ï¼Œç”¨äºå¤„ç†å¼ƒç”¨è­¦å‘Š
from diffusers.utils import deprecate

# å¯¼å…¥é…ç½®ç›¸å…³çš„ç±»å’Œå‡½æ•°
from ....configuration_utils import ConfigMixin, register_to_config
# å¯¼å…¥æ¨¡å‹ç›¸å…³çš„åŸºç±»
from ....models import ModelMixin
# å¯¼å…¥æ¿€æ´»å‡½æ•°è·å–å·¥å…·
from ....models.activations import get_activation
# å¯¼å…¥æ³¨æ„åŠ›å¤„ç†å™¨ç›¸å…³ç»„ä»¶
from ....models.attention_processor import (
    ADDED_KV_ATTENTION_PROCESSORS,  # é¢å¤–é”®å€¼æ³¨æ„åŠ›å¤„ç†å™¨
    CROSS_ATTENTION_PROCESSORS,      # äº¤å‰æ³¨æ„åŠ›å¤„ç†å™¨
    Attention,                       # æ³¨æ„åŠ›æœºåˆ¶ç±»
    AttentionProcessor,              # æ³¨æ„åŠ›å¤„ç†å™¨åŸºç±»
    AttnAddedKVProcessor,            # é¢å¤–é”®å€¼æ³¨æ„åŠ›å¤„ç†å™¨ç±»
    AttnAddedKVProcessor2_0,         # ç‰ˆæœ¬ 2.0 çš„é¢å¤–é”®å€¼æ³¨æ„åŠ›å¤„ç†å™¨
    AttnProcessor,                   # åŸºç¡€æ³¨æ„åŠ›å¤„ç†å™¨
)
# å¯¼å…¥åµŒå…¥å±‚ç›¸å…³ç»„ä»¶
from ....models.embeddings import (
    GaussianFourierProjection,        # é«˜æ–¯å‚…é‡Œå¶æŠ•å½±ç±»
    ImageHintTimeEmbedding,           # å›¾åƒæç¤ºæ—¶é—´åµŒå…¥ç±»
    ImageProjection,                  # å›¾åƒæŠ•å½±ç±»
    ImageTimeEmbedding,               # å›¾åƒæ—¶é—´åµŒå…¥ç±»
    TextImageProjection,              # æ–‡æœ¬å›¾åƒæŠ•å½±ç±»
    TextImageTimeEmbedding,           # æ–‡æœ¬å›¾åƒæ—¶é—´åµŒå…¥ç±»
    TextTimeEmbedding,                # æ–‡æœ¬æ—¶é—´åµŒå…¥ç±»
    TimestepEmbedding,                # æ—¶é—´æ­¥åµŒå…¥ç±»
    Timesteps,                        # æ—¶é—´æ­¥ç±»
)
# å¯¼å…¥ ResNet ç›¸å…³ç»„ä»¶
from ....models.resnet import ResnetBlockCondNorm2D
# å¯¼å…¥ 2D åŒé‡å˜æ¢å™¨æ¨¡å‹
from ....models.transformers.dual_transformer_2d import DualTransformer2DModel
# å¯¼å…¥ 2D å˜æ¢å™¨æ¨¡å‹
from ....models.transformers.transformer_2d import Transformer2DModel
# å¯¼å…¥ 2D æ¡ä»¶ UNet è¾“å‡ºç±»
from ....models.unets.unet_2d_condition import UNet2DConditionOutput
# å¯¼å…¥å·¥å…·å‡½æ•°å’Œå¸¸é‡
from ....utils import USE_PEFT_BACKEND, is_torch_version, logging, scale_lora_layers, unscale_lora_layers
# å¯¼å…¥ PyTorch ç›¸å…³å·¥å…·å‡½æ•°
from ....utils.torch_utils import apply_freeu

# åˆ›å»ºæ—¥å¿—è®°å½•å™¨å®ä¾‹
logger = logging.get_logger(__name__)  # pylint: disable=invalid-name

# å®šä¹‰è·å–ä¸‹é‡‡æ ·å—çš„å‡½æ•°
def get_down_block(
    down_block_type,                    # ä¸‹é‡‡æ ·å—ç±»å‹
    num_layers,                         # å±‚æ•°
    in_channels,                        # è¾“å…¥é€šé“æ•°
    out_channels,                       # è¾“å‡ºé€šé“æ•°
    temb_channels,                      # æ—¶é—´åµŒå…¥é€šé“æ•°
    add_downsample,                    # æ˜¯å¦æ·»åŠ ä¸‹é‡‡æ ·
    resnet_eps,                         # ResNet ä¸­çš„ epsilon å€¼
    resnet_act_fn,                     # ResNet æ¿€æ´»å‡½æ•°
    num_attention_heads,               # æ³¨æ„åŠ›å¤´æ•°é‡
    transformer_layers_per_block,      # æ¯ä¸ªå—ä¸­çš„å˜æ¢å™¨å±‚æ•°
    attention_type,                    # æ³¨æ„åŠ›ç±»å‹
    attention_head_dim,                # æ³¨æ„åŠ›å¤´ç»´åº¦
    resnet_groups=None,                 # ResNet ç»„æ•°ï¼ˆå¯é€‰ï¼‰
    cross_attention_dim=None,           # äº¤å‰æ³¨æ„åŠ›ç»´åº¦ï¼ˆå¯é€‰ï¼‰
    downsample_padding=None,            # ä¸‹é‡‡æ ·å¡«å……ï¼ˆå¯é€‰ï¼‰
    dual_cross_attention=False,         # æ˜¯å¦ä½¿ç”¨åŒé‡äº¤å‰æ³¨æ„åŠ›
    use_linear_projection=False,        # æ˜¯å¦ä½¿ç”¨çº¿æ€§æŠ•å½±
    only_cross_attention=False,         # æ˜¯å¦ä»…ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›
    upcast_attention=False,             # æ˜¯å¦ä¸Šå‡æ³¨æ„åŠ›
    resnet_time_scale_shift="default",  # ResNet æ—¶é—´ç¼©æ”¾åç§»
    resnet_skip_time_act=False,         # ResNet æ˜¯å¦è·³è¿‡æ—¶é—´æ¿€æ´»
    resnet_out_scale_factor=1.0,       # ResNet è¾“å‡ºç¼©æ”¾å› å­
    cross_attention_norm=None,          # äº¤å‰æ³¨æ„åŠ›å½’ä¸€åŒ–ï¼ˆå¯é€‰ï¼‰
    dropout=0.0,                       # dropout æ¦‚ç‡
):
    # å¦‚æœä¸‹é‡‡æ ·å—ç±»å‹ä»¥ "UNetRes" å¼€å¤´ï¼Œåˆ™å»æ‰å‰ç¼€
    down_block_type = down_block_type[7:] if down_block_type.startswith("UNetRes") else down_block_type
    # å¦‚æœä¸‹é‡‡æ ·å—ç±»å‹ä¸º "DownBlockFlat"ï¼Œåˆ™è¿”å›ç›¸åº”çš„å—å®ä¾‹
    if down_block_type == "DownBlockFlat":
        return DownBlockFlat(
            num_layers=num_layers,        # å±‚æ•°
            in_channels=in_channels,      # è¾“å…¥é€šé“æ•°
            out_channels=out_channels,    # è¾“å‡ºé€šé“æ•°
            temb_channels=temb_channels,  # æ—¶é—´åµŒå…¥é€šé“æ•°
            dropout=dropout,              # dropout æ¦‚ç‡
            add_downsample=add_downsample, # æ˜¯å¦æ·»åŠ ä¸‹é‡‡æ ·
            resnet_eps=resnet_eps,        # ResNet ä¸­çš„ epsilon å€¼
            resnet_act_fn=resnet_act_fn,  # ResNet æ¿€æ´»å‡½æ•°
            resnet_groups=resnet_groups,   # ResNet ç»„æ•°ï¼ˆå¯é€‰ï¼‰
            downsample_padding=downsample_padding, # ä¸‹é‡‡æ ·å¡«å……ï¼ˆå¯é€‰ï¼‰
            resnet_time_scale_shift=resnet_time_scale_shift, # ResNet æ—¶é—´ç¼©æ”¾åç§»
        )
    # æ£€æŸ¥ä¸‹é‡‡æ ·å—ç±»å‹æ˜¯å¦ä¸º CrossAttnDownBlockFlat
    elif down_block_type == "CrossAttnDownBlockFlat":
        # å¦‚æœæ²¡æœ‰æŒ‡å®š cross_attention_dimï¼Œåˆ™æŠ›å‡ºå€¼é”™è¯¯
        if cross_attention_dim is None:
            raise ValueError("cross_attention_dim must be specified for CrossAttnDownBlockFlat")
        # åˆ›å»ºå¹¶è¿”å› CrossAttnDownBlockFlat å®ä¾‹ï¼Œä¼ å…¥æ‰€éœ€å‚æ•°
        return CrossAttnDownBlockFlat(
            # è®¾ç½®ç½‘ç»œå±‚æ•°
            num_layers=num_layers,
            # è®¾ç½®è¾“å…¥é€šé“æ•°
            in_channels=in_channels,
            # è®¾ç½®è¾“å‡ºé€šé“æ•°
            out_channels=out_channels,
            # è®¾ç½®æ—¶é—´åµŒå…¥é€šé“æ•°
            temb_channels=temb_channels,
            # è®¾ç½® dropout æ¯”ç‡
            dropout=dropout,
            # è®¾ç½®æ˜¯å¦æ·»åŠ ä¸‹é‡‡æ ·å±‚
            add_downsample=add_downsample,
            # è®¾ç½® ResNet ä¸­çš„ epsilon å‚æ•°
            resnet_eps=resnet_eps,
            # è®¾ç½® ResNet æ¿€æ´»å‡½æ•°
            resnet_act_fn=resnet_act_fn,
            # è®¾ç½® ResNet ç»„çš„æ•°é‡
            resnet_groups=resnet_groups,
            # è®¾ç½®ä¸‹é‡‡æ ·çš„å¡«å……å‚æ•°
            downsample_padding=downsample_padding,
            # è®¾ç½®äº¤å‰æ³¨æ„åŠ›ç»´åº¦
            cross_attention_dim=cross_attention_dim,
            # è®¾ç½®æ³¨æ„åŠ›å¤´çš„æ•°é‡
            num_attention_heads=num_attention_heads,
            # è®¾ç½®æ˜¯å¦ä½¿ç”¨åŒäº¤å‰æ³¨æ„åŠ›
            dual_cross_attention=dual_cross_attention,
            # è®¾ç½®æ˜¯å¦ä½¿ç”¨çº¿æ€§æŠ•å½±
            use_linear_projection=use_linear_projection,
            # è®¾ç½®æ˜¯å¦ä»…ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›
            only_cross_attention=only_cross_attention,
            # è®¾ç½® ResNet çš„æ—¶é—´å°ºåº¦åç§»
            resnet_time_scale_shift=resnet_time_scale_shift,
        )
    # å¦‚æœä¸‹é‡‡æ ·å—ç±»å‹ä¸è¢«æ”¯æŒï¼Œåˆ™æŠ›å‡ºå€¼é”™è¯¯
    raise ValueError(f"{down_block_type} is not supported.")
# æ ¹æ®ç»™å®šå‚æ•°åˆ›å»ºä¸Šé‡‡æ ·å—çš„å‡½æ•°
def get_up_block(
    # ä¸Šé‡‡æ ·å—ç±»å‹
    up_block_type,
    # ç½‘ç»œå±‚æ•°
    num_layers,
    # è¾“å…¥é€šé“æ•°
    in_channels,
    # è¾“å‡ºé€šé“æ•°
    out_channels,
    # ä¸Šä¸€å±‚è¾“å‡ºé€šé“æ•°
    prev_output_channel,
    # æ¡ä»¶åµŒå…¥é€šé“æ•°
    temb_channels,
    # æ˜¯å¦æ·»åŠ ä¸Šé‡‡æ ·
    add_upsample,
    # ResNet çš„ epsilon å€¼
    resnet_eps,
    # ResNet çš„æ¿€æ´»å‡½æ•°
    resnet_act_fn,
    # æ³¨æ„åŠ›å¤´æ•°
    num_attention_heads,
    # æ¯ä¸ªå—çš„ Transformer å±‚æ•°
    transformer_layers_per_block,
    # åˆ†è¾¨ç‡ç´¢å¼•
    resolution_idx,
    # æ³¨æ„åŠ›ç±»å‹
    attention_type,
    # æ³¨æ„åŠ›å¤´ç»´åº¦
    attention_head_dim,
    # ResNet ç»„æ•°ï¼Œå¯é€‰å‚æ•°
    resnet_groups=None,
    # è·¨æ³¨æ„åŠ›ç»´åº¦ï¼Œå¯é€‰å‚æ•°
    cross_attention_dim=None,
    # æ˜¯å¦ä½¿ç”¨åŒé‡è·¨æ³¨æ„åŠ›
    dual_cross_attention=False,
    # æ˜¯å¦ä½¿ç”¨çº¿æ€§æŠ•å½±
    use_linear_projection=False,
    # æ˜¯å¦ä»…ä½¿ç”¨è·¨æ³¨æ„åŠ›
    only_cross_attention=False,
    # æ˜¯å¦ä¸Šæº¯æ³¨æ„åŠ›
    upcast_attention=False,
    # ResNet æ—¶é—´å°ºåº¦åç§»ï¼Œé»˜è®¤ä¸º "default"
    resnet_time_scale_shift="default",
    # ResNet æ˜¯å¦è·³è¿‡æ—¶é—´æ¿€æ´»
    resnet_skip_time_act=False,
    # ResNet è¾“å‡ºç¼©æ”¾å› å­
    resnet_out_scale_factor=1.0,
    # è·¨æ³¨æ„åŠ›å½’ä¸€åŒ–ç±»å‹ï¼Œå¯é€‰å‚æ•°
    cross_attention_norm=None,
    # dropout æ¦‚ç‡
    dropout=0.0,
):
    # å¦‚æœä¸Šé‡‡æ ·å—ç±»å‹ä»¥ "UNetRes" å¼€å¤´ï¼Œå»æ‰å‰ç¼€
    up_block_type = up_block_type[7:] if up_block_type.startswith("UNetRes") else up_block_type
    # å¦‚æœå—ç±»å‹æ˜¯ "UpBlockFlat"ï¼Œåˆ™è¿”å›ç›¸åº”çš„å®ä¾‹
    if up_block_type == "UpBlockFlat":
        return UpBlockFlat(
            # ä¼ å…¥å„ä¸ªå‚æ•°
            num_layers=num_layers,
            in_channels=in_channels,
            out_channels=out_channels,
            prev_output_channel=prev_output_channel,
            temb_channels=temb_channels,
            dropout=dropout,
            add_upsample=add_upsample,
            resnet_eps=resnet_eps,
            resnet_act_fn=resnet_act_fn,
            resnet_groups=resnet_groups,
            resnet_time_scale_shift=resnet_time_scale_shift,
        )
    # å¦‚æœå—ç±»å‹æ˜¯ "CrossAttnUpBlockFlat"
    elif up_block_type == "CrossAttnUpBlockFlat":
        # æ£€æŸ¥è·¨æ³¨æ„åŠ›ç»´åº¦æ˜¯å¦æŒ‡å®š
        if cross_attention_dim is None:
            raise ValueError("cross_attention_dim must be specified for CrossAttnUpBlockFlat")
        # è¿”å›ç›¸åº”çš„è·¨æ³¨æ„åŠ›ä¸Šé‡‡æ ·å—å®ä¾‹
        return CrossAttnUpBlockFlat(
            # ä¼ å…¥å„ä¸ªå‚æ•°
            num_layers=num_layers,
            in_channels=in_channels,
            out_channels=out_channels,
            prev_output_channel=prev_output_channel,
            temb_channels=temb_channels,
            dropout=dropout,
            add_upsample=add_upsample,
            resnet_eps=resnet_eps,
            resnet_act_fn=resnet_act_fn,
            resnet_groups=resnet_groups,
            cross_attention_dim=cross_attention_dim,
            num_attention_heads=num_attention_heads,
            dual_cross_attention=dual_cross_attention,
            use_linear_projection=use_linear_projection,
            only_cross_attention=only_cross_attention,
            resnet_time_scale_shift=resnet_time_scale_shift,
        )
    # å¦‚æœå—ç±»å‹ä¸æ”¯æŒï¼ŒæŠ›å‡ºå¼‚å¸¸
    raise ValueError(f"{up_block_type} is not supported.")


# å®šä¹‰ä¸€ä¸ª Fourier åµŒå…¥å™¨ç±»ï¼Œç»§æ‰¿è‡ª nn.Module
class FourierEmbedder(nn.Module):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®é¢‘ç‡å’Œæ¸©åº¦
    def __init__(self, num_freqs=64, temperature=100):
        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        super().__init__()

        # ä¿å­˜é¢‘ç‡æ•°
        self.num_freqs = num_freqs
        # ä¿å­˜æ¸©åº¦
        self.temperature = temperature

        # è®¡ç®—é¢‘ç‡å¸¦
        freq_bands = temperature ** (torch.arange(num_freqs) / num_freqs)
        # æ‰©å±•ç»´åº¦ä»¥ä¾¿åç»­æ“ä½œ
        freq_bands = freq_bands[None, None, None]
        # æ³¨å†Œé¢‘ç‡å¸¦ä¸ºç¼“å†²åŒºï¼Œè®¾ä¸ºéæŒä¹…æ€§
        self.register_buffer("freq_bands", freq_bands, persistent=False)

    # å®šä¹‰è°ƒç”¨æ–¹æ³•ï¼Œç”¨äºå¤„ç†è¾“å…¥
    def __call__(self, x):
        # å°†è¾“å…¥ä¸é¢‘ç‡å¸¦ç›¸ä¹˜
        x = self.freq_bands * x.unsqueeze(-1)
        # è¿”å›å¤„ç†åçš„ç»“æœï¼ŒåŒ…å«æ­£å¼¦å’Œä½™å¼¦
        return torch.stack((x.sin(), x.cos()), dim=-1).permute(0, 1, 3, 4, 2).reshape(*x.shape[:2], -1)


# å®šä¹‰ GLIGEN æ–‡æœ¬è¾¹ç•Œæ¡†æŠ•å½±ç±»ï¼Œç»§æ‰¿è‡ª nn.Module
class GLIGENTextBoundingboxProjection(nn.Module):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®å¯¹è±¡çš„åŸºæœ¬å‚æ•°
        def __init__(self, positive_len, out_dim, feature_type, fourier_freqs=8):
            # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
            super().__init__()
            # å­˜å‚¨æ­£æ ·æœ¬çš„é•¿åº¦
            self.positive_len = positive_len
            # å­˜å‚¨è¾“å‡ºçš„ç»´åº¦
            self.out_dim = out_dim
    
            # åˆå§‹åŒ–å‚…é‡Œå¶åµŒå…¥å™¨ï¼Œè®¾ç½®é¢‘ç‡æ•°é‡
            self.fourier_embedder = FourierEmbedder(num_freqs=fourier_freqs)
            # è®¡ç®—ä½ç½®ç‰¹å¾çš„ç»´åº¦ï¼ŒåŒ…å« sin å’Œ cos
            self.position_dim = fourier_freqs * 2 * 4  # 2: sin/cos, 4: xyxy
    
            # å¦‚æœè¾“å‡ºç»´åº¦æ˜¯å…ƒç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
            if isinstance(out_dim, tuple):
                out_dim = out_dim[0]
    
            # æ ¹æ®ç‰¹å¾ç±»å‹è®¾ç½®çº¿æ€§å±‚
            if feature_type == "text-only":
                self.linears = nn.Sequential(
                    # ç¬¬ä¸€å±‚çº¿æ€§å˜æ¢ï¼Œè¾“å…¥ä¸ºæ­£æ ·æœ¬é•¿åº¦åŠ ä½ç½®ç»´åº¦
                    nn.Linear(self.positive_len + self.position_dim, 512),
                    # æ¿€æ´»å‡½æ•°ä½¿ç”¨ SiLU
                    nn.SiLU(),
                    # ç¬¬äºŒå±‚çº¿æ€§å˜æ¢
                    nn.Linear(512, 512),
                    # æ¿€æ´»å‡½æ•°ä½¿ç”¨ SiLU
                    nn.SiLU(),
                    # è¾“å‡ºå±‚
                    nn.Linear(512, out_dim),
                )
                # å®šä¹‰ä¸€ä¸ªå…¨ä¸ºé›¶çš„å‚æ•°ï¼Œç”¨äºæ–‡æœ¬ç‰¹å¾çš„ç©ºå€¼å¤„ç†
                self.null_positive_feature = torch.nn.Parameter(torch.zeros([self.positive_len]))
    
            # å¤„ç†æ–‡æœ¬å’Œå›¾åƒçš„ç‰¹å¾ç±»å‹
            elif feature_type == "text-image":
                self.linears_text = nn.Sequential(
                    # ç¬¬ä¸€å±‚çº¿æ€§å˜æ¢
                    nn.Linear(self.positive_len + self.position_dim, 512),
                    # æ¿€æ´»å‡½æ•°ä½¿ç”¨ SiLU
                    nn.SiLU(),
                    # ç¬¬äºŒå±‚çº¿æ€§å˜æ¢
                    nn.Linear(512, 512),
                    # æ¿€æ´»å‡½æ•°ä½¿ç”¨ SiLU
                    nn.SiLU(),
                    # è¾“å‡ºå±‚
                    nn.Linear(512, out_dim),
                )
                self.linears_image = nn.Sequential(
                    # ç¬¬ä¸€å±‚çº¿æ€§å˜æ¢
                    nn.Linear(self.positive_len + self.position_dim, 512),
                    # æ¿€æ´»å‡½æ•°ä½¿ç”¨ SiLU
                    nn.SiLU(),
                    # ç¬¬äºŒå±‚çº¿æ€§å˜æ¢
                    nn.Linear(512, 512),
                    # æ¿€æ´»å‡½æ•°ä½¿ç”¨ SiLU
                    nn.SiLU(),
                    # è¾“å‡ºå±‚
                    nn.Linear(512, out_dim),
                )
                # å®šä¹‰æ–‡æœ¬ç‰¹å¾çš„ç©ºå€¼å¤„ç†å‚æ•°
                self.null_text_feature = torch.nn.Parameter(torch.zeros([self.positive_len]))
                # å®šä¹‰å›¾åƒç‰¹å¾çš„ç©ºå€¼å¤„ç†å‚æ•°
                self.null_image_feature = torch.nn.Parameter(torch.zeros([self.positive_len]))
    
            # å®šä¹‰ä½ç½®ç‰¹å¾çš„ç©ºå€¼å¤„ç†å‚æ•°
            self.null_position_feature = torch.nn.Parameter(torch.zeros([self.position_dim]))
    
        # å‰å‘ä¼ æ’­æ–¹æ³•å®šä¹‰
        def forward(
            self,
            boxes,
            masks,
            positive_embeddings=None,
            phrases_masks=None,
            image_masks=None,
            phrases_embeddings=None,
            image_embeddings=None,
    ):
        # åœ¨æœ€åä¸€ç»´å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œä¾¿äºåç»­æ“ä½œ
        masks = masks.unsqueeze(-1)

        # é€šè¿‡å‚…é‡Œå¶åµŒå…¥å‡½æ•°ç”Ÿæˆ boxes çš„åµŒå…¥è¡¨ç¤º
        xyxy_embedding = self.fourier_embedder(boxes)
        # è·å–ç©ºç™½ä½ç½®çš„ç‰¹å¾ï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä¸º (1, 1, -1)
        xyxy_null = self.null_position_feature.view(1, 1, -1)
        # è®¡ç®—åŠ æƒåµŒå…¥ï¼Œç»“åˆ masks å’Œç©ºç™½ä½ç½®ç‰¹å¾
        xyxy_embedding = xyxy_embedding * masks + (1 - masks) * xyxy_null

        # å¦‚æœå­˜åœ¨æ­£æ ·æœ¬åµŒå…¥
        if positive_embeddings:
            # è·å–æ­£æ ·æœ¬çš„ç©ºç™½ç‰¹å¾ï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä¸º (1, 1, -1)
            positive_null = self.null_positive_feature.view(1, 1, -1)
            # è®¡ç®—æ­£æ ·æœ¬åµŒå…¥çš„åŠ æƒï¼Œç»“åˆ masks å’Œç©ºç™½ç‰¹å¾
            positive_embeddings = positive_embeddings * masks + (1 - masks) * positive_null

            # å°†æ­£æ ·æœ¬åµŒå…¥ä¸ xyxy åµŒå…¥è¿æ¥å¹¶é€šè¿‡çº¿æ€§å±‚å¤„ç†
            objs = self.linears(torch.cat([positive_embeddings, xyxy_embedding], dim=-1))
        else:
            # åœ¨æœ€åä¸€ç»´å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œä¾¿äºåç»­æ“ä½œ
            phrases_masks = phrases_masks.unsqueeze(-1)
            image_masks = image_masks.unsqueeze(-1)

            # è·å–æ–‡æœ¬å’Œå›¾åƒçš„ç©ºç™½ç‰¹å¾ï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä¸º (1, 1, -1)
            text_null = self.null_text_feature.view(1, 1, -1)
            image_null = self.null_image_feature.view(1, 1, -1)

            # è®¡ç®—æ–‡æœ¬åµŒå…¥çš„åŠ æƒï¼Œç»“åˆ phrases_masks å’Œç©ºç™½ç‰¹å¾
            phrases_embeddings = phrases_embeddings * phrases_masks + (1 - phrases_masks) * text_null
            # è®¡ç®—å›¾åƒåµŒå…¥çš„åŠ æƒï¼Œç»“åˆ image_masks å’Œç©ºç™½ç‰¹å¾
            image_embeddings = image_embeddings * image_masks + (1 - image_masks) * image_null

            # å°†æ–‡æœ¬åµŒå…¥ä¸ xyxy åµŒå…¥è¿æ¥å¹¶é€šè¿‡æ–‡æœ¬çº¿æ€§å±‚å¤„ç†
            objs_text = self.linears_text(torch.cat([phrases_embeddings, xyxy_embedding], dim=-1))
            # å°†å›¾åƒåµŒå…¥ä¸ xyxy åµŒå…¥è¿æ¥å¹¶é€šè¿‡å›¾åƒçº¿æ€§å±‚å¤„ç†
            objs_image = self.linears_image(torch.cat([image_embeddings, xyxy_embedding], dim=-1))
            # å°†æ–‡æœ¬å’Œå›¾åƒçš„å¤„ç†ç»“æœåœ¨ç»´åº¦ 1 ä¸Šè¿æ¥
            objs = torch.cat([objs_text, objs_image], dim=1)

        # è¿”å›æœ€ç»ˆçš„å¯¹è±¡ç»“æœ
        return objs
# å®šä¹‰ä¸€ä¸ªåä¸º UNetFlatConditionModel çš„ç±»ï¼Œç»§æ‰¿è‡ª ModelMixin å’Œ ConfigMixin
class UNetFlatConditionModel(ModelMixin, ConfigMixin):
    r"""
    ä¸€ä¸ªæ¡ä»¶ 2D UNet æ¨¡å‹ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªæœ‰å™ªå£°çš„æ ·æœ¬ã€æ¡ä»¶çŠ¶æ€å’Œæ—¶é—´æ­¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ ·æœ¬å½¢çŠ¶çš„è¾“å‡ºã€‚

    è¯¥æ¨¡å‹ç»§æ‰¿è‡ª [`ModelMixin`]ã€‚è¯·æŸ¥çœ‹çˆ¶ç±»æ–‡æ¡£ä»¥äº†è§£å…¶ä¸ºæ‰€æœ‰æ¨¡å‹å®ç°çš„é€šç”¨æ–¹æ³•ï¼ˆä¾‹å¦‚ä¸‹è½½æˆ–ä¿å­˜ï¼‰ã€‚

    """

    # è®¾ç½®è¯¥æ¨¡å‹æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹
    _supports_gradient_checkpointing = True
    # å®šä¹‰ä¸è¿›è¡Œæ‹†åˆ†çš„æ¨¡å—åç§°åˆ—è¡¨
    _no_split_modules = ["BasicTransformerBlock", "ResnetBlockFlat", "CrossAttnUpBlockFlat"]

    # æ³¨å†Œåˆ°é…ç½®çš„è£…é¥°å™¨
    @register_to_config
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®ç±»çš„åŸºæœ¬å‚æ•°
        def __init__(
            # æ ·æœ¬å¤§å°ï¼Œå¯é€‰å‚æ•°
            self,
            sample_size: Optional[int] = None,
            # è¾“å…¥é€šé“æ•°ï¼Œé»˜è®¤ä¸º4
            in_channels: int = 4,
            # è¾“å‡ºé€šé“æ•°ï¼Œé»˜è®¤ä¸º4
            out_channels: int = 4,
            # æ˜¯å¦å°†è¾“å…¥æ ·æœ¬å±…ä¸­ï¼Œé»˜è®¤ä¸ºFalse
            center_input_sample: bool = False,
            # æ˜¯å¦å°†æ­£å¼¦å‡½æ•°ç¿»è½¬ä¸ºä½™å¼¦å‡½æ•°ï¼Œé»˜è®¤ä¸ºTrue
            flip_sin_to_cos: bool = True,
            # é¢‘ç‡åç§»é‡ï¼Œé»˜è®¤ä¸º0
            freq_shift: int = 0,
            # å‘ä¸‹é‡‡æ ·å—çš„ç±»å‹ï¼Œé»˜è®¤ä¸ºä¸‰ä¸ªCrossAttnDownBlockFlatå’Œä¸€ä¸ªDownBlockFlat
            down_block_types: Tuple[str] = (
                "CrossAttnDownBlockFlat",
                "CrossAttnDownBlockFlat",
                "CrossAttnDownBlockFlat",
                "DownBlockFlat",
            ),
            # ä¸­é—´å—çš„ç±»å‹ï¼Œé»˜è®¤ä¸ºUNetMidBlockFlatCrossAttn
            mid_block_type: Optional[str] = "UNetMidBlockFlatCrossAttn",
            # å‘ä¸Šé‡‡æ ·å—çš„ç±»å‹ï¼Œé»˜è®¤ä¸ºä¸€ä¸ªUpBlockFlatå’Œä¸‰ä¸ªCrossAttnUpBlockFlat
            up_block_types: Tuple[str] = (
                "UpBlockFlat",
                "CrossAttnUpBlockFlat",
                "CrossAttnUpBlockFlat",
                "CrossAttnUpBlockFlat",
            ),
            # æ˜¯å¦ä»…ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›ï¼Œé»˜è®¤ä¸ºFalse
            only_cross_attention: Union[bool, Tuple[bool]] = False,
            # å—è¾“å‡ºé€šé“æ•°ï¼Œé»˜è®¤ä¸º320, 640, 1280, 1280
            block_out_channels: Tuple[int] = (320, 640, 1280, 1280),
            # æ¯ä¸ªå—çš„å±‚æ•°ï¼Œé»˜è®¤ä¸º2
            layers_per_block: Union[int, Tuple[int]] = 2,
            # å‘ä¸‹é‡‡æ ·æ—¶çš„å¡«å……å¤§å°ï¼Œé»˜è®¤ä¸º1
            downsample_padding: int = 1,
            # ä¸­é—´å—çš„ç¼©æ”¾å› å­ï¼Œé»˜è®¤ä¸º1
            mid_block_scale_factor: float = 1,
            # dropoutæ¯”ä¾‹ï¼Œé»˜è®¤ä¸º0.0
            dropout: float = 0.0,
            # æ¿€æ´»å‡½æ•°ç±»å‹ï¼Œé»˜è®¤ä¸ºsilu
            act_fn: str = "silu",
            # å½’ä¸€åŒ–çš„ç»„æ•°ï¼Œå¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸º32
            norm_num_groups: Optional[int] = 32,
            # å½’ä¸€åŒ–çš„epsilonå€¼ï¼Œé»˜è®¤ä¸º1e-5
            norm_eps: float = 1e-5,
            # äº¤å‰æ³¨æ„åŠ›çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º1280
            cross_attention_dim: Union[int, Tuple[int]] = 1280,
            # æ¯ä¸ªå—çš„å˜æ¢å™¨å±‚æ•°ï¼Œé»˜è®¤ä¸º1
            transformer_layers_per_block: Union[int, Tuple[int], Tuple[Tuple]] = 1,
            # åå‘å˜æ¢å™¨å±‚æ•°çš„å¯é€‰é…ç½®
            reverse_transformer_layers_per_block: Optional[Tuple[Tuple[int]]] = None,
            # ç¼–ç å™¨éšè—ç»´åº¦çš„å¯é€‰å‚æ•°
            encoder_hid_dim: Optional[int] = None,
            # ç¼–ç å™¨éšè—ç»´åº¦ç±»å‹çš„å¯é€‰å‚æ•°
            encoder_hid_dim_type: Optional[str] = None,
            # æ³¨æ„åŠ›å¤´çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º8
            attention_head_dim: Union[int, Tuple[int]] = 8,
            # æ³¨æ„åŠ›å¤´æ•°é‡çš„å¯é€‰å‚æ•°
            num_attention_heads: Optional[Union[int, Tuple[int]]] = None,
            # æ˜¯å¦ä½¿ç”¨åŒäº¤å‰æ³¨æ„åŠ›ï¼Œé»˜è®¤ä¸ºFalse
            dual_cross_attention: bool = False,
            # æ˜¯å¦ä½¿ç”¨çº¿æ€§æŠ•å½±ï¼Œé»˜è®¤ä¸ºFalse
            use_linear_projection: bool = False,
            # ç±»åµŒå…¥ç±»å‹çš„å¯é€‰å‚æ•°
            class_embed_type: Optional[str] = None,
            # é™„åŠ åµŒå…¥ç±»å‹çš„å¯é€‰å‚æ•°
            addition_embed_type: Optional[str] = None,
            # é™„åŠ æ—¶é—´åµŒå…¥ç»´åº¦çš„å¯é€‰å‚æ•°
            addition_time_embed_dim: Optional[int] = None,
            # ç±»åµŒå…¥æ•°é‡çš„å¯é€‰å‚æ•°
            num_class_embeds: Optional[int] = None,
            # æ˜¯å¦å‘ä¸ŠæŠ•å°„æ³¨æ„åŠ›ï¼Œé»˜è®¤ä¸ºFalse
            upcast_attention: bool = False,
            # ResNetæ—¶é—´ç¼©æ”¾åç§»çš„é»˜è®¤å€¼
            resnet_time_scale_shift: str = "default",
            # ResNetè·³è¿‡æ—¶é—´æ¿€æ´»çš„è®¾ç½®ï¼Œé»˜è®¤ä¸ºFalse
            resnet_skip_time_act: bool = False,
            # ResNetè¾“å‡ºç¼©æ”¾å› å­ï¼Œé»˜è®¤ä¸º1.0
            resnet_out_scale_factor: int = 1.0,
            # æ—¶é—´åµŒå…¥ç±»å‹ï¼Œé»˜è®¤ä¸ºpositional
            time_embedding_type: str = "positional",
            # æ—¶é—´åµŒå…¥ç»´åº¦çš„å¯é€‰å‚æ•°
            time_embedding_dim: Optional[int] = None,
            # æ—¶é—´åµŒå…¥æ¿€æ´»å‡½æ•°çš„å¯é€‰å‚æ•°
            time_embedding_act_fn: Optional[str] = None,
            # æ—¶é—´æ­¥åæ¿€æ´»çš„å¯é€‰å‚æ•°
            timestep_post_act: Optional[str] = None,
            # æ—¶é—´æ¡ä»¶æŠ•å½±ç»´åº¦çš„å¯é€‰å‚æ•°
            time_cond_proj_dim: Optional[int] = None,
            # è¾“å…¥å·ç§¯æ ¸çš„å¤§å°ï¼Œé»˜è®¤ä¸º3
            conv_in_kernel: int = 3,
            # è¾“å‡ºå·ç§¯æ ¸çš„å¤§å°ï¼Œé»˜è®¤ä¸º3
            conv_out_kernel: int = 3,
            # æŠ•å½±ç±»åµŒå…¥è¾“å…¥ç»´åº¦çš„å¯é€‰å‚æ•°
            projection_class_embeddings_input_dim: Optional[int] = None,
            # æ³¨æ„åŠ›ç±»å‹ï¼Œé»˜è®¤ä¸ºdefault
            attention_type: str = "default",
            # ç±»åµŒå…¥æ˜¯å¦è¿æ¥ï¼Œé»˜è®¤ä¸ºFalse
            class_embeddings_concat: bool = False,
            # ä¸­é—´å—æ˜¯å¦ä»…ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›çš„å¯é€‰å‚æ•°
            mid_block_only_cross_attention: Optional[bool] = None,
            # äº¤å‰æ³¨æ„åŠ›çš„å½’ä¸€åŒ–ç±»å‹çš„å¯é€‰å‚æ•°
            cross_attention_norm: Optional[str] = None,
            # é™„åŠ åµŒå…¥ç±»å‹çš„å¤´æ•°é‡ï¼Œé»˜è®¤ä¸º64
            addition_embed_type_num_heads=64,
        # å£°æ˜è¯¥æ–¹æ³•ä¸ºå±æ€§
        @property
    # å®šä¹‰ä¸€ä¸ªè¿”å›æ³¨æ„åŠ›å¤„ç†å™¨å­—å…¸çš„æ–¹æ³•
    def attn_processors(self) -> Dict[str, AttentionProcessor]:
        r"""
        è¿”å›å€¼:
            `dict` çš„æ³¨æ„åŠ›å¤„ç†å™¨: ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æ¨¡å‹ä¸­ä½¿ç”¨çš„æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨ï¼Œä»¥å…¶æƒé‡åç§°ä¸ºç´¢å¼•ã€‚
        """
        # åˆå§‹åŒ–ä¸€ä¸ªç©ºå­—å…¸ä»¥é€’å½’å­˜å‚¨å¤„ç†å™¨
        processors = {}

        # å®šä¹‰ä¸€ä¸ªé€’å½’å‡½æ•°æ¥æ·»åŠ å¤„ç†å™¨
        def fn_recursive_add_processors(name: str, module: torch.nn.Module, processors: Dict[str, AttentionProcessor]):
            # å¦‚æœæ¨¡å—æœ‰è·å–å¤„ç†å™¨çš„æ–¹æ³•ï¼Œåˆ™æ·»åŠ åˆ°å­—å…¸ä¸­
            if hasattr(module, "get_processor"):
                processors[f"{name}.processor"] = module.get_processor()

            # éå†æ¨¡å—çš„å­æ¨¡å—ï¼Œé€’å½’è°ƒç”¨å‡½æ•°
            for sub_name, child in module.named_children():
                fn_recursive_add_processors(f"{name}.{sub_name}", child, processors)

            # è¿”å›å¤„ç†å™¨å­—å…¸
            return processors

        # éå†å½“å‰æ¨¡å—çš„å­æ¨¡å—ï¼Œå¹¶è°ƒç”¨é€’å½’å‡½æ•°
        for name, module in self.named_children():
            fn_recursive_add_processors(name, module, processors)

        # è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨çš„å­—å…¸
        return processors

    # å®šä¹‰ä¸€ä¸ªè®¾ç½®æ³¨æ„åŠ›å¤„ç†å™¨çš„æ–¹æ³•
    def set_attn_processor(self, processor: Union[AttentionProcessor, Dict[str, AttentionProcessor]]):
        r"""
        è®¾ç½®ç”¨äºè®¡ç®—æ³¨æ„åŠ›çš„å¤„ç†å™¨ã€‚

        å‚æ•°:
            processor (`dict` of `AttentionProcessor` or only `AttentionProcessor`):
                å®ä¾‹åŒ–çš„å¤„ç†å™¨ç±»æˆ–å¤„ç†å™¨ç±»çš„å­—å…¸ï¼Œå°†è¢«è®¾ç½®ä¸ºæ‰€æœ‰ `Attention` å±‚çš„å¤„ç†å™¨ã€‚

                å¦‚æœ `processor` æ˜¯å­—å…¸ï¼Œåˆ™é”®éœ€è¦å®šä¹‰å¯¹åº”çš„äº¤å‰æ³¨æ„åŠ›å¤„ç†å™¨çš„è·¯å¾„ã€‚
                åœ¨è®¾ç½®å¯è®­ç»ƒçš„æ³¨æ„åŠ›å¤„ç†å™¨æ—¶ï¼Œå¼ºçƒˆæ¨èè¿™ç§åšæ³•ã€‚
        """
        # è®¡ç®—å½“å‰æ³¨æ„åŠ›å¤„ç†å™¨çš„æ•°é‡
        count = len(self.attn_processors.keys())

        # å¦‚æœä¼ å…¥çš„æ˜¯å­—å…¸ä¸”æ•°é‡ä¸åŒ¹é…ï¼Œåˆ™å¼•å‘é”™è¯¯
        if isinstance(processor, dict) and len(processor) != count:
            raise ValueError(
                f"ä¼ å…¥çš„æ˜¯å¤„ç†å™¨å­—å…¸ï¼Œä½†å¤„ç†å™¨çš„æ•°é‡ {len(processor)} ä¸æ³¨æ„åŠ›å±‚çš„æ•°é‡ {count} ä¸åŒ¹é…ã€‚"
                f" è¯·ç¡®ä¿ä¼ å…¥ {count} ä¸ªå¤„ç†å™¨ç±»ã€‚"
            )

        # å®šä¹‰ä¸€ä¸ªé€’å½’å‡½æ•°æ¥è®¾ç½®æ³¨æ„åŠ›å¤„ç†å™¨
        def fn_recursive_attn_processor(name: str, module: torch.nn.Module, processor):
            # å¦‚æœæ¨¡å—æœ‰è®¾ç½®å¤„ç†å™¨çš„æ–¹æ³•ï¼Œåˆ™æ ¹æ®ä¼ å…¥çš„å¤„ç†å™¨è®¾ç½®
            if hasattr(module, "set_processor"):
                if not isinstance(processor, dict):
                    module.set_processor(processor)
                else:
                    module.set_processor(processor.pop(f"{name}.processor"))

            # éå†æ¨¡å—çš„å­æ¨¡å—ï¼Œé€’å½’è°ƒç”¨å‡½æ•°
            for sub_name, child in module.named_children():
                fn_recursive_attn_processor(f"{name}.{sub_name}", child, processor)

        # éå†å½“å‰æ¨¡å—çš„å­æ¨¡å—ï¼Œå¹¶è°ƒç”¨é€’å½’å‡½æ•°
        for name, module in self.named_children():
            fn_recursive_attn_processor(name, module, processor)
    # è®¾ç½®é»˜è®¤çš„æ³¨æ„åŠ›å¤„ç†å™¨
    def set_default_attn_processor(self):
        """
        ç¦ç”¨è‡ªå®šä¹‰æ³¨æ„åŠ›å¤„ç†å™¨ï¼Œå¹¶è®¾ç½®é»˜è®¤çš„æ³¨æ„åŠ›å®ç°ã€‚
        """
        # æ£€æŸ¥æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨æ˜¯å¦å±äºå·²æ·»åŠ çš„ KV æ³¨æ„åŠ›å¤„ç†å™¨
        if all(proc.__class__ in ADDED_KV_ATTENTION_PROCESSORS for proc in self.attn_processors.values()):
            # ä½¿ç”¨ AttnAddedKVProcessor ä½œä¸ºå¤„ç†å™¨
            processor = AttnAddedKVProcessor()
        # æ£€æŸ¥æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨æ˜¯å¦å±äºäº¤å‰æ³¨æ„åŠ›å¤„ç†å™¨
        elif all(proc.__class__ in CROSS_ATTENTION_PROCESSORS for proc in self.attn_processors.values()):
            # ä½¿ç”¨ AttnProcessor ä½œä¸ºå¤„ç†å™¨
            processor = AttnProcessor()
        else:
            # å¦‚æœå¤„ç†å™¨ç±»å‹ä¸åŒ¹é…ï¼Œåˆ™å¼•å‘å€¼é”™è¯¯
            raise ValueError(
                f"å½“æ³¨æ„åŠ›å¤„ç†å™¨çš„ç±»å‹ä¸º {next(iter(self.attn_processors.values()))} æ—¶ï¼Œæ— æ³•è°ƒç”¨ `set_default_attn_processor`"
            )

        # è®¾ç½®é€‰å®šçš„æ³¨æ„åŠ›å¤„ç†å™¨
        self.set_attn_processor(processor)

    # è®¾ç½®æ¢¯åº¦æ£€æŸ¥ç‚¹
    def _set_gradient_checkpointing(self, module, value=False):
        # å¦‚æœæ¨¡å—å…·æœ‰ gradient_checkpointing å±æ€§ï¼Œåˆ™è®¾ç½®å…¶å€¼
        if hasattr(module, "gradient_checkpointing"):
            module.gradient_checkpointing = value

    # å¯ç”¨ FreeU æœºåˆ¶
    def enable_freeu(self, s1, s2, b1, b2):
        r"""å¯ç”¨æ¥è‡ª https://arxiv.org/abs/2309.11497 çš„ FreeU æœºåˆ¶ã€‚

        ç¼©æ”¾å› å­çš„åç¼€è¡¨ç¤ºåº”ç”¨çš„é˜¶æ®µå—ã€‚

        è¯·å‚è€ƒ [å®˜æ–¹åº“](https://github.com/ChenyangSi/FreeU) ä»¥è·å–å·²çŸ¥åœ¨ä¸åŒç®¡é“ï¼ˆå¦‚ Stable Diffusion v1ã€v2 å’Œ Stable Diffusion XLï¼‰ä¸­è¡¨ç°è‰¯å¥½çš„å€¼ç»„åˆã€‚

        å‚æ•°:
            s1 (`float`):
                é˜¶æ®µ 1 çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾çš„è´¡çŒ®ã€‚è¿™æ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡å¹³æ»‘æ•ˆåº”â€ã€‚
            s2 (`float`):
                é˜¶æ®µ 2 çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è¿‡ç‰¹å¾çš„è´¡çŒ®ã€‚è¿™æ˜¯ä¸ºäº†å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡å¹³æ»‘æ•ˆåº”â€ã€‚
            b1 (`float`): é˜¶æ®µ 1 çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå¢å¼ºä¸»å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚
            b2 (`float`): é˜¶æ®µ 2 çš„ç¼©æ”¾å› å­ï¼Œç”¨äºå¢å¼ºä¸»å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚
        """
        # éå†ä¸Šé‡‡æ ·å—å¹¶è®¾ç½®ç›¸åº”çš„ç¼©æ”¾å› å­
        for i, upsample_block in enumerate(self.up_blocks):
            setattr(upsample_block, "s1", s1)  # è®¾ç½®é˜¶æ®µ 1 çš„ç¼©æ”¾å› å­
            setattr(upsample_block, "s2", s2)  # è®¾ç½®é˜¶æ®µ 2 çš„ç¼©æ”¾å› å­
            setattr(upsample_block, "b1", b1)  # è®¾ç½®é˜¶æ®µ 1 çš„ä¸»å¹²ç‰¹å¾ç¼©æ”¾å› å­
            setattr(upsample_block, "b2", b2)  # è®¾ç½®é˜¶æ®µ 2 çš„ä¸»å¹²ç‰¹å¾ç¼©æ”¾å› å­

    # ç¦ç”¨ FreeU æœºåˆ¶
    def disable_freeu(self):
        """ç¦ç”¨ FreeU æœºåˆ¶ã€‚"""
        freeu_keys = {"s1", "s2", "b1", "b2"}  # FreeU æœºåˆ¶çš„å…³é”®å­—é›†åˆ
        # éå†ä¸Šé‡‡æ ·å—å¹¶å°†å…³é”®å­—çš„å€¼è®¾ç½®ä¸º None
        for i, upsample_block in enumerate(self.up_blocks):
            for k in freeu_keys:
                # å¦‚æœä¸Šé‡‡æ ·å—å…·æœ‰è¯¥å±æ€§æˆ–å±æ€§å€¼ä¸ä¸º Noneï¼Œåˆ™å°†å…¶è®¾ç½®ä¸º None
                if hasattr(upsample_block, k) or getattr(upsample_block, k, None) is not None:
                    setattr(upsample_block, k, None)
    # å®šä¹‰ä¸€ä¸ªç”¨äºèåˆ QKV æŠ•å½±çš„å‡½æ•°
    def fuse_qkv_projections(self):
        # æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæè¿°è¯¥å‡½æ•°çš„ä½œç”¨åŠå®éªŒæ€§è´¨
        """
        Enables fused QKV projections. For self-attention modules, all projection matrices (i.e., query, key, value)
        are fused. For cross-attention modules, key and value projection matrices are fused.
    
        <Tip warning={true}>
    
        This API is ğŸ§ª experimental.
    
        </Tip>
        """
        # åˆå§‹åŒ–åŸå§‹æ³¨æ„åŠ›å¤„ç†å™¨ä¸º None
        self.original_attn_processors = None
    
        # éå†æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨
        for _, attn_processor in self.attn_processors.items():
            # æ£€æŸ¥å¤„ç†å™¨çš„ç±»åæ˜¯å¦åŒ…å« "Added"
            if "Added" in str(attn_processor.__class__.__name__):
                # å¦‚æœæ˜¯ï¼ŒæŠ›å‡ºé”™è¯¯æç¤ºä¸æ”¯æŒèåˆ
                raise ValueError("`fuse_qkv_projections()` is not supported for models having added KV projections.")
    
        # ä¿å­˜åŸå§‹çš„æ³¨æ„åŠ›å¤„ç†å™¨
        self.original_attn_processors = self.attn_processors
    
        # éå†æ‰€æœ‰æ¨¡å—
        for module in self.modules():
            # æ£€æŸ¥æ¨¡å—æ˜¯å¦æ˜¯ Attention ç±»çš„å®ä¾‹
            if isinstance(module, Attention):
                # èåˆæŠ•å½±
                module.fuse_projections(fuse=True)
    
    # å®šä¹‰ä¸€ä¸ªç”¨äºå–æ¶ˆ QKV æŠ•å½±èåˆçš„å‡½æ•°
    def unfuse_qkv_projections(self):
        # æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæè¿°è¯¥å‡½æ•°çš„ä½œç”¨åŠå®éªŒæ€§è´¨
        """Disables the fused QKV projection if enabled.
    
        <Tip warning={true}>
    
        This API is ğŸ§ª experimental.
    
        </Tip>
    
        """
        # æ£€æŸ¥åŸå§‹æ³¨æ„åŠ›å¤„ç†å™¨æ˜¯å¦ä¸ä¸º None
        if self.original_attn_processors is not None:
            # æ¢å¤åˆ°åŸå§‹çš„æ³¨æ„åŠ›å¤„ç†å™¨
            self.set_attn_processor(self.original_attn_processors)
    
    # å®šä¹‰ä¸€ä¸ªç”¨äºå¸è½½ LoRA æƒé‡çš„å‡½æ•°
    def unload_lora(self):
        # æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæè¿°è¯¥å‡½æ•°çš„ä½œç”¨
        """Unloads LoRA weights."""
        # å‘å‡ºå¸è½½çš„å¼ƒç”¨è­¦å‘Š
        deprecate(
            "unload_lora",
            "0.28.0",
            "Calling `unload_lora()` is deprecated and will be removed in a future version. Please install `peft` and then call `disable_adapters().",
        )
        # éå†æ‰€æœ‰æ¨¡å—
        for module in self.modules():
            # æ£€æŸ¥æ¨¡å—æ˜¯å¦å…·æœ‰ set_lora_layer å±æ€§
            if hasattr(module, "set_lora_layer"):
                # å°† LoRA å±‚è®¾ç½®ä¸º None
                module.set_lora_layer(None)
    
    # å®šä¹‰å‰å‘ä¼ æ’­å‡½æ•°
    def forward(
        self,
        sample: torch.Tensor,
        timestep: Union[torch.Tensor, float, int],
        encoder_hidden_states: torch.Tensor,
        class_labels: Optional[torch.Tensor] = None,
        timestep_cond: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None,
        cross_attention_kwargs: Optional[Dict[str, Any]] = None,
        added_cond_kwargs: Optional[Dict[str, torch.Tensor]] = None,
        down_block_additional_residuals: Optional[Tuple[torch.Tensor]] = None,
        mid_block_additional_residual: Optional[torch.Tensor] = None,
        down_intrablock_additional_residuals: Optional[Tuple[torch.Tensor]] = None,
        encoder_attention_mask: Optional[torch.Tensor] = None,
        return_dict: bool = True,
# å®šä¹‰ä¸€ä¸ªç»§æ‰¿è‡ª nn.Linear çš„çº¿æ€§å¤šç»´å±‚
class LinearMultiDim(nn.Linear):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œæ¥å—è¾“å…¥ç‰¹å¾ã€è¾“å‡ºç‰¹å¾åŠå…¶ä»–å‚æ•°
    def __init__(self, in_features, out_features=None, second_dim=4, *args, **kwargs):
        # å¦‚æœ in_features æ˜¯æ•´æ•°ï¼Œåˆ™å°†å…¶è½¬æ¢ä¸ºåŒ…å«ä¸‰ä¸ªç»´åº¦çš„åˆ—è¡¨
        in_features = [in_features, second_dim, 1] if isinstance(in_features, int) else list(in_features)
        # å¦‚æœæœªæä¾› out_featuresï¼Œåˆ™å°†å…¶è®¾ç½®ä¸º in_features
        if out_features is None:
            out_features = in_features
        # å¦‚æœ out_features æ˜¯æ•´æ•°ï¼Œåˆ™è½¬æ¢ä¸ºåŒ…å«ä¸‰ä¸ªç»´åº¦çš„åˆ—è¡¨
        out_features = [out_features, second_dim, 1] if isinstance(out_features, int) else list(out_features)
        # ä¿å­˜è¾“å…¥ç‰¹å¾çš„å¤šç»´ä¿¡æ¯
        self.in_features_multidim = in_features
        # ä¿å­˜è¾“å‡ºç‰¹å¾çš„å¤šç»´ä¿¡æ¯
        self.out_features_multidim = out_features
        # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¡ç®—è¾“å…¥å’Œè¾“å‡ºç‰¹å¾çš„æ€»æ•°é‡
        super().__init__(np.array(in_features).prod(), np.array(out_features).prod())

    # å®šä¹‰å‰å‘ä¼ æ’­æ–¹æ³•
    def forward(self, input_tensor, *args, **kwargs):
        # è·å–è¾“å…¥å¼ é‡çš„å½¢çŠ¶
        shape = input_tensor.shape
        # è·å–è¾“å…¥ç‰¹å¾çš„ç»´åº¦æ•°é‡
        n_dim = len(self.in_features_multidim)
        # å°†è¾“å…¥å¼ é‡é‡å¡‘ä¸ºé€‚åˆçº¿æ€§å±‚çš„å½¢çŠ¶
        input_tensor = input_tensor.reshape(*shape[0:-n_dim], self.in_features)
        # è°ƒç”¨çˆ¶ç±»çš„å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œå¾—åˆ°è¾“å‡ºå¼ é‡
        output_tensor = super().forward(input_tensor)
        # å°†è¾“å‡ºå¼ é‡é‡å¡‘ä¸ºç›®æ ‡å½¢çŠ¶
        output_tensor = output_tensor.view(*shape[0:-n_dim], *self.out_features_multidim)
        # è¿”å›è¾“å‡ºå¼ é‡
        return output_tensor


# å®šä¹‰ä¸€ä¸ªå¹³å¦çš„æ®‹å·®å—ç±»ï¼Œç»§æ‰¿è‡ª nn.Module
class ResnetBlockFlat(nn.Module):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œæ¥å—å¤šä¸ªå‚æ•°ï¼ŒåŒ…æ‹¬é€šé“æ•°ã€ä¸¢å¼ƒç‡ç­‰
    def __init__(
        self,
        *,
        in_channels,
        out_channels=None,
        dropout=0.0,
        temb_channels=512,
        groups=32,
        groups_out=None,
        pre_norm=True,
        eps=1e-6,
        time_embedding_norm="default",
        use_in_shortcut=None,
        second_dim=4,
        **kwargs,
    # åˆå§‹åŒ–æ–¹æ³•çš„ç»“æŸï¼Œæ¥æ”¶å‚æ•°
        ):
            # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
            super().__init__()
            # æ˜¯å¦è¿›è¡Œé¢„å½’ä¸€åŒ–ï¼Œè®¾ç½®ä¸ºä¼ å…¥çš„å€¼
            self.pre_norm = pre_norm
            # å°†é¢„å½’ä¸€åŒ–è®¾ç½®ä¸º True
            self.pre_norm = True
    
            # å¦‚æœè¾“å…¥é€šé“æ˜¯æ•´æ•°ï¼Œåˆ™æ„é€ ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªç»´åº¦çš„åˆ—è¡¨
            in_channels = [in_channels, second_dim, 1] if isinstance(in_channels, int) else list(in_channels)
            # è®¡ç®—è¾“å…¥é€šé“æ•°çš„ä¹˜ç§¯
            self.in_channels_prod = np.array(in_channels).prod()
            # ä¿å­˜è¾“å…¥é€šé“çš„å¤šç»´ä¿¡æ¯
            self.channels_multidim = in_channels
    
            # å¦‚æœè¾“å‡ºé€šé“ä¸ä¸º None
            if out_channels is not None:
                # å¦‚æœè¾“å‡ºé€šé“æ˜¯æ•´æ•°ï¼Œæ„é€ ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªç»´åº¦çš„åˆ—è¡¨
                out_channels = [out_channels, second_dim, 1] if isinstance(out_channels, int) else list(out_channels)
                # è®¡ç®—è¾“å‡ºé€šé“æ•°çš„ä¹˜ç§¯
                out_channels_prod = np.array(out_channels).prod()
                # ä¿å­˜è¾“å‡ºé€šé“çš„å¤šç»´ä¿¡æ¯
                self.out_channels_multidim = out_channels
            else:
                # å¦‚æœè¾“å‡ºé€šé“ä¸º Noneï¼Œåˆ™è¾“å‡ºé€šé“ä¹˜ç§¯ç­‰äºè¾“å…¥é€šé“ä¹˜ç§¯
                out_channels_prod = self.in_channels_prod
                # è¾“å‡ºé€šé“çš„å¤šç»´ä¿¡æ¯ä¸è¾“å…¥é€šé“ç›¸åŒ
                self.out_channels_multidim = self.channels_multidim
            # ä¿å­˜æ—¶é—´åµŒå…¥çš„å½’ä¸€åŒ–çŠ¶æ€
            self.time_embedding_norm = time_embedding_norm
    
            # å¦‚æœè¾“å‡ºç»„æ•°ä¸º Noneï¼Œä½¿ç”¨ä¼ å…¥çš„ç»„æ•°
            if groups_out is None:
                groups_out = groups
    
            # åˆ›å»ºç¬¬ä¸€ä¸ªå½’ä¸€åŒ–å±‚ï¼Œä½¿ç”¨ç»„å½’ä¸€åŒ–
            self.norm1 = torch.nn.GroupNorm(num_groups=groups, num_channels=self.in_channels_prod, eps=eps, affine=True)
            # åˆ›å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚ï¼Œä½¿ç”¨è¾“å…¥é€šé“å’Œè¾“å‡ºé€šé“ä¹˜ç§¯
            self.conv1 = torch.nn.Conv2d(self.in_channels_prod, out_channels_prod, kernel_size=1, padding=0)
    
            # å¦‚æœæ—¶é—´åµŒå…¥é€šé“ä¸ä¸º None
            if temb_channels is not None:
                # åˆ›å»ºæ—¶é—´åµŒå…¥æŠ•å½±å±‚
                self.time_emb_proj = torch.nn.Linear(temb_channels, out_channels_prod)
            else:
                # å¦‚æœæ—¶é—´åµŒå…¥é€šé“ä¸º Noneï¼Œåˆ™ä¸è¿›è¡ŒæŠ•å½±
                self.time_emb_proj = None
    
            # åˆ›å»ºç¬¬äºŒä¸ªå½’ä¸€åŒ–å±‚ï¼Œä½¿ç”¨è¾“å‡ºç»„æ•°å’Œè¾“å‡ºé€šé“ä¹˜ç§¯
            self.norm2 = torch.nn.GroupNorm(num_groups=groups_out, num_channels=out_channels_prod, eps=eps, affine=True)
            # åˆ›å»ºä¸¢å¼ƒå±‚ï¼Œä½¿ç”¨ä¼ å…¥çš„ä¸¢å¼ƒç‡
            self.dropout = torch.nn.Dropout(dropout)
            # åˆ›å»ºç¬¬äºŒä¸ªå·ç§¯å±‚ï¼Œä½¿ç”¨è¾“å‡ºé€šé“ä¹˜ç§¯
            self.conv2 = torch.nn.Conv2d(out_channels_prod, out_channels_prod, kernel_size=1, padding=0)
    
            # è®¾ç½®éçº¿æ€§æ¿€æ´»å‡½æ•°ä¸º SiLU
            self.nonlinearity = nn.SiLU()
    
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨è¾“å…¥çŸ­è·¯ï¼Œå¦‚æœçŸ­è·¯ä½¿ç”¨å‚æ•°ä¸º Noneï¼Œåˆ™æ ¹æ®é€šé“æ•°åˆ¤æ–­
            self.use_in_shortcut = (
                self.in_channels_prod != out_channels_prod if use_in_shortcut is None else use_in_shortcut
            )
    
            # åˆå§‹åŒ–å¿«æ·è¿æ¥å·ç§¯ä¸º None
            self.conv_shortcut = None
            # å¦‚æœä½¿ç”¨è¾“å…¥çŸ­è·¯
            if self.use_in_shortcut:
                # åˆ›å»ºå¿«æ·è¿æ¥å·ç§¯å±‚
                self.conv_shortcut = torch.nn.Conv2d(
                    self.in_channels_prod, out_channels_prod, kernel_size=1, stride=1, padding=0
                )
    # å®šä¹‰å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œæ¥æ”¶è¾“å…¥å¼ é‡å’Œæ—¶é—´åµŒå…¥
        def forward(self, input_tensor, temb):
            # è·å–è¾“å…¥å¼ é‡çš„å½¢çŠ¶
            shape = input_tensor.shape
            # è·å–å¤šç»´é€šé“çš„ç»´åº¦æ•°
            n_dim = len(self.channels_multidim)
            # è°ƒæ•´è¾“å…¥å¼ é‡å½¢çŠ¶ï¼Œåˆå¹¶é€šé“ç»´åº¦å¹¶å¢åŠ ä¸¤ä¸ªç»´åº¦
            input_tensor = input_tensor.reshape(*shape[0:-n_dim], self.in_channels_prod, 1, 1)
            # å°†å¼ é‡è§†å›¾è½¬æ¢ä¸ºæŒ‡å®šå½¢çŠ¶ï¼Œä¿æŒé€šé“æ•°å¹¶å¢åŠ ä¸¤ä¸ªç»´åº¦
            input_tensor = input_tensor.view(-1, self.in_channels_prod, 1, 1)
    
            # åˆå§‹åŒ–éšè—çŠ¶æ€ä¸ºè¾“å…¥å¼ é‡
            hidden_states = input_tensor
    
            # å¯¹éšè—çŠ¶æ€è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
            hidden_states = self.norm1(hidden_states)
            # åº”ç”¨éçº¿æ€§æ¿€æ´»å‡½æ•°
            hidden_states = self.nonlinearity(hidden_states)
            # é€šè¿‡ç¬¬ä¸€ä¸ªå·ç§¯å±‚å¤„ç†éšè—çŠ¶æ€
            hidden_states = self.conv1(hidden_states)
    
            # å¦‚æœæ—¶é—´åµŒå…¥ä¸ä¸ºç©º
            if temb is not None:
                # å¯¹æ—¶é—´åµŒå…¥è¿›è¡Œéçº¿æ€§å¤„ç†å¹¶è°ƒæ•´å½¢çŠ¶
                temb = self.time_emb_proj(self.nonlinearity(temb))[:, :, None, None]
                # å°†æ—¶é—´åµŒå…¥ä¸éšè—çŠ¶æ€ç›¸åŠ 
                hidden_states = hidden_states + temb
    
            # å¯¹éšè—çŠ¶æ€è¿›è¡Œç¬¬äºŒæ¬¡å½’ä¸€åŒ–å¤„ç†
            hidden_states = self.norm2(hidden_states)
            # å†æ¬¡åº”ç”¨éçº¿æ€§æ¿€æ´»å‡½æ•°
            hidden_states = self.nonlinearity(hidden_states)
    
            # å¯¹éšè—çŠ¶æ€åº”ç”¨ dropout æ“ä½œ
            hidden_states = self.dropout(hidden_states)
            # é€šè¿‡ç¬¬äºŒä¸ªå·ç§¯å±‚å¤„ç†éšè—çŠ¶æ€
            hidden_states = self.conv2(hidden_states)
    
            # å¦‚æœå­˜åœ¨çŸ­è·¯å·ç§¯å±‚
            if self.conv_shortcut is not None:
                # é€šè¿‡çŸ­è·¯å·ç§¯å±‚å¤„ç†è¾“å…¥å¼ é‡
                input_tensor = self.conv_shortcut(input_tensor)
    
            # å°†è¾“å…¥å¼ é‡ä¸éšè—çŠ¶æ€ç›¸åŠ ï¼Œç”Ÿæˆè¾“å‡ºå¼ é‡
            output_tensor = input_tensor + hidden_states
    
            # å°†è¾“å‡ºå¼ é‡è°ƒæ•´ä¸ºæŒ‡å®šå½¢çŠ¶ï¼Œå»æ‰å¤šä½™çš„ç»´åº¦
            output_tensor = output_tensor.view(*shape[0:-n_dim], -1)
            # å†æ¬¡è°ƒæ•´è¾“å‡ºå¼ é‡çš„å½¢çŠ¶ï¼ŒåŒ¹é…è¾“å‡ºé€šé“çš„å¤šç»´ç»“æ„
            output_tensor = output_tensor.view(*shape[0:-n_dim], *self.out_channels_multidim)
    
            # è¿”å›æœ€ç»ˆçš„è¾“å‡ºå¼ é‡
            return output_tensor
# å®šä¹‰ä¸€ä¸ªåä¸º DownBlockFlat çš„ç±»ï¼Œç»§æ‰¿è‡ª nn.Module
class DownBlockFlat(nn.Module):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œæ¥å—å¤šä¸ªå‚æ•°ç”¨äºé…ç½®æ¨¡å‹
    def __init__(
        self,
        in_channels: int,  # è¾“å…¥é€šé“æ•°
        out_channels: int,  # è¾“å‡ºé€šé“æ•°
        temb_channels: int,  # æ—¶é—´åµŒå…¥é€šé“æ•°
        dropout: float = 0.0,  # dropout æ¦‚ç‡
        num_layers: int = 1,  # ResNet å±‚æ•°
        resnet_eps: float = 1e-6,  # ResNet çš„ epsilon å€¼
        resnet_time_scale_shift: str = "default",  # ResNet çš„æ—¶é—´ç¼©æ”¾åç§»
        resnet_act_fn: str = "swish",  # ResNet çš„æ¿€æ´»å‡½æ•°
        resnet_groups: int = 32,  # ResNet çš„åˆ†ç»„æ•°
        resnet_pre_norm: bool = True,  # æ˜¯å¦åœ¨ ResNet å‰è¿›è¡Œå½’ä¸€åŒ–
        output_scale_factor: float = 1.0,  # è¾“å‡ºç¼©æ”¾å› å­
        add_downsample: bool = True,  # æ˜¯å¦æ·»åŠ ä¸‹é‡‡æ ·å±‚
        downsample_padding: int = 1,  # ä¸‹é‡‡æ ·æ—¶çš„å¡«å……
    ):
        # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
        super().__init__()
        # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜æ”¾ ResNet å±‚
        resnets = []

        # å¾ªç¯åˆ›å»ºæŒ‡å®šæ•°é‡çš„ ResNet å±‚
        for i in range(num_layers):
            # ç¬¬ä¸€å±‚ä½¿ç”¨è¾“å…¥é€šé“ï¼Œä¹‹åçš„å±‚ä½¿ç”¨è¾“å‡ºé€šé“
            in_channels = in_channels if i == 0 else out_channels
            # å°† ResNet å±‚æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            resnets.append(
                ResnetBlockFlat(
                    in_channels=in_channels,  # å½“å‰å±‚çš„è¾“å…¥é€šé“æ•°
                    out_channels=out_channels,  # å½“å‰å±‚çš„è¾“å‡ºé€šé“æ•°
                    temb_channels=temb_channels,  # æ—¶é—´åµŒå…¥é€šé“æ•°
                    eps=resnet_eps,  # epsilon å€¼
                    groups=resnet_groups,  # åˆ†ç»„æ•°
                    dropout=dropout,  # dropout æ¦‚ç‡
                    time_embedding_norm=resnet_time_scale_shift,  # æ—¶é—´åµŒå…¥å½’ä¸€åŒ–æ–¹å¼
                    non_linearity=resnet_act_fn,  # æ¿€æ´»å‡½æ•°
                    output_scale_factor=output_scale_factor,  # è¾“å‡ºç¼©æ”¾å› å­
                    pre_norm=resnet_pre_norm,  # æ˜¯å¦å‰å½’ä¸€åŒ–
                )
            )

        # å°† ResNet å±‚åˆ—è¡¨è½¬ä¸º nn.ModuleList ä»¥ä¾¿äºç®¡ç†
        self.resnets = nn.ModuleList(resnets)

        # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦æ·»åŠ ä¸‹é‡‡æ ·å±‚
        if add_downsample:
            self.downsamplers = nn.ModuleList(
                [
                    LinearMultiDim(
                        out_channels,  # è¾“å…¥é€šé“æ•°
                        use_conv=True,  # ä½¿ç”¨å·ç§¯
                        out_channels=out_channels,  # è¾“å‡ºé€šé“æ•°
                        padding=downsample_padding,  # å¡«å……
                        name="op"  # ä¸‹é‡‡æ ·å±‚åç§°
                    )
                ]
            )
        else:
            # å¦‚æœä¸æ·»åŠ ä¸‹é‡‡æ ·å±‚ï¼Œè®¾ç½®ä¸º None
            self.downsamplers = None

        # åˆå§‹åŒ–æ¢¯åº¦æ£€æŸ¥ç‚¹ä¸º False
        self.gradient_checkpointing = False

    # å®šä¹‰å‰å‘ä¼ æ’­æ–¹æ³•
    def forward(
        self, hidden_states: torch.Tensor, temb: Optional[torch.Tensor] = None  # è¾“å…¥çš„éšè—çŠ¶æ€å’Œå¯é€‰çš„æ—¶é—´åµŒå…¥
    ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, ...]]:
        # åˆå§‹åŒ–è¾“å‡ºçŠ¶æ€ä¸ºä¸€ä¸ªç©ºå…ƒç»„
        output_states = ()

        # éå†æ‰€æœ‰çš„ ResNet å±‚
        for resnet in self.resnets:
            # å¦‚æœåœ¨è®­ç»ƒæ¨¡å¼ä¸”å¼€å¯äº†æ¢¯åº¦æ£€æŸ¥ç‚¹
            if self.training and self.gradient_checkpointing:
                # å®šä¹‰ä¸€ä¸ªåˆ›å»ºè‡ªå®šä¹‰å‰å‘ä¼ æ’­çš„æ–¹æ³•
                def create_custom_forward(module):
                    # å®šä¹‰è‡ªå®šä¹‰å‰å‘ä¼ æ’­å‡½æ•°
                    def custom_forward(*inputs):
                        return module(*inputs)  # è°ƒç”¨æ¨¡å—è¿›è¡Œå‰å‘ä¼ æ’­

                    return custom_forward

                # æ£€æŸ¥ PyTorch ç‰ˆæœ¬ï¼Œä½¿ç”¨ä¸åŒçš„è°ƒç”¨æ–¹å¼
                if is_torch_version(">=", "1.11.0"):
                    hidden_states = torch.utils.checkpoint.checkpoint(
                        create_custom_forward(resnet), hidden_states, temb, use_reentrant=False  # è¿›è¡Œæ¢¯åº¦æ£€æŸ¥ç‚¹çš„å‰å‘ä¼ æ’­
                    )
                else:
                    hidden_states = torch.utils.checkpoint.checkpoint(
                        create_custom_forward(resnet), hidden_states, temb  # è¿›è¡Œæ¢¯åº¦æ£€æŸ¥ç‚¹çš„å‰å‘ä¼ æ’­
                    )
            else:
                # æ­£å¸¸è°ƒç”¨ ResNet å±‚è¿›è¡Œå‰å‘ä¼ æ’­
                hidden_states = resnet(hidden_states, temb)

            # å°†å½“å‰éšè—çŠ¶æ€æ·»åŠ åˆ°è¾“å‡ºçŠ¶æ€ä¸­
            output_states = output_states + (hidden_states,)

        # å¦‚æœå­˜åœ¨ä¸‹é‡‡æ ·å±‚
        if self.downsamplers is not None:
            # éå†æ‰€æœ‰ä¸‹é‡‡æ ·å±‚
            for downsampler in self.downsamplers:
                hidden_states = downsampler(hidden_states)  # å¯¹éšè—çŠ¶æ€è¿›è¡Œä¸‹é‡‡æ ·

            # å°†ä¸‹é‡‡æ ·åçš„éšè—çŠ¶æ€æ·»åŠ åˆ°è¾“å‡ºçŠ¶æ€ä¸­
            output_states = output_states + (hidden_states,)

        # è¿”å›æœ€ç»ˆçš„éšè—çŠ¶æ€å’Œæ‰€æœ‰è¾“å‡ºçŠ¶æ€
        return hidden_states, output_states
# å®šä¹‰ä¸€ä¸ªåä¸º CrossAttnDownBlockFlat çš„ç±»ï¼Œç»§æ‰¿è‡ª nn.Module
class CrossAttnDownBlockFlat(nn.Module):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œå®šä¹‰ç±»çš„å±æ€§
    def __init__(
        # è¾“å…¥é€šé“æ•°
        self,
        in_channels: int,
        # è¾“å‡ºé€šé“æ•°
        out_channels: int,
        # æ—¶é—´åµŒå…¥é€šé“æ•°
        temb_channels: int,
        # dropout æ¦‚ç‡ï¼Œé»˜è®¤ä¸º 0.0
        dropout: float = 0.0,
        # å±‚æ•°ï¼Œé»˜è®¤ä¸º 1
        num_layers: int = 1,
        # æ¯ä¸ªå—çš„å˜æ¢å™¨å±‚æ•°ï¼Œå¯ä»¥æ˜¯æ•´æ•°æˆ–æ•´æ•°å…ƒç»„ï¼Œé»˜è®¤ä¸º 1
        transformer_layers_per_block: Union[int, Tuple[int]] = 1,
        # ResNet çš„ epsilon å€¼ï¼Œé»˜è®¤ä¸º 1e-6
        resnet_eps: float = 1e-6,
        # ResNet çš„æ—¶é—´å°ºåº¦åç§»è®¾ç½®ï¼Œé»˜è®¤ä¸º "default"
        resnet_time_scale_shift: str = "default",
        # ResNet çš„æ¿€æ´»å‡½æ•°ï¼Œé»˜è®¤ä¸º "swish"
        resnet_act_fn: str = "swish",
        # ResNet çš„ç»„æ•°ï¼Œé»˜è®¤ä¸º 32
        resnet_groups: int = 32,
        # æ˜¯å¦ä½¿ç”¨é¢„å½’ä¸€åŒ–ï¼Œé»˜è®¤ä¸º True
        resnet_pre_norm: bool = True,
        # æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼Œé»˜è®¤ä¸º 1
        num_attention_heads: int = 1,
        # äº¤å‰æ³¨æ„åŠ›çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º 1280
        cross_attention_dim: int = 1280,
        # è¾“å‡ºç¼©æ”¾å› å­ï¼Œé»˜è®¤ä¸º 1.0
        output_scale_factor: float = 1.0,
        # ä¸‹é‡‡æ ·çš„å¡«å……å¤§å°ï¼Œé»˜è®¤ä¸º 1
        downsample_padding: int = 1,
        # æ˜¯å¦æ·»åŠ ä¸‹é‡‡æ ·å±‚ï¼Œé»˜è®¤ä¸º True
        add_downsample: bool = True,
        # æ˜¯å¦ä½¿ç”¨åŒé‡äº¤å‰æ³¨æ„åŠ›ï¼Œé»˜è®¤ä¸º False
        dual_cross_attention: bool = False,
        # æ˜¯å¦ä½¿ç”¨çº¿æ€§æŠ•å½±ï¼Œé»˜è®¤ä¸º False
        use_linear_projection: bool = False,
        # æ˜¯å¦åªä½¿ç”¨äº¤å‰æ³¨æ„åŠ›ï¼Œé»˜è®¤ä¸º False
        only_cross_attention: bool = False,
        # æ˜¯å¦ä¸Šæº¯æ³¨æ„åŠ›ï¼Œé»˜è®¤ä¸º False
        upcast_attention: bool = False,
        # æ³¨æ„åŠ›ç±»å‹ï¼Œé»˜è®¤ä¸º "default"
        attention_type: str = "default",
    ):
        # è°ƒç”¨çˆ¶ç±»çš„æ„é€ å‡½æ•°ä»¥åˆå§‹åŒ–åŸºç±»
        super().__init__()
        # åˆå§‹åŒ–å­˜å‚¨ ResNet å—çš„åˆ—è¡¨
        resnets = []
        # åˆå§‹åŒ–å­˜å‚¨æ³¨æ„åŠ›æ¨¡å‹çš„åˆ—è¡¨
        attentions = []

        # è®¾ç½®æ˜¯å¦ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›çš„æ ‡å¿—
        self.has_cross_attention = True
        # è®¾ç½®æ³¨æ„åŠ›å¤´çš„æ•°é‡
        self.num_attention_heads = num_attention_heads
        # å¦‚æœ transformer_layers_per_block æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œåˆ™å°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼
        if isinstance(transformer_layers_per_block, int):
            transformer_layers_per_block = [transformer_layers_per_block] * num_layers

        # ä¸ºæ¯ä¸€å±‚æ„å»º ResNet å—å’Œæ³¨æ„åŠ›æ¨¡å‹
        for i in range(num_layers):
            # è®¾ç½®å½“å‰å±‚çš„è¾“å…¥é€šé“æ•°ï¼Œç¬¬ä¸€å±‚ä½¿ç”¨ in_channelsï¼Œå…¶ä»–å±‚ä½¿ç”¨ out_channels
            in_channels = in_channels if i == 0 else out_channels
            # å‘ resnets åˆ—è¡¨æ·»åŠ ä¸€ä¸ª ResNet å—
            resnets.append(
                ResnetBlockFlat(
                    # è®¾ç½® ResNet å—çš„è¾“å…¥é€šé“æ•°
                    in_channels=in_channels,
                    # è®¾ç½® ResNet å—çš„è¾“å‡ºé€šé“æ•°
                    out_channels=out_channels,
                    # è®¾ç½®æ—¶é—´åµŒå…¥é€šé“æ•°
                    temb_channels=temb_channels,
                    # è®¾ç½® ResNet å—çš„ epsilon å€¼
                    eps=resnet_eps,
                    # è®¾ç½® ResNet å—çš„ç»„æ•°
                    groups=resnet_groups,
                    # è®¾ç½® dropout æ¦‚ç‡
                    dropout=dropout,
                    # è®¾ç½®æ—¶é—´åµŒå…¥çš„å½’ä¸€åŒ–æ–¹æ³•
                    time_embedding_norm=resnet_time_scale_shift,
                    # è®¾ç½®æ¿€æ´»å‡½æ•°
                    non_linearity=resnet_act_fn,
                    # è®¾ç½®è¾“å‡ºç¼©æ”¾å› å­
                    output_scale_factor=output_scale_factor,
                    # è®¾ç½®æ˜¯å¦åœ¨å‰é¢è¿›è¡Œå½’ä¸€åŒ–
                    pre_norm=resnet_pre_norm,
                )
            )
            # å¦‚æœä¸ä½¿ç”¨åŒäº¤å‰æ³¨æ„åŠ›
            if not dual_cross_attention:
                # å‘ attentions åˆ—è¡¨æ·»åŠ ä¸€ä¸ª Transformer 2D æ¨¡å‹
                attentions.append(
                    Transformer2DModel(
                        # è®¾ç½®æ³¨æ„åŠ›å¤´çš„æ•°é‡
                        num_attention_heads,
                        # è®¾ç½®æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„è¾“å‡ºé€šé“æ•°
                        out_channels // num_attention_heads,
                        # è®¾ç½®è¾“å…¥é€šé“æ•°
                        in_channels=out_channels,
                        # è®¾ç½®å½“å‰å±‚çš„ Transformer å±‚æ•°
                        num_layers=transformer_layers_per_block[i],
                        # è®¾ç½®äº¤å‰æ³¨æ„åŠ›çš„ç»´åº¦
                        cross_attention_dim=cross_attention_dim,
                        # è®¾ç½®å½’ä¸€åŒ–çš„ç»„æ•°
                        norm_num_groups=resnet_groups,
                        # è®¾ç½®æ˜¯å¦ä½¿ç”¨çº¿æ€§æŠ•å½±
                        use_linear_projection=use_linear_projection,
                        # è®¾ç½®æ˜¯å¦ä»…ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›
                        only_cross_attention=only_cross_attention,
                        # è®¾ç½®æ˜¯å¦æé«˜æ³¨æ„åŠ›ç²¾åº¦
                        upcast_attention=upcast_attention,
                        # è®¾ç½®æ³¨æ„åŠ›ç±»å‹
                        attention_type=attention_type,
                    )
                )
            else:
                # å‘ attentions åˆ—è¡¨æ·»åŠ ä¸€ä¸ªåŒ Transformer 2D æ¨¡å‹
                attentions.append(
                    DualTransformer2DModel(
                        # è®¾ç½®æ³¨æ„åŠ›å¤´çš„æ•°é‡
                        num_attention_heads,
                        # è®¾ç½®æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„è¾“å‡ºé€šé“æ•°
                        out_channels // num_attention_heads,
                        # è®¾ç½®è¾“å…¥é€šé“æ•°
                        in_channels=out_channels,
                        # å›ºå®šå±‚æ•°ä¸º 1
                        num_layers=1,
                        # è®¾ç½®äº¤å‰æ³¨æ„åŠ›çš„ç»´åº¦
                        cross_attention_dim=cross_attention_dim,
                        # è®¾ç½®å½’ä¸€åŒ–çš„ç»„æ•°
                        norm_num_groups=resnet_groups,
                    )
                )
        # å°†æ³¨æ„åŠ›æ¨¡å‹åˆ—è¡¨è½¬æ¢ä¸º PyTorch çš„ ModuleList
        self.attentions = nn.ModuleList(attentions)
        # å°† ResNet å—åˆ—è¡¨è½¬æ¢ä¸º PyTorch çš„ ModuleList
        self.resnets = nn.ModuleList(resnets)

        # å¦‚æœéœ€è¦æ·»åŠ ä¸‹é‡‡æ ·å±‚
        if add_downsample:
            # åˆå§‹åŒ–ä¸‹é‡‡æ ·å±‚ä¸º ModuleList
            self.downsamplers = nn.ModuleList(
                [
                    LinearMultiDim(
                        # è®¾ç½®è¾“å‡ºé€šé“æ•°
                        out_channels, use_conv=True, out_channels=out_channels, padding=downsample_padding, name="op"
                    )
                ]
            )
        else:
            # å¦‚æœä¸æ·»åŠ ä¸‹é‡‡æ ·å±‚ï¼Œå°†å…¶è®¾ä¸º None
            self.downsamplers = None

        # åˆå§‹åŒ–æ¢¯åº¦æ£€æŸ¥ç‚¹æ ‡å¿—ä¸º False
        self.gradient_checkpointing = False
    # å®šä¹‰å‰å‘ä¼ æ’­å‡½æ•°ï¼Œæ¥æ”¶éšè—çŠ¶æ€å’Œå…¶ä»–å¯é€‰å‚æ•°
        def forward(
            self,
            hidden_states: torch.Tensor,  # å½“å‰éšè—çŠ¶æ€çš„å¼ é‡
            temb: Optional[torch.Tensor] = None,  # å¯é€‰çš„æ—¶é—´åµŒå…¥å¼ é‡
            encoder_hidden_states: Optional[torch.Tensor] = None,  # å¯é€‰çš„ç¼–ç å™¨éšè—çŠ¶æ€å¼ é‡
            attention_mask: Optional[torch.Tensor] = None,  # å¯é€‰çš„æ³¨æ„åŠ›æ©ç 
            cross_attention_kwargs: Optional[Dict[str, Any]] = None,  # å¯é€‰çš„äº¤å‰æ³¨æ„åŠ›å‚æ•°
            encoder_attention_mask: Optional[torch.Tensor] = None,  # å¯é€‰çš„ç¼–ç å™¨æ³¨æ„åŠ›æ©ç 
            additional_residuals: Optional[torch.Tensor] = None,  # å¯é€‰çš„é¢å¤–æ®‹å·®å¼ é‡
        ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, ...]]:  # è¿”å›éšè—çŠ¶æ€å’Œè¾“å‡ºçŠ¶æ€å…ƒç»„
            output_states = ()  # åˆå§‹åŒ–è¾“å‡ºçŠ¶æ€å…ƒç»„
    
            blocks = list(zip(self.resnets, self.attentions))  # å°†æ®‹å·®ç½‘ç»œå’Œæ³¨æ„åŠ›æ¨¡å—é…å¯¹æˆå—
    
            for i, (resnet, attn) in enumerate(blocks):  # éå†æ¯ä¸ªå—åŠå…¶ç´¢å¼•
                if self.training and self.gradient_checkpointing:  # æ£€æŸ¥æ˜¯å¦åœ¨è®­ç»ƒä¸”å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
    
                    def create_custom_forward(module, return_dict=None):  # å®šä¹‰è‡ªå®šä¹‰å‰å‘ä¼ æ’­å‡½æ•°
                        def custom_forward(*inputs):  # è‡ªå®šä¹‰å‰å‘ä¼ æ’­é€»è¾‘
                            if return_dict is not None:  # å¦‚æœæä¾›äº†è¿”å›å­—å…¸
                                return module(*inputs, return_dict=return_dict)  # è¿”å›å¸¦å­—å…¸çš„ç»“æœ
                            else:
                                return module(*inputs)  # å¦åˆ™è¿”å›æ™®é€šç»“æœ
    
                        return custom_forward  # è¿”å›è‡ªå®šä¹‰å‰å‘ä¼ æ’­å‡½æ•°
    
                    # è®¾ç½®æ£€æŸ¥ç‚¹å‚æ•°ï¼Œå¦‚æœ PyTorch ç‰ˆæœ¬å¤§äºç­‰äº 1.11.0ï¼Œåˆ™ä½¿ç”¨éé‡å…¥æ¨¡å¼
                    ckpt_kwargs: Dict[str, Any] = {"use_reentrant": False} if is_torch_version(">=", "1.11.0") else {}
                    # é€šè¿‡æ£€æŸ¥ç‚¹æœºåˆ¶è®¡ç®—å½“å‰å—çš„éšè—çŠ¶æ€
                    hidden_states = torch.utils.checkpoint.checkpoint(
                        create_custom_forward(resnet),  # åˆ›å»ºè‡ªå®šä¹‰å‰å‘å‡½æ•°çš„æ£€æŸ¥ç‚¹
                        hidden_states,  # è¾“å…¥å½“å‰éšè—çŠ¶æ€
                        temb,  # è¾“å…¥æ—¶é—´åµŒå…¥
                        **ckpt_kwargs,  # ä¼ é€’æ£€æŸ¥ç‚¹å‚æ•°
                    )
                    # é€šè¿‡æ³¨æ„åŠ›æ¨¡å—å¤„ç†éšè—çŠ¶æ€å¹¶è·å–è¾“å‡º
                    hidden_states = attn(
                        hidden_states,
                        encoder_hidden_states=encoder_hidden_states,  # ç¼–ç å™¨éšè—çŠ¶æ€
                        cross_attention_kwargs=cross_attention_kwargs,  # äº¤å‰æ³¨æ„åŠ›å‚æ•°
                        attention_mask=attention_mask,  # æ³¨æ„åŠ›æ©ç 
                        encoder_attention_mask=encoder_attention_mask,  # ç¼–ç å™¨æ³¨æ„åŠ›æ©ç 
                        return_dict=False,  # ä¸è¿”å›å­—å…¸æ ¼å¼
                    )[0]  # å–å‡ºç¬¬ä¸€ä¸ªè¾“å‡º
                else:  # å¦‚æœä¸å¯ç”¨æ¢¯åº¦æ£€æŸ¥
                    # ç›´æ¥é€šè¿‡æ®‹å·®ç½‘ç»œå¤„ç†éšè—çŠ¶æ€
                    hidden_states = resnet(hidden_states, temb)
                    # é€šè¿‡æ³¨æ„åŠ›æ¨¡å—å¤„ç†éšè—çŠ¶æ€å¹¶è·å–è¾“å‡º
                    hidden_states = attn(
                        hidden_states,
                        encoder_hidden_states=encoder_hidden_states,  # ç¼–ç å™¨éšè—çŠ¶æ€
                        cross_attention_kwargs=cross_attention_kwargs,  # äº¤å‰æ³¨æ„åŠ›å‚æ•°
                        attention_mask=attention_mask,  # æ³¨æ„åŠ›æ©ç 
                        encoder_attention_mask=encoder_attention_mask,  # ç¼–ç å™¨æ³¨æ„åŠ›æ©ç 
                        return_dict=False,  # ä¸è¿”å›å­—å…¸æ ¼å¼
                    )[0]  # å–å‡ºç¬¬ä¸€ä¸ªè¾“å‡º
    
                # å¦‚æœæ˜¯æœ€åä¸€ä¸ªå—å¹¶ä¸”æä¾›äº†é¢å¤–æ®‹å·®ï¼Œåˆ™å°†å…¶æ·»åŠ åˆ°éšè—çŠ¶æ€
                if i == len(blocks) - 1 and additional_residuals is not None:
                    hidden_states = hidden_states + additional_residuals  # åŠ ä¸Šé¢å¤–æ®‹å·®
    
                output_states = output_states + (hidden_states,)  # å°†å½“å‰éšè—çŠ¶æ€æ·»åŠ åˆ°è¾“å‡ºçŠ¶æ€å…ƒç»„ä¸­
    
            if self.downsamplers is not None:  # å¦‚æœå­˜åœ¨ä¸‹é‡‡æ ·å™¨
                for downsampler in self.downsamplers:  # éå†æ¯ä¸ªä¸‹é‡‡æ ·å™¨
                    hidden_states = downsampler(hidden_states)  # å¤„ç†å½“å‰éšè—çŠ¶æ€
    
                output_states = output_states + (hidden_states,)  # å°†å½“å‰éšè—çŠ¶æ€æ·»åŠ åˆ°è¾“å‡ºçŠ¶æ€å…ƒç»„ä¸­
    
            return hidden_states, output_states  # è¿”å›æœ€ç»ˆçš„éšè—çŠ¶æ€å’Œè¾“å‡ºçŠ¶æ€å…ƒç»„
# ä» diffusers.models.unets.unet_2d_blocks ä¸­å¤åˆ¶ï¼Œæ›¿æ¢ UpBlock2D ä¸º UpBlockFlatï¼ŒResnetBlock2D ä¸º ResnetBlockFlatï¼ŒUpsample2D ä¸º LinearMultiDim
class UpBlockFlat(nn.Module):
    # åˆå§‹åŒ–å‡½æ•°ï¼Œå®šä¹‰è¾“å…¥è¾“å‡ºé€šé“åŠå…¶ä»–å‚æ•°
    def __init__(
        self,
        in_channels: int,  # è¾“å…¥é€šé“æ•°
        prev_output_channel: int,  # å‰ä¸€å±‚è¾“å‡ºé€šé“æ•°
        out_channels: int,  # å½“å‰å±‚è¾“å‡ºé€šé“æ•°
        temb_channels: int,  # æ—¶é—´åµŒå…¥é€šé“æ•°
        resolution_idx: Optional[int] = None,  # åˆ†è¾¨ç‡ç´¢å¼•
        dropout: float = 0.0,  # dropout æ¦‚ç‡
        num_layers: int = 1,  # å±‚æ•°
        resnet_eps: float = 1e-6,  # ResNet ä¸­çš„ epsilon å€¼
        resnet_time_scale_shift: str = "default",  # æ—¶é—´å°ºåº¦åç§»è®¾ç½®
        resnet_act_fn: str = "swish",  # æ¿€æ´»å‡½æ•°ç±»å‹
        resnet_groups: int = 32,  # åˆ†ç»„æ•°
        resnet_pre_norm: bool = True,  # æ˜¯å¦è¿›è¡Œé¢„å½’ä¸€åŒ–
        output_scale_factor: float = 1.0,  # è¾“å‡ºç¼©æ”¾å› å­
        add_upsample: bool = True,  # æ˜¯å¦æ·»åŠ ä¸Šé‡‡æ ·
    ):
        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        super().__init__()
        # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨å­˜å‚¨ ResNet å—
        resnets = []

        # éå†å±‚æ•°ï¼Œæ„å»ºæ¯ä¸€å±‚çš„ ResNet å—
        for i in range(num_layers):
            # æ ¹æ®å±‚æ•°å†³å®šæ®‹å·®è·³è·ƒé€šé“æ•°
            res_skip_channels = in_channels if (i == num_layers - 1) else out_channels
            # æ ¹æ®å½“å‰å±‚æ•°å†³å®šè¾“å…¥é€šé“æ•°
            resnet_in_channels = prev_output_channel if i == 0 else out_channels

            # å°† ResNet å—æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            resnets.append(
                ResnetBlockFlat(
                    in_channels=resnet_in_channels + res_skip_channels,  # è¾“å…¥é€šé“æ•°
                    out_channels=out_channels,  # è¾“å‡ºé€šé“æ•°
                    temb_channels=temb_channels,  # æ—¶é—´åµŒå…¥é€šé“æ•°
                    eps=resnet_eps,  # epsilon å€¼
                    groups=resnet_groups,  # åˆ†ç»„æ•°
                    dropout=dropout,  # dropout æ¦‚ç‡
                    time_embedding_norm=resnet_time_scale_shift,  # æ—¶é—´åµŒå…¥å½’ä¸€åŒ–
                    non_linearity=resnet_act_fn,  # æ¿€æ´»å‡½æ•°
                    output_scale_factor=output_scale_factor,  # è¾“å‡ºç¼©æ”¾å› å­
                    pre_norm=resnet_pre_norm,  # é¢„å½’ä¸€åŒ–
                )
            )

        # å°† ResNet å—åˆ—è¡¨è½¬æ¢ä¸ºæ¨¡å—åˆ—è¡¨
        self.resnets = nn.ModuleList(resnets)

        # å¦‚æœéœ€è¦æ·»åŠ ä¸Šé‡‡æ ·å±‚ï¼Œåˆ™åˆ›å»ºä¸Šé‡‡æ ·æ¨¡å—
        if add_upsample:
            self.upsamplers = nn.ModuleList([LinearMultiDim(out_channels, use_conv=True, out_channels=out_channels)])
        else:
            # å¦åˆ™è®¾ç½®ä¸º None
            self.upsamplers = None

        # åˆå§‹åŒ–æ¢¯åº¦æ£€æŸ¥ç‚¹æ ‡å¿—
        self.gradient_checkpointing = False
        # è®¾ç½®åˆ†è¾¨ç‡ç´¢å¼•
        self.resolution_idx = resolution_idx

    # å‰å‘ä¼ æ’­å‡½æ•°
    def forward(
        self,
        hidden_states: torch.Tensor,  # éšè—çŠ¶æ€å¼ é‡
        res_hidden_states_tuple: Tuple[torch.Tensor, ...],  # æ®‹å·®éšè—çŠ¶æ€å…ƒç»„
        temb: Optional[torch.Tensor] = None,  # å¯é€‰çš„æ—¶é—´åµŒå…¥å¼ é‡
        upsample_size: Optional[int] = None,  # å¯é€‰çš„ä¸Šé‡‡æ ·å¤§å°
        *args,  # å¯å˜å‚æ•°
        **kwargs,  # å¯å˜å…³é”®å­—å‚æ•°
    ) -> torch.Tensor:  # å®šä¹‰ä¸€ä¸ªè¿”å› torch.Tensor ç±»å‹çš„å‡½æ•°
        # å¦‚æœå‚æ•°åˆ—è¡¨ args é•¿åº¦å¤§äº 0 æˆ– kwargs ä¸­çš„ scale å‚æ•°ä¸ä¸º None
        if len(args) > 0 or kwargs.get("scale", None) is not None:
            # è®¾ç½®å¼ƒç”¨æ¶ˆæ¯ï¼Œæé†’ç”¨æˆ· scale å‚æ•°å·²å¼ƒç”¨ä¸”å°†è¢«å¿½ç•¥
            deprecation_message = "The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`."
            # è°ƒç”¨ deprecate å‡½æ•°ï¼Œè®°å½• scale å‚æ•°çš„å¼ƒç”¨
            deprecate("scale", "1.0.0", deprecation_message)

        # æ£€æŸ¥ FreeU æ˜¯å¦å¯ç”¨ï¼Œå–å†³äº s1, s2, b1 å’Œ b2 çš„å€¼
        is_freeu_enabled = (
            getattr(self, "s1", None)  # è·å– self ä¸­çš„ s1 å±æ€§
            and getattr(self, "s2", None)  # è·å– self ä¸­çš„ s2 å±æ€§
            and getattr(self, "b1", None)  # è·å– self ä¸­çš„ b1 å±æ€§
            and getattr(self, "b2", None)  # è·å– self ä¸­çš„ b2 å±æ€§
        )

        # éå† self.resnets ä¸­çš„æ¯ä¸ª ResNet æ¨¡å‹
        for resnet in self.resnets:
            # å¼¹å‡º res éšè—çŠ¶æ€çš„æœ€åä¸€ä¸ªå…ƒç´ 
            res_hidden_states = res_hidden_states_tuple[-1]  
            # ç§»é™¤ res éšè—çŠ¶æ€å…ƒç»„çš„æœ€åä¸€ä¸ªå…ƒç´ 
            res_hidden_states_tuple = res_hidden_states_tuple[:-1]  

            # FreeU: ä»…åœ¨å‰ä¸¤ä¸ªé˜¶æ®µè¿›è¡Œæ“ä½œ
            if is_freeu_enabled:
                # åº”ç”¨ FreeU æ“ä½œï¼Œè¿”å›æ›´æ–°åçš„ hidden_states å’Œ res_hidden_states
                hidden_states, res_hidden_states = apply_freeu(
                    self.resolution_idx,  # å½“å‰åˆ†è¾¨ç‡ç´¢å¼•
                    hidden_states,  # å½“å‰éšè—çŠ¶æ€
                    res_hidden_states,  # ä¹‹å‰çš„éšè—çŠ¶æ€
                    s1=self.s1,  # s1 å‚æ•°
                    s2=self.s2,  # s2 å‚æ•°
                    b1=self.b1,  # b1 å‚æ•°
                    b2=self.b2,  # b2 å‚æ•°
                )

            # å°†å½“å‰çš„ hidden_states å’Œ res_hidden_states åœ¨ç»´åº¦ 1 ä¸Šæ‹¼æ¥
            hidden_states = torch.cat([hidden_states, res_hidden_states], dim=1)  

            # å¦‚æœå¤„äºè®­ç»ƒæ¨¡å¼å¹¶ä¸”å¼€å¯äº†æ¢¯åº¦æ£€æŸ¥ç‚¹
            if self.training and self.gradient_checkpointing:
                # å®šä¹‰ä¸€ä¸ªåˆ›å»ºè‡ªå®šä¹‰å‰å‘å‡½æ•°çš„å‡½æ•°
                def create_custom_forward(module):
                    # å®šä¹‰è‡ªå®šä¹‰å‰å‘å‡½æ•°ï¼Œæ¥æ”¶è¾“å…¥å¹¶è°ƒç”¨æ¨¡å—
                    def custom_forward(*inputs):
                        return module(*inputs)

                    return custom_forward

                # å¦‚æœ PyTorch ç‰ˆæœ¬å¤§äºç­‰äº 1.11.0
                if is_torch_version(">=", "1.11.0"):
                    # ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æ¥è®¡ç®— hidden_states
                    hidden_states = torch.utils.checkpoint.checkpoint(
                        create_custom_forward(resnet),  # ä½¿ç”¨è‡ªå®šä¹‰å‰å‘å‡½æ•°
                        hidden_states,  # å½“å‰éšè—çŠ¶æ€
                        temb,  # ä¼ å…¥çš„é¢å¤–è¾“å…¥
                        use_reentrant=False  # ç¦ç”¨é‡å…¥æ£€æŸ¥
                    )
                else:
                    # å¯¹äºæ—©æœŸç‰ˆæœ¬ï¼Œä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹è®¡ç®— hidden_states
                    hidden_states = torch.utils.checkpoint.checkpoint(
                        create_custom_forward(resnet),  # ä½¿ç”¨è‡ªå®šä¹‰å‰å‘å‡½æ•°
                        hidden_states,  # å½“å‰éšè—çŠ¶æ€
                        temb  # ä¼ å…¥çš„é¢å¤–è¾“å…¥
                    )
            else:
                # åœ¨éè®­ç»ƒæ¨¡å¼ä¸‹ç›´æ¥è°ƒç”¨ resnet å¤„ç† hidden_states
                hidden_states = resnet(hidden_states, temb)  

        # å¦‚æœå­˜åœ¨ä¸Šé‡‡æ ·å™¨
        if self.upsamplers is not None:
            # éå†æ‰€æœ‰ä¸Šé‡‡æ ·å™¨
            for upsampler in self.upsamplers:
                # ä½¿ç”¨ä¸Šé‡‡æ ·å™¨å¯¹ hidden_states è¿›è¡Œå¤„ç†ï¼ŒæŒ‡å®šä¸Šé‡‡æ ·å°ºå¯¸
                hidden_states = upsampler(hidden_states, upsample_size)  

        # è¿”å›å¤„ç†åçš„ hidden_states
        return hidden_states  
# ä» diffusers.models.unets.unet_2d_blocks ä¸­å¤åˆ¶çš„ä»£ç ï¼Œä¿®æ”¹äº†ç±»åå’Œä¸€äº›ç»„ä»¶
class CrossAttnUpBlockFlat(nn.Module):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œå®šä¹‰ç±»çš„åŸºæœ¬å±æ€§å’Œå‚æ•°
    def __init__(
        # è¾“å…¥é€šé“æ•°
        in_channels: int,
        # è¾“å‡ºé€šé“æ•°
        out_channels: int,
        # ä¸Šä¸€å±‚è¾“å‡ºçš„é€šé“æ•°
        prev_output_channel: int,
        # é¢å¤–çš„æ—¶é—´åµŒå…¥é€šé“æ•°
        temb_channels: int,
        # å¯é€‰çš„åˆ†è¾¨ç‡ç´¢å¼•
        resolution_idx: Optional[int] = None,
        # dropout æ¦‚ç‡
        dropout: float = 0.0,
        # å±‚æ•°
        num_layers: int = 1,
        # æ¯ä¸ªå—çš„å˜æ¢å™¨å±‚æ•°ï¼Œå¯ä»¥æ˜¯å•ä¸ªæ•´æ•°æˆ–å…ƒç»„
        transformer_layers_per_block: Union[int, Tuple[int]] = 1,
        # ResNet çš„ epsilon å€¼
        resnet_eps: float = 1e-6,
        # ResNet æ—¶é—´å°ºåº¦åç§»çš„ç±»å‹
        resnet_time_scale_shift: str = "default",
        # ResNet æ¿€æ´»å‡½æ•°çš„ç±»å‹
        resnet_act_fn: str = "swish",
        # ResNet çš„ç»„æ•°
        resnet_groups: int = 32,
        # æ˜¯å¦åœ¨ ResNet ä¸­ä½¿ç”¨é¢„å½’ä¸€åŒ–
        resnet_pre_norm: bool = True,
        # æ³¨æ„åŠ›å¤´çš„æ•°é‡
        num_attention_heads: int = 1,
        # äº¤å‰æ³¨æ„åŠ›çš„ç»´åº¦
        cross_attention_dim: int = 1280,
        # è¾“å‡ºç¼©æ”¾å› å­
        output_scale_factor: float = 1.0,
        # æ˜¯å¦æ·»åŠ ä¸Šé‡‡æ ·æ­¥éª¤
        add_upsample: bool = True,
        # æ˜¯å¦ä½¿ç”¨åŒäº¤å‰æ³¨æ„åŠ›
        dual_cross_attention: bool = False,
        # æ˜¯å¦ä½¿ç”¨çº¿æ€§æŠ•å½±
        use_linear_projection: bool = False,
        # æ˜¯å¦ä»…ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›
        only_cross_attention: bool = False,
        # æ˜¯å¦ä¸Šæº¯æ³¨æ„åŠ›
        upcast_attention: bool = False,
        # æ³¨æ„åŠ›ç±»å‹
        attention_type: str = "default",
    # å®šä¹‰æ„é€ å‡½æ•°çš„ç»“æŸéƒ¨åˆ†
        ):
            # è°ƒç”¨çˆ¶ç±»çš„æ„é€ å‡½æ•°
            super().__init__()
            # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ç”¨äºå­˜å‚¨æ®‹å·®ç½‘ç»œå—
            resnets = []
            # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ç”¨äºå­˜å‚¨æ³¨æ„åŠ›æ¨¡å‹
            attentions = []
    
            # è®¾ç½®æ˜¯å¦ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æ ‡å¿—ä¸ºçœŸ
            self.has_cross_attention = True
            # è®¾ç½®æ³¨æ„åŠ›å¤´çš„æ•°é‡
            self.num_attention_heads = num_attention_heads
    
            # å¦‚æœ transformer_layers_per_block æ˜¯æ•´æ•°ï¼Œåˆ™å°†å…¶è½¬æ¢ä¸ºç›¸åŒé•¿åº¦çš„åˆ—è¡¨
            if isinstance(transformer_layers_per_block, int):
                transformer_layers_per_block = [transformer_layers_per_block] * num_layers
    
            # éå†æ¯ä¸€å±‚ä»¥æ„å»ºæ®‹å·®ç½‘ç»œå’Œæ³¨æ„åŠ›æ¨¡å‹
            for i in range(num_layers):
                # è®¾ç½®æ®‹å·®è·³è¿‡é€šé“æ•°ï¼Œæœ€åä¸€å±‚ä½¿ç”¨è¾“å…¥é€šé“ï¼Œå¦åˆ™ä½¿ç”¨è¾“å‡ºé€šé“
                res_skip_channels = in_channels if (i == num_layers - 1) else out_channels
                # è®¾ç½®æ®‹å·®ç½‘ç»œè¾“å…¥é€šé“æ•°ï¼Œç¬¬ä¸€å±‚ä½¿ç”¨å‰ä¸€å±‚è¾“å‡ºé€šé“ï¼Œå¦åˆ™ä½¿ç”¨å½“å‰è¾“å‡ºé€šé“
                resnet_in_channels = prev_output_channel if i == 0 else out_channels
    
                # æ·»åŠ ä¸€ä¸ªæ®‹å·®ç½‘ç»œå—åˆ° resnets åˆ—è¡¨ä¸­
                resnets.append(
                    ResnetBlockFlat(
                        # è®¾ç½®æ®‹å·®ç½‘ç»œè¾“å…¥é€šé“æ•°
                        in_channels=resnet_in_channels + res_skip_channels,
                        # è®¾ç½®æ®‹å·®ç½‘ç»œè¾“å‡ºé€šé“æ•°
                        out_channels=out_channels,
                        # è®¾ç½®æ—¶é—´åµŒå…¥é€šé“æ•°
                        temb_channels=temb_channels,
                        # è®¾ç½®æ®‹å·®ç½‘ç»œçš„ epsilon å€¼
                        eps=resnet_eps,
                        # è®¾ç½®æ®‹å·®ç½‘ç»œçš„ç»„æ•°
                        groups=resnet_groups,
                        # è®¾ç½®ä¸¢å¼ƒç‡
                        dropout=dropout,
                        # è®¾ç½®æ—¶é—´åµŒå…¥çš„å½’ä¸€åŒ–æ–¹æ³•
                        time_embedding_norm=resnet_time_scale_shift,
                        # è®¾ç½®éçº¿æ€§æ¿€æ´»å‡½æ•°
                        non_linearity=resnet_act_fn,
                        # è®¾ç½®è¾“å‡ºç¼©æ”¾å› å­
                        output_scale_factor=output_scale_factor,
                        # è®¾ç½®æ˜¯å¦è¿›è¡Œé¢„å½’ä¸€åŒ–
                        pre_norm=resnet_pre_norm,
                    )
                )
                # å¦‚æœä¸ä½¿ç”¨åŒé‡äº¤å‰æ³¨æ„åŠ›
                if not dual_cross_attention:
                    # æ·»åŠ ä¸€ä¸ªæ™®é€šçš„ Transformer2DModel åˆ° attentions åˆ—è¡¨ä¸­
                    attentions.append(
                        Transformer2DModel(
                            # è®¾ç½®æ³¨æ„åŠ›å¤´çš„æ•°é‡
                            num_attention_heads,
                            # è®¾ç½®æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„è¾“å‡ºé€šé“æ•°
                            out_channels // num_attention_heads,
                            # è®¾ç½®è¾“å…¥é€šé“æ•°
                            in_channels=out_channels,
                            # è®¾ç½®å±‚æ•°
                            num_layers=transformer_layers_per_block[i],
                            # è®¾ç½®äº¤å‰æ³¨æ„åŠ›ç»´åº¦
                            cross_attention_dim=cross_attention_dim,
                            # è®¾ç½®å½’ä¸€åŒ–ç»„æ•°
                            norm_num_groups=resnet_groups,
                            # è®¾ç½®æ˜¯å¦ä½¿ç”¨çº¿æ€§æŠ•å½±
                            use_linear_projection=use_linear_projection,
                            # è®¾ç½®æ˜¯å¦ä»…ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›
                            only_cross_attention=only_cross_attention,
                            # è®¾ç½®æ˜¯å¦ä¸Šæº¯æ³¨æ„åŠ›
                            upcast_attention=upcast_attention,
                            # è®¾ç½®æ³¨æ„åŠ›ç±»å‹
                            attention_type=attention_type,
                        )
                    )
                else:
                    # æ·»åŠ ä¸€ä¸ªåŒé‡ Transformer2DModel åˆ° attentions åˆ—è¡¨ä¸­
                    attentions.append(
                        DualTransformer2DModel(
                            # è®¾ç½®æ³¨æ„åŠ›å¤´çš„æ•°é‡
                            num_attention_heads,
                            # è®¾ç½®æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„è¾“å‡ºé€šé“æ•°
                            out_channels // num_attention_heads,
                            # è®¾ç½®è¾“å…¥é€šé“æ•°
                            in_channels=out_channels,
                            # è®¾ç½®å±‚æ•°ä¸º 1
                            num_layers=1,
                            # è®¾ç½®äº¤å‰æ³¨æ„åŠ›ç»´åº¦
                            cross_attention_dim=cross_attention_dim,
                            # è®¾ç½®å½’ä¸€åŒ–ç»„æ•°
                            norm_num_groups=resnet_groups,
                        )
                    )
            # å°†æ³¨æ„åŠ›æ¨¡å‹åˆ—è¡¨è½¬æ¢ä¸º nn.ModuleList
            self.attentions = nn.ModuleList(attentions)
            # å°†æ®‹å·®ç½‘ç»œå—åˆ—è¡¨è½¬æ¢ä¸º nn.ModuleList
            self.resnets = nn.ModuleList(resnets)
    
            # å¦‚æœéœ€è¦æ·»åŠ ä¸Šé‡‡æ ·å±‚
            if add_upsample:
                # å°†ä¸Šé‡‡æ ·å™¨æ·»åŠ åˆ° nn.ModuleList ä¸­
                self.upsamplers = nn.ModuleList([LinearMultiDim(out_channels, use_conv=True, out_channels=out_channels)])
            else:
                # å¦åˆ™å°†ä¸Šé‡‡æ ·å™¨è®¾ç½®ä¸º None
                self.upsamplers = None
    
            # è®¾ç½®æ¢¯åº¦æ£€æŸ¥ç‚¹æ ‡å¿—ä¸ºå‡
            self.gradient_checkpointing = False
            # è®¾ç½®åˆ†è¾¨ç‡ç´¢å¼•
            self.resolution_idx = resolution_idx
    # å®šä¹‰å‰å‘ä¼ æ’­å‡½æ•°ï¼Œæ¥æ”¶å¤šä¸ªè¾“å…¥å‚æ•°
        def forward(
            self,
            # éšè—çŠ¶æ€ï¼Œç±»å‹ä¸º PyTorch çš„å¼ é‡
            hidden_states: torch.Tensor,
            # åŒ…å«æ®‹å·®éšè—çŠ¶æ€çš„å…ƒç»„ï¼Œå…ƒç´ ç±»å‹ä¸º PyTorch å¼ é‡
            res_hidden_states_tuple: Tuple[torch.Tensor, ...],
            # å¯é€‰çš„æ—¶é—´åµŒå…¥ï¼Œç±»å‹ä¸º PyTorch çš„å¼ é‡
            temb: Optional[torch.Tensor] = None,
            # å¯é€‰çš„ç¼–ç å™¨éšè—çŠ¶æ€ï¼Œç±»å‹ä¸º PyTorch çš„å¼ é‡
            encoder_hidden_states: Optional[torch.Tensor] = None,
            # å¯é€‰çš„äº¤å‰æ³¨æ„åŠ›å‚æ•°ï¼Œç±»å‹ä¸ºå­—å…¸ï¼ŒåŒ…å«ä»»æ„é”®å€¼å¯¹
            cross_attention_kwargs: Optional[Dict[str, Any]] = None,
            # å¯é€‰çš„ä¸Šé‡‡æ ·å¤§å°ï¼Œç±»å‹ä¸ºæ•´æ•°
            upsample_size: Optional[int] = None,
            # å¯é€‰çš„æ³¨æ„åŠ›æ©ç ï¼Œç±»å‹ä¸º PyTorch çš„å¼ é‡
            attention_mask: Optional[torch.Tensor] = None,
            # å¯é€‰çš„ç¼–ç å™¨æ³¨æ„åŠ›æ©ç ï¼Œç±»å‹ä¸º PyTorch çš„å¼ é‡
            encoder_attention_mask: Optional[torch.Tensor] = None,
# ä» diffusers.models.unets.unet_2d_blocks ä¸­å¤åˆ¶çš„ UNetMidBlock2D ä»£ç ï¼Œæ›¿æ¢äº† UNetMidBlock2D ä¸º UNetMidBlockFlatï¼ŒResnetBlock2D ä¸º ResnetBlockFlat
class UNetMidBlockFlat(nn.Module):
    """
    2D UNet ä¸­é—´å— [`UNetMidBlockFlat`]ï¼ŒåŒ…å«å¤šä¸ªæ®‹å·®å—å’Œå¯é€‰çš„æ³¨æ„åŠ›å—ã€‚

    å‚æ•°ï¼š
        in_channels (`int`): è¾“å…¥é€šé“çš„æ•°é‡ã€‚
        temb_channels (`int`): æ—¶é—´åµŒå…¥é€šé“çš„æ•°é‡ã€‚
        dropout (`float`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 0.0): dropout æ¯”ç‡ã€‚
        num_layers (`int`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 1): æ®‹å·®å—çš„æ•°é‡ã€‚
        resnet_eps (`float`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 1e-6): resnet å—çš„ epsilon å€¼ã€‚
        resnet_time_scale_shift (`str`, *å¯é€‰*, é»˜è®¤å€¼ä¸º `default`):
            åº”ç”¨äºæ—¶é—´åµŒå…¥çš„å½’ä¸€åŒ–ç±»å‹ã€‚è¿™å¯ä»¥å¸®åŠ©æé«˜æ¨¡å‹åœ¨é•¿èŒƒå›´æ—¶é—´ä¾èµ–ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚
        resnet_act_fn (`str`, *å¯é€‰*, é»˜è®¤å€¼ä¸º `swish`): resnet å—çš„æ¿€æ´»å‡½æ•°ã€‚
        resnet_groups (`int`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 32):
            resnet å—çš„åˆ†ç»„å½’ä¸€åŒ–å±‚ä½¿ç”¨çš„ç»„æ•°ã€‚
        attn_groups (`Optional[int]`, *å¯é€‰*, é»˜è®¤å€¼ä¸º None): æ³¨æ„åŠ›å—çš„ç»„æ•°ã€‚
        resnet_pre_norm (`bool`, *å¯é€‰*, é»˜è®¤å€¼ä¸º `True`):
            æ˜¯å¦åœ¨ resnet å—ä¸­ä½¿ç”¨é¢„å½’ä¸€åŒ–ã€‚
        add_attention (`bool`, *å¯é€‰*, é»˜è®¤å€¼ä¸º `True`): æ˜¯å¦æ·»åŠ æ³¨æ„åŠ›å—ã€‚
        attention_head_dim (`int`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 1):
            å•ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦ã€‚æ³¨æ„åŠ›å¤´çš„æ•°é‡åŸºäºæ­¤å€¼å’Œè¾“å…¥é€šé“çš„æ•°é‡ç¡®å®šã€‚
        output_scale_factor (`float`, *å¯é€‰*, é»˜è®¤å€¼ä¸º 1.0): è¾“å‡ºç¼©æ”¾å› å­ã€‚

    è¿”å›ï¼š
        `torch.Tensor`: æœ€åä¸€ä¸ªæ®‹å·®å—çš„è¾“å‡ºï¼Œæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º `(batch_size, in_channels,
        height, width)` çš„å¼ é‡ã€‚

    """

    def __init__(
        self,
        in_channels: int,
        temb_channels: int,
        dropout: float = 0.0,
        num_layers: int = 1,
        resnet_eps: float = 1e-6,
        resnet_time_scale_shift: str = "default",  # é»˜è®¤ï¼Œç©ºé—´
        resnet_act_fn: str = "swish",
        resnet_groups: int = 32,
        attn_groups: Optional[int] = None,
        resnet_pre_norm: bool = True,
        add_attention: bool = True,
        attention_head_dim: int = 1,
        output_scale_factor: float = 1.0,
    ):
        # åˆå§‹åŒ– UNetMidBlockFlat ç±»ï¼Œè®¾ç½®å„å‚æ•°çš„é»˜è®¤å€¼
        super().__init__()  # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
        self.in_channels = in_channels  # ä¿å­˜è¾“å…¥é€šé“æ•°
        self.temb_channels = temb_channels  # ä¿å­˜æ—¶é—´åµŒå…¥é€šé“æ•°
        self.dropout = dropout  # ä¿å­˜ dropout æ¯”ç‡
        self.num_layers = num_layers  # ä¿å­˜æ®‹å·®å—çš„æ•°é‡
        self.resnet_eps = resnet_eps  # ä¿å­˜ resnet å—çš„ epsilon å€¼
        self.resnet_time_scale_shift = resnet_time_scale_shift  # ä¿å­˜æ—¶é—´ç¼©æ”¾åç§»ç±»å‹
        self.resnet_act_fn = resnet_act_fn  # ä¿å­˜æ¿€æ´»å‡½æ•°ç±»å‹
        self.resnet_groups = resnet_groups  # ä¿å­˜åˆ†ç»„æ•°
        self.attn_groups = attn_groups  # ä¿å­˜æ³¨æ„åŠ›ç»„æ•°
        self.resnet_pre_norm = resnet_pre_norm  # ä¿å­˜æ˜¯å¦ä½¿ç”¨é¢„å½’ä¸€åŒ–
        self.add_attention = add_attention  # ä¿å­˜æ˜¯å¦æ·»åŠ æ³¨æ„åŠ›å—
        self.attention_head_dim = attention_head_dim  # ä¿å­˜æ³¨æ„åŠ›å¤´çš„ç»´åº¦
        self.output_scale_factor = output_scale_factor  # ä¿å­˜è¾“å‡ºç¼©æ”¾å› å­

    def forward(self, hidden_states: torch.Tensor, temb: Optional[torch.Tensor] = None) -> torch.Tensor:
        # å®šä¹‰å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œæ¥å—éšè—çŠ¶æ€å’Œå¯é€‰çš„æ—¶é—´åµŒå…¥
        hidden_states = self.resnets[0](hidden_states, temb)  # é€šè¿‡ç¬¬ä¸€ä¸ªæ®‹å·®å—å¤„ç†éšè—çŠ¶æ€
        for attn, resnet in zip(self.attentions, self.resnets[1:]):  # éå†åç»­çš„æ³¨æ„åŠ›å—å’Œæ®‹å·®å—
            if attn is not None:  # å¦‚æœæ³¨æ„åŠ›å—å­˜åœ¨
                hidden_states = attn(hidden_states, temb=temb)  # é€šè¿‡æ³¨æ„åŠ›å—å¤„ç†éšè—çŠ¶æ€
            hidden_states = resnet(hidden_states, temb)  # é€šè¿‡æ®‹å·®å—å¤„ç†éšè—çŠ¶æ€

        return hidden_states  # è¿”å›å¤„ç†åçš„éšè—çŠ¶æ€
# ä» diffusers.models.unets.unet_2d_blocks ä¸­å¤åˆ¶ï¼Œæ›¿æ¢ UNetMidBlock2DCrossAttn ä¸º UNetMidBlockFlatCrossAttnï¼ŒResnetBlock2D ä¸º ResnetBlockFlat
class UNetMidBlockFlatCrossAttn(nn.Module):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œå®šä¹‰æ¨¡å‹å‚æ•°
    def __init__(
        self,
        # è¾“å…¥é€šé“æ•°
        in_channels: int,
        # æ—¶é—´åµŒå…¥é€šé“æ•°
        temb_channels: int,
        # è¾“å‡ºé€šé“æ•°ï¼Œé»˜è®¤ä¸º None
        out_channels: Optional[int] = None,
        # Dropout æ¦‚ç‡ï¼Œé»˜è®¤ä¸º 0.0
        dropout: float = 0.0,
        # å±‚æ•°ï¼Œé»˜è®¤ä¸º 1
        num_layers: int = 1,
        # æ¯ä¸ªå—çš„ Transformer å±‚æ•°ï¼Œé»˜è®¤ä¸º 1
        transformer_layers_per_block: Union[int, Tuple[int]] = 1,
        # ResNet çš„ epsilon å€¼ï¼Œé»˜è®¤ä¸º 1e-6
        resnet_eps: float = 1e-6,
        # ResNet çš„æ—¶é—´å°ºåº¦åç§»ï¼Œé»˜è®¤ä¸º "default"
        resnet_time_scale_shift: str = "default",
        # ResNet çš„æ¿€æ´»å‡½æ•°ç±»å‹ï¼Œé»˜è®¤ä¸º "swish"
        resnet_act_fn: str = "swish",
        # ResNet çš„åˆ†ç»„æ•°ï¼Œé»˜è®¤ä¸º 32
        resnet_groups: int = 32,
        # è¾“å‡ºçš„ ResNet åˆ†ç»„æ•°ï¼Œé»˜è®¤ä¸º None
        resnet_groups_out: Optional[int] = None,
        # æ˜¯å¦ä½¿ç”¨é¢„å½’ä¸€åŒ–ï¼Œé»˜è®¤ä¸º True
        resnet_pre_norm: bool = True,
        # æ³¨æ„åŠ›å¤´æ•°ï¼Œé»˜è®¤ä¸º 1
        num_attention_heads: int = 1,
        # è¾“å‡ºç¼©æ”¾å› å­ï¼Œé»˜è®¤ä¸º 1.0
        output_scale_factor: float = 1.0,
        # äº¤å‰æ³¨æ„åŠ›ç»´åº¦ï¼Œé»˜è®¤ä¸º 1280
        cross_attention_dim: int = 1280,
        # æ˜¯å¦ä½¿ç”¨åŒäº¤å‰æ³¨æ„åŠ›ï¼Œé»˜è®¤ä¸º False
        dual_cross_attention: bool = False,
        # æ˜¯å¦ä½¿ç”¨çº¿æ€§æŠ•å½±ï¼Œé»˜è®¤ä¸º False
        use_linear_projection: bool = False,
        # æ˜¯å¦ä¸Šå‡æ³¨æ„åŠ›è®¡ç®—ç²¾åº¦ï¼Œé»˜è®¤ä¸º False
        upcast_attention: bool = False,
        # æ³¨æ„åŠ›ç±»å‹ï¼Œé»˜è®¤ä¸º "default"
        attention_type: str = "default",
    # å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œå®šä¹‰æ¨¡å‹çš„å‰å‘è®¡ç®—é€»è¾‘
    def forward(
        self,
        # éšè—çŠ¶æ€å¼ é‡
        hidden_states: torch.Tensor,
        # å¯é€‰çš„æ—¶é—´åµŒå…¥å¼ é‡ï¼Œé»˜è®¤ä¸º None
        temb: Optional[torch.Tensor] = None,
        # å¯é€‰çš„ç¼–ç å™¨éšè—çŠ¶æ€å¼ é‡ï¼Œé»˜è®¤ä¸º None
        encoder_hidden_states: Optional[torch.Tensor] = None,
        # å¯é€‰çš„æ³¨æ„åŠ›æ©ç ï¼Œé»˜è®¤ä¸º None
        attention_mask: Optional[torch.Tensor] = None,
        # å¯é€‰çš„äº¤å‰æ³¨æ„åŠ›å‚æ•°å­—å…¸ï¼Œé»˜è®¤ä¸º None
        cross_attention_kwargs: Optional[Dict[str, Any]] = None,
        # å¯é€‰çš„ç¼–ç å™¨æ³¨æ„åŠ›æ©ç ï¼Œé»˜è®¤ä¸º None
        encoder_attention_mask: Optional[torch.Tensor] = None,
    ) -> torch.Tensor:  # å®šä¹‰å‡½æ•°çš„è¿”å›ç±»å‹ä¸º torch.Tensor
        if cross_attention_kwargs is not None:  # æ£€æŸ¥ cross_attention_kwargs æ˜¯å¦ä¸º None
            if cross_attention_kwargs.get("scale", None) is not None:  # æ£€æŸ¥ scale æ˜¯å¦åœ¨ cross_attention_kwargs ä¸­
                logger.warning("Passing `scale` to `cross_attention_kwargs` is deprecated. `scale` will be ignored.")  # å‘å‡ºè­¦å‘Šï¼Œæç¤º scale å‚æ•°å·²è¿‡æ—¶

        hidden_states = self.resnets[0](hidden_states, temb)  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ®‹å·®ç½‘ç»œå¤„ç†éšè—çŠ¶æ€å’Œæ—¶é—´åµŒå…¥
        for attn, resnet in zip(self.attentions, self.resnets[1:]):  # éå†æ³¨æ„åŠ›å±‚å’Œåç»­çš„æ®‹å·®ç½‘ç»œ
            if self.training and self.gradient_checkpointing:  # æ£€æŸ¥æ˜¯å¦åœ¨è®­ç»ƒæ¨¡å¼ä¸”å¼€å¯äº†æ¢¯åº¦æ£€æŸ¥ç‚¹

                def create_custom_forward(module, return_dict=None):  # å®šä¹‰ä¸€ä¸ªå‡½æ•°ä»¥åˆ›å»ºè‡ªå®šä¹‰å‰å‘ä¼ æ’­
                    def custom_forward(*inputs):  # å®šä¹‰å®é™…çš„å‰å‘ä¼ æ’­å‡½æ•°
                        if return_dict is not None:  # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿”å›å­—å…¸å½¢å¼çš„è¾“å‡º
                            return module(*inputs, return_dict=return_dict)  # è°ƒç”¨æ¨¡å—å¹¶è¿”å›å­—å…¸
                        else:  # å¦‚æœä¸éœ€è¦å­—å…¸å½¢å¼çš„è¾“å‡º
                            return module(*inputs)  # ç›´æ¥è°ƒç”¨æ¨¡å—å¹¶è¿”å›ç»“æœ

                    return custom_forward  # è¿”å›è‡ªå®šä¹‰å‰å‘ä¼ æ’­å‡½æ•°

                ckpt_kwargs: Dict[str, Any] = {"use_reentrant": False} if is_torch_version(">=", "1.11.0") else {}  # æ ¹æ® PyTorch ç‰ˆæœ¬è®¾ç½®æ£€æŸ¥ç‚¹å‚æ•°
                hidden_states = attn(  # ä½¿ç”¨æ³¨æ„åŠ›å±‚å¤„ç†éšè—çŠ¶æ€
                    hidden_states,  # è¾“å…¥éšè—çŠ¶æ€
                    encoder_hidden_states=encoder_hidden_states,  # è¾“å…¥ç¼–ç å™¨çš„éšè—çŠ¶æ€
                    cross_attention_kwargs=cross_attention_kwargs,  # ä¼ é€’äº¤å‰æ³¨æ„åŠ›å‚æ•°
                    attention_mask=attention_mask,  # ä¼ é€’æ³¨æ„åŠ›æ©ç 
                    encoder_attention_mask=encoder_attention_mask,  # ä¼ é€’ç¼–ç å™¨æ³¨æ„åŠ›æ©ç 
                    return_dict=False,  # ä¸è¿”å›å­—å…¸
                )[0]  # å–å‡ºè¾“å‡ºçš„ç¬¬ä¸€ä¸ªå…ƒç´ 
                hidden_states = torch.utils.checkpoint.checkpoint(  # ä½¿ç”¨æ£€æŸ¥ç‚¹ä¿å­˜å†…å­˜
                    create_custom_forward(resnet),  # åˆ›å»ºè‡ªå®šä¹‰å‰å‘ä¼ æ’­
                    hidden_states,  # è¾“å…¥éšè—çŠ¶æ€
                    temb,  # è¾“å…¥æ—¶é—´åµŒå…¥
                    **ckpt_kwargs,  # è§£åŒ…æ£€æŸ¥ç‚¹å‚æ•°
                )
            else:  # å¦‚æœä¸åœ¨è®­ç»ƒæ¨¡å¼æˆ–ä¸ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
                hidden_states = attn(  # ä½¿ç”¨æ³¨æ„åŠ›å±‚å¤„ç†éšè—çŠ¶æ€
                    hidden_states,  # è¾“å…¥éšè—çŠ¶æ€
                    encoder_hidden_states=encoder_hidden_states,  # è¾“å…¥ç¼–ç å™¨çš„éšè—çŠ¶æ€
                    cross_attention_kwargs=cross_attention_kwargs,  # ä¼ é€’äº¤å‰æ³¨æ„åŠ›å‚æ•°
                    attention_mask=attention_mask,  # ä¼ é€’æ³¨æ„åŠ›æ©ç 
                    encoder_attention_mask=encoder_attention_mask,  # ä¼ é€’ç¼–ç å™¨æ³¨æ„åŠ›æ©ç 
                    return_dict=False,  # ä¸è¿”å›å­—å…¸
                )[0]  # å–å‡ºè¾“å‡ºçš„ç¬¬ä¸€ä¸ªå…ƒç´ 
                hidden_states = resnet(hidden_states, temb)  # ä½¿ç”¨æ®‹å·®ç½‘ç»œå¤„ç†éšè—çŠ¶æ€å’Œæ—¶é—´åµŒå…¥

        return hidden_states  # è¿”å›å¤„ç†åçš„éšè—çŠ¶æ€
# ä» diffusers.models.unets.unet_2d_blocks.UNetMidBlock2DSimpleCrossAttn å¤åˆ¶ï¼Œæ›¿æ¢ UNetMidBlock2DSimpleCrossAttn ä¸º UNetMidBlockFlatSimpleCrossAttnï¼ŒResnetBlock2D ä¸º ResnetBlockFlat
class UNetMidBlockFlatSimpleCrossAttn(nn.Module):
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®å„å±‚çš„è¾“å…¥è¾“å‡ºå‚æ•°
    def __init__(
        # è¾“å…¥é€šé“æ•°
        in_channels: int,
        # æ¡ä»¶åµŒå…¥é€šé“æ•°
        temb_channels: int,
        # Dropout æ¦‚ç‡
        dropout: float = 0.0,
        # ç½‘ç»œå±‚æ•°
        num_layers: int = 1,
        # ResNet çš„ epsilon å€¼
        resnet_eps: float = 1e-6,
        # ResNet çš„æ—¶é—´ç¼©æ”¾åç§»æ–¹å¼
        resnet_time_scale_shift: str = "default",
        # ResNet æ¿€æ´»å‡½æ•°ç±»å‹
        resnet_act_fn: str = "swish",
        # ResNet ä¸­ç»„çš„æ•°é‡
        resnet_groups: int = 32,
        # æ˜¯å¦ä½¿ç”¨ ResNet å‰å½’ä¸€åŒ–
        resnet_pre_norm: bool = True,
        # æ³¨æ„åŠ›å¤´çš„ç»´åº¦
        attention_head_dim: int = 1,
        # è¾“å‡ºç¼©æ”¾å› å­
        output_scale_factor: float = 1.0,
        # äº¤å‰æ³¨æ„åŠ›çš„ç»´åº¦
        cross_attention_dim: int = 1280,
        # æ˜¯å¦è·³è¿‡æ—¶é—´æ¿€æ´»
        skip_time_act: bool = False,
        # æ˜¯å¦ä»…ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›
        only_cross_attention: bool = False,
        # äº¤å‰æ³¨æ„åŠ›çš„å½’ä¸€åŒ–æ–¹å¼
        cross_attention_norm: Optional[str] = None,
    ):
        # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
        super().__init__()

        # è®¾ç½®æ˜¯å¦ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶
        self.has_cross_attention = True

        # è®¾ç½®æ³¨æ„åŠ›å¤´çš„ç»´åº¦
        self.attention_head_dim = attention_head_dim
        # ç¡®å®š ResNet çš„ç»„æ•°ï¼Œè‹¥æœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤å€¼
        resnet_groups = resnet_groups if resnet_groups is not None else min(in_channels // 4, 32)

        # è®¡ç®—å¤´çš„æ•°é‡
        self.num_heads = in_channels // self.attention_head_dim

        # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ª ResNet å—
        resnets = [
            # åˆ›å»ºä¸€ä¸ª ResNet å—
            ResnetBlockFlat(
                in_channels=in_channels,
                out_channels=in_channels,
                temb_channels=temb_channels,
                eps=resnet_eps,
                groups=resnet_groups,
                dropout=dropout,
                time_embedding_norm=resnet_time_scale_shift,
                non_linearity=resnet_act_fn,
                output_scale_factor=output_scale_factor,
                pre_norm=resnet_pre_norm,
                skip_time_act=skip_time_act,
            )
        ]
        # åˆå§‹åŒ–æ³¨æ„åŠ›åˆ—è¡¨
        attentions = []

        # æ ¹æ®å±‚æ•°åˆ›å»ºå¯¹åº”çš„æ³¨æ„åŠ›æœºåˆ¶
        for _ in range(num_layers):
            # æ ¹æ®æ˜¯å¦æ”¯æŒç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›é€‰æ‹©å¤„ç†å™¨
            processor = (
                AttnAddedKVProcessor2_0() if hasattr(F, "scaled_dot_product_attention") else AttnAddedKVProcessor()
            )

            # æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶åˆ°åˆ—è¡¨
            attentions.append(
                Attention(
                    query_dim=in_channels,
                    cross_attention_dim=in_channels,
                    heads=self.num_heads,
                    dim_head=self.attention_head_dim,
                    added_kv_proj_dim=cross_attention_dim,
                    norm_num_groups=resnet_groups,
                    bias=True,
                    upcast_softmax=True,
                    only_cross_attention=only_cross_attention,
                    cross_attention_norm=cross_attention_norm,
                    processor=processor,
                )
            )
            # æ·»åŠ  ResNet å—åˆ°åˆ—è¡¨
            resnets.append(
                ResnetBlockFlat(
                    in_channels=in_channels,
                    out_channels=in_channels,
                    temb_channels=temb_channels,
                    eps=resnet_eps,
                    groups=resnet_groups,
                    dropout=dropout,
                    time_embedding_norm=resnet_time_scale_shift,
                    non_linearity=resnet_act_fn,
                    output_scale_factor=output_scale_factor,
                    pre_norm=resnet_pre_norm,
                    skip_time_act=skip_time_act,
                )
            )

        # å°†æ³¨æ„åŠ›å±‚å­˜å…¥æ¨¡å—åˆ—è¡¨
        self.attentions = nn.ModuleList(attentions)
        # å°† ResNet å—å­˜å…¥æ¨¡å—åˆ—è¡¨
        self.resnets = nn.ModuleList(resnets)

    def forward(
        # å®šä¹‰å‰å‘ä¼ æ’­çš„æ–¹æ³•
        self,
        hidden_states: torch.Tensor,
        # å¯é€‰çš„æ—¶é—´åµŒå…¥å¼ é‡
        temb: Optional[torch.Tensor] = None,
        # å¯é€‰çš„ç¼–ç å™¨éšè—çŠ¶æ€å¼ é‡
        encoder_hidden_states: Optional[torch.Tensor] = None,
        # å¯é€‰çš„æ³¨æ„åŠ›æ©ç å¼ é‡
        attention_mask: Optional[torch.Tensor] = None,
        # å¯é€‰çš„äº¤å‰æ³¨æ„åŠ›å‚æ•°å­—å…¸
        cross_attention_kwargs: Optional[Dict[str, Any]] = None,
        # å¯é€‰çš„ç¼–ç å™¨æ³¨æ„åŠ›æ©ç å¼ é‡
        encoder_attention_mask: Optional[torch.Tensor] = None,
    ) -> torch.Tensor:
        # å¦‚æœä¼ å…¥çš„ cross_attention_kwargs ä¸º Noneï¼Œåˆ™åˆå§‹åŒ–ä¸ºç©ºå­—å…¸
        cross_attention_kwargs = cross_attention_kwargs if cross_attention_kwargs is not None else {}
        # æ£€æŸ¥ cross_attention_kwargs ä¸­æ˜¯å¦æœ‰ 'scale'ï¼Œå¦‚æœæœ‰åˆ™å‘å‡ºè­¦å‘Šï¼Œè¯´æ˜è¯¥å‚æ•°å·²å¼ƒç”¨
        if cross_attention_kwargs.get("scale", None) is not None:
            logger.warning("Passing `scale` to `cross_attention_kwargs` is deprecated. `scale` will be ignored.")

        # å¦‚æœ attention_mask ä¸º None
        if attention_mask is None:
            # å¦‚æœ encoder_hidden_states è¢«å®šä¹‰ï¼šè¡¨ç¤ºæˆ‘ä»¬åœ¨è¿›è¡Œäº¤å‰æ³¨æ„åŠ›ï¼Œå› æ­¤åº”è¯¥ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æ©ç 
            mask = None if encoder_hidden_states is None else encoder_attention_mask
        else:
            # å½“ attention_mask è¢«å®šä¹‰æ—¶ï¼šæˆ‘ä»¬ä¸æ£€æŸ¥ encoder_attention_mask
            # è¿™æ˜¯ä¸ºäº†ä¸ UnCLIP å…¼å®¹ï¼ŒUnCLIP ä½¿ç”¨ 'attention_mask' å‚æ•°ä½œä¸ºäº¤å‰æ³¨æ„åŠ›æ©ç 
            # TODO: UnCLIP åº”é€šè¿‡ encoder_attention_mask å‚æ•°è€Œä¸æ˜¯ attention_mask å‚æ•°æ¥è¡¨è¾¾äº¤å‰æ³¨æ„åŠ›æ©ç 
            #       ç„¶åæˆ‘ä»¬å¯ä»¥ç®€åŒ–æ•´ä¸ª if/else å—ä¸ºï¼š
            #         mask = attention_mask if encoder_hidden_states is None else encoder_attention_mask
            mask = attention_mask

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ®‹å·®ç½‘ç»œå¤„ç†éšè—çŠ¶æ€å’Œæ—¶é—´åµŒå…¥
        hidden_states = self.resnets[0](hidden_states, temb)
        # éå†æ‰€æœ‰æ³¨æ„åŠ›å±‚å’Œå¯¹åº”çš„æ®‹å·®ç½‘ç»œ
        for attn, resnet in zip(self.attentions, self.resnets[1:]):
            # ä½¿ç”¨æ³¨æ„åŠ›å±‚å¤„ç†éšè—çŠ¶æ€
            hidden_states = attn(
                hidden_states,
                encoder_hidden_states=encoder_hidden_states,  # ä¼ é€’ç¼–ç å™¨éšè—çŠ¶æ€
                attention_mask=mask,  # ä¼ é€’æ©ç 
                **cross_attention_kwargs,  # ä¼ é€’äº¤å‰æ³¨æ„åŠ›å‚æ•°
            )

            # ä½¿ç”¨æ®‹å·®ç½‘ç»œå¤„ç†éšè—çŠ¶æ€
            hidden_states = resnet(hidden_states, temb)

        # è¿”å›æœ€ç»ˆçš„éšè—çŠ¶æ€
        return hidden_states
```