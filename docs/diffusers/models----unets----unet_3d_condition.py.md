# `.\diffusers\models\unets\unet_3d_condition.py`

```
# ç‰ˆæƒå£°æ˜ï¼Œå£°æ˜æ­¤ä»£ç çš„ç‰ˆæƒä¿¡æ¯å’Œæ‰€æœ‰æƒ
# Copyright 2024 Alibaba DAMO-VILAB and The HuggingFace Team. All rights reserved.
# ç‰ˆæƒå£°æ˜ï¼Œå£°æ˜æ­¤ä»£ç çš„ç‰ˆæƒä¿¡æ¯å’Œæ‰€æœ‰æƒ
# Copyright 2024 The ModelScope Team.
#
# è®¸å¯å£°æ˜ï¼Œå£°æ˜æœ¬ä»£ç ä½¿ç”¨çš„ Apache è®¸å¯è¯ 2.0 ç‰ˆæœ¬
# Licensed under the Apache License, Version 2.0 (the "License");
# ä½¿ç”¨æ­¤æ–‡ä»¶å‰éœ€éµå®ˆè®¸å¯è¯è§„å®š
# you may not use this file except in compliance with the License.
# å¯åœ¨ä»¥ä¸‹ç½‘å€è·å–è®¸å¯è¯å‰¯æœ¬
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# å…è´£å£°æ˜ï¼Œè¯´æ˜è½¯ä»¶åœ¨è®¸å¯ä¸‹æŒ‰ "åŸæ ·" æä¾›ï¼Œä¸é™„åŠ ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# è®¸å¯è¯ä¸­è§„å®šçš„æƒé™å’Œé™åˆ¶è¯´æ˜
# See the License for the specific language governing permissions and
# limitations under the License.

# ä» dataclasses æ¨¡å—å¯¼å…¥ dataclass è£…é¥°å™¨
from dataclasses import dataclass
# ä» typing æ¨¡å—å¯¼å…¥æ‰€éœ€çš„ç±»å‹æç¤º
from typing import Any, Dict, List, Optional, Tuple, Union

# å¯¼å…¥ PyTorch åº“
import torch
# å¯¼å…¥ PyTorch ç¥ç»ç½‘ç»œæ¨¡å—
import torch.nn as nn
# å¯¼å…¥ PyTorch çš„æ£€æŸ¥ç‚¹å·¥å…·
import torch.utils.checkpoint

# å¯¼å…¥é…ç½®ç›¸å…³çš„å·¥å…·ç±»å’Œå‡½æ•°
from ...configuration_utils import ConfigMixin, register_to_config
# å¯¼å…¥ UNet2D æ¡ä»¶åŠ è½½å™¨æ··åˆç±»
from ...loaders import UNet2DConditionLoadersMixin
# å¯¼å…¥åŸºæœ¬è¾“å‡ºç±»å’Œæ—¥å¿—å·¥å…·
from ...utils import BaseOutput, logging
# å¯¼å…¥æ¿€æ´»å‡½æ•°è·å–å·¥å…·
from ..activations import get_activation
# å¯¼å…¥å„ç§æ³¨æ„åŠ›å¤„ç†å™¨ç›¸å…³ç»„ä»¶
from ..attention_processor import (
    ADDED_KV_ATTENTION_PROCESSORS,  # å¯¼å…¥æ·»åŠ é”®å€¼å¯¹æ³¨æ„åŠ›å¤„ç†å™¨
    CROSS_ATTENTION_PROCESSORS,      # å¯¼å…¥äº¤å‰æ³¨æ„åŠ›å¤„ç†å™¨
    Attention,                       # å¯¼å…¥æ³¨æ„åŠ›ç±»
    AttentionProcessor,              # å¯¼å…¥æ³¨æ„åŠ›å¤„ç†å™¨åŸºç±»
    AttnAddedKVProcessor,            # å¯¼å…¥æ·»åŠ é”®å€¼å¯¹çš„æ³¨æ„åŠ›å¤„ç†å™¨
    AttnProcessor,                   # å¯¼å…¥æ™®é€šæ³¨æ„åŠ›å¤„ç†å™¨
    FusedAttnProcessor2_0,           # å¯¼å…¥èåˆæ³¨æ„åŠ›å¤„ç†å™¨
)
# å¯¼å…¥æ—¶é—´æ­¥åµŒå…¥å’Œæ—¶é—´æ­¥ç±»
from ..embeddings import TimestepEmbedding, Timesteps
# å¯¼å…¥æ¨¡å‹æ··åˆç±»
from ..modeling_utils import ModelMixin
# å¯¼å…¥æ—¶é—´å˜æ¢å™¨æ¨¡å‹
from ..transformers.transformer_temporal import TransformerTemporalModel
# å¯¼å…¥ 3D UNet ç›¸å…³çš„å—
from .unet_3d_blocks import (
    CrossAttnDownBlock3D,          # å¯¼å…¥äº¤å‰æ³¨æ„åŠ›ä¸‹é‡‡æ ·å—
    CrossAttnUpBlock3D,            # å¯¼å…¥äº¤å‰æ³¨æ„åŠ›ä¸Šé‡‡æ ·å—
    DownBlock3D,                   # å¯¼å…¥ä¸‹é‡‡æ ·å—
    UNetMidBlock3DCrossAttn,      # å¯¼å…¥ UNet ä¸­é—´äº¤å‰æ³¨æ„åŠ›å—
    UpBlock3D,                     # å¯¼å…¥ä¸Šé‡‡æ ·å—
    get_down_block,                # å¯¼å…¥è·å–ä¸‹é‡‡æ ·å—çš„å‡½æ•°
    get_up_block,                  # å¯¼å…¥è·å–ä¸Šé‡‡æ ·å—çš„å‡½æ•°
)

# åˆ›å»ºæ—¥å¿—è®°å½•å™¨ï¼Œä½¿ç”¨å½“å‰æ¨¡å—çš„åç§°
logger = logging.get_logger(__name__)  # pylint: disable=invalid-name

# å®šä¹‰ UNet3DConditionOutput æ•°æ®ç±»ï¼Œç»§æ‰¿è‡ª BaseOutput
@dataclass
class UNet3DConditionOutput(BaseOutput):
    """
    [`UNet3DConditionModel`] çš„è¾“å‡ºç±»ã€‚

    å‚æ•°ï¼š
        sample (`torch.Tensor` çš„å½¢çŠ¶ä¸º `(batch_size, num_channels, num_frames, height, width)`):
            åŸºäº `encoder_hidden_states` è¾“å…¥çš„éšè—çŠ¶æ€è¾“å‡ºã€‚æ¨¡å‹æœ€åä¸€å±‚çš„è¾“å‡ºã€‚
    """

    sample: torch.Tensor  # å®šä¹‰æ ·æœ¬è¾“å‡ºï¼Œç±»å‹ä¸º PyTorch å¼ é‡

# å®šä¹‰ UNet3DConditionModel ç±»ï¼Œç»§æ‰¿è‡ªå¤šä¸ªæ··åˆç±»
class UNet3DConditionModel(ModelMixin, ConfigMixin, UNet2DConditionLoadersMixin):
    r"""
    æ¡ä»¶ 3D UNet æ¨¡å‹ï¼Œæ¥å—å™ªå£°æ ·æœ¬ã€æ¡ä»¶çŠ¶æ€å’Œæ—¶é—´æ­¥ï¼Œå¹¶è¿”å›å½¢çŠ¶ä¸ºæ ·æœ¬çš„è¾“å‡ºã€‚

    æ­¤æ¨¡å‹ç»§æ‰¿è‡ª [`ModelMixin`]ã€‚æœ‰å…³å…¶é€šç”¨æ–¹æ³•çš„æ–‡æ¡£ï¼Œè¯·å‚é˜…è¶…ç±»æ–‡æ¡£ï¼ˆå¦‚ä¸‹è½½æˆ–ä¿å­˜ï¼‰ã€‚
    # å‚æ•°è¯´æ˜éƒ¨åˆ†
    Parameters:
        # è¾“å…¥/è¾“å‡ºæ ·æœ¬çš„é«˜åº¦å’Œå®½åº¦ï¼Œç±»å‹å¯ä»¥ä¸ºæ•´æ•°æˆ–å…ƒç»„ï¼Œé»˜è®¤ä¸º None
        sample_size (`int` or `Tuple[int, int]`, *optional*, defaults to `None`):
            Height and width of input/output sample.
        # è¾“å…¥æ ·æœ¬çš„é€šé“æ•°ï¼Œé»˜è®¤ä¸º 4
        in_channels (`int`, *optional*, defaults to 4): The number of channels in the input sample.
        # è¾“å‡ºçš„é€šé“æ•°ï¼Œé»˜è®¤ä¸º 4
        out_channels (`int`, *optional*, defaults to 4): The number of channels in the output.
        # ä½¿ç”¨çš„ä¸‹é‡‡æ ·å—ç±»å‹çš„å…ƒç»„ï¼Œé»˜è®¤ä¸ºæŒ‡å®šçš„å››ç§å—
        down_block_types (`Tuple[str]`, *optional*, defaults to `("CrossAttnDownBlock3D", "CrossAttnDownBlock3D", "CrossAttnDownBlock3D", "DownBlock3D")`):
            The tuple of downsample blocks to use.
        # ä½¿ç”¨çš„ä¸Šé‡‡æ ·å—ç±»å‹çš„å…ƒç»„ï¼Œé»˜è®¤ä¸ºæŒ‡å®šçš„å››ç§å—
        up_block_types (`Tuple[str]`, *optional*, defaults to `("UpBlock3D", "CrossAttnUpBlock3D", "CrossAttnUpBlock3D", "CrossAttnUpBlock3D")`):
            The tuple of upsample blocks to use.
        # æ¯ä¸ªå—çš„è¾“å‡ºé€šé“æ•°çš„å…ƒç»„ï¼Œé»˜è®¤ä¸º (320, 640, 1280, 1280)
        block_out_channels (`Tuple[int]`, *optional*, defaults to `(320, 640, 1280, 1280)`):
            The tuple of output channels for each block.
        # æ¯ä¸ªå—çš„å±‚æ•°ï¼Œé»˜è®¤ä¸º 2
        layers_per_block (`int`, *optional*, defaults to 2): The number of layers per block.
        # ä¸‹é‡‡æ ·å·ç§¯ä½¿ç”¨çš„å¡«å……ï¼Œé»˜è®¤ä¸º 1
        downsample_padding (`int`, *optional*, defaults to 1): The padding to use for the downsampling convolution.
        # ä¸­é—´å—ä½¿ç”¨çš„ç¼©æ”¾å› å­ï¼Œé»˜è®¤ä¸º 1.0
        mid_block_scale_factor (`float`, *optional*, defaults to 1.0): The scale factor to use for the mid block.
        # ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ï¼Œé»˜è®¤ä¸º "silu"
        act_fn (`str`, *optional*, defaults to `"silu"`): The activation function to use.
        # ç”¨äºå½’ä¸€åŒ–çš„ç»„æ•°ï¼Œé»˜è®¤ä¸º 32ï¼›å¦‚æœä¸º Noneï¼Œåˆ™è·³è¿‡å½’ä¸€åŒ–å’Œæ¿€æ´»å±‚
        norm_num_groups (`int`, *optional*, defaults to 32): The number of groups to use for the normalization.
            If `None`, normalization and activation layers is skipped in post-processing.
        # å½’ä¸€åŒ–ä½¿ç”¨çš„ epsilon å€¼ï¼Œé»˜è®¤ä¸º 1e-5
        norm_eps (`float`, *optional*, defaults to 1e-5): The epsilon to use for the normalization.
        # äº¤å‰æ³¨æ„åŠ›ç‰¹å¾çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º 1024
        cross_attention_dim (`int`, *optional*, defaults to 1024): The dimension of the cross attention features.
        # æ³¨æ„åŠ›å¤´çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º 64
        attention_head_dim (`int`, *optional*, defaults to 64): The dimension of the attention heads.
        # æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼Œç±»å‹ä¸ºæ•´æ•°ï¼Œé»˜è®¤ä¸º None
        num_attention_heads (`int`, *optional*): The number of attention heads.
        # æ—¶é—´æ¡ä»¶æŠ•å½±å±‚çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º None
        time_cond_proj_dim (`int`, *optional*, defaults to `None`):
            The dimension of `cond_proj` layer in the timestep embedding.
    """

    # æ˜¯å¦æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œé»˜è®¤ä¸º False
    _supports_gradient_checkpointing = False

    # å°†æ­¤ç±»æ³¨å†Œåˆ°é…ç½®ä¸­
    @register_to_config
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œç”¨äºåˆ›å»ºç±»çš„å®ä¾‹
        def __init__(
            # æ ·æœ¬å¤§å°ï¼Œé»˜è®¤ä¸º None
            self,
            sample_size: Optional[int] = None,
            # è¾“å…¥é€šé“æ•°é‡ï¼Œé»˜è®¤ä¸º 4
            in_channels: int = 4,
            # è¾“å‡ºé€šé“æ•°é‡ï¼Œé»˜è®¤ä¸º 4
            out_channels: int = 4,
            # ä¸‹é‡‡æ ·å—ç±»å‹çš„å…ƒç»„ï¼Œå®šä¹‰æ¨¡å‹çš„ä¸‹é‡‡æ ·ç»“æ„
            down_block_types: Tuple[str, ...] = (
                "CrossAttnDownBlock3D",
                "CrossAttnDownBlock3D",
                "CrossAttnDownBlock3D",
                "DownBlock3D",
            ),
            # ä¸Šé‡‡æ ·å—ç±»å‹çš„å…ƒç»„ï¼Œå®šä¹‰æ¨¡å‹çš„ä¸Šé‡‡æ ·ç»“æ„
            up_block_types: Tuple[str, ...] = (
                "UpBlock3D",
                "CrossAttnUpBlock3D",
                "CrossAttnUpBlock3D",
                "CrossAttnUpBlock3D",
            ),
            # æ¯ä¸ªå—çš„è¾“å‡ºé€šé“æ•°é‡ï¼Œå®šä¹‰æ¨¡å‹æ¯ä¸ªå±‚çš„é€šé“è®¾ç½®
            block_out_channels: Tuple[int, ...] = (320, 640, 1280, 1280),
            # æ¯ä¸ªå—çš„å±‚æ•°ï¼Œé»˜è®¤ä¸º 2
            layers_per_block: int = 2,
            # ä¸‹é‡‡æ ·æ—¶çš„å¡«å……å¤§å°ï¼Œé»˜è®¤ä¸º 1
            downsample_padding: int = 1,
            # ä¸­é—´å—çš„ç¼©æ”¾å› å­ï¼Œé»˜è®¤ä¸º 1
            mid_block_scale_factor: float = 1,
            # æ¿€æ´»å‡½æ•°ç±»å‹ï¼Œé»˜è®¤ä¸º "silu"
            act_fn: str = "silu",
            # å½’ä¸€åŒ–ç»„çš„æ•°é‡ï¼Œé»˜è®¤ä¸º 32
            norm_num_groups: Optional[int] = 32,
            # å½’ä¸€åŒ–çš„ epsilon å€¼ï¼Œé»˜è®¤ä¸º 1e-5
            norm_eps: float = 1e-5,
            # è·¨æ³¨æ„åŠ›ç»´åº¦ï¼Œé»˜è®¤ä¸º 1024
            cross_attention_dim: int = 1024,
            # æ³¨æ„åŠ›å¤´çš„ç»´åº¦ï¼Œå¯ä»¥æ˜¯å•ä¸€æ•´æ•°æˆ–æ•´æ•°å…ƒç»„ï¼Œé»˜è®¤ä¸º 64
            attention_head_dim: Union[int, Tuple[int]] = 64,
            # æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼Œå¯é€‰å‚æ•°
            num_attention_heads: Optional[Union[int, Tuple[int]]] = None,
            # æ—¶é—´æ¡ä»¶æŠ•å½±ç»´åº¦ï¼Œå¯é€‰å‚æ•°
            time_cond_proj_dim: Optional[int] = None,
        @property
        # ä» UNet2DConditionModel å¤åˆ¶çš„å±æ€§ï¼Œè·å–æ³¨æ„åŠ›å¤„ç†å™¨
        # è¿”å›æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨çš„å­—å…¸ï¼Œä»¥æƒé‡åç§°ä¸ºç´¢å¼•
        def attn_processors(self) -> Dict[str, AttentionProcessor]:
            r"""
            Returns:
                `dict` of attention processors: A dictionary containing all attention processors used in the model with
                indexed by its weight name.
            """
            # åˆå§‹åŒ–å¤„ç†å™¨å­—å…¸
            processors = {}
    
            # é€’å½’æ·»åŠ å¤„ç†å™¨çš„å‡½æ•°
            def fn_recursive_add_processors(name: str, module: torch.nn.Module, processors: Dict[str, AttentionProcessor]):
                # å¦‚æœæ¨¡å—æœ‰è·å–å¤„ç†å™¨çš„æ–¹æ³•ï¼Œæ·»åŠ åˆ°å¤„ç†å™¨å­—å…¸ä¸­
                if hasattr(module, "get_processor"):
                    processors[f"{name}.processor"] = module.get_processor()
    
                # éå†å­æ¨¡å—ï¼Œé€’å½’è°ƒç”¨è¯¥å‡½æ•°
                for sub_name, child in module.named_children():
                    fn_recursive_add_processors(f"{name}.{sub_name}", child, processors)
    
                # è¿”å›å¤„ç†å™¨å­—å…¸
                return processors
    
            # éå†å½“å‰ç±»çš„å­æ¨¡å—ï¼Œè°ƒç”¨é€’å½’æ·»åŠ å¤„ç†å™¨çš„å‡½æ•°
            for name, module in self.named_children():
                fn_recursive_add_processors(name, module, processors)
    
            # è¿”å›æ‰€æœ‰å¤„ç†å™¨
            return processors
    
        # ä» UNet2DConditionModel å¤åˆ¶çš„è®¾ç½®æ³¨æ„åŠ›åˆ‡ç‰‡çš„æ–¹æ³•
        # ä» UNet2DConditionModel å¤åˆ¶çš„è®¾ç½®æ³¨æ„åŠ›å¤„ç†å™¨çš„æ–¹æ³•
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ç”¨äºè®¾ç½®æ³¨æ„åŠ›å¤„ç†å™¨
    def set_attn_processor(self, processor: Union[AttentionProcessor, Dict[str, AttentionProcessor]]):
        r"""
        è®¾ç½®ç”¨äºè®¡ç®—æ³¨æ„åŠ›çš„å¤„ç†å™¨ã€‚
    
        å‚æ•°ï¼š
            processorï¼ˆ`dict` of `AttentionProcessor` æˆ–ä»… `AttentionProcessor`ï¼‰ï¼š
                å®ä¾‹åŒ–çš„å¤„ç†å™¨ç±»æˆ–ä¸€ä¸ªå¤„ç†å™¨ç±»çš„å­—å…¸ï¼Œå°†ä½œä¸ºæ‰€æœ‰ `Attention` å±‚çš„å¤„ç†å™¨ã€‚
    
                å¦‚æœ `processor` æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œé”®éœ€è¦å®šä¹‰ç›¸åº”çš„äº¤å‰æ³¨æ„åŠ›å¤„ç†å™¨çš„è·¯å¾„ã€‚
                åœ¨è®¾ç½®å¯è®­ç»ƒçš„æ³¨æ„åŠ›å¤„ç†å™¨æ—¶ï¼Œå¼ºçƒˆæ¨èè¿™æ ·åšã€‚
    
        """
        # è·å–å½“å‰æ³¨æ„åŠ›å¤„ç†å™¨çš„æ•°é‡
        count = len(self.attn_processors.keys())
    
        # å¦‚æœä¼ å…¥çš„å¤„ç†å™¨æ˜¯å­—å…¸ï¼Œä¸”æ•°é‡ä¸ç­‰äºæ³¨æ„åŠ›å±‚æ•°é‡ï¼ŒæŠ›å‡ºé”™è¯¯
        if isinstance(processor, dict) and len(processor) != count:
            raise ValueError(
                f"ä¼ å…¥äº†ä¸€ä¸ªå¤„ç†å™¨å­—å…¸ï¼Œä½†å¤„ç†å™¨çš„æ•°é‡ {len(processor)} ä¸"
                f" æ³¨æ„åŠ›å±‚çš„æ•°é‡ {count} ä¸åŒ¹é…ã€‚è¯·ç¡®ä¿ä¼ å…¥ {count} ä¸ªå¤„ç†å™¨ç±»ã€‚"
            )
    
        # å®šä¹‰ä¸€ä¸ªé€’å½’å‡½æ•°æ¥è®¾ç½®æ¯ä¸ªæ¨¡å—çš„å¤„ç†å™¨
        def fn_recursive_attn_processor(name: str, module: torch.nn.Module, processor):
            # å¦‚æœæ¨¡å—æœ‰è®¾ç½®å¤„ç†å™¨çš„æ–¹æ³•
            if hasattr(module, "set_processor"):
                # å¦‚æœå¤„ç†å™¨ä¸æ˜¯å­—å…¸ï¼Œç›´æ¥è®¾ç½®å¤„ç†å™¨
                if not isinstance(processor, dict):
                    module.set_processor(processor)
                else:
                    # ä»å­—å…¸ä¸­è·å–ç›¸åº”çš„å¤„ç†å™¨å¹¶è®¾ç½®
                    module.set_processor(processor.pop(f"{name}.processor"))
    
            # éå†å­æ¨¡å—å¹¶é€’å½’è°ƒç”¨å¤„ç†å™¨è®¾ç½®
            for sub_name, child in module.named_children():
                fn_recursive_attn_processor(f"{name}.{sub_name}", child, processor)
    
        # éå†å½“å‰å¯¹è±¡çš„æ‰€æœ‰å­æ¨¡å—ï¼Œå¹¶è°ƒç”¨é€’å½’è®¾ç½®å‡½æ•°
        for name, module in self.named_children():
            fn_recursive_attn_processor(name, module, processor)
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•æ¥å¯ç”¨å‰é¦ˆå±‚çš„åˆ†å—å¤„ç†
        def enable_forward_chunking(self, chunk_size: Optional[int] = None, dim: int = 0) -> None:
            """
            è®¾ç½®æ³¨æ„åŠ›å¤„ç†å™¨ä»¥ä½¿ç”¨ [å‰é¦ˆåˆ†å—](https://huggingface.co/blog/reformer#2-chunked-feed-forward-layers)ã€‚
    
            å‚æ•°ï¼š
                chunk_size (`int`, *å¯é€‰*):
                    å‰é¦ˆå±‚çš„åˆ†å—å¤§å°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†å¯¹ç»´åº¦ä¸º`dim`çš„æ¯ä¸ªå¼ é‡å•ç‹¬è¿è¡Œå‰é¦ˆå±‚ã€‚
                dim (`int`, *å¯é€‰*, é»˜è®¤ä¸º`0`):
                    åº”å¯¹å“ªä¸ªç»´åº¦è¿›è¡Œå‰é¦ˆè®¡ç®—çš„åˆ†å—ã€‚å¯ä»¥é€‰æ‹© dim=0ï¼ˆæ‰¹æ¬¡ï¼‰æˆ– dim=1ï¼ˆåºåˆ—é•¿åº¦ï¼‰ã€‚
            """
            # ç¡®ä¿ dim å‚æ•°ä¸º 0 æˆ– 1
            if dim not in [0, 1]:
                raise ValueError(f"Make sure to set `dim` to either 0 or 1, not {dim}")
    
            # é»˜è®¤çš„åˆ†å—å¤§å°ä¸º 1
            chunk_size = chunk_size or 1
    
            # å®šä¹‰ä¸€ä¸ªé€’å½’å‡½æ•°æ¥è®¾ç½®æ¯ä¸ªæ¨¡å—çš„åˆ†å—å‰é¦ˆå¤„ç†
            def fn_recursive_feed_forward(module: torch.nn.Module, chunk_size: int, dim: int):
                # å¦‚æœæ¨¡å—å…·æœ‰è®¾ç½®åˆ†å—å‰é¦ˆçš„å±æ€§ï¼Œåˆ™è®¾ç½®å®ƒ
                if hasattr(module, "set_chunk_feed_forward"):
                    module.set_chunk_feed_forward(chunk_size=chunk_size, dim=dim)
    
                # éå†å­æ¨¡å—ï¼Œé€’å½’è°ƒç”¨å‡½æ•°
                for child in module.children():
                    fn_recursive_feed_forward(child, chunk_size, dim)
    
            # éå†å½“å‰å®ä¾‹çš„å­æ¨¡å—ï¼Œåº”ç”¨é€’å½’å‡½æ•°
            for module in self.children():
                fn_recursive_feed_forward(module, chunk_size, dim)
    
        # å®šä¹‰ä¸€ä¸ªæ–¹æ³•æ¥ç¦ç”¨å‰é¦ˆå±‚çš„åˆ†å—å¤„ç†
        def disable_forward_chunking(self):
            # å®šä¹‰ä¸€ä¸ªé€’å½’å‡½æ•°æ¥ç¦ç”¨åˆ†å—å‰é¦ˆå¤„ç†
            def fn_recursive_feed_forward(module: torch.nn.Module, chunk_size: int, dim: int):
                # å¦‚æœæ¨¡å—å…·æœ‰è®¾ç½®åˆ†å—å‰é¦ˆçš„å±æ€§ï¼Œåˆ™è®¾ç½®ä¸º None
                if hasattr(module, "set_chunk_feed_forward"):
                    module.set_chunk_feed_forward(chunk_size=chunk_size, dim=dim)
    
                # éå†å­æ¨¡å—ï¼Œé€’å½’è°ƒç”¨å‡½æ•°
                for child in module.children():
                    fn_recursive_feed_forward(child, chunk_size, dim)
    
            # éå†å½“å‰å®ä¾‹çš„å­æ¨¡å—ï¼Œåº”ç”¨é€’å½’å‡½æ•°ï¼Œç¦ç”¨åˆ†å—
            for module in self.children():
                fn_recursive_feed_forward(module, None, 0)
    
        # ä» diffusers.models.unets.unet_2d_condition ä¸­å¤åˆ¶çš„æ–¹æ³•ï¼Œè®¾ç½®é»˜è®¤æ³¨æ„åŠ›å¤„ç†å™¨
        def set_default_attn_processor(self):
            """
            ç¦ç”¨è‡ªå®šä¹‰æ³¨æ„åŠ›å¤„ç†å™¨å¹¶è®¾ç½®é»˜è®¤æ³¨æ„åŠ›å®ç°ã€‚
            """
            # æ£€æŸ¥æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨æ˜¯å¦ä¸ºæ·»åŠ çš„ KV å¤„ç†å™¨
            if all(proc.__class__ in ADDED_KV_ATTENTION_PROCESSORS for proc in self.attn_processors.values()):
                processor = AttnAddedKVProcessor()  # è®¾ç½®ä¸ºæ·»åŠ çš„ KV å¤„ç†å™¨
            # æ£€æŸ¥æ‰€æœ‰æ³¨æ„åŠ›å¤„ç†å™¨æ˜¯å¦ä¸ºäº¤å‰æ³¨æ„åŠ›å¤„ç†å™¨
            elif all(proc.__class__ in CROSS_ATTENTION_PROCESSORS for proc in self.attn_processors.values()):
                processor = AttnProcessor()  # è®¾ç½®ä¸ºæ™®é€šæ³¨æ„åŠ›å¤„ç†å™¨
            else:
                # æŠ›å‡ºå¼‚å¸¸ï¼Œè‹¥æ³¨æ„åŠ›å¤„ç†å™¨ç±»å‹ä¸ç¬¦åˆé¢„æœŸ
                raise ValueError(
                    f"Cannot call `set_default_attn_processor` when attention processors are of type {next(iter(self.attn_processors.values()))}"
                )
    
            # è®¾ç½®é€‰å®šçš„æ³¨æ„åŠ›å¤„ç†å™¨
            self.set_attn_processor(processor)
    
        # å®šä¹‰ä¸€ä¸ªç§æœ‰æ–¹æ³•æ¥è®¾ç½®æ¨¡å—çš„æ¢¯åº¦æ£€æŸ¥ç‚¹
        def _set_gradient_checkpointing(self, module, value: bool = False) -> None:
            # æ£€æŸ¥æ¨¡å—æ˜¯å¦å±äºç‰¹å®šç±»å‹
            if isinstance(module, (CrossAttnDownBlock3D, DownBlock3D, CrossAttnUpBlock3D, UpBlock3D)):
                module.gradient_checkpointing = value  # è®¾ç½®æ¢¯åº¦æ£€æŸ¥ç‚¹å€¼
    
        # ä» diffusers.models.unets.unet_2d_condition ä¸­å¤åˆ¶çš„æ–¹æ³•ï¼Œå¯ç”¨è‡ªç”±åº¦
    # å¯ç”¨ FreeU æœºåˆ¶ï¼Œå‚æ•°ä¸ºä¸¤ä¸ªç¼©æ”¾å› å­å’Œä¸¤ä¸ªå¢å¼ºå› å­çš„å€¼
    def enable_freeu(self, s1, s2, b1, b2):
        r"""ä» https://arxiv.org/abs/2309.11497 å¯ç”¨ FreeU æœºåˆ¶ã€‚

        ç¼©æ”¾å› å­çš„åç¼€è¡¨ç¤ºå®ƒä»¬åº”ç”¨çš„é˜¶æ®µå—ã€‚

        è¯·å‚è€ƒ [å®˜æ–¹ä»“åº“](https://github.com/ChenyangSi/FreeU) ä»¥è·å–åœ¨ä¸åŒç®¡é“ï¼ˆå¦‚ Stable Diffusion v1ã€v2 å’Œ Stable Diffusion XLï¼‰ä¸­å·²çŸ¥æ•ˆæœè‰¯å¥½çš„å€¼ç»„åˆã€‚

        Args:
            s1 (`float`):
                ç¬¬1é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è·ƒç‰¹å¾çš„è´¡çŒ®ï¼Œä»¥å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡å¹³æ»‘æ•ˆåº”â€ã€‚
            s2 (`float`):
                ç¬¬2é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡å¼±è·³è·ƒç‰¹å¾çš„è´¡çŒ®ï¼Œä»¥å‡è½»å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„â€œè¿‡å¹³æ»‘æ•ˆåº”â€ã€‚
            b1 (`float`): ç¬¬1é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå¢å¼ºéª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚
            b2 (`float`): ç¬¬2é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå¢å¼ºéª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚
        """
        # éå†ä¸Šé‡‡æ ·å—ï¼Œç»™æ¯ä¸ªå—è®¾ç½®ç¼©æ”¾å› å­å’Œå¢å¼ºå› å­
        for i, upsample_block in enumerate(self.up_blocks):
            # è®¾ç½®ç¬¬1é˜¶æ®µçš„ç¼©æ”¾å› å­
            setattr(upsample_block, "s1", s1)
            # è®¾ç½®ç¬¬2é˜¶æ®µçš„ç¼©æ”¾å› å­
            setattr(upsample_block, "s2", s2)
            # è®¾ç½®ç¬¬1é˜¶æ®µçš„å¢å¼ºå› å­
            setattr(upsample_block, "b1", b1)
            # è®¾ç½®ç¬¬2é˜¶æ®µçš„å¢å¼ºå› å­
            setattr(upsample_block, "b2", b2)

    # ä» diffusers.models.unets.unet_2d_condition.UNet2DConditionModel.disable_freeu å¤åˆ¶
    # ç¦ç”¨ FreeU æœºåˆ¶
    def disable_freeu(self):
        """ç¦ç”¨ FreeU æœºåˆ¶ã€‚"""
        # å®šä¹‰ FreeU æœºåˆ¶çš„å…³é”®å±æ€§
        freeu_keys = {"s1", "s2", "b1", "b2"}
        # éå†ä¸Šé‡‡æ ·å—
        for i, upsample_block in enumerate(self.up_blocks):
            # éå† FreeU å…³é”®å±æ€§
            for k in freeu_keys:
                # å¦‚æœä¸Šé‡‡æ ·å—æœ‰è¯¥å±æ€§ï¼Œæˆ–è€…è¯¥å±æ€§å€¼ä¸ä¸º None
                if hasattr(upsample_block, k) or getattr(upsample_block, k, None) is not None:
                    # å°†å±æ€§å€¼è®¾ç½®ä¸º Noneï¼Œç¦ç”¨ FreeU
                    setattr(upsample_block, k, None)

    # ä» diffusers.models.unets.unet_2d_condition.UNet2DConditionModel.fuse_qkv_projections å¤åˆ¶
    # å¯ç”¨èåˆçš„ QKV æŠ•å½±
    def fuse_qkv_projections(self):
        """
        å¯ç”¨èåˆçš„ QKV æŠ•å½±ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œæ‰€æœ‰æŠ•å½±çŸ©é˜µï¼ˆå³æŸ¥è¯¢ã€é”®ã€å€¼ï¼‰éƒ½è¢«èåˆã€‚å¯¹äºäº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œé”®å’Œå€¼æŠ•å½±çŸ©é˜µè¢«èåˆã€‚

        <Tip warning={true}>

        æ­¤ API æ˜¯ ğŸ§ª å®éªŒæ€§çš„ã€‚

        </Tip>
        """
        # ä¿å­˜åŸå§‹çš„æ³¨æ„åŠ›å¤„ç†å™¨
        self.original_attn_processors = None

        # éå†æ³¨æ„åŠ›å¤„ç†å™¨
        for _, attn_processor in self.attn_processors.items():
            # å¦‚æœæ³¨æ„åŠ›å¤„ç†å™¨çš„ç±»åä¸­åŒ…å«â€œAddedâ€
            if "Added" in str(attn_processor.__class__.__name__):
                # æŠ›å‡ºé”™è¯¯ï¼Œè¡¨ç¤ºä¸æ”¯æŒå…·æœ‰é™„åŠ  KV æŠ•å½±çš„æ¨¡å‹
                raise ValueError("`fuse_qkv_projections()` is not supported for models having added KV projections.")

        # ä¿å­˜å½“å‰çš„æ³¨æ„åŠ›å¤„ç†å™¨
        self.original_attn_processors = self.attn_processors

        # éå†æ‰€æœ‰æ¨¡å—
        for module in self.modules():
            # å¦‚æœæ¨¡å—æ˜¯ Attention ç±»å‹
            if isinstance(module, Attention):
                # èåˆæŠ•å½±
                module.fuse_projections(fuse=True)

        # è®¾ç½®æ³¨æ„åŠ›å¤„ç†å™¨ä¸ºèåˆçš„æ³¨æ„åŠ›å¤„ç†å™¨
        self.set_attn_processor(FusedAttnProcessor2_0())

    # ä» diffusers.models.unets.unet_2d_condition.UNet2DConditionModel.unfuse_qkv_projections å¤åˆ¶
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºç¦ç”¨å·²å¯ç”¨çš„èåˆ QKV æŠ•å½±
    def unfuse_qkv_projections(self):
        """ç¦ç”¨å·²å¯ç”¨çš„èåˆ QKV æŠ•å½±ã€‚
    
        <Tip warning={true}>
    
        è¯¥ API æ˜¯ ğŸ§ª å®éªŒæ€§çš„ã€‚
    
        </Tip>
    
        """
        # å¦‚æœå­˜åœ¨åŸå§‹çš„æ³¨æ„åŠ›å¤„ç†å™¨ï¼Œåˆ™è®¾ç½®å½“å‰çš„æ³¨æ„åŠ›å¤„ç†å™¨ä¸ºåŸå§‹å¤„ç†å™¨
        if self.original_attn_processors is not None:
            self.set_attn_processor(self.original_attn_processors)
    
    # å®šä¹‰å‰å‘ä¼ æ’­æ–¹æ³•ï¼Œæ¥å—å¤šä¸ªå‚æ•°è¿›è¡Œè®¡ç®—
    def forward(
        self,
        sample: torch.Tensor,  # è¾“å…¥æ ·æœ¬ï¼Œå¼ é‡æ ¼å¼
        timestep: Union[torch.Tensor, float, int],  # å½“å‰æ—¶é—´æ­¥ï¼Œå¯ä»¥æ˜¯å¼ é‡ã€æµ®ç‚¹æ•°æˆ–æ•´æ•°
        encoder_hidden_states: torch.Tensor,  # ç¼–ç å™¨çš„éšè—çŠ¶æ€ï¼Œå¼ é‡æ ¼å¼
        class_labels: Optional[torch.Tensor] = None,  # ç±»åˆ«æ ‡ç­¾ï¼Œé»˜è®¤ä¸º None
        timestep_cond: Optional[torch.Tensor] = None,  # æ—¶é—´æ­¥æ¡ä»¶ï¼Œé»˜è®¤ä¸º None
        attention_mask: Optional[torch.Tensor] = None,  # æ³¨æ„åŠ›æ©ç ï¼Œé»˜è®¤ä¸º None
        cross_attention_kwargs: Optional[Dict[str, Any]] = None,  # è·¨æ³¨æ„åŠ›çš„å…³é”®å­—å‚æ•°ï¼Œé»˜è®¤ä¸º None
        down_block_additional_residuals: Optional[Tuple[torch.Tensor]] = None,  # é™çº§å—çš„é™„åŠ æ®‹å·®ï¼Œé»˜è®¤ä¸º None
        mid_block_additional_residual: Optional[torch.Tensor] = None,  # ä¸­é—´å—çš„é™„åŠ æ®‹å·®ï¼Œé»˜è®¤ä¸º None
        return_dict: bool = True,  # æ˜¯å¦è¿”å›å­—å…¸æ ¼å¼çš„ç»“æœï¼Œé»˜è®¤ä¸º True
```