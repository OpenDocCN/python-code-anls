# `.\diffusers\pipelines\pipeline_utils.py`

```py
# coding=utf-8  # æŒ‡å®šæ–‡ä»¶ç¼–ç ä¸º UTF-8
# Copyright 2024 The HuggingFace Inc. team.  # ç‰ˆæƒå£°æ˜ï¼Œè¡¨æ˜æ–‡ä»¶å½’ HuggingFace Inc. å›¢é˜Ÿæ‰€æœ‰
# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.  # ç‰ˆæƒå£°æ˜ï¼Œè¡¨æ˜æ–‡ä»¶å½’ NVIDIA CORPORATION æ‰€æœ‰
#
# Licensed under the Apache License, Version 2.0 (the "License");  # æŒ‡æ˜æ­¤æ–‡ä»¶çš„è®¸å¯è¯ä¸º Apache 2.0 ç‰ˆæœ¬
# you may not use this file except in compliance with the License.  # æŒ‡å‡ºå¿…é¡»éµå¾ªè®¸å¯è¯æ‰èƒ½ä½¿ç”¨æ­¤æ–‡ä»¶
# You may obtain a copy of the License at  # æä¾›è·å–è®¸å¯è¯çš„æ–¹å¼
#
#     http://www.apache.org/licenses/LICENSE-2.0  # æŒ‡å‘è®¸å¯è¯çš„ URL
#
# Unless required by applicable law or agreed to in writing, software  # æŒ‡å‡ºè½¯ä»¶åœ¨æ²¡æœ‰æ˜ç¡®åŒæ„æˆ–é€‚ç”¨æ³•å¾‹æ—¶æŒ‰â€œåŸæ ·â€æä¾›
# distributed under the License is distributed on an "AS IS" BASIS,  # å£°æ˜ä¸æä¾›ä»»ä½•å½¢å¼çš„ä¿è¯
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  # æ²¡æœ‰ä»»ä½•å½¢å¼çš„æ˜ç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿
# See the License for the specific language governing permissions and  # å»ºè®®æŸ¥çœ‹è®¸å¯è¯ä»¥è·å–æƒé™å’Œé™åˆ¶çš„å…·ä½“ä¿¡æ¯
# limitations under the License.  # æŒ‡å‡ºè®¸å¯è¯ä¸‹çš„é™åˆ¶
import fnmatch  # å¯¼å…¥ fnmatch æ¨¡å—ï¼Œç”¨äºæ–‡ä»¶ååŒ¹é…
import importlib  # å¯¼å…¥ importlib æ¨¡å—ï¼Œç”¨äºåŠ¨æ€å¯¼å…¥æ¨¡å—
import inspect  # å¯¼å…¥ inspect æ¨¡å—ï¼Œç”¨äºè·å–å¯¹è±¡çš„ä¿¡æ¯
import os  # å¯¼å…¥ os æ¨¡å—ï¼Œç”¨äºæ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½
import re  # å¯¼å…¥ re æ¨¡å—ï¼Œç”¨äºæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
import sys  # å¯¼å…¥ sys æ¨¡å—ï¼Œç”¨äºè®¿é—® Python è§£é‡Šå™¨çš„å˜é‡å’Œå‡½æ•°
from dataclasses import dataclass  # ä» dataclasses å¯¼å…¥ dataclass è£…é¥°å™¨ï¼Œç”¨äºç®€åŒ–ç±»çš„å®šä¹‰
from pathlib import Path  # ä» pathlib å¯¼å…¥ Path ç±»ï¼Œç”¨äºè·¯å¾„æ“ä½œ
from typing import Any, Callable, Dict, List, Optional, Union, get_args, get_origin  # å¯¼å…¥ç±»å‹æç¤ºç›¸å…³çš„å·¥å…·

import numpy as np  # å¯¼å…¥ NumPy åº“å¹¶ç®€å†™ä¸º npï¼Œç”¨äºæ•°å€¼è®¡ç®—
import PIL.Image  # å¯¼å…¥ PIL çš„ Image æ¨¡å—ï¼Œç”¨äºå›¾åƒå¤„ç†
import requests  # å¯¼å…¥ requests åº“ï¼Œç”¨äºå‘é€ HTTP è¯·æ±‚
import torch  # å¯¼å…¥ PyTorch åº“ï¼Œç”¨äºæ·±åº¦å­¦ä¹ 
from huggingface_hub import (  # ä» huggingface_hub å¯¼å…¥å¤šä¸ªåŠŸèƒ½
    ModelCard,  # å¯¼å…¥ ModelCard ç±»ï¼Œç”¨äºå¤„ç†æ¨¡å‹å¡
    create_repo,  # å¯¼å…¥ create_repo å‡½æ•°ï¼Œç”¨äºåˆ›å»ºæ¨¡å‹ä»“åº“
    hf_hub_download,  # å¯¼å…¥ hf_hub_download å‡½æ•°ï¼Œç”¨äºä» Hugging Face Hub ä¸‹è½½æ–‡ä»¶
    model_info,  # å¯¼å…¥ model_info å‡½æ•°ï¼Œç”¨äºè·å–æ¨¡å‹ä¿¡æ¯
    snapshot_download,  # å¯¼å…¥ snapshot_download å‡½æ•°ï¼Œç”¨äºä¸‹è½½å¿«ç…§
)
from huggingface_hub.utils import OfflineModeIsEnabled, validate_hf_hub_args  # å¯¼å…¥å¸®åŠ©å‡½æ•°ç”¨äºéªŒè¯å‚æ•°å’Œæ£€æŸ¥ç¦»çº¿æ¨¡å¼
from packaging import version  # ä» packaging å¯¼å…¥ version æ¨¡å—ï¼Œç”¨äºç‰ˆæœ¬æ¯”è¾ƒ
from requests.exceptions import HTTPError  # ä» requests.exceptions å¯¼å…¥ HTTPErrorï¼Œç”¨äºå¤„ç† HTTP é”™è¯¯
from tqdm.auto import tqdm  # ä» tqdm.auto å¯¼å…¥ tqdmï¼Œç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡

from .. import __version__  # ä»å½“å‰æ¨¡å—å¯¼å…¥ç‰ˆæœ¬å·
from ..configuration_utils import ConfigMixin  # ä»ä¸Šçº§æ¨¡å—å¯¼å…¥ ConfigMixin ç±»ï¼Œç”¨äºé…ç½®æ··å…¥
from ..models import AutoencoderKL  # ä»ä¸Šçº§æ¨¡å—å¯¼å…¥ AutoencoderKL æ¨¡å‹
from ..models.attention_processor import FusedAttnProcessor2_0  # ä»ä¸Šçº§æ¨¡å—å¯¼å…¥ FusedAttnProcessor2_0 ç±»
from ..models.modeling_utils import _LOW_CPU_MEM_USAGE_DEFAULT, ModelMixin  # ä»ä¸Šçº§æ¨¡å—å¯¼å…¥å¸¸é‡å’Œ ModelMixin ç±»
from ..schedulers.scheduling_utils import SCHEDULER_CONFIG_NAME  # ä»ä¸Šçº§æ¨¡å—å¯¼å…¥è°ƒåº¦å™¨é…ç½®åç§°
from ..utils import (  # ä»ä¸Šçº§æ¨¡å—å¯¼å…¥å¤šä¸ªå·¥å…·å‡½æ•°å’Œå¸¸é‡
    CONFIG_NAME,  # é…ç½®æ–‡ä»¶å
    DEPRECATED_REVISION_ARGS,  # å·²å¼ƒç”¨çš„ä¿®è®¢å‚æ•°
    BaseOutput,  # åŸºç¡€è¾“å‡ºç±»
    PushToHubMixin,  # æ¨é€åˆ° Hub çš„æ··å…¥ç±»
    deprecate,  # ç”¨äºæ ‡è®°å¼ƒç”¨çš„å‡½æ•°
    is_accelerate_available,  # æ£€æŸ¥ accelerate åº“æ˜¯å¦å¯ç”¨çš„å‡½æ•°
    is_accelerate_version,  # æ£€æŸ¥ accelerate ç‰ˆæœ¬çš„å‡½æ•°
    is_torch_npu_available,  # æ£€æŸ¥ PyTorch NPU æ˜¯å¦å¯ç”¨çš„å‡½æ•°
    is_torch_version,  # æ£€æŸ¥ PyTorch ç‰ˆæœ¬çš„å‡½æ•°
    logging,  # æ—¥å¿—è®°å½•æ¨¡å—
    numpy_to_pil,  # NumPy æ•°ç»„è½¬æ¢ä¸º PIL å›¾åƒçš„å‡½æ•°
)
from ..utils.hub_utils import load_or_create_model_card, populate_model_card  # ä»ä¸Šçº§æ¨¡å—å¯¼å…¥å¤„ç†æ¨¡å‹å¡çš„å‡½æ•°
from ..utils.torch_utils import is_compiled_module  # ä»ä¸Šçº§æ¨¡å—å¯¼å…¥æ£€æŸ¥æ¨¡å—æ˜¯å¦å·²ç¼–è¯‘çš„å‡½æ•°


if is_torch_npu_available():  # å¦‚æœ PyTorch NPU å¯ç”¨
    import torch_npu  # å¯¼å…¥ torch_npu æ¨¡å—ï¼Œæä¾›å¯¹ NPU çš„æ”¯æŒ # noqa: F401  # noqa: F401 è¡¨ç¤ºå¿½ç•¥æœªä½¿ç”¨çš„å¯¼å…¥è­¦å‘Š


from .pipeline_loading_utils import (  # ä»å½“å‰åŒ…å¯¼å…¥å¤šä¸ªåŠ è½½ç®¡é“ç›¸å…³çš„å·¥å…·
    ALL_IMPORTABLE_CLASSES,  # æ‰€æœ‰å¯å¯¼å…¥çš„ç±»
    CONNECTED_PIPES_KEYS,  # è¿æ¥ç®¡é“çš„é”®
    CUSTOM_PIPELINE_FILE_NAME,  # è‡ªå®šä¹‰ç®¡é“æ–‡ä»¶å
    LOADABLE_CLASSES,  # å¯åŠ è½½çš„ç±»
    _fetch_class_library_tuple,  # è·å–ç±»åº“å…ƒç»„çš„ç§æœ‰å‡½æ•°
    _get_custom_pipeline_class,  # è·å–è‡ªå®šä¹‰ç®¡é“ç±»çš„ç§æœ‰å‡½æ•°
    _get_final_device_map,  # è·å–æœ€ç»ˆè®¾å¤‡æ˜ å°„çš„ç§æœ‰å‡½æ•°
    _get_pipeline_class,  # è·å–ç®¡é“ç±»çš„ç§æœ‰å‡½æ•°
    _unwrap_model,  # è§£åŒ…æ¨¡å‹çš„ç§æœ‰å‡½æ•°
    is_safetensors_compatible,  # æ£€æŸ¥æ˜¯å¦å…¼å®¹ SafeTensors çš„å‡½æ•°
    load_sub_model,  # åŠ è½½å­æ¨¡å‹çš„å‡½æ•°
    maybe_raise_or_warn,  # å¯èƒ½æŠ›å‡ºè­¦å‘Šæˆ–é”™è¯¯çš„å‡½æ•°
    variant_compatible_siblings,  # æ£€æŸ¥å˜ä½“å…¼å®¹çš„å…„å¼Ÿç±»çš„å‡½æ•°
    warn_deprecated_model_variant,  # å‘å‡ºå…³äºæ¨¡å‹å˜ä½“å¼ƒç”¨çš„è­¦å‘Šçš„å‡½æ•°
)


if is_accelerate_available():  # å¦‚æœ accelerate åº“å¯ç”¨
    import accelerate  # å¯¼å…¥ accelerate åº“ï¼Œæä¾›åŠ é€ŸåŠŸèƒ½


LIBRARIES = []  # åˆå§‹åŒ–ç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨åº“
for library in LOADABLE_CLASSES:  # éå†å¯åŠ è½½çš„ç±»
    LIBRARIES.append(library)  # å°†æ¯ä¸ªåº“æ·»åŠ åˆ° LIBRARIES åˆ—è¡¨ä¸­

SUPPORTED_DEVICE_MAP = ["balanced"]  # å®šä¹‰æ”¯æŒçš„è®¾å¤‡æ˜ å°„ï¼Œä½¿ç”¨å¹³è¡¡ç­–ç•¥

logger = logging.get_logger(__name__)  # åˆ›å»ºä¸€ä¸ªä¸å½“å‰æ¨¡å—åŒåçš„æ—¥å¿—è®°å½•å™¨


@dataclass  # ä½¿ç”¨ dataclass è£…é¥°å™¨å®šä¹‰ä¸€ä¸ªæ•°æ®ç±»
class ImagePipelineOutput(BaseOutput):  # å®šä¹‰å›¾åƒç®¡é“è¾“å‡ºç±»ï¼Œç»§æ‰¿è‡ª BaseOutput
    """
    Output class for image pipelines.  # å›¾åƒç®¡é“çš„è¾“å‡ºç±»

    Args:  # å‚æ•°è¯´æ˜
        images (`List[PIL.Image.Image]` or `np.ndarray`)  # images å‚æ•°ï¼Œæ¥å— PIL å›¾åƒåˆ—è¡¨æˆ– NumPy æ•°ç»„
            List of denoised PIL images of length `batch_size` or NumPy array of shape `(batch_size, height, width,
            num_channels)`.  # è¯´æ˜è¯¥å‚æ•°å¯ä»¥æ˜¯å›¾åƒåˆ—è¡¨æˆ–å…·æœ‰ç‰¹å®šå½¢çŠ¶çš„ NumPy æ•°ç»„
    """
    # å®šä¹‰ä¸€ä¸ªå˜é‡ imagesï¼Œå®ƒå¯ä»¥æ˜¯ä¸€ä¸ª PIL å›¾åƒå¯¹è±¡åˆ—è¡¨æˆ–ä¸€ä¸ª NumPy æ•°ç»„
    images: Union[List[PIL.Image.Image], np.ndarray]
# å®šä¹‰éŸ³é¢‘ç®¡é“è¾“å‡ºçš„æ•°æ®ç±»ï¼Œç»§æ‰¿è‡ª BaseOutput
@dataclass
class AudioPipelineOutput(BaseOutput):
    """
    éŸ³é¢‘ç®¡é“çš„è¾“å‡ºç±»ã€‚

    å‚æ•°:
        audios (`np.ndarray`)
            ä¸€ä¸ªå½¢çŠ¶ä¸º `(batch_size, num_channels, sample_rate)` çš„ NumPy æ•°ç»„ï¼Œè¡¨ç¤ºå»å™ªåçš„éŸ³é¢‘æ ·æœ¬åˆ—è¡¨ã€‚
    """

    # å­˜å‚¨éŸ³é¢‘æ ·æœ¬çš„ NumPy æ•°ç»„
    audios: np.ndarray


# å®šä¹‰æ‰©æ•£ç®¡é“çš„åŸºç±»ï¼Œç»§æ‰¿è‡ª ConfigMixin å’Œ PushToHubMixin
class DiffusionPipeline(ConfigMixin, PushToHubMixin):
    r"""
    æ‰€æœ‰ç®¡é“çš„åŸºç±»ã€‚

    [`DiffusionPipeline`] å­˜å‚¨æ‰€æœ‰æ‰©æ•£ç®¡é“çš„ç»„ä»¶ï¼ˆæ¨¡å‹ã€è°ƒåº¦å™¨å’Œå¤„ç†å™¨ï¼‰ï¼Œå¹¶æä¾›åŠ è½½ã€ä¸‹è½½å’Œä¿å­˜æ¨¡å‹çš„æ–¹æ³•ã€‚å®ƒè¿˜åŒ…å«ä»¥ä¸‹æ–¹æ³•ï¼š

        - å°†æ‰€æœ‰ PyTorch æ¨¡å—ç§»åŠ¨åˆ°æ‚¨é€‰æ‹©çš„è®¾å¤‡
        - å¯ç”¨/ç¦ç”¨å»å™ªè¿­ä»£çš„è¿›åº¦æ¡

    ç±»å±æ€§ï¼š

        - **config_name** (`str`) -- å­˜å‚¨æ‰©æ•£ç®¡é“æ‰€æœ‰ç»„ä»¶ç±»å’Œæ¨¡å—åç§°çš„é…ç½®æ–‡ä»¶åã€‚
        - **_optional_components** (`List[str]`) -- æ‰€æœ‰å¯é€‰ç»„ä»¶çš„åˆ—è¡¨ï¼Œè¿™äº›ç»„ä»¶åœ¨ç®¡é“åŠŸèƒ½ä¸Šå¹¶ä¸æ˜¯å¿…éœ€çš„ï¼ˆåº”ç”±å­ç±»é‡å†™ï¼‰ã€‚
    """

    # é…ç½®æ–‡ä»¶åç§°ï¼Œé»˜è®¤å€¼ä¸º "model_index.json"
    config_name = "model_index.json"
    # æ¨¡å‹ CPU å¸è½½åºåˆ—ï¼Œåˆå§‹å€¼ä¸º None
    model_cpu_offload_seq = None
    # Hugging Face è®¾å¤‡æ˜ å°„ï¼Œåˆå§‹å€¼ä¸º None
    hf_device_map = None
    # å¯é€‰ç»„ä»¶åˆ—è¡¨ï¼Œåˆå§‹åŒ–ä¸ºç©º
    _optional_components = []
    # ä¸å‚ä¸ CPU å¸è½½çš„ç»„ä»¶åˆ—è¡¨ï¼Œåˆå§‹åŒ–ä¸ºç©º
    _exclude_from_cpu_offload = []
    # æ˜¯å¦åŠ è½½è¿æ¥çš„ç®¡é“ï¼Œåˆå§‹åŒ–ä¸º False
    _load_connected_pipes = False
    # æ˜¯å¦ä¸º ONNX æ ¼å¼ï¼Œåˆå§‹åŒ–ä¸º False
    _is_onnx = False

    # æ³¨å†Œæ¨¡å—çš„æ–¹æ³•ï¼Œæ¥æ”¶ä»»æ„å…³é”®å­—å‚æ•°
    def register_modules(self, **kwargs):
        # éå†å…³é”®å­—å‚æ•°ä¸­çš„æ¨¡å—
        for name, module in kwargs.items():
            # æ£€ç´¢åº“
            if module is None or isinstance(module, (tuple, list)) and module[0] is None:
                # å¦‚æœæ¨¡å—ä¸º Noneï¼Œæ³¨å†Œå­—å…¸è®¾ç½®ä¸º None
                register_dict = {name: (None, None)}
            else:
                # è·å–åº“å’Œç±»åçš„å…ƒç»„
                library, class_name = _fetch_class_library_tuple(module)
                # æ³¨å†Œå­—å…¸è®¾ç½®ä¸ºåº“å’Œç±»åå…ƒç»„
                register_dict = {name: (library, class_name)}

            # ä¿å­˜æ¨¡å‹ç´¢å¼•é…ç½®
            self.register_to_config(**register_dict)

            # è®¾ç½®æ¨¡å‹
            setattr(self, name, module)

    # è‡ªå®šä¹‰å±æ€§è®¾ç½®æ–¹æ³•
    def __setattr__(self, name: str, value: Any):
        # æ£€æŸ¥å±æ€§æ˜¯å¦åœ¨å®ä¾‹å­—å…¸ä¸­ä¸”åœ¨é…ç½®ä¸­å­˜åœ¨
        if name in self.__dict__ and hasattr(self.config, name):
            # å¦‚æœåç§°åœ¨é…ç½®ä¸­å­˜åœ¨ï¼Œåˆ™éœ€è¦è¦†ç›–é…ç½®
            if isinstance(getattr(self.config, name), (tuple, list)):
                # å¦‚æœå€¼ä¸ä¸º None ä¸”é…ç½®ä¸­å­˜åœ¨æœ‰æ•ˆå€¼
                if value is not None and self.config[name][0] is not None:
                    # è·å–ç±»åº“å…ƒç»„
                    class_library_tuple = _fetch_class_library_tuple(value)
                else:
                    # å¦åˆ™è®¾ç½®ä¸º None
                    class_library_tuple = (None, None)

                # æ³¨å†Œåˆ°é…ç½®ä¸­
                self.register_to_config(**{name: class_library_tuple})
            else:
                # ç›´æ¥æ³¨å†Œåˆ°é…ç½®ä¸­
                self.register_to_config(**{name: value})

        # è°ƒç”¨çˆ¶ç±»çš„è®¾ç½®å±æ€§æ–¹æ³•
        super().__setattr__(name, value)

    # ä¿å­˜é¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•
    def save_pretrained(
        self,
        save_directory: Union[str, os.PathLike],
        safe_serialization: bool = True,
        variant: Optional[str] = None,
        push_to_hub: bool = False,
        **kwargs,
    @property
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œè¿”å›å½“å‰ä½¿ç”¨çš„è®¾å¤‡ç±»å‹
    def device(self) -> torch.device:
        r"""
        Returns:
            `torch.device`: The torch device on which the pipeline is located.
        """
        # è·å–å½“å‰å®ä¾‹çš„æ¨¡å—åå’Œå…¶ä»–ç›¸å…³ä¿¡æ¯
        module_names, _ = self._get_signature_keys(self)
        # æ ¹æ®æ¨¡å—åè·å–å®ä¾‹ä¸­å¯¹åº”çš„æ¨¡å—å¯¹è±¡ï¼Œè‹¥ä¸å­˜åœ¨åˆ™ä¸º None
        modules = [getattr(self, n, None) for n in module_names]
        # è¿‡æ»¤å‡ºç±»å‹ä¸º torch.nn.Module çš„æ¨¡å—
        modules = [m for m in modules if isinstance(m, torch.nn.Module)]

        # éå†æ‰€æœ‰æ¨¡å—
        for module in modules:
            # è¿”å›ç¬¬ä¸€ä¸ªæ¨¡å—çš„è®¾å¤‡ç±»å‹
            return module.device

        # å¦‚æœæ²¡æœ‰æ¨¡å—ï¼Œé»˜è®¤è¿”å› CPU è®¾å¤‡
        return torch.device("cpu")

    # å®šä¹‰ä¸€ä¸ªåªè¯»å±æ€§ï¼Œè¿”å›å½“å‰ä½¿ç”¨çš„æ•°æ®ç±»å‹
    @property
    def dtype(self) -> torch.dtype:
        r"""
        Returns:
            `torch.dtype`: The torch dtype on which the pipeline is located.
        """
        # è·å–å½“å‰å®ä¾‹çš„æ¨¡å—åå’Œå…¶ä»–ç›¸å…³ä¿¡æ¯
        module_names, _ = self._get_signature_keys(self)
        # æ ¹æ®æ¨¡å—åè·å–å®ä¾‹ä¸­å¯¹åº”çš„æ¨¡å—å¯¹è±¡ï¼Œè‹¥ä¸å­˜åœ¨åˆ™ä¸º None
        modules = [getattr(self, n, None) for n in module_names]
        # è¿‡æ»¤å‡ºç±»å‹ä¸º torch.nn.Module çš„æ¨¡å—
        modules = [m for m in modules if isinstance(m, torch.nn.Module)]

        # éå†æ‰€æœ‰æ¨¡å—
        for module in modules:
            # è¿”å›ç¬¬ä¸€ä¸ªæ¨¡å—çš„æ•°æ®ç±»å‹
            return module.dtype

        # å¦‚æœæ²¡æœ‰æ¨¡å—ï¼Œé»˜è®¤è¿”å› float32 æ•°æ®ç±»å‹
        return torch.float32

    # å®šä¹‰ä¸€ä¸ªç±»æ–¹æ³•ï¼Œè¿”å›æ¨¡å‹çš„åç§°æˆ–è·¯å¾„
    @classmethod
    @validate_hf_hub_args
    @property
    def name_or_path(self) -> str:
        # ä»é…ç½®ä¸­è·å–åç§°æˆ–è·¯å¾„ï¼Œè‹¥ä¸å­˜åœ¨åˆ™ä¸º None
        return getattr(self.config, "_name_or_path", None)

    # å®šä¹‰ä¸€ä¸ªåªè¯»å±æ€§ï¼Œè¿”å›æ‰§è¡Œè®¾å¤‡
    @property
    def _execution_device(self):
        r"""
        Returns the device on which the pipeline's models will be executed. After calling
        [`~DiffusionPipeline.enable_sequential_cpu_offload`] the execution device can only be inferred from
        Accelerate's module hooks.
        """
        # éå†ç»„ä»¶å­—å…¸ä¸­çš„æ¯ä¸ªæ¨¡å‹
        for name, model in self.components.items():
            # å¦‚æœä¸æ˜¯ nn.Module æˆ–è€…åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼Œåˆ™è·³è¿‡
            if not isinstance(model, torch.nn.Module) or name in self._exclude_from_cpu_offload:
                continue

            # å¦‚æœæ¨¡å‹æ²¡æœ‰ HF hookï¼Œè¿”å›å½“å‰è®¾å¤‡
            if not hasattr(model, "_hf_hook"):
                return self.device
            # éå†æ¨¡å‹ä¸­çš„æ‰€æœ‰æ¨¡å—
            for module in model.modules():
                # æ£€æŸ¥æ¨¡å—æ˜¯å¦æœ‰æ‰§è¡Œè®¾å¤‡ä¿¡æ¯
                if (
                    hasattr(module, "_hf_hook")
                    and hasattr(module._hf_hook, "execution_device")
                    and module._hf_hook.execution_device is not None
                ):
                    # è¿”å›æ‰¾åˆ°çš„æ‰§è¡Œè®¾å¤‡
                    return torch.device(module._hf_hook.execution_device)
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›å½“å‰è®¾å¤‡
        return self.device

    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºç§»é™¤æ‰€æœ‰æ³¨å†Œçš„ hook
    def remove_all_hooks(self):
        r"""
        Removes all hooks that were added when using `enable_sequential_cpu_offload` or `enable_model_cpu_offload`.
        """
        # éå†ç»„ä»¶å­—å…¸ä¸­çš„æ¯ä¸ªæ¨¡å‹
        for _, model in self.components.items():
            # å¦‚æœæ˜¯ nn.Module ä¸”æœ‰ HF hookï¼Œåˆ™ç§»é™¤ hook
            if isinstance(model, torch.nn.Module) and hasattr(model, "_hf_hook"):
                accelerate.hooks.remove_hook_from_module(model, recurse=True)
        # æ¸…ç©ºæ‰€æœ‰ hooks åˆ—è¡¨
        self._all_hooks = []
    # å®šä¹‰ä¸€ä¸ªå¯èƒ½é‡Šæ”¾æ¨¡å‹é’©å­çš„å‡½æ•°
        def maybe_free_model_hooks(self):
            r"""
            è¯¥å‡½æ•°å¸è½½æ‰€æœ‰ç»„ä»¶ï¼Œç§»é™¤é€šè¿‡ `enable_model_cpu_offload` æ·»åŠ çš„æ¨¡å‹é’©å­ï¼Œç„¶åå†æ¬¡åº”ç”¨å®ƒä»¬ã€‚
            å¦‚æœæ¨¡å‹æœªè¢«å¸è½½ï¼Œè¯¥å‡½æ•°æ— æ“ä½œã€‚ç¡®ä¿å°†æ­¤å‡½æ•°æ·»åŠ åˆ°ç®¡é“çš„ `__call__` å‡½æ•°æœ«å°¾ï¼Œä»¥ä¾¿åœ¨åº”ç”¨ enable_model_cpu_offload æ—¶æ­£ç¡®å·¥ä½œã€‚
            """
            # æ£€æŸ¥æ˜¯å¦æ²¡æœ‰é’©å­è¢«æ·»åŠ ï¼Œå¦‚æœæ²¡æœ‰ï¼Œä»€ä¹ˆéƒ½ä¸åš
            if not hasattr(self, "_all_hooks") or len(self._all_hooks) == 0:
                # `enable_model_cpu_offload` å°šæœªè¢«è°ƒç”¨ï¼Œå› æ­¤é™é»˜è¿”å›
                return
    
            # ç¡®ä¿æ¨¡å‹çš„çŠ¶æ€ä¸è°ƒç”¨ä¹‹å‰ä¸€è‡´
            self.enable_model_cpu_offload(device=getattr(self, "_offload_device", "cuda"))
    
    # å®šä¹‰ä¸€ä¸ªé‡ç½®è®¾å¤‡æ˜ å°„çš„å‡½æ•°
        def reset_device_map(self):
            r"""
            å°†è®¾å¤‡æ˜ å°„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰é‡ç½®ä¸º Noneã€‚
            """
            # å¦‚æœè®¾å¤‡æ˜ å°„å·²ç»æ˜¯ Noneï¼Œä»€ä¹ˆéƒ½ä¸åš
            if self.hf_device_map is None:
                return
            else:
                # ç§»é™¤æ‰€æœ‰é’©å­
                self.remove_all_hooks()
                # éå†ç»„ä»¶ï¼Œå°†æ¯ä¸ª torch.nn.Module ç§»åŠ¨åˆ° CPU
                for name, component in self.components.items():
                    if isinstance(component, torch.nn.Module):
                        component.to("cpu")
                # å°†è®¾å¤‡æ˜ å°„è®¾ç½®ä¸º None
                self.hf_device_map = None
    
    # å®šä¹‰ä¸€ä¸ªç±»æ–¹æ³•ä»¥è·å–ç­¾åé”®
        @classmethod
        @validate_hf_hub_args
        @classmethod
        def _get_signature_keys(cls, obj):
            # è·å–å¯¹è±¡åˆå§‹åŒ–æ–¹æ³•çš„å‚æ•°
            parameters = inspect.signature(obj.__init__).parameters
            # è·å–æ‰€éœ€å‚æ•°ï¼ˆæ²¡æœ‰é»˜è®¤å€¼çš„ï¼‰
            required_parameters = {k: v for k, v in parameters.items() if v.default == inspect._empty}
            # è·å–å¯é€‰å‚æ•°ï¼ˆæœ‰é»˜è®¤å€¼çš„ï¼‰
            optional_parameters = set({k for k, v in parameters.items() if v.default != inspect._empty})
            # é¢„æœŸæ¨¡å—ä¸ºæ‰€éœ€å‚æ•°çš„é”®é›†ï¼Œæ’é™¤ "self"
            expected_modules = set(required_parameters.keys()) - {"self"}
    
            # å°†å¯é€‰å‚æ•°åè½¬æ¢ä¸ºåˆ—è¡¨
            optional_names = list(optional_parameters)
            # éå†å¯é€‰å‚æ•°ï¼Œå¦‚æœåœ¨å¯é€‰ç»„ä»¶ä¸­ï¼Œåˆ™æ·»åŠ åˆ°é¢„æœŸæ¨¡å—å¹¶ä»å¯é€‰å‚æ•°ä¸­ç§»é™¤
            for name in optional_names:
                if name in cls._optional_components:
                    expected_modules.add(name)
                    optional_parameters.remove(name)
    
            # è¿”å›é¢„æœŸæ¨¡å—å’Œå¯é€‰å‚æ•°
            return expected_modules, optional_parameters
    
    # å®šä¹‰ä¸€ä¸ªç±»æ–¹æ³•ä»¥è·å–ç­¾åç±»å‹
        @classmethod
        def _get_signature_types(cls):
            # åˆå§‹åŒ–ä¸€ä¸ªå­—å…¸ä»¥å­˜å‚¨ç­¾åç±»å‹
            signature_types = {}
            # éå†åˆå§‹åŒ–æ–¹æ³•çš„å‚æ•°ï¼Œè·å–æ¯ä¸ªå‚æ•°çš„æ³¨è§£
            for k, v in inspect.signature(cls.__init__).parameters.items():
                # å¦‚æœå‚æ•°æ³¨è§£æ˜¯ç±»ï¼Œå­˜å‚¨è¯¥æ³¨è§£
                if inspect.isclass(v.annotation):
                    signature_types[k] = (v.annotation,)
                # å¦‚æœå‚æ•°æ³¨è§£æ˜¯è”åˆç±»å‹ï¼Œè·å–æ‰€æœ‰ç±»å‹
                elif get_origin(v.annotation) == Union:
                    signature_types[k] = get_args(v.annotation)
                # å¦‚æœæ— æ³•è·å–ç±»å‹æ³¨è§£ï¼Œè®°å½•è­¦å‘Š
                else:
                    logger.warning(f"cannot get type annotation for Parameter {k} of {cls}.")
            # è¿”å›ç­¾åç±»å‹å­—å…¸
            return signature_types
    
    # å®šä¹‰ä¸€ä¸ªå±æ€§
        @property
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œè¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«åˆå§‹åŒ–ç®¡é“æ‰€éœ€çš„æ‰€æœ‰æ¨¡å—
    def components(self) -> Dict[str, Any]:
        r"""  # æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæè¿°æ–¹æ³•çš„åŠŸèƒ½å’Œè¿”å›å€¼
        The `self.components` property can be useful to run different pipelines with the same weights and
        configurations without reallocating additional memory.

        Returns (`dict`):
            A dictionary containing all the modules needed to initialize the pipeline.

        Examples:

        ```py
        >>> from diffusers import (
        ...     StableDiffusionPipeline,
        ...     StableDiffusionImg2ImgPipeline,
        ...     StableDiffusionInpaintPipeline,
        ... )

        >>> text2img = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
        >>> img2img = StableDiffusionImg2ImgPipeline(**text2img.components)
        >>> inpaint = StableDiffusionInpaintPipeline(**text2img.components)
        ```py
        """
        # è·å–é¢„æœŸæ¨¡å—å’Œå¯é€‰å‚æ•°çš„ç­¾å
        expected_modules, optional_parameters = self._get_signature_keys(self)
        # æ„å»ºä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„ç»„ä»¶
        components = {
            k: getattr(self, k) for k in self.config.keys() if not k.startswith("_") and k not in optional_parameters
        }

        # æ£€æŸ¥ç»„ä»¶çš„é”®æ˜¯å¦ä¸é¢„æœŸæ¨¡å—åŒ¹é…
        if set(components.keys()) != expected_modules:
            # å¦‚æœä¸åŒ¹é…ï¼ŒæŠ›å‡ºé”™è¯¯ï¼Œè¯´æ˜åˆå§‹åŒ–æœ‰è¯¯
            raise ValueError(
                f"{self} has been incorrectly initialized or {self.__class__} is incorrectly implemented. Expected"
                f" {expected_modules} to be defined, but {components.keys()} are defined."
            )

        # è¿”å›æ„å»ºçš„ç»„ä»¶å­—å…¸
        return components

    # å®šä¹‰ä¸€ä¸ªé™æ€æ–¹æ³•ï¼Œå°† NumPy å›¾åƒæˆ–å›¾åƒæ‰¹æ¬¡è½¬æ¢ä¸º PIL å›¾åƒ
    @staticmethod
    def numpy_to_pil(images):
        """
        Convert a NumPy image or a batch of images to a PIL image.
        """
        # è°ƒç”¨å¤–éƒ¨å‡½æ•°è¿›è¡Œè½¬æ¢
        return numpy_to_pil(images)

    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºåˆ›å»ºè¿›åº¦æ¡
    def progress_bar(self, iterable=None, total=None):
        # æ£€æŸ¥æ˜¯å¦å·²å®šä¹‰è¿›åº¦æ¡é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆå§‹åŒ–ä¸ºç©ºå­—å…¸
        if not hasattr(self, "_progress_bar_config"):
            self._progress_bar_config = {}
        # å¦‚æœå·²ç»å®šä¹‰ï¼Œåˆ™æ£€æŸ¥å…¶ç±»å‹æ˜¯å¦ä¸ºå­—å…¸
        elif not isinstance(self._progress_bar_config, dict):
            # å¦‚æœç±»å‹ä¸åŒ¹é…ï¼ŒæŠ›å‡ºé”™è¯¯
            raise ValueError(
                f"`self._progress_bar_config` should be of type `dict`, but is {type(self._progress_bar_config)}."
            )

        # å¦‚æœæä¾›äº†å¯è¿­ä»£å¯¹è±¡ï¼Œåˆ™è¿”å›ä¸€ä¸ªå¸¦è¿›åº¦æ¡çš„å¯è¿­ä»£å¯¹è±¡
        if iterable is not None:
            return tqdm(iterable, **self._progress_bar_config)
        # å¦‚æœæä¾›äº†æ€»æ•°ï¼Œåˆ™è¿”å›ä¸€ä¸ªæ€»æ•°ä¸º total çš„è¿›åº¦æ¡
        elif total is not None:
            return tqdm(total=total, **self._progress_bar_config)
        # å¦‚æœä¸¤ä¸ªéƒ½æ²¡æœ‰æä¾›ï¼ŒæŠ›å‡ºé”™è¯¯
        else:
            raise ValueError("Either `total` or `iterable` has to be defined.")

    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºè®¾ç½®è¿›åº¦æ¡çš„é…ç½®
    def set_progress_bar_config(self, **kwargs):
        # å°†ä¼ å…¥çš„å‚æ•°å­˜å‚¨åˆ°è¿›åº¦æ¡é…ç½®ä¸­
        self._progress_bar_config = kwargs
    # å®šä¹‰ä¸€ä¸ªå¯ç”¨ xFormers å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›çš„æ–¹æ³•ï¼Œæ”¯æŒå¯é€‰çš„æ³¨æ„åŠ›æ“ä½œ
    def enable_xformers_memory_efficient_attention(self, attention_op: Optional[Callable] = None):
            r"""
            å¯ç”¨æ¥è‡ª [xFormers](https://facebookresearch.github.io/xformers/) çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚å¯ç”¨æ­¤é€‰é¡¹åï¼Œ
            ä½ åº”è¯¥ä¼šè§‚å¯Ÿåˆ°è¾ƒä½çš„ GPU å†…å­˜ä½¿ç”¨ç‡ï¼Œå¹¶åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯èƒ½åŠ é€Ÿã€‚è®­ç»ƒæœŸé—´çš„åŠ é€Ÿä¸ä¿è¯ã€‚
    
            <Tip warning={true}>
    
            âš ï¸ å½“åŒæ—¶å¯ç”¨å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›å’Œåˆ‡ç‰‡æ³¨æ„åŠ›æ—¶ï¼Œå†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ä¼˜å…ˆã€‚
    
            </Tip>
    
            å‚æ•°:
                attention_op (`Callable`, *å¯é€‰*):
                    ç”¨äºè¦†ç›–é»˜è®¤çš„ `None` æ“ä½œç¬¦ï¼Œä»¥ç”¨ä½œ xFormers çš„
                    [`memory_efficient_attention()`](https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.memory_efficient_attention)
                    å‡½æ•°çš„ `op` å‚æ•°ã€‚
    
            ç¤ºä¾‹:
    
            ```py
            >>> import torch
            >>> from diffusers import DiffusionPipeline
            >>> from xformers.ops import MemoryEfficientAttentionFlashAttentionOp
    
            >>> pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2-1", torch_dtype=torch.float16)
            >>> pipe = pipe.to("cuda")
            >>> pipe.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)
            >>> # é’ˆå¯¹ Flash Attention ä½¿ç”¨ VAE æ—¶ä¸æ¥å—æ³¨æ„åŠ›å½¢çŠ¶çš„è§£å†³æ–¹æ³•
            >>> pipe.vae.enable_xformers_memory_efficient_attention(attention_op=None)
            ```py
            """
            # è°ƒç”¨è®¾ç½®å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›çš„å‡½æ•°ï¼Œå¹¶å°†æ ‡å¿—è®¾ä¸º True å’Œä¼ å…¥çš„æ³¨æ„åŠ›æ“ä½œ
            self.set_use_memory_efficient_attention_xformers(True, attention_op)
    
    # å®šä¹‰ä¸€ä¸ªç¦ç”¨ xFormers å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›çš„æ–¹æ³•
    def disable_xformers_memory_efficient_attention(self):
            r"""
            ç¦ç”¨æ¥è‡ª [xFormers](https://facebookresearch.github.io/xformers/) çš„å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›ã€‚
            """
            # è°ƒç”¨è®¾ç½®å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›çš„å‡½æ•°ï¼Œå¹¶å°†æ ‡å¿—è®¾ä¸º False
            self.set_use_memory_efficient_attention_xformers(False)
    
    # å®šä¹‰ä¸€ä¸ªè®¾ç½®å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›çš„å‡½æ•°ï¼Œæ¥å—æœ‰æ•ˆæ ‡å¿—å’Œå¯é€‰æ³¨æ„åŠ›æ“ä½œ
    def set_use_memory_efficient_attention_xformers(
            self, valid: bool, attention_op: Optional[Callable] = None
        ) -> None:
            # é€’å½’éå†æ‰€æœ‰å­æ¨¡å—
            # ä»»ä½•æš´éœ² set_use_memory_efficient_attention_xformers æ–¹æ³•çš„å­æ¨¡å—å°†æ¥æ”¶æ­¤æ¶ˆæ¯
            def fn_recursive_set_mem_eff(module: torch.nn.Module):
                # æ£€æŸ¥æ¨¡å—æ˜¯å¦æœ‰è®¾ç½®å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›çš„æ–¹æ³•ï¼Œå¦‚æœæœ‰åˆ™è°ƒç”¨
                if hasattr(module, "set_use_memory_efficient_attention_xformers"):
                    module.set_use_memory_efficient_attention_xformers(valid, attention_op)
    
                # é€’å½’å¤„ç†æ‰€æœ‰å­æ¨¡å—
                for child in module.children():
                    fn_recursive_set_mem_eff(child)
    
            # è·å–å½“å‰å¯¹è±¡çš„æ¨¡å—åç§°åŠå…¶ç­¾å
            module_names, _ = self._get_signature_keys(self)
            # è·å–æ‰€æœ‰å­æ¨¡å—ï¼Œè¿‡æ»¤å‡º torch.nn.Module ç±»å‹çš„æ¨¡å—
            modules = [getattr(self, n, None) for n in module_names]
            modules = [m for m in modules if isinstance(m, torch.nn.Module)]
    
            # å¯¹æ¯ä¸ªæ¨¡å—è°ƒç”¨é€’å½’è®¾ç½®å‡½æ•°
            for module in modules:
                fn_recursive_set_mem_eff(module)
    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•æ¥å¯ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ï¼Œé»˜è®¤ä¸ºâ€œautoâ€
        def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = "auto"):
            r"""
            å¯ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼Œæ³¨æ„åŠ›æ¨¡å—å°†è¾“å…¥å¼ é‡åˆ†æˆå¤šä¸ªåˆ‡ç‰‡
            ä»¥åˆ†æ­¥éª¤è®¡ç®—æ³¨æ„åŠ›ã€‚å¯¹äºå¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œè®¡ç®—å°†åœ¨æ¯ä¸ªå¤´ä¸Šé¡ºåºæ‰§è¡Œã€‚
            è¿™æœ‰åŠ©äºèŠ‚çœä¸€äº›å†…å­˜ï¼Œæ¢å–ç•¥å¾®é™ä½çš„é€Ÿåº¦ã€‚
    
            <Tip warning={true}>
    
            âš ï¸ å¦‚æœæ‚¨å·²ç»åœ¨ä½¿ç”¨æ¥è‡ª PyTorch 2.0 çš„ `scaled_dot_product_attention` (SDPA) æˆ– xFormersï¼Œ
            è¯·å‹¿å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ã€‚è¿™äº›æ³¨æ„åŠ›è®¡ç®—å·²ç»éå¸¸èŠ‚çœå†…å­˜ï¼Œå› æ­¤æ‚¨ä¸éœ€è¦å¯ç”¨
            æ­¤åŠŸèƒ½ã€‚å¦‚æœåœ¨ SDPA æˆ– xFormers ä¸­å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸¥é‡çš„æ€§èƒ½ä¸‹é™ï¼
    
            </Tip>
    
            å‚æ•°:
                slice_size (`str` æˆ– `int`, *å¯é€‰*, é»˜è®¤ä¸º `"auto"`):
                    å½“ä¸º `"auto"` æ—¶ï¼Œå°†è¾“å…¥åˆ†ä¸ºä¸¤ä¸ªæ³¨æ„åŠ›å¤´è¿›è¡Œè®¡ç®—ã€‚
                    å¦‚æœä¸º `"max"`ï¼Œåˆ™é€šè¿‡ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªåˆ‡ç‰‡æ¥ä¿å­˜æœ€å¤§å†…å­˜ã€‚
                    å¦‚æœæä¾›ä¸€ä¸ªæ•°å­—ï¼Œä½¿ç”¨ `attention_head_dim // slice_size` ä¸ªåˆ‡ç‰‡ã€‚
                    åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`attention_head_dim` å¿…é¡»æ˜¯ `slice_size` çš„å€æ•°ã€‚
    
            ç¤ºä¾‹:
    
            ```py
            >>> import torch
            >>> from diffusers import StableDiffusionPipeline
    
            >>> pipe = StableDiffusionPipeline.from_pretrained(
            ...     "runwayml/stable-diffusion-v1-5",
            ...     torch_dtype=torch.float16,
            ...     use_safetensors=True,
            ... )
    
            >>> prompt = "a photo of an astronaut riding a horse on mars"
            >>> pipe.enable_attention_slicing()
            >>> image = pipe(prompt).images[0]
            ```
            """
            # è°ƒç”¨è®¾ç½®åˆ‡ç‰‡çš„æ–¹æ³•ï¼Œä¼ å…¥åˆ‡ç‰‡å¤§å°
            self.set_attention_slice(slice_size)
    
        # å®šä¹‰ä¸€ä¸ªæ–¹æ³•æ¥ç¦ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—
        def disable_attention_slicing(self):
            r"""
            ç¦ç”¨åˆ‡ç‰‡æ³¨æ„åŠ›è®¡ç®—ã€‚å¦‚æœä¹‹å‰è°ƒç”¨è¿‡ `enable_attention_slicing`ï¼Œåˆ™æ³¨æ„åŠ›
            å°†åœ¨ä¸€æ­¥ä¸­è®¡ç®—ã€‚
            """
            # å°†åˆ‡ç‰‡å¤§å°è®¾ç½®ä¸º `None` ä»¥ç¦ç”¨ `attention slicing`
            self.enable_attention_slicing(None)
    
        # å®šä¹‰ä¸€ä¸ªæ–¹æ³•æ¥è®¾ç½®åˆ‡ç‰‡å¤§å°
        def set_attention_slice(self, slice_size: Optional[int]):
            # è·å–å½“å‰ç±»çš„ç­¾åé”®å’Œæ¨¡å—åç§°
            module_names, _ = self._get_signature_keys(self)
            # è·å–å½“å‰ç±»çš„æ‰€æœ‰æ¨¡å—
            modules = [getattr(self, n, None) for n in module_names]
            # è¿‡æ»¤å‡ºå…·æœ‰ `set_attention_slice` æ–¹æ³•çš„ PyTorch æ¨¡å—
            modules = [m for m in modules if isinstance(m, torch.nn.Module) and hasattr(m, "set_attention_slice")]
    
            # éå†æ‰€æœ‰æ¨¡å—å¹¶è®¾ç½®åˆ‡ç‰‡å¤§å°
            for module in modules:
                module.set_attention_slice(slice_size)
    
        # ç±»æ–¹æ³•çš„å®šä¹‰å¼€å§‹
        @classmethod
# å®šä¹‰ä¸€ä¸ªæ··åˆç±»ï¼Œç”¨äºå¤„ç†å…·æœ‰ VAE å’Œ UNet çš„æ‰©æ•£ç®¡é“ï¼ˆä¸»è¦ç”¨äºç¨³å®šæ‰©æ•£ LDMï¼‰
class StableDiffusionMixin:
    r""" 
    å¸®åŠ© DiffusionPipeline ä½¿ç”¨ VAE å’Œ UNetï¼ˆä¸»è¦ç”¨äº LDMï¼Œå¦‚ç¨³å®šæ‰©æ•£ï¼‰
    """

    # å¯ç”¨åˆ‡ç‰‡ VAE è§£ç çš„åŠŸèƒ½
    def enable_vae_slicing(self):
        r"""
        å¯ç”¨åˆ‡ç‰‡ VAE è§£ç ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAE å°†è¾“å…¥å¼ é‡åˆ†å‰²ä¸ºåˆ‡ç‰‡
        ä»¥åˆ†å‡ æ­¥è®¡ç®—è§£ç ã€‚è¿™å¯¹äºèŠ‚çœå†…å­˜å’Œå…è®¸æ›´å¤§çš„æ‰¹å¤„ç†å¤§å°å¾ˆæœ‰ç”¨ã€‚
        """
        # è°ƒç”¨ VAE çš„æ–¹æ³•ä»¥å¯ç”¨åˆ‡ç‰‡
        self.vae.enable_slicing()

    # ç¦ç”¨åˆ‡ç‰‡ VAE è§£ç çš„åŠŸèƒ½
    def disable_vae_slicing(self):
        r"""
        ç¦ç”¨åˆ‡ç‰‡ VAE è§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº† `enable_vae_slicing`ï¼Œæ­¤æ–¹æ³•å°†æ¢å¤åˆ°
        ä¸€æ­¥è®¡ç®—è§£ç ã€‚
        """
        # è°ƒç”¨ VAE çš„æ–¹æ³•ä»¥ç¦ç”¨åˆ‡ç‰‡
        self.vae.disable_slicing()

    # å¯ç”¨å¹³é“º VAE è§£ç çš„åŠŸèƒ½
    def enable_vae_tiling(self):
        r"""
        å¯ç”¨å¹³é“º VAE è§£ç ã€‚å½“å¯ç”¨æ­¤é€‰é¡¹æ—¶ï¼ŒVAE å°†è¾“å…¥å¼ é‡åˆ†å‰²ä¸ºå—
        ä»¥åˆ†å‡ æ­¥è®¡ç®—è§£ç å’Œç¼–ç ã€‚è¿™å¯¹äºèŠ‚çœå¤§é‡å†…å­˜å¹¶å…è®¸å¤„ç†æ›´å¤§å›¾åƒå¾ˆæœ‰ç”¨ã€‚
        """
        # è°ƒç”¨ VAE çš„æ–¹æ³•ä»¥å¯ç”¨å¹³é“º
        self.vae.enable_tiling()

    # ç¦ç”¨å¹³é“º VAE è§£ç çš„åŠŸèƒ½
    def disable_vae_tiling(self):
        r"""
        ç¦ç”¨å¹³é“º VAE è§£ç ã€‚å¦‚æœä¹‹å‰å¯ç”¨äº† `enable_vae_tiling`ï¼Œæ­¤æ–¹æ³•å°†æ¢å¤åˆ°
        ä¸€æ­¥è®¡ç®—è§£ç ã€‚
        """
        # è°ƒç”¨ VAE çš„æ–¹æ³•ä»¥ç¦ç”¨å¹³é“º
        self.vae.disable_tiling()

    # å¯ç”¨ FreeU æœºåˆ¶ï¼Œä½¿ç”¨æŒ‡å®šçš„ç¼©æ”¾å› å­
    def enable_freeu(self, s1: float, s2: float, b1: float, b2: float):
        r"""å¯ç”¨ FreeU æœºåˆ¶ï¼Œå¦‚ https://arxiv.org/abs/2309.11497 æ‰€è¿°ã€‚

        ç¼©æ”¾å› å­åç¼€è¡¨ç¤ºåº”ç”¨å®ƒä»¬çš„é˜¶æ®µã€‚

        è¯·å‚è€ƒ [å®˜æ–¹åº“](https://github.com/ChenyangSi/FreeU) ä»¥è·å–å·²çŸ¥é€‚ç”¨äºä¸åŒç®¡é“ï¼ˆå¦‚
        ç¨³å®šæ‰©æ•£ v1ã€v2 å’Œç¨³å®šæ‰©æ•£ XLï¼‰ç»„åˆçš„å€¼ã€‚

        Args:
            s1 (`float`):
                ç¬¬ä¸€é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡è½»è·³è¿‡ç‰¹å¾çš„è´¡çŒ®ï¼Œä»¥ç¼“è§£å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„
                â€œè¿‡å¹³æ»‘æ•ˆåº”â€ã€‚
            s2 (`float`):
                ç¬¬äºŒé˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºå‡è½»è·³è¿‡ç‰¹å¾çš„è´¡çŒ®ï¼Œä»¥ç¼“è§£å¢å¼ºå»å™ªè¿‡ç¨‹ä¸­çš„
                â€œè¿‡å¹³æ»‘æ•ˆåº”â€ã€‚
            b1 (`float`): ç¬¬ä¸€é˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚
            b2 (`float`): ç¬¬äºŒé˜¶æ®µçš„ç¼©æ”¾å› å­ï¼Œç”¨äºæ”¾å¤§éª¨å¹²ç‰¹å¾çš„è´¡çŒ®ã€‚
        """
        # æ£€æŸ¥å½“å‰å¯¹è±¡æ˜¯å¦å…·æœ‰ `unet` å±æ€§
        if not hasattr(self, "unet"):
            # å¦‚æœæ²¡æœ‰ï¼Œåˆ™æŠ›å‡ºå€¼é”™è¯¯
            raise ValueError("The pipeline must have `unet` for using FreeU.")
        # è°ƒç”¨ UNet çš„æ–¹æ³•ä»¥å¯ç”¨ FreeUï¼Œä¼ é€’ç¼©æ”¾å› å­
        self.unet.enable_freeu(s1=s1, s2=s2, b1=b1, b2=b2)

    # ç¦ç”¨ FreeU æœºåˆ¶
    def disable_freeu(self):
        """ç¦ç”¨ FreeU æœºåˆ¶ï¼ˆå¦‚æœå·²å¯ç”¨ï¼‰ã€‚"""
        # è°ƒç”¨ UNet çš„æ–¹æ³•ä»¥ç¦ç”¨ FreeU
        self.unet.disable_freeu()
    # å®šä¹‰èåˆ QKV æŠ•å½±çš„æ–¹æ³•ï¼Œé»˜è®¤å¯ç”¨ UNet å’Œ VAE
        def fuse_qkv_projections(self, unet: bool = True, vae: bool = True):
            """
            å¯ç”¨èåˆ QKV æŠ•å½±ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œæ‰€æœ‰æŠ•å½±çŸ©é˜µï¼ˆå³æŸ¥è¯¢ã€é”®ã€å€¼ï¼‰è¢«èåˆã€‚
            å¯¹äºäº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œé”®å’Œå€¼æŠ•å½±çŸ©é˜µè¢«èåˆã€‚
    
            <Tip warning={true}>
    
            æ­¤ API ä¸º ğŸ§ª å®éªŒæ€§ã€‚
    
            </Tip>
    
            å‚æ•°:
                unet (`bool`, é»˜è®¤å€¼ä¸º `True`): æ˜¯å¦åœ¨ UNet ä¸Šåº”ç”¨èåˆã€‚
                vae (`bool`, é»˜è®¤å€¼ä¸º `True`): æ˜¯å¦åœ¨ VAE ä¸Šåº”ç”¨èåˆã€‚
            """
            # åˆå§‹åŒ– UNet å’Œ VAE çš„èåˆçŠ¶æ€ä¸º False
            self.fusing_unet = False
            self.fusing_vae = False
    
            # å¦‚æœå¯ç”¨ UNet èåˆ
            if unet:
                # è®¾ç½® UNet èåˆçŠ¶æ€ä¸º True
                self.fusing_unet = True
                # è°ƒç”¨ UNet çš„ QKV èåˆæ–¹æ³•
                self.unet.fuse_qkv_projections()
                # è®¾ç½® UNet çš„æ³¨æ„åŠ›å¤„ç†å™¨ä¸ºèåˆç‰ˆæœ¬
                self.unet.set_attn_processor(FusedAttnProcessor2_0())
    
            # å¦‚æœå¯ç”¨ VAE èåˆ
            if vae:
                # æ£€æŸ¥ VAE æ˜¯å¦ä¸º AutoencoderKL ç±»å‹
                if not isinstance(self.vae, AutoencoderKL):
                    # æŠ›å‡ºå¼‚å¸¸æç¤ºä¸æ”¯æŒçš„ VAE ç±»å‹
                    raise ValueError("`fuse_qkv_projections()` is only supported for the VAE of type `AutoencoderKL`.")
    
                # è®¾ç½® VAE èåˆçŠ¶æ€ä¸º True
                self.fusing_vae = True
                # è°ƒç”¨ VAE çš„ QKV èåˆæ–¹æ³•
                self.vae.fuse_qkv_projections()
                # è®¾ç½® VAE çš„æ³¨æ„åŠ›å¤„ç†å™¨ä¸ºèåˆç‰ˆæœ¬
                self.vae.set_attn_processor(FusedAttnProcessor2_0())
    
        # å®šä¹‰å–æ¶ˆ QKV æŠ•å½±èåˆçš„æ–¹æ³•ï¼Œé»˜è®¤å¯ç”¨ UNet å’Œ VAE
        def unfuse_qkv_projections(self, unet: bool = True, vae: bool = True):
            """å¦‚æœå¯ç”¨äº† QKV æŠ•å½±èåˆï¼Œåˆ™ç¦ç”¨å®ƒã€‚
    
            <Tip warning={true}>
    
            æ­¤ API ä¸º ğŸ§ª å®éªŒæ€§ã€‚
    
            </Tip>
    
            å‚æ•°:
                unet (`bool`, é»˜è®¤å€¼ä¸º `True`): æ˜¯å¦åœ¨ UNet ä¸Šåº”ç”¨èåˆã€‚
                vae (`bool`, é»˜è®¤å€¼ä¸º `True`): æ˜¯å¦åœ¨ VAE ä¸Šåº”ç”¨èåˆã€‚
    
            """
            # å¦‚æœå¯ç”¨ UNet è§£èåˆ
            if unet:
                # æ£€æŸ¥ UNet æ˜¯å¦å·²ç»èåˆ
                if not self.fusing_unet:
                    # å¦‚æœæ²¡æœ‰èåˆï¼Œè®°å½•è­¦å‘Šä¿¡æ¯
                    logger.warning("The UNet was not initially fused for QKV projections. Doing nothing.")
                else:
                    # è°ƒç”¨ UNet çš„è§£èåˆæ–¹æ³•
                    self.unet.unfuse_qkv_projections()
                    # è®¾ç½® UNet èåˆçŠ¶æ€ä¸º False
                    self.fusing_unet = False
    
            # å¦‚æœå¯ç”¨ VAE è§£èåˆ
            if vae:
                # æ£€æŸ¥ VAE æ˜¯å¦å·²ç»èåˆ
                if not self.fusing_vae:
                    # å¦‚æœæ²¡æœ‰èåˆï¼Œè®°å½•è­¦å‘Šä¿¡æ¯
                    logger.warning("The VAE was not initially fused for QKV projections. Doing nothing.")
                else:
                    # è°ƒç”¨ VAE çš„è§£èåˆæ–¹æ³•
                    self.vae.unfuse_qkv_projections()
                    # è®¾ç½® VAE èåˆçŠ¶æ€ä¸º False
                    self.fusing_vae = False
```