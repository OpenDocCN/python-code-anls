# `.\cogview3-finetune\inference\cli_demo.py`

```py
# 该脚本演示如何使用 Hugging Face 的 `diffusers` 管道生成图像
"""
This script demonstrates how to generate an image using the CogView3-Plus-3B model with the Hugging Face `diffusers` pipeline.
It showcases memory-efficient techniques like model offloading, VAE slicing, and tiling to reduce memory consumption during inference.
The prompt describes an image to be generated by the model, and the final image is saved to disk.

Running the Script:
To run the script, use the following command with appropriate arguments:


python cli_demo.py --prompt "A beautiful sunset over a mountain" --width 1024 --height 1024


Additional options are available to specify the model path, guidance scale, number of inference steps, image generation type, and output paths.
"""
from diffusers import CogView3PlusPipeline  # 从 diffusers 库导入 CogView3PlusPipeline 类
import torch  # 导入 PyTorch 库以进行张量操作
import argparse  # 导入 argparse 库以解析命令行参数


def generate_image(  # 定义生成图像的函数
    prompt, model_path, guidance_scale, num_images_per_prompt, num_inference_steps, width, height, output_path, dtype
):
    # 使用指定精度加载预训练模型
    pipe = CogView3PlusPipeline.from_pretrained(model_path, torch_dtype=dtype)

    # 启用 CPU 卸载，以便在层未被使用时释放 GPU 内存
    pipe.enable_model_cpu_offload()

    # 启用 VAE 切片和拼接以优化内存使用
    pipe.vae.enable_slicing()
    pipe.vae.enable_tiling()

    # 根据提示生成图像
    image = pipe(
        prompt=prompt,
        guidance_scale=guidance_scale,
        num_images_per_prompt=num_images_per_prompt,
        num_inference_steps=num_inference_steps,
        width=width,
        height=height,
    ).images[0]  # 获取生成的第一幅图像

    # 将生成的图像保存到本地文件系统
    image.save(output_path)

    # 打印保存路径
    print(f"Image saved to {output_path}")


if __name__ == "__main__":  # 检查是否为主程序
    parser = argparse.ArgumentParser(description="Generate an image using the CogView3-Plus-3B model.")  # 创建参数解析器

    # 定义用于提示、模型路径等的参数
    parser.add_argument("--prompt", type=str, required=True, help="The text description for generating the image.")  # 添加提示参数
    parser.add_argument(
        "--model_path", type=str, default="THUDM/CogView3-Plus-3B", help="Path to the pre-trained model."  # 添加模型路径参数
    )
    parser.add_argument(
        "--guidance_scale", type=float, default=7.0, help="The guidance scale for classifier-free guidance."  # 添加引导比例参数
    )
    parser.add_argument(
        "--num_images_per_prompt", type=int, default=1, help="Number of images to generate per prompt."  # 添加每个提示生成图像数量的参数
    )
    parser.add_argument("--num_inference_steps", type=int, default=50, help="Number of denoising steps for inference.")  # 添加推理步骤数量的参数
    parser.add_argument("--width", type=int, default=1024, help="Width of the generated image.")  # 添加生成图像宽度的参数
    parser.add_argument("--height", type=int, default=1024, help="Height of the generated image.")  # 添加生成图像高度的参数
    parser.add_argument("--output_path", type=str, default="cogview3.png", help="Path to save the generated image.")  # 添加输出路径参数
    parser.add_argument("--dtype", type=str, default="bfloat16", help="Precision type (float16 or bfloat16).")  # 添加数据类型参数
    # 解析命令行参数
    args = parser.parse_args()

    # 将 dtype 参数转换为 PyTorch 的数据类型
    dtype = torch.bfloat16 if args.dtype == "bfloat16" else torch.float16

    # 调用生成图像的函数
    generate_image(
        # 传入用户输入的提示文本
        prompt=args.prompt,
        # 传入模型的路径
        model_path=args.model_path,
        # 传入引导尺度
        guidance_scale=args.guidance_scale,
        # 传入每个提示生成的图像数量
        num_images_per_prompt=args.num_images_per_prompt,
        # 传入推理步骤的数量
        num_inference_steps=args.num_inference_steps,
        # 传入生成图像的宽度
        width=args.width,
        # 传入生成图像的高度
        height=args.height,
        # 传入输出图像的路径
        output_path=args.output_path,
        # 传入转换后的数据类型
        dtype=dtype,
    )
```