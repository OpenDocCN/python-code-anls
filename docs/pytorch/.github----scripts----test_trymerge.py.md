# `.\pytorch\.github\scripts\test_trymerge.py`

```py
#!/usr/bin/env python3
# Tests implemented in this file are relying on GitHub GraphQL APIs
# In order to avoid test flakiness, results of the queries
# are cached in gql_mocks.json
# PyTorch Lint workflow does not have GITHUB_TOKEN defined to avoid
# flakiness, so if you are making changes to merge_rules or
# GraphQL queries in trymerge.py, please make sure to delete `gql_mocks.json`
# And re-run the test locally with ones PAT

import gzip
import json
import os
import warnings
from hashlib import sha256
from typing import Any, Dict, List, Optional
from unittest import main, mock, skip, TestCase
from urllib.error import HTTPError

from github_utils import gh_graphql

from gitutils import get_git_remote_name, get_git_repo_dir, GitRepo

from trymerge import (
    categorize_checks,
    DRCI_CHECKRUN_NAME,
    find_matching_merge_rule,
    get_classifications,
    get_drci_classifications,
    get_rockset_results,
    gh_get_team_members,
    GitHubPR,
    JobCheckState,
    main as trymerge_main,
    MandatoryChecksMissingError,
    MergeRule,
    RE_GHSTACK_DESC,
    read_merge_rules,
    remove_job_name_suffix,
    validate_revert,
)

# Set default GIT_REMOTE_URL if not already defined in environment variables
if "GIT_REMOTE_URL" not in os.environ:
    os.environ["GIT_REMOTE_URL"] = "https://github.com/pytorch/pytorch"

# Define file names for mocked GraphQL, Rockset, and DRCI data
GQL_MOCKS = "gql_mocks.json.gz"
ROCKSET_MOCKS = "rockset_mocks.json.gz"
DRCI_MOCKS = "drci_mocks.json.gz"


def mock_query(
    fallback_function: Any,
    file_name: str,
    key_function: Any,
    *args: Any,
) -> Any:
    # Generate the full path to the mocked GraphQL database file
    gql_db_fname = os.path.join(os.path.dirname(__file__), file_name)

    def get_mocked_queries() -> Any:
        # Read mocked queries from the JSON file if it exists
        if not os.path.exists(gql_db_fname):
            return {}
        with gzip.open(gql_db_fname, encoding="utf-8", mode="rt") as f:
            return json.load(f)

    def save_mocked_queries(obj: Any) -> None:
        # Save updated mocked queries to the JSON file
        with gzip.open(gql_db_fname, encoding="utf-8", mode="wt") as f:
            json.dump(obj, f, indent=2)
            f.write("\n")

    # Generate a unique key based on input arguments
    key = key_function(*args)
    # Load existing mocked queries
    mocked_queries = get_mocked_queries()

    # Check if there is a cached result for the current key
    if key in mocked_queries:
        return mocked_queries[key]

    # If no cached result is found, execute the fallback function
    try:
        rc = fallback_function(*args)
    # 捕获 HTTPError 异常
    except HTTPError as err:
        # 如果错误码为 401 或 403
        if err.code == 401 or err.code == 403:
            # 构建错误信息字符串，提醒更新特定文件
            err_msg = f"If you are seeing this message during workflow run, please make sure to update {file_name}"
            err_msg += f" locally, by deleting it and running {os.path.basename(__file__)} with"
            err_msg += " GitHub Personal Access Token passed via GITHUB_TOKEN,"
            err_msg += " the rockset api key passed via ROCKSET_API_KEY,"
            err_msg += " and drci api key passed via DRCI_BOT_KEY environment variables"
            # 检查环境变量是否都已设置
            if (
                os.getenv("GITHUB_TOKEN") is None
                or os.getenv("ROCKSET_API_KEY") is None
                or os.getenv("DRCI_BOT_KEY") is None
            ):
                # 若有任何环境变量未设置，更新错误信息
                err_msg = (
                    "Failed to update cached queries as GITHUB_TOKEN or ROCKSET_API_KEY or DRCI_BOT_KEY "
                    + "is not defined. "
                    + err_msg
                )
            # 抛出 RuntimeError 异常，并将原始异常链接到此异常
            raise RuntimeError(err_msg) from err
    # 更新 mocked_queries 字典中的键为 key 的值为 rc
    mocked_queries[key] = rc

    # 保存更新后的 mocked_queries 字典
    save_mocked_queries(mocked_queries)

    # 返回变量 rc
    return rc
def mocked_gh_graphql(query: str, **kwargs: Any) -> Any:
    def key_function(query: str, kwargs: Any) -> str:
        # 构造缓存键，包括查询的SHA256哈希和关键字参数的排序列表
        return f"query_sha={sha256(query.encode('utf-8')).hexdigest()} " + " ".join(
            [f"{k}={kwargs[k]}" for k in sorted(kwargs.keys())]
        )

    def gh_graphql_wrapper(query: str, kwargs: Any) -> Any:
        # 调用真实的 GitHub GraphQL 查询函数
        return gh_graphql(query, **kwargs)

    # 返回模拟查询的结果，调用模拟查询函数
    return mock_query(gh_graphql_wrapper, GQL_MOCKS, key_function, query, kwargs)


def mocked_rockset_results(head_sha: str, merge_base: str, num_retries: int = 3) -> Any:
    # 返回模拟的 Rockset 查询结果
    return mock_query(
        get_rockset_results,
        ROCKSET_MOCKS,
        lambda x, y: f"{x} {y}",
        head_sha,
        merge_base,
    )


def mocked_drci_classifications(pr_num: int, project: str, num_retries: int = 3) -> Any:
    # 返回模拟的 DRCI 分类结果
    return mock_query(
        get_drci_classifications,
        DRCI_MOCKS,
        lambda x, y: f"{x} {y}",
        pr_num,
        project,
    )


def mock_parse_args(revert: bool = False, force: bool = False) -> Any:
    # 模拟解析命令行参数，返回一个包含参数的对象
    class Object:
        def __init__(self) -> None:
            self.revert = revert
            self.force = force
            self.pr_num = 76123
            self.dry_run = True
            self.comment_id = 0
            self.reason = "this is for testing"
            self.ignore_current = False
            self.check_mergeability = False

    return Object()


def mock_remove_label(
    org: str, repo: str, pr_num: str, label: str, dry_run: bool
) -> None:
    # 模拟移除标签操作，不执行任何实际操作
    pass


def mock_revert(
    repo: GitRepo,
    pr: GitHubPR,
    *,
    dry_run: bool = False,
    comment_id: Optional[int] = None,
    reason: Optional[str] = None,
) -> None:
    # 模拟回滚操作，不执行任何实际操作
    pass


def mock_merge(
    pr: GitHubPR,
    repo: GitRepo,
    dry_run: bool = False,
    skip_mandatory_checks: bool = False,
    comment_id: Optional[int] = None,
    timeout_minutes: int = 400,
    stale_pr_days: int = 3,
    ignore_current: bool = False,
) -> None:
    # 模拟合并操作，不执行任何实际操作
    pass


def mock_gh_get_info() -> Any:
    # 返回模拟的 GitHub 信息，描述一个尚未关闭的 PR
    return {
        "closed": False,
        "isCrossRepository": False,
        "headRefName": "foo",
        "baseRefName": "bar",
        "baseRepository": {"defaultBranchRef": {"name": "bar"}},
        "files": {"nodes": [], "pageInfo": {"hasNextPage": False}},
        "changedFiles": 0,
    }


def mocked_read_merge_rules_NE(repo: Any, org: str, project: str) -> List[MergeRule]:
    # 返回模拟的合并规则，包括一个不存在的检查名称
    return [
        MergeRule(
            name="mock with nonexistent check",
            patterns=["*"],
            approved_by=[],
            mandatory_checks_name=["Lint", "Facebook CLA Check", "nonexistent"],
            ignore_flaky_failures=True,
        ),
    ]


def mocked_read_merge_rules(repo: Any, org: str, project: str) -> List[MergeRule]:
    # 这个函数的具体实现将在其它地方提供，未在这里包含
    pass
    返回一个包含两个 MergeRule 对象的列表，每个对象定义了一个合并规则
    return [
        # 第一个合并规则，命名为 "super"
        MergeRule(
            # 匹配所有模式
            name="super",
            # 被 pytorch/metamates 和 ngimel 批准
            approved_by=["pytorch/metamates", "ngimel"],
            # 必须通过以下检查项：Lint 和 pull / linux-xenial-cuda11.3-py3.7-gcc7 / build
            mandatory_checks_name=[
                "Lint",
                "pull / linux-xenial-cuda11.3-py3.7-gcc7 / build",
            ],
            # 忽略易出错的失败
            ignore_flaky_failures=True,
        ),
        # 第二个合并规则，命名为 "xla"
        MergeRule(
            # 只匹配 .github/ci_commit_pins/xla.txt 模式
            patterns=[".github/ci_commit_pins/xla.txt"],
            # 被 pytorchbot 批准
            approved_by=["pytorchbot"],
            # 必须通过以下检查项：Lint、EasyCLA、pull / linux-focal-py3_8-clang9-xla / build、pull / linux-focal-py3_8-clang9-xla / test (xla, 1, 1, linux.12xlarge)
            mandatory_checks_name=[
                "Lint",
                "EasyCLA",
                "pull / linux-focal-py3_8-clang9-xla / build",
                "pull / linux-focal-py3_8-clang9-xla / test (xla, 1, 1, linux.12xlarge)",
            ],
            # 忽略易出错的失败
            ignore_flaky_failures=True,
        ),
    ]
def mocked_read_merge_rules_approvers(
    repo: Any, org: str, project: str
) -> List[MergeRule]:
    # 返回一个模拟的合并规则列表，每个规则包含名称、匹配模式、通过者列表和强制检查名称列表
    return [
        MergeRule(
            name="Core Reviewers",
            patterns=["*"],
            approved_by=["1", "2", "3", "4", "5", "6"],
            mandatory_checks_name=[
                "Lint",
                "pull",
            ],
        ),
        MergeRule(
            name="Core Maintainers",
            patterns=["*"],
            approved_by=["1", "2", "malfet"],
            mandatory_checks_name=[
                "Lint",
                "pull",
            ],
        ),
    ]


def mocked_read_merge_rules_raise(repo: Any, org: str, project: str) -> List[MergeRule]:
    # 抛出一个 RuntimeError 异常，用于测试目的
    raise RuntimeError("testing")


def xla_merge_rules(repo: Any, org: str, project: str) -> List[MergeRule]:
    # 返回一个模拟的 XLA 合并规则列表，包含名称、匹配模式、通过者列表、强制检查名称列表和是否忽略失败的标志
    return [
        MergeRule(
            name=" OSS CI / pytorchbot / XLA",
            patterns=[".github/ci_commit_pins/xla.txt"],
            approved_by=["pytorchbot"],
            mandatory_checks_name=[
                "Lint",
                "EasyCLA",
                "pull / linux-bionic-py3_8-clang8-xla / build",
                "pull / linux-bionic-py3_8-clang8-xla / test (xla, 1, 1, linux.4xlarge)",
                "inductor / cuda11.8-py3.10-gcc7-sm86 / test (inductor_torchbench_dynamic, 1, 1, linux.g5.4xlarge.nvidia.gpu)",
            ],
            ignore_flaky_failures=False,
        ),
    ]


def empty_rockset_results(head_sha: str, merge_base: str) -> List[Dict[str, Any]]:
    # 返回一个空列表，用于模拟 Rockset 的查询结果
    return []


class DummyGitRepo(GitRepo):
    def __init__(self) -> None:
        super().__init__(get_git_repo_dir(), get_git_remote_name())

    def commits_resolving_gh_pr(self, pr_num: int) -> List[str]:
        # 返回一个包含虚假提交 SHA 的列表，模拟解决 GitHub PR 的提交
        return ["FakeCommitSha"]

    def commit_message(self, ref: str) -> str:
        # 返回一个虚假的提交消息，模拟 Git 提交的消息
        return "super awsome commit message"


@mock.patch("trymerge.get_rockset_results", side_effect=empty_rockset_results)
@mock.patch("trymerge.gh_graphql", side_effect=mocked_gh_graphql)
@mock.patch(
    "trymerge.get_drci_classifications", side_effect=mocked_drci_classifications
)
class TestTryMerge(TestCase):
    def test_merge_rules_valid(self, *args: Any) -> None:
        # 测试读取合并规则是否有效
        repo = DummyGitRepo()
        merge_rules = read_merge_rules(repo, "pytorch", "pytorch")
        self.assertGreater(len(merge_rules), 1)

    @mock.patch("trymerge.read_merge_rules", side_effect=mocked_read_merge_rules)
    def test_match_rules(self, *args: Any) -> None:
        # 测试 PR 是否符合合并规则
        pr = GitHubPR("pytorch", "pytorch", 109999)
        repo = DummyGitRepo()
        self.assertTrue(find_matching_merge_rule(pr, repo) is not None)

    @mock.patch("trymerge.read_merge_rules", side_effect=mocked_read_merge_rules_raise)
    # 测试未能读取合并规则时引发异常
    def test_read_merge_rules_fails(self, *args: Any) -> None:
        "Tests that PR fails to read the merge rules"
        pr = GitHubPR("pytorch", "pytorch", 77700)
        repo = DummyGitRepo()
        # 断言捕获 RuntimeError 异常，并验证异常消息包含 "testing"
        self.assertRaisesRegex(
            RuntimeError, "testing", lambda: find_matching_merge_rule(pr, repo)
        )

    @mock.patch(
        "trymerge.read_merge_rules", side_effect=mocked_read_merge_rules_approvers
    )
    # 测试匹配规则是否具有必要的审批人员
    def test_match_rules_approvers(self, *args: Any) -> None:
        "Tests that PR has the necessary approvers"
        repo = DummyGitRepo()

        pr = GitHubPR("pytorch", "pytorch", 115329)
        # 如果 PR 没有其中之一的审批人员，则测试所有规则可能的审批人员是否已列出
        for mock_rule in ["Core Reviewers", "Core Maintainers"]:
            self.assertRaisesRegex(
                RuntimeError,
                mock_rule,
                lambda: find_matching_merge_rule(pr, repo),
            )

        pr = GitHubPR("pytorch", "pytorch", 115495)
        # 测试具有正确审批人员的 PR 是否不引发任何异常
        self.assertTrue(find_matching_merge_rule(pr, repo) is not None)

    @mock.patch("trymerge.read_merge_rules", side_effect=mocked_read_merge_rules)
    # 测试失败的 lint 检查是否引发异常
    def test_lint_fails(self, *args: Any) -> None:
        "Tests that PR fails mandatory lint check"
        pr = GitHubPR("pytorch", "pytorch", 90791)
        repo = DummyGitRepo()
        self.assertRaises(RuntimeError, lambda: find_matching_merge_rule(pr, repo))

    # 测试能够获取最后一条评论
    def test_get_last_comment(self, *args: Any) -> None:
        "Tests that last comment can be fetched"
        pr = GitHubPR("pytorch", "pytorch", 71759)
        comment = pr.get_last_comment()
        self.assertEqual(comment.author_login, "github-actions")
        self.assertIsNone(comment.editor_login)
        self.assertTrue("You've committed this PR" in comment.body_text)

    # 测试能够计算 PR 作者
    def test_get_author_null(self, *args: Any) -> None:
        """Tests that PR author can be computed
        If reply contains NULL
        """
        pr = GitHubPR("pytorch", "pytorch", 71759)
        author = pr.get_author()
        self.assertTrue(author is not None)
        self.assertTrue("@" in author)
        self.assertTrue(pr.get_diff_revision() is None)

        # 对于具有多个贡献者的 PR，但创建者 ID 不在作者列表中
        pr = GitHubPR("pytorch", "pytorch", 75095)
        self.assertEqual(pr.get_pr_creator_login(), "mruberry")
        author = pr.get_author()
        self.assertTrue(author is not None)

    # 测试能够获取包含 100+ 文件的 PR
    def test_large_diff(self, *args: Any) -> None:
        "Tests that PR with 100+ files can be fetched"
        pr = GitHubPR("pytorch", "pytorch", 73099)
        self.assertTrue(pr.get_changed_files_count() > 100)
        flist = pr.get_changed_files()
        self.assertEqual(len(flist), pr.get_changed_files_count())
    # 测试内部更改的 PR 被正确检测到
    def test_internal_changes(self, *args: Any) -> None:
        "Tests that PR with internal changes is detected"
        pr = GitHubPR("pytorch", "pytorch", 110140)
        # 断言该 PR 是否有内部更改
        self.assertTrue(pr.has_internal_changes())

    # 测试能够获取超过50条评论的 PR
    def test_comments_pagination(self, *args: Any) -> None:
        "Tests that PR with 50+ comments can be fetched"
        pr = GitHubPR("pytorch", "pytorch", 31093)
        # 断言该 PR 的评论数量大于50
        self.assertGreater(len(pr.get_comments()), 50)

    # 测试具有60次提交的 PR 的评论和结论获取
    def test_gql_complexity(self, *args: Any) -> None:
        "Fetch comments and conclusions for PR with 60 commits"
        # 旧版 GrapQL 查询可能导致 HTTP/502 错误
        # 参见 https://gist.github.com/malfet/9b93bc7eeddeaf1d84546efc4f0c577f
        pr = GitHubPR("pytorch", "pytorch", 68111)
        # 断言该 PR 的评论数量大于20
        self.assertGreater(len(pr.get_comments()), 20)
        # 断言该 PR 的提交数量大于60
        self.assertGreater(pr.get_commit_count(), 60)

    # 被跳过的测试：GitHub 不再保留这些数据
    @skip("GitHub doesn't keep this data anymore")
    def test_gql_retrieve_checksuites(self, *args: Any) -> None:
        "Fetch comments and conclusions for PR with 60 commits"
        pr = GitHubPR("pytorch", "pytorch", 94787)
        # 断言该 PR 的 checkrun 结论数量为182
        self.assertEqual(len(pr.get_checkrun_conclusions()), 182)

    # 测试获取团队成员功能是否正常工作
    def test_team_members(self, *args: Any) -> None:
        "Test fetching team members works"
        # 获取名为 'pytorch-dev-infra' 的团队成员
        dev_infra_team = gh_get_team_members("pytorch", "pytorch-dev-infra")
        # 断言团队成员数量大于2
        self.assertGreater(len(dev_infra_team), 2)
        # 断言警告被触发，因为 'qwertyuiop' 团队不存在
        with self.assertWarns(Warning):
            non_existing_team = gh_get_team_members("pytorch", "qwertyuiop")
            # 断言不存在的团队成员数量为0
            self.assertEqual(len(non_existing_team), 0)

    # 测试能够获取大量提交的作者信息
    def test_get_author_many_commits(self, *args: Any) -> None:
        """Tests that authors for all commits can be fetched"""
        pr = GitHubPR("pytorch", "pytorch", 76118)
        authors = pr.get_authors()
        # 断言该 PR 的提交数量大于100
        self.assertGreater(pr.get_commit_count(), 100)
        # 断言作者数量大于50
        self.assertGreater(len(authors), 50)
        # 断言 PR 的作者包含 '@'
        self.assertTrue("@" in pr.get_author())

    # 测试 PR 包含不存在/待处理状态检查的情况，应该返回正确的错误信息
    @mock.patch("trymerge.read_merge_rules", side_effect=mocked_read_merge_rules_NE)
    def test_pending_status_check(self, *args: Any) -> None:
        """Tests that PR with nonexistent/pending status checks fails with the right reason."""
        pr = GitHubPR("pytorch", "pytorch", 76118)
        repo = DummyGitRepo()
        # 断言调用 find_matching_merge_rule 函数会引发 MandatoryChecksMissingError，并包含指定错误信息
        self.assertRaisesRegex(
            MandatoryChecksMissingError,
            ".*are pending/not yet run.*",
            lambda: find_matching_merge_rule(pr, repo),
        )
    # 测试函数：测试获取 Pull Request 所有审批者
    def test_get_author_many_reviews(self, *args: Any) -> None:
        """Tests that all reviews can be fetched"""
        # 创建 GitHubPR 对象，指定仓库名、项目名、PR号码
        pr = GitHubPR("pytorch", "pytorch", 76123)
        # 获取所有审批者
        approved_by = pr.get_approved_by()
        # 断言：审批者数量应大于 0
        self.assertGreater(len(approved_by), 0)
        # 确保 _reviews 属性不为 None，以满足 mypy 的要求
        assert pr._reviews is not None  # to pacify mypy
        # 断言：_reviews 中的审查数应大于 100
        self.assertGreater(len(pr._reviews), 100)

    # 测试函数：测试获取 Pull Request 的共同作者
    def get_co_authors(self, *args: Any) -> None:
        """Tests that co-authors are recognized"""
        # 创建 GitHubPR 对象，指定仓库名、项目名、PR号码
        pr = GitHubPR("pytorch", "pytorch", 118347)
        # 获取所有作者
        authors = pr.get_authors()
        # 断言：列表中应包含特定的共同作者
        self.assertIn("kit1980", authors)
        # 断言：生成的提交消息应包含 "Co-authored-by:" 字符串
        self.assertIn("Co-authored-by:", pr.gen_commit_message())

    # 测试函数：测试获取 Pull Request 的所有检查运行结果
    def test_get_checkruns_many_runs(self, *args: Any) -> None:
        """Tests that all checkruns can be fetched"""
        # 创建 GitHubPR 对象，指定仓库名、项目名、PR号码
        pr = GitHubPR("pytorch", "pytorch", 105260)
        # 获取所有检查运行结果的结论
        conclusions = pr.get_checkrun_conclusions()
        # 断言：检查运行结果的结论数量应为 221
        self.assertEqual(len(conclusions), 221)
        # 断言：特定的检查运行结果应在结论字典的键中
        self.assertTrue(
            "pull / linux-docs / build-docs-cpp-false" in conclusions.keys()
        )

    # 测试函数：测试取消的工作流不会覆盖现有的成功状态
    def test_cancelled_gets_ignored(self, *args: Any) -> None:
        """Tests that cancelled workflow does not override existing successful status"""
        # 创建 GitHubPR 对象，指定仓库名、项目名、PR号码
        pr = GitHubPR("pytorch", "pytorch", 110367)
        # 获取所有检查运行结果的结论
        conclusions = pr.get_checkrun_conclusions()
        # 获取所有包含 "Lint" 字样的检查名列表
        lint_checks = [name for name in conclusions.keys() if "Lint" in name]
        # 断言：至少应有一个 "Lint" 检查
        self.assertTrue(len(lint_checks) > 0)
        # 断言：所有 "Lint" 检查的状态应为 "SUCCESS"
        self.assertTrue(
            all(conclusions[name].status == "SUCCESS" for name in lint_checks)
        )

    # 测试函数：测试根据评论 ID 获取评论（即使所请求的评论实际上是审查而不是简单评论）
    def test_get_review_comment_by_id(self, *args: Any) -> None:
        """Tests that even if the comment requested was actually a review instead of a simple comment, we can still find it"""
        # 创建 GitHubPR 对象，指定仓库名、项目名、PR号码
        pr = GitHubPR("pytorch", "pytorch", 107070)
        # 指定要获取的审查评论的 ID
        review_comment_id = 1582767635
        # 获取评论对象
        comment = pr.get_comment_by_id(review_comment_id)
        # 断言：评论对象不应为 None
        self.assertIsNotNone(comment)

    # 测试函数：测试主函数中的回滚操作
    @mock.patch("trymerge.gh_get_pr_info", return_value=mock_gh_get_info())
    @mock.patch("trymerge.parse_args", return_value=mock_parse_args(True, False))
    @mock.patch("trymerge.try_revert", side_effect=mock_revert)
    def test_main_revert(self, mock_revert: Any, *args: Any) -> None:
        """Tests that main function handles revert operation correctly"""
        # 调用主函数
        trymerge_main()
        # 断言：try_revert 函数应被调用一次
        mock_revert.assert_called_once()

    # 测试函数：测试主函数中的强制合并操作
    @mock.patch("trymerge.gh_get_pr_info", return_value=mock_gh_get_info())
    @mock.patch("trymerge.parse_args", return_value=mock_parse_args(False, True))
    @mock.patch("trymerge.gh_remove_label", side_effect=mock_remove_label)
    @mock.patch("trymerge.merge", side_effect=mock_merge)
    def test_main_force(
        self, mock_merge: Any, mock_parse_args: Any, *args: Any
    ) -> None:
        """Tests that main function handles force merge operation correctly"""
        # 调用主函数
        trymerge_main()
        # 断言：merge 函数应被正确调用
        mock_merge.assert_called_once_with(
            mock.ANY,
            mock.ANY,
            dry_run=mock.ANY,
            skip_mandatory_checks=True,
            comment_id=mock.ANY,
            ignore_current=False,
        )
    @mock.patch("trymerge.gh_get_pr_info", return_value=mock_gh_get_info())
    # 使用 mock.patch 装饰器模拟 gh_get_pr_info 函数调用，并返回预设的 mock_gh_get_info 结果

    @mock.patch("trymerge.parse_args", return_value=mock_parse_args(False, False))
    # 使用 mock.patch 装饰器模拟 parse_args 函数调用，并返回预设的 mock_parse_args 结果

    @mock.patch("trymerge.gh_remove_label", side_effect=mock_remove_label)
    # 使用 mock.patch 装饰器模拟 gh_remove_label 函数调用，并设置 side_effect 为 mock_remove_label

    @mock.patch("trymerge.merge", side_effect=mock_merge)
    # 使用 mock.patch 装饰器模拟 merge 函数调用，并设置 side_effect 为 mock_merge

    def test_main_merge(self, mock_merge: Any, *args: Any) -> None:
        # 定义测试方法 test_main_merge，其中 mock_merge 参数为模拟的 merge 函数

        trymerge_main()
        # 调用 trymerge_main 函数，测试主函数的合并操作

        mock_merge.assert_called_once_with(
            mock.ANY,
            mock.ANY,
            dry_run=mock.ANY,
            skip_mandatory_checks=False,
            comment_id=mock.ANY,
            ignore_current=False,
        )
        # 断言 mock_merge 函数被调用一次，且参数匹配指定条件

    @mock.patch("trymerge.read_merge_rules", side_effect=mocked_read_merge_rules)
    # 使用 mock.patch 装饰器模拟 read_merge_rules 函数调用，并设置 side_effect 为 mocked_read_merge_rules

    def test_revert_rules(self, *args: Any) -> None:
        """Tests that reverts from collaborators are allowed"""
        # 测试从协作者处允许回滚操作

        pr = GitHubPR("pytorch", "pytorch", 79694)
        # 创建 GitHubPR 对象，指定仓库 pytorch 中 PR 编号为 79694

        repo = DummyGitRepo()
        # 创建虚拟的 Git 仓库对象

        self.assertIsNotNone(validate_revert(repo, pr, comment_id=1189459845))
        # 断言 validate_revert 函数返回值不为 None

    def test_get_changed_files(self, *args: Any) -> None:
        """
        Tests that the list changed files in a PR doesn't include duplicates
        """
        # 测试 PR 中修改文件列表不包含重复项

        pr = GitHubPR("pytorch", "pytorch", 95233)
        # 创建 GitHubPR 对象，指定仓库 pytorch 中 PR 编号为 95233

        try:
            changed_files = pr.get_changed_files()
            # 尝试获取 PR 中修改的文件列表
        except RuntimeError as error:
            self.fail(f"get_changed_files throws an exception: {error}")
            # 捕获 RuntimeError 异常并输出错误信息

        self.assertEqual(len(changed_files), pr.get_changed_files_count())
        # 断言修改文件列表的长度等于实际修改文件数量

    def test_revert_codev_abandoned_diff_succeeds(self, *args: Any) -> None:
        # 测试回滚被放弃的 diff 是否成功

        pr = GitHubPR("pytorch", "pytorch", 100652)
        # 创建 GitHubPR 对象，指定仓库 pytorch 中 PR 编号为 100652

        class GitRepoCoDev(DummyGitRepo):
            def commit_message(self, ref: str) -> str:
                return pr.get_body()
            # 定义 GitRepoCoDev 类，覆盖 commit_message 方法以返回 PR 的正文内容

        repo = GitRepoCoDev()
        # 创建 GitRepoCoDev 对象

        validate_revert(repo, pr, comment_id=1588195237)
        # 执行回滚验证操作

    def test_pr_changed_submodule_detection(self, *args: Any) -> None:
        # 测试 PR 中修改子模块的检测方法

        # Updates submodule during dev-cycle but reverts it later
        # 在开发周期中更新子模块，但稍后将其回滚

        pr = GitHubPR("pytorch", "pytorch", 95045)
        # 创建 GitHubPR 对象，指定仓库 pytorch 中 PR 编号为 95045

        self.assertEqual(pr.get_changed_submodules(), [])
        # 断言获取的修改子模块列表为空列表

        self.assertFalse(pr.has_invalid_submodule_updates())
        # 断言 PR 中无无效的子模块更新

        # PR updates ideep
        # PR 更新 ideep 子模块

        pr = GitHubPR("pytorch", "pytorch", 94939)
        # 创建 GitHubPR 对象，指定仓库 pytorch 中 PR 编号为 94939

        self.assertEqual(pr.get_changed_submodules(), ["third_party/ideep"])
        # 断言获取的修改子模块列表为 ["third_party/ideep"]

        self.assertTrue(pr.has_invalid_submodule_updates())
        # 断言 PR 中存在无效的子模块更新

        # Automated submodule update
        # 自动化子模块更新

        pr = GitHubPR("pytorch", "pytorch", 91051)
        # 创建 GitHubPR 对象，指定仓库 pytorch 中 PR 编号为 91051

        self.assertEqual(pr.get_changed_submodules(), ["third_party/kineto"])
        # 断言获取的修改子模块列表为 ["third_party/kineto"]

        self.assertFalse(pr.has_invalid_submodule_updates())
        # 断言 PR 中无无效的子模块更新
    # 定义测试方法，用于测试去除作业名称后缀的函数
    def test_remove_job_name_suffix(self, *args: Any) -> None:
        # 准备测试用例列表，每个测试用例包含输入名称和预期输出
        test_cases = [
            {
                "name": "linux-bionic-cuda12.1-py3.10-gcc9-sm86 / test (default, 1, 5, linux.g5.4xlarge.nvidia.gpu)",
                "expected": "linux-bionic-cuda12.1-py3.10-gcc9-sm86 / test (default)",
            },
            {
                "name": "android-emulator-build-test / build-and-test (default, 1, 1, ubuntu-20.04-16x)",
                "expected": "android-emulator-build-test / build-and-test (default)",
            },
            {
                "name": "linux-focal-rocm5.4.2-py3.8 / build",
                "expected": "linux-focal-rocm5.4.2-py3.8 / build",
            },
            {
                "name": "libtorch-cpu-shared-with-deps-release-build",
                "expected": "libtorch-cpu-shared-with-deps-release-build",
            },
            {
                "name": "manywheel-py3_8-cuda11_8-test / test",
                "expected": "manywheel-py3_8-cuda11_8-test / test",
            },
            {
                "name": "lintrunner / linux-job",
                "expected": "lintrunner / linux-job",
            },
            {
                "name": "Test `run_test.py` is usable without boto3/rockset",
                "expected": "Test `run_test.py` is usable without boto3/rockset",
            },
        ]

        # 遍历每个测试用例，调用函数进行断言比较
        for case in test_cases:
            self.assertEqual(case["expected"], remove_job_name_suffix(case["name"]))

    # 定义测试方法，用于测试获取合并基准的函数
    def test_get_merge_base(self, *args: Any) -> None:
        # 创建 GitHubPR 对象，用于处理某个 Pull Request
        pr = GitHubPR("pytorch", "pytorch", 104121)

        # 设置模拟的合并基准 SHA 值
        mock_merge_base = "mocked-sha"
        # 使用 mock.patch 创建一个虚拟的函数调用，返回预设的合并基准 SHA 值
        with mock.patch(
            "trymerge.gh_fetch_merge_base", return_value=mock_merge_base
        ) as mocked_gh_fetch_merge_base:
            # 断言实际获取的合并基准 SHA 值与预设的相等
            self.assertEqual(mock_merge_base, pr.get_merge_base())

            # 确保连续调用不会重复查询，而是复用之前的结果
            self.assertEqual(mock_merge_base, pr.get_merge_base())
            # 断言模拟的获取合并基准函数只被调用了一次
            mocked_gh_fetch_merge_base.assert_called_once()
# 使用 mock.patch 装饰器，模拟 `trymerge.get_rockset_results` 函数的行为为 `mocked_rockset_results`
# 使用 mock.patch 装饰器，模拟 `trymerge.gh_graphql` 函数的行为为 `mocked_gh_graphql`
# 使用 mock.patch 装饰器，模拟 `trymerge.gh_fetch_merge_base` 函数返回空字符串
# 使用 mock.patch 装饰器，模拟 `trymerge.get_drci_classifications` 函数的行为为 `mocked_drci_classifications`
class TestBypassFailures(TestCase):
    # 定义一个测试方法，用于测试获取分类信息的功能
    def test_get_classifications(self, *args: Any) -> None:
        # 创建一个 GitHubPR 对象，指定仓库为 "pytorch"，PR 编号为 109584
        pr = GitHubPR("pytorch", "pytorch", 109584)
        # 获取该 PR 的检查运行结果列表
        checks = pr.get_checkrun_conclusions()
        # 获取分类信息，传入 PR 编号、项目名称、检查结果列表和空列表
        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 断言检查项的分类是否为 "BROKEN_TRUNK"
        self.assertTrue(
            checks[
                "pull / linux-focal-py3.11-clang10 / test (dynamo, 1, 2, linux.2xlarge)"
            ].classification
            == "BROKEN_TRUNK"
        )
        # 断言检查项的分类是否为 "FLAKY"
        self.assertTrue(
            checks[
                "trunk / win-vs2019-cpu-py3 / test (default, 2, 3, windows.4xlarge.nonephemeral)"
            ].classification
            == "FLAKY"
        )
        # 断言检查项的分类是否为 "FLAKY"
        self.assertTrue(
            checks[
                "pull / linux-jammy-py3.8-gcc11 / test (distributed, 1, 2, linux.2xlarge)"
            ].classification
            == "FLAKY"
        )
        # 断言检查项的分类是否为 "FLAKY"
        self.assertTrue(
            checks[
                "pull / linux-focal-cuda11.8-py3.10-gcc9 / test (distributed, 1, 3, linux.8xlarge.nvidia.gpu)"
            ].classification
            == "FLAKY"
        )

        # 设置 ok_failed_checks_threshold 参数为 6，用于对检查项进行分类
        pending, failed, ignorable = categorize_checks(
            checks, list(checks.keys()), ok_failed_checks_threshold=6
        )
        # 断言没有待处理项
        self.assertTrue(len(pending) == 0)
        # 断言没有失败项
        self.assertTrue(len(failed) == 0)
        # 断言忽略的 "FLAKY" 分类项为 4 个
        self.assertTrue(len(ignorable["FLAKY"]) == 4)
        # 断言忽略的 "BROKEN_TRUNK" 分类项为 2 个

        # 设置 ok_failed_checks_threshold 参数为默认值 -1，忽略所有 "FLAKY" 和 "BROKEN_TRUNK" 失败项
        pending, failed, ignorable = categorize_checks(checks, list(checks.keys()))
        # 断言没有待处理项
        self.assertTrue(len(pending) == 0)
        # 断言没有失败项
        self.assertTrue(len(failed) == 0)
        # 断言忽略的 "FLAKY" 分类项为 4 个
        self.assertTrue(len(ignorable["FLAKY"]) == 4)
        # 断言忽略的 "BROKEN_TRUNK" 分类项为 2 个

        # 设置 ok_failed_checks_threshold 参数为 1，只保留至少有一个 OK 失败的检查项
        pending, failed, ignorable = categorize_checks(
            checks, list(checks.keys()), ok_failed_checks_threshold=1
        )
        # 断言没有待处理项
        self.assertTrue(len(pending) == 0)
        # 断言失败项为 6 个
        self.assertTrue(len(failed) == 6)
        # 断言忽略的 "FLAKY" 分类项为 4 个
        self.assertTrue(len(ignorable["FLAKY"]) == 4)
        # 断言忽略的 "BROKEN_TRUNK" 分类项为 2 个

        # 再次设置 ok_failed_checks_threshold 参数为 1，模拟忽略所有 "FLAKY" 和 "BROKEN_TRUNK" 失败项
        pending, failed, ignorable = categorize_checks(
            checks, list(checks.keys()), ok_failed_checks_threshold=1
        )
        # 断言没有待处理项
        self.assertTrue(len(pending) == 0)
        # 断言失败项为 6 个
        self.assertTrue(len(failed) == 6)
        # 断言忽略的 "FLAKY" 分类项为 4 个
        self.assertTrue(len(ignorable["FLAKY"]) == 4)
        # 断言忽略的 "BROKEN_TRUNK" 分类项为 2 个
    # 测试获取 GitHub 上 Pull Request 的分类结果，全名匹配时的情况
    def test_get_classifications_flaky_fullname(self, *args: Any) -> None:
        # 创建 GitHubPR 对象，指定仓库名、项目名和 PR 编号
        pr = GitHubPR("pytorch", "pytorch", 110362)
        # 获取 PR 的检查运行结果
        checks = pr.get_checkrun_conclusions()
        # 调用 get_classifications 函数获取分类结果，传入 PR 编号、项目名、检查结果和空列表
        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 对分类结果进行进一步处理，分别获取待处理、失败和可忽略的检查项
        pending, failed, ignorable = categorize_checks(checks, list(checks.keys()))
        # 断言：待处理列表应为空
        self.assertTrue(len(pending) == 0)
        # 断言：失败列表应为空
        self.assertTrue(len(failed) == 0)
        # 断言：可忽略列表中的 "FLAKY" 类别应有一项
        self.assertTrue(len(ignorable["FLAKY"]) == 1)

    # 测试获取 GitHub 上 Pull Request 的分类结果，无效取消情况
    def test_get_classifications_invalid_cancel(self, *args: Any) -> None:
        # 创建 GitHubPR 对象，指定仓库名、项目名和 PR 编号
        pr = GitHubPR("pytorch", "pytorch", 110367)
        # 获取 PR 的检查运行结果
        checks = pr.get_checkrun_conclusions()
        # 调用 get_classifications 函数获取分类结果，传入 PR 编号、项目名、检查结果和空列表
        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 对分类结果进行进一步处理，分别获取待处理、失败和可忽略的检查项
        pending, failed, ignorable = categorize_checks(checks, list(checks.keys()))
        # 断言：待处理列表应为空
        self.assertTrue(len(pending) == 0)
        # 断言：失败列表应为空
        self.assertTrue(len(failed) == 0)
        # 断言：可忽略列表中的 "FLAKY" 类别应为空，"BROKEN_TRUNK" 类别应为空，"UNSTABLE" 类别应有三项
        self.assertTrue(len(ignorable["FLAKY"]) == 0)
        self.assertTrue(len(ignorable["BROKEN_TRUNK"]) == 0)
        self.assertTrue(len(ignorable["UNSTABLE"]) == 3)

    # 测试获取 GitHub 上 Pull Request 的分类结果，相似失败情况
    def test_get_classifications_similar_failures(self, *args: Any) -> None:
        # 创建 GitHubPR 对象，指定仓库名、项目名和 PR 编号
        pr = GitHubPR("pytorch", "pytorch", 109750)
        # 获取 PR 的检查运行结果
        checks = pr.get_checkrun_conclusions()
        # 调用 get_classifications 函数获取分类结果，传入 PR 编号、项目名、检查结果和空列表
        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 对分类结果进行进一步处理，分别获取待处理、失败和可忽略的检查项
        pending, failed, ignorable = categorize_checks(checks, list(checks.keys()))
        # 断言：待处理列表应为空
        self.assertTrue(len(pending) == 0)
        # 断言：失败列表应为空
        self.assertTrue(len(failed) == 0)
        # 断言：可忽略列表中的 "FLAKY" 类别应有一项
        self.assertTrue(len(ignorable["FLAKY"]) == 1)
    # 定义一个测试方法，用于测试获取未稳定状态的分类
    def test_get_classifications_unstable(self, *args: Any) -> None:
        # 创建一个 GitHubPR 对象，表示 pytorch 仓库中的 PR 编号 104312
        pr = GitHubPR("pytorch", "pytorch", 104312)
        # 获取与该 PR 相关的所有检查运行结果
        checks = pr.get_checkrun_conclusions()
        # 获取对应 PR 的分类信息，传入的空列表表示没有需要忽略的检查
        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 设置工作流名称和作业名称，用于验证检查结果是否包含指定作业的分类为 "UNSTABLE"
        workflow_name = "linux-bionic-cuda12.1-py3.10-gcc9-bazel-test"
        job_name = "build-and-test (default, 1, 1, linux.4xlarge.nvidia.gpu, unstable)"
        # 断言指定作业的分类是否为 "UNSTABLE"
        self.assertTrue(
            checks[f"pull / {workflow_name} / {job_name}"].classification == "UNSTABLE"
        )
        # 对检查结果进行分类，获取待处理、失败和可忽略的检查
        pending, failed, ignorable = categorize_checks(
            checks, list(checks.keys()), ok_failed_checks_threshold=1
        )
        # 断言待处理检查数量为 0
        self.assertTrue(len(pending) == 0)
        # 断言失败检查数量为 0
        self.assertTrue(len(failed) == 0)
        # 断言可忽略的 UNSTABLE 类型检查数量为 1
        self.assertTrue(len(ignorable["UNSTABLE"]) == 1)

        # 添加另一个测试案例，其中作业名称中没有 "unstable" 关键字，但是作业已标记为不稳定状态
        pr = GitHubPR("pytorch", "executorch", 3318)
        # 获取与该 PR 相关的所有检查运行结果
        checks = pr.get_checkrun_conclusions()
        # 获取对应 PR 的分类信息，传入的空列表表示没有需要忽略的检查
        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 设置工作流名称和作业名称，用于验证检查结果是否包含指定作业的分类为 "UNSTABLE"
        workflow_name = "test-llama-app"
        job_name = "mobile-job (android)"
        # 断言指定作业的分类是否为 "UNSTABLE"
        self.assertTrue(
            checks[f"Android / {workflow_name} / {job_name}"].classification
            == "UNSTABLE"
        )
        # 对检查结果进行分类，获取待处理、失败和可忽略的检查
        pending, failed, ignorable = categorize_checks(
            checks, list(checks.keys()), ok_failed_checks_threshold=1
        )
        # 断言待处理检查数量为 0
        self.assertTrue(len(pending) == 0)
        # 断言失败检查数量为 0
        self.assertTrue(len(failed) == 0)
        # 断言可忽略的 UNSTABLE 类型检查数量为 1
        self.assertTrue(len(ignorable["UNSTABLE"]) == 1)
    # 定义一个测试方法，用于测试获取破损主干分类的情况
    def test_get_classifications_broken_trunk(self, *args: Any) -> None:
        # 设置测试用例列表，每个字典表示一个测试案例
        test_cases = [
            {
                # 此 PR 曾有一个破损主干失败，但在与基础提交不同的分片上运行。
                # 这种情况仍然应被视为破损主干
                "pr_num": 104214,
                "related_failure_count": 0,
                "flaky_or_broken_trunk": 1,
            },
            {
                # 此 PR 曾有一个破损主干失败，并且使用了 ghstack
                "pr_num": 105145,
                "related_failure_count": 0,
                "flaky_or_broken_trunk": 1,
            },
            {
                # 合并基础的失败已成功重试，
                # 结论从失败更改为成功。我们希望保留来自合并基础的失败记录，
                # 以便用于检测破损主干
                "pr_num": 107160,
                "related_failure_count": 0,
                "flaky_or_broken_trunk": 1,
            },
            {
                # 此 PR 使用了 Dr.CI 破损主干分类
                "pr_num": 111253,
                "related_failure_count": 1,
                "flaky_or_broken_trunk": 1,
            },
        ]

        # 对于每个测试案例进行迭代
        for case in test_cases:
            pr_num = case["pr_num"]
            related_failure_count = case["related_failure_count"]
            flaky_or_broken_trunk = case["flaky_or_broken_trunk"]

            # 根据项目和 PR 编号创建 GitHubPR 对象
            pr = GitHubPR("pytorch", "pytorch", pr_num)
            # 获取 PR 的检查运行结果
            checks = pr.get_checkrun_conclusions()
            # 获取分类结果，根据项目、检查运行结果和空列表
            checks = get_classifications(
                pr.pr_num,
                pr.project,
                checks,
                [],
            )

            # 将检查结果按照状态分类为 pending、failed 和 ignored
            pending, failed, _ = categorize_checks(checks, list(checks.keys()))
            # 断言没有 pending 的检查结果
            self.assertTrue(len(pending) == 0)
            # 断言 failed 的检查结果数量符合相关的失败计数
            self.assertTrue(len(failed) == related_failure_count)

            # 当 ok_failed_checks_threshold 设置为 0 时，破损主干失败不会被忽略
            pending, failed, _ = categorize_checks(
                checks, list(checks.keys()), ok_failed_checks_threshold=0
            )
            # 断言没有 pending 的检查结果
            self.assertTrue(len(pending) == 0)
            # 断言 failed 的检查结果数量符合破损主干和相关失败计数的总和
            self.assertTrue(
                len(failed) == flaky_or_broken_trunk + related_failure_count
            )
    # 定义一个测试方法，测试忽略当前检查的各种交互情况，确保忽略当前检查发生在其他分类（如不稳定、脆弱的主干等）之后：
    # 只有真正的新失败应保留在忽略当前检查列表中，以用于记录与实际失败的强制合并
    def test_ignore_current(self, *args: Any) -> None:
        # 已知的 flaky 失败优先于忽略当前检查（需要设置合并基础来获取 Rockset 的结果，并对主干脆弱失败进行分类）
        flaky = "pull / linux-focal-cuda11.8-py3.10-gcc9 / test (distributed, 1, 3, linux.8xlarge.nvidia.gpu)"
        broken_trunk = (
            "pull / linux-focal-py3.11-clang10 / test (dynamo, 1, 2, linux.2xlarge)"
        )

        # 创建 GitHubPR 对象来获取 Pull Request 信息
        pr = GitHubPR("pytorch", "pytorch", 109584)
        # 获取 PR 的检查运行结果
        checks = pr.get_checkrun_conclusions()

        # 调用 get_classifications 函数对检查结果进行分类，传入 broken_trunk 和 flaky 作为已知失败类型
        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [broken_trunk, flaky],
        )
        # 断言检查结果中 flaky 的分类为 "FLAKY"
        self.assertTrue(checks[flaky].classification == "FLAKY")
        # 断言检查结果中 broken_trunk 的分类为 "BROKEN_TRUNK"
        self.assertTrue(checks[broken_trunk].classification == "BROKEN_TRUNK")
        
        # 调用 categorize_checks 函数对检查结果进行进一步分类
        _, failed, ignorable = categorize_checks(checks, list(checks.keys()))
        # 断言失败检查列表长度为 0
        self.assertTrue(len(failed) == 0)
        # 断言忽略当前检查列表长度为 0
        self.assertTrue(len(ignorable["IGNORE_CURRENT_CHECK"]) == 0)
        # 断言 flaky 类型的忽略列表长度为 4
        self.assertTrue(len(ignorable["FLAKY"]) == 4)
        # 断言 broken_trunk 类型的忽略列表长度为 2
        self.assertTrue(len(ignorable["BROKEN_TRUNK"]) == 2)

    # 定义一个测试方法，测试当工作流名称错误时的情况
    def test_get_classifications_wrong_workflow_name(self, *args: Any) -> None:
        # 创建 GitHubPR 对象来获取 Pull Request 信息
        pr = GitHubPR("pytorch", "pytorch", 123104)
        # 获取 PR 的检查运行结果
        checks = pr.get_checkrun_conclusions()

        check_name = "linux-binary-conda / conda-py3_8-cuda11_8-build / build"
        check_name_workflow_path = ".github/workflows/generated-linux-binary-conda-nightly.yml / conda-py3_8-cuda11_8-build / build"

        # 模拟一个检查，其中工作流名称使用完整路径
        checks[check_name_workflow_path] = JobCheckState(
            check_name_workflow_path,
            checks[check_name].url,
            checks[check_name].status,
            checks[check_name].classification,
            checks[check_name].job_id,
            checks[check_name].title,
            checks[check_name].summary,
        )
        # 删除原来的检查
        del checks[check_name]

        # 调用 get_classifications 函数对检查结果进行分类，传入一个空列表作为已知失败类型
        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 调用 categorize_checks 函数对检查结果进行进一步分类
        pending, failed, ignorable = categorize_checks(
            checks,
            list(checks.keys()),
        )

        # 断言待处理列表长度为 0
        self.assertTrue(len(pending) == 0)
        # 断言失败列表长度为 0
        self.assertTrue(len(failed) == 0)
        # 断言 flaky 类型的忽略列表长度为 1
        self.assertTrue(len(ignorable["FLAKY"]) == 1)
        # 断言 broken_trunk 类型的忽略列表长度为 0
        self.assertTrue(len(ignorable["BROKEN_TRUNK"]) == 0)
    # 测试函数，验证在相同工作流中忽略失败的情况
    def test_ignore_failures_older_run_same_workflow(self, *args: Any) -> None:
        # 创建 GitHubPR 对象，表示来自 pytorch 仓库的 pull request 129013
        pr = GitHubPR("pytorch", "pytorch", 129013)
        # 获取 pull request 的检查运行结论
        checks = pr.get_checkrun_conclusions()
        # 获取对应的分类信息
        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 对检查结果进行分类，获取未决、失败和可忽略的信息
        pending, failed, ignorable = categorize_checks(
            checks,
            list(checks.keys()),
        )
        # 断言未决的检查数量为 0
        self.assertTrue(len(pending) == 0)
        # 断言失败的检查数量为 0
        self.assertTrue(len(failed) == 0)
        # 断言可忽略的 "FLAKY" 类型检查数量为 2
        self.assertTrue(len(ignorable["FLAKY"]) == 2)
        # 断言可忽略的 "UNSTABLE" 类型检查数量为 13
        self.assertTrue(len(ignorable["UNSTABLE"]) == 13)

    # 使用 mock.patch 装饰器模拟 read_merge_rules 函数的行为，返回 xla_merge_rules
    @mock.patch("trymerge.read_merge_rules", side_effect=xla_merge_rules)
    def test_dont_ignore_flaky_failures(self, *args: Any) -> None:
        """
        Regression test for https://github.com/pytorch/test-infra/issues/4126
        """
        # 创建 GitHubPR 对象，表示来自 pytorch 仓库的 pull request 105312
        pr = GitHubPR("pytorch", "pytorch", 105312)
        # 创建一个虚拟的 Git 仓库对象
        repo = DummyGitRepo()
        # 使用 warnings.catch_warnings 捕获警告，同时确保引发 RuntimeError 异常
        with warnings.catch_warnings(record=True) as w, self.assertRaises(RuntimeError):
            # 查找匹配的合并规则
            rule = find_matching_merge_rule(pr, repo)
        # 断言捕获的警告数量为 1
        self.assertEqual(len(w), 1)
        # 断言警告消息中包含特定的文本
        self.assertIn(
            "1 checks failed but were likely due flakiness or broken trunk",
            str(w[0].message),
        )
@mock.patch("trymerge.get_rockset_results", side_effect=mocked_rockset_results)
@mock.patch("trymerge.gh_graphql", side_effect=mocked_gh_graphql)
@mock.patch("trymerge.gh_fetch_merge_base", return_value="")
@mock.patch("trymerge.get_drci_classifications", return_value={})
# 使用 mock.patch 修饰器替换 trymerge 模块中的四个函数，确保测试时使用模拟数据

class TestBypassFailuresOnSandCastle(TestCase):
    def test_get_classifications(self, *args: Any) -> None:
        pr = GitHubPR("pytorch", "pytorch", 111467)
        # 创建 GitHubPR 对象，针对指定的项目和 PR 编号

        checks = pr.get_checkrun_conclusions()
        # 获取 PR 的所有检查运行结果

        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 对检查结果进行分类处理，返回分类后的结果

        pending, failed, ignorable = categorize_checks(checks, list(checks.keys()))
        # 根据检查结果和键列表对检查进行分类

        self.assertTrue(len(pending) == 0)
        # 断言没有待处理的检查

        self.assertTrue(len(failed) == 0)
        # 断言没有失败的检查

        self.assertTrue(len(ignorable["FLAKY"]) == 1)
        # 断言有一个可忽略的“FLAKY”类型的检查

        self.assertTrue(len(ignorable["BROKEN_TRUNK"]) == 1)
        # 断言有一个可忽略的“BROKEN_TRUNK”类型的检查

    def test_get_classifications_drci_checkrun_not_found(self, *args: Any) -> None:
        pr = GitHubPR("pytorch", "pytorch", 111467)
        # 创建 GitHubPR 对象，针对指定的项目和 PR 编号

        # No summary
        checks = pr.get_checkrun_conclusions()
        # 获取 PR 的所有检查运行结果

        checks[DRCI_CHECKRUN_NAME] = JobCheckState(
            DRCI_CHECKRUN_NAME,
            "",
            "NEUTRAL",
            None,
            1,
            "",
            None,
        )
        # 在检查结果中添加一个空的 Dr.CI 检查运行结果

        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 对检查结果进行分类处理，返回分类后的结果

        pending, failed, ignorable = categorize_checks(checks, list(checks.keys()))
        # 根据检查结果和键列表对检查进行分类

        self.assertTrue(len(pending) == 0)
        # 断言没有待处理的检查

        self.assertTrue(len(failed) == 2)
        # 断言有两个失败的检查

        # Empty summary
        checks = pr.get_checkrun_conclusions()
        # 获取 PR 的所有检查运行结果

        checks[DRCI_CHECKRUN_NAME] = JobCheckState(
            DRCI_CHECKRUN_NAME,
            "",
            "NEUTRAL",
            None,
            1,
            "",
            "",
        )
        # 在检查结果中添加一个空的 Dr.CI 检查运行结果

        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 对检查结果进行分类处理，返回分类后的结果

        pending, failed, ignorable = categorize_checks(checks, list(checks.keys()))
        # 根据检查结果和键列表对检查进行分类

        self.assertTrue(len(pending) == 0)
        # 断言没有待处理的检查

        self.assertTrue(len(failed) == 2)
        # 断言有两个失败的检查

        # No Dr.CI checkrun
        checks = pr.get_checkrun_conclusions()
        # 获取 PR 的所有检查运行结果

        del checks[DRCI_CHECKRUN_NAME]
        # 删除 Dr.CI 检查运行结果

        checks = get_classifications(
            pr.pr_num,
            pr.project,
            checks,
            [],
        )
        # 对检查结果进行分类处理，返回分类后的结果

        pending, failed, ignorable = categorize_checks(checks, list(checks.keys()))
        # 根据检查结果和键列表对检查进行分类

        self.assertTrue(len(pending) == 0)
        # 断言没有待处理的检查

        self.assertTrue(len(failed) == 2)
        # 断言有两个失败的检查


@mock.patch("trymerge.get_rockset_results", side_effect=mocked_rockset_results)
@mock.patch("trymerge.gh_graphql", side_effect=mocked_gh_graphql)
@mock.patch("trymerge.gh_fetch_merge_base", return_value="")
@mock.patch(
    "trymerge.get_drci_classifications", side_effect=mocked_drci_classifications
)
# 使用 mock.patch 修饰器替换 trymerge 模块中的四个函数，确保测试时使用模拟数据

class TestGitHubPRGhstackDependencies(TestCase):
    # 定义测试函数，验证 GitHub Pull Request 的依赖关系生成正确的提交消息
    def test_pr_dependencies(self, *args: Any) -> None:
        # 创建 GitHubPR 对象，指定仓库 "pytorch"，PR号为 106068
        pr = GitHubPR("pytorch", "pytorch", 106068)
        # 生成过滤 ghstack 的提交消息
        msg = pr.gen_commit_message(filter_ghstack=True)
        # 断言生成的消息与预期相等
        self.assertEqual(
            msg,
            f"{pr.get_title()} (#106068)\n\n{RE_GHSTACK_DESC.sub('', pr.get_body())}\n"
            "Pull Request resolved: https://github.com/pytorch/pytorch/pull/106068\n"
            "Approved by: https://github.com/ezyang, https://github.com/fegin\n",
        )

    # 定义测试函数，验证带有 ghstack 依赖的 GitHub Pull Request 的提交消息生成
    def test_pr_dependencies_ghstack(self, *args: Any) -> None:
        # 创建多个 GitHubPR 对象，每个对象代表一个依赖的 PR
        pr0 = GitHubPR("pytorch", "pytorch", 106032)
        pr1 = GitHubPR("pytorch", "pytorch", 106033)
        pr2 = GitHubPR("pytorch", "pytorch", 106034)
        pr = GitHubPR("pytorch", "pytorch", 106068)
        # 生成过滤 ghstack 的提交消息，并添加 ghstack 依赖信息
        msg = pr.gen_commit_message(filter_ghstack=True, ghstack_deps=[pr0, pr1, pr2])
        # 断言生成的消息与预期相等
        self.assertEqual(
            msg,
            f"{pr.get_title()} (#106068)\n\n{RE_GHSTACK_DESC.sub('', pr.get_body())}\n"
            "Pull Request resolved: https://github.com/pytorch/pytorch/pull/106068\n"
            "Approved by: https://github.com/ezyang, https://github.com/fegin\n"
            "ghstack dependencies: #106032, #106033, #106034\n",
        )

    # 标记当前测试跳过执行，并添加跳过原因
    @skip(
        reason="This test is run against a mutable PR that has changed, so it no longer works. The test should be changed"
    )
    # 使用 mock.patch 装饰器，模拟 read_merge_rules 函数
    @mock.patch("trymerge.read_merge_rules")
    # 使用 mock.patch 装饰器，模拟 GitRepo 类
    @mock.patch("trymerge.GitRepo")
    # 使用 mock.patch 装饰器，模拟 get_ghstack_prs 函数
    @mock.patch("trymerge.get_ghstack_prs")
    # 定义测试函数，验证将 ghstack 的 PR 合并到目标分支的功能
    def test_merge_ghstack_into(
        self,
        mock_get_ghstack_prs: mock.MagicMock,
        mock_repo: mock.MagicMock,
        mock_merge_rules: mock.MagicMock,
        *args: Any,
    ) -> None:
        """
        Test that the merge_ghstack_into method works correctly
        """
        # 创建四个 GitHubPR 对象，分别表示四个不同的 GitHub Pull Request
        pr0 = GitHubPR("pytorch", "pytorch", 106032)
        pr1 = GitHubPR("pytorch", "pytorch", 106033)
        pr2 = GitHubPR("pytorch", "pytorch", 106034)
        pr = GitHubPR("pytorch", "pytorch", 106068)

        # 设置 mock_get_ghstack_prs 方法的返回值，模拟获取的 GitHub PR 列表
        # 注意：顺序是反向的（例如 self.pr 是最后一个提交，堆栈顶部）
        mock_get_ghstack_prs.return_value = [
            (pr0, "rev0"),
            (pr1, "rev1"),
            (pr2, "rev2"),
            (pr, "rev123"),
        ]

        # 设置 mock_merge_rules 方法的返回值，模拟合并规则
        mock_merge_rules.return_value = [
            MergeRule(
                "Mock title", patterns=["*"], approved_by=[], mandatory_checks_name=None
            )
        ]

        # 设置 mock_repo.cherry_pick 方法的返回值为 None
        mock_repo.cherry_pick.return_value = None
        # 设置 mock_repo.amend_commit_message 方法的返回值为 None
        mock_repo.amend_commit_message.return_value = None

        # 调用待测试的方法 merge_ghstack_into
        res = pr.merge_ghstack_into(mock_repo, True)

        # 断言结果的正确性，期望返回 [pr2, pr]
        self.assertEqual(res, [pr2, pr])

        # 验证 cherry_pick 方法的调用情况
        mock_repo.cherry_pick.assert_any_call("rev2")
        mock_repo.cherry_pick.assert_any_call("rev123")

        # 断言不应该调用 "rev1" 的情况
        self.assertTrue(mock.call("rev1") not in mock_repo.cherry_pick.call_args_list)

        # 验证第一次调用 amend_commit_message 方法时的参数 message
        message = mock_repo.amend_commit_message.call_args_list[0].args[0]
        prefix = (
            "[FSDP] Optimize away intermediate `div_` for HSDP (#106034)\n\n\r\n"
            "### Background: Gradient Pre-Divide"
        )
        suffix = (
            "\nPull Request resolved: https://github.com/pytorch/pytorch/pull/106034\nApproved by: \nghstack "
            "dependencies: #106032, #106033\n"
        )

        self.assertTrue(message.startswith(prefix))
        self.assertTrue(message.endswith(suffix))

        # 验证第二次调用 amend_commit_message 方法时的参数 message
        mock_repo.amend_commit_message.assert_any_call(
            "[FSDP] Break up `_post_backward_hook` into smaller funcs (#106068)\n\n\n"
            "Differential Revision: ["
            "D47852461](https://our.internmc.facebook.com/intern/diff/D47852461)\n"
            "Pull Request resolved: "
            "https://github.com/pytorch/pytorch/pull/106068\n"
            "Approved by: \n"
            "ghstack dependencies: #106032, #106033, #106034\n"
        )
# 如果这个模块被直接运行而不是被导入到其他模块中，则执行以下代码
if __name__ == "__main__":
    # 调用 main 函数，这是习惯用法，用于执行程序的主要逻辑
    main()
```