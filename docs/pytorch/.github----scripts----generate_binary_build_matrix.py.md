# `.\pytorch\.github\scripts\generate_binary_build_matrix.py`

```
#!/usr/bin/env python3
# 设置脚本的解释器为 Python 3

"""Generates a matrix to be utilized through github actions

Will output a condensed version of the matrix if on a pull request that only
includes the latest version of python we support built on three different
architectures:
    * CPU
    * Latest CUDA
    * Latest ROCM
"""

import os
# 导入操作系统模块
from typing import Dict, List, Optional, Tuple
# 导入类型提示所需的模块

CUDA_ARCHES = ["11.8", "12.1", "12.4"]
# 定义 CUDA 架构版本列表

CUDA_ARCHES_FULL_VERSION = {"11.8": "11.8.0", "12.1": "12.1.1", "12.4": "12.4.0"}
# 定义完整的 CUDA 架构版本号字典

CUDA_ARCHES_CUDNN_VERSION = {"11.8": "9", "12.1": "9", "12.4": "9"}
# 定义 CUDA 架构对应的 cuDNN 版本号字典

ROCM_ARCHES = ["6.0", "6.1"]
# 定义 ROCM 架构版本列表

CPU_CXX11_ABI_ARCH = ["cpu-cxx11-abi"]
# 定义 CPU 架构版本列表（CXX11 ABI）

CPU_AARCH64_ARCH = ["cpu-aarch64"]
# 定义 CPU 架构版本列表（AARCH64）

CPU_S390X_ARCH = ["cpu-s390x"]
# 定义 CPU 架构版本列表（S390X）

CUDA_AARCH64_ARCH = ["cuda-aarch64"]
# 定义 CUDA 架构版本列表（AARCH64）

PYTORCH_EXTRA_INSTALL_REQUIREMENTS = {
    "11.8": (
        "nvidia-cuda-nvrtc-cu11==11.8.89; platform_system == 'Linux' and platform_machine == 'x86_64' | "  # noqa: B950
        "nvidia-cuda-runtime-cu11==11.8.89; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cuda-cupti-cu11==11.8.87; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cudnn-cu11==9.1.0.70; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cublas-cu11==11.11.3.6; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cufft-cu11==10.9.0.58; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-curand-cu11==10.3.0.86; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cusolver-cu11==11.4.1.48; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cusparse-cu11==11.7.5.86; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-nccl-cu11==2.20.5; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-nvtx-cu11==11.8.86; platform_system == 'Linux' and platform_machine == 'x86_64'"
    ),
    # PyTorch 额外安装要求，针对 CUDA 11.8 版本
    # "12.1" 版本的 NVIDIA CUDA 相关软件包依赖声明，适用于 Linux x86_64 平台
    "12.1": (
        "nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cuda-runtime-cu12==12.1.105; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cuda-cupti-cu12==12.1.105; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cudnn-cu12==9.1.0.70; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cublas-cu12==12.1.3.1; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cufft-cu12==11.0.2.54; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-curand-cu12==10.3.2.106; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cusolver-cu12==11.4.5.107; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cusparse-cu12==12.1.0.106; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-nccl-cu12==2.20.5; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-nvtx-cu12==12.1.105; platform_system == 'Linux' and platform_machine == 'x86_64'"
    ),
    # "12.4" 版本的 NVIDIA CUDA 相关软件包依赖声明，适用于 Linux x86_64 平台
    "12.4": (
        "nvidia-cuda-nvrtc-cu12==12.4.99; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cuda-runtime-cu12==12.4.99; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cuda-cupti-cu12==12.4.99; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cudnn-cu12==9.1.0.70; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cublas-cu12==12.4.2.65; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cufft-cu12==11.2.0.44; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-curand-cu12==10.3.5.119; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cusolver-cu12==11.6.0.99; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-cusparse-cu12==12.3.0.142; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-nccl-cu12==2.20.5; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-nvtx-cu12==12.4.99; platform_system == 'Linux' and platform_machine == 'x86_64' | "
        "nvidia-nvjitlink-cu12==12.4.99; platform_system == 'Linux' and platform_machine == 'x86_64'"
    ),
}

# 获取当前脚本的父目录的父目录的父目录中的 nccl 版本文件路径
def get_nccl_submodule_version() -> str:
    from pathlib import Path

    nccl_version_mk = (
        Path(__file__).absolute().parent.parent.parent
        / "third_party"
        / "nccl"
        / "nccl"
        / "makefiles"
        / "version.mk"
    )
    # 如果 nccl 版本文件路径不存在，则抛出运行时异常
    if not nccl_version_mk.exists():
        raise RuntimeError(
            "Please make sure that nccl submodule is checked out when importing this script"
        )
    # 读取 nccl 版本文件内容
    with nccl_version_mk.open("r") as f:
        content = f.read()
    # 初始化一个空字典用于存储版本号信息
    d = {}
    # 解析版本文件内容，提取以 "NCCL_" 开头的行，将其作为键值对存入字典 d 中
    for l in content.split("\n"):
        if not l.startswith("NCCL_"):
            continue
        (k, v) = l.split(":=")
        d[k.strip()] = v.strip()
    # 返回格式化的 NCCL 版本号
    return f"{d['NCCL_MAJOR']}.{d['NCCL_MINOR']}.{d['NCCL_PATCH']}"


# 获取给定架构版本的 NCCL wheel 版本
def get_nccl_wheel_version(arch_version: str) -> str:
    import re

    # 从 PYTORCH_EXTRA_INSTALL_REQUIREMENTS 中获取架构版本对应的要求列表
    requirements = map(
        str.strip, re.split("[;|]", PYTORCH_EXTRA_INSTALL_REQUIREMENTS[arch_version])
    )
    # 找到第一个以 "nvidia-nccl-cu" 开头的要求，并提取其版本号部分
    return next(x for x in requirements if x.startswith("nvidia-nccl-cu")).split("==")[1]


# 验证 NCCL 依赖一致性
def validate_nccl_dep_consistency(arch_version: str) -> None:
    # 获取 NCCL wheel 版本和 submodule 版本
    wheel_ver = get_nccl_wheel_version(arch_version)
    submodule_ver = get_nccl_submodule_version()
    # 如果两者版本号不一致，则抛出运行时异常
    if wheel_ver != submodule_ver:
        raise RuntimeError(
            f"NCCL submodule version {submodule_ver} differs from wheel version {wheel_ver}"
        )


# 根据架构版本返回架构类型
def arch_type(arch_version: str) -> str:
    if arch_version in CUDA_ARCHES:
        return "cuda"
    elif arch_version in ROCM_ARCHES:
        return "rocm"
    elif arch_version in CPU_CXX11_ABI_ARCH:
        return "cpu-cxx11-abi"
    elif arch_version in CPU_AARCH64_ARCH:
        return "cpu-aarch64"
    elif arch_version in CPU_S390X_ARCH:
        return "cpu-s390x"
    elif arch_version in CUDA_AARCH64_ARCH:
        return "cuda-aarch64"
    else:  # 在这种情况下，arch_version 应始终为 "cpu"
        return "cpu"


# 默认标签，如果环境变量 RELEASE_VERSION_TAG 未设置，则使用 "main"
DEFAULT_TAG = os.getenv("RELEASE_VERSION_TAG", "main")

# WHEEL_CONTAINER_IMAGES 字典，包含不同架构对应的镜像版本
WHEEL_CONTAINER_IMAGES = {
    **{
        gpu_arch: f"pytorch/manylinux-builder:cuda{gpu_arch}-{DEFAULT_TAG}"
        for gpu_arch in CUDA_ARCHES
    },
    **{
        gpu_arch: f"pytorch/manylinux-builder:rocm{gpu_arch}-{DEFAULT_TAG}"
        for gpu_arch in ROCM_ARCHES
    },
    "cpu": f"pytorch/manylinux-builder:cpu-{DEFAULT_TAG}",
    "cpu-cxx11-abi": f"pytorch/manylinuxcxx11-abi-builder:cpu-cxx11-abi-{DEFAULT_TAG}",
    "cpu-aarch64": f"pytorch/manylinuxaarch64-builder:cpu-aarch64-{DEFAULT_TAG}",
    "cpu-s390x": f"pytorch/manylinuxs390x-builder:cpu-s390x-{DEFAULT_TAG}",
    "cuda-aarch64": f"pytorch/manylinuxaarch64-builder:cuda12.4-{DEFAULT_TAG}",
}

# CONDA_CONTAINER_IMAGES 字典，包含不同架构对应的 Conda 镜像版本
CONDA_CONTAINER_IMAGES = {
    **{
        gpu_arch: f"pytorch/conda-builder:cuda{gpu_arch}-{DEFAULT_TAG}"
        for gpu_arch in CUDA_ARCHES
    },
    "cpu": f"pytorch/conda-builder:cpu-{DEFAULT_TAG}",
}

# 预定义常量，表示不同 ABI 版本和发布模式
PRE_CXX11_ABI = "pre-cxx11"
CXX11_ABI = "cxx11-abi"
RELEASE = "release"
DEBUG = "debug"
# 定义一个字典，映射每种 GPU 架构及 ABI 版本到对应的 LibTorch 容器镜像地址
LIBTORCH_CONTAINER_IMAGES: Dict[Tuple[str, str], str] = {
    **{
        (
            gpu_arch,
            PRE_CXX11_ABI,
        ): f"pytorch/manylinux-builder:cuda{gpu_arch}-{DEFAULT_TAG}"
        for gpu_arch in CUDA_ARCHES
    },
    **{
        (
            gpu_arch,
            CXX11_ABI,
        ): f"pytorch/libtorch-cxx11-builder:cuda{gpu_arch}-{DEFAULT_TAG}"
        for gpu_arch in CUDA_ARCHES
    },
    **{
        (
            gpu_arch,
            PRE_CXX11_ABI,
        ): f"pytorch/manylinux-builder:rocm{gpu_arch}-{DEFAULT_TAG}"
        for gpu_arch in ROCM_ARCHES
    },
    **{
        (
            gpu_arch,
            CXX11_ABI,
        ): f"pytorch/libtorch-cxx11-builder:rocm{gpu_arch}-{DEFAULT_TAG}"
        for gpu_arch in ROCM_ARCHES
    },
    ("cpu", PRE_CXX11_ABI): f"pytorch/manylinux-builder:cpu-{DEFAULT_TAG}",
    ("cpu", CXX11_ABI): f"pytorch/libtorch-cxx11-builder:cpu-{DEFAULT_TAG}",
}

FULL_PYTHON_VERSIONS = ["3.8", "3.9", "3.10", "3.11", "3.12"]


def translate_desired_cuda(gpu_arch_type: str, gpu_arch_version: str) -> str:
    # 根据 GPU 架构类型和版本映射到对应的 CUDA 版本或 ROCm 版本
    return {
        "cpu": "cpu",
        "cpu-aarch64": "cpu",
        "cpu-cxx11-abi": "cpu-cxx11-abi",
        "cpu-s390x": "cpu",
        "cuda": f"cu{gpu_arch_version.replace('.', '')}",
        "cuda-aarch64": "cu124",
        "rocm": f"rocm{gpu_arch_version}",
    }.get(gpu_arch_type, gpu_arch_version)


def list_without(in_list: List[str], without: List[str]) -> List[str]:
    # 从输入列表中去除指定的元素列表，返回新列表
    return [item for item in in_list if item not in without]


def generate_conda_matrix(os: str) -> List[Dict[str, str]]:
    ret: List[Dict[str, str]] = []
    arches = ["cpu"]
    python_versions = FULL_PYTHON_VERSIONS
    if os == "linux" or os == "windows":
        arches += CUDA_ARCHES
    for python_version in python_versions:
        # 对于每个 Python 版本，生成对应的 Conda 构建矩阵
        for arch_version in arches:
            gpu_arch_type = arch_type(arch_version)  # 获取 GPU 架构类型
            gpu_arch_version = "" if arch_version == "cpu" else arch_version  # 获取 GPU 架构版本
            ret.append(
                {
                    "python_version": python_version,
                    "gpu_arch_type": gpu_arch_type,
                    "gpu_arch_version": gpu_arch_version,
                    "desired_cuda": translate_desired_cuda(
                        gpu_arch_type, gpu_arch_version
                    ),  # 获取期望的 CUDA 版本或 ROCm 版本
                    "container_image": CONDA_CONTAINER_IMAGES[arch_version],  # 使用的 Conda 容器镜像
                    "package_type": "conda",
                    "build_name": f"conda-py{python_version}-{gpu_arch_type}{gpu_arch_version}".replace(
                        ".", "_"
                    ),  # 构建名称
                }
            )
    return ret


def generate_libtorch_matrix(
    os: str,
    abi_version: str,
    arches: Optional[List[str]] = None,
    libtorch_variants: Optional[List[str]] = None,
) -> List[Dict[str, str]]:
    # 生成 LibTorch 构建矩阵，包括操作系统、ABI 版本、GPU 架构和 LibTorch 变体
    pass  # 函数未实现内容，暂时留空
    # 如果未提供 arches 参数，则默认为 ["cpu"]
    if arches is None:
        arches = ["cpu"]
        # 根据操作系统类型 os 进行不同的处理
        if os == "linux":
            # 如果是 Linux 操作系统，则在默认 arches 列表后添加 CUDA 架构和 ROCm 架构
            arches += CUDA_ARCHES
            arches += ROCM_ARCHES
        elif os == "windows":
            # 如果是 Windows 操作系统，则只在默认 arches 列表后添加 CUDA 架构
            arches += CUDA_ARCHES

    # 如果未提供 libtorch_variants 参数，则默认为指定的四种变体
    if libtorch_variants is None:
        libtorch_variants = [
            "shared-with-deps",
            "shared-without-deps",
            "static-with-deps",
            "static-without-deps",
        ]

    # 初始化一个空列表 ret 用于存储结果
    ret: List[Dict[str, str]] = []

    # 遍历 arches 和 libtorch_variants 所有可能的组合
    for arch_version in arches:
        for libtorch_variant in libtorch_variants:
            # 根据 arch_version 获取 GPU 架构类型
            gpu_arch_type = arch_type(arch_version)
            # 如果 arch_version 是 "cpu"，则 gpu_arch_version 留空字符串；否则与 arch_version 相同
            gpu_arch_version = "" if arch_version == "cpu" else arch_version

            # 如果 GPU 架构类型是 "rocm" 并且 libtorch_variant 包含 "without-deps"，则跳过当前组合
            if gpu_arch_type == "rocm" and "without-deps" in libtorch_variant:
                continue

            # 构建一个字典，包含当前组合的各项信息
            ret.append(
                {
                    "gpu_arch_type": gpu_arch_type,
                    "gpu_arch_version": gpu_arch_version,
                    "desired_cuda": translate_desired_cuda(
                        gpu_arch_type, gpu_arch_version
                    ),
                    "libtorch_variant": libtorch_variant,
                    "libtorch_config": abi_version if os == "windows" else "",
                    "devtoolset": abi_version if os != "windows" else "",
                    "container_image": (
                        LIBTORCH_CONTAINER_IMAGES[(arch_version, abi_version)]
                        if os != "windows"
                        else ""
                    ),
                    "package_type": "libtorch",
                    "build_name": f"libtorch-{gpu_arch_type}{gpu_arch_version}-{libtorch_variant}-{abi_version}".replace(
                        ".", "_"
                    ),
                }
            )

    # 返回存储所有组合结果的列表 ret
    return ret
# 定义一个函数生成轮子矩阵，用于不同操作系统和架构下的Python包管理
def generate_wheels_matrix(
    os: str,
    arches: Optional[List[str]] = None,
    python_versions: Optional[List[str]] = None,
) -> List[Dict[str, str]]:
    # 默认包类型为 "wheel"
    package_type = "wheel"
    
    # 如果操作系统是特定的 Linux 架构，指定包类型为 "manywheel"
    if os == "linux" or os == "linux-aarch64" or os == "linux-s390x":
        # 注意: 我们只为 x86_64、aarch64 和 s390x 的 Linux 架构构建 manywheel 包
        package_type = "manywheel"

    # 如果未提供 Python 版本列表，则使用全局定义的版本列表 FULL_PYTHON_VERSIONS
    if python_versions is None:
        python_versions = FULL_PYTHON_VERSIONS

    # 如果未提供架构列表，则根据操作系统设定默认的计算架构
    if arches is None:
        # 定义默认的计算架构为 "cpu"
        arches = ["cpu"]
        
        # 根据操作系统添加特定的计算架构
        if os == "linux":
            arches += CPU_CXX11_ABI_ARCH + CUDA_ARCHES + ROCM_ARCHES
        elif os == "windows":
            arches += CUDA_ARCHES
        elif os == "linux-aarch64":
            # 对于 aarch64 架构，只包含一个 cpu-aarch64 和 cuda-aarch64
            arches = ["cpu-aarch64", "cuda-aarch64"]
        elif os == "linux-s390x":
            # 对于 s390x 架构，只包含一个 cpu-s390x
            arches = ["cpu-s390x"]

    # 初始化返回的矩阵为空列表
    ret: List[Dict[str, str]] = []
    return ret


# 验证依赖关系是否一致，传入的参数为版本号字符串
validate_nccl_dep_consistency("12.4")
validate_nccl_dep_consistency("12.1")
validate_nccl_dep_consistency("11.8")
```