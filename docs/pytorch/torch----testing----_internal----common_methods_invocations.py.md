# `.\pytorch\torch\testing\_internal\common_methods_invocations.py`

```
# 忽略类型检查错误，通常用于类型检查时遇到的特定情况
# 从 functools 模块导入 wraps 和 partial 函数
from functools import wraps, partial
# 从 itertools 模块导入 product, chain, islice 函数
from itertools import product, chain, islice
# 导入 itertools 模块的所有内容
import itertools
# 导入 functools 模块的所有内容
import functools
# 导入 copy 模块
import copy
# 导入 operator 模块
import operator
# 导入 random 模块
import random
# 导入 unittest 模块
import unittest
# 导入 math 模块
import math
# 导入 enum 模块
import enum

# 导入 torch 模块
import torch
# 导入 numpy 模块，并使用 np 作为别名
import numpy as np
# 从 torch 模块中导入 inf 和 nan 常量
from torch import inf, nan

# 从 typing 模块中导入类型相关的声明
from typing import Any, Dict, List, Tuple, Union, Sequence
# 从 torch.testing 模块中导入 make_tensor 函数
from torch.testing import make_tensor
# 从 torch.testing._internal.common_dtype 模块中导入一系列类型相关的声明和函数
from torch.testing._internal.common_dtype import (
    _dispatch_dtypes, floating_types, floating_types_and, complex_types, floating_and_complex_types,
    floating_and_complex_types_and, all_types_and_complex_and, all_types_and, all_types_and_complex, integral_types_and,
    all_types, empty_types, complex_types_and, integral_types, custom_types,
)
# 从 torch.testing._internal.common_device_type 模块中导入一系列设备类型相关的声明和函数
from torch.testing._internal.common_device_type import \
    (onlyCPU, onlyCUDA, onlyNativeDeviceTypes, disablecuDNN, skipCUDAIfNoMagma, skipCUDAIfNoMagmaAndNoCusolver,
     skipCUDAIfNoCusolver, skipCPUIfNoLapack, skipCPUIfNoFFT, skipCUDAIf, precisionOverride,
     skipCPUIfNoMklSparse,
     toleranceOverride, tol)
# 从 torch.testing._internal.common_cuda 模块中导入一系列 CUDA 相关的声明和函数
from torch.testing._internal.common_cuda import (
    PLATFORM_SUPPORTS_FLASH_ATTENTION, PLATFORM_SUPPORTS_FUSED_ATTENTION, PLATFORM_SUPPORTS_MEM_EFF_ATTENTION,
    SM53OrLater, SM80OrLater, SM90OrLater, with_tf32_off, TEST_CUDNN, _get_torch_cuda_version,
    _get_torch_rocm_version,
)
# 从 torch.testing._internal.common_utils 模块中导入一系列通用工具函数和声明
from torch.testing._internal.common_utils import (
    make_fullrank_matrices_with_distinct_singular_values,
    TEST_WITH_ROCM, IS_WINDOWS, IS_MACOS, TEST_SCIPY,
    torch_to_numpy_dtype_dict, numpy_to_torch_dtype, TEST_WITH_ASAN,
    GRADCHECK_NONDET_TOL, slowTest, TEST_WITH_SLOW,
    TEST_WITH_TORCHINDUCTOR
)
# 从 torch.testing._utils 模块中导入 wrapper_set_seed 函数
from torch.testing._utils import wrapper_set_seed

# 导入 torch._refs 和 torch._prims 模块的特定内容，忽略未使用的警告
import torch._refs as refs  # noqa: F401
import torch._refs.nn.functional
import torch._refs.special
import torch._refs.linalg
import torch._prims as prims  # noqa: F401
# 从 torch.utils 模块中导入 _pytree 模块
from torch.utils import _pytree as pytree

# 导入 version 函数，用于版本检查
from packaging import version

# 从 torch.testing._internal.opinfo.core 模块中导入一系列核心操作信息相关的声明和函数，忽略未使用的警告
from torch.testing._internal.opinfo.core import (  # noqa: F401
    L,
    M,
    S,
    XS,
    _NOTHING,
    _getattr_qual,
    DecorateInfo,
    SampleInput,
    ErrorInput,
    AliasInfo,
    NumericsFilter,
    OpInfo,
    _generate_reduction_inputs,
    _generate_reduction_kwargs,
    sample_inputs_reduction,
    ReductionOpInfo,
    reference_inputs_elementwise_binary,
    make_error_inputs_elementwise_binary,
    generate_elementwise_binary_tensors,
    generate_elementwise_binary_arbitrarily_strided_tensors,
    generate_elementwise_binary_small_value_tensors,
    generate_elementwise_binary_large_value_tensors,
    generate_elementwise_binary_extremal_value_tensors,
    generate_elementwise_binary_broadcasting_tensors,
    generate_elementwise_binary_with_scalar_samples,
    generate_elementwise_binary_with_scalar_and_type_promotion_samples,
    generate_elementwise_binary_noncontiguous_tensors,
    sample_inputs_elementwise_binary,
    BinaryUfuncInfo,
    sample_inputs_elementwise_unary,
)
    # 导入生成各种元素级一元操作张量的函数
    generate_elementwise_unary_tensors,
    # 导入生成小值元素级一元操作张量的函数
    generate_elementwise_unary_small_value_tensors,
    # 导入生成大值元素级一元操作张量的函数
    generate_elementwise_unary_large_value_tensors,
    # 导入生成极端值元素级一元操作张量的函数
    generate_elementwise_unary_extremal_value_tensors,
    # 导入元素级一元操作的参考输入
    reference_inputs_elementwise_unary,
    # 定义一元通用函数信息类
    UnaryUfuncInfo,
    # 导入光谱操作的示例输入
    sample_inputs_spectral_ops,
    # 定义光谱函数类型枚举
    SpectralFuncType,
    # 定义光谱函数信息类
    SpectralFuncInfo,
    # 定义形状函数信息类
    ShapeFuncInfo,
    # 导入foreach操作的示例输入
    sample_inputs_foreach,
    # 定义foreach函数信息类
    ForeachFuncInfo,
    # 包装具有厄米特输入的梯度检查函数
    gradcheck_wrapper_hermitian_input,
    # 包装具有三角形输入的梯度检查函数
    gradcheck_wrapper_triangular_input,
    # 包装具有实正对角线的三角形输入的梯度检查函数
    gradcheck_wrapper_triangular_input_real_positive_diagonal,
    # 包装具有掩码操作的梯度检查函数
    gradcheck_wrapper_masked_operation,
    # 包装具有掩码逐点操作的梯度检查函数
    gradcheck_wrapper_masked_pointwise_operation,
    # 复制示例
    clone_sample,
# 导入必要的模块和函数
from torch.testing._internal.opinfo.refs import (
    _find_referenced_opinfo,  # 导入操作信息查找函数
    _inherit_constructor_args,  # 导入构造函数参数继承函数
    PythonRefInfo,  # Python 参考信息类
    ReductionPythonRefInfo,  # 减少操作的 Python 参考信息类
    ElementwiseUnaryPythonRefInfo,  # 单元素操作的 Python 参考信息类
    ElementwiseBinaryPythonRefInfo,  # 二元素操作的 Python 参考信息类
)
from torch.testing._internal.opinfo.utils import (
    np_unary_ufunc_integer_promotion_wrapper,  # NumPy 单目整数推广包装器
    reference_reduction_numpy,  # NumPy 参考减少操作
    prod_numpy  # NumPy 乘积函数
)
from torch.testing._internal import opinfo  # 导入操作信息模块
from torch.testing._internal.opinfo.definitions.linalg import (
    sample_inputs_linalg_cholesky,  # 线性代数 Cholesky 分解的示例输入
    sample_inputs_linalg_cholesky_inverse,  # 线性代数 Cholesky 逆的示例输入
    sample_inputs_cross,  # 向量叉积的示例输入
    sample_inputs_linalg_qr_geqrf,  # 线性代数 QR 分解的示例输入
    sample_inputs_linalg_invertible,  # 线性代数可逆性的示例输入
    sample_inputs_lu_solve,  # LU 分解求解的示例输入
    sample_inputs_legacy_solve,  # 遗留求解的示例输入
    sample_inputs_svd,  # 奇异值分解的示例输入
    sample_inputs_linalg_det_logdet_slogdet,  # 行列式、对数行列式、符号行列式的示例输入
    sample_inputs_linalg_lu,  # 线性代数 LU 分解的示例输入
    sample_inputs_diagonal_diag_embed,  # 对角线和 diag_embed 操作的示例输入
    error_inputs_diagonal_diag_embed,  # 对角线和 diag_embed 操作的错误输入
)
from torch.testing._internal.opinfo.definitions.special import (
    sample_inputs_i0_i1,  # i0 和 i1 特殊函数的示例输入
    sample_inputs_polygamma,  # polygamma 函数的示例输入
    reference_polygamma,  # polygamma 函数的参考实现
)
from torch.testing._internal.opinfo.definitions._masked import (
    sample_inputs_softmax_variant,  # softmax 变体的示例输入
)
from torch.testing._internal.opinfo.definitions.sparse import (
    error_inputs_sparse_like_fns,  # 稀疏函数类似的错误输入
    sample_inputs_sparse_like_fns,  # 稀疏函数类似的示例输入
    error_inputs_sparse_mul,  # 稀疏乘法的错误输入
    sample_inputs_sparse_mul,  # 稀疏乘法的示例输入
    error_inputs_sparse_reduction_sum,  # 稀疏求和的错误输入
    sample_inputs_sparse_reduction_sum  # 稀疏求和的示例输入
)

# 如果启用了测试 SCIPY，则导入相关模块
if TEST_SCIPY:
    from scipy import stats  # 导入 scipy 的统计模块
    import scipy.spatial  # 导入 scipy 的空间模块
    import scipy.special  # 导入 scipy 的特殊函数模块


# 检查张量是否接近整数
def close_to_int(x, eps=0.1):
    if x.is_complex():
        y = torch.abs(torch.view_as_complex(torch.frac(torch.view_as_real(x))))
    else:
        y = torch.abs(torch.frac(x))
    return (y < eps) | (y > (1 - eps))


# 生成切片操作的示例输入
def sample_inputs_slice(op_info, device, dtype, requires_grad, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype,
                         low=None, high=None, requires_grad=requires_grad)

    # 返回不同参数下的切片示例输入
    yield SampleInput(make_input(3), 0)

    yield SampleInput(make_input(20, 30, 40), dim=1, start=1, end=-2)

    yield SampleInput(make_input(20, 30, 40), dim=1, start=1, end=-2, step=3)

    yield SampleInput(make_input(20, 30, 40), dim=0, start=-10, end=-2, step=2)


# 生成张量分割操作的示例输入
def sample_inputs_tensor_split(op_info, device, dtype, requires_grad, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype,
                         low=None, high=None, requires_grad=requires_grad)

    # 不同情况下的张量分割示例输入
    args_cases = (
        # 使用张量索引的情况
        (torch.tensor([1, 2, 3]),),
        (torch.tensor(1),),
        (torch.tensor([1, 2, 3]), 1),
        (torch.tensor([1, 4, 2, 5, 3, 6])[::2], 1),
        # 使用索引列表的情况
        ((2, 4),),
        ((2, 4), 1),
        ((2, 4), -1),
        # 使用整数段的情况
        (3,),
        (3, 1),
        (3, -1),
    )

    for args in args_cases:
        yield SampleInput(make_input((S, S, S)), args=args)
# 定义函数 sample_inputs_hsplit，生成水平分割操作的输入样本
def sample_inputs_hsplit(op_info, device, dtype, requires_grad, **kwargs):
    # 创建局部函数 make_arg，用于生成指定设备和数据类型的张量，并指定梯度需求
    make_arg = partial(make_tensor, dtype=dtype, device=device,
                       low=None, high=None, requires_grad=requires_grad)
    # 生成并返回两个 SampleInput 对象，分别表示不同形状和分割参数的输入样本
    yield SampleInput(make_arg(6), 2)
    yield SampleInput(make_arg(S, S, S), [1, 2, 3])

# 定义函数 sample_inputs_vsplit，生成垂直分割操作的输入样本
def sample_inputs_vsplit(op_info, device, dtype, requires_grad, **kwargs):
    # 创建局部函数 make_arg，用于生成指定设备和数据类型的张量，并指定梯度需求
    make_arg = partial(make_tensor, dtype=dtype, device=device,
                       low=None, high=None, requires_grad=requires_grad)
    # 生成并返回两个 SampleInput 对象，分别表示不同形状和分割参数的输入样本
    yield SampleInput(make_arg(6, S), 2)
    yield SampleInput(make_arg(S, S, S), [1, 2, 3])

# 定义函数 sample_inputs_dsplit，生成深度分割操作的输入样本
def sample_inputs_dsplit(op_info, device, dtype, requires_grad, **kwargs):
    # 创建局部函数 make_arg，用于生成指定设备和数据类型的张量，并指定梯度需求
    make_arg = partial(make_tensor, dtype=dtype, device=device,
                       low=None, high=None, requires_grad=requires_grad)
    # 生成并返回两个 SampleInput 对象，分别表示不同形状和分割参数的输入样本
    yield SampleInput(make_arg(S, S, S), [1, 2, 3])
    yield SampleInput(make_arg(S, S, 6), 2)

# 定义函数 error_inputs_hsplit，生成水平分割操作的错误输入样本
def error_inputs_hsplit(op_info, device, **kwargs):
    # 创建局部函数 make_arg，用于生成指定设备和默认数据类型的张量
    make_arg = partial(make_tensor, dtype=torch.float32, device=device)
    # 定义错误信息字符串1，指示当传入的张量维度为零时的错误情况
    err_msg1 = ("torch.hsplit requires a tensor with at least 1 dimension, "
                "but got a tensor with 0 dimensions!")
    # 生成并返回一个 ErrorInput 对象，用于测试零维张量的错误处理
    yield ErrorInput(SampleInput(make_arg(()), 0), error_regex=err_msg1)

    # 定义错误信息字符串2，指示当尝试沿第一维度分割且维度大小不能被分割尺寸整除时的错误情况
    err_msg2 = (f"torch.hsplit attempted to split along dimension 1, "
                f"but the size of the dimension {S} "
                f"is not divisible by the split_size 0!")
    # 生成并返回一个 ErrorInput 对象，用于测试维度大小不可被分割尺寸整除的错误处理
    yield ErrorInput(SampleInput(make_arg((S, S, S)), 0), error_regex=err_msg2)

    # 定义错误信息字符串3，指示当传入错误类型的 indices_or_section 参数时的错误情况
    err_msg3 = ("received an invalid combination of arguments.")
    # 生成并返回一个 ErrorInput 对象，用于测试传入错误类型的 indices_or_section 的错误处理
    yield ErrorInput(
        SampleInput(make_arg((S, S, S)), "abc"),
        error_type=TypeError, error_regex=err_msg3)

# 定义函数 error_inputs_vsplit，生成垂直分割操作的错误输入样本
def error_inputs_vsplit(op_info, device, **kwargs):
    # 创建局部函数 make_arg，用于生成指定设备和默认数据类型的张量
    make_arg = partial(make_tensor, dtype=torch.float32, device=device)
    # 定义错误信息字符串1，指示当传入的张量维度不足两个时的错误情况
    err_msg1 = ("torch.vsplit requires a tensor with at least 2 dimension, "
                "but got a tensor with 1 dimensions!")
    # 生成并返回一个 ErrorInput 对象，用于测试维度不足两个的张量的错误处理
    yield ErrorInput(SampleInput(make_arg(S), 0), error_regex=err_msg1)

    # 定义错误信息字符串2，指示当尝试沿第零维度分割且维度大小不能被分割尺寸整除时的错误情况
    err_msg2 = (f"torch.vsplit attempted to split along dimension 0, "
                f"but the size of the dimension {S} "
                f"is not divisible by the split_size 0!")
    # 生成并返回一个 ErrorInput 对象，用于测试维度大小不可被分割尺寸整除的错误处理
    yield ErrorInput(SampleInput(make_arg(S, S, S), 0),
                     error_regex=err_msg2)

    # 定义错误信息字符串3，指示当传入错误类型的 indices_or_section 参数时的错误情况
    err_msg3 = ("received an invalid combination of arguments.")
    # 生成并返回一个 ErrorInput 对象，用于测试传入错误类型的 indices_or_section 的错误处理
    yield ErrorInput(SampleInput(make_arg(S, S, S), "abc"),
                     error_type=TypeError, error_regex=err_msg3)

# 定义函数 error_inputs_dsplit，生成深度分割操作的错误输入样本
def error_inputs_dsplit(op_info, device, **kwargs):
    # 创建局部函数 make_arg，用于生成指定设备和默认数据类型的张量
    make_arg = partial(make_tensor, dtype=torch.float32, device=device)
    # 定义错误信息字符串1，指示当传入的张量维度不足三个时的错误情况
    err_msg1 = ("torch.dsplit requires a tensor with at least 3 dimension, "
                "but got a tensor with 1 dimensions!")
    # 生成并返回一个 ErrorInput 对象，用于测试维度不足三个的张量的错误处理
    yield ErrorInput(SampleInput(make_arg(S), 0), error_regex=err_msg1)
    # 构建错误消息字符串，指示尝试在第二维度上使用 torch.dsplit 进行分割，但维度 S 的大小
    # 不能被 split_size 0 整除！
    err_msg2 = (f"torch.dsplit attempted to split along dimension 2, "
                f"but the size of the dimension {S} "
                f"is not divisible by the split_size 0!")
    # 生成一个 ErrorInput 对象的生成器，表示错误的输入情况，包括了错误消息的正则表达式匹配
    yield ErrorInput(SampleInput(make_arg(S, S, S), 0), error_regex=err_msg2)
# 定义一个函数，生成具有指定参数的张量，作为生成器的部分参数
def sample_inputs_as_strided(op_info, device, dtype, requires_grad, **kwargs):
    # 创建生成张量的部分函数，设定设备、数据类型、梯度需求等参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义测试用例，每个元组包含输入形状、输出形状、输出步幅、输出存储偏移
    test_cases = (
        ((1,), (1,), (1,), 0),
        ((3, 3), (2, 2), (1, 2), 0),
        ((3, 3), (2, 2), (1, 2), 1),
        ((16,), (2, 2, 2, 2), (1, 1, 1, 1), 0),
        ((16,), (2, 1, 1, 2), (1, 7, 7, 1), 0),
    )

    # 遍历测试用例
    for input_shape, output_shape, stride, storage_offset in test_cases:
        # 生成输入张量
        input_t = make_arg(input_shape)
        # 准备关键字参数字典，设置存储偏移
        kwargs = dict(storage_offset=storage_offset)
        # 返回一个生成器，生成 SampleInput 对象，其中包含输入张量、位置参数（输出形状、输出步幅）、关键字参数（存储偏移）
        yield SampleInput(input_t, args=(output_shape, stride), kwargs=kwargs)


# 定义另一个函数，生成部分视图的张量作为生成器的部分参数
def sample_inputs_as_strided_partial_views(op_info, device, dtype, requires_grad, **kwargs):
    # 内部函数，创建部分视图的张量
    def make_arg():
        # 生成基础张量
        base = make_tensor((20,), device=device, dtype=dtype)
        # 返回索引为 5 到 14 的部分视图，并指定是否需要梯度
        return base[5:15].requires_grad_(requires_grad)

    # 返回生成器，生成 SampleInput 对象，其中包含部分视图的张量、位置参数（输出形状、输出步幅）、关键字参数（存储偏移）
    yield SampleInput(make_arg(), (2, 2), (1, 2))
    yield SampleInput(make_arg(), (2, 2), (1, 2), storage_offset=0)
    yield SampleInput(make_arg(), (2, 2), (1, 2), storage_offset=10)


# 定义另一个函数，执行scatter操作的张量生成器
def sample_inputs_as_strided_scatter(op_info, device, dtype, requires_grad, **kwargs):
    # 创建生成张量的部分函数，设定设备、数据类型、梯度需求等参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义测试用例，每个元组包含输入形状、输出形状、输出步幅、输出存储偏移
    test_cases = [
        ((1,), (), (), 0),
        ((1,), (1,), (1,), 0),
        ((3, 3), (2, 2), (1, 2), 0),
        ((3, 3), (2, 2), (1, 2), 1),
        ((3, 3), (2, 2), (2, 1), 0),
        # 扩展到更大的维度
        ((16,), (2, 2, 2, 2), (8, 4, 2, 1), 0),
        # 扩展到更大的维度，步幅反转
        ((16,), (2, 1, 1, 2), (1, 2, 4, 8), 0),
    ]

    # 遍历测试用例
    for input_shape, output_shape, stride, storage_offset in test_cases:
        # 生成输入张量
        input_t = make_arg(input_shape)
        # 生成输出形状的源张量
        input_src = make_arg(output_shape)
        # 返回一个生成器，生成 SampleInput 对象，其中包含输入张量、输入源张量、位置参数（输出形状、输出步幅）、关键字参数（存储偏移）
        yield SampleInput(input_t, input_src, output_shape, stride, storage_offset=storage_offset)


# 定义一个函数，生成错误情况的张量输入
def error_inputs_as_strided_scatter(op_info, device, **kwargs):
    # 创建生成张量的部分函数，设定设备、数据类型、梯度需求等参数
    make_arg = partial(make_tensor, device=device, dtype=torch.float32, requires_grad=False)

    # 创建一个小张量，并尝试在超出边界时进行scatter操作
    input_t = make_arg([4, 4])
    input_src = make_arg([2, 2])
    # 返回一个生成器，生成 ErrorInput 对象，其中包含 SampleInput 对象和预期的错误正则表达式
    yield ErrorInput(
        SampleInput(input_t, input_src, [2, 2], [200, 200], storage_offset=0),
        error_regex="itemsize 4 requiring a storage size of 1604 are out of bounds for storage of size 64"
    )


# 定义一个函数，生成组合参数的张量输入
def sample_inputs_combinations(op_info, device, dtype, requires_grad, **kwargs):
    # 输入值的不同组合
    inputs = (
        (0,),
        (0, 1),
        (0, 1, 2, 3),
    )

    # 返回值的不同值
    rvals = [1, 2, 4]

    # 参数的所有可能组合
    products = product(inputs, rvals, [False, True])
    # 遍历名为 `products` 的迭代器，每次迭代解包出 `input_data`, `r`, `with_replacement`
    for input_data, r, with_replacement in products:
        # 使用 `torch.tensor` 创建张量 `input_t`，设备为 `device`，数据类型为 `dtype`，是否需要梯度根据 `requires_grad` 决定
        input_t = torch.tensor(input_data, device=device, dtype=dtype, requires_grad=requires_grad)
        # 生成并返回一个 `SampleInput` 实例，其中包含张量 `input_t`，以及参数 `r` 和 `with_replacement`
        yield SampleInput(input_t, r=r, with_replacement=with_replacement)
# 生成器函数，生成输入参数为 op_info, device, dtype, requires_grad 的笛卡尔积样本
def sample_inputs_cartesian_prod(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用函数，创建 torch.tensor 的偏函数，指定设备、数据类型和梯度要求
    make_arg = partial(torch.tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 构造 1 维张量，元素数量可变
    a = make_arg((0,))
    b = make_arg((0, 1))
    c = make_arg((0, 1, 2, 3))

    # 返回只包含一个张量的样本
    yield SampleInput(a)

    # 返回包含两个张量的样本
    yield SampleInput(a, b)

    # 返回包含三个张量的样本
    yield SampleInput(a, b, c)


# 生成器函数，生成输入参数为 op_info, device, dtype, requires_grad 的余弦相似性样本
def sample_inputs_cosine_similarity(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用函数，创建 make_tensor 的偏函数，指定设备、数据类型和梯度要求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义元组 cases，包含输入形状和参数字典的对应关系
    cases: Tuple[tuple, dict] = (
        ((S, S), {'dim': 1}),
        ((S, 2), {'dim': -1}),
        ((S,), {'dim': 0, 'eps': 0.5}),
        ((), {'dim': 0}),
        ((S, S, M), {'dim': 2}),
        ((S, S), {})
    )

    # 遍历 cases 中的每一组输入形状和参数字典，生成样本
    for input_shape, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(make_arg(input_shape),), kwargs=kwargs)

    # 测试广播特性，生成相应的样本
    yield SampleInput(make_arg((1, 2, 3)), args=(make_arg((2, 1, 3)),), kwargs={'dim': -1})
    yield SampleInput(make_arg((1, 2, 3)), args=(make_arg((2, 1, 3)),), kwargs={'dim': -2})
    yield SampleInput(make_arg((2, 3)), args=(make_arg((2, 1, 3)),), kwargs={'dim': -1})


# 生成器函数，生成输入参数为 op_info, device, dtype, requires_grad 的 item 样本
def sample_inputs_item(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用函数，创建 make_tensor 的偏函数，指定数据类型和设备，梯度不需要
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)

    # 定义元组 cases，包含不同形状的输入
    cases = (
        (),
        (()),
        (1),
        ((1,)),
    )

    # 遍历 cases 中的每个形状，生成相应的样本
    for shape in cases:
        yield SampleInput(make_arg(shape))


# 函数，生成输入参数为 op, device 的 item 错误样本
def error_inputs_item(op, device, **kwargs):
    # 部分应用函数，创建 make_tensor 的偏函数，指定数据类型为 float32，设备和梯度不需要
    make_arg = partial(make_tensor, dtype=torch.float32, device=device, requires_grad=False)

    # 定义元组 cases，包含不同形状的输入，这些输入会导致 RuntimeError 错误
    cases = (
        (M),
        ((S,)),
        (S, S),
        (S, M, L),
    )

    # 遍历 cases 中的每个形状，生成相应的错误输入样本
    for shape in cases:
        yield ErrorInput(
            SampleInput(make_arg(shape)), error_type=RuntimeError,
            error_regex="elements cannot be converted to Scalar")


# 生成器函数，生成输入参数为 op_info, device, dtype, requires_grad 的批标准化样本
def sample_inputs_batch_norm(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用函数，创建 make_tensor 的偏函数，指定设备、数据类型和梯度要求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 部分应用函数，创建 make_tensor 的偏函数，指定设备和数据类型，不需要梯度
    make_arg_without_requires_grad = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)

    # 定义元组 cases，包含输入形状和训练相关参数、动量和 eps 参数的字典
    cases: Tuple[Tuple[int], dict] = (
        ((S, S, S), {'training': True, 'momentum': 0.5, 'eps': 0.6}),
        ((3, 2, 4), {'training': False, 'momentum': -1.2}),
        ((3, 1), {'training': True, 'momentum': 0.0}),
        ((0,), {'training': True}),
        ((0,), {'training': False}),
        ((3, 2, 3, 4), {'training': True, 'momentum': -1.0, 'eps': 0.5}),
        ((3, 2, 3, 4), {'training': False, 'momentum': -1.0, 'eps': 0.5}),
        ((2, 1), {}),
    )

    # 遍历 cases 中的每一组输入形状和参数字典，生成样本
    for input_shape, kwargs in cases:
        yield SampleInput(make_arg(input_shape), kwargs=kwargs)
    # 遍历测试用例中的输入形状和参数
    for input_shape, kwargs in cases:
        # 如果输入形状的长度大于1，则获取通道数，否则通道数为0
        channels = input_shape[1] if len(input_shape) > 1 else 0
        # 如果通道数大于0，则创建权重参数，否则为None
        weight = make_arg(channels) if channels > 0 else None
        # 如果通道数大于0，则创建偏置参数，否则为None
        bias = make_arg(channels) if channels > 0 else None
        # 创建不需要梯度的运行均值参数
        running_mean = make_arg_without_requires_grad(channels, low=0)
        # 创建不需要梯度的运行方差参数
        running_var = make_arg_without_requires_grad(channels, low=0)

        # 生成一个样本输入
        yield SampleInput(
            make_arg(input_shape),
            args=(
                running_mean,
                running_var,
                weight,
                bias
            ),
            kwargs=kwargs
        )

    # 检查权重和偏置为`None`的排列组合
    weights = [channels, None, None]
    biases = [None, channels, None]
    is_training = [True, False, False]

    # 遍历权重、偏置和训练标志的组合
    for weight, bias, training in zip(weights, biases, is_training):
        # 生成一个样本输入
        yield SampleInput(
            make_arg(input_shape),
            args=(
                running_mean,
                running_var,
                make_arg(channels),
                make_arg(channels)
            ),
            kwargs={'training': training}
        )

    # 用于没有可选参数的测试用例
    # 在评估模式下（training: False）需要运行均值和运行方差，但在训练模式下不需要
    yield SampleInput(make_arg((1, 2, 3)), args=(None, None, None, None), kwargs={'training': True})
def sample_inputs_softmax_backward_data(op_info, device, dtype, requires_grad, **kwargs):
    # 创建生成张量的 partially-applied 函数
    make_arg = partial(
        make_tensor, device=device, dtype=dtype, requires_grad=requires_grad
    )
    # 定义不同情况下的输入形状和维度
    cases = [
        ((S,), 0),
        ((S, S), 0),
        ((S, M, S), -1),
    ]
    input_dtypes = [dtype]
    # 如果数据类型为 torch.float 且设备为 'cuda'，则添加 torch.float16 数据类型
    if dtype == torch.float and device == 'cuda':
        input_dtypes += [torch.float16]

    # 针对不同情况生成样本输入
    for (shape, dim), input_dtype in product(cases, input_dtypes):
        input = make_arg(shape)
        output = torch.nn.functional.softmax(input, dim=dim, dtype=input_dtype)
        # 生成样本输入
        yield SampleInput(make_arg(shape), output, dim, input_dtype)

def sample_inputs_native_batch_norm(op_info, device, dtype, requires_grad, **kwargs):
    # 生成标准化样本输入
    samples = sample_inputs_batch_norm(op_info, device, dtype, requires_grad, **kwargs)
    for sample in samples:
        # torch.native_batch_norm 不支持元素数为 0 的张量
        if sample.input.numel() == 0:
            continue
        args = sample.args
        training = sample.kwargs.get('training', True)
        momentum = sample.kwargs.get('momentum', 0.5)
        eps = sample.kwargs.get('eps', 1e-5)
        # 生成样本输入
        yield SampleInput(sample.input, args=(args[2], args[3], args[0], args[1], training, momentum, eps)

def sample_inputs__native_batch_norm_legit(op_info, device, dtype, requires_grad, **kwargs):
    # 生成标准化样本输入
    samples = sample_inputs_batch_norm(op_info, device, dtype, requires_grad, **kwargs)
    for sample in samples:
        # torch.native_batch_norm 不支持元素数为 0 的张量
        if sample.input.numel() == 0:
            continue
        args = sample.args
        training = sample.kwargs.get('training', True)
        momentum = sample.kwargs.get('momentum', 0.5)
        eps = sample.kwargs.get('eps', 1e-5)
        # 如果参数不是 None，则生成样本输入，否则跳过
        if args[0] is not None and args[1] is not None:
            yield SampleInput(sample.input, args=(args[2], args[3], args[0], args[1], training, momentum, eps))
        else:
            yield SampleInput(sample.input, args=(args[2], args[3], training, momentum, eps))

def sample_inputs__batch_norm_with_update(op_info, device, dtype, requires_grad, **kwargs):
    # 生成标准化样本输入
    samples = sample_inputs_batch_norm(op_info, device, dtype, requires_grad, **kwargs)
    for sample in samples:
        # torch.native_batch_norm 不支持元素数为 0 的张量
        if sample.input.numel() == 0:
            continue
        args = sample.args
        momentum = sample.kwargs.get('momentum', 0.5)
        eps = sample.kwargs.get('eps', 1e-5)
        # 如果参数有任何一个是 None，则跳过
        if any(args[i] is None for i in range(4)):
            continue
        # 生成样本输入
        yield SampleInput(sample.input, args=(args[2], args[3], args[0], args[1], momentum, eps))
# 定义一个生成用于测试激活函数ReLU的样本输入的函数
def sample_inputs_nn_activation_relu(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数，用于生成张量，并指定设备、数据类型和是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 不同形状的测试用例
    cases = (
        (()),       # 空元组
        ((S, )),    # 单个维度为S的元组
        ((S, S)),   # 二维形状为S x S
        ((S, M, S)) # 三维形状为S x M x S
    )

    # 遍历每个测试用例的形状
    for shape in cases:
        # 生成一个SampleInput对象，传入make_arg生成的张量作为参数
        yield SampleInput(make_arg(shape))

# 定义一个生成用于测试激活函数PReLU的样本输入的函数
def sample_inputs_prelu(op_info, device, dtype, requires_grad, **kwargs):
    # 从op_info中获取操作的关键字参数
    op_kwargs = op_info.sample_kwargs(device, dtype, None)[0]
    # 使用元素级一元操作的样本输入作为初始生成器
    yield from sample_inputs_elementwise_unary(op_info, device, dtype, requires_grad,
                                               op_kwargs=op_kwargs)

    # 创建一个偏函数，用于生成张量，并指定设备、数据类型和是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 不同形状的测试用例
    cases = (
        (()),       # 空元组
        ((S, )),    # 单个维度为S的元组
        ((S, S)),   # 二维形状为S x S
        ((S, M, S)) # 三维形状为S x M x S
    )

    # 遍历每个测试用例的形状
    for shape in cases:
        # 遍历不同的权重值，-1.、0.、0.8、1.
        for weight in [-1., 0., 0.8, 1.]:
            # 创建权重张量，并传入make_arg生成的张量作为参数
            weight_tensor = torch.tensor(weight, device=device, dtype=dtype, requires_grad=requires_grad)
            yield SampleInput(make_arg(shape), args=(weight_tensor,))

        # 计算通道大小，如果形状长度大于等于2，则为第二维度的大小，否则为1
        channel_size = shape[1] if len(shape) >= 2 else 1
        # 生成带有权重张量作为参数的SampleInput对象
        yield SampleInput(make_arg(shape), args=(make_arg((channel_size,)),))

    # 创建权重张量，并传入make_arg生成的张量作为参数
    weight_tensor = torch.tensor(1., device=device, dtype=dtype, requires_grad=requires_grad)
    # 生成带有权重张量作为关键字参数的SampleInput对象
    yield SampleInput(make_arg((S, S)), kwargs=dict(weight=weight_tensor,))

    # 生成带有权重张量作为关键字参数的SampleInput对象
    yield SampleInput(make_arg((S, S)), kwargs=dict(weight=make_arg((S,)),))

# 定义用于测试PReLU激活函数的参考输入的函数
def reference_inputs_prelu(op, device, dtype, requires_grad, **kwargs):
    # 生成PReLU激活函数的样本输入，传入op、设备、数据类型、是否需要梯度以及其他关键字参数
    yield from sample_inputs_prelu(op, device, dtype, requires_grad, **kwargs)
    # 生成元素级一元操作的参考输入，传入op、设备、数据类型、是否需要梯度以及其他关键字参数
    yield from reference_inputs_elementwise_unary(op, device, dtype, requires_grad, **kwargs)

# 定义用于生成PReLU激活函数标量权重样本参数的函数
def sample_kwargs_prelu_scalar_weight(device, dtype, input):
    # 生成一个随机张量作为权重，设备为device、数据类型为dtype
    weight = torch.rand(tuple(), device=device, dtype=dtype)
    # 如果数据类型为torch.bfloat16，则将权重转换为torch.float32，设备为CPU
    if dtype == torch.bfloat16:
        weight_cpu = weight.to(dtype=torch.float32, device="cpu")
    else:
        weight_cpu = weight.cpu()
    # 将CPU上的权重张量转换为NumPy数组
    np_weight = weight_cpu.numpy()
    # 返回包含权重字典的元组
    return ({'weight': weight}, {'weight': np_weight})

# 定义用于测试PReLU激活函数错误输入的函数
def error_inputs_prelu(op, device):
    # 生成一个形状为空元组的张量，设备为device、数据类型为torch.float32
    inp = make_tensor(tuple(), device=device, dtype=torch.float32)
    # 生成一个形状为(2,)的张量作为权重，设备为device、数据类型为torch.float32
    weight = make_tensor((2,), device=device, dtype=torch.float32)
    # 生成一个错误输入，传入形状为空元组的SampleInput对象和包含权重张量的关键字参数
    yield ErrorInput(SampleInput(inp, kwargs={'weight': weight}),
                     error_regex="Not allow zero-dim input tensor.")

    # 生成一个形状为(2, 8, 3)的张量，设备为device、数据类型为torch.float32
    inp = make_tensor((2, 8, 3), device=device, dtype=torch.float32)
    # 生成一个形状为(9,)的张量作为权重，设备为device、数据类型为torch.float32
    weight = make_tensor((9,), device=device, dtype=torch.float32)
    # 生成一个错误输入，传入形状为(2, 8, 3)的SampleInput对象和包含权重张量的关键字参数
    yield ErrorInput(SampleInput(inp, kwargs={'weight': weight}),
                     error_regex="Mismatch of parameter numbers and input channel size.")

    # 生成一个形状为(2, 8, 3)的张量，设备为device、数据类型为torch.float32
    # 创建一个形状为 (2, 4) 的张量，并指定设备和数据类型
    weight = make_tensor((2, 4), device=device, dtype=torch.float32)
    
    # 使用 ErrorInput 类创建一个错误输入对象，包含输入数据和关键字参数 'weight'
    # error_regex 指定了期望的错误信息正则表达式
    yield ErrorInput(SampleInput(inp, kwargs={'weight': weight}),
                     error_regex="prelu: Expected `weight` to be a scalar or 1D tensor, but got: ndim = 2")
    
    # 提示信息：源张量和索引张量必须具有相同的维度数量
# 定义函数，生成输入样本以测试无穷范数规范化操作
def sample_inputs_norm_inf(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数创建生成张量的函数，指定设备、数据类型和是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义测试用例列表，每个元组包含：张量形状、参数元组、测试用例名称
    cases = [
        ((S, S), (2,), '2'),
        ((S, S), (0,), '0'),
        ((S, S), (0.5,), '0_5'),
        ((S, S), (1,), '1'),
        ((S, S), (3,), '3'),
        ((S, S), (-1,), 'neg_1'),
        ((S, S), (-2,), 'neg_2'),
        ((S, S), (-0.5,), 'neg_0_5'),
        ((S, S), (-1.5,), 'neg_1_5'),
    ]

    # 定义包含非零输入的测试用例列表
    cases_nonzero_input = (
        ((S, S, S), (1.5,), '1_5_default'),
        ((S, S, S), (1.5, 1), '1_5_dim'),
        ((S, S, S), (1.5, -1), '1_5_neg_dim'),
        ((S, S, S), (1.5, 1, True), 'keepdim_1_5_dim'),
        ((S, S, S), (1.5, -1, True), 'keepdim_1_5_neg_dim'),
    )

    # 定义正维度测试用例列表
    cases_posdim = (
        ((S, S), (-2, 1,), 'neg_2_dim'),
        ((S, S), (-1, 1,), 'neg_1_dim'),
        ((S, S), (0, 1,), '0_dim'),
        ((S, S), (1, 1,), '1_dim'),
        ((S, S), (2, 1,), '2_dim'),
        ((S, S), (3, 1,), '3_dim'),
        ((S, S, S), (2, 1), '2_dim'),
        ((S, S, S), (3, 1), '3_dim'),
        ((S, S, S), (2, 1, True), 'keepdim_2_dim'),
        ((S, S, S), (3, 1, True), 'keepdim_3_dim'),
        ((), (2, 0), '2_dim_scalar'),
        ((), (3, 0), '3_dim_scalar'),
        ((), (2, 0, True), 'keepdim_2_dim_scalar'),
        ((), (3, 0, True), 'keepdim_3_dim_scalar'),
    )

    # 根据正维度测试用例生成负维度测试用例列表
    cases_negdim = ((shape, args[:1] + (-args[1],) + args[2:], name.replace("_dim", "_neg_dim"))
                    for shape, args, name in cases_posdim)

    # 合并所有测试用例（正常、非零、正维度和负维度），并生成对应的 SampleInput 实例
    for shape, args, name in itertools.chain(cases, cases_posdim, cases_negdim):
        yield SampleInput(make_arg(shape), args=args, name=name)

    # 生成包含非零输入的测试用例的 SampleInput 实例
    for shape, args, name in cases_nonzero_input:
        yield SampleInput(make_arg(shape, exclude_zero=True), args=args, name=name)
    # 定义测试用例 cases，每个元组包含三个元素：shape, args, name
    cases = (
        # 第一个测试用例，shape 为 (S, S)，args 为 (-inf,)，name 为 '-inf'
        ((S, S), (-inf,), '-inf'),
        # 第二个测试用例，shape 为 (S, S)，args 为 (inf,)，name 为 'inf'
        ((S, S), (inf,), 'inf'),
        # 第三个测试用例，shape 为 (S, S)，args 为 (inf, 1,)，name 为 'inf_2_dim'
        ((S, S), (inf, 1,), 'inf_2_dim'),
        # 第四个测试用例，shape 为 (S, S)，args 为 (inf, -1,)，name 为 'inf_2_neg_dim'
        ((S, S), (inf, -1,), 'inf_2_neg_dim'),
    )
    
    # 遍历每个测试用例，生成对应的 SampleInput 对象
    for shape, args, name in cases:
        # 使用 make_arg 函数生成输入参数，创建 SampleInput 实例，包括 shape, args 和 name
        yield SampleInput(make_arg(shape), args=args, name=name)
# 定义一个函数，生成给定操作的样本输入
def sample_inputs_equal(op, device, dtype, requires_grad, **kwargs):
    # 使用偏函数 partial 生成一个创建张量的函数 make_arg，指定设备、数据类型和梯度属性
    make_arg = partial(
        make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同形状的张量对，每个元组包含左右张量的形状
    shapes = (
        ((), ()),        # 标量之间的比较
        ((S,), ()),      # 向量与标量之间的比较
        ((), (S,)),      # 标量与向量之间的比较
        ((S, 1), (S,)),  # 二维张量与向量之间的比较
        ((M, S), ()),    # 高维张量与标量之间的比较
        ((S, S), (S, S)) # 方阵之间的比较
    )

    # 遍历所有形状对
    for shape_lhs, shape_rhs in shapes:
        # 创建左侧张量和右侧张量，根据 make_arg 函数生成
        lhs = make_arg(shape_lhs)
        rhs = make_arg(shape_rhs)
        # 判断是否需要广播输入
        broadcasts_input = shape_lhs != torch.broadcast_shapes(shape_lhs, shape_rhs)

        # 生成 SampleInput 对象，表示一个样本输入，包括左侧张量、右侧张量和广播信息
        yield SampleInput(lhs, args=(rhs,), broadcasts_input=broadcasts_input)
        
        # 如果左侧形状等于右侧形状，则再生成一个没有广播的 SampleInput 对象
        if shape_lhs == shape_rhs:
            yield SampleInput(lhs, args=(lhs.clone().detach_(),))


# 定义一个函数，生成给定操作的样本输入，并处理更多复杂的形状对
def sample_inputs_jiterator(op, device, dtype, requires_grad, **kwargs):
    # 使用偏函数 partial 生成一个创建张量的函数 make_arg，指定设备、数据类型和梯度属性
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同形状的张量对，每个元组包含左右张量的形状
    shapes = (
        ((), ()),               # 标量之间的比较
        ((S,), ()),             # 向量与标量之间的比较
        ((S, 1), (S,)),         # 二维张量与向量之间的比较
        ((M, S), ()),           # 高维张量与标量之间的比较
        ((S, M, S), (M, S)),    # 三维张量与二维张量之间的比较
        ((S, M, S), (S, M, S)), # 三维张量之间的比较
        ((M, 1, S), (M, S)),    # 三维张量与二维张量之间的比较
        ((M, 1, S), (1, M, S)), # 三维张量与二维张量之间的比较
        ((0, 1, 3), (0, 10, 3)) # 不规则形状之间的比较
    )

    # 从 kwargs 中获取 num_inputs 和 sample_kwargs 参数
    num_inputs = kwargs.get('num_inputs')
    sample_kwargs = kwargs.get('sample_kwargs', {})

    # 遍历所有形状对
    for shape_lhs, shape_rhs in shapes:
        # 创建左侧张量，根据 make_arg 函数生成
        lhs = make_arg(shape_lhs)

        # 创建多个右侧张量，数量为 num_inputs - 1，每个右侧张量根据 make_arg 函数生成
        args = []
        for i in range(num_inputs - 1):
            args.append(make_arg(shape_rhs))
        
        # 判断是否需要广播输入
        broadcasts_input = (shape_lhs != torch.broadcast_shapes(shape_lhs, shape_rhs))

        # 生成 SampleInput 对象，表示一个样本输入，包括左侧张量、右侧张量、附加参数和广播信息
        yield SampleInput(lhs, args=tuple(args), kwargs=sample_kwargs, broadcasts_input=broadcasts_input)


# 定义一个函数，生成给定操作的样本输入，并考虑不同形状之间的广播情况
def sample_inputs_broadcast_shapes(op, device, dtype, requires_grad, **kwargs):
    # 定义不同形状的张量对，每个元组包含输入形状和附加参数
    shapes = (
        ((), ()),         # 标量之间的比较
        ((S,), ()),       # 向量与标量之间的比较
        ((S, 1), (S,)),   # 二维张量与向量之间的比较
        ((S, 1), S),      # 二维张量与标量之间的比较
        ((M, S), ()),     # 高维张量与标量之间的比较
        ((S, M, S), (M, S)),    # 三维张量与二维张量之间的比较
        ((S, M, S), (S, M, S)), # 三维张量之间的比较
        ((M, 1, S), (M, S)),    # 三维张量与二维张量之间的比较
        ((M, 1, S), (1, M, S)), # 三维张量与二维张量之间的比较
        ((0, 1, 3), (0, 10, 3)) # 不规则形状之间的比较
    )

    # 遍历所有形状对
    for shape in shapes:
        inp, *arg0 = shape
        # 生成 SampleInput 对象，表示一个样本输入，包括输入形状和附加参数
        yield SampleInput(inp, args=tuple(arg0))


# 定义一个函数，生成给定操作的样本输入，并处理元素级二元操作的情况
def sample_inputs_add_sub(op, device, dtype, requires_grad, **kwargs):
    # 使用 sample_inputs_elementwise_binary 函数生成样本输入
    yield from sample_inputs_elementwise_binary(op, device, dtype, requires_grad, **kwargs)

    # 添加 alpha 关键字参数的情况
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 创建左侧张量和右侧张量，根据 op 对象中的 lhs_make_tensor_kwargs 和 rhs_make_tensor_kwargs 参数生成
    lhs = make_arg((S, S), **op.lhs_make_tensor_kwargs)
    rhs = make_arg((S, S), **op.rhs_make_tensor_kwargs)

    # 如果数据类型不是布尔型，则生成一个带有 alpha 参数的 SampleInput 对象
    if dtype is not torch.bool:
        yield SampleInput(lhs, args=(rhs,), kwargs={'alpha': 2})
    else:
        yield SampleInput(lhs, args=(rhs,), kwargs={'alpha': True})

    # 根据数据类型是否是浮点型或复数型，生成不同 alpha 参数的 SampleInput 对象
    neg_alpha = -3.125 if (dtype.is_floating_point or dtype.is_complex) else -3
    lhs = make_arg((S, S), **op.lhs_make_tensor_kwargs)
    rhs = make_arg((S, S), **op.rhs_make_tensor_kwargs)
    if dtype is not torch.bool:
        yield SampleInput(lhs, args=(rhs,), kwargs={'alpha': neg_alpha})
    else:
        # 如果条件不满足，则执行以下代码块
        # 使用 yield 关键字返回一个 SampleInput 对象
        yield SampleInput(lhs, args=(rhs,), kwargs={'alpha': False})
# 生成用于测试 arange 函数的错误输入样本
def error_inputs_arange(op, device, **kwargs):
    # 生成步长为零的错误样本
    yield ErrorInput(SampleInput(0, args=(3, 0)), error_type=RuntimeError, error_regex='step must be nonzer')
    # 生成步长与边界符号不一致的错误样本
    yield ErrorInput(SampleInput(0, args=(-3, 2)), error_type=RuntimeError, error_regex='bound inconsistent with step sign')
    # 生成步长与边界符号不一致的错误样本
    yield ErrorInput(SampleInput(0, args=(3, -2)), error_type=RuntimeError, error_regex='bound inconsistent with step sign')
    # 生成不支持的范围错误样本（起始值为正无穷）
    yield ErrorInput(SampleInput(0, args=(float('inf'), 2)), error_type=RuntimeError, error_regex='unsupported range')
    # 生成不支持的范围错误样本（起始值为负无穷）
    yield ErrorInput(SampleInput(float('-inf'), args=(1, 2)), error_type=RuntimeError, error_regex='unsupported range')

# 生成用于测试 arange 函数的输入样本
def sample_inputs_arange(op, device, dtype, requires_grad, **kwargs):
    # 整数类型的样本集合
    int_samples = (
        # 正向步进
        (-1, 2, 2),
        # 负向步进
        (2, -3, -1),
        # 开始 == 结束
        (1, 1, 1),
        (1, 1, -1),
        # 整除步进
        (0, -8, -4),
        (1, 5, 2),
        # 布尔值
        (False, True, True),
        # 默认步长
        (0, 1, None),
        # 默认开始值
        (None, 3, None),
    )

    # 转换为浮点数的样本集合
    def to_float(start, end, step):
        start = start + 0.1 if start is not None else None
        end = end + 0.1
        step = float(step) if step is not None else None
        return start, end, step

    float_samples = (
        # 包含终点值
        (0., -8. - 1e-6, -4.),
        (1., 5. + 1e-6, 2.),
        (0., -8., -4.),
        (1., 5., 2.),
        *(to_float(start, end, step) for (start, end, step) in int_samples),
    )

    # 大数值的样本集合
    large_samples = (
        (0, 10000, None),
    )

    # 合并所有样本集合
    samples = int_samples + float_samples
    # 若 dtype 不是 torch.int8 或 torch.uint8，则添加大数值的样本
    if dtype not in (torch.int8, torch.uint8):
        samples += large_samples

    # 生成所有样本的输入
    for start, end, step in samples:
        if start is None:
            assert step is None
            # 传入终点值作为位置参数
            yield SampleInput(end, kwargs={"dtype": dtype, "device": device})
            # 类似调用 torch.arange(end=3)
            yield SampleInput(0, kwargs={"end": end, "dtype": dtype, "device": device})
        elif step is None:
            # 只传入起始值和终点值作为参数
            yield SampleInput(start, args=(end,), kwargs={"dtype": dtype, "device": device})
        else:
            # 传入起始值、终点值和步长作为参数
            yield SampleInput(start, args=(end, step), kwargs={"dtype": dtype, "device": device})

    # 添加额外的单一参数样本输入
    yield SampleInput(2)
    yield SampleInput(1, args=(3, 1))

# 生成用于测试 randn 函数的输入样本
def sample_inputs_randn(op, device, dtype, requires_grad, **kwargs):
    # 部分应用 make_tensor 函数生成张量的偏函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)

    # 张量形状的样本集合
    shapes = (
        (M,),
        (S, S)
    )

    # 生成所有形状样本的输入
    for shape in shapes:
        yield SampleInput(input=shape, kwargs=dict(dtype=dtype, device=device, requires_grad=requires_grad))

# 生成用于测试 normal 函数的输入样本
def sample_inputs_normal(op, device, dtype, requires_grad, **kwargs):

    # 部分应用 make_tensor 函数生成张量的偏函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    
    # 正态分布参数的样本集合
    samples = (
        ((S, S), 0, 5),
        ((S, S, S), -2, 0.5),
    )
    # 对于每个元组 (shape, mean, std) 中的元素，依次取出并迭代
    for shape, mean, std in samples:
        # 使用 make_arg 函数创建参数
        # 返回一个 SampleInput 对象，参数为 shape 和元组 (mean, std)
        yield SampleInput(make_arg(shape), args=(mean, std))
# 生成包含错误输入的生成器函数，返回错误输入对象列表
def error_inputs_normal(op, device, **kwargs):
    # 创建一个张量t，全零，长度为10，在指定设备上
    t = torch.zeros([10], device=device)
    # 设置无效的标准差为-1
    invalid_std = -1
    # 生成一个包含错误输入的ErrorInput对象，抛出RuntimeError错误
    yield ErrorInput(
        # 创建一个SampleInput对象，传入张量t和参数元组(0, invalid_std)
        SampleInput(t, args=(0, invalid_std)),
        # 设置错误类型为RuntimeError
        error_type=RuntimeError,
        # 设置错误正则表达式消息，描述错误类型
        error_regex=fr"normal expects std >= 0.0, but found std {invalid_std}",
    )


# 生成包含样本输入的生成器函数，返回样本输入对象列表
def sample_inputs_cauchy(op, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数make_arg，用于创建张量，设定dtype、device和requires_grad参数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    # 定义多个样本形状、中位数和gamma参数的元组
    samples = (
        ((M,), 0, 0.5),
        ((S, S), 0, 1),
        ((S, S, S), -2, 1),
    )
    # 遍历样本元组，生成样本输入对象
    for shape, median, gamma in samples:
        # 生成一个SampleInput对象，传入由make_arg创建的张量和参数元组(median, gamma)
        yield SampleInput(make_arg(shape), args=(median, gamma))


# 生成包含错误输入的生成器函数，返回错误输入对象列表
def error_inputs_cauchy(op, device, **kwargs):
    # 创建一个张量t，全零，长度为10，在指定设备上
    t = torch.zeros([10], device=device)
    # 设置无效的尺度为0
    invalid_scale = 0
    # 生成一个包含错误输入的ErrorInput对象，抛出RuntimeError错误
    yield ErrorInput(
        # 创建一个SampleInput对象，传入张量t和参数元组(0, invalid_scale)
        SampleInput(t, args=(0, invalid_scale,)),
        # 设置错误类型为RuntimeError
        error_type=RuntimeError,
        # 设置错误正则表达式消息，描述错误类型
        error_regex=fr"cauchy_ expects sigma > 0.0, but found sigma={invalid_scale}",
    )


# 生成包含样本输入的生成器函数，返回样本输入对象列表
def sample_inputs_exponential(op, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数make_arg，用于创建张量，设定dtype、device和requires_grad参数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    # 定义多个样本形状和速率参数的元组
    samples = (
        ((M,), 0.5),
        ((S, S), 1),
        ((S, S, S), 1.5),
    )
    # 遍历样本元组，生成样本输入对象
    for shape, rate in samples:
        # 生成一个SampleInput对象，传入由make_arg创建的张量和参数元组(rate,)
        yield SampleInput(make_arg(shape), args=(rate,))


# 生成包含错误输入的生成器函数，返回错误输入对象列表
def error_inputs_exponential(op, device, **kwargs):
    # 创建一个张量t，全零，长度为10，在指定设备上
    t = torch.zeros([10], device=device)
    # 设置无效的速率为0
    invalid_rate = 0
    # 生成一个包含错误输入的ErrorInput对象，抛出RuntimeError错误
    yield ErrorInput(
        # 创建一个SampleInput对象，传入张量t和参数元组(invalid_rate,)
        SampleInput(t, args=(invalid_rate,)),
        # 设置错误类型为RuntimeError
        error_type=RuntimeError,
        # 设置错误正则表达式消息，描述错误类型
        error_regex=fr"exponential_ expects lambda > 0.0, but found lambda={invalid_rate}",
    )


# 生成包含样本输入的生成器函数，返回样本输入对象列表
def sample_inputs_geometric(op, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数make_arg，用于创建张量，设定dtype、device和requires_grad参数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    # 定义多个样本形状和速率参数的元组
    samples = (
        ((M,), 0.2),
        ((S, S), 0.5),
        ((S, S, S), 0.8),
    )
    # 遍历样本元组，生成样本输入对象
    for shape, rate in samples:
        # 生成一个SampleInput对象，传入由make_arg创建的张量和参数元组(rate,)
        yield SampleInput(make_arg(shape), args=(rate,))


# 生成包含错误输入的生成器函数，返回错误输入对象列表
def error_inputs_geometric(op, device, **kwargs):
    # 创建一个张量t，全零，长度为10，在指定设备上
    t = torch.zeros([10], device=device)
    # 设置无效的概率为-1
    neg_prob = -1
    # 生成一个包含错误输入的ErrorInput对象，抛出RuntimeError错误
    yield ErrorInput(
        # 创建一个SampleInput对象，传入张量t和参数元组(neg_prob,)
        SampleInput(t, args=(neg_prob,)),
        # 设置错误类型为RuntimeError
        error_type=RuntimeError,
        # 设置错误正则表达式消息，描述错误类型
        error_regex=fr"geometric_ expects p to be in \(0, 1\), but got p={neg_prob}",
    )


# 生成包含样本输入的生成器函数，返回样本输入对象列表
def sample_inputs_log_normal(op, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数make_arg，用于创建张量，设定dtype、device和requires_grad参数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    # 定义多个样本形状、均值和标准差参数的元组
    samples = (
        ((M,), 0, 0.25),
        ((S, S), 0.5, 1),
        ((S, S, S), 0, 0.5),
    )
    # 遍历样本元组，生成样本输入对象
    for shape, mean, std in samples:
        # 生成一个SampleInput对象，传入由make_arg创建的张量和参数元组(mean, std)
        yield SampleInput(make_arg(shape), args=(mean, std))


# 生成包含错误输入的生成器函数，返回错误输入对象列表
def error_inputs_log_normal(op, device, **kwargs):
    # 创建一个张量t，全零，长度为10，在指定设备上
    t = torch.zeros([10], device=device)
    # 设置无效的标准差为0
    invalid_std = 0
    # 生成一个包含错误输入的ErrorInput对象，抛出RuntimeError错误
    yield ErrorInput(
        # 创建一个SampleInput对象，传入张量t和参数元组(0, invalid_std)
        SampleInput(t, args=(0, invalid_std)),
        # 设置错误类型为RuntimeError
        error_type=RuntimeError,
        # 设置错误正则表达式消息，描述错误类型
        error_regex=fr"log_normal_ expects std > 0.0, but found std={invalid_std}",
    )
def sample_inputs_uniform(op, device, dtype, requires_grad, **kwargs):
    # 使用偏函数创建一个函数 make_arg，用于生成指定类型和设备的张量，不需要梯度
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    # 定义不同形状和取值范围的样本数据
    samples = (
        ((M,), -100, 100),
        ((S, S), 0, 1),
        ((S, S, S), 1, 2),
    )
    # 遍历样本数据，生成 SampleInput 对象并 yield 返回
    for shape, hi, lo in samples:
        yield SampleInput(make_arg(shape), args=(hi, lo))

def sample_inputs_ones_zeros(op, device, dtype, requires_grad, **kwargs):
    # 参数 sizes 中包含不同形状的元组，用于生成大小为 1 或 2 的张量
    sizes = (
        (M,),
        (S, S),
    )
    # 遍历 sizes，生成 SampleInput 对象并 yield 返回，同时传递 dtype 和 device 作为 kwargs
    for size in sizes:
        yield SampleInput(size, kwargs={'dtype': dtype, 'device': device})

def sample_inputs_full(op, device, dtype, requires_grad, **kwargs):
    # 定义一个函数 get_val 用于创建一个标量张量，其类型由参数 dtype 指定
    def get_val(dtype):
        return make_tensor([], dtype=dtype, device="cpu").item()

    # 参数 sizes 包含不同形状的元组，用于生成大小为 1 或 2 的张量
    sizes = (
        (M,),
        (S, S),
    )
    # fill_values 包含两个值，分别由 get_val 函数生成，用作填充参数
    fill_values = [get_val(dtype), get_val(torch.int)]

    # 使用 product 函数生成 sizes 和 fill_values 的组合，生成 SampleInput 对象并 yield 返回
    for size, fill_value in product(sizes, fill_values):
        yield SampleInput(size, fill_value, dtype=dtype, device=device)


def error_inputs_uniform(op, device, **kwargs):
    # 创建一个大小为 [10] 的零张量 t，作为错误输入的基础输入
    t = torch.zeros([10], device=device)
    # 生成一个 ErrorInput 对象，包含基础输入 SampleInput，以及预期的 RuntimeError 错误信息
    yield ErrorInput(
        SampleInput(t, args=(3, -1)),
        error_type=RuntimeError,
        error_regex=r"uniform_ expects to return a \[from, to\) range, but found from=3 > to=-1",
    )


def error_inputs_linspace(op, device, **kwargs):
    # 生成一个 ErrorInput 对象，包含一个 SampleInput 作为基础输入，以及预期的 RuntimeError 错误信息
    yield ErrorInput(SampleInput(0, args=(3, -1)), error_type=RuntimeError, error_regex='number of steps must be non-negative')
    # 生成一个 ErrorInput 对象，包含一个 SampleInput 作为基础输入，以及预期的 TypeError 错误信息
    yield ErrorInput(
        SampleInput(0, args=(3, 1.)),
        error_type=TypeError,
        error_regex="received an invalid combination of arguments - got \\(int, int, float",
    )
    # 生成一个 ErrorInput 对象，包含一个 SampleInput 作为基础输入，以及预期的 RuntimeError 错误信息
    yield ErrorInput(
        SampleInput(torch.tensor([1, 1], device=device), args=(torch.tensor([3, 3], device=device), 1)),
        error_type=RuntimeError,
        error_regex="only supports 0-dimensional start and end tensors"
    )


def sample_inputs_linspace(op, device, dtype, requires_grad, **kwargs):
    # 定义不同的起始值、结束值和步数的组合，用于生成线性空间样本数据
    ends = (-3, 0, 1, 4, 50)
    starts = (-2., 0, 4.3, 50)
    nsteps = (0, 1, 50)
    # 增加一个额外的情况，用于在 CUDA 上复制出现的偏移错误
    cases = list(product(starts, ends, nsteps)) + [(0, 7, 50)]
    # 遍历 cases，生成 SampleInput 对象并 yield 返回，同时传递 dtype 和 device 作为 kwargs
    for start, end, nstep in cases:
        # 如果 dtype 是 torch.uint8 并且起始值或结束值小于 0，则跳过当前循环
        if dtype == torch.uint8 and (end < 0 or start < 0):
            continue
        yield SampleInput(start, args=(end, nstep), kwargs={"dtype": dtype, "device": device})

    # 生成一个额外的 SampleInput 对象并 yield 返回，用于特定参数的情况
    yield SampleInput(1, args=(3, 1))


def sample_inputs_linspace_tensor_overload(op, device, dtype, requires_grad, **kwargs):
    # 定义不同的起始值、结束值和步数的组合，以及是否使用张量作为起始值和结束值的元组
    ends = (-3, 0, 1, 4, 50)
    starts = (-2., 0, 4.3, 50)
    nsteps = (0, 1, 50)
    is_start_end_tensors = ((True, True), (True, False), (False, True))
    # 使用偏函数创建一个函数 make_arg，用于生成指定类型和设备的张量，不需要梯度
    make_arg = partial(torch.tensor, device=device, requires_grad=False)

    # 增加一个额外的情况，用于在 CUDA 上复制出现的偏移错误
    cases = list(product(starts, ends, nsteps, is_start_end_tensors)) + [(0, 7, 50, (True, True))]
    # 对于每个测试案例，解包 cases 中的元组，获取起始点、终止点、步长和是否为张量的标志
    for start, end, nstep, (is_start_tensor, is_end_tensor) in cases:
        # 如果数据类型为 torch.uint8 并且起始点或终止点小于 0，则跳过当前迭代
        if dtype == torch.uint8 and (end < 0 or start < 0):
            continue

        # 设定张量的选项，指定数据类型和设备
        tensor_options = {"dtype": dtype, "device": device}
        
        # 如果起始点为张量，则根据其类型调整为 float32 或 int64
        if is_start_tensor:
            start = make_arg(start, dtype=torch.float32 if isinstance(start, float) else torch.int64)
        
        # 如果终止点为张量，则根据其类型调整为 float32 或 int64
        if is_end_tensor:
            end = make_arg(end, dtype=torch.float32 if isinstance(end, float) else torch.int64)

        # 生成一个 SampleInput 实例，传入起始点、参数元组 (终止点, 步长) 和张量选项
        yield SampleInput(start, args=(end, nstep), kwargs=tensor_options)

    # 生成一个默认的 SampleInput 实例，用于特定参数值的测试
    yield SampleInput(1, args=(3, 1))
# 定义一个函数用于生成以对数间隔的样本输入
def sample_inputs_logspace(op, device, dtype, requires_grad, **kwargs):
    # 定义结束点的数组
    ends = (-3, 0, 1.2, 2, 4)
    # 定义起始点的数组
    starts = (-2., 0, 1, 2, 4.3)
    # 定义步数的数组
    nsteps = (0, 1, 2, 4)
    # 如果数据类型是 torch.int8 或 torch.uint8，则使用不同的基数
    bases = (2., 1.1) if dtype in (torch.int8, torch.uint8) else (None, 2., 3., 1.1, 5.)
    
    # 遍历起始点、结束点、步数和基数的笛卡尔积
    for start, end, nstep, base in product(starts, ends, nsteps, bases):
        # 如果数据类型是 torch.uint8 且结束点小于0，或者起始点小于0，则跳过当前循环
        if dtype == torch.uint8 and end < 0 or start < 0:
            continue
        # 如果步数为1且起始点是浮点数，并且数据类型不是复数类型或浮点类型，则跳过当前循环
        if nstep == 1 and isinstance(start, float) and not (dtype.is_complex or dtype.is_floating_point):
            # https://github.com/pytorch/pytorch/issues/82242
            continue
        
        # 如果基数为None，则创建一个使用参数的起始点和结束点的 SampleInput 对象
        if base is None:
            yield SampleInput(start, args=(end, nstep), kwargs={"dtype": dtype, "device": device})
        else:
            # 否则创建一个使用参数的起始点、结束点、步数和基数的 SampleInput 对象
            yield SampleInput(start, args=(end, nstep, base), kwargs={"dtype": dtype, "device": device})
    
    # 最后生成一个额外的 SampleInput 对象，参数为 1, (3, 1, 2.)
    yield SampleInput(1, args=(3, 1, 2.))


# 定义一个函数用于生成以张量重载的对数间隔的样本输入
def sample_inputs_logspace_tensor_overload(op, device, dtype, requires_grad, **kwargs):
    # 定义结束点的数组
    ends = (-3, 0, 1.2, 2, 4)
    # 定义起始点的数组
    starts = (-2., 0, 1, 2, 4.3)
    # 定义步数的数组
    nsteps = (0, 1, 2, 4)
    # 如果数据类型是 torch.int8 或 torch.uint8，则使用不同的基数
    bases = (2., 1.1) if dtype in (torch.int8, torch.uint8) else (None, 2., 3., 1.1, 5.)
    # 定义是否起始点和结束点是张量的布尔值数组
    is_start_end_tensors = ((True, True), (True, False), (False, True))
    # 创建一个部分函数，用于根据设备创建张量
    make_arg = partial(torch.tensor, device=device)
    
    # 遍历起始点、结束点、步数、基数和是否张量的布尔值的笛卡尔积
    for start, end, nstep, base, (is_start_tensor, is_end_tensor) in product(starts, ends, nsteps, bases, is_start_end_tensors):
        # 如果数据类型是 torch.uint8 且结束点小于0，或者起始点小于0，则跳过当前循环
        if dtype == torch.uint8 and end < 0 or start < 0:
            continue
        # 如果步数为1且起始点是浮点数，并且数据类型不是复数类型或浮点类型，则跳过当前循环
        if nstep == 1 and isinstance(start, float) and not (dtype.is_complex or dtype.is_floating_point):
            # https://github.com/pytorch/pytorch/issues/82242
            continue

        # 创建张量选项字典，包含数据类型和设备
        tensor_options = {"dtype": dtype, "device": device}

        # 如果起始点是张量，则使用部分函数创建张量，使用 float32 或 int64 作为数据类型
        if is_start_tensor:
            start = make_arg(start, dtype=torch.float32 if isinstance(start, float) else torch.int64)
        # 如果结束点是张量，则使用部分函数创建张量，使用 float32 或 int64 作为数据类型
        if is_end_tensor:
            end = make_arg(end, dtype=torch.float32 if isinstance(end, float) else torch.int64)

        # 如果基数为None，则创建一个使用参数的起始点和结束点的 SampleInput 对象
        if base is None:
            yield SampleInput(start, args=(end, nstep), kwargs=tensor_options)
        else:
            # 否则创建一个使用参数的起始点、结束点、步数和基数的 SampleInput 对象
            yield SampleInput(start, args=(end, nstep, base), kwargs=tensor_options)
    
    # 最后生成一个额外的 SampleInput 对象，参数为 1, (3, 1, 2.)
    yield SampleInput(1, args=(3, 1, 2.))


# 定义一个函数用于生成用于 isclose 函数的样本输入
def sample_inputs_isclose(op, device, dtype, requires_grad, **kwargs):
    # 从 elementwise_binary 操作中生成更多的输入
    yield from sample_inputs_elementwise_binary(op, device, dtype, requires_grad, **kwargs)

    # 创建额外的输入，用于测试 rtol、atol 和 equal_nan 参数
    rtols = [0., 1e-7]
    atols = [0., 1e-7]
    equal_nans = [False, True]

    # 计算 rtol、atol 和 equal_nan 的所有组合
    products = product(rtols, atols, equal_nans)

    # 创建一个部分函数，用于根据设备、数据类型和梯度要求创建张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 遍历 rtol、atol 和 equal_nan 的所有组合
    for rtol, atol, equal_nan in products:
        # 使用 elementwise_binary 操作中定义的参数创建左右张量
        lhs = make_arg((S, S), **op.lhs_make_tensor_kwargs)
        rhs = make_arg((S, S), **op.rhs_make_tensor_kwargs)

        # 生成一个 SampleInput 对象，参数为左右张量、rtol、atol 和 equal_nan
        yield SampleInput(lhs, args=(rhs,),
                          kwargs=dict(rtol=rtol, atol=atol, equal_nan=equal_nan))
def error_inputs_isclose(op, device, **kwargs):
    # 部分函数调用的简化形式，固定了 device 参数为给定值，dtype 为 torch.float，requires_grad 为 False
    make_float_arg = partial(make_tensor, device=device, dtype=torch.float, requires_grad=False)

    # 生成并返回一个 ErrorInput 对象，用于测试 rtol 参数小于零的情况
    yield ErrorInput(
        SampleInput(make_float_arg(()), args=(make_float_arg(()),), kwargs={'rtol': -0.4}),
        error_type=RuntimeError,
        error_regex='rtol must be greater than or equal to zero')

    # 生成并返回一个 ErrorInput 对象，用于测试 atol 参数小于零的情况
    yield ErrorInput(
        SampleInput(make_float_arg(()), args=(make_float_arg(()),), kwargs={'atol': -0.4}),
        error_type=RuntimeError,
        error_regex='atol must be greater than or equal to zero')


def sample_inputs_t(op_info, device, dtype, requires_grad, **kwargs):
    # 部分函数调用的简化形式，根据给定的 device, dtype, requires_grad 生成对应的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 生成并返回一个 SampleInput 对象，用于测试形状为 (1, 2) 的张量
    yield SampleInput(make_arg((1, 2)))

    # 生成并返回一个 SampleInput 对象，用于测试形状为 (2,) 的张量
    yield SampleInput(make_arg((2,)))

    # 生成并返回一个 SampleInput 对象，用于测试形状为空的张量
    yield SampleInput(make_arg(()))


def sample_inputs_mm(op_info, device, dtype, requires_grad, **kwargs):
    # 部分函数调用的简化形式，根据给定的 device, dtype, requires_grad 生成对应的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 生成并返回一个 SampleInput 对象，用于测试形状为 (S, M) 和 (M, S) 的矩阵乘法
    first_shape, second_shape = (S, M), (M, S)
    yield SampleInput(make_arg(first_shape), args=(make_arg(second_shape),))

    # 如果数据类型为复数，则生成并返回一个 SampleInput 对象，用于测试共轭转置后的矩阵乘法
    if dtype.is_complex:
        yield SampleInput(make_arg(first_shape), args=(make_arg_conj(second_shape),))

    # 生成并返回一个 SampleInput 对象，用于测试空矩阵的乘法
    # (0, S) 和 (S, 0) 都是空矩阵的情况
    yield SampleInput(make_arg((0, S)), args=(make_arg(S, M),))
    yield SampleInput(make_arg((S, 0)), args=(make_arg(0, M),))


def sample_inputs_addmm(op_info, device, dtype, requires_grad, **kwargs):
    # 根据数据类型是否为复数，确定 alpha 和 beta 的默认值
    alpha_val = kwargs.get('alpha', 2 + 3j if dtype.is_complex else 0.6)
    beta_val = kwargs.get('beta', 1 + 2j if dtype.is_complex else 0.2)

    # 定义测试用例列表，每个元素包含三个形状以及一个布尔值，用于指示是否对第一个输入进行广播
    tests_list = [
        ((2, 3), (2, 2), (2, 3), False),
        ((3, 3), (3, 3), (3, 3), False),
    ]
    tests_with_lhs_broadcasting = [
        ((1,), (2, 2), (2, 3), True),
        ((), (2, 2), (2, 3), True),
    ]
    test_cases = tests_list + tests_with_lhs_broadcasting  # type: ignore[operator]

    kwargs = dict(alpha=alpha_val, beta=beta_val)
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 遍历所有测试用例，并生成对应的 SampleInput 对象
    for shape_a, shape_b, shape_c, broadcasts_input in test_cases:
        yield SampleInput(
            make_arg(shape_a),
            make_arg(shape_b),
            make_arg(shape_c),
            **kwargs,
        ).with_metadata(broadcasts_input=broadcasts_input)

    # 如果数据类型为复数，则生成额外的两个 SampleInput 对象，测试共轭转置后的 addmm
    if dtype.is_complex:
        shape = (3, 3)
        yield SampleInput(
            make_arg(shape),
            make_arg(shape, requires_grad=False).mH.requires_grad_(requires_grad),
            make_arg(shape),
            **kwargs,
        )
        yield SampleInput(
            make_arg(shape),
            make_arg(shape),
            make_arg(shape, requires_grad=False).mH.requires_grad_(requires_grad),
            **kwargs,
        )

    # 生成并返回两个 SampleInput 对象，用于测试空矩阵的 addmm
    # 如果 dtype 是浮点数类型
    if dtype.is_floating_point:
        # 使用 make_arg 函数创建 SampleInput 实例，传入参数 (S, M)， (S, 0)， (0, M)，和其他关键字参数 kwargs
        yield SampleInput(make_arg(S, M), make_arg(S, 0), make_arg(0, M), **kwargs)
        # 创建带有元数据的 SampleInput 实例，使用 make_arg 函数创建参数 (M)， (S, 0)， (0, M)，和其他关键字参数 kwargs
        # 元数据指示这是一个空的矩阵乘法，其中输入可以广播
        yield SampleInput(make_arg(M), make_arg(S, 0), make_arg(0, M), **kwargs).with_metadata(broadcasts_input=True)
# 定义一个生成稀疏矩阵稀疏采样加乘矩阵乘法的输入样本的函数
def sample_inputs_sparse_sampled_addmm(op_info, device, dtype, requires_grad, **kwargs):
    # 根据数据类型是否复数选择不同的 alpha 和 beta 值
    alpha = 2 + 3j if dtype.is_complex else 0.6
    beta = 1 + 2j if dtype.is_complex else 0.2
    # 创建一个函数，用于生成张量的辅助函数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # sparse.sampled_addmm 执行以下操作：alpha * (A @ B) * sparse_ones_like(C) + beta * C
    # 使用 itertools.product 生成 m, n, k 的所有可能组合
    for m, n, k in itertools.product([0, 5], repeat=3):
        yield SampleInput(
            # 创建 m x n 的单位矩阵，并转换为稀疏的 CSR 格式张量，设定是否需要梯度
            torch.eye(m, n, device=device, dtype=dtype)
            .to_sparse_csr()
            .requires_grad_(requires_grad),
            # 生成形状为 (m, k) 的张量输入
            make_arg((m, k)),
            # 生成形状为 (k, n) 的张量输入
            make_arg((k, n)),
            alpha=alpha,  # 设置 alpha 的值
            beta=beta,    # 设置 beta 的值
        )

# 定义一个生成稀疏矩阵乘法降维操作输入样本的函数
def sample_inputs_sparse_mm_reduce(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个函数，用于生成张量的辅助函数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义需要进行的降维操作列表
    reductions = ["sum", "mean", "amax", "amin"]
    # 使用 itertools.product 生成 m, k, reduce 的所有可能组合
    for m, k, reduce in product([5, 7], [3, 11], reductions):
        yield SampleInput(
            # 创建 m x m 的单位矩阵，并转换为稀疏的 CSR 格式张量，设定是否需要梯度
            torch.eye(m, m)
            .to(device=device, dtype=dtype)
            .to_sparse_csr()
            .requires_grad_(requires_grad),
            # 生成形状为 (m, k) 的张量输入
            make_arg((m, k)),
            # 降维操作类型，例如 'sum', 'mean', 'amax', 'amin'
            reduce,
        )

# 定义一个生成矩阵向量乘法输入样本的函数
def sample_inputs_mv(self, device, dtype, requires_grad, **kwargs):
    # 创建一个函数，用于生成张量的辅助函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, low=None, high=None, requires_grad=requires_grad)
    yield SampleInput(make_arg(S, M), make_arg(M))

# 定义一个生成批量矩阵乘法输入样本的函数
def sample_inputs_bmm(self, device, dtype, requires_grad, **kwargs):
    # 创建一个函数，用于生成张量的辅助函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, low=None, high=None, requires_grad=requires_grad)
    yield SampleInput(make_arg(M, S, M), make_arg(M, M, S))

# 定义一个生成点积和共轭点积输入样本的函数
def sample_inputs_dot_vdot(self, device, dtype, requires_grad, **kwargs):
    # 创建一个函数，用于生成张量的辅助函数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义生成共轭张量的辅助函数
    def make_arg_conj(size):
        return make_arg(size).conj().requires_grad_(requires_grad)

    # 生成形状为 (S,) 的张量输入样本
    yield SampleInput(make_arg((S, )), make_arg((S, )))
    if dtype.is_complex:
        # 若数据类型为复数，测试共轭输入张量的点积和共轭点积
        # 这部分在 test_conj_view 中测试，该测试仅涉及具有共轭输入张量的操作
        yield SampleInput(make_arg((S, )), make_arg_conj((S, )))

# 定义一个生成点积和共轭点积错误输入样本的函数
def error_inputs_dot_vdot(op_info, device, is_ref=False, **kwargs):
    # 创建生成张量的辅助函数，设定数据类型为 torch.float32
    make_input = partial(make_tensor, device=device, dtype=torch.float32)

    if not is_ref:
        # 生成错误输入样本，期望错误信息包含 'dot : expected both vectors to have same dtype'
        yield ErrorInput(SampleInput(make_input(1), args=(make_input(3, dtype=torch.float16),)),
                         error_regex='dot : expected both vectors to have same dtype')
    # 生成错误输入样本，期望错误信息包含 '1D tensors expected'
    yield ErrorInput(SampleInput(make_input(1, 1), args=(make_input(3),)),
                     error_regex='1D tensors expected')
    # 生成错误输入样本，期望错误信息包含 'inconsistent tensor size'
    yield ErrorInput(SampleInput(make_input(9), args=(make_input(3),)),
                     error_regex='inconsistent tensor size')
    # 如果设备不是 "cpu" 并且不是参考模式
    if device != "cpu" and not is_ref:
        # 返回一个错误输入的生成器，生成的错误输入为 SampleInput 对象，
        # 其中的参数是包含两个 make_input(3) 返回值的元组，第一个元素使用默认设备，
        # 第二个元素使用设备为 "cpu"
        yield ErrorInput(
            SampleInput(
                make_input(3),  # 生成默认设备的输入数据
                args=(make_input(3, device="cpu"),)  # 生成设备为 "cpu" 的输入数据
            ),
            error_regex='Expected all tensors to be on the same device'  # 错误信息的正则表达式
        )
# 使用部分函数make_tensor创建make_arg函数，固定了dtype、device、requires_grad参数
def sample_inputs_addmv(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义测试用例，每个测试用例是一个元组，包含size、mat、vec、beta、alpha和broadcasts_input
    test_cases = (((S,), (S, M), (M,), 1, 1, False),       # 没有广播
                  ((S,), (S, M), (M,), 0.2, 0.6, False),  # 没有广播
                  ((1,), (S, M), (M,), 1, 1, True),       # mat广播到size，vec广播到mat
                  ((1,), (S, M), (M,), 0.2, 0.6, True),   # mat广播到size，vec广播到mat
                  ((), (S, M), (M,), 1, 1, True),         # mat广播到size，vec广播到mat
                  ((), (S, M), (M,), 0.2, 0.6, True),     # mat广播到size，vec广播到mat
                  )

    # 含有广播的测试用例
    test_cases_with_broadcast = (((1,), (S, M), (M,), 1, 1, True),      # mat广播到size，vec广播到mat
                                 ((1,), (S, M), (M,), 0.2, 0.6, True),  # mat广播到size，vec广播到mat
                                 ((), (S, M), (M,), 1, 1, True),        # mat广播到size，vec广播到mat
                                 ((), (S, M), (M,), 0.2, 0.6, True),    # mat广播到size，vec广播到mat
                                 )

    # 组合所有测试用例
    cases = test_cases + test_cases_with_broadcast

    # 遍历所有测试用例
    for size, mat, vec, beta, alpha, broadcasts_input in cases:
        # 生成一个SampleInput对象，使用make_arg生成输入张量，设置args和kwargs参数，并指定是否广播
        yield SampleInput(make_arg(size), args=(make_arg(mat), make_arg(vec)),
                          kwargs=dict(beta=beta, alpha=alpha), broadcasts_input=broadcasts_input)

# 生成addbmm操作的输入样本
def sample_inputs_addbmm(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义测试用例，每个测试用例包含input_shape、batch1_shape、batch2_shape、beta、alpha和is_broadcasting
    test_cases = [((S, M), (S, S, S), (S, S, M), 1, 1, False),    # 没有广播
                  ((1,), (S, S, S), (S, S, M), 1, 1, True),      # batch1_shape广播到input_shape，batch2_shape广播到batch1_shape
                  ((S, M), (S, S, S), (S, S, M), 0.6, 0.2, False),# 没有广播
                  ((1,), (S, S, S), (S, S, M), 0.6, 0.2, True),  # batch1_shape广播到input_shape，batch2_shape广播到batch1_shape
                  ((), (S, S, S), (S, S, M), 1, 1, True),        # batch1_shape广播到input_shape，batch2_shape广播到batch1_shape
                  ((), (S, S, S), (S, S, M), 0.6, 0.2, True),    # batch1_shape广播到input_shape，batch2_shape广播到batch1_shape
                  ]

    # 遍历所有测试用例
    for input_shape, batch1_shape, batch2_shape, beta, alpha, is_broadcasting in test_cases:
        # 如果dtype是复数类型，生成复数类型的beta和alpha值
        if dtype.is_complex:
            beta_complex, alpha_complex = beta * (1 + 2j), alpha * (2 + 3j)
            yield SampleInput(make_arg(input_shape), args=(make_arg(batch1_shape), make_arg(batch2_shape)),
                              kwargs=dict(beta=beta_complex, alpha=alpha_complex), broadcasts_input=is_broadcasting)
        # 否则生成标量beta和alpha值
        yield SampleInput(make_arg(input_shape), args=(make_arg(batch1_shape), make_arg(batch2_shape)),
                          kwargs=dict(beta=beta, alpha=alpha), broadcasts_input=is_broadcasting)

# 生成addcmul和addcdiv操作的输入样本
def sample_inputs_addcmul_addcdiv(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 定义测试用例，每个测试用例包含三个元组：(input_shape, tensor1_shape, tensor2_shape)和is_broadcasting标志
    test_cases = [(((S, S), (S, S), (S, S)), False),      # 没有广播
                  (((S, S), (S, 1), (1, S)), False),      # 没有广播
                  (((1,), (S, S, 1), (1, S)), True),      # tensor1_shape广播到input_shape，tensor2_shape广播到tensor1_shape
                  (((), (), ()), False),                  # 没有广播
                  (((S, S), (), ()), True),               # tensor1_shape广播到input_shape
                  (((), (S, S, 1), (1, S)), True)         # tensor1_shape广播到input_shape，tensor2_shape广播到tensor1_shape
                  ]
    # 对于每个测试用例中的输入参数和广播输入进行迭代处理
    for input_args, broadcasts_input in test_cases:
        # 对于每个输入参数，如果是元组类型，则使用 exclude_zero=True 进行处理
        # 当前版本中，如果分母为零，addcdiv 函数会抛出 ZeroDivisionError
        # TODO: 在 https://github.com/pytorch/pytorch/issues/73638 修复后，可以移除 exclude_zeros
        args = tuple(make_arg(arg, exclude_zero=True) if isinstance(arg, tuple) else arg
                     for arg in input_args)
        # 生成一个带有元数据的 SampleInput 对象，其中包括广播输入信息
        yield SampleInput(*args).with_metadata(broadcasts_input=broadcasts_input)

        # 对于每个输入参数，如果是元组类型，则使用 exclude_zero=True 进行处理
        # 当前版本中，如果分母为零，addcdiv 函数会抛出 ZeroDivisionError
        # TODO: 在 https://github.com/pytorch/pytorch/issues/73638 修复后，可以移除 exclude_zeros
        args = tuple(make_arg(arg, exclude_zero=True) if isinstance(arg, tuple) else arg
                     for arg in input_args)
        # 生成一个带有元数据的 SampleInput 对象，其中包括广播输入信息
        yield SampleInput(
            *args, value=3.14 if dtype.is_floating_point or dtype.is_complex else 3
        ).with_metadata(broadcasts_input=broadcasts_input)
# 生成器函数，用于生成 addcmul_addcdiv 操作的输入样本
def reference_inputs_addcmul_addcdiv(op_info, device, dtype, requires_grad, **kwargs):
    # 调用 sample_inputs_addcmul_addcdiv 函数生成输入样本
    yield from sample_inputs_addcmul_addcdiv(
        op_info, device, dtype, requires_grad, **kwargs)

    # 定义支持的数据类型组合
    supported_dtypes = op_info.supported_dtypes(device)
    # 创建一个部分应用了 device 和 requires_grad 参数的 make_tensor 函数
    make_arg = partial(make_tensor, device=device, requires_grad=requires_grad)

    # 不同的数据类型和数值示例
    types = (
        (torch.float64, torch.complex128),
        (torch.bfloat16, torch.float32),
    )

    values = (
        None,
        True, False,
        3.14, 3,
        1.0, 1,
        0.0, 0,
        -3.14, -3,
        3.14 + 2.71j,
    )

    # 遍历类型组合和数值示例的笛卡尔积
    for (type2, type3), value in product(types, values):
        # 如果 type2 或 type3 不在支持的数据类型中，则跳过当前循环
        if (type2 not in supported_dtypes or
                type3 not in supported_dtypes):
            continue

        # 复数类型的值要求必须是 torch.complex128 类型，否则跳过当前循环
        if (type(value) is complex and
                type2 is not torch.complex128):
            continue

        # 创建三个张量参数
        arg1 = make_arg([5, 5], dtype=dtype)
        arg2 = make_arg([5, 5], dtype=type2)
        arg3 = make_arg([1, 5], dtype=type3)

        # 如果 value 不是 None，则创建带有 value 参数的 SampleInput 对象；否则创建不带 value 参数的 SampleInput 对象
        if value is not None:
            yield SampleInput(arg1, args=(arg2, arg3), kwargs=dict(value=value))
        else:
            yield SampleInput(arg1, args=(arg2, arg3))

# 生成器函数，用于生成 baddbmm 操作的输入样本
def sample_inputs_baddbmm(op_info, device, dtype, requires_grad, **kwargs):
    # 定义多个测试用例，每个测试用例由一组输入形状、批次形状、alpha、beta 和 broadcasts_input 组成
    test_cases = [((S, S, M), (S, S, S), (S, S, M), 1, 1, False),
                  ((1,), (S, S, S), (S, S, M), 1, 1, True),
                  ((S, S, M), (S, S, S), (S, S, M), 0.6, 0.2, False),
                  ((1,), (S, S, S), (S, S, M), 0.6, 0.2, True),
                  ((), (S, S, S), (S, S, M), 1, 1, True),
                  ((), (S, S, S), (S, S, M), 0.6, 0.2, True),
                  ]
    # 创建一个部分应用了 device、dtype、requires_grad 参数的 make_tensor 函数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    # 遍历测试用例
    for (input_shape, batch1_shape, batch2_shape, alpha, beta, broadcasts_input) in test_cases:
        # 生成 SampleInput 对象，包括输入张量和 alpha、beta 参数，带有 broadcasts_input 元数据
        yield SampleInput(
            make_arg(input_shape),
            make_arg(batch1_shape),
            make_arg(batch2_shape),
            beta=beta,
            alpha=alpha
        ).with_metadata(broadcasts_input=broadcasts_input)

        # 如果 dtype 是复数类型，则生成另一个 SampleInput 对象，参数乘以复数值
        if dtype.is_complex:
            yield SampleInput(
                make_arg(input_shape),
                make_arg(batch1_shape),
                make_arg(batch2_shape),
                beta=beta * (1 + 2j),
                alpha=alpha * (2 + 3j),
            ).with_metadata(broadcasts_input=broadcasts_input)
    # 如果数据类型是复数的话，执行以下操作
    if dtype.is_complex:
        # 定义不同形状的元组列表
        shapes = [(S, S, S), (S, M, S), (S, S, M)]
        # 使用生成器表达式生成参数列表，其中每个参数通过 make_arg 函数处理
        args = tuple(make_arg(s) for s in shapes)
        # 生成一个 SampleInput 对象，包括以下参数：
        # - 第一个参数，对应 args[0] 的转置结果
        # - 第二个参数，对应 args[1] 的转置并共轭后的结果，并根据 requires_grad 设置梯度需求
        # - 第三个参数，对应 args[2] 的转置并共轭后的结果，并根据 requires_grad 设置梯度需求
        # - beta 参数，复数乘法运算结果
        # - alpha 参数，复数乘法运算结果
        yield SampleInput(
            args[0].transpose_(-1, 1),
            args[1].transpose(-1, 1).conj().requires_grad_(requires_grad),
            args[2].transpose(-1, 1).conj().requires_grad_(requires_grad),
            beta=beta * (1 + 2j),
            alpha=alpha * (2 + 3j),
        )
# TODO: add reduction kwargs
# 定义一个生成多标签软间隔损失函数示例输入的函数
def sample_inputs_multilabel_soft_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用 make_tensor 函数，固定设备、数据类型、梯度要求
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同形状的张量输入
    shapes = (
        (S,),    # 形状为 (S,) 的张量
        (S, S),  # 形状为 (S, S) 的张量
    )

    # 遍历各种形状的张量输入
    for shape in shapes:
        # 返回一个带有权重和一个不带权重的示例输入
        yield SampleInput(_make_tensor(shape), args=(_make_tensor(shape, requires_grad=False),), kwargs={})
        # 返回一个带有权重的示例输入
        yield SampleInput(_make_tensor(shape), args=(_make_tensor(shape, requires_grad=False),),
                          kwargs={'weight': _make_tensor(shape, requires_grad=False)})

# 定义一个生成地址函数示例输入的函数
def sample_inputs_addr(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用 make_tensor 函数，固定设备、数据类型、梯度要求，并指定 low 和 high 为 None
    make_arg = partial(
        make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None
    )

    # 返回一个带有指定形状参数的示例输入
    yield SampleInput(make_arg(S, M), make_arg(S), make_arg(M))

    # 返回一个带有广播输入标记的示例输入
    yield SampleInput(make_arg(), make_arg(S), make_arg(M)).with_metadata(broadcasts_input=True)

    # 根据数据类型选择 alpha 和 beta 的值
    if dtype.is_complex:
        alpha, beta = 0.1 + 0.3j, 0.4 + 0.6j
    elif dtype.is_floating_point:
        alpha, beta = 0.2, 0.6
    else:
        alpha, beta = 2, 3

    # 返回一个带有指定形状和额外参数 beta 和 alpha 的示例输入
    yield SampleInput(make_arg(S, M), make_arg(S), make_arg(M), beta=beta, alpha=alpha)

    # 返回一个带有广播输入标记和额外参数 beta 和 alpha 的示例输入
    yield SampleInput(
        make_arg(),
        make_arg(S),
        make_arg(M),
        beta=beta,
        alpha=alpha,
    ).with_metadata(broadcasts_input=True)

    # 对于浮点数数据类型且不需要梯度的情况，返回一些无法通过梯度检查的示例输入
    if dtype.is_floating_point and not requires_grad:
        # 定义包含 NaN 的张量示例输入
        tensor_options = dict(device=device, dtype=dtype, requires_grad=requires_grad)
        yield SampleInput(
            torch.tensor([[math.nan]], **tensor_options),
            torch.tensor([0.0], **tensor_options),
            torch.tensor([0.0], **tensor_options),
            beta=0.0,
            alpha=0.0,
        ).with_metadata(broadcasts_input=True)

        yield SampleInput(
            torch.tensor([[0.0]], **tensor_options),
            torch.tensor([math.nan], **tensor_options),
            torch.tensor([math.nan], **tensor_options),
            beta=0.0,
            alpha=0.0,
        ).with_metadata(broadcasts_input=True)

# 定义一个生成零值函数示例输入的函数
def sample_inputs_zero_(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用 make_tensor 函数，固定设备、数据类型、梯度要求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同形状的张量输入
    cases = ((), (S, S, S), (S,))

    # 遍历各种形状的张量输入
    for shape in cases:
        # 返回一个带有指定形状的示例输入
        yield SampleInput(make_arg(shape))

# 定义一个生成多边损失函数示例输入的函数
def sample_inputs_multi_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用 make_tensor 函数，固定设备、数据类型、梯度要求
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 定义用于生成目标张量的函数
    make_target = partial(_make_tensor, dtype=torch.long, requires_grad=False)
    # 定义用于生成权重张量的函数
    make_weight = partial(_make_tensor, requires_grad=False)
    # 定义输入数据的多个测试用例
    inputs = (
        # 第1个测试用例：空输入，目标为一个空列表，参数为空字典
        ((), make_target([], low=0, high=1), {}),
        # 第2个测试用例：输入为一个长度为 S 的元组，目标为一个空列表，参数包含键 "p"，值为 1
        ((S,), make_target([], low=0, high=S), {"p": 1}),
        # 第3个测试用例：输入为一个长度为 S 的元组，目标为包含元素 1 的列表，参数包含键 "p"，值为 2
        ((S,), make_target([1], low=0, high=S), {"p": 2}),
        # 第4个测试用例：输入为长度为 S 和 M 的元组，目标为包含元素 S 的列表，参数包含键 "margin"，值为 1.0
        ((S, M), make_target([S], low=0, high=M), {"margin": 1.0}),
        # 第5个测试用例：输入为长度为 S 和 M 的元组，目标为包含元素 S 的列表，参数包含键 "margin"，值为 -3.14
        ((S, M), make_target([S], low=0, high=M), {"margin": -3.14}),
        # 第6个测试用例：输入为长度为 M 和 S 的元组，目标为包含元素 M 的列表，参数包含键 "weight"，值为 None
        ((M, S), make_target([M], low=0, high=S), {"weight": None}),
        # 第7个测试用例：输入为长度为 M 和 S 的元组，目标为包含元素 M 的列表，参数包含键 "weight"，值为从 -10.0 到 10.0 范围内的权重
        ((M, S), make_target([M], low=0, high=S), {"weight": make_weight([S], low=-10., high=10.)}),
        # 第8个测试用例：输入为长度为 M 和 S 的元组，目标为包含元素 M 的列表，参数包含键 "reduction"，值为 "none"
        ((M, S), make_target([M], low=0, high=S), {"reduction": "none"}),
        # 第9个测试用例：输入为长度为 M 和 S 的元组，目标为包含元素 M 的列表，参数包含键 "reduction"，值为 "mean"
        ((M, S), make_target([M], low=0, high=S), {"reduction": "mean"}),
        # 第10个测试用例：输入为长度为 M 和 S 的元组，目标为包含元素 M 的列表，参数包含键 "reduction"，值为 "sum"
        ((M, S), make_target([M], low=0, high=S), {"reduction": "sum"}),
    )

    # 遍历每个输入测试用例，并生成相应的 SampleInput 对象
    for input_shape, target, kwargs in inputs:
        # 使用 _make_tensor 函数创建输入数据的张量表示，传入目标和参数
        yield SampleInput(_make_tensor(input_shape), args=(target,), kwargs=kwargs)
# 生成多分类边界损失函数的参考输入
def reference_inputs_multi_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 使用 sample_inputs_multi_margin_loss 函数生成样本输入
    yield from sample_inputs_multi_margin_loss(op_info, device, dtype, requires_grad, **kwargs)
    
    # 部分应用 make_tensor 函数，创建特定参数的张量生成器
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 创建目标张量的生成器，固定类型为 torch.long，无需梯度
    make_target = partial(_make_tensor, dtype=torch.long, requires_grad=False)
    # 创建权重张量的生成器，无需梯度
    make_weight = partial(_make_tensor, requires_grad=False)

    # 定义一组输入样本元组
    inputs = (
        ((), make_target([], low=0, high=1)),  # 空输入，目标为 [0, 1] 之间的整数
        ((S,), make_target([], low=0, high=S)),  # 长度为 S 的一维输入，目标为 [0, S] 之间的整数
        ((S,), make_target([1], low=0, high=S)),  # 长度为 S 的一维输入，目标为 [0, S] 之间的整数，目标有一个维度
        ((M, S), make_target([M], low=0, high=S)),  # M × S 大小的二维输入，目标为 [0, S] 之间的整数，有 M 个目标
    )
    
    # 定义 p 的值
    ps = (1, 2)
    # 定义 margin 的值
    margins = (0, 7, -3.14)
    # 定义 weights 的值
    weights = (False, True)
    # 定义 reductions 的值
    reductions = (None, "none", "mean", "sum")

    # 使用 product 函数遍历所有可能的输入组合
    for (input_shape, target), p, margin, weight, reduction in product(inputs, ps, margins, weights, reductions):
        # 创建输入张量
        input = _make_tensor(input_shape)
        # 根据输入张量的维度创建权重张量的形状
        weight_shape = [input.size(-1)] if input.ndim > 0 else [1]
        # 如果 weight 参数为 True，则创建权重张量在 [-10, 10] 之间的随机数
        weight = make_weight(weight_shape, low=-10., high=10.) if weight else None
        # 构造参数字典 kwargs，包括 p、margin 和 weight
        kwargs = {"p": p, "margin": margin, "weight": weight}
        # 如果 reduction 不为 None，则添加到 kwargs 中
        if reduction is not None:
            kwargs["reduction"] = reduction
        # 返回样本输入对象 SampleInput
        yield SampleInput(input, args=(target,), kwargs=kwargs)


# 生成多分类边界损失函数的错误输入
def error_inputs_multi_margin_loss(op, device, **kwargs):
    # 部分应用 make_tensor 函数，创建特定参数的张量生成器
    make_input = partial(make_tensor, device=device, dtype=torch.float32)
    
    # 无效的 reduction 错误输入
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5,),), kwargs={'reduction': 'abc'}),
                     error_type=ValueError, error_regex='abc is not a valid value for reduction')
    
    # 无效的输入尺寸错误输入
    yield ErrorInput(SampleInput(make_input(5, 0), args=(make_input(5,),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'Expected non-empty vector or matrix with optional 0-dim batch size, but got: \[5, 0\]')
    
    # 无效的目标尺寸错误输入
    yield ErrorInput(SampleInput(make_input(0,), args=(make_input(5,),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'Expected non-empty vector or matrix with optional 0-dim batch size, but got: \[0\]')
    
    # 不一致的目标尺寸错误输入
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4),), kwargs={}),
                     error_type=RuntimeError, error_regex=r'inconsistent target size, expected 5 but got \[5, 4\]')
    
    # 无效的目标数据类型错误输入
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5,),), kwargs={}),
                     error_type=RuntimeError, error_regex='expected scalar type Long but found Float')
    
    # 无效的权重维度错误输入
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5,),), kwargs={'weight': make_input(())}),
                     error_type=ValueError, error_regex='weight must be one-dimensional')
    # 生成一个 ErrorInput 对象，用于测试给定的输入和参数是否触发特定错误
    yield ErrorInput(
        # 使用 SampleInput 构造函数创建一个输入示例，其中包含一个 5x4 的输入和相应的参数
        SampleInput(make_input(5, 4),
                    # 传递额外的位置参数，这里传入一个长度为 5 的输入
                    args=(make_input(5,),),
                    # 传递额外的关键字参数，这里传入一个 5x1 的权重数组
                    kwargs={'weight': make_input(5, 4)}),
        # 指定预期的错误类型为 ValueError
        error_type=ValueError,
        # 指定预期的错误消息正则表达式为 'weight must be one-dimensional'
        error_regex='weight must be one-dimensional')

    # 生成另一个 ErrorInput 对象，用于测试给定的输入和参数是否触发特定错误
    yield ErrorInput(
        # 使用 SampleInput 构造函数创建一个输入示例，其中包含一个 5x4 的输入和相应的参数
        SampleInput(make_input(5, 4),
                    # 传递额外的位置参数，这里传入一个长度为 5 的输入
                    args=(make_input(5,),),
                    # 传递额外的关键字参数，这里传入一个长度为 5 的权重数组
                    kwargs={'weight': make_input(5,)}),
        # 指定预期的错误类型为 RuntimeError
        error_type=RuntimeError,
        # 指定预期的错误消息正则表达式为 'inconsistent weight size, expected 4 but got [5]'
        error_regex=r'inconsistent weight size, expected 4 but got \[5\]')

    # 生成另一个 ErrorInput 对象，用于测试给定的输入和参数是否触发特定错误
    # 这里的注释是为了说明 'p' 参数为 3 时触发的错误
    yield ErrorInput(
        # 使用 SampleInput 构造函数创建一个输入示例，其中包含一个 5x4 的输入和相应的参数
        SampleInput(make_input(5, 4),
                    # 传递额外的位置参数，这里传入一个长度为 5 的输入
                    args=(make_input(5,),),
                    # 传递额外的关键字参数，这里传入 'p' 参数为 3
                    kwargs={'p': 3}),
        # 指定预期的错误类型为 ValueError
        error_type=ValueError,
        # 指定预期的错误消息正则表达式为 'only p == 1 and p == 2 supported'
        error_regex='only p == 1 and p == 2 supported')
# 定义一个方法，生成多个不同形状和参数的输入组合，用于测试对数求和指数函数
def sample_inputs_logsumexp(self, device, dtype, requires_grad, **kwargs):
    # 不同的输入组合：(形状, 维度, 是否保持维度)
    inputs = (
        ((), (0,), True),               # 空元组，维度0，保持维度
        ((S, S), (1,), True),           # 形状为(S, S)，维度1，保持维度
        ((S, S), (1,), False),          # 形状为(S, S)，维度1，不保持维度
        ((S, S), (-2,), False),         # 形状为(S, S)，维度-2，不保持维度
        ((S, S), (0, 1), False),        # 形状为(S, S)，维度0和1，不保持维度
    )
    
    # 测试数值稳定性的大输入
    lows = (None, 1e3, 1e6) if dtype in (torch.float32, torch.float64) else (None,)
    for low in lows:
        high = low * 2 if low is not None else None
        for shape, dim, keepdim in inputs:
            # 创建张量，用于测试
            t = make_tensor(shape, dtype=dtype, device=device,
                            low=low, high=high,
                            requires_grad=requires_grad)
            # 生成一个 SampleInput 对象，并返回
            yield SampleInput(t, dim, keepdim)

# 定义一个方法，生成对数求和指数函数的参考输入
def reference_inputs_logsumexp(op, device, dtype, requires_grad, **kwargs):
    # 使用 sample_inputs_logsumexp 方法生成输入
    yield from sample_inputs_logsumexp(op, device, dtype, requires_grad, **kwargs)
    
    # 添加额外的输入用例
    # https://github.com/pytorch/pytorch/issues/91843
    t = torch.tensor([20, 30, 100], dtype=dtype, device=device, requires_grad=requires_grad)
    yield SampleInput(t, 0, False)

    t = torch.tensor((), dtype=dtype, device=device, requires_grad=requires_grad)
    yield SampleInput(t, 0, False)

    # 测试掩码功能
    # https://github.com/pytorch/pytorch/pull/91860#pullrequestreview-1241344073
    t = torch.tensor(float("inf"))
    yield SampleInput(t, 0, True)

# 定义一个方法，生成多种形状和参数的输入组合，用于测试张量的类似函数
def sample_inputs_like_fns(self, device, dtype, requires_grad, **kwargs):
    inputs = [
        ((), {}),                                    # 空元组
        ((S, S), {}),                                # 形状为(S, S)
        ((0, S, 0), {}),                             # 形状为(0, S, 0)
        ((S,), {'dtype': dtype, 'device': device}),  # 形状为(S)，指定dtype和device
        ((S,), {'dtype': torch.double}),             # 形状为(S)，指定dtype为torch.double
        ((S,), {'device': 'cpu'}),                   # 形状为(S)，指定device为cpu
        ((S,), {'dtype': torch.double, 'device': 'cpu'}),  # 形状为(S)，指定dtype为torch.double，device为cpu
    ]
    
    # 如果CUDA可用，则添加一个CUDA设备的输入
    if torch.cuda.is_available():
        inputs.append(((S,), {'device': 'cuda'}))

    for shape, kwargs in inputs:
        # 创建张量，用于测试
        t = make_tensor(shape, dtype=dtype, device=device,
                        low=None, high=None,
                        requires_grad=requires_grad)
        # 生成一个 SampleInput 对象，并返回
        yield SampleInput(t, **kwargs)

# 定义一个方法，生成类似函数的参考输入
def reference_inputs_like_fns(op, device, dtype, requires_grad, **kwargs):
    # 使用 sample_inputs_like_fns 方法生成输入
    yield from sample_inputs_like_fns(op, device, dtype, requires_grad, **kwargs)
    
    # 添加形状的测试用例
    cases = (
        (), (0,), (1, 0), (1, 1, 4, 5), (5, 3, 0, 1), (1, 4, 3, 1, 1)
    )
    
    # 创建一个部分应用的 make_tensor 函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    for shape in cases:
        yield SampleInput(make_arg(shape))
        yield SampleInput(make_arg(shape).transpose(0, -1))
        yield SampleInput(make_arg(shape, noncontiguous=True))
        yield SampleInput(make_arg(shape, noncontiguous=True).transpose(0, -1))

# 定义一个方法，生成多标签边际损失函数的输入组合
def sample_inputs_multilabel_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 创建一个偏函数 `make_target`，用于创建长整型的张量，不需要梯度
    make_target = partial(_make_tensor, dtype=torch.long, requires_grad=False)

    # 定义多组输入数据 `inputs`，每组包含不同的形状 `shape`、目标张量 `target` 和可选参数 `kwargs`
    inputs = (
        ([], make_target([], low=0, high=1), {}),
        ([S], make_target([S], low=0, high=S), {}),
        ([M, S], make_target([M, S], low=0, high=S), {}),
        ([M, S], make_target([M, S], low=0, high=S), {"reduction": "none"}),
        ([M, S], make_target([M, S], low=0, high=S), {"reduction": "mean"}),
        ([M, S], make_target([M, S], low=0, high=S), {"reduction": "sum"}),
    )

    # 对每组输入数据进行迭代处理
    for shape, target, kwargs in inputs:
        # 生成一个 `SampleInput` 对象，传入一个根据 `shape` 创建的张量作为参数，以及目标张量和可选参数
        yield SampleInput(_make_tensor(shape), args=(target,), kwargs=kwargs)
# 生成多标签边际损失函数的参考输入数据集
def reference_inputs_multilabel_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 从示例输入数据生成器中获取多标签边际损失函数的样本输入
    yield from sample_inputs_multilabel_margin_loss(op_info, device, dtype, requires_grad, **kwargs)
    
    # 创建部分应用了设备、数据类型和梯度需求的张量生成函数
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 创建部分应用了设备、数据类型和梯度不需要的目标张量生成函数
    make_target = partial(_make_tensor, dtype=torch.long, requires_grad=False)
    # 创建部分应用了设备、数据类型和梯度不需要的 torch.tensor 函数作为目标张量生成函数
    make_target_tensor = partial(torch.tensor, device=device, dtype=torch.long, requires_grad=False)

    # 定义多种输入数据及其对应的目标张量和缩减方式
    inputs = (
        # 随机测试，包括 -1 的目标标签
        ([], make_target([], low=-1, high=1)),
        ([S], make_target([S], low=-1, high=S)),
        ([M, S], make_target([M, S], low=-1, high=S)),
        # 重复的目标标签和 -1（第一个 -1 之后的标签将被忽略）
        ([], make_target_tensor(-1)),
        ([7], make_target_tensor([2, 0, 6, -1, 4, -1, 6])),
        ([4, 5], make_target_tensor([[4, -1, 0, -1, 2], [0, 0, 4, 1, 4], [-1, 3, -1, 1, 0], [4, 3, 2, 1, 0]])),
    )
    # 定义不同的缩减方式
    reductions = (None, "none", "mean", "sum")

    # 对每种输入数据及缩减方式进行排列组合
    for (shape, target), reduction in product(inputs, reductions):
        kwargs = {}
        if reduction is not None:
            kwargs["reduction"] = reduction
        # 生成样本输入对象
        yield SampleInput(_make_tensor(shape), args=(target,), kwargs=kwargs)


# 处理多标签边际损失函数的错误输入
def error_inputs_multilabel_margin_loss(op, device, **kwargs):
    # 创建部分应用了设备的 torch.float32 张量生成函数作为输入生成函数
    make_input = partial(make_tensor, device=device, dtype=torch.float32)
    # 无效的缩减方式
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4),), kwargs={'reduction': 'abc'}),
                     error_type=ValueError, error_regex='abc is not a valid value for reduction')
    # 无效的输入
    yield ErrorInput(SampleInput(make_input(5, 0), args=(make_input(5, 4),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'Expected non-empty vector or matrix with optional 0-dim batch size, but got: \[5, 0\]')
    yield ErrorInput(SampleInput(make_input(0,), args=(make_input(0,),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'Expected non-empty vector or matrix with optional 0-dim batch size, but got: \[0\]')
    # 无效的目标张量
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(4,),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'inconsistent target size: \[4\] for input of size: \[5, 4\]')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input((),),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'inconsistent target size: \[\] for input of size: \[5, 4\]')


# 复制张量并设置为需要梯度
def get_independent_tensor(tensor):
    return tensor.clone().requires_grad_(tensor.requires_grad)


# 生成随机整数输入数据集
def sample_inputs_randint(self, device, dtype, requires_grad, **kwargs):
    low = 2
    high = 10
    # 使用 sample_inputs_like_fns 方法生成样本数据，循环遍历每个样本
    for sample in sample_inputs_like_fns(self, device, dtype, requires_grad, **kwargs):
        # 设置 sample.kwargs 字典中的 'device' 键，默认为当前设备
        sample.kwargs.setdefault('device', device)
        # 生成一个新的 SampleInput 对象，传入 high 作为参数
        yield SampleInput(high, sample.input.shape, *sample.args, **sample.kwargs)
        # 生成一个新的 SampleInput 对象，传入 low 和 high 作为参数
        yield SampleInput(low, high, sample.input.shape, *sample.args, **sample.kwargs)
# 定义一个生成器函数，生成与指定样本类似的随机整数样本输入
def sample_inputs_randint_like(self, device, dtype, requires_grad, **kwargs):
    # 设置随机整数的下界和上界
    low = 2
    high = 10

    # 调用 sample_inputs_like_fns 函数生成样本输入的迭代器
    for sample in sample_inputs_like_fns(self, device, dtype, requires_grad, **kwargs):
        # 使用上界 high 来创建一个新的 SampleInput 对象
        yield SampleInput(
            sample.input,  # 使用原始样本的输入
            high,  # 设定为上界
            *sample.args,  # 传递原始样本的其他位置参数
            **sample.kwargs)  # 传递原始样本的其他关键字参数
        # 使用下界 low 和上界 high 来创建另一个新的 SampleInput 对象
        yield SampleInput(
            get_independent_tensor(sample.input),  # 使用独立的张量作为输入
            low,  # 设定为下界
            high,  # 设定为上界
            *sample.args,  # 传递原始样本的其他位置参数
            **sample.kwargs)  # 传递原始样本的其他关键字参数

# 定义一个生成器函数，生成 margin ranking loss 函数的样本输入
def sample_inputs_margin_ranking_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用 make_tensor 函数，设定设备、数据类型和梯度需求
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同形状的张量样本
    shapes = (
        (),
        (S,),
        (S, S),
        (S, S, S),
    )

    # 不同的 margin 和 reduction 组合
    margins = (0., 1.)
    reductions = ('sum', 'mean', 'none')

    # 遍历所有形状和 margin/reduction 组合，生成样本输入
    for shape in shapes:
        for margin, reduction in product(margins, reductions):
            kwargs = {'margin': margin, 'reduction': reduction}
            yield SampleInput(_make_tensor(shape),  # 生成指定形状的张量作为输入
                              args=(_make_tensor(shape, requires_grad=False),  # 生成两个不需梯度的张量作为参数
                                    _make_tensor(shape, requires_grad=False)),  # 生成两个不需梯度的张量作为参数
                              kwargs=kwargs)  # 传递 margin 和 reduction 参数作为关键字参数

# 定义一个生成器函数，生成 margin ranking loss 函数的参考输入
def reference_inputs_margin_ranking_loss(op, device, dtype, requires_grad, **kwargs):
    # 委托给 sample_inputs_margin_ranking_loss 函数生成 margin ranking loss 的样本输入
    yield from sample_inputs_margin_ranking_loss(op, device, dtype, requires_grad, **kwargs)
    
    # 部分应用 make_tensor 函数，设定设备、数据类型和梯度需求
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 生成特定 reduction 类型的样本输入
    for reduction in ('sum', 'mean', 'none'):
        if dtype.is_floating_point:  # 只支持整数和浮点数
            # NaN 传播处理
            inp1 = make_input((10, ))
            inp1[2] = float('nan')  # 将特定位置设为 NaN
            inp2 = make_input((10, ))
            inp2[4] = float('nan')  # 将特定位置设为 NaN
            target = make_input((10, ))
            inp2[9] = float('nan')  # 将特定位置设为 NaN
            yield SampleInput(inp1, args=(inp2, target), kwargs={'reduction': reduction})  # 生成 SampleInput 对象

            # 无穷大处理
            inp1 = make_input((10, ))
            inp2[1] = float('inf')  # 将特定位置设为无穷大
            inp2 = make_input((10, ))
            inp2[4] = float('inf')  # 将特定位置设为无穷大
            target = make_input((10, ))
            inp2[7] = float('inf')  # 将特定位置设为无穷大
            yield SampleInput(inp1, args=(inp2, target), kwargs={'reduction': reduction})  # 生成 SampleInput 对象

        # 广播处理
        inp1 = make_input((5, 2))
        inp2 = make_input((5, 1))
        target = make_input((1, 2))
        yield SampleInput(inp1, args=(inp2, target), kwargs={'reduction': reduction})  # 生成 SampleInput 对象

# 定义一个生成器函数，生成 margin ranking loss 函数的错误输入
def error_inputs_margin_ranking_loss(op, device, **kwargs):
    # 部分应用 make_tensor 函数，设定设备为 device，数据类型为 torch.float32
    make_input = partial(make_tensor, device=device, dtype=torch.float32)

    # 生成无效 reduction 值的错误输入
    yield ErrorInput(SampleInput(make_input(5, 4),  # 生成指定形状的张量作为输入
                                 args=(make_input(5, 4), make_input(5, 4),),  # 生成两个张量作为参数
                                 kwargs={'reduction': 'abc'}),  # 指定无效的 reduction 值作为关键字参数
                     error_type=ValueError, error_regex='is not a valid value')  # 指定错误类型和正则表达式匹配

    # 生成无效输入形状的错误输入
    # 使用 yield 生成一个 ErrorInput 对象，其中包含 SampleInput 对象作为参数
    # SampleInput 的第一个参数是通过 make_input 生成的输入数据，参数为 (5, 4)
    # SampleInput 的第二个参数是一个元组，包含两个通过 make_input 生成的输入数据，分别为 (5, 4) 和 (5,)
    # ErrorInput 的 error_regex 参数为 'margin_ranking_loss : All input tensors should'
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4), make_input(5,),)),
                     error_regex='margin_ranking_loss : All input tensors should')
# 定义一个生成器函数，用于生成包含不同参数组合的输入示例
def sample_inputs_new_fns(self, device, dtype, requires_grad, *, is_strided=False, **kwargs):
    # input_shape, output_shape, strides, kwargs
    # 预定义一系列不同参数组合的输入示例，每个示例由四个元素组成：input_shape, output_shape, strides, kwargs
    inputs = [
        ((), (), (), {}),  # 示例1：空元组作为各参数的默认值
        ((S, S), (2, 0), (3, 4), {}),  # 示例2：包含两个维度的形状，具体的输出形状和步长
        ((0, S, 0), (3, 2, 2), (1, 2, 3), {}),  # 示例3：包含零维的形状，以及具体的输出形状和步长
        ((S,), (2, 3), (7, 8), {'dtype': dtype, 'device': device}),  # 示例4：包含设备和数据类型的自定义参数
        # 固定一些数据类型和设备。我们想要测试数据类型和设备与输入不同的情况
        ((S,), (10,), (S,), {'dtype': torch.double}),  # 示例5：固定数据类型为双精度浮点数
        ((S,), (1, 1, 12), (S, L, M), {'device': 'cpu'}),  # 示例6：指定设备为 CPU
        ((S,), (2, 2, 2), (L, M, S), {'dtype': torch.double, 'device': 'cpu'}),  # 示例7：指定数据类型为双精度浮点数，设备为 CPU
    ]
    # 如果 CUDA 可用，添加一个额外的输入示例
    if torch.cuda.is_available():
        inputs.append(((S,), (7, 2), (3, 4), {'device': 'cuda'}))

    # 遍历生成器函数的输入参数列表，并生成对应的 SampleInput 实例
    for input_shape, output_shape, strides, kwargs in inputs:
        # 调用 make_tensor 函数创建张量 t，根据不同的情况决定是否使用步长参数
        t = make_tensor(input_shape, dtype=dtype, device=device,
                        low=None, high=None,
                        requires_grad=requires_grad)
        if is_strided:
            # 如果需要使用步长参数，生成带有步长的 SampleInput 实例
            yield SampleInput(t, output_shape, strides, **kwargs)
        else:
            # 否则，生成普通的 SampleInput 实例
            yield SampleInput(t, output_shape, **kwargs)

# 定义一个生成器函数，生成不同形状和步长的输入示例
def sample_inputs_empty_strided(op, device, dtype, requires_grad=False, **kwargs):
    # 预定义一系列不同形状和步长的输入示例
    inputs = [
        ((), (), {'dtype': dtype, 'device': device}),  # 示例1：空形状和步长的输入，指定数据类型和设备
        ((S,), (4,), {'dtype': dtype, 'device': device}),  # 示例2：指定一个维度的形状和步长，数据类型和设备
        ((S, S), (2, 1), {'dtype': dtype, 'device': device}),  # 示例3：指定两个维度的形状和步长，数据类型和设备
        ((S, S, S), (2, 0, 1), {'dtype': dtype, 'device': device}),  # 示例4：指定三个维度的形状和步长，数据类型和设备
    ]

    # 遍历生成器函数的输入参数列表，并生成对应的 SampleInput 实例
    for shape, strides, kwargs in inputs:
        yield SampleInput(shape, strides, requires_grad=requires_grad, **kwargs)

# 定义一个生成器函数，生成不同形状的输入示例
def sample_inputs_empty(op, device, dtype, requires_grad, **kwargs):
    # 预定义一系列不同形状的输入示例
    cases = (
        (), (0,), (1,), (1, 3, 5), (5, 3, 1), (1, 0, 5, 1),
    )

    # 遍历生成器函数的输入参数列表，并生成对应的 SampleInput 实例
    for case in cases:
        yield SampleInput(case, device=device, dtype=dtype, requires_grad=requires_grad)

# 定义一个生成器函数，生成不同形状和排列的输入示例
def sample_inputs_empty_permuted(op, device, dtype, requires_grad, **kwargs):
    # 预定义一系列不同形状的输入示例
    cases = (
        (), (0,), (1,), (1, 3, 5), (5, 3, 1), (1, 0, 5, 1),
    )

    # 遍历形状列表和其排列的所有可能，生成对应的 SampleInput 实例
    for case in cases:
        for layout in itertools.permutations(range(len(case))):
            yield SampleInput(case, layout, device=device, dtype=dtype, requires_grad=requires_grad)

# 定义一个生成器函数，生成引发错误的输入示例
def error_inputs_empty_permuted(op_info, device, **kwargs):
    # 生成错误输入的示例，每个示例由 ErrorInput 实例组成
    yield ErrorInput(
        SampleInput((2,), args=((0, 1),)),  # 示例1：错误的输入，引发 RuntimeError，期望的错误信息为 "Number of dimensions in size does not match the length of the physical_layout"
        error_type=RuntimeError,
        error_regex="Number of dimensions in size does not match the length of the physical_layout"
    )
    yield ErrorInput(
        SampleInput((2,), args=((3,),)),  # 示例2：错误的输入，引发 RuntimeError，期望的错误信息为 "Dimension out of range"
        error_type=RuntimeError,
        error_regex="Dimension out of range"
    )
    yield ErrorInput(
        SampleInput((2, 3), args=((0, 0),)),  # 示例3：错误的输入，引发 RuntimeError，期望的错误信息为 "Duplicate dim not allowed"
        error_type=RuntimeError,
        error_regex="Duplicate dim not allowed"
    )

# 定义一个生成器函数，生成标量张量的输入示例
def sample_inputs_scalar_tensor(op, device, dtype, requires_grad, **kwargs):
    `
        # 不包括标量张量在内的 vals，因为元测试由于缺乏对 _local_scalar_dense 的元数据支持而开始失败
        # torch.tensor(2, device=device)
        # 定义一个包含整数值的元组 vals
        vals = (-5, 0, 1)
    
        # 遍历元组 vals 中的每个元素
        for item in vals:
            # 使用 SampleInput 类实例化对象，传入当前元素 item，以及设备、数据类型和是否需要梯度的标志
            yield SampleInput(item, device=device, dtype=dtype, requires_grad=requires_grad)
def sample_inputs_eye(op, device, dtype, requires_grad, **kwargs):
    # 定义可能的大小值，其中包括特定的 L、M、S 值
    sizes = (None, 0, 1, 2, 3, 4, 7, L, M, S)

    # 遍历所有可能的大小组合
    for n, m in product(sizes, sizes):
        # 如果 n 为 None，则跳过当前循环
        if n is None:
            continue

        # 准备输入参数的关键字字典，设定设备、数据类型和是否需要梯度信息
        _kwargs = {'device': device, 'dtype': dtype, 'requires_grad': requires_grad}
        
        # 如果 m 为 None，则创建只有 n 参数的 SampleInput 实例
        if m is None:
            yield SampleInput(n, args=(), kwargs=_kwargs)
        else:
            # 否则创建包含 n 和 m 参数的 SampleInput 实例
            yield SampleInput(n, args=(m,), kwargs=_kwargs)

def error_inputs_eye(op_info, device, **kwargs):
    # 准备输入参数的关键字字典，设定设备和默认数据类型为 torch.float32
    _kwargs = {'device': device, 'dtype': torch.float32}

    # 返回 n 为负数的错误输入实例
    yield ErrorInput(
        SampleInput(-1, args=(), kwargs=_kwargs),
        error_regex="n must be greater or equal to 0, got -1"
    )

    yield ErrorInput(
        SampleInput(-7, args=(42,), kwargs=_kwargs),
        error_regex="n must be greater or equal to 0, got -7"
    )

    # 返回 m 为负数的错误输入实例
    yield ErrorInput(
        SampleInput(0, args=(-3,), kwargs=_kwargs),
        error_regex="m must be greater or equal to 0, got -3"
    )


def sample_inputs_new_full(self, device, dtype, requires_grad, **kwargs):
    def get_val(dtype):
        # 返回一个空张量的单一值，以便作为填充值使用
        return make_tensor([], dtype=dtype, device="cpu").item()

    # 遍历 sample_inputs_new_fns 函数生成的样本输入
    for sample in sample_inputs_new_fns(self, device, dtype, requires_grad, **kwargs):
        # 确定要传递给 new_full 方法的标量与结果张量的数据类型一致
        use_dtype = sample.kwargs['dtype'] if 'dtype' in sample.kwargs else dtype
        yield SampleInput(
            sample.input, *sample.args, get_val(use_dtype), **sample.kwargs)

def sample_inputs_full_like(self, device, dtype, requires_grad, **kwargs):
    def get_val(dtype):
        # 返回一个空张量的单一值，以便作为填充值使用
        return make_tensor([], dtype=dtype, device="cpu").item()

    # 预设不同输入的形状、填充值和关键字参数
    inputs = [
        ((), get_val(dtype), {}),
        ((S, S), get_val(dtype), {}),
        ((0, S, 0), get_val(dtype), {}),
        ((S,), get_val(dtype), {'dtype': dtype, 'device': device}),
        ((S,), get_val(torch.double), {'dtype': torch.double}),
        ((S,), get_val(dtype), {'device': 'cpu'}),
        ((S,), get_val(torch.double), {'dtype': torch.double, 'device': 'cpu'}),
    ]
    # 如果有 CUDA 设备可用，则添加一个 CUDA 设备的输入
    if torch.cuda.is_available():
        inputs.append(((S,), get_val(dtype), {'device': 'cuda'}))

    # 遍历所有预设的输入组合
    for shape, fill_value, kwargs in inputs:
        # 创建一个具有指定形状、数据类型、设备和是否需要梯度信息的张量
        t = make_tensor(shape, dtype=dtype, device=device,
                        low=None, high=None,
                        requires_grad=requires_grad)
        yield SampleInput(t, fill_value, **kwargs)

def sample_inputs_multinomial(self, device, dtype, requires_grad, **kwargs):
    # 创建测试用例
    cases = [
        ([3], 3, {}), # 第一种情况：shape为[3], num_samples为3, 无额外参数
        ([10], 3, {}), # 第二种情况：shape为[10], num_samples为3, 无额外参数
        ([3, 10], 3, {}), # 第三种情况：shape为[3, 10], num_samples为3, 无额外参数
        ([3], 3, dict(replacement=False)), # 第四种情况：shape为[3], num_samples为3, 需要额外参数replacement为False
        ([3], 3, dict(replacement=True)), # 第五种情况：shape为[3], num_samples为3, 需要额外参数replacement为True
        ([3, 4], 4, dict(replacement=True)), # 第六种情况：shape为[3, 4], num_samples为4, 需要额外参数replacement为True
        ([3, 4], 4, dict(replacement=False)), # 第七种情况：shape为[3, 4], num_samples为4, 需要额外参数replacement为False
    ]

    # 遍历测试用例
    for shape, num_samples, kwargs in cases:
        # 根据shape、dtype、device、low、high、requires_grad参数创建张量并赋值给t
        t = make_tensor(shape, dtype=dtype, device=device,
                        low=0, high=None,
                        requires_grad=requires_grad)
        # 生成样本输入
        yield SampleInput(t, num_samples, **kwargs)
# 生成普通输入样本的生成器函数，用于生成正常情况下的输入
def sample_inputs_normal_common(self, device, dtype, requires_grad, cases, **kwargs):
    # 内部函数：根据值或形状生成张量
    def get_value_or_make_tensor(value_or_shape):
        if isinstance(value_or_shape, list):
            return make_tensor(value_or_shape, dtype=dtype, device=device,
                               low=0, high=None,
                               requires_grad=requires_grad)
        return value_or_shape

    # 遍历每个测试用例，生成均值和标准差的张量，然后生成 SampleInput 实例
    for value_or_mean_shape, value_or_std_shape, kwargs in cases:
        mean = get_value_or_make_tensor(value_or_mean_shape)
        std = get_value_or_make_tensor(value_or_std_shape)
        yield SampleInput(mean, std, **kwargs)

# 生成普通输入样本的生成器函数，其中第一个参数为张量的形状
def sample_inputs_normal_tensor_first(self, device, dtype, requires_grad, **kwargs):
    # 定义测试用例列表
    cases = [
        ([], [], {}),
        ([3], [3], {}),
        ([3, 4, 2], [3, 4, 2], {}),
        ([2, 3], 1.1, {}),
        ([1, 2, 3], [5, 2, 3], {}),  # broadcasting
    ]

    # 调用普通输入生成函数并返回生成器结果
    return sample_inputs_normal_common(self, device, dtype, requires_grad, cases, **kwargs)

# 生成普通输入样本的生成器函数，其中第二个参数为张量的形状
def sample_inputs_normal_tensor_second(self, device, dtype, requires_grad, **kwargs):
    # 依次生成不同形状的 SampleInput 实例的生成器
    yield SampleInput(1.6, 0.3, [2, 3], dtype=dtype, device=device)
    yield SampleInput(1.6, 0.3, [2, 2, 2], dtype=dtype, layout=torch.strided, device=device)
    yield SampleInput(2.7, make_tensor([4, 3], dtype=dtype, device=device, low=0, high=None, requires_grad=requires_grad))

# 生成 Bernoulli 分布输入样本的生成器函数
def sample_inputs_bernoulli(self, device, dtype, requires_grad, **kwargs):
    # 不同形状的 Bernoulli 分布张量的形状列表
    shapes = [
        [3],
        [],
        [0, 3],
        [2, 3, 4],
    ]

    # 遍历每个形状，生成对应的 Bernoulli 分布输入张量，然后生成 SampleInput 实例
    for shape in shapes:
        t = make_tensor(shape, dtype=dtype, device=device,
                        low=0, high=1,
                        requires_grad=requires_grad)
        yield SampleInput(t)

# 生成 Bernoulli 分布输入样本的错误情况生成器函数
def error_inputs_bernoulli(op_info, device, **kwargs):
    # 创建一个随机张量并扩展其形状，生成错误输入的 ErrorInput 实例
    x = torch.rand((1,), device=device).expand((6,))
    err_msg = 'unsupported operation'
    yield ErrorInput(SampleInput(torch.rand_like(x), kwargs={'out': x}),
                     error_regex=err_msg)

# 生成 logcumsumexp 操作输入样本的生成器函数
def sample_inputs_logcumsumexp(self, device, dtype, requires_grad, **kwargs):
    # 不同形状和维度的张量输入组合
    inputs = (
        ((S, S, S), 0),
        ((S, S, S), 1),
        ((), 0),
    )

    # 遍历每个输入组合，生成对应的张量输入，并根据条件修改第一个元素的值
    for large_number in (True, False):
        for shape, dim in inputs:
            t = make_tensor(shape, dtype=dtype, device=device,
                            low=None, high=None,
                            requires_grad=requires_grad)

            # 如果设置了大数标志且张量维度大于零，则修改第一个元素的值为 10000
            if large_number and t.dim() > 0:
                t[0] = 10000
            yield SampleInput(t, dim)

# 生成 trace 操作输入样本的生成器函数
def sample_inputs_trace(self, device, dtype, requires_grad, **kwargs):
    # 生成给定形状的张量，并生成对应的 SampleInput 实例
    yield SampleInput(
        make_tensor((S, S), dtype=dtype, device=device,
                    low=None, high=None,
                    requires_grad=requires_grad))


def error_inputs_trace(op, device):
    # 待实现的 trace 操作错误输入生成函数
    pass
    # 使用生成器函数 yield 返回一个 ErrorInput 对象，该对象包含一个 SampleInput 对象作为输入参数，
    # 该 SampleInput 对象由 make_tensor 函数创建，生成一个形状为 (3, 4, 5) 的三维张量，
    # 数据类型为 torch.float32，存储在指定的设备上。
    # error_regex 参数指定了一个正则表达式模式 "expected a matrix"，用于匹配错误信息。
    yield ErrorInput(SampleInput(make_tensor((3, 4, 5), dtype=torch.float32, device=device)), error_regex="expected a matrix")
def sample_inputs_renorm(self, device, dtype, requires_grad, **kwargs):
    # 部分应用函数，用于创建具有指定设备、数据类型和梯度需求的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    
    # 不同的测试用例，每个包含一个形状和一组参数
    cases = (((S, S, S), (2, 1, 0.5)),
             ((S, S, S), (2, -1, 0.5)),
             ((S, S, S), (1, 2, 3)),
             ((S, S, S), (float('inf'), 2, 0.5)),
             )
    
    # 遍历每个测试用例，生成相应的 SampleInput 实例
    for shape, args in cases:
        yield SampleInput(make_arg(shape), args=args)


def sample_inputs_transpose_swapdims(self, device, dtype, requires_grad, **kwargs):
    # 部分应用函数，用于创建具有指定设备、数据类型和梯度需求的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同的测试用例，每个包含一个形状和一组参数
    cases = (((1, 2, 3), (-1, -2)),
             ((1, 2, 3), (-1, 2)),
             ((1, 2, 3), (1, -2)),
             ((1, 2, 3), (1, 2)),
             ((), (0, 0)),
             ((1, ), (0, 0)),
             ((M, M), (0, 1)),
             ((S, S, S), (2, 0)), )

    # 遍历每个测试用例，生成相应的 SampleInput 实例
    for shape, args in cases:
        yield SampleInput(make_arg(shape), args=args)


def _numpy_ref_transpose(a, dim0, dim1):
    # 如果数组的维度小于等于1，则直接返回数组本身
    if a.ndim <= 1:
        return a

    # 使用 NumPy 的 swapaxes 函数交换指定维度的轴
    return np.swapaxes(a, dim0, dim1)


def sample_inputs_adjoint(self, device, dtype, requires_grad, **kwargs):
    # 部分应用函数，用于创建具有指定设备、数据类型和梯度需求的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同的形状作为测试用例，每个形状生成一个 SampleInput 实例
    shapes = ((1, 2, 3), (M, M), (S, S, S), (S, M, S), (M, S, M, S))
    return (SampleInput(make_arg(shape)) for shape in shapes)


def sample_inputs_T(self, device, dtype, requires_grad, **kwargs):
    # 部分应用函数，用于创建具有指定设备、数据类型和梯度需求的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同的形状作为测试用例，每个形状生成一个 SampleInput 实例
    shapes = ((M, M), (M, L))
    return (SampleInput(make_arg(shape)) for shape in shapes)


def error_inputs_T(self, device, has_ndims_error=False):
    # 部分应用函数，用于创建具有指定设备和默认数据类型的张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 如果 has_ndims_error 为 True，生成特定错误输入的 ErrorInput 实例
    if has_ndims_error:
        # 对于 ndims == 1 的情况，生成错误输入实例，检查是否匹配指定错误信息的正则表达式
        yield ErrorInput(SampleInput(make_arg(M)),
                         error_regex=(r'The use of `x\.T` on tensors of dimension other than 0 or 2 '
                                      r'to reverse their shape is not supported\.'))

        # 对于 ndims > 2 的情况，生成错误输入实例，检查是否匹配指定错误信息的正则表达式
        yield ErrorInput(SampleInput(make_arg(M, S, L)),
                         error_regex=(r'The use of `x\.T` on tensors of dimension other than 0 or 2 '
                                      r'to reverse their shape is not supported\.'))


def sample_inputs_singular_matrix_factors(op_info, device, dtype, requires_grad=False):
    """
    This function produces two tensors of shape (*, m, k) and (*, n, k) with k <= min(m, n).
    Their matrix product could be used to generate tensor of shape (*, m, n) of rank k.
    """
    # 部分应用函数，用于创建具有指定设备、数据类型和梯度需求的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 不同的批次大小和尺寸作为测试用例，每个组合生成一个 SampleInput 实例
    batches = [(), (0, ), (2, ), (1, 1)]
    size = [1, 5, 10]
    # 使用 product 函数生成 batches、size、size 的三元组迭代器
    for batch, m, n in product(batches, size, size):
        # 针对当前的 m 和 n，循环 k 从 0 到 min(3, m, n)
        for k in range(min(3, m, n)):
            # 调用 make_arg 函数生成参数 a，参数为 (*batch, m, k)
            a = make_arg((*batch, m, k))
            # 调用 make_arg 函数生成参数 b，参数为 (*batch, n, k)
            b = make_arg((*batch, n, k))
            # 使用 yield 语句产生 a 和 b 作为生成器的输出
            yield a, b
def sample_inputs_svd_lowrank(op_info, device, dtype, requires_grad=False, **kwargs):
    # 定义一个函数，针对复杂输入输出的情况进行良好定义
    def fn(usv):
        U, S, V = usv
        return U @ V.mH, S

    # 对于每对从sample_inputs_singular_matrix_factors函数中获取的输入(a, b)，进行迭代
    for (a, b) in sample_inputs_singular_matrix_factors(op_info, device, dtype, requires_grad):
        *batch, m, k = a.shape
        n = b.shape[-2]

        # 注意：由于svd_lowrank依赖于非排名显示的SVD，
        # 它继承了与重复奇异值（包括零）相关的不稳定行为问题。
        # 由于我们希望避免（重复的）零作为奇异值，
        # 我们只能使用k作为q。
        # 这个问题可以通过使用不包括“零”奇异值的排名显示SVD来解决。
        # 生成带有元数据的SampleInput对象，其中的输出处理函数为fn
        yield SampleInput(a, b, q=k, M=None).with_metadata(output_process_fn_grad=fn)

    # 再次对从sample_inputs_singular_matrix_factors函数中获取的输入(a, b)进行迭代
    for (a, b) in sample_inputs_singular_matrix_factors(op_info, device, dtype, requires_grad):
        *batch, m, k = a.shape
        n = b.shape[-2]
        # 创建一个与a形状匹配的张量M，使用make_tensor函数生成
        M = make_tensor((*batch, m, n), dtype=dtype, device=device, requires_grad=requires_grad)
        # 生成带有元数据的SampleInput对象，其中的输出处理函数为fn
        yield SampleInput(a, b, q=k, M=M).with_metadata(output_process_fn_grad=fn)

def chunk_iter(iterable, size):
    # 创建一个迭代器，每次返回指定大小的chunk元组
    it = iter(iterable)
    while True:
        chunk = tuple(islice(it, size))
        if not chunk:
            break
        yield chunk

def sample_inputs_pca_lowrank(op_info, device, dtype, requires_grad=False, **kwargs):
    # 重复使用来自svd_lowrank的样本，这些样本成对出现，其中kwargs['M'] = None和kwargs['M'] = <some tensor>
    samples = sample_inputs_svd_lowrank(op_info, device, dtype, requires_grad, **kwargs)
    # 使用chunk_iter函数对samples进行分块迭代，每次两个一组
    for s1, s2 in chunk_iter(samples, 2):
        del s1.kwargs['M']
        del s2.kwargs['M']
        s1.kwargs['center'] = False
        s2.kwargs['center'] = True
        # 生成修改后的SampleInput对象s1和s2
        yield s1
        yield s2

def np_sinc_with_fp16_as_fp32(x):
    # 包装numpy的sinc函数，以便在调用sinc之前将fp16值提升为fp32
    # 上下文：对于fp16，numpy的sinc在0处评估时返回NaN。
    if x.dtype == np.float16:
        return np.sinc(x.astype(np.float32))
    else:
        return np.sinc(x)

def sample_inputs_broadcast_to(op_info, device, dtype, requires_grad, **kwargs):
    # 定义测试用例元组
    test_cases = (
        ((S, 1, 1), (S, S, S)),
        ((S, 1, S), (S, S, S)),
        ((S, 1), (S, S, S)),
        ((1,), (S, S, S)),
        ((1, S), (1, 1, S)),
        ((), ()),
        ((), (1, 3, 2)),
    )

    # 生成SampleInput对象的生成器，对每个测试用例调用make_tensor生成输入张量
    return (
        SampleInput(
            make_tensor(size, dtype=dtype, device=device, low=None, high=None, requires_grad=requires_grad),
            shape,
        ) for size, shape in test_cases)

def sample_inputs_broadcast_tensors(op_info, device, dtype, requires_grad, **kwargs):
    # 使用partial函数生成make_tensor的局部函数make_arg
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 定义包含多个测试用例元组的元组
    test_cases: Tuple[tuple] = (((3,), (1, 2, 1), (1, 1), (5, 1, 1),),)
    # 遍历测试用例列表，每个测试用例包含一个主要形状和其他形状
    for shape, *other_shapes in test_cases:
        # 生成主要形状的输入参数，并将其作为参数传递给SampleInput对象
        yield SampleInput(make_arg(shape), args=tuple(make_arg(s) for s in other_shapes))
# 定义一个生成器函数，生成广播张量的样本输入
def reference_inputs_broadcast_tensors(op, device, dtype, requires_grad, **kwargs):
    # 调用另一个生成器函数获取广播张量的样本输入
    yield from sample_inputs_broadcast_tensors(op, device, dtype, requires_grad, **kwargs)

    # 创建函数 partial 对象，用于创建指定属性的张量
    m = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    n = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad, noncontiguous=True)

    # 定义不同的测试用例
    cases = (
        ((), (1, 1), (1, 1, 7, 1), (3, 1, 1)),
        ((3, 5, 6), (1, 3, 5, 6), (1, 1, 1, 1, 6), (8, 3, 5, 6))
    )

    # 遍历测试用例，生成样本输入
    for a, b, c, d in cases:
        yield SampleInput(m(a), args=(m(b), m(c), m(d)))
        yield SampleInput(n(a), args=(n(b), n(c), n(d)))

# 定义一个生成器函数，生成块对角矩阵的样本输入
def sample_inputs_block_diag(op_info, device, dtype, requires_grad, **kwargs):
    # 创建函数 partial 对象，用于创建指定属性的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 定义不同的测试用例
    test_cases: Tuple[tuple] = (
        ((1, S), (2, S), (3, S),),
        ((S, 1), (S, 2), (S, 3),),
        ((1,), (2,), (3,),),
        ((2, S), (S,))
    )

    # 遍历测试用例，生成样本输入
    for shape, *other_shapes in test_cases:
        yield SampleInput(make_arg(shape), args=tuple(make_arg(s) for s in other_shapes))
        # 在测试块对角矩阵的同时，还要测试混合复杂和非复杂输入的情况
        if dtype == torch.complex32 or dtype == torch.complex64:
            non_complex_dtype = torch.float32 if dtype == torch.complex32 else torch.float64
            make_arg_non_complex = partial(make_tensor, dtype=non_complex_dtype, device=device, requires_grad=requires_grad)
            yield SampleInput(make_arg_non_complex(shape), args=tuple(make_arg(s) for s in other_shapes))

# 定义一个生成器函数，生成距离矩阵的样本输入
def sample_inputs_cdist(op_info, device, dtype, requires_grad, **kwargs):
    small_S = 2
    # 定义不同的测试用例
    test_cases = (
        ((S, S, 2), (S, S + 1, 2)),
        ((S, S), (S, S)),
        ((S, S, S), (S, S, S)),
        ((3, 5), (3, 5)),
        ((2, 3, 5), (2, 3, 5)),
        ((1, 2, 3), (1, 2, 3)),
        ((1, 1), (S, 1)),
        ((0, 5), (4, 5)),
        ((4, 5), (0, 5)),
        ((0, 4, 5), (3, 5)),
        ((4, 5), (0, 3, 5)),
        ((0, 4, 5), (1, 3, 5)),
        ((1, 4, 5), (0, 3, 5)),
        ((small_S, small_S, small_S + 1, 2), (small_S, small_S, small_S + 2, 2)),
        ((small_S, 1, 1, small_S), (1, small_S, small_S)),
        ((1, 1, small_S), (small_S, 1, small_S, small_S)),
    )

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    
    # 遍历不同的参数组合，生成样本输入
    for cm in ['use_mm_for_euclid_dist', 'donot_use_mm_for_euclid_dist']:
        # FIXME add an override for JIT and revert 0. back to 0
        # since it's accepted by eager
        for p in [0., 1., 2., 3., 0.5, 1.5, 2.5, float("inf")]:
            for t1_size, t2_size in test_cases:
                # 参数不应为非连续，因为反向传播不支持非连续参数
                yield SampleInput(make_arg(t1_size), make_arg(t2_size), p, cm)

# 定义一个函数，用于用指定值填充 NumPy 数组的非零元素
def _fill_np(a, value):
    # 复制数组 a，确保不修改原始数组，然后用指定的值填充数组
    a = a.copy()
    a.fill(value)
    return a
def _fill_sample_kwargs(device, dtype, input):
    if dtype is torch.bool:
        # 如果 dtype 是 torch.bool 类型，则 value 设为 True
        value = True
    else:
        # 否则设为 3
        value = 3

    return ({'value': value}, {'value': value})

def sample_inputs_comparison_ops(op, device, dtype, requires_grad, **kwargs):
    # 从另一个生成器函数中获取元素级二元操作的示例输入
    yield from sample_inputs_elementwise_binary(op, device, dtype, requires_grad, **kwargs)

    # 创建张量的辅助函数，其中 lhs 是一个具有形状 (S, S) 的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    lhs = make_arg((S, S))
    # 返回一个 SampleInput 对象，其中包含 lhs 和其克隆的副本作为参数
    yield SampleInput(lhs, args=(lhs.clone(),))

def sample_inputs_stack(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同形状和张量数量的情况
    cases = (
        ((3, 4), 1),
        ((1, 2, 1, 4), 3),
        ((0, 1, 0), 2),
    )

    for shape, num_tensors in cases:
        tensors = []
        # 生成指定形状和数量的张量列表
        for _ in range(num_tensors):
            tensors.append(make_arg(shape))
        # 遍历维度范围，从 -1 到最后一个维度的前一个
        for dim in range(-1, len(shape) - 1):
            # 返回 SampleInput 对象，其中包含 tensors 列表和维度 dim 作为参数
            yield SampleInput(tensors, args=(dim,))

def sample_inputs_chunk_cat(op_info, device, dtype, requires_grad, **kwargs):
    # 定义形状相同的情况
    same_ndim_cases = (
        (
            [
                torch.Size([1, 2, 3]),
                torch.Size([1, 2, 3]),
            ], -1, 5
        ),
        (
            [
                torch.Size([1, 2, 129]),
                torch.Size([1, 2, 297]),
            ], -1, 5
        ),
        (
            [
                torch.Size([1, 2, 3]),
                torch.Size([1, 2, 3]),
            ], 1, 5
        ),
        (
            [
                torch.Size([3, 3, 2, 1]),
                torch.Size([1, 4, 2, 2]),
                torch.Size([2, 1, 3, 3]),
            ], 0, 2
        ),
    )
    for sizes, dim, num_chunks in same_ndim_cases:
        tensors = []
        # 生成具有指定大小的张量列表
        for size in sizes:
            tensors.append(make_arg(size))
        # 返回 SampleInput 对象，其中包含 tensors 列表、维度 dim 和 num_chunks 作为参数
        yield SampleInput(tensors, args=(dim, num_chunks))

    # 定义形状不同的情况
    different_ndim_case = [
        torch.Size([2, 3, 3]),
        torch.Size([2, 3, 1, 2]),
        torch.Size([2, 3]),
        torch.Size([2, 3, 2]),
        torch.Size([2, 3, 271]),
    ]
    max_dim, num_chunks = 2, 3
    # 对于每一个维度 dim 在范围 max_dim 内进行循环迭代
    for dim in range(max_dim):
        # 创建一个空列表来存储不同维度情况下生成的张量
        tensors = []
        # 对于不同的维度案例中的每一个 size 进行迭代
        for size in different_ndim_case:
            # 调用 make_arg 函数生成一个张量，并将其添加到 tensors 列表中
            tensors.append(make_arg(size))
        # 使用生成的张量列表和参数 (dim, num_chunks) 创建一个 SampleInput 实例，并通过 yield 生成器函数返回该实例
        yield SampleInput(tensors, args=(dim, num_chunks))
# 定义函数 error_inputs_chunk_cat，用于生成不同类型的错误输入样本
def error_inputs_chunk_cat(op_info, device, **kwargs):
    # 使用偏函数 partial 创建 make_arg 函数，固定了 device 参数为指定的设备，数据类型为 torch.float32
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 示例1：输入张量的维度不同，但指定的维度 dim 是负数
    sizes, dim, num_chunks = [torch.Size([2, 3]), torch.Size([4,])], -1, 3
    # 根据 sizes 中的每个尺寸创建张量列表
    tensors = [make_arg(size) for size in sizes]
    # 生成一个 ErrorInput 对象，包含 SampleInput 对象和错误信息正则表达式
    yield ErrorInput(
        SampleInput(tensors, args=(dim, num_chunks)),
        error_regex='_chunk_cat expects non-negative dim when input tensors have different ndims',
    )

    # 示例2：输入张量的维度不同，且指定的维度 dim 大于等于某些输入张量的维度
    sizes, dim, num_chunks = [torch.Size([2, 3]), torch.Size([4,])], 1, 3
    tensors = [make_arg(size) for size in sizes]
    yield ErrorInput(
        SampleInput(tensors, args=(dim, num_chunks)),
        error_regex='_chunk_cat expects dim < ndim for all input tensors',
    )

    # 示例3：某些张量在前 dim 个维度上的尺寸不同
    sizes, dim, num_chunks = [torch.Size([2, 3, 4]), torch.Size([4, 3])], 1, 3
    tensors = [make_arg(size) for size in sizes]
    yield ErrorInput(
        SampleInput(tensors, args=(dim, num_chunks)),
        error_regex='_chunk_cat expects same sizes of 0,...,dim-1 dimensions for all tensors',
    )

    # 示例4：num_chunks 是负数
    sizes, dim, num_chunks = [torch.Size([2,]), torch.Size([3,])], 0, -1
    tensors = [make_arg(size) for size in sizes]
    yield ErrorInput(
        SampleInput(tensors, args=(dim, num_chunks)),
        error_regex='_chunk_cat expects positive num_chunks',
    )

    # 示例5：num_chunks 是零
    sizes, dim, num_chunks = [torch.Size([2,]), torch.Size([3,])], 0, 0
    tensors = [make_arg(size) for size in sizes]
    yield ErrorInput(
        SampleInput(tensors, args=(dim, num_chunks)),
        error_regex='_chunk_cat expects positive num_chunks',
    )

    # 示例6：空的输入张量列表
    dim, num_chunks = 0, 1
    yield ErrorInput(
        SampleInput([], args=(dim, num_chunks)),
        error_regex='_chunk_cat expects a non-empty input tensor list',
    )

    # 示例7：空的输入张量且包含 0 个元素
    sizes, dim, num_chunks = [torch.Size([0,]), torch.Size([3,])], 0, 1
    tensors = [make_arg(size) for size in sizes]
    yield ErrorInput(
        SampleInput(tensors, args=(dim, num_chunks)),
        error_regex='_chunk_cat expects non-empty tensor',
    )
    cases: Tuple[tuple, tuple, dict] = (  # type: ignore[assignment]
        # 定义测试用例元组，每个元组包含两个输入形状和一个关键字参数字典
        ((S, S), (S, S), {'dim': -1}),  # 同样的形状，指定维度为最后一个
        ((S, S), (S, S), {'dim': 1}),   # 同样的形状，指定维度为第一个
        ((M, S), (S, S), {'dim': 0}),   # 不同的形状，指定维度为第零个（通常是按照索引）
        ((1, 2, 3), (1, 2, 3), {'dim': -2}),  # 形状为 (1, 2, 3)，指定维度为倒数第二个
        ((0,), (0,), {'dim': 0}),      # 空张量，指定维度为第零个
        ((0,), (S, S), {'dim': 1}),    # 空张量与非空张量，并指定维度为第一个（对于特定的 legacy_cat_wrap_dim 情况）
        ((0, S), (S, S), {'dim': 0}),  # 形状为 (0, S) 和 (S, S)，指定维度为第零个
        ((1,), (1,), {})              # 形状为 (1,)，未指定维度，使用默认值
    )

    # 遍历每个测试用例，并生成对应的 SampleInput 实例
    for input_shape1, input_shape2, kwargs in cases:
        yield SampleInput([make_arg(input_shape1), make_arg(input_shape2)], kwargs=kwargs)

    # from coat_lite_mini
    # 从 coat_lite_mini 中生成一个额外的 SampleInput 实例，使用指定的参数
    yield SampleInput([make_arg((2, 2, 2, 2), memory_format=torch.channels_last)], args=(1,),)
def error_inputs_cat(op_info, device, **kwargs):
    # 创建一个部分应用的函数，用于创建特定设备和数据类型的张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 为写入张量的多个元素引发错误输入，这些元素引用同一内存位置
    yield ErrorInput(SampleInput([make_arg((S, S)), make_arg((S, S))],
                                 kwargs={'out': make_arg((1, S)).expand((2 * S, S))}),
                     error_regex='unsupported operation')

    # 引发空张量的错误输入
    yield ErrorInput(SampleInput([], kwargs={'dim': 1}),
                     error_regex='non-empty list of Tensors')

    # 引发不同大小张量的错误输入
    yield ErrorInput(SampleInput([make_arg((S, S, L, L)), make_arg((S, 0, L - 1, L))], kwargs={'dim': 1}),
                     error_regex='Sizes of tensors must match except in dimension')
    yield ErrorInput(SampleInput([make_arg((S, 0, L - 1, L)), make_arg((S, S, L, L))], kwargs={'dim': 1}),
                     error_regex='Sizes of tensors must match except in dimension')

    # 引发不同维度张量的错误输入
    yield ErrorInput(SampleInput([make_arg((S - 1, 0)), make_arg((S, 0, L - 1, L))], kwargs={'dim': 1}),
                     error_regex='Tensors must have same number of dimensions')
    yield ErrorInput(SampleInput([make_arg((S, 0, L - 1, L)), make_arg((S - 1, 0))], kwargs={'dim': 1}),
                     error_regex='Tensors must have same number of dimensions')

    # 引发相同内存位置张量的错误输入
    x = torch.zeros((0), device=device)
    y = torch.randn((4, 6), device=device)
    err_msg = "the written-to tensor refer to a single memory location"

    yield ErrorInput(SampleInput((x, y), kwargs={'dim': 0, 'out': x}),
                     error_regex=err_msg)
    yield ErrorInput(SampleInput((x, y), kwargs={'dim': 0, 'out': y}),
                     error_regex=err_msg)

    z = torch.zeros((4, 6), device=device)
    yield ErrorInput(SampleInput((y, z), kwargs={'out': z[:2, :]}),
                     error_regex=err_msg)

    # 引发不同设备张量的错误输入
    if torch.device(device).type == 'cuda':
        x_cuda = make_tensor((3, 3), device=device, dtype=torch.float32)
        y_cpu = make_tensor((3, 3), device='cpu', dtype=torch.float32)
        yield ErrorInput(SampleInput((x_cuda, y_cpu)),
                         error_regex='Expected all tensors to be on the same device')

    # 引发多于两个张量输入不同大小的错误输入
    yield ErrorInput(SampleInput([make_arg((L, 1)), make_arg((L, 1, 1)), make_arg((L, 1, 1))]),
                     error_regex='Tensors must have same number of dimensions')

    yield ErrorInput(SampleInput([make_arg((S, 1, M)), make_arg((S, 1, 1)), make_arg((S, M, 1))],
                                 kwargs={'dim': 1}),
                     error_regex='Sizes of tensors must match')

    # 引发空输入的错误输入
    # 使用 SampleInput 创建一个带有错误输入的 ErrorInput 实例，其中输入为 (S, 1, 1)，期望值为 None，错误类型为 TypeError，错误信息包含 'got None'
    yield ErrorInput(SampleInput((make_arg((S, 1, 1)), None)), error_type=TypeError,
                     error_regex='got None')

    # 创建多个错误输入，用于零维张量的情况
    yield ErrorInput(SampleInput([make_arg(()), make_arg(())]),
                     error_regex='zero-dimensional.*cannot be concatenated')

    # 创建错误输入，展示不同输出张量的 dtype 不匹配的情况
    # 使用 make_tensor 创建一个形状为 (2, 3)，在指定设备上且数据类型为 torch.double 的张量 d
    d = make_tensor((2, 3), device=device, dtype=torch.double)
    # 使用 make_tensor 创建一个形状为 (2, 3)，在指定设备上且数据类型为 torch.float32 的张量 x
    x = make_tensor((2, 3), device=device, dtype=torch.float32)
    # 创建 ErrorInput 实例，输入为 x，kwargs 包含指定的输出张量 d，错误类型为 TypeError，错误信息包含 'invalid combination of arguments'
    yield ErrorInput(SampleInput(x, kwargs={'out': d}), error_type=TypeError,
                     error_regex='invalid combination of arguments')
def reference_inputs_cat(op, device, dtype, requires_grad, **kwargs):
    # 从sample_inputs_cat_concat生成输入样本
    yield from sample_inputs_cat_concat(op, device, dtype, requires_grad, **kwargs)

    # 创建部分函数make_arg，使用指定的设备、数据类型和梯度信息
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # Noncontiguous type promoting tensors
    # 创建三个张量a, b, c，每个张量的形状和类型有所不同
    a = make_arg((3, 4, 2))
    b = make_arg((3, 2, 2), noncontiguous=True, dtype=torch.double)
    c = make_arg((3, 3, 2), dtype=torch.float16).permute(1, 0, 2)

    # 生成一个SampleInput对象，包含张量a, b, c，并传递额外的关键字参数dim: 1
    yield SampleInput((a, b, c), kwargs={'dim': 1})

    # Special 1D tensor with dim length of 0 case
    # 创建特殊情况的张量a, b，其中a是空张量，b是具有指定形状和类型的张量
    a = make_arg((0,))
    b = make_arg((3, 2, 2))

    # 生成一个SampleInput对象，包含张量a, b, a
    yield SampleInput((a, b, a))
    yield SampleInput((a, a, a))

def _elementwise_type_promo_np(*args, type_promotion_kind):
    # 定义内部函数_maybe_torch，将numpy数组转换为torch张量
    def _maybe_torch(x):
        if isinstance(x, np.ndarray):
            return torch.from_numpy(x)
        return x

    # 展平输入参数args，将其转换为torch张量，然后调用elementwise_dtypes计算结果的数据类型
    flattened = pytree.arg_tree_leaves(*args)
    transformed = tuple(_maybe_torch(a) for a in flattened)
    # 返回结果的数据类型和一个未使用的字典
    result_dtype, _ = prims.utils.elementwise_dtypes(
        *transformed,
        type_promotion_kind=type_promotion_kind)
    return torch_to_numpy_dtype_dict[result_dtype]

def _cat_np(input_seq, dim=0):
    # 从输入序列中选择所有非空张量，并组成一个元组inputs
    inputs = tuple(a for a in input_seq if not (a.ndim == 1 and a.size == 0))

    # 如果inputs为空，则根据输入序列调用_elementwise_type_promo_np获取数据类型，并返回一个空的numpy数组
    if len(inputs) == 0:
        np_dtype = _elementwise_type_promo_np(
            input_seq,
            type_promotion_kind=prims.utils.ELEMENTWISE_TYPE_PROMOTION_KIND.NO_OPMATH)
        return np.empty(0, dtype=np_dtype)

    # 否则，使用指定的维度dim对inputs中的所有张量进行连接操作，返回结果
    return np.concatenate(inputs, axis=dim)

def _floor_divide_np(a, b):
    # 根据输入参数a, b的类型调用_elementwise_type_promo_np获取数据类型
    dtype = _elementwise_type_promo_np(
        a,
        b,
        type_promotion_kind=prims.utils.ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)
    # 如果a是numpy数组，则将其转换为指定数据类型dtype
    if isinstance(a, np.ndarray):
        a = a.astype(dtype)
    # 如果b是numpy数组，则将其转换为指定数据类型dtype
    if isinstance(b, np.ndarray):
        b = b.astype(dtype)
    # 返回a与b的元素级除法结果，使用floor_divide函数
    return np.floor_divide(a, b)

def sample_inputs_hstack_dstack_vstack(op_info, device, dtype, requires_grad, **kwargs):
    # 创建部分函数make_arg，使用指定的数据类型、设备和梯度信息
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 定义不同形状的张量组合，用于测试hstack, dstack, vstack操作
    tensor_shapes = (
        # First Tensor being 1-D is special
        # case for hstack
        ((S,), (S,), (S,)),
        ((S, S), (S, S), (S, S)),
    )
    # 遍历每个形状组合，创建相应形状的张量，并生成SampleInput对象
    for s1, s2, s3 in tensor_shapes:
        tensors = (make_arg(s1,), make_arg(s2,), make_arg(s3))
        yield SampleInput(tensors)

def error_inputs_hstack_dstack_vstack(op, device):
    # 创建部分函数make_arg，使用指定的数据类型、设备和梯度信息
    make_arg = partial(make_tensor, dtype=torch.int32, device=device, requires_grad=False)
    # 定义不同形状的张量组合，用于测试hstack, dstack, vstack操作
    tensor_shapes = (
        ((S,), (S, S, S, S), (S,)),
    )
    # 遍历每个形状组合，创建相应形状的张量，并生成ErrorInput对象
    for s1, s2, s3 in tensor_shapes:
        tensors = (make_arg(s1,), make_arg(s2,), make_arg(s3))
        # 返回一个ErrorInput对象，表示不同维度的张量错误情况
        yield ErrorInput(SampleInput(tensors), error_regex="Tensors must have same number of dimensions")

    # 返回一个ErrorInput对象，表示空张量列表的错误情况
    yield ErrorInput(SampleInput(()), error_regex="expects a non-empty TensorList")

def sample_inputs_unbind(op_info, device, dtype, requires_grad, **kwargs):
    # 此函数未提供完整实现，可以继续根据需求添加代码
    # 注意：我们不会对长度为 0 的维度进行解绑测试
    # 因为在这种情况下，unbind 返回一个空元组，这会破坏 test_ops.py 中一些反向测试的假设
    
    # 定义了一组测试用例的形状和维度信息
    shape_dims = (((S,), 0),          # 形状为 (S,)，维度为 0
                  ((S, S), 0),        # 形状为 (S, S)，维度为 0
                  ((S, S), 1),        # 形状为 (S, S)，维度为 1
                  ((S, S), -1),       # 形状为 (S, S)，维度为 -1
                  ((S, 0, S), 0),     # 形状为 (S, 0, S)，维度为 0
                  ((S, S, S), 1),     # 形状为 (S, S, S)，维度为 1
                 )
    
    # 遍历每个测试用例的形状和维度
    for shape, dim in shape_dims:
        # 生成一个示例输入，创建一个张量，具有指定形状、数据类型、设备，是否需要梯度
        yield SampleInput(make_tensor(shape, dtype=dtype, device=device,
                                      requires_grad=requires_grad),
                          args=(dim,))
# 定义一个生成器函数，用于生成 ErrorInput 对象，表示错误的输入情况
def error_inputs_unbind(op_info, device):
    # 创建一个偏函数 make_arg，用于生成 torch.int32 类型的张量，不需要梯度
    make_arg = partial(make_tensor, dtype=torch.int32, device=device, requires_grad=False)
    # 返回第一个错误情况的 ErrorInput 对象，表示在维度为 0 的情况下索引超出范围的错误
    yield ErrorInput(SampleInput(make_arg(()), args=(0,)), error_type=IndexError,
                     error_regex="Dimension specified as 0 but tensor has no dimensions")
    # 返回第二个错误情况的 ErrorInput 对象，表示索引超出维度范围的错误
    yield ErrorInput(SampleInput(make_arg((2,)), args=(2,)), error_type=IndexError,
                     error_regex="Dimension out of range")

# 定义一个函数 reference_unbind，实现了 torch.unbind 的 numpy 实现
def reference_unbind(t, dim):
    """A numpy implementation of torch.unbind"""
    # 返回一个元组，包含按给定维度 dim 拆分并挤压后的张量 s 的结果
    return tuple(s.squeeze(dim) for s in np.split(t, t.shape[dim], dim))

# 定义一个生成器函数，用于生成 SampleInput 对象，表示 gather 函数的不同输入情况
def sample_inputs_gather(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数 make_arg，用于生成指定设备、数据类型和梯度属性的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    # 返回第一个 SampleInput 对象，包含 make_arg((M, S)) 生成的张量、gather_variable 函数的结果
    yield SampleInput(
        make_arg((M, S)),
        0,
        gather_variable((S, S), 1, M, True, device=device))
    # 返回第二个 SampleInput 对象，包含 make_arg((M, S)) 生成的张量、gather_variable 函数的结果
    yield SampleInput(
        make_arg((M, S)),
        1,
        gather_variable((M, S // 2), 0, S, True, device=device))
    # 返回第三个 SampleInput 对象，包含 make_arg((S,)) 生成的张量、空的 torch.tensor 作为索引
    yield SampleInput(
        make_arg((S,)),
        0,
        torch.tensor([], dtype=torch.uint8, device=device))
    # 返回第四个 SampleInput 对象，包含 make_arg((S,)) 生成的张量、空的 torch.tensor 作为索引
    yield SampleInput(
        make_arg((S,)),
        0,
        torch.tensor([[], []], dtype=torch.uint8, device=device))
    # 返回第五个 SampleInput 对象，包含 make_arg(()) 生成的零维张量、包含一个元素的 torch.tensor 作为索引
    yield SampleInput(
        make_arg(()),
        0,
        torch.tensor([0], dtype=torch.int64, device=device))
    # 返回第六个 SampleInput 对象，包含 make_arg(()) 生成的零维张量、包含一个元素的 torch.tensor 作为索引
    yield SampleInput(
        make_arg(()),
        0,
        torch.tensor(0, dtype=torch.int64, device=device))

# 定义一个函数 _fill_indices，用于填充索引张量 idx
def _fill_indices(idx, dim, dim_size, elems_per_row, m, n, o):
    # 根据不同的维度 dim，填充索引张量 idx
    for i in range(1 if dim == 0 else m):
        for j in range(1 if dim == 1 else n):
            for k in range(1 if dim == 2 else o):
                ii = [i, j, k]
                # 将维度为 dim 的索引设置为切片，长度为 idx.size(dim) + 1
                ii[dim] = slice(0, idx.size(dim) + 1)
                # 将随机排列的 dim_size 长度的整数，截取前 elems_per_row 个元素，填充到 idx 中
                idx[tuple(ii)] = torch.randperm(dim_size)[0:elems_per_row]

# 定义一个生成器函数，用于生成 ErrorInput 对象，表示 gather 函数的错误输入情况
def error_inputs_gather(op_info, device, **kwargs):
    # 创建一个形状为 ((1, 2), (3, 4)) 的浮点型张量 src
    src = torch.tensor(((1, 2), (3, 4)), device=device, dtype=torch.float32)
    # 创建一个形状为 ((0, 0), (1, 0)) 的长整型张量 idx
    idx = torch.tensor(((0, 0), (1, 0)), device=device, dtype=torch.long)

    # 创建一个形状为 (1, 1) 的浮点型张量 bad_src，用作错误情况下的输入
    bad_src = make_tensor((1, 1), device=device, dtype=torch.float32)
    # 返回 ErrorInput 对象，表示 bad_src 与索引 idx 维度不匹配的错误
    yield ErrorInput(SampleInput(bad_src, args=(1, idx,)),
                     error_regex="Size does not match at dimension 0")

    # 将 idx 张量转换为 torch.int32 类型的张量 bad_idx
    bad_idx = idx.to(torch.int32)
    # 返回 ErrorInput 对象，表示 bad_idx 不是预期的 int64 类型的索引错误
    yield ErrorInput(SampleInput(src, args=(1, bad_idx)),
                     error_regex="Expected dtype int64 for index")

    # 创建新的 src 和 idx 张量，以处理 SampleInputs 不能共享张量的问题
    src = torch.tensor(((1, 2), (3, 4)), device=device, dtype=torch.float32)
    idx = torch.tensor(((0, 0), (1, 0)), device=device, dtype=torch.long)
    # 创建一个空的张量，形状为 (2, 2)，设备为指定的设备，数据类型为 torch.float64
    out = torch.empty((2, 2), device=device, dtype=torch.float64)
    # 生成一个 ErrorInput 对象，用于表示输入错误的情况，传入一个 SampleInput 对象作为参数，包含源张量 src、位置参数 (1, idx) 和关键字参数 {'out': out}
    yield ErrorInput(SampleInput(src, args=(1, idx), kwargs={'out': out}),
                     error_regex="Expected out tensor to have dtype")

    # 源张量 src 和索引张量 idx 必须具有相同的维数
    # idx 的维数过少
    src = torch.tensor(((1, 2), (3, 4)), device=device, dtype=torch.float32)
    idx = torch.tensor((0, 0), device=device, dtype=torch.long)
    # 生成一个 ErrorInput 对象，表示输入错误，传入 SampleInput 对象，包含源张量 src 和位置参数 (1, idx)
    yield ErrorInput(SampleInput(src, args=(1, idx)),
                     error_regex="Index tensor must have the same number of dimensions")

    # 源张量 src 的维数过少
    src = torch.tensor((1, 2), device=device, dtype=torch.float32)
    idx = torch.tensor(((0, 0), (1, 0)), device=device, dtype=torch.long)
    # 生成一个 ErrorInput 对象，表示输入错误，传入 SampleInput 对象，包含源张量 src 和位置参数 (0, idx)
    yield ErrorInput(SampleInput(src, args=(0, idx)),
                     error_regex="Index tensor must have the same number of dimensions")

    # 索引超出界限
    # 注意：这个 ErrorInput 受保护，因为 CUDA 设备上不进行边界检查
    if torch.device(device).type == 'cpu':
        src = torch.tensor(((1, 2), (3, 4)), device=device, dtype=torch.float32)
        idx = torch.tensor(((0, 23), (1, 0)), device=device, dtype=torch.long)
        # 生成一个 ErrorInput 对象，表示输入错误，传入 SampleInput 对象，包含源张量 src、位置参数 (1, idx)
        yield ErrorInput(SampleInput(src, args=(1, idx,)),
                         error_regex="index 23 is out of bounds for dimension")

    # 创建一个随机张量 x，形状为 (1,)，并在指定设备上扩展为形状 (3,)
    x = torch.rand((1,), device=device).expand((3,))
    # 创建一个随机张量 src，形状为 (6,)，设备为指定设备
    src = torch.rand((6,), device=device)
    # 创建一个整数张量 ind，包含元素 [2, 1, 0]，设备为指定设备，数据类型为 torch.int64
    ind = torch.tensor([2, 1, 0], device=device, dtype=torch.int64)

    # 生成一个 ErrorInput 对象，表示运行时错误，传入 SampleInput 对象，包含源张量 src 和位置参数 (0, ind)，以及关键字参数 {'out': x}
    yield ErrorInput(SampleInput(src, args=(0, ind,), kwargs=dict(out=x)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

    # 生成一个 ErrorInput 对象，表示运行时错误，传入 SampleInput 对象，包含源张量 src 和位置参数 (0, ind)，以及关键字参数 {'out': src}
    yield ErrorInput(SampleInput(src, args=(0, ind,), kwargs=dict(out=src)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

    # 生成一个 ErrorInput 对象，表示运行时错误，传入 SampleInput 对象，包含克隆的张量 ind、位置参数 (0, ind[1:])，以及关键字参数 {'out': ind[:1]}
    yield ErrorInput(SampleInput(ind.clone(), args=(0, ind[1:],), kwargs=dict(out=ind[:1])),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')
# 定义一个生成器函数，生成一系列的错误输入样本，用于测试指定操作的异常情况
def error_inputs_take(op_info, device, **kwargs):
    # 创建一个大小为3的张量x，内容为随机数，使用指定设备，然后扩展为大小为(3,)的张量
    x = torch.rand((1,), device=device).expand((3,))
    # 创建一个大小为6的张量src，内容为随机数，使用指定设备
    src = torch.rand((6,), device=device)
    # 创建一个包含整数[2, 1, 0]的张量ind，使用指定设备和int64类型
    ind = torch.tensor([2, 1, 0], device=device, dtype=torch.int64)

    # 生成一个ErrorInput对象，使用SampleInput包含src作为参数，ind作为args，x作为out的关键字参数
    yield ErrorInput(SampleInput(src, args=(ind,), kwargs=dict(out=x)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

    # 生成一个ErrorInput对象，使用SampleInput包含src作为参数，ind作为args，src作为out的关键字参数
    yield ErrorInput(SampleInput(src, args=(ind,), kwargs=dict(out=src)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

    # 生成一个ErrorInput对象，使用SampleInput包含ind的克隆作为参数，ind的子集作为args，ind的前一部分作为out的关键字参数
    yield ErrorInput(SampleInput(ind.clone(), args=(ind[1:],), kwargs=dict(out=ind[:-1])),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

# Error inputs for scatter
# 定义一系列的错误输入样本，用于测试scatter和scatter_add操作的异常情况
def error_inputs_scatter_and_scatter_add(op_info, device, **kwargs):
    # 当self的dtype不等于src的dtype（且src不是标量）时发生错误
    src = make_tensor((2, 5), device=device, dtype=torch.float32)
    idx = torch.tensor(((0, 1), (1, 2)), device=device, dtype=torch.long)
    dst = torch.zeros((3, 5), device=device, dtype=torch.double)
    # 生成一个ErrorInput对象，使用SampleInput包含dst作为参数，0和idx，src作为args的一部分
    yield ErrorInput(SampleInput(dst, args=(0, idx, src)),
                     error_regex="Expected self.dtype to be equal to src.dtype")

    # 索引的dtype必须是long类型
    src = make_tensor((2, 5), device=device, dtype=torch.float32)
    idx = torch.tensor(((0, 1), (1, 2)), device=device, dtype=torch.int32)
    dst = torch.zeros((3, 5), device=device, dtype=torch.float32)
    # 生成一个ErrorInput对象，使用SampleInput包含dst作为参数，0和idx，src作为args的一部分
    yield ErrorInput(SampleInput(dst, args=(0, idx, src)),
                     error_regex="Expected dtype int64 for index")

    # 索引和目标必须具有相同的维度数量
    src = make_tensor((2, 5), device=device, dtype=torch.float32)
    idx = torch.tensor(((0, 1), (1, 2)), device=device, dtype=torch.long)
    dst = torch.zeros((3, 5, 3), device=device, dtype=torch.float32)
    # 生成一个ErrorInput对象，使用SampleInput包含dst作为参数，0和idx，src作为args的一部分
    yield ErrorInput(SampleInput(dst, args=(0, idx, src)),
                     error_regex="Index tensor must have the same number of dimensions as self tensor")

    # 当src不是标量时，索引和src必须具有相同的维度数量
    src = make_tensor((2, 5, 2), device=device, dtype=torch.float32)
    idx = torch.tensor(((34, 1), (1, 2)), device=device, dtype=torch.long)
    dst = torch.zeros((3, 5), device=device, dtype=torch.float32)
    # 生成一个ErrorInput对象，使用SampleInput包含dst作为参数，0和idx，src作为args的一部分
    yield ErrorInput(SampleInput(dst, args=(0, idx, src)),
                     error_regex="Index tensor must have the same number of dimensions as src tensor")

    # 索引超出边界
    # 注意：此ErrorInput受保护，因为CUDA设备上不进行边界检查
    # 检查指定的设备是否为CPU
    if torch.device(device).type == 'cpu':
        # 创建一个形状为 (2, 5) 的浮点数张量，并指定设备和数据类型
        src = make_tensor((2, 5), device=device, dtype=torch.float32)
        # 创建一个长整型张量，包含元组 ((34, 1), (1, 2)) 的数据，并指定设备和数据类型
        idx = torch.tensor(((34, 1), (1, 2)), device=device, dtype=torch.long)
        # 创建一个形状为 (3, 5) 的零张量，并指定设备和数据类型
        dst = torch.zeros((3, 5), device=device, dtype=torch.float32)
        # 生成一个 ErrorInput 对象，包含一个 SampleInput 对象作为参数
        # SampleInput 对象包括 dst 张量和其他参数 (0, idx, src)
        # 同时设置错误的正则表达式匹配条件 "index 34 is out of bounds for dimension 0 with size 3"
        yield ErrorInput(SampleInput(dst, args=(0, idx, src)),
                         error_regex="index 34 is out of bounds for dimension 0 with size 3")
# 生成一个在指定设备上随机生成的标量张量
zero_d = torch.randn((), device=device)
# 返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
yield ErrorInput(SampleInput(zero_d, args=(0.5, 0, 1.0)), error_type=RuntimeError,
                 error_regex="needs at least 2 dimensions, got 0 dimensions")

# 创建一个指定设备上的全零张量，形状为 (5, 0)
tensor_0 = torch.full((5, 0,), 1, device=device)
# 创建一个指定设备上的全一张量，形状为 (5,)
tensor_1 = torch.full((5,), 1, device=device)
# 创建一个指定设备上的全一张量，形状为 (5, 5)
tensor_2 = torch.full((5, 5,), 1, device=device)
# 创建两个布尔值变量
bool_3 = True
bool_4 = True
# 返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
yield ErrorInput(SampleInput(tensor_0, args=(tensor_1, tensor_2, bool_3, bool_4)), error_type=RuntimeError,
                 error_regex=r"tau.shape\[-1\] must be less than or equal to input.shape\[-1\]")

# 生成一个在指定设备上随机生成的标量张量
zero_d = torch.randn((), device=device)
# 返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
yield ErrorInput(SampleInput(zero_d, args=(0,)), error_type=RuntimeError,
                 error_regex="1D or 2D")
# 生成一个在指定设备上随机生成的形状为 (1, 1, 1) 的张量
zero_d = torch.randn(1, 1, 1, device=device)
# 返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
yield ErrorInput(SampleInput(zero_d, args=(0,)), error_type=RuntimeError,
                 error_regex="1D or 2D")

# 创建一个在指定设备上随机生成的形状为 (2, 2) 的长整型张量
indices = torch.rand(2, 2, device=device).long()
# 创建一个包含两个张量的列表
weights = [
    torch.tensor(1.0, device=device),
    torch.tensor(1.0, device=device).reshape(1, 1, 1),
]

# 遍历 weights 列表中的每个张量并返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
for weight in weights:
    yield ErrorInput(SampleInput(weight, args=(indices,)), error_type=RuntimeError,
                     error_regex="'weight' must be 2-D")

# 返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
yield ErrorInput(
    SampleInput(torch.randn(2, 3, 4, 5, device=device)),
    error_regex="expects a tensor with <= 2",
)

# 创建一个指定设备上形状为 (1, 2, 3) 的双精度空张量
x = torch.empty(1, 2, 3, dtype=torch.double, device=device)
# 返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
yield ErrorInput(SampleInput(x, args=(2,)),
                 error_regex="prob_dist must be 1 or 2 dim")

# 创建一个指定设备上形状为 (1, 2) 的长整型空张量
x = torch.empty(1, 2, dtype=torch.long, device=device)
# 返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
yield ErrorInput(SampleInput(x, args=(2,)),
                 error_regex="multinomial only supports floating-point dtypes for input")

# 创建两个指定设备上形状为 (1, 2) 的双精度空张量
x = torch.empty(1, 2, dtype=torch.double, device=device)
y = torch.empty(1, 2, dtype=torch.double, device=device)
# 返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
yield ErrorInput(SampleInput(x, args=(2,), kwargs=dict(out=y)),
                 error_regex="multinomial expects Long tensor out")

# 创建一个指定设备上形状为 (2,) 的双精度空张量
x = torch.empty(2, dtype=torch.double, device=device)
# 返回一个包含单个 ErrorInput 对象的生成器，用于测试运行时错误
yield ErrorInput(SampleInput(x, args=(0,)),
                 error_regex="cannot sample n_sample <= 0 samples")

# 创建一个指定设备上形状为 (2,) 的双精度空张量
x = torch.empty(2, dtype=torch.double, device=device)
    # 创建一个 ErrorInput 对象，表示输入样本 x 含有负数元素的情况
    yield ErrorInput(SampleInput(x, args=(-1,)),
                     error_regex="cannot sample n_sample <= 0 samples")

    # 创建一个空的 torch 张量 x，数据类型为双精度浮点型，在指定的设备上
    x = torch.empty(2, dtype=torch.double, device=device)
    # 创建一个 ErrorInput 对象，表示尝试从概率分布中采样超过其可能的样本数
    yield ErrorInput(SampleInput(x, args=(3, False,)),
                     error_regex="cannot sample n_sample > prob_dist")

    # 创建一个过大的 torch 张量 x，数据类型为双精度浮点型，在指定的设备上
    x = torch.empty(16777217, dtype=torch.double, device=device)
    # 创建一个 ErrorInput 对象，表示类别数量超过了允许的最大值
    yield ErrorInput(SampleInput(x, args=(3,)),
                     error_regex="number of categories cannot exceed")

    # 定义一组输入数据，每组包含三个元素的元组
    inputs = ((1., -1., 1.), (1., inf, 1.), (1., -inf, 1.), (1., 1., nan))

    # 错误消息定义
    err_msg1 = "probability tensor contains either `inf`, `nan` or element < 0"
    err_msg2 = "invalid multinomial distribution"

    # 根据当前设备类型确定是否需要进行重复采样
    rep_arg = (False, True) if torch.device(device).type == 'cpu' else (False,)

    # 遍历重复采样参数
    for rep in rep_arg:
        kwargs = {'num_samples': 2, 'replacement': rep}

        # 遍历输入数据组
        for shape in inputs:
            # 创建一个 ErrorInput 对象，表示输入张量包含 `inf`、`nan` 或负元素的情况
            yield ErrorInput(SampleInput(torch.tensor(shape), kwargs=kwargs),
                             error_regex=err_msg1 if rep is False else err_msg2)

        # 创建一个全零张量 x，形状为 (3,)，在指定的设备上
        x = torch.zeros(3, device=device)
        # 创建一个 ErrorInput 对象，表示无效的多项分布（概率和 <= 0），1-D 输入
        yield ErrorInput(SampleInput(x, kwargs=kwargs),
                         error_regex=err_msg2)

        # 创建一个全零张量 x，形状为 (3, 3)，在指定的设备上
        x = torch.zeros(3, 3, device=device)
        # 创建一个 ErrorInput 对象，表示无效的多项分布（概率和 <= 0），2-D 输入
        yield ErrorInput(SampleInput(x, kwargs=kwargs),
                         error_regex=err_msg2)

        # 修改 x 的第二行所有元素为 1
        x[1, :] = 1
        # 创建一个 ErrorInput 对象，表示无效的多项分布（概率和 <= 0）
        yield ErrorInput(SampleInput(x, kwargs=kwargs),
                         error_regex=err_msg2)
# 定义函数 `error_inputs_gradient`，接受操作信息 `op_info`、设备 `device` 和其他关键字参数 `kwargs`
def error_inputs_gradient(op_info, device, **kwargs):
    # 遍历三种数据类型：torch.long、torch.float32、torch.complex64
    for dtype in [torch.long, torch.float32, torch.complex64]:
        # 创建一个二维张量 `t`，包含数字 1 到 9，设备和数据类型由参数指定
        t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], device=device, dtype=dtype)

        # 设置维度 `dim` 为元组 (1, 0)
        dim = (1, 0)
        # 设置间距 `spacing` 为列表 [0.1]
        spacing = [0.1]
        # 返回一个 `ErrorInput` 实例，传入 `SampleInput` 对象和错误信息
        yield ErrorInput(SampleInput(t, kwargs=dict(spacing=spacing, dim=dim, edge_order=1)),
                         error_type=RuntimeError,
                         error_regex='torch.gradient expected spacing to be unspecified, a scalar ')

        # 返回一个 `ErrorInput` 实例，传入 `SampleInput` 对象和错误信息
        yield ErrorInput(SampleInput(t, kwargs=dict(edge_order=3)),
                         error_type=RuntimeError,
                         error_regex='torch.gradient only supports edge_order=1 and edge_order=2.')

        # 设置维度 `dim` 为元组 (1, 1)
        dim = (1, 1)
        # 设置间距 `spacing` 为标量 0.1
        spacing = 0.1
        # 返回一个 `ErrorInput` 实例，传入 `SampleInput` 对象和错误信息
        yield ErrorInput(SampleInput(t, kwargs=dict(spacing=spacing, dim=dim, edge_order=1)),
                         error_type=RuntimeError,
                         error_regex='dim 1 appears multiple times in the list of dims')

        # 设置维度 `dim` 为元组 (0, 1)
        dim = (0, 1)
        # 创建一个包含两个张量的列表 `coordinates`，分别在不同设备上
        coordinates = [torch.tensor([1, 2, 4], device='cpu'), torch.tensor([1, 2, 4], device='meta')]
        # 返回一个 `ErrorInput` 实例，传入 `SampleInput` 对象和错误信息
        yield ErrorInput(SampleInput(t, kwargs=dict(spacing=coordinates, dim=dim, edge_order=1)),
                         error_type=RuntimeError,
                         error_regex='torch.gradient expected each tensor to be on the same device,')

        # 返回一个 `ErrorInput` 实例，传入 `SampleInput` 对象和错误信息
        yield ErrorInput(SampleInput(t, kwargs=dict(dim=3)),
                         error_type=IndexError, error_regex='')

        # 创建一个二维张量 `t`，只包含三行一列的数据
        t = torch.tensor([[1], [2], [3]])
        # 返回一个 `ErrorInput` 实例，传入 `SampleInput` 对象和错误信息
        yield ErrorInput(SampleInput(t, kwargs=dict(edge_order=1)),
                         error_type=RuntimeError,
                         error_regex='torch.gradient expected each dimension size to be at least')

        # 创建一个二维张量 `t`，只包含两行两列的数据
        t = torch.tensor([[1, 2], [3, 4]])
        # 返回一个 `ErrorInput` 实例，传入 `SampleInput` 对象和错误信息
        yield ErrorInput(SampleInput(t, kwargs=dict(edge_order=2)),
                         error_type=RuntimeError,
                         error_regex='torch.gradient expected each dimension size to be at least')

# 定义函数 `sample_inputs_rrelu`，接受操作信息 `op_info`、设备 `device`、数据类型 `dtype`、是否需要梯度 `requires_grad` 和其他关键字参数 `kwargs`
def sample_inputs_rrelu(op_info, device, dtype, requires_grad, **kwargs):
    # 通过 `sample_inputs_elementwise_unary` 生成器获取样本输入
    yield from sample_inputs_elementwise_unary(
        op_info, device, dtype, requires_grad, op_kwargs=dict(lower=0., upper=1., training=True))

    # 创建 `make_arg` 函数，部分应用 `make_tensor` 函数，设备和数据类型由参数指定
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 返回一个 `SampleInput` 实例，传入 `make_arg` 函数和 `S` 参数
    yield SampleInput(make_arg(S))
    # 返回一个 `SampleInput` 实例，传入 `make_arg` 函数、 `S` 参数和 `training=False` 参数
    yield SampleInput(make_arg(S), training=False)

# 定义函数 `error_inputs_rrelu`，接受操作信息 `op_info`、设备 `device` 和其他关键字参数 `kwargs`
def error_inputs_rrelu(op_info, device, **kwargs):
    # 创建一个 `input` 张量，形状为 `(S, S)`，设备和数据类型由参数指定
    input = make_tensor((S, S), device=device, dtype=torch.float32)
    # 返回一个 `ErrorInput` 实例，传入 `SampleInput` 对象和错误信息
    yield ErrorInput(SampleInput(input, kwargs={'lower': 0.3, 'upper': 0.1}),
                     error_regex='Lower bound should be less than or equal to the upper bound')

# 定义函数 `error_inputs_masked_select`，接受操作信息 `op_info`、设备 `device` 和其他关键字参数 `kwargs`
def error_inputs_masked_select(op_info, device, **kwargs):
    # 创建一个形状为 `(1,)` 的随机张量 `x`，并将其扩展为形状 `(3,)`
    x = torch.rand((1,), device=device).expand((3,))
    # 创建一个形状为 `(6,)` 的随机张量 `y`
    y = torch.rand((6,), device=device)
    # 创建一个布尔掩码张量 `mask`
    mask = torch.tensor([True, False, True, True, False, False], device=device)
    # 使用 ErrorInput 生成器函数生成一个带有异常输入的对象，包括输入参数 y，一个元组 args 包含 mask，以及一个关键字参数字典包含输出 x
    yield ErrorInput(SampleInput(y, args=(mask,), kwargs=dict(out=x)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

    # 使用 ErrorInput 生成器函数生成一个带有异常输入的对象，包括输入参数 y，一个元组 args 包含 mask，以及一个关键字参数字典包含输出 y
    yield ErrorInput(SampleInput(y, args=(mask,), kwargs=dict(out=y)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

    # 使用 ErrorInput 生成器函数生成一个带有异常输入的对象，包括输入参数 mask 的克隆，一个元组 args 包含 mask，以及一个关键字参数字典包含输出 mask
    yield ErrorInput(SampleInput(mask.clone(), args=(mask,), kwargs=dict(out=mask)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')
def error_inputs_median(op_info, device, **kwargs):
    # 创建包含 NaN 值的高维张量 x，使用指定的设备
    x = torch.tensor([[[[[[[[[[[[[[[[[[[[[[[[[nan],
                               [nan]]]]]]]]]]]]]]]]]]]]]]]]], device=device)
    # 如果设备是 'cuda'，则生成一个错误输入对象
    if device == 'cuda':
        yield ErrorInput(SampleInput(x, kwargs=dict(dim=(-1))),
                         error_type=RuntimeError,
                         error_regex='CUDA Tensors cannot have more than 25 dimensions')
    else:
        # 否则返回空
        return


def error_inputs_index_select(op_info, device, **kwargs):
    # 创建张量 x 和 y，使用指定的设备
    x = torch.rand((1, 6), device=device).expand((2, 6))
    y = torch.rand((3, 6), device=device)
    # 创建索引张量 ind，使用指定的设备和数据类型
    ind = torch.tensor([0, 1], dtype=torch.int64, device=device)

    # 生成一个错误输入对象，用于测试索引选择操作
    yield ErrorInput(SampleInput(y, args=(1, ind,), kwargs=dict(out=x)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')


def error_inputs_index_add(op_info, device, **kwargs):
    # 创建源张量和结果张量，用于测试索引加法操作
    result = torch.tensor([[1., 2.], [4., 5.], [7., 8.]])
    source = torch.tensor([2., 4.])

    # 生成一个错误输入对象，测试索引加法操作的异常情况
    yield ErrorInput(SampleInput(result, args=(0, torch.tensor([0, 2]), source)),
                     error_type=RuntimeError,
                     error_regex=r'source tensor shape must match self tensor shape, '
                     r'excluding the specified dimension. Got self.shape = \[3, 2\] source.shape = \[2\]')


def error_inputs_logcumsumexp(op_info, device, **kwargs):
    # 指定维度为3，创建多个随机张量作为输入数据
    dim = 3
    srcs = [torch.randn(5, 2, device=device), torch.randn(0, 2, device=device)]
    # 遍历每个输入张量，生成相应的错误输入对象
    for src in srcs:
        yield ErrorInput(SampleInput(src, args=(dim,)),
                         error_type=IndexError,
                         error_regex='Dimension out of range')


def sample_inputs_take_along_dim(op_info, device, dtype, requires_grad, **kwargs):
    # 创建张量和 gather 操作的参数，生成多个样本输入
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    yield SampleInput(
        make_arg((S, S)), gather_variable((S, S), 1, S, True, device=device), 0)

    # `indices` 广播操作的样本输入
    yield SampleInput(
        make_arg((S, S)), gather_variable((1, S // 2), 0, S, True, device=device), 1)

    # `self` 广播操作的样本输入
    yield SampleInput(
        make_arg((1, S)), gather_variable((S, S // 2), 0, S, True, device=device), 1)

    # 没有 `dim` 参数的样本输入
    yield SampleInput(
        make_arg((S, S)), gather_variable((S, S // 2), 0, S, True, device=device))


def error_inputs_aminmax_amax_amin(op_info, device, is_ref=False, **kwargs):
    # 错误输入用于处理零维张量，并检查是否提供了 'dim' 参数
    shape = (S, 0, S)
    err_msg_amax_amin = "reduction"
    err_msg_aminmax = "cannot compute aminmax over an empty dimension as the operation has no identity"
    if op_info.name in ['amax', 'amin', '_refs.amax', '_refs.amin']:
        # 生成用于测试 amax 或 amin 操作异常情况的错误输入对象
        yield ErrorInput(SampleInput(torch.rand(shape, device=device)), error_regex=err_msg_amax_amin)
    elif op_info.name in ['aminmax']:
        # 生成用于测试 aminmax 操作异常情况的错误输入对象
        yield ErrorInput(SampleInput(torch.rand(shape, device=device)), error_regex=err_msg_aminmax)
    # Error Inputs for tensors with more than 64 dimensions
    sizes = [1] * 65  # 创建一个包含65个元素的列表，每个元素为1，表示一个超过64维度的张量尺寸
    err_msg1 = "only tensors with up to 64 dims are supported"  # 错误消息，指示仅支持最多64维的张量
    yield ErrorInput(SampleInput(torch.randn(sizes, device=device), kwargs={'dim': -1}),
                     error_regex=err_msg1)  # 生成一个错误输入对象，传入一个超过64维度的张量，并期望匹配错误消息err_msg1
    yield ErrorInput(SampleInput(torch.randn(sizes, device=device), kwargs={'dim': 64}),
                     error_regex=err_msg1)  # 同上，测试64维度的张量是否触发相同的错误消息

    # Error Inputs for repeated 'dim'
    if op_info.name in ['amax', 'amin', '_refs.amax', '_refs.amin']:
        dims = [(0, 0), (0, -4)]  # 定义一些重复的维度组合
        err_msg2 = "in the list of dims"  # 错误消息，指示在维度列表中出现重复
        x = torch.randn(S, S, S, S, device=device)  # 创建一个具有四个维度的张量
        for dim in dims:
            yield ErrorInput(SampleInput(x, kwargs={'dim': dim}), error_regex=err_msg2)
            # 生成错误输入对象，每次使用不同的维度组合dim，并期望匹配错误消息err_msg2

    # Error Input for illegal dtype
    input5 = torch.randn(L, L, dtype=torch.float32, device=device)  # 创建一个指定dtype的张量
    max_values = torch.empty(L, dtype=torch.float32, device=device)  # 创建一个指定dtype的空张量
    min_values = torch.empty(L, dtype=torch.double, device=device)  # 创建一个指定dtype的空张量
    illegal_values = torch.empty(L, dtype=torch.int, device=device)  # 创建一个指定dtype的空张量

    # Unlike regular PyTorch, amax and amin refs don't require input and out
    # dtypes to match exactly:
    # https://github.com/pytorch/pytorch/pull/87765#pullrequestreview-1162023824
    if is_ref:
        err_msg_amax_amin2 = ("Attempting to cast from torch.float32 to out tensor with dtype "
                              "torch.int32, but this can't be cast because it is not safe!")
    else:
        err_msg_amax_amin2 = ("Expected the dtype for input and out to match, but got Float "
                              "for input's dtype and Int for out's dtype.")
    err_msg_aminmax2 = "Expected out tensor to have dtype float, but got double instead"

    if op_info.name in ['amax', 'amin', '_refs.amax', '_refs.amin']:
        yield ErrorInput(SampleInput(input5, kwargs={'dim': 0, 'out': illegal_values}),
                         error_regex=err_msg_amax_amin2)
        # 生成错误输入对象，传入一个张量和一个非法的输出张量illegal_values，并期望匹配错误消息err_msg_amax_amin2
    elif op_info.name in ['aminmax']:
        yield ErrorInput(SampleInput(input5, kwargs={'dim': 0, 'out': (max_values, min_values)}),
                         error_regex=err_msg_aminmax2)
        # 生成错误输入对象，传入一个张量和一个非法的输出元组(max_values, min_values)，并期望匹配错误消息err_msg_aminmax2

    # Error Inputs for functions to raise an error on specified zero'd dimension as reduction dim
    err_msg3 = "reduction"  # 错误消息，指示在指定的维度上作为降维操作时出错
    # FIXME: eager and ref impl throw different types of errors
    error_type = IndexError if 'refs' not in op_info.name else RuntimeError
    yield ErrorInput(SampleInput(torch.rand(shape, device=device), kwargs={'dim': 1}),
                     error_type=error_type, error_regex=err_msg3)
    # 生成错误输入对象，传入一个随机张量和一个指定维度为1的kwargs，期望匹配错误类型error_type和错误消息err_msg3
# 定义一个生成器函数，生成输入数据以进行最小值和最大值操作的测试
def sample_inputs_aminmax(op_info, device, dtype, requires_grad, **kwargs):
    # 定义不同形状和参数的测试用例元组
    test_cases: Tuple[tuple, dict] = (
        ((S, S, S), {}),                    # 3维张量的基本情况
        ((S, S, S), {'dim': 1}),            # 指定维度为1的情况
        ((S, S, S), {'dim': 1, 'keepdim': True}),  # 指定维度为1且保持维度的情况
        ((), {'dim': 0}),                   # 零维张量的情况
        ((), {}),                           # 零维张量的基本情况
        ((), {'dim': 0, 'keepdim': True}),  # 零维张量保持维度的情况
        ((S, 0, S), {'dim': 0}),            # 形状为(S, 0, S)的张量的情况
    )

    # 遍历测试用例
    for shape, kwargs in test_cases:
        # 使用make_tensor函数生成张量样本，并作为SampleInput的一部分返回
        yield SampleInput(
            make_tensor(shape, dtype=dtype, device=device, requires_grad=requires_grad),
            **kwargs)

# 定义一个生成器函数，生成包含错误输入的测试用例
def error_inputs_diff(op_info, device, **kwargs):
    # 生成一个形状为(1, 3)的随机张量
    t = torch.rand((1, 3), device=device)
    n = -1
    # 生成一个包含错误输入的ErrorInput对象
    yield ErrorInput(SampleInput(t, args=(n, ), kwargs=kwargs),
                     error_type=RuntimeError,
                     error_regex=f'order must be non-negative but got {n}')

# 定义一个生成器函数，生成不同形状的输入数据用于测试
def sample_inputs_diff(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同测试用例的元组
    test_cases = (
        ((1,), 0, None, None),
        ((S,), 0, None, None),
        ((S, 1), 0, None, None),
        ((S, 1), 1, None, None),
        ((S, S), 0, None, None),
        ((S, S), 1, None, None),
        ((S, S), 0, (1, S), (2, S)),
        ((S, S), 0, None, (2, S)),
        ((XS, XS, XS), 1, None, None),
        ((XS, XS, XS), 2, None, None),
        ((XS, XS, XS), 1, (XS, 1, XS), (XS, 1, XS)),
        ((XS, XS, XS), 2, (XS, XS, 1), (XS, XS, 1)),
        ((XS, XS, XS), 2, (XS, XS, XS), (XS, XS, XS)),
    )

    # 遍历测试用例
    for size, dim, size_prepend, size_append in test_cases:
        # 计算前缀和后缀的大小
        prepend_size = 0 if (size_prepend is None) else size_prepend[dim]
        append_size = 0 if (size_append is None) else size_append[dim]
        dim_size = size[dim] + prepend_size + append_size
        # 对于每个维度大小，生成不同的输入张量，并作为SampleInput的一部分返回
        for n in range(dim_size):
            input_tensor = make_arg(size)
            prepend = make_arg(size_prepend) if size_prepend else None
            append = make_arg(size_append) if size_append else None
            yield SampleInput(input_tensor, n, dim, prepend, append)

    # 添加一些n大于dim_size的样本
    yield SampleInput(make_arg((XS, XS, XS)), S + 1, 1)
    yield SampleInput(make_arg((XS, XS, XS)), S * 3 + 2, 2, make_arg((XS, XS, XS)), make_arg((XS, XS, XS)))

# 定义一个生成器函数，生成用于直方图操作的输入数据
def sample_inputs_histogram(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同形状的张量作为测试用例的sizes元组
    sizes = ((), (S,), (S, S), (S, S, S), (S, 1, S), (S, 0, S))
    # 遍历 sizes、range(1, 5)、[False, True]、[False, True] 组成的笛卡尔积
    for size, bin_ct, weighted, density in product(sizes, range(1, 5), [False, True], [False, True]):
        # 根据当前 size 生成输入张量
        input_tensor = make_arg(size)
        # 如果 weighted 为 True，则生成相应尺寸的权重张量，否则为 None
        weight_tensor = make_arg(size) if weighted else None

        # 生成 SampleInput 对象，包括输入张量、bin_ct 数量，可能的权重张量和密度参数
        yield SampleInput(input_tensor, bin_ct,
                          weight=weight_tensor, density=density)

        # 生成 bins_tensor，其长度为 bin_ct + 1
        bins_tensor = make_arg((bin_ct + 1,))
        # 生成 SampleInput 对象，包括输入张量、bins_tensor、可能的权重张量和密度参数
        yield SampleInput(input_tensor, bins_tensor,
                          weight=weight_tensor, density=density)
# 定义函数，生成多个输入直方图分布的示例
def sample_inputs_histogramdd(op_info, device, dtype, requires_grad, **kwargs):
    # 部分函数生成器，用于生成具有指定设备、数据类型和梯度要求的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同的尺寸和直方图分布模式
    sizes = ((S, S), (S, S, S), (S, 1, S), (S, 0, S))
    bin_ct_patterns = ((1, 1, 1, 1, 1), (2, 3, 2, 3, 2), (3, 2, 3, 2, 3))

    # 使用 product 函数生成所有组合的示例输入
    for size, bin_ct_pattern, weighted, density in product(sizes, bin_ct_patterns, [False, True], [False, True]):
        # 创建输入张量
        input_tensor = make_arg(size)
        # 获取当前维度对应的 bins 数量
        bin_ct = bin_ct_pattern[:size[-1]]
        # 创建权重张量（如果需要的话）
        weight_tensor = make_arg(size[:-1]) if weighted else None

        # 生成 SampleInput 对象，包含输入张量、bins 数组、权重张量和密度标志
        yield SampleInput(input_tensor, bin_ct,
                          weight=weight_tensor, density=density)

        # 生成 SampleInput 对象，包含输入张量、bins 张量数组、权重张量和密度标志
        bins_tensor = [make_arg(ct + 1) for ct in bin_ct]
        yield SampleInput(input_tensor, bins_tensor,
                          weight=weight_tensor, density=density)

# 定义函数，生成直方图函数中的错误输入示例
def error_inputs_histogramdd(opinfo, device, **kwargs):
    # 无效的 bins 数组
    invalid_bins = [1, 1, 1, 1, 1]
    # 部分函数生成器，用于生成具有指定设备和数据类型的张量
    make_arg = partial(make_tensor, dtype=torch.float, device=device, requires_grad=False)
    # 错误信息
    msg = "histogramdd: The size of bins must be equal to the innermost dimension of the input."
    # 生成 ErrorInput 对象，包含样本输入对象和错误信息
    yield ErrorInput(SampleInput(make_arg(5, 6), invalid_bins), error_regex=msg)

# 定义函数，生成直方图计数的示例输入
def sample_inputs_histc(op_info, device, dtype, requires_grad, **kwargs):
    # 部分函数生成器，用于生成具有指定设备、数据类型和梯度要求的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同的尺寸和最小最大值组合
    sizes = ((), (S,), (S, S), (S, S, S), (S, 1, S), (S, 0, S))

    # 使用 product 函数生成所有组合的示例输入
    for size, min, max in product(sizes, [0, -10], [0, 10]):
        # 生成 SampleInput 对象，包含输入张量和最小最大值
        yield SampleInput(make_arg(size), min=min, max=max)

        # 使用不同的 bins 值生成 SampleInput 对象
        for bins in [1, 3, 10]:
            yield SampleInput(make_arg(size), bins=bins, min=min, max=max)

# 定义函数，生成计数非零元素的示例输入
def sample_inputs_bincount(op_info, device, dtype, requires_grad, **kwargs):
    # 部分函数生成器，用于生成具有指定设备、数据类型和梯度要求的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 使用 product 函数生成所有组合的示例输入
    for size, weighted in product((S, M), [False, True]):
        # 创建随机整数张量作为输入张量
        input_tensor = torch.randint(0, size, (size,), dtype=dtype, device=device)
        # 创建权重张量（如果需要的话）
        weight_tensor = make_arg((size,)) if weighted else None

        # 获取输入张量的最大值
        max_val = int(input_tensor.max().item())

        # 使用不同的 minlength 值生成 SampleInput 对象
        for minlength in [0, max_val // 2, max_val, 2 * max_val]:
            yield SampleInput(
                input_tensor, weights=weight_tensor, minlength=minlength)

# 定义函数，生成 bucketize 操作的示例输入
def sample_inputs_bucketize(op_info, device, dtype, requires_grad, reference_inputs_mode=False, **kwargs):
    # 部分函数生成器，用于生成具有指定设备、数据类型和梯度要求的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同的尺寸和桶的数量组合
    sizes = (((), S), ((S,), S), ((S, S), S), ((S, S, S), S), ((S, 1, S), S), ((S, 0, S), S))

    # 如果是参考输入模式，添加额外的尺寸和桶的数量组合
    if reference_inputs_mode:
        sizes += (((256,), 128), ((128,), 256), ((32, 32), 11), ((32, 4, 32), 33))
    # 使用 product 函数生成所有可能的组合：input_shape, nb, out_int32, right
    # 其中 sizes 是输入形状的列表，[False, True] 是 out_int32 的可能取值，[False, True] 是 right 的可能取值
    for (input_shape, nb), out_int32, right in product(sizes, [False, True], [False, True]):
        # 根据 input_shape 创建输入张量
        input_tensor = make_arg(input_shape)
        # 根据 nb 创建边界并排序
        boundaries = make_arg(nb).msort()

        # 生成 SampleInput 对象，包括 input_tensor、boundaries 以及其他参数 out_int32 和 right
        yield SampleInput(input_tensor, boundaries,
                          out_int32=out_int32, right=right)
# 使用偏函数创建一个特定模式的 sample_inputs_bucketize 函数
reference_inputs_bucketize = partial(sample_inputs_bucketize, reference_inputs_mode=True)

# 定义一个生成器函数 error_inputs_bucketize，用于生成 ErrorInput 对象
def error_inputs_bucketize(opinfo, device, **kwargs):
    # 使用偏函数创建一个 make_tensor 函数，设置了 dtype、device 和 requires_grad 参数
    make_arg = partial(make_tensor, dtype=torch.float, device=device, requires_grad=False)
    # 生成并 yield 一个 ErrorInput 对象，包含两个 SampleInput 对象和一个 error_regex 参数
    yield ErrorInput(SampleInput(make_arg((S, S, S)), make_arg((S, S))),
                     error_regex="boundaries tensor must be 1 dimension")

# 定义一个生成器函数 sample_inputs_searchsorted，用于生成 SampleInput 对象
def sample_inputs_searchsorted(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数创建一个 make_tensor 函数，设置了 dtype、device 和 requires_grad 参数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义多组测试数据的大小、输入大小和标量标记
    sizes = (
        ((0,), ((0,),), False),
        ((M,), ((), (M,), (M, M)), False),
        ((0, 0), ((0, 0),), False),
        ((M, M), ((M, M),), False),
        ((0, 0, 0), ((0, 0, 0),), False),
        ((M, M, M), ((M, M, M),), False),
        ((L,), ((),), True),
    )

    # 使用 product 函数生成所有可能的组合，并遍历生成 SampleInput 对象
    for (size, input_sizes, is_scalar), noncontiguous, out_int32, right in product(
        sizes, [False, True], [False, True], [False, True]
    ):
        # 创建未排序的张量 unsorted_tensor
        unsorted_tensor = make_arg(size, noncontiguous=noncontiguous)
        for input_size in input_sizes:
            # 创建输入张量 input
            input = make_arg(input_size, noncontiguous=noncontiguous)
            if is_scalar:
                input = input.item()
            # 如果 size 的元素乘积为 0，则将 boundary_tensor 设置为 unsorted_tensor
            if np.prod(size) == 0:
                boundary_tensor = unsorted_tensor
                # 创建一个排序器 sorter，数据类型为 torch.int64
                sorter = make_tensor(size, dtype=torch.int64, device=device, noncontiguous=noncontiguous)
            else:
                # 对 unsorted_tensor 进行排序，boundary_tensor 为排序后的结果，sorter 为排序的索引
                boundary_tensor, sorter = torch.sort(unsorted_tensor)
            # 根据 right 参数确定 side 的值为 "right" 或 "left"
            side = "right" if right else "left"

            # yield 生成 SampleInput 对象，包含 boundary_tensor、input、out_int32 和 right 参数
            yield SampleInput(boundary_tensor, input, out_int32=out_int32, right=right)
            # yield 生成 SampleInput 对象，包含 boundary_tensor、input、out_int32 和 side 参数
            yield SampleInput(boundary_tensor, input, out_int32=out_int32, side=side)

            # yield 生成 SampleInput 对象，包含 unsorted_tensor、input、out_int32、right 和 sorter 参数
            yield SampleInput(unsorted_tensor, input, out_int32=out_int32, right=right, sorter=sorter)
            # yield 生成 SampleInput 对象，包含 unsorted_tensor、input、out_int32、side 和 sorter 参数
            yield SampleInput(unsorted_tensor, input, out_int32=out_int32, side=side, sorter=sorter)

# 定义一个生成器函数 sample_inputs_gradient，用于生成 SampleInput 对象
def sample_inputs_gradient(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数创建一个 make_tensor 函数，设置了 device、dtype、requires_grad、low 和 high 参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    
    # 定义多组测试数据的大小、间隔、维度和边界顺序
    test_cases_float = (
        ((S,), None, None, 1),
        ((S,), 2., None, 1),
        ((S, S), None, None, 2),
        ((S, S), [2.0, 2.1], None, 1),
        ((S, S), [2.0, 2.1], (0, 1), 1),
        ((4, 4, 4), [2., 1.], (0, 1), 2),
    )
    
    # 遍历 test_cases_float 生成 SampleInput 对象
    for size, spacing, dim, edge_order in test_cases_float:
        t = make_arg(size)
        yield SampleInput(t, dim=dim, spacing=spacing, edge_order=edge_order)

    # 定义另一组测试数据的大小、间隔、维度和边界顺序
    test_cases_tensor = (
        ((3, 3, 3), ((1.1, 2.0, 3.5), (4.0, 2, 6.0)), (0, -1), 1),
        ((3, 3, 3), ((1.0, 3.0, 2.0), (8.0, 6.0, 1.0)), (0, 1), 2),
    )
    
    # 遍历 test_cases_tensor 生成 SampleInput 对象
    for size, spacing, dim, edge_order in test_cases_tensor:
        t1 = make_arg(size)
        t2 = make_arg(spacing)
        yield SampleInput(t1, t2, dim=dim, edge_order=edge_order)
    # 对于每个测试用例，从 `test_cases_tensor` 中解包 `size`, `coordinates`, `dim`, `edge_order`
    for size, coordinates, dim, edge_order in test_cases_tensor:
        # 调用 `make_arg` 函数生成张量 `t`
        t = make_arg(size)
        
        # 初始化一个空列表 `coordinates_tensor_list` 用于存储坐标张量
        coordinates_tensor_list = []
        
        # 遍历 `coordinates` 列表中的每个坐标 `coords`
        for coords in coordinates:
            # 创建包含坐标数据的张量 `a`，并将其存入 `coordinates_tensor_list`
            # 注意：`coords` 中的值为浮点数，Python 3.10 不支持隐式转换为整数
            # TODO: 在 https://github.com/pytorch/pytorch/issues/69316 修复后可以简化此处代码
            a = torch.tensor(coords, device=device)
            coordinates_tensor_list.append(a.to(dtype))
        
        # 使用生成的张量和参数创建 `SampleInput` 对象，并通过 `yield` 语句返回
        yield SampleInput(t, dim=dim, spacing=coordinates_tensor_list, edge_order=edge_order)
# 定义函数 sample_inputs_getitem，生成测试输入参数的生成器
def sample_inputs_getitem(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数 make_arg，用于生成张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    
    # 定义多组测试参数
    test_args = [
        ([1, 2],),  # 测试参数列表
        (slice(0, 3),),  # 测试切片参数
        ([slice(0, 3), 1],),  # 测试包含切片和索引的参数
        ([[0, 2, 3], [1, 3, 3], [0, 0, 2]],),  # 测试多维列表参数
        ([[0, 0, 3], [1, 1, 3], [0, 0, 2]],),  # 另一组多维列表参数
        ([slice(None), slice(None), [0, 3]],),  # 测试包含 None 的切片参数
        ([slice(None), [0, 3], slice(None)],),  # 更多包含 None 的切片参数
        ([[0, 3], slice(None), slice(None)],),  # 另一组包含 None 的切片参数
        ([[0, 3], [1, 2], slice(None)],),  # 测试混合索引和切片参数
        ([[0, 3], ],),  # 测试只含一个子列表的参数
        ([[0, 3], slice(None)],),  # 测试包含一个切片的子列表参数
        ([[0, 3], Ellipsis],),  # 测试包含省略号的子列表参数
        ([[0, 2, 3], [1, 3, 3], torch.LongTensor([0, 0, 2])],),  # 测试包含张量的多维列表参数
        (index_variable(2, S, device=device),),  # 使用索引变量生成的参数
        (mask_not_all_zeros((S,)),),  # 使用非全零掩码生成的参数
    ]
    
    # 遍历测试参数，并生成 SampleInput 对象的生成器
    for args in test_args:
        yield SampleInput(make_arg((S, S, S)), args=args)
    
    # 添加一个额外的测试参数，测试四维张量的情况
    yield SampleInput(make_arg((S, S, S, S)), args=([slice(None), [0, 1], slice(None), [0, 1]],))

# 定义函数 sample_inputs_index_put，生成测试输入参数的生成器
def sample_inputs_index_put(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数 make_arg，用于生成张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    
    # 遍历 accumulate 变量的两种可能取值：False 和 True
    for accumulate in [False, True]:
        # 测试使用索引参数的情况
        yield SampleInput(
            make_arg((S, S,)),  # 生成一个二维张量
            (index_variable(2, S, device=device),),  # 使用索引变量生成的参数
            make_arg((2, S)),  # 生成一个二维张量
            accumulate=accumulate)  # 是否累积
        
        # 测试使用掩码参数的情况
        mask = torch.zeros(S, dtype=torch.bool) if accumulate else mask_not_all_zeros((S,))
        yield SampleInput(
            make_arg((S, S)),  # 生成一个二维张量
            (mask, ),  # 使用掩码生成的参数
            make_arg((S,)),  # 生成一个一维张量
            accumulate=accumulate)  # 是否累积

# 定义函数 sample_inputs_sort，生成测试输入参数的生成器
def sample_inputs_sort(op_info, device, dtype, requires_grad, **kwargs):
    # 定义一个生成小型三维独特张量的函数
    def small_3d_unique():
        res = torch.randperm(S * S * S, dtype=torch.int64, device=device).view(S, S, S)
        res = res.to(dtype).requires_grad_(requires_grad)
        return res
    
    # 定义一个生成大型一维独特张量的函数
    def large_1d_unique():
        res = torch.randperm(L * L * L, dtype=torch.int64, device=device)
        res = res.to(dtype).requires_grad_(requires_grad)
        return res
    
    # 测试用例：大型张量的情况
    yield SampleInput(large_1d_unique())
    
    # 测试用例：小型三维张量的情况，模仿自 test/test_torch.py 中的传统测试
    dims = range(-3, 3)
    flag = [True, False]
    for dim, descending, stable in product(dims, flag, flag):
        # 默认方案，不稳定排序
        yield SampleInput(small_3d_unique(), dim, descending)
        # 包含稳定排序的方案，目前不支持 CUDA
        if torch.device(device).type == 'cpu':
            yield SampleInput(
                small_3d_unique(), dim=dim, descending=descending, stable=stable)
    
    # 测试用例：标量张量的情况
    tensor_opt = dict(dtype=dtype, device=device, requires_grad=requires_grad)
    yield SampleInput(torch.tensor(1, **tensor_opt))  # 生成一个标量张量
    yield SampleInput(torch.tensor(1, **tensor_opt), 0)  # 生成一个标量张量，并指定索引参数
    yield SampleInput(torch.tensor(1, **tensor_opt), 0, True)  # 生成一个标量张量，并指定索引和布尔参数

    # 测试用例：空张量的情况
    # 使用 SampleInput 类生成一个输入样本，其中包含一个空的 Torch 张量，使用 tensor_opt 中的选项
    yield SampleInput(torch.tensor((), **tensor_opt))
    
    # 使用 SampleInput 类生成一个输入样本，包含一个空的 Torch 张量和一个额外的参数 0，使用 tensor_opt 中的选项
    yield SampleInput(torch.tensor((), **tensor_opt), 0)
    
    # 使用 SampleInput 类生成一个输入样本，包含一个空的 Torch 张量、额外参数 0 和参数 True，使用 tensor_opt 中的选项
    yield SampleInput(torch.tensor((), **tensor_opt), 0, True)

    # 使用 SampleInput 类生成一个输入样本，包含一个小型 3D 唯一数据集，使用稳定排序选项
    yield SampleInput(small_3d_unique(), stable=True)
    
    # 使用 SampleInput 类生成一个输入样本，包含一个小型 3D 唯一数据集，指定维度为 0 和稳定排序选项
    yield SampleInput(small_3d_unique(), dim=0, stable=True)
    
    # 使用 SampleInput 类生成一个输入样本，包含一个小型 3D 唯一数据集，指定维度为 0、降序排序和稳定排序选项
    yield SampleInput(small_3d_unique(), dim=0, descending=True, stable=True)
def sample_inputs_threshold(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了 make_tensor 的函数，用于生成张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 定义不同的张量尺寸
    sizes = ((), (S,), (S, S), (S, S, S))
    # 遍历每种尺寸
    for x_size in sizes:
        # threshold 和 values 参数必须是数字
        yield SampleInput(make_arg(x_size), make_arg(()).item(), make_arg(()).item())

def sample_inputs_unique(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了 make_tensor 的函数，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 定义不同的张量尺寸和其他参数组合
    sizes = ((), (S,), (S, S), (S, S, S), (S, 1, S), (S, 0, S))

    # 使用 product 生成不同的参数组合
    for shape, sorted, return_inverse, return_counts, dim in \
            product(sizes, [False, True], [False, True], [False, True], [None, -2, -1, 0, 1, 2]):
        # 如果张量尺寸包含 0，并且 0 不是选定的维度，跳过
        if 0 in shape and shape.index(0) is not dim:
            continue

        # 跳过无效的维度参数
        if dim is not None and (dim < -len(shape) or dim >= len(shape)):
            continue

        # 根据当前参数组合构造 kwargs 字典
        kwargs = dict(sorted=sorted, return_inverse=return_inverse, return_counts=return_counts, dim=dim)

        # 构造只有一个唯一值的测试用例
        input_t = torch.zeros(shape, dtype=dtype, device=device, requires_grad=requires_grad)
        yield SampleInput(input_t, **kwargs)

        # 构造包含混合 0 和 1 的测试用例
        input_t = make_arg(shape, dtype=torch.bool, requires_grad=False)\
            .to(dtype).requires_grad_(requires_grad)
        yield SampleInput(input_t, **kwargs)

        # 构造包含多个不同值的测试用例
        yield SampleInput(make_arg(shape), **kwargs)

def sample_inputs_unique_consecutive(*args, **kwargs):
    # 遍历 sample_inputs_unique 生成的所有样本输入
    for sample_input in sample_inputs_unique(*args, **kwargs):
        # 如果不要求有序，从 kwargs 中移除 sorted 键
        if not sample_input.kwargs["sorted"]:
            sample_input.kwargs.pop("sorted")
            yield sample_input

def sample_inputs_adaptive_avg_pool1d(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了 make_tensor 的函数，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 按照 (输入形状, 输出大小) 的顺序定义测试案例
    cases = (
        ((0, 8, 8), (5,)),
        ((3, 8, 8), 5),
        ((3, 8, 8), 1)
    )

    # 遍历每个测试案例
    for input_shape, output_size in cases:
        # 批处理情况下的测试样本
        yield SampleInput(make_arg(input_shape), args=(output_size,))
        # 非批处理情况下的测试样本
        yield SampleInput(make_arg(input_shape[1:]), args=(output_size,))


def error_inputs_adaptive_avg_pool1d(opinfo, device, **kwargs):
    # 创建一个部分应用了 make_tensor 的函数，用于生成浮点数张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 空输出的错误输入
    yield ErrorInput(SampleInput(make_arg((1, 2, 3)), output_size=()),
                     error_regex="'output_size' should contain one int")

    # 输出大小小于 0 的错误输入
    # 使用生成器函数 yield 返回一个 ErrorInput 对象
    # ErrorInput 对象的构造函数接受 SampleInput 和 error_regex 参数
    # SampleInput 构造函数的 make_arg 方法返回一个包含元组 (1, 1, 1) 的参数
    yield ErrorInput(SampleInput(make_arg((1, 1, 1)), output_size=(-1,)),
                     error_regex="elements of output_size must be greater than or equal to 0")
def sample_inputs_adaptive_avg_pool2d(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用make_tensor函数，固定设备、数据类型和梯度要求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义测试用例，每个元组包含输入形状和输出大小
    cases = (
        ((1, 8, 8, 8), (5, 7)),      # 输入形状为(1, 8, 8, 8)，输出大小为(5, 7)
        ((2, 8, 8, 8), (None, 7)),   # 输入形状为(2, 8, 8, 8)，输出大小为(None, 7)
        ((1, 8, 4, 3), (5, None)),   # 输入形状为(1, 8, 4, 3)，输出大小为(5, None)
        ((1, 8, 4, 3), (None, None)),# 输入形状为(1, 8, 4, 3)，输出大小为(None, None)
        ((1, 8, 4, 3), (5)),         # 输入形状为(1, 8, 4, 3)，输出大小为(5)
    )

    for input_shape, output_size in cases:
        # 批量处理的情况
        yield SampleInput(make_arg(input_shape), args=(output_size,))
        # 非批量处理的情况
        yield SampleInput(make_arg(input_shape[1:]), args=(output_size,))


def error_inputs_adaptive_avg_pool2d(opinfo, device, **kwargs):
    # 部分应用make_tensor函数，固定设备为给定设备，数据类型为32位浮点数
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 错误的输入维度情况
    yield ErrorInput(SampleInput(make_arg((2, 2)), output_size=(2, 2)),
                     error_type=ValueError, error_regex="Input dimension should be at least 3")

    # 空输出的错误情况
    yield ErrorInput(SampleInput(make_arg((1, 2, 3, 4)), output_size=()),
                     error_regex="output_size must be 2")

    # 输出大小小于0的错误情况
    yield ErrorInput(SampleInput(make_arg((1, 1, 1, 1)), output_size=(-1, 0)),
                     error_regex="elements of output_size must be greater than or equal to 0")


def sample_inputs_adaptive_avg_pool3d(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用make_tensor函数，固定设备、数据类型和梯度要求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义测试用例，每个元组包含输入形状和输出大小
    cases = (
        ((0, 8, 8, 8, 8), (5, 7, 4)),          # 输入形状为(0, 8, 8, 8, 8)，输出大小为(5, 7, 4)
        ((1, 8, 4, 3, 7), (None, None, None)),# 输入形状为(1, 8, 4, 3, 7)，输出大小为(None, None, None)
        ((1, 8, 4, 3, 7), (1, 1, 1)),         # 输入形状为(1, 8, 4, 3, 7)，输出大小为(1, 1, 1)
        ((3, 3, 8, 8, 6), (5, 7, None)),      # 输入形状为(3, 3, 8, 8, 6)，输出大小为(5, 7, None)
        ((1, 3, 8, 8, 6), (5, None, 2)),      # 输入形状为(1, 3, 8, 8, 6)，输出大小为(5, None, 2)
        ((3, 3, 8, 8, 6), (None, 3, 2)),      # 输入形状为(3, 3, 8, 8, 6)，输出大小为(None, 3, 2)
    )

    for input_shape, output_size in cases:
        # 批量处理的情况
        yield SampleInput(make_arg(input_shape), args=(output_size,))
        # 非批量处理的情况
        yield SampleInput(make_arg(input_shape[1:]), args=(output_size,))


def error_inputs_adaptive_avg_pool3d(opinfo, device, **kwargs):
    # 部分应用make_tensor函数，固定设备为给定设备，数据类型为32位浮点数
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 错误的输入维度情况
    yield ErrorInput(SampleInput(make_arg((2, 2, 2)), output_size=(2, 2, 2)),
                     error_type=ValueError, error_regex="Input dimension should be at least 4")

    # 空输出的错误情况
    yield ErrorInput(SampleInput(make_arg((1, 2, 3, 4)), output_size=()),
                     error_regex="output_size must be 3")

    # 输出大小小于0的错误情况
    yield ErrorInput(SampleInput(make_arg((1, 1, 1, 1, 1)), output_size=(-1, 0, 2)),
                     error_regex="elements of output_size must be greater than or equal to 0")
    # 创建一个部分应用了 make_tensor 函数的函数 make_arg，固定了部分参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义测试用例
    cases = (
        # 第一个测试案例：输入形状为 (0, 8, 8)，期望输出大小为 5
        # 由于批处理大小为 0，无法将包含 0 个元素的张量重塑为形状 [0, 8, -1]
        ((0, 8, 8), (5,)),
        # 第二个测试案例：输入形状为 (3, 4, 4)，期望输出大小为 3
        ((3, 4, 4), 3),
        # 第三个测试案例：输入形状为 (3, 4, 4)，期望输出大小为 1
        ((3, 4, 4), 1)
    )

    # 对于每个形状组合和返回索引的情况，生成样本输入
    for shapes, return_idx in product(cases, (True, False)):
        # 对于批处理的情况，生成样本输入
        yield SampleInput(make_arg(shapes[0]), args=(shapes[1], return_idx))
        # 对于非批处理的情况，生成样本输入
        yield SampleInput(make_arg(shapes[0][1:]), args=(shapes[1], return_idx))
# 定义一个函数，生成适用于adaptive_max_pool1d函数的错误输入
def error_inputs_adaptive_max_pool1d(opinfo, device, **kwargs):
    # 创建一个部分函数，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 生成一个空输出的错误输入
    yield ErrorInput(SampleInput(make_arg((1, 2, 3)), output_size=()),
                     error_regex="'output_size' should contain one int")

    # 生成一个输出大小小于0的错误输入
    yield ErrorInput(SampleInput(make_arg((1, 1, 1)), output_size=(-1,)),
                     error_regex="Trying to create tensor with negative dimension")

# 定义一个函数，生成适用于adaptive_max_pool2d函数的示例输入
def sample_inputs_adaptive_max_pool2d(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分函数，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同情况下的输入形状和输出大小
    cases = (
        ((1, 4, 4, 4), (2, 3)),
        ((2, 4, 4, 4), (None, 3)),
        ((2, 4, 4, 4), (1, 1)),
        ((1, 4, 4, 3), (3, None)),
        ((1, 4, 4, 3), (None, None)),
        ((1, 4, 4, 3), (3)),
    )

    # 遍历不同情况，生成示例输入
    for shapes, return_idx in product(cases, (True, False)):
        # 批处理
        yield SampleInput(make_arg(shapes[0]), args=(shapes[1], return_idx))
        # 非批处理
        yield SampleInput(make_arg(shapes[0][1:]), args=(shapes[1], return_idx))

# 定义一个函数，生成适用于adaptive_max_pool2d函数的错误输入
def error_inputs_adaptive_max_pool2d(opinfo, device, **kwargs):
    # 创建一个部分函数，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 生成输入维度不正确的错误输入
    yield ErrorInput(SampleInput(make_arg((2, 2)), output_size=(2, 2)),
                     error_type=ValueError, error_regex="Input dimension should be at least 3")

    # 生成一个空输出的错误输入
    yield ErrorInput(SampleInput(make_arg((1, 2, 3, 4)), output_size=()),
                     error_regex="internal error")

    # 生成一个输出大小小于0的错误输入
    yield ErrorInput(SampleInput(make_arg((1, 1, 1, 1)), output_size=(-1, 0)),
                     error_regex="Trying to create tensor with negative dimension")

# 定义一个函数，生成适用于adaptive_max_pool3d函数的示例输入
def sample_inputs_adaptive_max_pool3d(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分函数，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同情况下的输入形状和输出大小
    cases = (
        ((1, 4, 4, 3, 5), (None, None, None)),
        ((1, 4, 4, 3, 5), (1, 1, 1)),
        ((3, 3, 4, 4, 6), (2, 3, None)),
        ((1, 3, 4, 4, 6), (3, None, 2)),
        ((3, 3, 4, 4, 6), (None, 3, 2)),
    )

    # 遍历不同情况，生成示例输入
    for shapes, return_idx in product(cases, (True, False)):
        # 批处理
        yield SampleInput(make_arg(shapes[0]), args=(shapes[1], return_idx))
        # 非批处理
        yield SampleInput(make_arg(shapes[0][1:]), args=(shapes[1], return_idx))
# 定义一个生成器函数，生成适合于错误输入的 SampleInput 对象
def error_inputs_adaptive_max_pool3d(opinfo, device, **kwargs):
    # 使用偏函数 make_arg 创建张量，并设置设备和数据类型
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 生成错误输入：当输入维度不正确时抛出 ValueError 异常，异常信息中包含 "Input dimension should be at least 4"
    yield ErrorInput(SampleInput(make_arg((2, 2, 2)), output_size=(2, 2, 2)),
                     error_type=ValueError, error_regex="Input dimension should be at least 4")

    # 生成错误输入：当输出尺寸为空时抛出异常，异常信息中包含 "internal error"
    yield ErrorInput(SampleInput(make_arg((1, 2, 3, 4)), output_size=()),
                     error_regex="internal error")

    # 生成错误输入：当输出尺寸中存在小于零的维度时抛出异常，异常信息中包含 "Trying to create tensor with negative dimension"
    yield ErrorInput(SampleInput(make_arg((1, 1, 1, 1, 1)), output_size=(-1, 0, 2)),
                     error_regex="Trying to create tensor with negative dimension")


class _TestParamsMaxPoolBase:

    def __init__(self):
        # 初始化参数字典 kwargs，包括池化操作的各种参数选择
        self.kwargs = {
            'kernel_size': [3],
            'stride': [2, None],
            'ceil_mode': [True, False],
            'padding': [0, 1],
            'dilation': [1],
            'return_indices': [True, False]
        }

        # 初始化形状列表 shapes，包括池化操作可能的输入形状维度组合
        self.shapes = [
            [1, 2, None],  # batch
            [2],  # channels
            [3, 6]  # signal
        ]

    # 生成形状参数的组合迭代器
    def _gen_shape(self):
        for shape in product(*self.shapes):
            # 如果 shape[0] 为 None，表示缺少批处理维度，因此将其忽略
            if shape[0] is None:
                shape = shape[1:]
            
            # 生成包含 shape 和内存格式 torch.contiguous_format 的元组
            yield shape, torch.contiguous_format
            
            # 如果 shapes 列表包含四个元素且 shape 的长度为 4，则支持 channels_last 内存格式
            if len(self.shapes) == 4 and len(shape) == 4:
                yield shape, torch.channels_last

    # 生成参数 kwargs 的组合迭代器
    def _gen_kwargs(self):
        keys = self.kwargs.keys()
        for values in product(*self.kwargs.values()):
            yield dict(zip(keys, values))

    # 生成输入参数的组合迭代器
    def gen_input_params(self):
        yield from product(self._gen_shape(), self._gen_kwargs())


class _TestParamsMaxPool1d(_TestParamsMaxPoolBase):

    def __init__(self):
        super().__init__()
        # 扩展 kernel_size、stride、padding 和 dilation 参数的选择
        self.kwargs['kernel_size'] += [(3,)]
        self.kwargs['stride'] += [(2,)]
        self.kwargs['padding'] += [(1,)]
        self.kwargs['dilation'] += [(1,)]


class _TestParamsMaxPool2d(_TestParamsMaxPoolBase):

    def __init__(self):
        super().__init__()
        # 扩展 kernel_size、stride、padding 和 dilation 参数的选择
        self.kwargs['kernel_size'] += [(3, 2)]
        self.kwargs['stride'] += [(2, 1)]
        self.kwargs['padding'] += [(1, 1)]
        self.kwargs['dilation'] += [(1, 2)]

        # 添加一个额外的维度组合到 shapes 列表
        self.shapes.append([6])


class _TestParamsMaxPool3d(_TestParamsMaxPoolBase):

    def __init__(self):
        super().__init__()
        # 扩展 kernel_size 和 stride 参数的选择，同时添加 dilation 参数的选择
        self.kwargs['kernel_size'] += [(3, 2, 3)]
        self.kwargs['stride'] += [(2, 1, 2)]
        self.kwargs['dilation'] += [(1, 2, 1)]

        # 添加两个额外的维度组合到 shapes 列表
        self.shapes.append([6])
        self.shapes.append([5])


def sample_inputs_max_pool(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数 make_arg 创建张量，并设置设备、数据类型和梯度是否需要计算
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)
    # 定义一个字典，将函数名映射到相应的参数生成器类
    params_generator_type_dict = {
        'nn.functional.max_pool1d': _TestParamsMaxPool1d,
        'nn.functional.max_pool2d': _TestParamsMaxPool2d,
        'nn.functional.max_pool3d': _TestParamsMaxPool3d,
        'max_pool2d_with_indices_backward': _TestParamsMaxPool2d,
    }
    
    # 根据操作信息的名称从字典中选择对应的参数生成器类，并实例化一个对象
    params_generator = params_generator_type_dict[op_info.name]()
    
    # 使用参数生成器对象生成输入参数的形状和内存格式，并遍历生成器的结果
    for (shape, memory_format), kwargs in params_generator.gen_input_params():
        # 创建一个张量参数，设置形状和内存格式，需要梯度的话设置requires_grad为True
        arg = make_arg(shape).to(memory_format=memory_format).requires_grad_(requires_grad)
        # 生成一个SampleInput对象，将参数和额外的关键字参数传递给kwargs
        yield SampleInput(arg, kwargs=kwargs)
# 定义函数，用于计算 2D 最大池化操作的反向传播
def max_pool2d_backward(*args, kernel_size=(), stride=(), padding=(0,), dilation=(1,), ceil_mode=False, **kwargs):
    # 调用 PyTorch 中的 max_pool2d_with_indices 函数进行 2D 最大池化操作，并返回池化结果和索引
    out, indices = torch.nn.functional.max_pool2d_with_indices(
        *args, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, ceil_mode=ceil_mode, return_indices=True)
    # 创建一个和 out 相同形状的张量，用于表示梯度，默认为全 1
    grad_out = torch.ones_like(out)
    # 如果未指定 stride，则将其设置为 kernel_size，用于后续计算
    if stride is None:
        stride = kernel_size
    # 调用 Torch 内部的 max_pool2d_with_indices_backward 函数，计算 2D 最大池化的反向传播结果
    out_b = torch.ops.aten.max_pool2d_with_indices_backward.default(
        grad_out, *args, kernel_size, stride, padding, dilation, ceil_mode, indices)
    # 返回计算得到的反向传播结果
    return out_b

# 定义函数，生成用于测试 max_pool1d 函数错误输入的样例
def error_inputs_max_pool1d(op_info, device, **kwargs):
    # 设定生成张量的函数，部分参数固定，例如数据类型、是否需要梯度等
    make_arg = partial(make_tensor, device=device, dtype=torch.float, requires_grad=False)
    # 错误情况：当 padding 为负数时的测试样例
    x = make_arg((0, 1, 49))
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': -1, 'return_indices': True}),
                     error_regex='pad must be non-negative')
    # 错误情况：当 kernel_size 是二维时的测试样例
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2), 'stride': 50, 'padding': -1, 'return_indices': True}),
                     error_regex='pad must be non-negative')

    # 错误情况：当 pad 大于 kernel_size 的一半时，kernel_size 为整数的情况
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': 4, 'return_indices': True}),
                     error_regex='pad should be at most half of effective kernel size')

    # 错误情况：当 pad 大于 kernel_size 的一半时，kernel_size 为元组的情况
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2), 'stride': 50, 'padding': 4, 'return_indices': True}),
                     error_regex='pad should be at most half of effective kernel size')

    # 错误情况：输入张量为未批处理的 3D 张量，其中至少一个维度为零
    err_msg = r'Expected 3D or 4D \(batch mode\) tensor with optional 0 dim batch size for input'
    yield ErrorInput(SampleInput(make_arg((1, 0, 10)),
                                 kwargs={'kernel_size': 1}),
                     error_regex=err_msg)

    # 错误情况：输入张量为批处理的 4D 张量，其中至少一个维度为零
    yield ErrorInput(SampleInput(make_arg((2, 1, 10, 0)),
                                 kwargs={'kernel_size': 1}),
                     error_regex=err_msg)


# 定义函数，生成用于测试 max_pool3d 函数错误输入的样例
def error_inputs_max_pool3d(op_info, device, **kwargs):
    # 设定生成张量的函数，部分参数固定，例如数据类型、是否需要梯度等
    make_arg = partial(make_tensor, device=device, dtype=torch.float, requires_grad=False)
    # 错误情况：当 padding 为负数时的测试样例
    x = make_arg((0, 1, 49, 50))
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': -1, 'return_indices': True}),
                     error_regex='pad must be non-negative')
    # 错误情况：当 kernel_size 是三维时的测试样例
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': -1, 'return_indices': True}),
                     error_regex='pad must be non-negative')
    # 生成一个错误输入，示例包括样本输入 `x` 和指定的参数字典
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2, 2), 'stride': 50,
                                            'padding': -1, 'return_indices': True}),
                     error_regex='pad must be non-negative')

    # 生成一个错误输入，示例包括样本输入 `x` 和指定的参数字典，当 pad > kernel_size / 2 (kernel_size 为整数) 时出错
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': 4, 'return_indices': True}),
                     error_regex='pad should be at most half of effective kernel size')

    # 生成一个错误输入，示例包括样本输入 `x` 和指定的参数字典，当 pad > kernel_size / 2 (kernel_size 为元组) 时出错
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2, 2), 'stride': 50,
                                            'padding': 4, 'return_indices': True}),
                     error_regex='pad should be at most half of effective kernel size')

    # 生成一个错误输入，示例包括一个大小为 (0, 1, 2, 10) 的参数，期望输入的非批处理维度具有正长度
    err_msg = r'Expected input\'s non-batch dimensions to have positive length'
    yield ErrorInput(SampleInput(make_arg((0, 1, 2, 10)),
                                 kwargs={'kernel_size': 1}),
                     error_regex=err_msg)

    # 生成一个错误输入，示例包括一个大小为 (2, 1, 0, 1, 2) 的参数，期望输入的非批处理维度具有正长度
    yield ErrorInput(SampleInput(make_arg((2, 1, 0, 1, 2)),
                                 kwargs={'kernel_size': 1}),
                     error_regex=err_msg)
# 根据给定的设备、数据类型、梯度需求等参数，生成一个部分应用了make_tensor函数的函数make_arg
make_arg = partial(make_tensor, low=-1, high=1, device=device, dtype=dtype, requires_grad=requires_grad)

cases: Tuple[Tuple[int], dict] = (  # type: ignore[assignment]
                                 # 定义多个输入形状和关键字参数的元组，用于测试
                                 ((2, 1, 4, 5), {'p': 1., 'dim': 2}),
                                 ((2, 3, 4, 5), {'p': 2., 'dim': 1}),
                                 ((1, 2, 4, 5), {'p': 0.5, 'dim': 0}),
                                 ((1, 3, 4, 5), {'p': -1., 'dim': 1}),
                                 ((1, 3, 4, 5), {'p': 0., 'dim': -1}),
                                 ((), {'p': 1.2, 'dim': 0}),
                                 ((2, 3, 4, 5), {}),
                                 ((2, 3, 4, 5), {'eps': 1e-4}))

for input_shape, kwargs in cases:
    # 使用make_arg函数生成输入张量，并将kwargs作为附加参数传递给SampleInput类的实例化
    yield SampleInput(make_arg(input_shape), kwargs=kwargs)


def complex_conv(fn, input_size, weight, grad_output, stride, padding, dilation, groups):
    # 复杂卷积运算的实现，基于公式 conv(W, x, b) = conv(Wr, xr, br) - conv(Wi, xi, 0) + i(conv(Wi, xr, bi) + conv(Wr, xi, 0))

    # 将梯度输出张量视为实部和虚部
    grad_output_ = torch.view_as_real(grad_output)
    grad_output_r = grad_output_[..., 0]
    grad_output_i = grad_output_[..., 1]

    # 将权重张量视为实部和虚部
    weight_ = torch.view_as_real(weight)
    weight_r = weight_[..., 0]
    weight_i = weight_[..., 1]

    # 计算复杂卷积的各个部分
    a = fn(input_size, weight_r, grad_output_r, stride, padding, dilation, groups)
    b = fn(input_size, weight_i, grad_output_i, stride, padding, dilation, groups)
    c = fn(input_size, weight_r + weight_i, grad_output_r + grad_output_i, stride, padding, dilation, groups)

    # 返回复杂卷积的结果
    return (a - b) + 1j * (c - a - b)


def conv_transpose_ref(input, weight, bias, stride=1, padding=0,
                       output_padding=0, dilation=1, groups=1,
                       fn=None):
    # `conv`的导数是`conv_transpose`。
    # 为了验证`conv_transpose`的正确性，我们依赖`torch.nn.grad`的实现（已在test_nn.py中测试过）来处理浮点数数据类型。

    assert fn is not None

    # 映射不同的conv_transpose函数到对应的grad函数
    grad_fn_map = {torch.nn.functional.conv_transpose1d: torch.nn.grad.conv1d_input,
                   torch.nn.functional.conv_transpose2d: torch.nn.grad.conv2d_input,
                   torch.nn.functional.conv_transpose3d: torch.nn.grad.conv3d_input}
    
    # 映射不同维度的conv_transpose函数到批次维度
    batched_dim_map = {torch.nn.functional.conv_transpose1d: 3,
                       torch.nn.functional.conv_transpose2d: 4,
                       torch.nn.functional.conv_transpose3d: 5}

    # 将输入和权重从ndarray转换为Tensor
    input, weight = torch.from_numpy(input), torch.from_numpy(weight)

    # 检查输入是否为批次输入
    is_batched = len(input.shape) == batched_dim_map[fn]
    if not is_batched:
        input = input.unsqueeze(0)
    # 如果给定了偏置项，将其转换为 PyTorch 张量
    if bias is not None:
        bias = torch.from_numpy(bias)
        # 确定需要插入的维度数，与输入张量维度相关
        unsqueeze_dims = input.ndim - 2
        for _ in range(unsqueeze_dims):
            bias = bias.unsqueeze(1)

    # 梯度输出与输入相同
    grad_output = input
    # 使用指定的转置卷积函数计算输出
    # 将输入、权重和其他参数传递给该函数
    conv_transpose_output = fn(grad_output.to('meta'), weight.to('meta'), None,
                               stride=stride, padding=padding, output_padding=output_padding,
                               groups=groups, dilation=dilation)
    # 获取转置卷积输出的形状
    input_size = conv_transpose_output.shape

    # 根据函数映射获取梯度函数
    grad_fn = grad_fn_map[fn]
    # 如果权重数据类型是复数
    if weight.dtype.is_complex:
        # 调用复数卷积函数计算输出
        out = complex_conv(grad_fn, input_size, weight, grad_output, stride, padding, dilation, groups)
    else:  # 浮点数类型
        # 调用普通卷积函数计算输出
        out = grad_fn(input_size, weight, grad_output, stride, padding, dilation, groups)

    # 如果存在偏置项，将其加到输出上
    if bias is not None:
        out = out + bias

    # 如果未进行批处理，则压缩第一个维度并返回输出
    return out.squeeze(0) if not is_batched else out
def sample_inputs_conv_transpose1d(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个函数 make_arg，用于生成张量，固定设备、数据类型和是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同情况下的输入形状、权重、偏置以及参数字典
    # 元组中包含输入形状、权重形状、偏置形状，和一个参数字典，包含 (步长、填充、输出填充、分组、扩展) 的数值
    cases: Tuple[Tuple[int], Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 3, 4), (3, 3, 3), (3,),
         {'stride': (2,), 'padding': 2, 'output_padding': (1,), 'groups': 1}),
        ((2, 2, 4), (2, 2, 4), (4,),
         {'stride': (3,), 'padding': (1,), 'output_padding': (2,), 'groups': 2, 'dilation': (4,)}),
        ((1, 1, 4), (1, 1, 4), (1,),
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1, 'dilation': (2,)}),
        ((1, 1, 4), (1, 2, 3), None,
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1}),
        ((1, 4, 5), (4, 8, 3), None,
         {})
    )

    # 遍历每个情况
    for input_shape, weight, bias, kwargs in cases:
        # 对于批量的情况，生成 SampleInput 对象，其中包含输入张量、权重和可能的偏置
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        # 对于非批量的情况，生成 SampleInput 对象，输入张量的形状为去除第一个维度后的形状
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)


def sample_inputs_conv_transpose2d(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个函数 make_arg，用于生成张量，固定设备、数据类型和是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同情况下的输入形状、权重、偏置以及参数字典
    # 元组中包含输入形状、权重形状、偏置形状，和一个参数字典，包含 (步长、填充、输出填充、分组、扩展) 的数值
    cases: Tuple[Tuple[int], Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 3, 4, 4), (3, 3, 3, 3), (3,),
         {'stride': (2, 2), 'padding': 2, 'output_padding': (1, 1), 'groups': 1}),
        ((2, 2, 4, 4), (2, 2, 4, 5), (4,),
         {'stride': (3, 2), 'padding': (1, 2), 'output_padding': (2, 3), 'groups': 2, 'dilation': (4, 4)}),
        ((1, 1, 4, 5), (1, 1, 4, 3), (1,),
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1, 'dilation': (2, 3)}),
        ((1, 1, 4, 3), (1, 2, 3, 4), None,
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1}),
        ((2, 4, 4, 4), (4, 1, 3, 3), None, {'groups': 4}),
        ((1, 2, 5, 5), (2, 4, 3, 3), None, {})
    )

    # 遍历每个情况
    for input_shape, weight, bias, kwargs in cases:
        # 对于批量的情况，生成 SampleInput 对象，其中包含输入张量、权重和可能的偏置
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        # 对于非批量的情况，生成 SampleInput 对象，输入张量的形状为去除第一个维度后的形状
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
    # 使用偏函数 `partial` 创建 `make_tensor` 函数的新版本 `make_arg`，
    # 并指定默认的设备、数据类型、是否需要梯度。
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义了一组测试用例 `cases`，每个测试用例是一个元组，包含输入形状、权重、偏置和参数字典。
    # 每个元组的结构是 ((输入形状), (权重), (偏置), {参数字典})
    cases: Tuple[Tuple[int], Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 3, 4, 4, 4), (3, 3, 3, 3, 3), (3,),
         {'stride': (2, 2, 2), 'padding': 2, 'output_padding': (1, 1, 1), 'groups': 1}),
        ((2, 2, 4, 4, 4), (2, 2, 4, 5, 6), (4,),
         {'stride': (3, 2, 1), 'padding': (1, 2, 3), 'output_padding': (2, 3, 1), 'groups': 2, 'dilation': (4, 4, 4)}),
        ((1, 1, 4, 5, 2), (1, 1, 4, 3, 1), (1,),
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1, 'dilation': (2, 3, 2)}),
        ((1, 1, 4, 3, 4), (1, 2, 3, 4, 5), None,
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1}),
        ((1, 4, 5, 5, 5), (4, 8, 3, 3, 3), None,
         {})
    )

    # 遍历每个测试用例，生成对应的 `SampleInput` 对象
    for input_shape, weight, bias, kwargs in cases:
        # 对于批处理数据的情况，使用 `make_arg` 函数创建输入、权重和偏置的张量，
        # 并生成对应的 `SampleInput` 对象，传入参数字典 `kwargs`。
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        
        # 对于未经批处理的数据，从输入形状中排除批处理维度后创建张量，
        # 同样生成对应的 `SampleInput` 对象，传入参数字典 `kwargs`。
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
# 定义一个函数用于生成 Conv1d 操作的示例输入数据
def sample_inputs_conv1d(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数 make_arg，用于根据给定的设备、数据类型和梯度需求生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义多个示例输入的形状，权重，偏置和额外参数的元组列表
    cases: Tuple = (
        ((1, 3, 4), (3, 3, 3), (3,), {'stride': (2,), 'padding': 2, 'groups': 1}),
        ((2, 4, 8), (2, 2, 3), (2,), {'stride': 3, 'padding': 1, 'groups': 2, 'dilation': 2}),
        ((1, 4, 5), (1, 4, 3), None, {'stride': (2,), 'padding': 'valid'}),
        ((2, 2, 4), (2, 1, 4), (2,), {'stride': (1,), 'padding': 'same', 'groups': 2, 'dilation': (2,)}),
        # 使用默认值
        ((1, 4, 5), (3, 4, 3), None, {}),
    )

    # 遍历每个示例输入，并生成 SampleInput 对象
    for input_shape, weight, bias, kwargs in cases:
        # 对于批处理数据
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        # 对于非批处理数据
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)


# 定义一个函数用于生成 Conv1d 操作的错误输入数据
def error_inputs_conv1d(opinfo, device, **kwargs):
    # 创建偏函数 make_arg，用于生成特定设备和数据类型的张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float64)
    make_int_arg = partial(make_tensor, device=device, dtype=torch.int64)
    make_complex_arg = partial(make_tensor, device=device, dtype=torch.complex128)

    # 不同数据类型的输入张量和偏置的错误输入
    yield ErrorInput(
        SampleInput(make_int_arg((1, 1, 4)), args=(make_int_arg((1, 1, 2)), make_arg((1,)))),
        error_regex="should be the same")

    # 不同数据类型的输入张量和偏置的错误输入
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 1, 2)), make_complex_arg((1,)))),
        error_regex="should be the same")

    # 负步长的错误输入
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 2, 2)), make_arg((1,))),
                    kwargs={'stride': (-1,)}), error_regex="non-positive stride is not supported")

    # 负填充值的错误输入
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 2, 2)), make_arg((1,))),
                    kwargs={'padding': (-1,)}), error_regex="negative padding is not supported")

    # 负扩张率的错误输入
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 1, 2)), make_arg((1,))),
                    kwargs={'dilation': (-1,)}), error_regex="dilation should be greater than zero")

    # FIXME: https://github.com/pytorch/pytorch/issues/85656
    # 偏置形状与输出通道数不相等的错误输入
    # yield ErrorInput(SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 1, 3)), make_arg((2,)))),
    #                  error_regex="expected bias to be 1-dimensional with 1 elements")
    # 输入的错误情况，因为输入的张量维度与权重张量维度不匹配
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 2)), make_arg((1,)))),
                     error_regex="weight should have at least three dimensions")

    # 输入的错误情况，因为权重张量的第一个维度小于组数
    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4)), args=(make_arg((2, 2, 2)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': 3}), error_regex="expected weight to be at least 3 at dimension 0")

    # 输入的错误情况，因为权重张量的第一个维度小于组数
    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4)), args=(make_arg((2, 2, 2)), make_arg((2,))),
                    kwargs={'groups': 3}), error_regex="expected weight to be at least 3 at dimension 0")

    # 输入的错误情况，因为组数设置为无效值（负数）
    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4)), args=(make_arg((2, 2, 2)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': -1}), error_regex="non-positive groups is not supported")

    # 输入的错误情况，因为组数设置为无效值（零）
    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4)), args=(make_arg((2, 2, 2)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': 0}), error_regex="non-positive groups is not supported")
# 定义一个函数用于生成错误输入样例，用于测试 Conv2D 操作的异常情况
def error_inputs_conv2d(opinfo, device, **kwargs):
    # 使用偏函数 partial 创建不同数据类型和设备的张量生成函数
    make_arg = partial(make_tensor, device=device, dtype=torch.float64)
    make_int_arg = partial(make_tensor, device=device, dtype=torch.int64)
    make_complex_arg = partial(make_tensor, device=device, dtype=torch.complex128)

    # 返回一个错误输入样例，测试整数类型输入张量和偏置的情况
    yield ErrorInput(
        SampleInput(make_int_arg((2, 4, 4)), args=(make_int_arg((3, 2, 3, 3)), make_arg((3,)))),
        error_regex="should be the same")

    # 返回一个错误输入样例，测试不同数据类型输入张量和复数类型偏置的情况
    yield ErrorInput(
        SampleInput(make_arg((2, 4, 4)), args=(make_arg((3, 2, 3, 3)), make_complex_arg((3,)))),
        error_regex="should be the same")

    # 返回一个错误输入样例，测试负步长的情况
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4)), args=(make_arg((1, 2, 2, 3)), make_arg((1,))),
                    kwargs={'stride': (-1,)}), error_regex="non-positive stride is not supported")

    # 返回一个错误输入样例，测试负填充的情况
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 3)), args=(make_arg((1, 2, 2, 4)), make_arg((1,))),
                    kwargs={'padding': (-1,)}), error_regex="negative padding is not supported")

    # 返回一个错误输入样例，测试负扩展的情况
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 2)), args=(make_arg((1, 1, 2, 5)), make_arg((1,))),
                    kwargs={'dilation': (-1,)}), error_regex="dilation should be greater than zero")

    # FIXME: https://github.com/pytorch/pytorch/issues/85656
    # 返回一个错误输入样例，测试偏置的形状与输出通道数不相等的情况
    # yield ErrorInput(SampleInput(make_arg((1, 1, 4, 4)), args=(make_arg((1, 1, 3, 2)), make_arg((2,)))),
    #                  error_regex="expected bias to be 1-dimensional with 1 elements")

    # 返回一个错误输入样例，测试输入张量维度与权重张量维度不匹配的情况
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 3)), args=(make_arg((1, 2, 2)), make_arg((1,))),
                    kwargs={'padding': 'same'}), error_regex="Expected 3-dimensional input for 3-dimensional weight")

    # 返回一个错误输入样例，测试权重的第一个维度小于分组数的情况
    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4, 3)), args=(make_arg((2, 2, 1, 3)), make_arg((2,))),
                    kwargs={'groups': 3}), error_regex="expected weight to be at least 3 at dimension 0")

    # 返回一个错误输入样例，测试权重的第一个维度小于分组数且存在相同填充的情况
    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4, 3)), args=(make_arg((2, 2, 1, 3)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': 3}), error_regex="expected weight to be at least 3 at dimension 0")

    # 返回一个错误输入样例，测试无效分组数的情况
    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4, 5)), args=(make_arg((2, 2, 1, 4)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': -1}), error_regex="non-positive groups is not supported")
    # 生成一个 ErrorInput 对象，表示一个错误输入的情况，用于测试
    yield ErrorInput(
        # 创建一个 SampleInput 对象作为 ErrorInput 的参数，包含两个参数和一个关键字参数
        SampleInput(
            # 调用 make_arg 函数创建一个参数元组 (2, 2, 4, 3)
            make_arg((2, 2, 4, 3)),
            # 将第一个参数元组作为第一个参数传入，第二个参数元组 (2,) 作为第二个参数传入
            args=(make_arg((2, 2, 4, 3)), make_arg((2,))),
            # 指定关键字参数 kwargs={'padding': 'same', 'groups': 0}
            kwargs={'padding': 'same', 'groups': 0}
        ),
        # 定义一个错误的正则表达式，用于匹配错误消息
        error_regex="non-positive groups is not supported"
    )
# 定义一个函数，生成 Conv2D 操作的示例输入
def sample_inputs_conv2d(op_info, device, dtype, requires_grad, jit_fail_sample=False, **kwargs):
    # 创建一个偏函数，用于生成张量，参数包括设备、数据类型、是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义多组测试用例，每组包括输入形状、权重、偏置以及额外参数的字典
    cases: Tuple = (
        ((1, 3, 4, 4), (3, 3, 3, 3), (3,), {'stride': (2, 2), 'padding': 2, 'groups': 1}),
        ((2, 4, 8, 8), (2, 2, 3, 3), (2,), {'stride': (3, 2), 'padding': (2, 1), 'groups': 2, 'dilation': (4, 4)}),
        ((1, 4, 5, 5), (1, 4, 2, 3), (1,), {'stride': 2, 'padding': 1, 'groups': 1, 'dilation': (2, 3)}),
        ((1, 4, 5, 5), (1, 4, 2, 3), (1,), {'stride': 2, 'padding': 1, 'groups': 1, 'dilation': (2, 3)}),
        ((1, 2, 4, 3), (4, 2, 3, 4), None, {'stride': 2, 'padding': 1, 'groups': 1}),
        ((1, 4, 5, 5), (1, 4, 2, 3), (1,), {'stride': 2, 'padding': "valid"}),
        ((1, 4, 5, 5), (1, 4, 2, 3), (1,), {'stride': 1, 'padding': "same", 'dilation': 3}),
        ((2, 4, 6, 6), (4, 1, 3, 3), (4,), {'groups': 4}),
        ((2, 4, 6, 6), (8, 1, 3, 3), (8,), {'groups': 4}),
        ((2, 4, 6, 6), (8, 1, 3, 3), None, {'groups': 4}),
        ((2, 4, 6, 6), (4, 1, 3, 3), (4,), {'groups': 4, 'stride': (3, 2)}),
        ((2, 4, 6, 6), (4, 1, 3, 3), (4,), {'groups': 4, 'padding': (1, 1)}),
        ((2, 4, 5, 5), (4, 1, 2, 2), (4,), {'groups': 4, 'dilation': (2, 2)}),
        ((2, 4, 6, 5), (6, 2, 3, 2), (6,), {'groups': 2}),
        ((1, 4, 5, 5), (3, 4, 3, 3), None, {}),
    )

    # 遍历每组测试用例
    for input_shape, weight, bias, kwargs in cases:
        # 对于批处理的情况，生成一个 SampleInput 对象
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        # 对于非批处理的情况，生成一个 SampleInput 对象
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)


# 定义一个函数，生成 Conv3D 操作的示例输入
def sample_inputs_conv3d(opinfo, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数，用于生成张量，参数包括设备、数据类型、是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # Ordered as shapes for input, weight, bias
    # and dict of values of (stride, padding, dilation, groups)
    # 顺序是输入形状、权重、偏置及 (步长、填充、扩展、分组) 的字典值
    cases: Tuple = (
        ((1, 1, 4, 4, 4), (1, 1, 1, 1, 1), (1,), {'padding': 'same'}),
        ((1, 1, 4, 4, 4), (1, 1, 4, 4, 4), (1,), {'stride': (2, 2, 2)}),
        ((1, 1, 5, 5, 5), (1, 1, 3, 3, 3), (1,), {'dilation': 2}),
        ((1, 1, 1, 1, 10), (1, 1, 1, 1, 4), None, {'padding': 'valid'}),
        ((1, 1, 10, 11, 12), (1, 1, 1, 2, 5), None, {'padding': 'same'}),
        ((1, 1, 10, 11, 12), (1, 1, 1, 2, 5), None, {'padding': 'same', 'dilation': 2}),
        ((1, 1, 10, 11, 12), (1, 1, 4, 4, 4), None, {'padding': 'same', 'dilation': 3}),
        ((1, 1, 1, 1, 10), (1, 1, 1, 1, 4), None, {'padding': 'valid'}),
        ((3, 9, 3, 1, 9), (3, 3, 3, 1, 9), (3,), {'groups': 3}),
        ((3, 9, 3, 1, 9), (3, 3, 3, 1, 9), (3,), {'stride': (2, 2, 2), 'dilation': 1, 'groups': 3}),
    )

    # 对每个测试案例生成样本输入
    for input_shape, weight, bias, kwargs in cases:
        # 生成批处理的样本输入
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        # 生成非批处理的样本输入
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
# 定义函数，用于生成错误输入条件下的 Conv3D 操作的测试用例
def error_inputs_conv3d(opinfo, device, **kwargs):
    # 创建部分函数，用于生成特定设备和数据类型的张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float64)
    make_int_arg = partial(make_tensor, device=device, dtype=torch.int64)
    make_complex_arg = partial(make_tensor, device=device, dtype=torch.complex128)

    # 生成测试用例：输入张量和偏置张量的数据类型不匹配
    yield ErrorInput(
        SampleInput(make_int_arg((1, 1, 4, 4, 4)), args=(make_int_arg((1, 1, 2, 2, 2)), make_arg((1,)))),
        error_regex="should be the same")

    # 生成测试用例：输入张量和偏置张量的数据类型不匹配（复数类型）
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 2, 2, 2)), make_complex_arg((1,)))),
        error_regex="should be the same")

    # 生成测试用例：负步长的输入张量
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 2, 2, 2)), make_arg((1,))),
                    kwargs={'stride': (-1,)}), error_regex="non-positive stride is not supported")

    # 生成测试用例：负填充值的输入张量
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 2, 2, 2)), make_arg((1,))),
                    kwargs={'padding': (-1,)}), error_regex="negative padding is not supported")

    # 生成测试用例：负膨胀值的输入张量
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 2, 2, 2)), make_arg((1,))),
                    kwargs={'dilation': (-1,)}), error_regex="dilation should be greater than zero")

    # FIXME: https://github.com/pytorch/pytorch/issues/85656
    # 生成测试用例：偏置张量形状与输出通道数不匹配的情况
    # yield ErrorInput(SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 3, 3, 3)), make_arg((2,)))),
    #                  error_regex="expected bias to be 1-dimensional with 1 elements")

    # 生成测试用例：输入张量的维度与权重张量的维度不匹配
    yield ErrorInput(
        SampleInput(make_arg((1, 1, 3, 4, 5)), args=(make_arg((1, 1, 4, 3)), make_arg((1,))),
                    kwargs={'padding': 'same'}), error_regex="Expected 4-dimensional input for 4-dimensional weight")

    # 生成测试用例：权重张量的第一个维度小于分组数的情况
    yield ErrorInput(
        SampleInput(make_arg((2, 2, 3, 4, 5)), args=(make_arg((2, 2, 4, 3, 3)),
                    make_arg((2,))), kwargs={'groups': 3}),
        error_regex="expected weight to be at least 3 at dimension 0")

    # 生成测试用例：权重张量的第一个维度小于分组数的情况（带有相同填充的情况）
    yield ErrorInput(
        SampleInput(make_arg((2, 2, 3, 4, 5)), args=(make_arg((2, 2, 4, 3, 3)),
                    make_arg((2,))), kwargs={'padding': 'same', 'groups': 3}),
        error_regex="expected weight to be at least 3 at dimension 0")

    # 生成测试用例：无效分组数的情况
    # 生成一个 ErrorInput 对象，用于测试非正 groups 值不支持的情况
    yield ErrorInput(
        # 创建一个 SampleInput 对象，包含输入参数和关键字参数
        SampleInput(make_arg((2, 2, 3, 4, 5)), args=(make_arg((2, 2, 4, 3, 3)),
                    make_arg((2,))), kwargs={'padding': 'same', 'groups': 0}),
        # 指定错误正则表达式，用于匹配错误信息
        error_regex="non-positive groups is not supported")

    # 生成一个 ErrorInput 对象，用于测试在 strided convolutions 情况下不支持 padding='same'
    yield ErrorInput(
        # 创建一个 SampleInput 对象，包含输入参数和关键字参数
        SampleInput(make_arg((18, 27, 9, 1, 9)), args=(make_arg((9, 9, 9, 1, 9)),
                    make_arg((9,))), kwargs={'stride': 2, 'padding': 'same', 'groups': 3}),
        # 指定错误正则表达式，用于匹配错误信息
        error_regex="padding='same' is not supported for strided convolutions")
# 生成带有指定设备、数据类型、是否需要梯度的张量的部分应用函数
def sample_inputs_group_norm(opinfo, device, dtype, requires_grad, **kwargs):
    # 偏函数，用于创建张量，指定设备、数据类型、是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同输入形状、分组数和eps参数的测试用例
    cases: Tuple[Tuple[int], int, float] = (  # type: ignore[assignment]
        ((1, 6, 3), 2, {'eps' : 0.5}),     # 示例1
        ((2, 6, 3), 2, {'eps' : -0.5}),    # 示例2
        ((1, 3), 1, {'eps' : 1e-5}),       # 示例3
        ((0, 2), 1, {'eps' : 1e-5}),       # 示例4
        ((S, S, S), 1, {'eps' : 0.5}),     # 示例5，其中S为未定义的变量
    )

    # 推断通道数为输入形状的第二维度
    for input_shape, num_groups, kwargs in cases:
        # 计算通道数，如果输入形状的长度大于1则为第二维度，否则为0
        channels = input_shape[1] if len(input_shape) > 1 else 0
        # 创建权重张量和偏置张量
        weight_tensor = make_arg(channels)
        bias_tensor = make_arg(channels)

        # 检查权重和偏置的各种组合情况，其中可以有None
        weights = [weight_tensor, None]
        biases = [bias_tensor, None]
        for weight, bias in itertools.product(weights, biases):
            kwargs = {
                'weight': weight,
                'bias': bias,
                **kwargs
            }
            # 生成一个SampleInput对象，包含输入张量、分组数和其他关键字参数
            yield SampleInput(make_arg(input_shape), num_groups, **kwargs)

    # 不带任何可选参数的情况
    yield SampleInput(make_arg((1, 2)), args=(1,))


# 参考输入生成器，继承自sample_inputs_group_norm，参数和功能类似
def reference_inputs_group_norm(op_info, device, dtype, requires_grad, **kwargs):
    # 从sample_inputs_group_norm生成输入
    yield from sample_inputs_group_norm(
        op_info, device, dtype, requires_grad, **kwargs)

    # 再次创建偏函数，用于创建张量，指定设备、数据类型、是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同输入形状、分组数和eps参数的另一组测试用例
    cases: Tuple[Tuple[int], int, float] = (  # type: ignore[assignment]
        ((20, 6, 10, 10), 3, {'eps' : 1e-5}),     # 示例6
        # 等同于InstanceNorm的情况
        ((20, 6, 10, 10), 6, {'eps' : 1e-5}),     # 示例7
        # 等同于LayerNorm的情况
        ((20, 6, 10, 10), 1, {'eps' : 1e-5}),     # 示例8
    )

    # 推断通道数为输入形状的第二维度
    for input_shape, num_groups, kwargs in cases:
        # 计算通道数，如果输入形状的长度大于1则为第二维度，否则为0
        channels = input_shape[1] if len(input_shape) > 1 else 0
        # 创建输入张量、权重张量和偏置张量
        input_tensor = make_arg(input_shape)
        weight_tensor = make_arg(channels)
        bias_tensor = make_arg(channels)

        # 检查权重和偏置的各种组合情况，其中可以有None
        weights = [weight_tensor, None]
        biases = [bias_tensor, None]
        for weight, bias in itertools.product(weights, biases):
            kwargs = {
                'weight': weight,
                'bias': bias,
                **kwargs
            }
            # 生成一个SampleInput对象，包含输入张量、分组数和其他关键字参数
            yield SampleInput(input_tensor, num_groups, **kwargs)
# 定义函数，生成一组标准化层的输入示例
def sample_inputs_instance_norm(opinfo, device, dtype, requires_grad, **kwargs):
    # 创建部分函数make_arg和make_arg_without_requires_grad，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_arg_without_requires_grad = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)

    # 定义不同测试用例的输入形状和附加参数
    cases: Tuple[Tuple[int], dict] = (  # type: ignore[assignment]
        ((S, S, S), {'momentum': 0.5, 'eps': 0.6}),  # 输入形状为(S, S, S)，包含动量和eps参数
        ((S, S, S), {'momentum': 0.5, 'eps': 0.6, 'use_input_stats': True}),  # 输入形状为(S, S, S)，包含动量、eps和use_input_stats参数
        ((3, 2, 4), {'momentum': -1.2}),  # 输入形状为(3, 2, 4)，包含负动量参数
        ((3, 2, 4), {'momentum': 0.0}),  # 输入形状为(3, 2, 4)，包含零动量参数
        ((3, 2, 3, 4), {'momentum': -1.0, 'eps': 0.5}),  # 输入形状为(3, 2, 3, 4)，包含负动量和eps参数
        ((3, 2, 3, 4), {'momentum': -1.0, 'eps': 0.5})  # 输入形状为(3, 2, 3, 4)，包含负动量和eps参数（重复定义）
    )

    # 遍历测试用例
    for input_shape, kwargs in cases:
        # 从输入形状中获取通道数
        channels = input_shape[1]
        # 创建权重和偏置张量，其形状为(通道数,)
        weight = make_arg(channels)
        bias = make_arg(channels)
        # 创建不需要梯度的运行均值和运行方差张量，其形状为(通道数,)
        running_mean = make_arg_without_requires_grad(channels, low=0)
        running_var = make_arg_without_requires_grad(channels, low=0)
        # 更新参数字典，包括运行均值、运行方差、权重和偏置等
        new_kwargs = {
            'running_mean': running_mean,
            'running_var': running_var,
            'weight': weight,
            'bias': bias,
            **kwargs
        }

        # 生成一个样例输入，包括输入形状和新的参数字典
        yield SampleInput(
            make_arg(input_shape),
            args=(),
            kwargs=new_kwargs
        )

    # 检查权重和偏置为None的情况
    # instance_norm假设如果有偏置，则一定有权重
    weights = [channels, None]
    biases = [None, None]

    # 遍历权重和偏置的组合
    for weight_channels, bias_channels in zip(weights, biases):
        # 创建不需要梯度的运行均值和运行方差张量，其形状为(通道数,)
        running_mean = make_arg_without_requires_grad(channels, low=0)
        running_var = make_arg_without_requires_grad(channels, low=0)
        # 生成一个样例输入，包括输入形状和相应的参数字典（包括可能的权重和偏置）
        yield SampleInput(
            make_arg(input_shape),
            args=(),
            kwargs={
                'running_mean': running_mean,
                'running_var': running_var,
                'weight': make_arg(weight_channels) if weight_channels is not None else None,
                'bias': make_arg(bias_channels) if bias_channels is not None else None
            }
        )

    # 测试没有可选参数的情况
    yield SampleInput(make_arg((1, 2, 3)), kwargs={})


def sample_inputs_layer_norm(opinfo, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同测试用例的输入形状、标准化形状和eps参数字典
    cases: Tuple[Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 2, 3), (1, 2, 3), {'eps': 0.5}),  # 输入形状为(1, 2, 3)，标准化形状为(1, 2, 3)，包含eps参数
        ((2, 2, 3), (2, 3), {'eps': -0.5}),  # 输入形状为(2, 2, 3)，标准化形状为(2, 3)，包含负eps参数
        ((1,), (1,), {}),  # 输入形状为(1,)，标准化形状为(1,)，无额外参数
        ((1, 2), (2,), {}),  # 输入形状为(1, 2)，标准化形状为(2,)，无额外参数
        ((0, 1), (1,), {})  # 输入形状为(0, 1)，标准化形状为(1,)，无额外参数
    )
    # 遍历测试用例集合 cases，每个元素包含 input_shape, normalized_shape 和 kwargs
    for input_shape, normalized_shape, kwargs in cases:
        # 创建与 normalized_shape 形状相同的权重和偏置
        weight = make_arg(normalized_shape)
        bias = make_arg(normalized_shape)
        # 生成一个 SampleInput 实例，传入 input_shape 作为第一个参数，args 包括 normalized_shape、weight 和 bias，kwargs 是额外的关键字参数
        yield SampleInput(
            make_arg(input_shape),
            args=(normalized_shape, weight, bias),
            kwargs=kwargs
        )
    
    # 生成一个没有任何可选参数的 SampleInput 实例，传入形状为 (1, 2)
    yield SampleInput(make_arg((1, 2)), args=((2,),))

    # TODO: @krshrimali，一旦 SampleInput 类中的 to_numpy 方法被修改以接受 None 输入，启用以下输入；参考 https://github.com/pytorch/pytorch/pull/63276#discussion_r691950400

    # 使用权重和一个 `None` 偏置
    # yield SampleInput(make_arg((1, 2)), args=((2,), make_arg((2,)), None))

    # 使用 `None` 权重和偏置（这些测试未通过，参考上述链接）
    # yield SampleInput(make_arg((1, 2)), args=((2,), None, make_arg((2,))))
# 定义函数 sample_inputs_native_layer_norm，生成标准化层的示例输入
def sample_inputs_native_layer_norm(opinfo, device, dtype, requires_grad, **kwargs):
    # 使用 make_tensor 函数创建 tensor 的部分应用函数 make_arg
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同输入情况的元组 cases，包括输入形状 input shape、标准化形状 normalized_shape 和 epsilon 值 eps
    cases: Tuple[Tuple[int], Tuple[int], float] = (  # type: ignore[assignment]
        ((1, 2, 3), (1, 2, 3), 0.5),  # 第一种情况
        ((2, 2, 3), (2, 3), -0.5),    # 第二种情况
        ((1,), (1,), 1e-5),          # 第三种情况
        ((1, 2), (2,), 1e-5),         # 第四种情况
        ((0, 1), (1,), 1e-5),         # 第五种情况
    )

    # 遍历每一种情况
    for input_shape, normalized_shape, eps in cases:
        # 根据标准化形状创建权重 weight 和偏置 bias
        weight = make_arg(normalized_shape)
        bias = make_arg(normalized_shape)
        
        # 生成 SampleInput 对象，包含输入数据和参数元组
        yield SampleInput(
            make_arg(input_shape),     # 输入数据
            args=(normalized_shape, weight, bias, eps),  # 参数元组
        )
        yield SampleInput(
            make_arg(input_shape),
            args=(normalized_shape, None, bias, eps),
        )
        yield SampleInput(
            make_arg(input_shape),
            args=(normalized_shape, weight, None, eps),
        )
        yield SampleInput(
            make_arg(input_shape),
            args=(normalized_shape, None, None, eps),
        )

# 定义函数 sample_inputs_rms_norm，生成 RMS 归一化层的示例输入
def sample_inputs_rms_norm(opinfo, device, dtype, requires_grad, **kwargs):
    # 使用 make_tensor 函数创建 tensor 的部分应用函数 make_arg
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同输入情况的元组 cases，包括输入形状 input shape、标准化形状 normalized_shape 和关键字参数字典 kwargs
    cases: Tuple[Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 2, 3), (1, 2, 3), {'eps': 0.5}),  # 第一种情况
        ((2, 2, 3), (2, 3), {'eps': -0.5}),    # 第二种情况
        ((1,), (1,), {}),                     # 第三种情况
        ((1, 2), (2,), {}),                   # 第四种情况
        ((0, 1), (1,), {}),                   # 第五种情况
    )

    # 遍历每一种情况
    for input_shape, normalized_shape, kwargs in cases:
        # 根据标准化形状创建权重 weight
        weight = make_arg(normalized_shape)
        
        # 生成 SampleInput 对象，包含输入数据、参数元组和关键字参数字典
        yield SampleInput(
            make_arg(input_shape),     # 输入数据
            args=(normalized_shape, weight),  # 参数元组
            kwargs=kwargs              # 关键字参数字典
        )
    
    # 生成没有可选参数的示例输入
    yield SampleInput(make_arg((1, 2)), args=((2,),))

# 定义函数 error_inputs_group_norm，生成分组归一化层的错误示例输入
def error_inputs_group_norm(opinfo, device, **kwargs):
    # 使用 make_tensor 函数创建 tensor 的部分应用函数 make_arg
    make_arg = partial(make_tensor, device=device, dtype=torch.float32, requires_grad=False)

    # 检查输入张量的最小维度
    err_msg1 = "Expected at least 2 dimensions for input tensor but received"
    s1 = SampleInput(make_arg(1), args=(1,))
    yield ErrorInput(s1, error_regex=err_msg1)

    # 检查通道维度是否与分组数兼容
    err_msg2 = "Expected number of channels in input to be divisible by num_groups, but got input of shape"
    s2 = SampleInput(make_arg((2, 7, 4)), args=(2,))
    yield ErrorInput(s2, error_regex=err_msg2)

# 定义函数 error_inputs_native_layer_norm，生成标准化层的错误示例输入
def error_inputs_native_layer_norm(opinfo, device, **kwargs):
    # 使用 make_tensor 函数创建 tensor 的部分应用函数 make_arg
    make_arg = partial(make_tensor, device=device, dtype=torch.float32, requires_grad=False)
    
    # 定义输入形状 input_shape
    input_shape = (1, 2, 3)
    # 定义错误消息字符串，指示预期为至少一维的标准化形状
    err_msg1 = "Expected normalized_shape to be at least 1-dimensional"
    # 使用 make_arg 函数创建 SampleInput 对象 s1，传入参数和默认值
    s1 = SampleInput(
        make_arg(input_shape), args=(tuple(), None, None, 1e-5)
    )
    # 生成 ErrorInput 对象，用于检测错误情况 s1，并指定错误消息的正则表达式
    yield ErrorInput(s1, error_regex=err_msg1)

    # 定义标准化形状的元组
    normalized_shape = (1, 2, 3)
    # 使用 make_arg 函数创建权重参数
    weight = make_arg((1, 2))
    # 定义错误消息字符串，指示预期权重与标准化形状具有相同的形状
    err_msg2 = "Expected weight to be of same shape as normalized_shape"
    # 使用 make_arg 函数创建 SampleInput 对象 s2，传入参数和默认值
    s2 = SampleInput(
        make_arg(input_shape), args=(normalized_shape, weight, None, 1e-5)
    )
    # 生成 ErrorInput 对象，用于检测错误情况 s2，并指定错误消息的正则表达式
    yield ErrorInput(s2, error_regex=err_msg2)

    # 使用 make_arg 函数创建偏置参数
    bias = make_arg((1, 2))
    # 定义错误消息字符串，指示预期偏置与标准化形状具有相同的形状
    err_msg3 = "Expected bias to be of same shape as normalized_shape"
    # 使用 make_arg 函数创建 SampleInput 对象 s3，传入参数和默认值
    s3 = SampleInput(
        make_arg(input_shape), args=(normalized_shape, None, bias, 1e-5)
    )
    # 生成 ErrorInput 对象，用于检测错误情况 s3，并指定错误消息的正则表达式
    yield ErrorInput(s3, error_regex=err_msg3)

    # 定义错误消息字符串，指示给定的标准化形状
    err_msg4 = "Given normalized_shape="
    # 使用 make_arg 函数创建 SampleInput 对象 s4，传入参数和默认值
    s4 = SampleInput(
        make_arg((2, 2, 3)), args=((2, 2), None, None, 1e-5)
    )
    # 生成 ErrorInput 对象，用于检测错误情况 s4，并指定错误消息的正则表达式
    yield ErrorInput(s4, error_regex=err_msg4)
def error_inputs_rms_norm(opinfo, device, **kwargs):
    # 创建一个部分应用函数，使用指定的设备、数据类型和梯度设置，生成浮点数张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float32, requires_grad=False)
    # 定义输入形状为 (1, 2, 3)
    input_shape = (1, 2, 3)

    # 错误消息1
    err_msg1 = "Expected normalized_shape to be at least 1-dimensional"
    # 创建第一个样本输入，使用 make_arg 生成的张量，参数为 tuple()、None 和 1e-5
    s1 = SampleInput(
        make_arg(input_shape), args=(tuple(), None, 1e-5)
    )
    # 返回错误输入，期望错误消息匹配 err_msg1
    yield ErrorInput(s1, error_regex=err_msg1)

    # 定义 normalized_shape 和 weight
    normalized_shape = (1, 2, 3)
    weight = make_arg((1, 2))
    # 错误消息2
    err_msg2 = "Expected weight to be of same shape as normalized_shape"
    # 创建第二个样本输入，使用 make_arg 生成的张量，参数为 normalized_shape、weight 和 1e-5
    s2 = SampleInput(
        make_arg(input_shape), args=(normalized_shape, weight, 1e-5)
    )
    # 返回错误输入，期望错误消息匹配 err_msg2
    yield ErrorInput(s2, error_regex=err_msg2)

    # 错误消息4
    err_msg4 = "Given normalized_shape="
    # 创建第四个样本输入，使用 make_arg 生成的张量，参数为 (2, 2, 3)、((2, 2), None 和 1e-5)
    s4 = SampleInput(
        make_arg((2, 2, 3)), args=((2, 2), None, 1e-5)
    )
    # 返回错误输入，期望错误消息匹配 err_msg4
    yield ErrorInput(s4, error_regex=err_msg4)


def sample_inputs_local_response_norm(opinfo, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，使用指定的设备、数据类型和梯度设置，生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同的测试用例，包括输入形状、size 和 kwargs 字典
    cases: Tuple[Tuple[int], Tuple[int], dict] = (
        ((1, 6, 3), 2, {'alpha': 3e-05, 'beta': 0.5, 'k': 1.25}),
        ((1, 6, 3), 2, {'beta': 0.5, 'k': 1.25}),
        ((1, 6, 3), 2, {'alpha': 3e-05, 'k': 1.25}),
        ((1, 6, 3), 2, {'alpha': 3e-05, 'beta': 0.5}),
        ((1, 6, 3), 2, {'alpha': 3e-05}),
        ((1, 6, 3), 2, {'beta': 0.5}),
        ((1, 6, 3), 2, {'k': 1.25}),
        ((1, 6, 3), 2, {}),
        ((2, 6, 3), 2, {'alpha': 3e-05, 'beta': 0.5, 'k': 1.25}),
        ((1, 1, 2), 1, {'alpha': 3e-05, 'beta': 0.5, 'k': 1.25}),
        ((0, 1, 2), 1, {'alpha': 3e-05, 'beta': 0.5, 'k': 1.25}),
    )

    # 遍历测试用例，生成样本输入
    for input_shape, size, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(size,), kwargs=kwargs)


def sample_inputs_hardswish(self, device, dtype, requires_grad, **kwargs):
    N = 5
    # 确保我们测试的范围在 -3 到 3 之间，默认是 -10 到 10，可能是不必要的
    make_arg = partial(make_tensor, device=device, dtype=dtype,
                       requires_grad=requires_grad, low=-5, high=5)
    # 返回生成的张量样本输入，N 次循环
    return (SampleInput(make_arg((N * 2, N * 2))) for _ in range(1, N))


def sample_inputs_linear(self, device, dtype, requires_grad, **kwargs):
    # 不同的特征选项
    features_options = [[3, 4], [8, 8]]
    # 批处理选项列表
    batch_options: List[List[int]] = [
        [],  # 没有批处理
        [0],
        [8],
        [2, 3],
    ]
    # 创建张量的部分应用函数，使用指定的设备、数据类型和梯度设置，生成张量
    create_tensor = partial(make_tensor, device=device, dtype=dtype,
                            requires_grad=requires_grad, low=-2, high=2)
    # 使用 itertools.product 生成器来生成所有可能的组合：
    # - has_bias 可能为 True 或 False
    # - (in_feat, out_feat) 从 features_options 中取得输入特征数和输出特征数
    # - batch_shape 从 batch_options 中取得批量形状
    for has_bias, (in_feat, out_feat), batch_shape in \
            itertools.product([True, False], features_options, batch_options):
        # 创建输入张量，形状为 batch_shape + [in_feat]
        input_tensor = create_tensor(batch_shape + [in_feat])
        # 创建权重张量，形状为 [out_feat, in_feat]
        weight = create_tensor([out_feat, in_feat])
        # 如果没有偏置，生成一个 SampleInput 对象，并继续下一个循环
        if not has_bias:
            yield SampleInput(input_tensor, weight)
            continue
        
        # 如果有偏置，创建偏置张量，形状为 [out_feat]
        bias = create_tensor([out_feat])
        # 生成一个带偏置的 SampleInput 对象
        yield SampleInput(input_tensor, weight, bias)

    # 生成一个特定的样例输入：一个 5 维张量，用于复现 MPS 中的问题
    # 参见 https://github.com/pytorch/pytorch/issues/114942
    yield SampleInput(create_tensor(2, 1, 2, 1, 2), create_tensor(4, 2))
    # 生成一个特定的样例输入：一个 5 维张量，并带有权重和额外的偏置张量
    yield SampleInput(create_tensor(2, 1, 2, 1, 2), create_tensor(4, 2), create_tensor(4))
# 定义一个函数用于生成双线性插值的示例输入数据
def sample_inputs_bilinear(self, device, dtype, requires_grad, **kwargs):
    # 可选的特征维度组合
    features_options = [[3, 4, 5], [8, 8, 8]]
    # 可选的批次形状列表
    batch_options: List[List[int]] = [
        [],     # 无批次
        [0],    # 单个批次
        [8],    # 单个批次
        [2, 3], # 多个批次
    ]
    # 创建张量的部分函数，用于生成张量并设置相关属性
    create_tensor = partial(make_tensor, device=device, dtype=dtype,
                            requires_grad=requires_grad, low=-2, high=2)

    # 使用 itertools.product 生成所有可能的组合
    for has_bias, (in_feat1, in_feat2, out_feat), batch_shape in \
            itertools.product([True, False], features_options, batch_options):
        # 创建输入张量1
        input_tensor1 = create_tensor(batch_shape + [in_feat1])
        # 创建输入张量2
        input_tensor2 = create_tensor(batch_shape + [in_feat2])
        # 创建权重张量
        weight = create_tensor([out_feat, in_feat1, in_feat2])
        # 如果没有偏置，则生成没有偏置的示例输入
        if not has_bias:
            yield SampleInput(input_tensor1, input_tensor2, weight)
            continue
        # 否则，生成带有偏置的示例输入
        bias = create_tensor([out_feat])
        yield SampleInput(input_tensor1, input_tensor2, weight, bias)

# 定义一个函数用于生成门控线性单元（GLU）的示例输入数据
def sample_inputs_glu(self, device, dtype, requires_grad, **kwargs):
    # 可选的特征维度组合
    features_options = [[2], [2, 4], [8, 8], [3, 6, 8], [1, 4, 6, 7]]
    # 可选的批次形状列表
    batch_options: List[List[int]] = [
        [],     # 无批次
        [0],    # 单个批次
        [8],    # 单个批次
        [2, 3], # 多个批次
    ]
    # 创建张量的部分函数，用于生成张量并设置相关属性
    create_tensor = partial(make_tensor, device=device, dtype=dtype,
                            requires_grad=requires_grad, low=-2, high=2)

    # 使用 itertools.product 生成所有可能的组合
    for features, batch_shape in itertools.product(features_options, batch_options):
        # 计算张量的维度数
        ndim = len(features) + len(batch_shape)
        # 遍历维度并创建输入张量
        for dim in range(ndim):
            input_tensor = create_tensor(batch_shape + features)
            dim_size = input_tensor.size(dim)
            # 如果维度大小大于0且是偶数，则生成相应的示例输入
            if dim_size > 0 and dim_size % 2 == 0:
                yield SampleInput(input_tensor, dim)

# 定义一个函数用于生成插值操作的示例输入数据
def sample_inputs_interpolate(mode, self, device, dtype, requires_grad, **kwargs):
    # 定义一些固定的维度参数
    N, C = 2, 3
    D = 4
    S = 3
    L = 5

    # 对齐角落选项，根据插值模式进行设置
    align_corners_options: Tuple[Any, ...] = (None,)
    if mode in ('linear', 'bilinear', 'bicubic', 'trilinear'):
        align_corners_options = (True, False, None)
    
    # 不同插值模式对应的维度列表
    ranks_for_mode = {
        'nearest': [1, 2, 3],
        'nearest-exact': [1, 2, 3],
        'linear': [1],
        'bilinear': [2],
        'bicubic': [2],
        'trilinear': [3],
        'area': [1, 2, 3]
    }

    # 定义一个函数，根据给定的大小、秩和是否包含批次和通道维度来生成形状
    def shape(size, rank, with_batch_channel=True):
        if with_batch_channel:
            return tuple([N, C] + ([size] * rank))
        return tuple([size] * rank)
    # 如果插值模式为 'bilinear' 或 'bicubic'，并且数据类型是 torch.uint8
    if mode in ('bilinear', 'bicubic') and dtype == torch.uint8:
        # 创建 make_tensor 的部分应用函数，设置设备、数据类型、梯度需求
        make_arg = partial(
            make_tensor,
            device=device,
            dtype=dtype,
            requires_grad=requires_grad,
            # 对于 uint8 数据类型，选择更接近典型图像处理使用的上限 256，而不是默认的 10
            high=256 if dtype == torch.uint8 else None,
        )
        # 提供几个样本以更接近典型图像处理的用法
        rank = 2
        # 遍历内存格式选项，如连续存储格式和通道最后存储格式
        for memory_format in [torch.contiguous_format, torch.channels_last]:
            # 生成 SampleInput 对象，包含 make_arg 创建的张量、目标形状、插值模式和其他参数
            yield SampleInput(
                make_arg(shape(270, rank), memory_format=memory_format),
                shape(130, rank, False),
                scale_factor=None,
                mode=mode,
                align_corners=False,
            )

    # 创建 make_tensor 的部分应用函数，设置设备、数据类型、梯度需求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 遍历 align_corners_options 中的对齐角落选项
    for align_corners in align_corners_options:
        # 遍历特定模式下的秩选项
        for rank in ranks_for_mode[mode]:
            # 生成 SampleInput 对象，包含 make_arg 创建的张量、目标形状、插值模式和其他参数
            yield SampleInput(
                make_arg(shape(D, rank)),
                shape(S, rank, False),
                scale_factor=None,
                mode=mode,
                align_corners=align_corners,
            )
            # 生成另一个 SampleInput 对象，包含 make_arg 创建的张量、目标形状、插值模式和其他参数
            yield SampleInput(
                make_arg(shape(D, rank)),
                shape(L, rank, False),
                scale_factor=None,
                mode=mode,
                align_corners=align_corners,
            )
            # 遍历重新计算缩放因子和缩放因子选项
            for recompute_scale_factor in [False, True]:
                # 遍历不同的缩放因子值
                for scale_factor in [1.7, 0.6]:
                    # 生成 SampleInput 对象，包含 make_arg 创建的张量、缩放因子、插值模式和其他参数
                    yield SampleInput(
                        make_arg(shape(D, rank)),
                        size=None,
                        scale_factor=scale_factor,
                        mode=mode,
                        align_corners=align_corners,
                        recompute_scale_factor=recompute_scale_factor,
                    )
# 生成上采样操作的参考输入样本
def reference_inputs_interpolate(mode, self, device, dtype, requires_grad, **kwargs):
    # 从采样输入生成器中获取输入样本
    yield from sample_inputs_interpolate(mode, self, device, dtype, requires_grad, **kwargs)

    # 如果插值模式是双线性或双三次
    if mode in ('bilinear', 'bicubic'):
        # 创建部分参数函数，设置设备、数据类型、梯度需求
        make_arg = partial(
            make_tensor,
            device=device,
            dtype=dtype,
            requires_grad=requires_grad,
            # 对于无符号8位整数数据类型，选择更真实的上限值256，而不是默认的10
            high=256 if dtype == torch.uint8 else None,
        )
        # 提供几个样本以更典型的图像处理用途
        for memory_format in [torch.contiguous_format, torch.channels_last]:
            for aa in [True, False]:
                yield SampleInput(
                    make_arg((2, 3, 345, 456), memory_format=memory_format),
                    (270, 270),
                    scale_factor=None,
                    mode=mode,
                    align_corners=False,
                    antialias=aa,
                )

# 生成上采样操作的样本输入
def sample_inputs_upsample(mode, self, device, dtype, requires_grad, **kwargs):
    N, C = 2, 3
    D = 4
    S = 3
    L = 5

    ranks_for_mode = {
        'nearest': [1, 2, 3],
        'bilinear': [2],
    }

    # 定义形状函数，用于创建特定尺寸和秩的张量
    def shape(size, rank, with_batch_channel=True):
        if with_batch_channel:
            return torch.Size([N, C] + ([size] * rank))
        return torch.Size([size] * rank)

    # 创建部分参数函数，设置设备、数据类型、梯度需求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 针对给定模式的秩，生成相应的样本输入
    for rank in ranks_for_mode[mode]:
        yield SampleInput(make_arg(shape(D, rank)), size=shape(S, rank, False))
        yield SampleInput(make_arg(shape(D, rank)), size=shape(L, rank, False))
        yield SampleInput(make_arg(shape(D, rank)), scale_factor=1.7)
        yield SampleInput(make_arg(shape(D, rank)), scale_factor=0.6)

# 生成上采样操作的参考输入样本
def reference_inputs_upsample(mode, self, device, dtype, requires_grad, **kwargs):
    # 从上采样样本输入生成器中获取输入样本
    yield from sample_inputs_upsample(mode, self, device, dtype, requires_grad, **kwargs)

    # 如果插值模式是双线性
    if mode in ('bilinear', ):
        # 创建部分参数函数，设置设备、数据类型、梯度需求
        make_arg = partial(
            make_tensor,
            device=device,
            dtype=dtype,
            requires_grad=requires_grad,
            # 对于无符号8位整数数据类型，选择更真实的上限值256，而不是默认的10
            high=256 if dtype == torch.uint8 else None,
        )
        # 提供单个样本以更典型的图像处理用途
        for memory_format in [torch.contiguous_format, torch.channels_last]:
            yield SampleInput(
                make_arg((2, 3, 345, 456), memory_format=memory_format),
                (270, 270),
            )

# 生成带抗锯齿处理的上采样操作的样本输入
def sample_inputs_upsample_aa(mode, self, device, dtype, requires_grad, **kwargs):
    N = 6
    C = 3
    H = 10
    W = 20
    S = 3
    L = 5

    # 创建输入张量，设置设备、数据类型、梯度需求
    input_tensor = make_tensor(torch.Size([N, C, H, W]), device=device, dtype=dtype, requires_grad=requires_grad)
    # 返回一个用于测试的SampleInput对象，指定输出大小为[S, S]，关闭对齐角落选项，未指定缩放因子
    yield SampleInput(input_tensor, output_size=torch.Size([S, S]), align_corners=False, scale_factors=None)
    # 返回一个用于测试的SampleInput对象，指定输出大小为[L, L]，关闭对齐角落选项，未指定缩放因子
    yield SampleInput(input_tensor, output_size=torch.Size([L, L]), align_corners=False, scale_factors=None)
    # 返回一个用于测试的SampleInput对象，未指定输出大小，关闭对齐角落选项，指定缩放因子为[1.7, 0.9]
    yield SampleInput(input_tensor, output_size=None, align_corners=False, scale_factors=[1.7, 0.9])
    # 返回一个用于测试的SampleInput对象，未指定输出大小，开启对齐角落选项，指定缩放因子为[0.8, 1.0]

    # 返回一个用于测试的SampleInput对象，指定输出大小为[S, S]，关闭对齐角落选项，未指定缩放因子
    yield SampleInput(input_tensor, output_size=torch.Size([S, S]), align_corners=False, scales_h=None, scales_w=None)
    # 返回一个用于测试的SampleInput对象，指定输出大小为[S, S]，关闭对齐角落选项，指定水平和垂直缩放因子为1.7和0.9
    yield SampleInput(input_tensor, output_size=torch.Size([S, S]), align_corners=False, scales_h=1.7, scales_w=0.9)
    # 返回一个用于测试的SampleInput对象，指定输出大小为[S, S]，开启对齐角落选项，指定水平和垂直缩放因子为1.7和0.9
# 生成用于 GELU 操作的样本输入，包括不同的设备、数据类型、梯度需求等参数
def sample_inputs_gelu(self, device, dtype, requires_grad, **kwargs):
    # 定义循环次数 N
    N = 5
    # 循环 N-1 次，生成样本输入
    for _ in range(1, N):
        # 遍历两种近似方式：'none' 和 'tanh'
        for approximate in ['none', 'tanh']:
            # 生成 SampleInput 对象，并返回
            yield SampleInput(
                make_tensor((N * 2, N * 2), device=device, dtype=dtype,
                            requires_grad=requires_grad, low=-3, high=3),
                approximate=approximate)


# 生成 GELU 操作错误输入的样本
def error_inputs_gelu(op, device, **kwargs):
    # 生成 ErrorInput 对象，验证当传递一个未知的近似方式时，GELU 函数是否会报错
    yield ErrorInput(SampleInput(make_tensor((), dtype=torch.float, device=device), kwargs={"approximate": "asdf"}),
                     error_regex="approximate argument must be either")


# 生成带有指定维度进行最大最小值约简操作的样本输入
def sample_inputs_max_min_reduction_with_dim(op_info, device, dtype, requires_grad, **kwargs):
    inputs = []
    # 定义不同的维度约简参数组合
    args_for_reduction_with_dim = (
        ((S, S, S), (1,),),
        ((S, S, S), (1, True, ),),
        ((), (0,),),
        ((), (0, True,),),
    )
    # 返回生成的 SampleInput 对象的生成器
    return ((SampleInput(make_tensor(input_tensor, dtype=dtype, device=device,
                                     low=None, high=None,
                                     requires_grad=requires_grad),
                         *args))
            for input_tensor, args in args_for_reduction_with_dim)


# 生成不带指定维度进行最大最小值约简操作的样本输入
def sample_inputs_max_min_reduction_no_dim(op_info, device, dtype, requires_grad, **kwargs):
    # 部分函数化定义 make_tensor 函数的参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    # 生成 SampleInput 对象，并返回
    yield SampleInput(make_arg((S, S, S)))
    yield SampleInput(make_arg(()))


# 生成包含 NaN 的约简操作输入样本
def _generate_nan_reduction_inputs(device, dtype, requires_grad, **kwargs):
    # 生成包含 NaN 值的约简操作输入样本
    yield from _generate_reduction_inputs(device, dtype, requires_grad)
    # 如果数据类型为复数或浮点数，则添加包含 NaN 的张量
    if dtype.is_complex or dtype.is_floating_point:
        yield torch.tensor([2, torch.nan, -1], device=device, dtype=dtype, requires_grad=requires_grad)
        yield torch.tensor([[torch.nan, 2], [0, 1]], device=device, dtype=dtype, requires_grad=requires_grad)


# 生成用于包含 NaN 的约简操作的样本输入
def sample_inputs_nan_reduction(supports_multiple_dims):
    # 生成包含输入张量、维度和 keepdim 等参数的约简操作样本输入
    def fn(op_info, device, dtype, requires_grad, **kwargs):
        # 生成包含 NaN 值的约简操作输入样本
        for t in _generate_nan_reduction_inputs(device, dtype, requires_grad):
            # 添加不带维度和 keepdim 参数的情况
            yield SampleInput(t.clone().requires_grad_(requires_grad))
            # 生成额外的约简操作参数和关键字参数
            for kwargs in _generate_reduction_kwargs(t.ndim, supports_multiple_dims):
                yield SampleInput(t.clone().requires_grad_(requires_grad), **kwargs)

    return fn


# 生成用于分位数约简操作的样本输入
def sample_inputs_reduction_quantile(op_info, device, dtype, requires_grad, **kwargs):
    # 定义测试分位数和插值方式的列表
    test_quantiles = (0.5, make_tensor((2,), dtype=dtype, device=device, low=0, high=1, requires_grad=requires_grad))
    test_interpolations = ['linear', 'midpoint']
    # 遍历测试的分位数
    for quantiles in test_quantiles:
        # 生成用于减少操作的输入
        for t in _generate_reduction_inputs(device, dtype, requires_grad):
            # 添加没有 dim 和 keepdim 参数的情况
            # 克隆输入张量并设置是否需要梯度
            input = t.clone().requires_grad_(requires_grad)
            # 生成一个包含输入和分位数的样本输入
            yield SampleInput(input, quantiles)
            # 生成不同的减少参数，不支持多个维度
            for kwargs in _generate_reduction_kwargs(t.ndim, supports_multiple_dims=False):
                # 目前只支持提供 dim 和 keepdim 时的插值参数
                kwargs.setdefault('dim', 0)
                kwargs.setdefault('keepdim', False)
                # 遍历测试的插值方式
                for interpolation in test_interpolations:
                    kwargs['interpolation'] = interpolation
                    # 克隆输入张量并设置是否需要梯度
                    input = t.clone().requires_grad_(requires_grad)
                    # 生成一个包含输入、分位数和参数的样本输入
                    yield SampleInput(input, quantiles, **kwargs)
def sample_inputs_reduction_count_nonzero(*args, **kwargs):
    """Generate sample inputs for count_nonzero"""
    # count_nonzero does not support keepdim yet
    # Iterate over sample inputs generated by sample_inputs_reduction
    for sample in sample_inputs_reduction(*args, **kwargs):
        # Remove 'keepdim' from kwargs if present
        sample.kwargs.pop('keepdim', None)
        # Yield each modified sample input
        yield sample

def sample_inputs_leaky_relu(op_info, device, dtype, requires_grad, **kwargs):
    """Generate sample inputs for leaky_relu"""
    N = 10
    # Partial function for creating tensors with specified device, dtype, and requires_grad
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # Return a generator yielding SampleInput objects with tensors of shape (N, N)
    return (SampleInput(make_arg((N, N))) for _ in range(1, N))

def sample_inputs_fractional_max_pool2d(op_info, device, dtype, requires_grad, **kwargs):
    """Generate sample inputs for fractional_max_pool2d"""
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # Define test cases with input shapes and kernel sizes
    cases = (((1, 3, 9, 9), 3),
             ((1, 3, 9, 9), (4, 4)),
             ((1, 3, 9, 9), (6, 6)),
             ((2, 3, 9, 9), (3, 3)),
             ((1, 1, 4, 4), (2, 2)),
             ((1, 2, 6, 6), (4, 4)))

    # Iterate through each case
    for input_shape, kernel_size in cases:
        # Iterate over return_indices options
        for return_indices in [False, True]:
            # Yield a SampleInput with specified arguments
            yield SampleInput(
                make_arg(input_shape),
                kernel_size,
                output_size=2,
                return_indices=return_indices,
            )

            # Yield a SampleInput with output_size as a tuple
            yield SampleInput(
                make_arg(input_shape),
                kernel_size,
                output_size=(2, 3),
                return_indices=return_indices,
            )

            # Yield a SampleInput with output_ratio specified
            yield SampleInput(
                make_arg(input_shape),
                kernel_size,
                output_ratio=(0.5, 0.5),
                return_indices=return_indices,
            )

def sample_inputs_fractional_max_pool3d(op_info, device, dtype, requires_grad, **kwargs):
    """Generate sample inputs for fractional_max_pool3d"""
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # Define test cases with input shapes and kernel sizes
    cases = (((2, 3, 5, 5, 5), (2, 2, 2)),
             ((1, 2, 6, 5, 4), 2),
             ((1, 2, 5, 6, 5), (2, 3, 2)),
             ((1, 2, 6, 6, 6), (2, 3, 2)),
             ((1, 1, 7, 6, 7), (2, 3, 4)),
             ((1, 1, 4, 5, 4), (2, 2, 1)),
             ((1, 1, 8, 7, 6), (4, 3, 2)),
             ((0, 1, 4, 5, 4), (2, 2, 1)))
    # 对于每个输入形状 input_shape 和卷积核大小 kernel_size 中的每一对
    for input_shape, kernel_size in cases:
        # 对于 return_indices 取值为 False 和 True 的两种情况进行测试
        for return_indices in [False, True]:
            # 测试用例：传入单一的输出大小 output_size
            yield SampleInput(
                make_arg(input_shape),  # 创建输入参数
                kernel_size,            # 设置卷积核大小
                output_size=2,          # 指定输出大小为 2
                return_indices=return_indices,  # 设置是否返回索引
            )

            # 测试用例：传入元组形式的输出大小 output_size
            yield SampleInput(
                make_arg(input_shape),      # 创建输入参数
                kernel_size,                # 设置卷积核大小
                output_size=(2, 3, 2),      # 指定输出大小为元组 (2, 3, 2)
                return_indices=return_indices,  # 设置是否返回索引
            )

            # 测试用例：传入输出比例 output_ratio
            yield SampleInput(
                make_arg(input_shape),      # 创建输入参数
                kernel_size,                # 设置卷积核大小
                output_ratio=(0.5, 0.5, 0.5),   # 指定输出比例为 (0.5, 0.5, 0.5)
                return_indices=return_indices,  # 设置是否返回索引
            )
def sample_inputs_avgpool2d(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数 make_arg，用于生成张量，固定了设备、数据类型和梯度要求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 不同的池化案例，每个案例包括 input_shape, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override
    cases = (((1, 3, 9, 9), 3, 1, 1, True, False, 2),                # 第一个案例
             ((1, 3, 9, 9), (4, 4), (2, 3), 1, True, False, 2),     # 第二个案例
             ((1, 3, 9, 9), (6, 6), (3, 3), (2, 3), True, True, 2), # 第三个案例
             ((2, 3, 9, 9), (3, 3), (1, 1), (1, ), True, False, 2), # 第四个案例
             ((1, 1, 4, 4), (2, 2), (), (0, ), False, True, -2),    # 第五个案例
             ((1, 2, 6, 6), (4, 4), (2, 2), (2, ), True, True, None))  # 第六个案例

    # 遍历每个池化案例
    for input_shape, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override in cases:
        # 生成 SampleInput 对象，使用 make_arg 生成输入张量，args 为池化的参数
        yield SampleInput(make_arg(input_shape),
                          args=(kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override))
    
    # 单独的案例，只包含 input_shape 和 kernel_size
    yield SampleInput(make_arg((1, 3, 9, 9)), args=((3, 3)))


def sample_inputs_avgpool1d(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数 make_arg，用于生成张量，固定了设备、数据类型和梯度要求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 池化案例的顺序：input_shape, kernel_size, kwargs
    cases: List[Tuple[Tuple[int, ...], Union[int, Tuple[int, ...]], Dict]] = [
        ((2, 3, 9), (3,), {}),  # 第一个案例
        ((1, 3, 9), 3, dict(stride=1, padding=1, ceil_mode=True, count_include_pad=False)),  # 第二个案例
        ((1, 3, 9), (6,), dict(stride=(3,), padding=(2,), ceil_mode=True, count_include_pad=True)),  # 第三个案例
        ((2, 3, 9), (3,), dict(stride=(1,), padding=(1,), ceil_mode=False, count_include_pad=True)),  # 第四个案例
        ((0, 3, 9), (6,), dict(stride=(3,), padding=(2,), ceil_mode=False, count_include_pad=True)),  # 第五个案例
        ((1, 2, 9), (7,), dict(stride=(3,), padding=(2,), ceil_mode=False)),  # 第六个案例
        ((1, 2, 9), (7,), dict(stride=(3,), padding=(3,), ceil_mode=True)),  # 第七个案例
        ((1, 2, 9), (7,), dict(stride=(3,), ceil_mode=False)),  # 第八个案例
        ((1, 2, 9), (7,), dict(stride=(3,), ceil_mode=True)),  # 第九个案例
    ]

    # 遍历每个池化案例
    for input_shape, kernel_size, kwargs in cases:
        # 生成 SampleInput 对象，使用 make_arg 生成输入张量，args 为池化的参数，kwargs 为其他参数
        yield SampleInput(make_arg(input_shape), args=(kernel_size,), kwargs=kwargs)


def sample_inputs_avgpool3d(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数 make_arg，用于生成张量，固定了设备、数据类型和梯度要求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # Order: input_shape, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override
    cases: List[Tuple[Tuple[int, ...], Union[int, Tuple[int, ...]], Dict]] = [
        # 定义一个列表 cases，包含了多个元组，每个元组表示一组输入数据
        ((2, 3, 3, 4, 4), (2, 2, 2), {}),
        # 第一组输入数据，输入形状为 (2, 3, 3, 4, 4)，卷积核大小为 (2, 2, 2)，kwargs 是空字典
        ((1, 2, 4, 4, 4), 2, dict(stride=1, padding=1, ceil_mode=True,
                                  count_include_pad=False, divisor_override=2)),
        # 第二组输入数据，输入形状为 (1, 2, 4, 4, 4)，卷积核大小为 2，kwargs 包含了多个参数设定
        ((1, 2, 5, 5, 5), (2, 3, 4), dict(stride=(1, 2, 2), padding=(0, 1, 2), ceil_mode=True,
                                          count_include_pad=True, divisor_override=2)),
        # 第三组输入数据，输入形状为 (1, 2, 5, 5, 5)，卷积核大小为 (2, 3, 4)，kwargs 包含了多个参数设定
        ((1, 2, 5, 5, 5), (2, 3, 4), dict(stride=(1, 2, 2), padding=(0, 1, 2), ceil_mode=False)),
        # 第四组输入数据，输入形状为 (1, 2, 5, 5, 5)，卷积核大小为 (2, 3, 4)，kwargs 包含了部分参数设定
        ((1, 1, 7, 5, 7), (6, 3, 4), dict(stride=(2, 3, 2), padding=(3, 1, 0), ceil_mode=False,
                                          count_include_pad=False, divisor_override=2)),
        # 第五组输入数据，输入形状为 (1, 1, 7, 5, 7)，卷积核大小为 (6, 3, 4)，kwargs 包含了多个参数设定
        ((1, 1, 4, 5, 4), (2, 2, 3), dict(stride=(2, 2, 1), padding=0, ceil_mode=False,
                                          count_include_pad=True, divisor_override=-2)),
        # 第六组输入数据，输入形状为 (1, 1, 4, 5, 4)，卷积核大小为 (2, 2, 3)，kwargs 包含了多个参数设定
        ((1, 1, 6, 5, 6), (4, 5, 6), dict(stride=(2, 3, 2), padding=2, ceil_mode=True,
                                          count_include_pad=True, divisor_override=None)),
        # 第七组输入数据，输入形状为 (1, 1, 6, 5, 6)，卷积核大小为 (4, 5, 6)，kwargs 包含了多个参数设定
        ((0, 1, 4, 5, 4), (2, 3, 1), dict(stride=(2, 1, 2), padding=0, ceil_mode=False,
                                          count_include_pad=True, divisor_override=None)),
        # 第八组输入数据，输入形状为 (0, 1, 4, 5, 4)，卷积核大小为 (2, 3, 1)，kwargs 包含了多个参数设定
    ]

    for input_shape, kernel_size, kwargs in cases:
        # 遍历 cases 中的每一组数据，依次取出 input_shape、kernel_size 和 kwargs
        yield SampleInput(make_arg(input_shape), args=(kernel_size,), kwargs=kwargs)
        # 使用 make_arg 函数处理 input_shape，然后以 (kernel_size, kwargs) 作为参数生成 SampleInput 实例，并 yield 出来
# 定义一个函数，用于生成一系列的错误输入示例，针对 `avg_pool1d` 操作进行测试
def error_inputs_avg_pool1d(op_info, device, **kwargs):
    # 创建一个形状为 [0, 1, 49] 的随机张量 x，数据类型为 float32
    x = torch.rand([0, 1, 49], dtype=torch.float32)
    # 生成一个 ErrorInput 对象，测试当 padding 设置为负数时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': 2, 'stride': 50, 'padding': -1}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': -1}),
                     error_regex='pad must be non-negative')

    # 生成一个 ErrorInput 对象，测试当 padding 大于 kernel_size 的一半时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': 2, 'stride': 50, 'padding': 4}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': 4}),
                     error_regex='pad should be at most half of effective kernel size')

# 定义一个函数，用于生成一系列的错误输入示例，针对 `avg_pool2d` 操作进行测试
def error_inputs_avg_pool2d(op_info, device, **kwargs):
    # 创建一个形状为 [0, 1, 49] 的随机张量 x，数据类型为 float32
    x = torch.rand([0, 1, 49], dtype=torch.float32)
    # 生成一个 ErrorInput 对象，测试当 padding 设置为负数时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': 2, 'stride': 50, 'padding': -1}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': -1}),
                     error_regex='pad must be non-negative')
    
    # 生成一个 ErrorInput 对象，测试当 2D kernel 的 padding 设置为负数时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': (3, 2), 'stride': 50, 'padding': -1}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2), 'stride': 50, 'padding': -1}),
                     error_regex='pad must be non-negative')

    # 生成一个 ErrorInput 对象，测试当 padding 大于 kernel_size 的一半时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': 2, 'stride': 50, 'padding': 4}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': 4}),
                     error_regex='pad should be at most half of effective kernel size')
    
    # 生成一个 ErrorInput 对象，测试当 2D kernel 的 padding 大于 kernel_size 的一半时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': (3, 2), 'stride': 50, 'padding': 4}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2), 'stride': 50, 'padding': 4}),
                     error_regex='pad should be at most half of effective kernel size')

    # 生成一个 ErrorInput 对象，测试当 divisor_override 设置为 0 时的错误情况，
    # 使用全零的 3x3x3 张量 x 和参数 {'kernel_size': (2, 2), 'divisor_override': 0}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (2, 2), 'divisor_override': 0}),
                     error_regex='divisor must be not zero')

# 定义一个函数，用于生成一系列的错误输入示例，针对 `avg_pool3d` 操作进行测试
def error_inputs_avg_pool3d(op_info, device, **kwargs):
    # 创建一个形状为 [0, 1, 49, 50] 的随机张量 x，数据类型为 float32
    x = torch.rand([0, 1, 49, 50], dtype=torch.float32)
    # 生成一个 ErrorInput 对象，测试当 padding 设置为负数时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': 2, 'stride': 50, 'padding': -1}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': -1}),
                     error_regex='pad must be non-negative')
    
    # 生成一个 ErrorInput 对象，测试当 3D kernel 的 padding 设置为负数时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': (3, 2, 2), 'stride': 50, 'padding': -1}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2, 2), 'stride': 50, 'padding': -1}),
                     error_regex='pad must be non-negative')

    # 生成一个 ErrorInput 对象，测试当 padding 大于 kernel_size 的一半时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': 2, 'stride': 50, 'padding': 4}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': 4}),
                     error_regex='pad should be at most half of effective kernel size')
    
    # 生成一个 ErrorInput 对象，测试当 3D kernel 的 padding 大于 kernel_size 的一半时的错误情况，
    # 使用 SampleInput 对象包含张量 x 和参数 {'kernel_size': (3, 2, 2), 'stride': 50, 'padding': 4}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2, 2), 'stride': 50, 'padding': 4}),
                     error_regex='pad should be at most half of effective kernel size')

    # 生成一个 ErrorInput 对象，测试当 divisor_override 设置为 0 时的错误情况，
    # 使用全零的 3x3x3x3 张量 x 和参数 {'kernel_size': (2, 2, 2), 'divisor_override': 0}
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (2, 2, 2), 'divisor_override': 0}),
                     error_regex='divisor must be not zero')

    # 生成一个 ErrorInput 对象，测试当输入张量的维度不正确时的错误情况，
    # 使用形状为 [0, 1, 49] 的随机张量 x，数据类型为 float32
    x = torch.rand([0, 1, 49], dtype=torch.float32)
    # 使用生成器函数 yield 返回一个 ErrorInput 对象
    yield ErrorInput(
        # 创建一个 SampleInput 对象，传入参数 x，kwargs 包含 kernel_size: 2, stride: 50, padding: 0
        SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': 0}),
        # 指定错误正则表达式为 'non-empty 4D or 5D'
        error_regex='non-empty 4D or 5D'
    )
# 定义一个生成样本输入的函数，生成多种输入组合作为测试数据
def sample_inputs_to(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于生成张量的函数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    
    # 如果指定的设备是 CPU，则设备列表为 [cpu, cuda:0]（如果 CUDA 可用）
    devices = [device]
    if torch.device(device).type == 'cpu':
        devices = [torch.device('cpu'), torch.device('cuda:0')] if torch.cuda.is_available() else devices
    
    # 内存格式选项，包括保留格式和通道末尾
    memory_formats = [torch.preserve_format, torch.channels_last]
    
    # 遍历设备、是否需要梯度、是否需要拷贝以及内存格式的组合
    for device, nb, cp, mem_f in product(devices, [True, False], [True, False], memory_formats):
        # 设置参数字典，指定内存格式
        kwargs = {
            "memory_format": mem_f,
        }
        # 生成样本输入对象，包括输入张量、位置参数（设备、数据类型、是否需要梯度、是否需要拷贝）和关键字参数
        yield SampleInput(make_arg((S, S, S, S)), args=(device, torch.float64, nb, cp), kwargs=kwargs)
    
    # 遍历是否需要梯度、是否需要拷贝以及内存格式的组合（不指定设备）
    for nb, cp, mem_f in product([True, False], [True, False], memory_formats):
        # 设置参数字典，指定内存格式
        kwargs = {
            "memory_format": mem_f,
        }
        # 生成样本输入对象，包括输入张量、位置参数（数据类型、是否需要梯度、是否需要拷贝）和关键字参数
        yield SampleInput(make_arg((S, S, S, S)), args=(torch.float64, nb, cp), kwargs=kwargs)
    
    # 遍历设备、是否需要梯度、是否需要拷贝以及内存格式的组合
    for device, nb, cp, mem_f in product(devices, [True, False], [True, False], memory_formats):
        # 设置参数字典，指定内存格式
        kwargs = {
            "memory_format": mem_f,
        }
        # 创建另一个输入张量作为参考对象
        other = make_arg((S, S, S, S), dtype=torch.float64, device=device)
        # 生成样本输入对象，包括输入张量、位置参数（参考对象、是否需要梯度、是否需要拷贝）和关键字参数
        yield SampleInput(make_arg((S, S, S, S)), args=(other, nb, cp), kwargs=kwargs)


# 定义生成用于 topk 操作的样本输入的函数
def sample_inputs_topk(op_info, device, dtype, requires_grad, **kwargs):
    # 定义生成指定大小张量的函数
    def get_tensor_input(size):
        return make_tensor(size, dtype=dtype, device=device, requires_grad=requires_grad)
    
    # 生成不同参数组合的样本输入对象，包括输入张量和 topk 参数
    yield SampleInput(get_tensor_input((S, M, S)), 3)
    yield SampleInput(get_tensor_input((S, M, S)), 3, 1)
    yield SampleInput(get_tensor_input((S, M, S)), 3, -2)
    yield SampleInput(get_tensor_input((S, M, S)), 3, 1, True)
    yield SampleInput(get_tensor_input((S, M, S)), 3, -2, True)
    yield SampleInput(get_tensor_input((S, M, S)), 3, 1, True, True)
    yield SampleInput(get_tensor_input((S, M, S)), 3, -2, True, True)
    
    # 生成不同参数组合的样本输入对象，包括输入张量和 topk 参数
    yield SampleInput(get_tensor_input(()), 1)
    yield SampleInput(get_tensor_input(()), 1, 0)
    yield SampleInput(get_tensor_input(()), 1, -1)
    yield SampleInput(get_tensor_input(()), 1, 0, True)
    yield SampleInput(get_tensor_input(()), 1, -1, True)
    yield SampleInput(get_tensor_input(()), 1, 0, True, True)
    yield SampleInput(get_tensor_input(()), 1, -1, True, True)


# 定义生成用于 outer 操作的样本输入的函数
def sample_inputs_outer(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于生成张量的函数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 生成两个不同大小的输入张量作为样本输入对象
    yield SampleInput(make_arg(S), make_arg(M))


# 定义生成用于 dist 操作的样本输入的函数
def sample_inputs_dist(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于生成张量的函数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 指定不同的张量大小和参数，作为样本输入对象
    sizes = ((S, S, S), (S,), (S, 1, S), (), (S, S))
    ps = (2, 4)
    # 使用 product 函数生成三个可迭代对象 sizes, sizes, ps 中元素的笛卡尔积，每个元素包含 size_x, size_y, p
    for size_x, size_y, p in product(sizes, sizes, ps):
        # 生成 SampleInput 对象并返回，其中参数是 size_x 作为位置参数，size_y 和 p 作为关键字参数
        yield SampleInput(make_arg(size_x), args=(make_arg(size_y), p))
# 缺失测试操作的非确定性
# https://github.com/pytorch/pytorch/issues/53352
def sample_inputs_index(op_info, device, dtype, requires_grad, reference=False, **kwargs):
    # 根据操作信息判断是否为 index_select 操作
    select = "index_select" in op_info.name
    # 根据操作信息判断是否为 index_add 操作
    add = "index_add" in op_info.name
    # 根据操作信息判断是否为 index_copy 操作
    copy = "index_copy" in op_info.name
    # 根据操作信息判断是否为 index_fill 操作
    fill = "index_fill" in op_info.name

    # 扩展参考输入。我们生成练习原子加法/多次写入同一位置
    if reference:
        make_arg = partial(torch.ones, device=device, dtype=dtype, requires_grad=requires_grad)
        make_idx = partial(torch.zeros, device=device, dtype=torch.int64)
    else:
        make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
        # 对于确定性复制和添加，它们的索引必须不同
        if copy or add:
            make_idx = partial(torch.randperm, device=device, dtype=torch.int64)
        else:
            def make_idx(n):
                return make_tensor((n,), device=device, dtype=torch.int64, low=0, high=n)

    shapes = [(), (1,), (S, S)]
    # 对于 index_add，额外的参数
    if add:
        if dtype == torch.bool:
            alphas = (True, False)
        else:
            alphas = (-1, 0, 2)
    else:
        alphas = (None,)

    if fill:
        # 用一个奇怪的数字来捕获错误。
        # 前一个测试 `index_fill.int_Scalar`，后一个测试 `index_fill.int_Tensor`。
        values = (make_arg((1,)).item(), make_arg(()))
    else:
        values = (None,)

    for shape, alpha, value in product(shapes, alphas, values):
        t = make_arg(shape)
        args = []

        # 维度。我们处理标量情况
        dim = -1 if t.ndim == 2 else 0
        args.append(dim)

        idx = make_idx(t.shape[dim] if t.ndim != 0 else 1)
        args.append(idx)

        # 源张量
        if copy or add:
            args.append(make_arg(shape))
        elif fill:
            args.append(value)

        args = tuple(args)
        kwargs = {} if alpha is None else {"alpha": alpha}

        yield SampleInput(t, args=args, kwargs=kwargs)

def sample_inputs_index_reduce(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    def make_idx(n, m):
        return make_tensor((n,), device=device, dtype=torch.int64, low=0, high=m)

    shapes = [((), ()), ((1,), (1,)), ((S, S), (S, M)), ((S, S, S), (S, M, S))]
    include_selfs = (True, False)
    reduce = op_info.variant_test_name
    assert reduce in ('prod', 'mean', 'amin', 'amax')
    # 遍历形状和包含自身标志的笛卡尔积
    for shape, include_self in product(shapes, include_selfs):
        # 分别取出自身形状和源形状
        self_shape, src_shape = shape
        # 计算维度。如果自身形状长度大于等于2，则维度为1，否则为0（处理标量情况）
        dim = 1 if len(self_shape) >= 2 else 0
        # 根据维度创建索引
        idx = make_idx(src_shape[dim] if len(src_shape) != 0 else 1,
                       self_shape[dim] if len(self_shape) != 0 else 1)
        # 准备参数：维度、索引、源形状的参数表示、reduce 方法
        args = (dim, idx, make_arg(src_shape), reduce)
        # 生成一个 SampleInput 对象，表示一个样本输入，包含参数和关键字参数
        yield SampleInput(make_arg(self_shape),
                          args=args,
                          kwargs={'include_self' : include_self})

    # 针对反向传播测试边缘情况的样本输入
    if requires_grad and reduce == 'prod':
        # 检查在乘积（prod）reduce 操作中，当源或自身存在零元素时，梯度是否正确传播
        # 本样本测试以下情况的梯度：
        # (a) 一个零元素被reduce（来自源 self[0, 1]，来自自身 self[0, 0]）
        # (b) 两个零元素被reduce（来自源和自身各一个 self[1, 0], self[1, 1]）
        # (c) 没有零元素被reduce（self[2, 1], self[2, 2]）
        # (d) 两个来自源的零元素被reduce的情况，在 test/test_autograd.py 的 test_scatter_index_reduce_prod_gradgrad_error 中测试，因为这种情况不支持 gradgrad
        input = torch.tensor([[0, 13], [0, 0], [15, 19]], dtype=dtype, device=device, requires_grad=requires_grad)
        src = torch.tensor([[2, 0], [0, 0], [2, 3], [2, 2]], dtype=dtype, device=device, requires_grad=requires_grad)
        idx = torch.tensor([0, 1, 2, 0], dtype=torch.long, device=device)
        
        # 生成一个 SampleInput 对象，表示一个样本输入，包含输入数据、参数和关键字参数
        yield SampleInput(input,
                          args=(0, idx, src, reduce),
                          kwargs={'include_self': True})
# 定义一个函数，生成带有未安全掩码索引的样本输入
def sample_inputs__unsafe_masked_index(op_info, device, dtype, requires_grad, **kwargs):
    # 使用部分函数make_tensor创建张量，并固定设备、数据类型和是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义一个函数，用于生成索引张量
    def make_idx(n, m, dim, d):
        # 创建一个形状为view_shape的张量，并在指定维度d上设置为n
        view_shape = [1] * dim
        view_shape[d] = n
        return make_tensor((n,), device=device, dtype=torch.int64, low=0, high=m).view(view_shape)

    # 定义不同的测试用例
    cases = [
        ((S, S), S, M),        # 第一个测试用例
        ((S, S), M, S),        # 第二个测试用例
        ((S, S, S), S, M),     # 第三个测试用例
    ]

    # 创建一个空张量并提取其单元值
    fill_value = make_tensor([], dtype=dtype, device="cpu").item()

    # 遍历测试用例
    for c in cases:
        self_shape, high, idx_size = c
        dim = len(self_shape)
        # 生成多维索引张量列表
        indices = [make_idx(idx_size, high, dim, d) for d in range(dim)]
        # 生成掩码张量列表
        masks = [torch.logical_and(idx >= 0, idx < self_shape[i]) for i, idx in enumerate(indices) if idx is not None]
        # 使用逻辑与对掩码列表进行减少操作
        mask = functools.reduce(torch.logical_and, masks)
        # 生成样本输入对象并返回
        yield SampleInput(make_arg(self_shape), mask, indices, fill_value)

        # 生成修改后的掩码张量列表
        masks = [torch.logical_and(idx >= 1, idx < self_shape[i] - 1) for i, idx in enumerate(indices) if idx is not None]
        # 使用逻辑与对修改后的掩码列表进行减少操作
        mask = functools.reduce(torch.logical_and, masks)
        # 生成样本输入对象并返回
        yield SampleInput(make_arg(self_shape), mask, indices, fill_value)

# 定义一个函数，生成带有未安全掩码索引放置累积的样本输入
def sample_inputs__unsafe_masked_index_put_accumulate(op_info, device, dtype, requires_grad, **kwargs):
    # 使用部分函数make_tensor创建张量，并固定设备、数据类型和是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义一个函数，用于生成索引张量
    def make_idx(n, m, dim, d):
        # 创建一个形状为view_shape的张量，并在指定维度d上设置为n
        view_shape = [1] * dim
        view_shape[d] = n
        return make_tensor((n,), device=device, dtype=torch.int64, low=0, high=m).view(view_shape)

    # 定义不同的测试用例
    cases = [
        ((S, S), S, (M, M)),           # 第一个测试用例
        ((S, S), M, (S, S + 1)),       # 第二个测试用例
        ((S, S, S), S, (M, M - 1, M + 1)),  # 第三个测试用例
    ]

    # 创建一个空张量并提取其单元值
    fill_value = make_tensor([], dtype=dtype, device="cpu").item()

    # 遍历测试用例
    for c in cases:
        self_shape, high, idx_sizes = c
        dim = len(self_shape)
        # 生成多维索引张量列表
        indices = [make_idx(idx_sizes[d], high, dim, d) for d in range(dim)]
        # 生成掩码张量列表
        masks = [torch.logical_and(idx >= 0, idx < self_shape[i]) for i, idx in enumerate(indices) if idx is not None]
        # 使用逻辑与对掩码列表进行减少操作
        mask = functools.reduce(torch.logical_and, masks)
        # 使用make_arg生成值张量
        values = make_arg(idx_sizes)
        # 生成样本输入对象并返回
        yield SampleInput(make_arg(self_shape), mask, indices, values)

        # 生成修改后的掩码张量列表
        masks = [torch.logical_and(idx >= 1, idx < self_shape[i] - 1) for i, idx in enumerate(indices) if idx is not None]
        # 使用逻辑与对修改后的掩码列表进行减少操作
        mask = functools.reduce(torch.logical_and, masks)
        # 生成样本输入对象并返回
        yield SampleInput(make_arg(self_shape), mask, indices, values)


# 定义一个函数，生成样本输入的模式
def sample_inputs_mode(op_info, device, dtype, requires_grad, **kwargs):
    # 不同的参数组合
    args = (
        ((S, S, S), (),),          # 第一个参数组合
        ((S, S, S), (1, ),),       # 第二个参数组合
        ((S, S, S), (1, True, ),), # 第三个参数组合
        ((), (),),                 # 第四个参数组合
        ((), (0,),),               # 第五个参数组合
        ((), (0, True,),),         # 第六个参数组合
        # 在CUDA上非融合模式内核
        ((3000,), ()),             # 第七个参数组合
    )
    # 使用部分函数make_tensor创建张量，并固定设备、数据类型和是否需要梯度，同时保留None和None的值
    make_arg = partial(make_tensor, dtype=dtype, device=device,
                       requires_grad=requires_grad, low=None, high=None)
    # 返回一个生成器，生成每个输入张量及其对应参数的 SampleInput 对象
    return (SampleInput(make_arg(input_tensor), *args)
            for input_tensor, args in args)
# 定义函数sample_inputs_put，用于生成带有不同输入的SampleInput对象
# op_info: 操作信息
# device: 设备类型
# dtype: 数据类型
# requires_grad: 是否需要梯度
# **kwargs: 其他参数
def sample_inputs_put(op_info, device, dtype, requires_grad, **kwargs):
    # 使用make_tensor函数创建部分应用的函数make_arg和make_idx，以简化参数生成过程
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    make_idx = partial(make_tensor, low=0, dtype=torch.int64, device=device, requires_grad=False)

    # 设置常数S为3
    S = 3

    # 生成通用输入
    idx = torch.randperm(S * S, device=device, dtype=torch.int64)[:S]
    idx_list = [idx, -idx - 1]
    # 生成每个idx和acc的组合，使用product函数遍历idx_list和acc的所有可能组合
    for idx, acc in product(idx_list, (True, False)):
        yield SampleInput(input=make_arg((S, S)),
                          args=(idx.clone(),
                                make_arg((S,)),
                                acc))

    # 标量输入情况
    scalar_sizes = [(), (1,)]
    tgt_gen = (make_arg(size) for size in scalar_sizes)
    idx_gen = (make_idx(size, high=1) for size in scalar_sizes)
    src_gen = (make_arg(size) for size in scalar_sizes)
    # 生成每个tgt、idx、src和acc的组合，使用product函数遍历它们的所有可能组合
    for tgt, idx, src, acc in product(tgt_gen, idx_gen, src_gen, (True, False)):
        yield SampleInput(input=tgt.clone().requires_grad_(requires_grad),
                          args=(idx.clone(),
                                src.clone().requires_grad_(requires_grad),
                                acc))

    # 空输入情况
    tgt_sizes = [(0,), (), (1,), (3, 2)]
    tgt_gen = (make_arg(size) for size in tgt_sizes)
    idx = make_idx((0,), high=1)
    src = make_arg((0,))
    # 生成每个tgt和acc的组合，使用product函数遍历它们的所有可能组合
    for tgt, acc in product(tgt_gen, (True, False)):
        yield SampleInput(input=tgt.clone().requires_grad_(requires_grad),
                          args=(idx.clone(),
                                src.clone().requires_grad_(requires_grad),
                                acc))

# 定义函数sample_inputs_take，用于生成带有不同输入的SampleInput对象
# op_info: 操作信息
# device: 设备类型
# dtype: 数据类型
# requires_grad: 是否需要梯度
# **kwargs: 其他参数
def sample_inputs_take(op_info, device, dtype, requires_grad, **kwargs):
    # 使用make_tensor函数创建部分应用的函数make_arg和make_idx，以简化参数生成过程
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    make_idx = partial(make_tensor, low=0, dtype=torch.int64, device=device, requires_grad=False)

    # 设置常数S为3
    S = 3

    # 生成通用输入：从S * S的元素中取出S个元素
    index = make_idx((S,), high=(S * S))
    # 生成每个idx的组合，使用product函数遍历index和其相反数的所有可能组合
    for idx in (index, -index - 1):
        yield SampleInput(input=make_arg((S, S)), args=(idx,))

    # 标量输入情况
    scalar_sizes = [(), (1,)]
    src_gen = (make_arg(size) for size in scalar_sizes)
    idx_gen = (make_idx(size, high=1) for size in scalar_sizes)
    # 生成每个src和idx的组合，使用product函数遍历它们的所有可能组合
    for src, idx in product(src_gen, idx_gen):
        yield SampleInput(input=src.clone().requires_grad_(requires_grad),
                          args=(idx.clone(),))

    # 空输入情况
    src_sizes = [(0,), (), (1,), (3, 2)]
    src_gen = (make_arg(size) for size in src_sizes)

    idx = make_idx((0,), high=1)
    # 生成每个src的组合，使用product函数遍历它们的所有可能组合
    for src in src_gen:
        yield SampleInput(input=src.clone().requires_grad_(requires_grad),
                          args=(idx.clone(),))
    # 使用偏函数 `partial` 创建 `make_tensor` 函数的可调用对象 `make_arg`，
    # 设置参数 `dtype`、`device`、`low`、`high` 和 `requires_grad` 的默认值
    make_arg = partial(make_tensor, dtype=dtype, device=device, low=None, high=None, requires_grad=requires_grad)
    # 生成一个样本输入，调用 `make_arg` 生成一个形状为 (4, 3, 2, 1) 的张量，
    # 并指定目标输出为 [0, 1, 2, 3]，期望输出为 [3, 2, 1, 0]
    yield SampleInput(make_arg((4, 3, 2, 1)), [0, 1, 2, 3], [3, 2, 1, 0])
    # 生成另一个样本输入，调用 `make_arg` 生成一个形状为 (4, 3, 2, 1) 的张量，
    # 并指定目标输出为 [0, -1, -2, -3]，期望输出为 [-3, -2, -1, 0]
    yield SampleInput(make_arg((4, 3, 2, 1)), [0, -1, -2, -3], [-3, -2, -1, 0])
def reference_movedim_moveaxis(op_info, device, dtype, requires_grad, **kwargs):
    # 调用 sample_movedim_moveaxis 函数生成器，并将其结果 yield 返回
    yield from sample_movedim_moveaxis(op_info, device, dtype, requires_grad, **kwargs)

    # 使用偏函数 make_tensor 创建一个函数 make_arg，设置了设备、数据类型和梯度需求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义测试用例的参数 args，包括空输入、整数输入（含负数）、交换边界、非顺序输入等
    args = (
        # empty inputs
        ((), (), ()),
        # int inputs, negative
        ((3, 5, 7, 2), -2, 1),
        # swap bounds
        ((3, 5, 7, 2), (-1, 0), (0, -1)),
        # non-sequential, negative
        ((2, 3, 4, 5, 6), (3, -3, 4), (1, 0, -1)),
        # idempotence, negative
        ((2, 3, 4, 5, 6), (-3, 4, 3, 1), (-3, 4, 3, 1)),
        # reverse, sequential, positive
        ((6, 2, 3, 5, 4), (4, 3, 2, 1, 0), (0, 1, 2, 3, 4)),
        # reverse, non-sequential
        ((6, 2, 3, 5, 4), (-3, -2, -4, -5, -1), (2, 1, 3, 4, 0)),
        # reverse, sequential, negative
        ((6, 2, 3, 5, 4), (4, -2, 2, -4, -5), (-5, 1, 2, -2, -1)),
    )

    # 遍历参数 args，为每个测试用例生成 SampleInput 实例并 yield 返回
    for shape, source, destination in args:
        yield SampleInput(make_arg(shape), args=(source, destination))

def error_movedim_moveaxis(op_info, device, **kwargs):
    # 使用偏函数 make_tensor 创建一个函数 make_arg，设置了设备和默认数据类型为 torch.float32
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # source length < destination length 的错误测试用例
    yield ErrorInput(
        SampleInput(make_arg(2, 3, 4, 5, 6), args=((3, -3), (1, 0, -1))),
        # 匹配错误信息的正则表达式
        error_regex=(r"movedim: Invalid source or destination dims: source "
                     r"\(\[3, -3\] dims\) should contain the same number of "
                     r"dims as destination \(\[1, 0, -1\] dims\)"),
    )

    # source length > destination length 的错误测试用例
    yield ErrorInput(
        SampleInput(make_arg(2, 3, 4, 5, 6), args=((3, -3, 4), (1, 0))),
        # 匹配错误信息的正则表达式
        error_regex=(r"movedim: Invalid source or destination dims: source "
                     r"\(\[3, -3, 4\] dims\) should contain the same number of "
                     r"dims as destination \(\[1, 0\] dims\)"),
    )

    # source 中重复的维度，且含有负索引 的错误测试用例
    yield ErrorInput(
        SampleInput(make_arg(2, 3, 4, 5, 6), args=((0, 4, -5), (1, 0, 2))),
        # 匹配错误信息的正则表达式
        error_regex=r"movedim: repeated dim in `source` \(\[0, 4, -5\]\)",
    )

    # destination 中重复的维度，且含有负索引 的错误测试用例
    yield ErrorInput(
        SampleInput(make_arg(2, 3, 4, 5, 6), args=((1, 0, 2), (0, 4, -5))),
        # 匹配错误信息的正则表达式
        error_regex=r"movedim: repeated dim in `destination` \(\[0, 4, -5\]\)",
    )

    # source 和 destination 中均有重复维度，且含有负索引 的错误测试用例
    yield ErrorInput(
        SampleInput(make_arg(2, 3, 4, 5, 6), args=((1, 0, -4), (0, 4, -5))),
        # 匹配错误信息的正则表达式
        error_regex=r"movedim: repeated dim in `source` \(\[1, 0, -4\]\)",
    )

    # source 中超出范围的维度输入，且含有负索引 的错误测试用例
    yield ErrorInput(
        SampleInput(make_arg(2, 3, 4, 5, 6), args=((0, 1, -6), (1, 4, 2))),
        # 匹配错误信息的正则表达式
        error_regex=r"Dimension out of range \(expected to be in range of \[-5, 4\], but got -6\)",
        # 预期的错误类型
        error_type=IndexError,
    )

    # destination 中超出范围的维度输入，且含有负索引 的错误测试用例
    # 生成一个 ErrorInput 对象并返回，其包含一个 SampleInput 对象和相关的错误信息
    yield ErrorInput(
        # 使用 make_arg 函数生成样例输入，参数为 2, 3, 4, 5, 6，并设置额外参数为 ((1, 4, 2), (0, 1, -6))
        SampleInput(make_arg(2, 3, 4, 5, 6), args=((1, 4, 2), (0, 1, -6))),
        # 设置错误信息的正则表达式，用于匹配预期的错误消息
        error_regex=r"Dimension out of range \(expected to be in range of \[-5, 4\], but got -6\)",
        # 设置错误类型为 IndexError
        error_type=IndexError,
    )

    # 生成另一个 ErrorInput 对象并返回，其包含一个 SampleInput 对象和相关的错误信息
    yield ErrorInput(
        # 使用 make_arg 函数生成样例输入，参数为 2, 3, 4, 5, 6，并设置额外参数为 (-6, 1)
        SampleInput(make_arg(2, 3, 4, 5, 6), args=(-6, 1)),
        # 设置错误信息的正则表达式，用于匹配预期的错误消息
        error_regex=r"Dimension out of range \(expected to be in range of \[-5, 4\], but got -6\)",
        # 设置错误类型为 IndexError
        error_type=IndexError,
    )

    # 生成另一个 ErrorInput 对象并返回，其包含一个 SampleInput 对象和相关的错误信息
    yield ErrorInput(
        # 使用 make_arg 函数生成样例输入，参数为 2, 3, 4, 5, 6，并设置额外参数为 (3, -6)
        SampleInput(make_arg(2, 3, 4, 5, 6), args=(3, -6)),
        # 设置错误信息的正则表达式，用于匹配预期的错误消息
        error_regex=r"Dimension out of range \(expected to be in range of \[-5, 4\], but got -6\)",
        # 设置错误类型为 IndexError
        error_type=IndexError,
    )


这些注释解释了每行代码的作用和意图，保持了代码块的完整性和原始结构。
# 定义一个函数，生成指定操作信息的样本输入数据
def sample_repeat_tile(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于生成指定设备、数据类型和梯度设置的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 定义不同的重复维度和形状组合
    rep_dims = ((), (0, ), (1, ), (0, 2), (1, 1), (2, 3), (2, 3, 2), (0, 2, 3), (2, 1, 1, 1),)
    shapes = ((), (0,), (2,), (3, 0), (3, 2), (3, 0, 1))

    # 如果需要计算梯度，则测试较慢的变体一致性测试、梯度、二阶梯度
    # 使用较小的 `rep_dims` 和 `shapes` 组合
    if requires_grad:
        rep_dims = ((), (0, ), (0, 2), (1, 1), (2, 3), (1, 3, 2), (3, 1, 1))  # type: ignore[assignment]
        shapes = ((), (0,), (2,), (3, 2))  # type: ignore[assignment]

    # 检查当前操作是否为重复操作
    is_repeat_op = op_info.name in ['repeat', '_refs.repeat']
    # 遍历所有的重复维度和形状组合
    for rep_dim, shape in product(rep_dims, shapes):
        # 如果是重复操作且重复维度少于形状维度，则跳过
        if is_repeat_op and len(rep_dim) < len(shape):
            continue
        # 生成样本输入，使用部分应用函数生成的张量和当前的重复维度
        yield SampleInput(make_arg(shape), rep_dim)


# 生成窄化操作的样本输入数据
def sample_inputs_narrow_narrow_copy(op_info, device, dtype, requires_grad, *, is_narrow, **kwargs):
    # 定义不同形状和参数组合
    shapes_and_args = (
        ((S, S, S), 1, 2, 2),
        ((S, S, S), -1, 2, 2),
        ((S, S, S), 1, 0, 0),
        ((S, S, S), -1, 0, 0),
        ((S, S, S), 2, 1, 2),
    )

    # 遍历所有形状和参数组合
    for shape, dim, start, length in shapes_and_args:
        # 使用指定设备、数据类型、梯度设置生成张量
        tensor = make_tensor(shape, dtype=dtype, device=device, low=None, high=None,
                             requires_grad=requires_grad)
        # 生成窄化操作的样本输入
        yield SampleInput(tensor, dim, start, length)
        # 如果是窄化操作，并且起始位置参数是张量，则生成另一种样本输入
        if is_narrow:
            yield SampleInput(tensor, dim, torch.tensor(start), length)


# 生成窄化操作的参考输入数据
def reference_inputs_narrow_narrow_copy(op_info, device, dtype, requires_grad, *, is_narrow, **kwargs):
    # 调用上述生成窄化操作样本输入的函数
    yield from sample_inputs_narrow_narrow_copy(op_info, device, dtype, requires_grad, is_narrow=is_narrow, **kwargs)
    shapes_and_args = (
        # 定义不同维度的形状和参数
        # 1维
        ((M,), 0, 0, 0),    # 从左边取0个元素
        ((M,), -1, -1, 0),  # 从右边取0个元素
        ((M,), 0, 5, 3),    # 从左边取3个元素
        ((M,), 0, -5, 2),   # 从右边取2个元素
        ((M,), -1, 0, M),   # 从左边取M个元素
        ((M,), 0, -M, M),   # 从右边取M个元素

        # 2维
        ((M, S), 1, 0, 0),    # 第1维，从左边取0个元素
        ((S, M), -2, -1, 0),  # 第0维，从右边取0个元素
        ((L, S), 1, 2, 3),    # 第1维，从左边取3个元素
        ((L, S), -1, 3, 2),   # 第1维，从左边取2个元素
        ((M, L), 0, 0, M),    # 第0维，从左边取M个元素
        ((M, L), -1, -L, L),  # 第1维，从右边取L个元素

        # 3维
        ((L, M, S), 2, 0, 0),    # 第2维，从左边取0个元素
        ((M, S, L), -1, -1, 0),  # 第2维，从右边取0个元素
        ((S, L, M), 2, 0, M),    # 第2维，从左边取M个元素
        ((L, S, M), -1, -M, M),  # 第2维，从右边取M个元素
        ((S, L, M), 1, 0, 0),    # 第1维，从左边取0个元素
        ((S, L, M), 0, 2, 1),    # 第0维，从左边取1个元素
        ((M, S, M), -1, -5, 4),  # 第2维，从右边取4个元素
    )

    for shape, dim, start, length in shapes_and_args:
        # 使用给定参数创建一个张量
        tensor = make_tensor(shape, dtype=dtype, device=device, low=None, high=None,
                             requires_grad=requires_grad)
        # 生成一个 SampleInput 实例并返回
        yield SampleInput(tensor, dim, start, length)
        # 如果是 narrow 操作，也允许 start 参数为一个张量
        if is_narrow:
            yield SampleInput(tensor, dim, torch.tensor(start), length)
# 定义一个生成器函数，用于生成错误输入的样本
def error_inputs_narrow_narrow_copy(op_info, device, *, is_narrow, is_ref):
    # 使用 functools.partial 创建一个部分应用了 make_tensor 函数的新函数 make_arg，设定了 device 和 dtype
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 生成一个针对 0 维张量的错误输入样本
    yield ErrorInput(SampleInput(make_arg(()), 0, 0, 1),
                     error_type=RuntimeError,
                     error_regex=r"narrow\(\) cannot be applied to a 0-dim tensor\.")

    # 如果不是 narrow 和不是 ref，并且设备类型为 'cpu'，则生成特定错误输入样本
    if not is_narrow and not is_ref and torch.device(device).type == 'cpu':
        # narrow_copy_dense_cpu_out
        yield ErrorInput(SampleInput(make_arg((M, S, L)), 3, 0, 0),
                         error_type=RuntimeError,
                         error_regex=r"Expected dim < static_cast<int64_t>\(self_sizes.size\(\)\) to be true, but got false\.")
    else:
        # 否则生成一般的索引错误输入样本
        yield ErrorInput(SampleInput(make_arg((M, S, L)), 3, 0, 0),
                         error_type=IndexError,
                         error_regex=r"Dimension out of range \(expected to be in range of \[-3, 2\], but got 3\)")

    # 生成一个负索引的错误输入样本
    yield ErrorInput(SampleInput(make_arg((L, S, M)), -4, 0, 0),
                     error_type=IndexError,
                     error_regex=r"Dimension out of range \(expected to be in range of \[-3, 2\], but got -4\)")

    # 生成一个超出起始索引界限的错误输入样本
    yield ErrorInput(SampleInput(make_arg((L, M, S)), 1, M + 1, 0),
                     error_type=IndexError,
                     error_regex=r"start out of range \(expected to be in range of \[-10, 10\], but got 11\)")

    # 生成一个负起始索引的错误输入样本
    yield ErrorInput(SampleInput(make_arg((L, M, S)), 1, -M - 1, 0),
                     error_type=IndexError,
                     error_regex=r"start out of range \(expected to be in range of \[-10, 10\], but got -11\)")

    # 生成一个超出长度界限的错误输入样本
    yield ErrorInput(SampleInput(make_arg((S, L, M)), 2, 0, M + 1),
                     error_type=RuntimeError,
                     error_regex=r"start \(0\) \+ length \(11\) exceeds dimension size \(10\)\.")

    # 如果不是 narrow 和不是 ref，并且设备类型为 'cpu'，则生成特定错误输入样本
    if not is_narrow and not is_ref and torch.device(device).type == 'cpu':
        # narrow_copy_dense_cpu_out
        yield ErrorInput(SampleInput(make_arg((M,)), 0, 0, -1),
                         error_type=RuntimeError,
                         error_regex=r"start \(0\) \+ length \(-1\) exceeds dimension size \(10\)\.")
    else:
        # 否则生成一般的运行时错误输入样本
        yield ErrorInput(SampleInput(make_arg((M,)), 0, 0, -1),
                         error_type=RuntimeError,
                         error_regex=r"narrow\(\): length must be non-negative\.")

    # 测试 XLA 添加的张量重载，要求起始索引为 0 维整数张量。narrow_copy 不支持此重载。
    # https://github.com/pytorch/pytorch/issues/31558
    # 如果条件 is_narrow 为真，则执行以下代码块
    if is_narrow:
        # 生成一个错误输入的示例，其中：
        # 创建一个 SampleInput 对象，包含参数 (L, M, S) 和 1，以及参数 S（类型为 torch.int）
        # 用 RuntimeError 类型表示错误
        # 使用正则表达式 r"start must be an 0-dim integral Tensor\." 匹配错误信息
        yield ErrorInput(SampleInput(make_arg((L, M, S)), 1, make_arg(S, dtype=torch.int), 2),
                         error_type=RuntimeError,
                         error_regex=r"start must be an 0-dim integral Tensor\.")

        # 生成一个错误输入的示例，其中：
        # 创建一个 SampleInput 对象，包含参数 (L, M, S) 和 -3，以及参数 ()（类型为 torch.bool）
        # 用 RuntimeError 类型表示错误
        # 使用正则表达式 r"start must be an 0-dim integral Tensor\." 匹配错误信息
        yield ErrorInput(SampleInput(make_arg((L, M, S)), -3, make_arg((), dtype=torch.bool), 3),
                         error_type=RuntimeError,
                         error_regex=r"start must be an 0-dim integral Tensor\.")
def sample_trapezoid(op_info, device, dtype, requires_grad, **kwargs):
    # 定义多个输入形状、参数和关键字参数的组合列表
    y_shape_x_shape_and_kwargs = [
        ((2, 3), (2, 3), {}),        # 示例1：两个形状为 (2, 3) 的张量，无额外参数
        ((2, 3), (2, 3), {'dim': 1}),    # 示例2：一个形状为 (2, 3) 的张量和一个维度参数为 1
        ((6,), (6,), {}),            # 示例3：两个形状为 (6,) 的张量，无额外参数
        ((6,), None, {}),            # 示例4：一个形状为 (6,) 的张量，一个为 None，无额外参数
        # 当 'trapezoid' 被空输入调用时，不产生需要梯度的输出
        # 参见 Issue #{61619}
        # ((6,0), (6,0), {}),
        ((2, 3), (1, 3), {}),        # 示例5：一个形状为 (2, 3) 的张量和一个形状为 (1, 3) 的张量，无额外参数
        ((3, 3), (3, 3), {}),        # 示例6：两个形状为 (3, 3) 的张量，无额外参数
        ((3, 3), (3, 3), {'dim': -2}),    # 示例7：两个形状为 (3, 3) 的张量，一个维度参数为 -2
        ((5,), None, {'dx': 2.0}),    # 示例8：一个形状为 (5,) 的张量，一个额外参数 dx 为 2.0
        ((2, 2), None, {'dx': 3.0})    # 示例9：一个形状为 (2, 2) 的张量，一个额外参数 dx 为 3.0
    ]
    # 创建张量的部分函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, low=None, high=None,
                       requires_grad=requires_grad)
    # 遍历每个组合并生成样本输入
    for y_shape, x_shape, kwarg in y_shape_x_shape_and_kwargs:
        y_tensor = make_arg(y_shape)
        if x_shape is not None:
            x_tensor = make_arg(x_shape)
            yield SampleInput(y_tensor, x_tensor, **kwarg)
        else:
            yield SampleInput(y_tensor, **kwarg)


def sample_cumulative_trapezoid(op_info, device, dtype, requires_grad, **kwargs):
    # 定义多个输入形状、参数和关键字参数的组合列表
    y_shape_x_shape_and_kwargs = [
        ((2, 3), (2, 3), {}),        # 示例1：两个形状为 (2, 3) 的张量，无额外参数
        ((2, 3), (2, 3), {'dim': 1}),    # 示例2：一个形状为 (2, 3) 的张量和一个维度参数为 1
        ((6,), (6,), {}),            # 示例3：两个形状为 (6,) 的张量，无额外参数
        ((6,), None, {}),            # 示例4：一个形状为 (6,) 的张量，一个为 None，无额外参数
        # 当 'cumulative_trapezoid' 被空输入调用时，不产生需要梯度的输出
        # 参见 Issue #{61619}
        # ((6,0), (6,0), {}),
        ((2, 3), (1, 3), {}),        # 示例5：一个形状为 (2, 3) 的张量和一个形状为 (1, 3) 的张量，无额外参数
        ((3, 3), (3, 3), {}),        # 示例6：两个形状为 (3, 3) 的张量，无额外参数
        ((3, 3), (3, 3), {'dim': -2}),    # 示例7：两个形状为 (3, 3) 的张量，一个维度参数为 -2
        ((5,), None, {'dx': 2.0}),    # 示例8：一个形状为 (5,) 的张量，一个额外参数 dx 为 2.0
        ((2, 2), None, {'dx': 3.0})    # 示例9：一个形状为 (2, 2) 的张量，一个额外参数 dx 为 3.0
    ]
    # 创建张量的部分函数
    make_arg = partial(make_tensor, device=device, dtype=dtype,
                       requires_grad=requires_grad, low=None, high=None)
    # 遍历每个组合并生成样本输入
    for y_shape, x_shape, kwarg in y_shape_x_shape_and_kwargs:
        y_tensor = make_arg(y_shape)
        if x_shape is not None:
            x_tensor = make_arg(x_shape)
            yield SampleInput(y_tensor, x_tensor, **kwarg)
        else:
            yield SampleInput(y_tensor, **kwarg)


def sample_unsqueeze(op_info, device, dtype, requires_grad, **kwargs):
    # 定义多个形状和轴的组合列表
    shapes_and_axes = [
        ((3, 4, 5), 0),     # 示例1：形状为 (3, 4, 5) 的张量，在轴 0 上进行 unsqueeze
        ((3, 4, 5), 1),     # 示例2：形状为 (3, 4, 5) 的张量，在轴 1 上进行 unsqueeze
        ((3, 4, 5), 3),     # 示例3：形状为 (3, 4, 5) 的张量，在轴 3 上进行 unsqueeze
        ((3, 4, 5), -1),    # 示例4：形状为 (3, 4, 5) 的张量，在轴 -1 上进行 unsqueeze
        ((3, 4, 5), -3),    # 示例5：形状为 (3, 4, 5) 的张量，在轴 -3 上进行 unsqueeze
        ((), 0),            # 示例6：形状为空的张量，在轴 0 上进行 unsqueeze
        ((), -1),           # 示例7：形状为空的张量，在轴 -1 上进行 unsqueeze
        ((1,), 0),          # 示例8：形状为 (1,) 的张量，在轴 0 上进行 unsqueeze
        ((1,), -1),         # 示例9：形状为 (1,) 的张量，在轴 -1 上进行 unsqueeze
    ]

    # 遍历每个形状和轴的组合并生成样本输入
    for shape, axis in shapes_and_axes:
        tensor = make_tensor(shape, dtype=dtype, device=device, low=None, high=None,
                             requires_grad=requires_grad)
        yield SampleInput(tensor, axis)


def sample_inputs_nn_unfold(op_info, device, dtype, requires_grad, **kwargs):
    shapes = ((0, 1, 5, 5), (2, 3, 5, 5))
    kernel_sizes = (2, (2, 2), (2, 3))
    dilations = (1, 2, (1, 2))
    paddings = (0, 1, (1, 2))
    strides = (1, 2, (1, 2))

    # 组合所有可能的输入形状、核大小、膨胀、填充和步幅
    cases = product(shapes, kernel_sizes, dilations, paddings, strides)
    # 创建张量的部分函数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 对于每个测试用例中的形状、卷积核大小、膨胀率、填充、步长，逐一进行迭代
    for shape, kernel_size, dilation, padding, stride in cases:
        # 创建一个输入张量，根据当前形状
        tensor = make_arg(shape)
        # 生成一个 SampleInput 对象，包括当前张量及其余的卷积参数
        yield SampleInput(tensor, kernel_size, dilation, padding, stride)

    # 使用默认参数生成一个 SampleInput 对象
    yield SampleInput(make_arg((1, 1, 5, 5)), (3, 3))
def sample_inputs_squeeze(op_info, device, dtype, requires_grad, **kwargs):
    # 定义不同形状和参数的示例元组
    shapes_and_args = (
        ((S, 1, S, 1), ()),                # 示例1：形状为(S, 1, S, 1)，无参数
        ((1, 1, 1, 1), ()),                # 示例2：形状为(1, 1, 1, 1)，无参数
        ((1, 1, 1, 1), (0,)),              # 示例3：形状为(1, 1, 1, 1)，参数为(0,)
        ((S, 1, S, 1), (1,)),              # 示例4：形状为(S, 1, S, 1)，参数为(1,)
        ((S, 1, S, 1), (-1,)),             # 示例5：形状为(S, 1, S, 1)，参数为(-1,)
        ((S, 1, S, 1), (2,)),              # 示例6：形状为(S, 1, S, 1)，参数为(2,)
        ((S, 1, S, 1), (-2,)),             # 示例7：形状为(S, 1, S, 1)，参数为(-2,)
        ((), (0,)),                       # 示例8：形状为()，参数为(0,)
    )

    for shape, args in shapes_and_args:
        # 创建指定形状的张量，用make_tensor函数生成
        tensor = make_tensor(shape, dtype=dtype, device=device, low=None, high=None,
                             requires_grad=requires_grad)
        # 使用yield生成SampleInput对象，传入张量和对应的参数
        yield SampleInput(tensor, args=args)


def sample_inputs_squeeze_multiple(op_info, device, dtype, requires_grad, **kwargs):
    # 定义不同形状和维度参数的示例元组
    shapes_and_args = (
        ((1, 1, 1, 1), ()),                # 示例1：形状为(1, 1, 1, 1)，无参数
        ((S, 1, S, 1), (1,)),              # 示例2：形状为(S, 1, S, 1)，参数为(1,)
        ((S, 1, S, 1), (-1,)),             # 示例3：形状为(S, 1, S, 1)，参数为(-1,)
        ((S, 1, S, 1), (1, 3)),            # 示例4：形状为(S, 1, S, 1)，参数为(1, 3)
        ((S, 1, S, 1), (1, 2,)),           # 示例5：形状为(S, 1, S, 1)，参数为(1, 2)
        ((), (0,)),                       # 示例6：形状为()，参数为(0,)
    )

    for shape, dims in shapes_and_args:
        # 创建指定形状的张量，用make_tensor函数生成
        tensor = make_tensor(shape, dtype=dtype, device=device, low=None, high=None,
                             requires_grad=requires_grad)
        # 使用yield生成SampleInput对象，传入张量和对应的维度参数
        yield SampleInput(tensor, dims)


def _squeeze_ref(x, axis=None):
    # NumPy不允许压缩标量
    if x.ndim == 0:
        return x

    if isinstance(axis, Sequence):
        # NumPy不允许指定非单一维度
        axis = tuple(a for a in axis if x.shape[a] == 1)

    if isinstance(axis, int) and x.shape[axis] != 1:
        return x

    # 调用NumPy的squeeze函数来压缩张量x的维度
    return np.squeeze(x, axis)


def sample_inputs_nn_pad(op_info, device, dtype, requires_grad, mode, **kwargs):
    # 确保mode参数是有效的填充模式
    assert mode in ('constant', 'reflect', 'replicate', 'circular')

    if mode in ['reflect', 'replicate']:
        cases: tuple = (  # 忽略
            ((1, 3), (1, 2)),
            ((1, 3), (0, 1)),
            ((0, 3, 3), (1, 2)),
            ((0, 3, 3), (0, 1)),
            ((1, 3, 3), (1, 2)),
            ((1, 3, 3), (0, 1)),
            ((1, 3, 3), (0, 2, 0, 1)),
            ((0, 3, 3, 3), (0, 2, 0, 1)),
            ((3, 3, 5, 5), (0, 2, 0, 1)),
            ((3, 3, 5, 5), (1, 1, 1, 1, 1, 1)),
            ((1, 3, 3, 3, 3), (1, 1, 1, 1, 1, 1)),
            ((1, 3, 4, 4), (-1, 1, -2, 1)),
        )
    elif mode == 'constant':
        cases = (
            ((1, 3), (1, 2)),  # 定义常量模式下的填充案例，包括形状和填充值
            ((1, 3), (0, 1)),  # 同上，不同的填充方式
            ((1, 3), (0, 2, 0, 1)),  # 同上，使用更复杂的填充方式
            ((0, 3, 3), (1, 2)),  # 同上，不同的形状和填充值
            ((0, 3, 3), (0, 1)),  # 同上，不同的填充方式
            ((0, 3, 3), (0, 2, 0, 1)),  # 同上，使用更复杂的填充方式
            ((0, 3, 3), (1, 1, 1, 1, 1, 1)),  # 同上，更复杂的填充方式
            ((1, 3, 3), (1, 2)),  # 同上，不同的形状和填充值
            ((1, 3, 3), (0, 1)),  # 同上，不同的填充方式
            ((1, 3, 3), (0, 2, 0, 1)),  # 同上，使用更复杂的填充方式
            ((1, 3, 3), (1, 1, 1, 1, 1, 1)),  # 同上，更复杂的填充方式
            ((0, 3, 3, 3), (1, 2)),  # 同上，不同的形状和填充值
            ((0, 3, 3, 3), (0, 1)),  # 同上，不同的填充方式
            ((0, 3, 3, 3), (0, 2, 0, 1)),  # 同上，使用更复杂的填充方式
            ((0, 3, 3, 3), (1, 1, 1, 1, 1, 1)),  # 同上，更复杂的填充方式
            ((3, 3, 5, 5), (1, 2)),  # 同上，不同的形状和填充值
            ((3, 3, 5, 5), (0, 1)),  # 同上，不同的填充方式
            ((3, 3, 5, 5), (0, 2, 0, 1)),  # 同上，使用更复杂的填充方式
            ((3, 3, 5, 5), (1, 1, 1, 1, 1, 1)),  # 同上，更复杂的填充方式
            ((1, 3, 3, 3, 3), (1, 2)),  # 同上，不同的形状和填充值
            ((1, 3, 3, 3, 3), (0, 1)),  # 同上，不同的填充方式
            ((1, 3, 3, 3, 3), (0, 2, 0, 1)),  # 同上，使用更复杂的填充方式
            ((1, 3, 3, 3, 3), (1, 1, 1, 1, 1, 1)),  # 同上，更复杂的填充方式
            ((1, 3, 4, 4), (-1, 1, -2, 1)),  # 同上，不同的形状和填充值
        )
    else:  # mode == 'circular'
        if dtype == torch.bool:
            # 如果数据类型是布尔型，使用特定的填充案例
            # 在 ASAN 上，test_dtypes 失败，对于案例 ab
            # 运行时错误：加载值 190，这不是布尔类型 'bool' 的有效值
            # 参考：https://github.com/pytorch/pytorch/pull/62814#issuecomment-894156562
            # 参考问题：https://github.com/pytorch/pytorch/issues/63034
            cases = (
                ((2, 3, 3), (1, 2)),  # 定义布尔型数据的填充案例，包括形状和填充值
                ((1, 3, 3), (1, 2)),  # 同上，不同的形状和填充值
            )
        else:
            cases = (
                ((0, 3, 3), (1, 2)),  # 定义环绕模式下的填充案例，包括形状和填充值
                ((0, 3, 3), (0, 1)),  # 同上，不同的填充方式
                ((1, 3, 3), (1, 2)),  # 同上，不同的形状和填充值
                ((1, 3, 3), (0, 1)),  # 同上，不同的填充方式
                ((0, 3, 3, 3), (0, 2, 0, 1)),  # 同上，更复杂的填充方式
                ((3, 3, 5, 5), (0, 2, 0, 1)),  # 同上，更复杂的填充方式
                ((1, 3, 3, 3, 3), (1, 1, 1, 1, 1, 1)),  # 同上，更复杂的填充方式
                ((1, 3, 4, 4), (-1, 1, -2, 1)),  # 同上，不同的形状和填充值
            )

    make_inp = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    if mode == 'constant':
        # 如果模式是常量，则生成一个默认参数的输入样本
        yield SampleInput(make_inp((1, 3, 3)), args=((2, 2),))

    if mode in ['reflect', 'replicate', 'circular']:
        # 如果模式是反射、复制或环绕，则遍历所有案例生成输入样本
        for shape, pad in cases:
            yield SampleInput(make_inp(shape), args=(pad, mode))
    else:  # mode == 'constant'
        # 如果模式是常量，则生成多个带不同填充值的输入样本
        for pad_value in (1., 2.):
            for shape, pad in cases:
                yield SampleInput(make_inp(shape), args=(pad, mode, pad_value))
def sample_inputs_nn_pad_replicate_negative(op_info, device, dtype, requires_grad, **kwargs):
    # 定义不同的输入形状和填充值
    cases: tuple = (
        ((5, 3, 4, 4), (-4, 5, 0, 0)),
        ((6, 2, 4, 4), (0, 0, 2, -4)),
        ((5, 6, 4, 4), (5, -4, -4, 3)),
        ((4, 2, 5, 5), (-2, -1, 4, 6)),
        ((2, 6, 5, 5), (8, -1, -1, -3)),
        ((8, 1, 5, 5), (-2, -1, -1, -3)),
    )
    # 创建一个函数，用于生成特定设备、数据类型、梯度属性的张量
    make_inp = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 遍历每个输入形状和填充值的组合
    for shape, pad in cases:
        # 生成样本输入，使用指定的填充策略为'replicate'
        yield SampleInput(make_inp(shape), args=(pad, 'replicate'))


def sample_inputs_constant_pad_nd(op_info, device, dtype, *args, **kwargs):
    # 继承自 nn.pad 的样本输入，但调整以适应 constant_pad_nd 的接口
    nn_samples = sample_inputs_nn_pad(op_info, device, dtype, *args,
                                      mode='constant', **kwargs)

    # 引入 torch._prims_common 中的 dtype_to_type 函数
    from torch._prims_common import dtype_to_type
    # 将数据类型转换为相应的标量类型
    scalar_type = dtype_to_type(dtype)

    # 定义函数，根据值参数来生成样本输入
    def drop_mode_argument(input, pad, mode=None, value=None):
        if value is None:
            return SampleInput(input, args=(pad,))
        else:
            # 将值参数转换为正确的标量类型后生成样本输入
            return SampleInput(input, args=(pad, scalar_type(value)))

    # 遍历 nn_samples 中的每个样本
    for sample in nn_samples:
        yield drop_mode_argument(sample.input, *sample.args, **sample.kwargs)


def sample_inputs_repeat_interleave(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个函数，用于生成指定设备、数据类型、梯度属性的张量
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 生成空张量的样本输入，重复次数为2
    yield SampleInput(make_input(()), repeats=2)
    # 生成指定形状的张量的样本输入，重复次数为2
    yield SampleInput(make_input((2, 3, 4)), repeats=2)
    # 生成指定形状的张量的样本输入，重复次数为2，沿着第一维度重复
    yield SampleInput(make_input((2, 3, 4)), repeats=2, dim=1)
    # 生成指定形状的张量的样本输入，重复次数为从0到2，沿着第一维度重复
    yield SampleInput(make_input((2, 3, 4)), repeats=torch.arange(3, device=device), dim=1)


def sample_inputs_stft(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个生成指定形状的张量的函数
    def mt(shape, **kwargs):
        return make_tensor(shape, device=device, dtype=dtype,
                           requires_grad=requires_grad, **kwargs)

    # 生成长度为100的张量的样本输入，使用n_fft为10，返回复数值
    yield SampleInput(mt(100), n_fft=10, return_complex=True)
    # 生成长度为100的张量的样本输入，使用n_fft为10，返回实数值
    yield SampleInput(mt(100), n_fft=10, return_complex=False)
    # 如果数据类型为复数型，则生成长度为100的张量的样本输入，使用n_fft为10
    if dtype.is_complex:
        yield SampleInput(mt(100), n_fft=10)

    # 遍历布尔值为False和True的情况
    for center in [False, True]:
        # 生成长度为10的张量的样本输入，使用n_fft为7，是否居中取决于center，返回复数值
        yield SampleInput(mt(10), n_fft=7, center=center, return_complex=True)
        # 生成形状为(10, 100)的张量的样本输入，使用n_fft为16，hop_length为4，是否居中取决于center，返回复数值
        yield SampleInput(mt((10, 100)), n_fft=16, hop_length=4,
                          center=center, return_complex=True)

    # 创建形状为(16,)的窗口张量，范围在0.5到2.0之间
    window = mt(16, low=.5, high=2.0)
    # 生成形状为(2, 100)的张量的样本输入，使用n_fft为16，窗口为window，返回复数值，是否居中取决于center
    yield SampleInput(
        mt((2, 100)), kwargs=dict(n_fft=16, window=window, return_complex=True, center=center))
    # 生成形状为(3, 100)的张量的样本输入，使用n_fft为16，窗口为window，返回复数值，是否居中取决于center
    yield SampleInput(
        mt((3, 100)), kwargs=dict(n_fft=16, window=window, return_complex=True, center=center))
    # 如果数据类型不是复数型，则生成形状为(10, 100)的张量的样本输入，使用n_fft为16，窗口为window，返回复数值
    if not dtype.is_complex:
        yield SampleInput(
            mt((10, 100)), n_fft=16, window=window, onesided=False,
            return_complex=True)
# 定义函数 sample_inputs_istft，生成输入样本用于反短时傅里叶变换的测试
def sample_inputs_istft(op_info, device, dtype, requires_grad, **kwargs):
    # 创建部分函数 make_arg，用于生成具有指定设备、数据类型、梯度需求的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义内部函数 mt，用于生成张量并根据数据类型是否复数进行形状调整
    def mt(shape, **kwargs):
        real_shape = shape if dtype.is_complex else shape + (2,)
        return make_arg(real_shape, **kwargs)

    # 生成三种不同参数的 SampleInput 对象，用于测试不同的输入情况
    yield SampleInput(mt((10, 2)), kwargs=dict(n_fft=10))
    yield SampleInput(mt((6, 3)), kwargs=dict(n_fft=6, onesided=False))
    yield SampleInput(mt((6, 4)), kwargs=dict(n_fft=10, onesided=True))

    # 遍历两种 center 参数的组合，生成对应的 SampleInput 对象
    for center in [False, True]:
        yield SampleInput(mt((10, 10, 6)), kwargs=dict(n_fft=10, center=center))
        yield SampleInput(mt((1, 9, 10)), kwargs=dict(n_fft=16, hop_length=4, center=center))

    # 生成带有窗函数的 SampleInput 对象，包括复数返回情况的测试
    window = make_arg(10, low=.5, high=2.0)
    yield SampleInput(mt((10, 10, 6)), kwargs=dict(
        n_fft=10, window=window, center=center, return_complex=dtype.is_complex))
    yield SampleInput(mt((10, 10, 10)), kwargs=dict(
        n_fft=10, window=window[:8], win_length=8, center=center, return_complex=True))

    # 处理实部窗口情况的 SampleInput 对象生成
    real_window = window if not dtype.is_complex else window.real
    yield SampleInput(mt((10, 5, 6)), kwargs=dict(n_fft=8, window=real_window[:8], center=center))


# 定义函数 sample_inputs_ormqr，生成输入样本用于求解 QR 矩阵乘法的测试
def sample_inputs_ormqr(op_info, device, dtype, requires_grad, **kwargs):
    # 创建部分函数 make_input，用于生成具有指定数据类型、设备、范围的张量
    make_input = partial(make_tensor, dtype=dtype, device=device, low=-1, high=1)

    # 定义不同参数组合的迭代器，生成对应的 SampleInput 对象
    batches = [(), (0, ), (2, ), (2, 1)]
    ns = [5, 2, 0]
    tf = [True, False]
    for batch, (m, n), left, transpose in product(batches, product(ns, ns), tf, tf):
        # 生成输入矩阵，并通过 torch.geqrf 计算反射向量和 tau
        input = make_input((*batch, m, n))
        reflectors, tau = torch.geqrf(input)
        reflectors.requires_grad_(requires_grad)
        tau.requires_grad_(requires_grad)
        other_matrix_shape = (m, n) if left else (n, m)
        # 生成另一个矩阵，并设置其是否需要梯度
        other = make_input((*batch, *other_matrix_shape), requires_grad=requires_grad)
        yield SampleInput(reflectors, tau, other, left=left, transpose=transpose)


# 定义函数 sample_inputs_cholesky_solve，生成输入样本用于 Cholesky 解法的测试
def sample_inputs_cholesky_solve(op_info, device, dtype, requires_grad=False, **kwargs):
    # 生成 Cholesky 逆矩阵的输入样本
    cholesky_inverse_samples = sample_inputs_linalg_cholesky_inverse(
        op_info, device, dtype, requires_grad=False
    )

    # 遍历 Cholesky 逆矩阵的样本，并生成对应的 SampleInput 对象
    for sample in cholesky_inverse_samples:
        psd_matrix = sample.input
        # 使用 make_tensor 生成指定形状、数据类型、设备的张量，并设置其是否需要梯度
        sample.input = make_tensor(psd_matrix.shape, dtype=dtype, device=device, requires_grad=requires_grad, low=None, high=None)
        sample.args = (psd_matrix.requires_grad_(requires_grad),)
        yield sample


# 定义函数 sample_inputs_lu，生成输入样本用于 LU 分解的测试
def sample_inputs_lu(op_info, device, dtype, requires_grad=False, **kwargs):
    # 创建部分函数 make_arg，用于生成具有指定数据类型、设备、是否需要梯度的满秩矩阵
    make_arg = partial(make_fullrank_matrices_with_distinct_singular_values,
                       dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义测试的批次形状
    batch_shapes = ((), (3,), (3, 3))
    # 对于每个批量形状、获取信息的方式和大小变化的组合，生成迭代器
    for batch_shape, get_infos, size_delta in product(batch_shapes, (True, False), (-2, -1, 0, +1, +2)):
        # 构建输入的形状，将当前批量形状与给定的大小变化组合成新的形状
        shape = batch_shape + (S + size_delta, S)
        # 利用指定的形状创建输入参数
        input = make_arg(*shape)
        # 生成一个包含输入和额外参数的样本输入对象，并作为生成器的下一个元素
        yield SampleInput(input, args=(True, get_infos))
# 定义函数，生成 LU 分解的输入样本
def sample_inputs_lu_unpack(op_info, device, dtype, requires_grad=False, **kwargs):
    # 定义内部函数，用于处理输出
    def out_fn(output):
        return output[1], output[2]

    # 遍历通过 linalg_lu 函数生成的 LU 分解样本
    for lu_sample in sample_inputs_linalg_lu(op_info, device, dtype, requires_grad, **kwargs):
        # 对 LU 分解的输入数据进行 LU 分解因子化处理
        lu_data, pivots = torch.linalg.lu_factor(lu_sample.input)
        # 根据 requires_grad 参数决定是否需要设置梯度跟踪
        lu_data.requires_grad_(requires_grad)
        # 生成一个带有元数据的 SampleInput 对象，并使用定义好的输出处理函数
        yield SampleInput(lu_data, pivots).with_metadata(output_process_fn_grad=out_fn)


# 定义函数，生成 roll 操作的输入样本
def sample_inputs_roll(op_info, device, dtype, requires_grad=False, **kwargs):
    # 部分应用 make_tensor 函数，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义多种参数组合
    args = ((0, 0), (1, 2), (0, 2), (2, 0), (-1, 0), (10000, 1), (2,), ((1, 2, -1), (0, 1, 2)))

    # 遍历参数组合并生成 SampleInput 对象
    for arg in args:
        yield SampleInput(make_arg((0, 0, 0)), args=arg)
        yield SampleInput(make_arg((S, S, S)), args=arg)

    # 生成一个标量张量的 SampleInput 对象
    yield SampleInput(make_arg(()), args=(10, ))


# 定义函数，生成 roll 操作的错误输入样本
def error_inputs_roll(op_info, device, **kwargs):
    # 部分应用 make_tensor 函数，用于生成 float32 类型的张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 定义错误消息
    err_msg1 = "`shifts` required"
    # 创建一个 SampleInput 对象，用于测试错误情况
    s1 = SampleInput(make_arg((S,)), ())
    yield ErrorInput(s1, error_regex=err_msg1)

    err_msg2 = ("shifts and dimensions must align")
    s2 = SampleInput(make_arg((S, S)), (2, 1), 0)
    yield ErrorInput(s2, error_regex=err_msg2)

    err_msg3 = ("out of range")
    s3 = SampleInput(make_arg((S, )), 0, 2)
    yield ErrorInput(s3, error_regex=err_msg3, error_type=IndexError)

    err_msg4 = ("Dimension specified as 0")
    s4 = SampleInput(make_arg(()), 0, 0)
    yield ErrorInput(s4, error_regex=err_msg4, error_type=IndexError)


# 定义函数，生成 rot90 操作的输入样本
def sample_inputs_rot90(op_info, device, dtype, requires_grad=False, **kwargs):
    # 部分应用 make_tensor 函数，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 生成多种参数组合的迭代器
    args = itertools.product(range(-5, 6), [(0, 1), (1, 2), (1, -1)])

    # 生成一个标准形状的 SampleInput 对象
    yield SampleInput(make_arg((S, S, S)))
    # 遍历参数组合并生成相应的 SampleInput 对象
    for arg in args:
        yield SampleInput(make_arg((S, S, S)), args=arg)


# 定义函数，生成 rot90 操作的错误输入样本
def error_inputs_rot90(op_info, device, **kwargs):
    # 部分应用 make_tensor 函数，用于生成 float32 类型的张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 定义错误消息
    err_msg1 = "expected total rotation dims"
    s1 = SampleInput(make_arg((S, S)), dims=(0,))
    yield ErrorInput(s1, error_regex=err_msg1)

    err_msg2 = "expected total dims >= 2"
    s2 = SampleInput(make_arg((S,)))
    yield ErrorInput(s2, error_regex=err_msg2)

    err_msg3 = "expected rotation dims to be different"
    s3 = SampleInput(make_arg((S, S)), dims=(1, 1))
    yield ErrorInput(s3, error_regex=err_msg3)


# 定义函数，生成标准差和方差操作的输入样本
def sample_inputs_std_var(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用 make_tensor 函数，用于生成指定形状的张量
    tensor_nd = partial(make_tensor, (S, S, S), device=device, dtype=dtype,
                        requires_grad=requires_grad)
    tensor_1d = partial(make_tensor, (S,), device=device, dtype=dtype,
                        requires_grad=requires_grad)

    # 生成标准形状的 SampleInput 对象
    yield SampleInput(tensor_nd())
    # 生成另一种形状的 SampleInput 对象
    yield SampleInput(tensor_nd(), dim=1)
    # 生成一个带有默认参数的 SampleInput 实例，tensor 是一个空的张量（默认维度为 0）
    yield SampleInput(tensor_nd(), dim=1, unbiased=True, keepdim=True)
    
    # 生成一个带有默认参数的 SampleInput 实例，tensor 是一个一维张量（维度为 1）
    yield SampleInput(tensor_1d(), dim=0, unbiased=True, keepdim=True)
    
    # 生成一个带有默认参数的 SampleInput 实例，tensor 是一个一维张量（维度为 1），不使用无偏估计，不保持维度
    yield SampleInput(tensor_1d(), dim=0, unbiased=False, keepdim=False)
    
    # 生成一个带有默认参数的 SampleInput 实例，tensor 是一个多维张量（默认维度为 0），指定维度为元组 (1,)
    yield SampleInput(tensor_nd(), dim=(1,), correction=1.3)
    
    # 生成一个带有默认参数的 SampleInput 实例，tensor 是一个多维张量（默认维度为 0），指定维度为元组 (1,)，使用 S 的一半作为修正值
    yield SampleInput(tensor_nd(), dim=(1,), correction=S // 2)
    
    # 生成一个带有默认参数的 SampleInput 实例，tensor 是一个多维张量（默认维度为 0），不指定维度，修正值为 0，保持维度
    yield SampleInput(tensor_nd(), dim=None, correction=0, keepdim=True)
    
    # 生成一个带有默认参数的 SampleInput 实例，tensor 是一个多维张量（默认维度为 0），不指定维度，不指定修正值
    yield SampleInput(tensor_nd(), dim=None, correction=None)
    
    # 生成一个带有默认参数的 SampleInput 实例，tensor 是一个多维张量（默认维度为 0），修正值为 0，保持维度
    yield SampleInput(tensor_nd(), correction=0, keepdim=True)
    
    # 生成一个带有默认参数的 SampleInput 实例，生成一个 3x4x5 的张量，指定设备和数据类型，是否需要梯度不确定
    yield SampleInput(make_tensor(3, 4, 5, device=device, dtype=dtype, requires_grad=requires_grad), dim=-3)
def sample_inputs_std_var_unbiased(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数创建一个函数make_arg，用于创建张量，并指定设备、数据类型和梯度需求
    make_arg = partial(make_tensor, device=device, dtype=dtype,
                       requires_grad=requires_grad)

    # 测试 var_mean(Tensor self, bool unbiased=True) -> (Tensor, Tensor) 函数的样本输入
    yield SampleInput(make_arg((S, S)), True)
    yield SampleInput(make_arg((S,)), False)


def _generate_correlation_inputs(device, dtype, requires_grad, **kwargs):
    # 定义不同形状的张量输入样本，以生成相关性函数的输入
    shapes = [(2,), (1, 2), (3, 2), (2, 3)]
    for shape in shapes:
        yield make_tensor(shape, dtype=dtype, device=device, requires_grad=requires_grad)


def sample_inputs_corrcoef(op_info, device, dtype, requires_grad, **kwargs):
    # 生成用于相关系数计算的输入样本
    return (SampleInput(t) for t in _generate_correlation_inputs(device, dtype, requires_grad))


def sample_inputs_cov(op_info, device, dtype, requires_grad, **kwargs):
    # 生成用于协方差计算的输入样本
    for t in _generate_correlation_inputs(device, dtype, requires_grad):
        yield SampleInput(t)
        # 确定观测次数，如果张量维度小于2，则为元素个数，否则为第二维度的大小
        num_observations = t.numel() if t.ndimension() < 2 else t.size(1)
        # 创建权重张量fweights，用于协方差计算，数据类型为整数类型
        fweights = make_tensor((num_observations,), dtype=torch.int, device=device, low=1, high=10)
        # 创建权重张量aweights，用于协方差计算，数据类型为浮点数类型，需求是否需要梯度根据输入而定
        aweights = make_tensor((num_observations,), dtype=torch.float, device=device, low=0, high=1, requires_grad=requires_grad)
        # 对于每一种修正（correction）、fweights权重和aweights权重的组合，生成输入样本
        for correction, fw, aw in product(range(num_observations), [None, fweights], [None, aweights]):
            yield SampleInput(t.clone().requires_grad_(requires_grad),
                              correction=correction, fweights=fw, aweights=aw)


def error_inputs_cov(op_info, device, **kwargs):
    # 创建一个形状为(S,)的随机张量a，用于生成协方差函数的错误输入样本
    a = torch.rand(S, device=device)
    # 生成期望引发错误的错误输入样本，检查输入维度超过两个维度的情况
    yield ErrorInput(
        SampleInput(torch.rand(S, S, S, device=device)),
        error_regex="expected input to have two or fewer dimensions")
    # 生成期望引发错误的错误输入样本，检查fweights张量超过一维的情况
    yield ErrorInput(
        SampleInput(a, fweights=torch.rand(S, S, device=device)),
        error_regex="expected fweights to have one or fewer dimensions")
    # 生成期望引发错误的错误输入样本，检查aweights张量超过一维的情况
    yield ErrorInput(
        SampleInput(a, aweights=torch.rand(S, S, device=device)),
        error_regex="expected aweights to have one or fewer dimensions")
    # 生成期望引发错误的错误输入样本，检查fweights张量不是整数类型的情况
    yield ErrorInput(
        SampleInput(a, fweights=torch.rand(S, device=device)),
        error_regex="expected fweights to have integral dtype")
    # 生成期望引发错误的错误输入样本，检查aweights张量不是浮点数类型的情况
    yield ErrorInput(
        SampleInput(a, aweights=torch.tensor([1, 1], device=device)),
        error_regex="expected aweights to have floating point dtype")
    # 生成期望引发错误的错误输入样本，检查fweights张量与输入张量元素个数不匹配的情况
    yield ErrorInput(
        SampleInput(a, fweights=torch.tensor([1], device=device)),
        error_regex="expected fweights to have the same numel")
    # 生成期望引发错误的错误输入样本，检查aweights张量与输入张量元素个数不匹配的情况
    yield ErrorInput(
        SampleInput(a, aweights=torch.rand(1, device=device)),
        error_regex="expected aweights to have the same numel")
    # 生成期望引发错误的错误输入样本，检查fweights张量包含负数的情况
    yield ErrorInput(
        SampleInput(a, fweights=torch.tensor([-1, -2, -3, -4 , -5], device=device)),
        error_regex="fweights cannot be negative")
    # 使用生成器函数 yield 返回一个 ErrorInput 对象，其中 SampleInput 的第一个参数为 a，
    # 第二个参数为一个在设备上的张量，张量的值为 [-1., -2., -3., -4., -5.]，
    # 这个张量表示权重，必须为非负数。
    yield ErrorInput(
        SampleInput(a, aweights=torch.tensor([-1., -2., -3., -4., -5.], device=device)),
        error_regex="aweights cannot be negative")
# 生成带有指定参数的张量样本，用于变换操作的测试
def sample_inputs_permute(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分函数，用于生成指定设备、数据类型、是否需要梯度的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 不同形状和参数的测试用例
    cases = [((1, 2, 3, 4), (0, 2, 3, 1)),
             ((1, 2, 3, 4), (0, -2, -1, 1)),
             ((), ()),
             ((1, 2, 3, 4), (2, 1, 3, 0))]

    # 遍历测试用例，生成样本输入
    for shape, args in cases:
        yield SampleInput(make_arg(shape), args=(args,))

# 生成变换操作的参考输入样本
def reference_inputs_permute(op, device, dtype, requires_grad, **kwargs):
    # 从样本输入生成变换操作的参考输入
    yield from sample_inputs_permute(op, device, dtype, requires_grad, **kwargs)

    # 创建一个部分函数，用于生成指定设备、数据类型、是否需要梯度的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 不同形状和参数的测试用例
    cases = (
        ((), ()),
        ((1,), (0,)),
        ((2, 2), (1, 0)),
        ((2, 2), (0, 1)),
        ((2, 0, 1), (0, 2, 1)),
        ((3, 4, 2), (2, 1, 0)),
        ((3, 4, 2), (1, 0, 2)),
        ((3, 4, 2), (0, 1, 2)),
    )

    # 遍历测试用例，生成参考输入
    # 包含了复杂的置换和非连续置换
    for shape, permutation in cases:
        for p in itertools.permutations(permutation):
            # 生成张量并进行置换，生成样本输入
            a = make_arg(shape).permute(p)
            yield SampleInput(a, args=(permutation,))

            # 生成非连续张量并进行置换，生成样本输入
            a = make_arg(shape, noncontiguous=True).permute(p)
            yield SampleInput(a, args=(permutation,))

# 生成软阈值收缩操作的错误输入样本
def error_inputs_softshrink(op, device, **kwargs):
    # 生成一个错误输入，测试软阈值操作的异常情况
    yield ErrorInput(SampleInput(make_tensor((1,), dtype=torch.float, device=device), kwargs={"lambd": -0.5}),
                     error_regex="lambda must be greater or equal to 0, but found to be -0.5")

# 生成软阈值收缩操作的样本输入
def sample_inputs_softshrink(op_info, device, dtype, requires_grad=False, **kwargs):
    # 创建一个部分函数，用于生成指定设备、数据类型、是否需要梯度的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 添加额外的样本以检查比默认值更大的lambd值（默认值已经由sample_inputs_elementwise_unary检查）
    for lbda in (0., 0.5):
        yield SampleInput(make_arg(S, S), kwargs={"lambd": lbda})

    # 从元素级一元操作的样本输入中继续生成
    yield from sample_inputs_elementwise_unary(op_info, device, dtype, requires_grad)

# 生成硬阈值收缩操作的样本输入
def sample_inputs_hardshrink(op_info, device, dtype, requires_grad=False, **kwargs):
    # 创建一个部分函数，用于生成指定设备、数据类型、是否需要梯度的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 添加额外的样本以检查不同于默认值的lambd值（默认值已经由sample_inputs_elementwise_unary检查）
    # 注意，与softshrink不同，hardshrink允许lambd为负值
    for lbda in (-0.5, 0., 0.5):
        yield SampleInput(make_arg(S, S), kwargs={"lambd": lbda})

    # 从元素级一元操作的样本输入中继续生成
    yield from sample_inputs_elementwise_unary(op_info, device, dtype, requires_grad)

# 生成硬切割操作的样本输入
def sample_inputs_hardtanh(op_info, device, dtype, requires_grad=False, **kwargs):
    # 创建一个部分函数，用于生成指定设备、数据类型、是否需要梯度的张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 添加额外的样本以检查不同于默认值的min_val和max_val值
    # （类似于软阈值收缩，但不同于默认值）
    ```
    # 对每一个 (max_val, min_val) 组合进行迭代，生成 SampleInput 对象
    for max_val, min_val in ((0.5, -0.5), (0., 0.)):
        # 使用给定的参数创建 SampleInput 对象，其中 S 是一个参数
        yield SampleInput(make_arg(S, S), kwargs={"min_val": min_val, "max_val": max_val})

    # 调用另一个函数，生成更多的 SampleInput 对象，并将其 yield 出来
    yield from sample_inputs_elementwise_unary(op_info, device, dtype, requires_grad)
def error_inputs_hardtanh(op_info, device, **kwargs):
    # 测试当 min_val > max_val 时，hardtanh 是否会报错
    yield ErrorInput(SampleInput(make_tensor((1,), dtype=torch.float, device=device), kwargs={"min_val": 0.5, "max_val": -0.5}),
                     error_type=ValueError, error_regex="min_val cannot be greater than max_val")

def sample_inputs_einsum(op_info, device, dtype, requires_grad=False, **kwargs):
    def c(t):
        return t.clone().requires_grad_(requires_grad)

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    x = make_arg((3,))
    y = make_arg((4,))
    A = make_arg((2, 3,))
    B = make_arg((1, 3,))
    C = make_arg((1, 2, 3,))
    D = make_arg((1, 3, 4,))
    E = make_arg((4, 4,))
    H = make_arg((3, 3,))
    I = make_arg((1, 3, 1,))

    # 向量操作
    yield SampleInput([c(x)], 'i->')                      # 求和
    yield SampleInput([c(x), c(y)], 'i,j->ij')            # 外积

    # 矩阵操作
    yield SampleInput([c(A)], "ij->i")                    # 列求和
    yield SampleInput([c(A), c(B)], "ij,kj->ik")          # 矩阵乘法
    yield SampleInput([c(A), c(E)], "ij,Ab->ijAb")        # 矩阵外积

    # 张量操作
    yield SampleInput([c(C), c(D)], "aij,ajk->aik")       # 批量矩阵乘法
    yield SampleInput([c(D), c(E)], "aij,jk->aik")        # 张量矩阵缩并
    yield SampleInput([c(C), c(B)], "ijk,ik->j")          # 非连续操作

    # 测试对角线操作
    yield SampleInput([c(I)], 'iji->j')                   # 非连续迹

    # 测试省略号操作
    yield SampleInput([c(H)], "i...->...")
    yield SampleInput([c(C), c(x)], '...ik, ...j -> ij')


def sample_inputs_flip(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    sizes = ((S, M, S), (S, 0, M))
    all_dims = ((0, 1, 2), (0,), (0, 2), (-1,), ())

    for size, dims in product(sizes, all_dims):
        yield SampleInput(make_arg(size), kwargs={"dims": dims})

def sample_inputs_fliplr_flipud(op_info, device, dtype, requires_grad, **kwargs):
    shapes = [
        (S, M, S),
        (S, 0, M),
    ]
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    return (SampleInput(make_arg(shape, low=None, high=None)) for shape in shapes)

def error_inputs_fliplr(op, device, **kwargs):
    yield ErrorInput(SampleInput(make_tensor((1,), dtype=torch.float, device=device)),
                     error_regex="Input must be >= 2-d.")

def error_inputs_flipud(op, device, **kwargs):
    yield ErrorInput(SampleInput(make_tensor((), dtype=torch.float, device=device)),
                     error_regex="Input must be >= 1-d.")

def sample_inputs_clamp(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, low=None, high=None, requires_grad=requires_grad)
    shape = (S, M, S)
    # 生成一个样本输入对象，使用指定的形状作为参数，并传递两个相同形状的参数给函数
    yield SampleInput(make_arg(shape), args=(make_arg(shape), make_arg(shape)))
    
    # 生成一个样本输入对象，使用指定的形状作为参数，并传递两个形状切片的参数给函数
    yield SampleInput(make_arg(shape), args=(make_arg(shape[1:]), make_arg(shape[1:])))
    
    # 生成一个样本输入对象，使用指定的形状作为参数，并传递一个具有特定形状的参数给函数
    yield SampleInput(make_arg(shape), args=(make_arg((S, 1, S)),))
    
    # 生成一个样本输入对象，使用指定的形状作为参数，并传递一个参数为 None 和另一个与指定形状相同的参数给函数
    yield SampleInput(make_arg(shape), args=(None, make_arg(shape)))
    
    # 生成一个样本输入对象，使用指定的形状作为参数，并传递一个参数为指定形状的参数和另一个参数为 None 给函数
    yield SampleInput(make_arg(shape), args=(make_arg(shape), None))
# 生成器函数，用于生成按元素三元运算的输入样本
def reference_inputs_elementwise_ternary(op, device, dtype, requires_grad, *, sample_inputs_func, supports_scalars=False, **kwargs):
    # 调用外部传入的样本生成函数，并生成样本输入
    yield from sample_inputs_func(op, device, dtype, requires_grad, **kwargs)

    # 部分应用 make_tensor 函数以便稍后使用
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 部分应用 make_tensor 以创建标量张量
    make_scalar_tensor = partial(make_tensor, (), device='cpu', dtype=dtype, requires_grad=requires_grad)
    # 获取操作支持的数据类型列表
    supported_dtypes = op.supported_dtypes(device)

    # 不同的广播和非连续情况下的输入样本组合
    cases = (
        ((4, 4), (4, 4), (4, 4)),
        ((4, 4), (1, 4, 4), (4, 4)),
        ((4, 4), (1, 4, 4), (4, 1, 4)),
        ((4, 4, 1), (1, 4, 4), (4, 4)),
        ((4, 1), (1, 4, 4), (1, 4)),
        ((4, 4), (), (4, 4)),
        ((4, 4), (), ()),
        ((), (4, 4), (1, 4, 4)),
    )

    # 遍历每种情况，生成样本输入
    for a, b, c in cases:
        yield SampleInput(make_arg(a), args=(make_arg(b), make_arg(c)))
        # 对于非连续的情况，额外创建转置后的输入样本
        yield SampleInput(make_arg(a, noncontiguous=True),
                          args=(make_arg(b).transpose(0, -1), make_arg(c, noncontiguous=True).transpose(0, -1)))

    # 标量输入情况
    if supports_scalars:
        cases = [
            ((), 1, 2,),
            ((), 1., 2),
            ((4, 4), 1., 2,),
            ((3, 4), make_scalar_tensor(), make_scalar_tensor()),
        ]

        # 如果支持复数类型，则添加复数与实数的组合
        if torch.complex64 in supported_dtypes:
            cases.extend([
                ((3, 1, 4), complex(1, 2), 3.),
            ])

        # 遍历每种情况，生成样本输入
        for a, b, c in cases:
            yield SampleInput(make_arg(a), args=(b, c))

    # 类型提升情况
    # 整数与浮点数的组合
    if torch.float in supported_dtypes and torch.long in supported_dtypes:
        a = make_arg((), dtype=torch.long)
        b = make_arg((1, 4), dtype=torch.float)
        c = make_arg((3, 4))

        cases = (
            (a, b, c),
            (c, a, b),
        )

        # 遍历每种情况，生成样本输入
        for a, b, c in cases:
            yield SampleInput(a, args=(b, c))

    # NaN 传播情况
    if dtype.is_floating_point or dtype.is_complex:
        nan = float('nan') if dtype.is_floating_point else complex(float('nan'), float('nan'))

        a = make_arg((12,))
        a[4] = nan
        a[7] = nan
        b = make_arg((12,))
        b[1] = nan
        b[7] = nan
        c = make_arg((12,))
        c[9] = nan

        # 创建包含 NaN 的样本输入
        yield SampleInput(a, args=(b, c))


# 使用 NumPy 实现的最大值截断函数
def _clamp_min_numpy(a, min=None):
    return np.maximum(a, min)


# 使用 NumPy 实现的最小值截断函数
def _clamp_max_numpy(a, max=None):
    return np.minimum(a, max)


# 使用 NumPy 实现的区间截断函数
def _clamp_numpy(a, min=None, max=None):
    if min is None:
        return np.minimum(a, max)
    if max is None:
        return np.maximum(a, min)

    return np.minimum(max, np.maximum(a, min))


# 生成累积乘积的样本输入的函数
def sample_inputs_cumprod(op_info, device, dtype, requires_grad, **kwargs):
    def make_arg(shape):
        # 收缩值以使其在 [-1, +1] 区间内，以提高梯度检查的精度
        return make_tensor(shape, dtype=dtype, device=device, low=-1, high=+1, requires_grad=requires_grad)
    # 定义一个函数 `prod_zeros`，用于生成特定维度上的零值张量
    def prod_zeros(dim_select):
        # 断言维度选择的长度为2
        assert len(dim_select) == 2
        # 创建一个形状为 (S, S, S) 的张量
        result = make_arg(3 * (S,))
        # 在指定的维度上进行窄化操作，并将选定区域置零
        result.narrow(dim_select[0], 0, 1).narrow(dim_select[1], 1, 1).zero_()
        result.narrow(dim_select[0], 2, 1).narrow(dim_select[1], 3, 1).zero_()
        result.narrow(dim_select[0], 4, 1).narrow(dim_select[1], 3, 1).zero_()
        # 返回生成的零值张量
        return result

    # 对于每个维度在范围 [0, 1, 2] 上，生成对应的 SampleInput 实例，并使用 make_arg 创建相应的输入张量
    for dim in range(3):
        yield SampleInput(make_arg((S, S, S)), args=(dim,))

    # 对于每个尺寸 [(), (1,), (0,)]，生成对应的 SampleInput 实例，并使用 make_arg 创建相应的输入张量
    # 其中 () 表示标量张量，(1,) 表示具有一个元素的张量，(0,) 表示空张量
    for size in [(), (1,), (0,)]:
        yield SampleInput(make_arg(size), args=(0,))

    # 生成对应于 prod_zeros 函数的 SampleInput 实例，传入不同的维度选择
    yield SampleInput(prod_zeros([0, 1]), args=(1,))
    yield SampleInput(prod_zeros([0, 2]), args=(1,))
    yield SampleInput(prod_zeros([1, 2]), args=(1,))

    # 测试 dtype 参数的使用，传入不同的数据类型参数
    yield SampleInput(prod_zeros([1, 2]), args=(1,), kwargs={'dtype': dtype})
# 生成一个复杂张量作为输入的样本，返回一个生成器对象
def sample_inputs_view_as_complex(op_info, device, dtype, requires_grad, **kwargs):
    # 使用 make_tensor 函数生成一个形状为 (S, 2) 的张量，设备为 device，数据类型为 dtype，是否需要梯度为 requires_grad
    yield SampleInput(make_tensor((S, 2), dtype=dtype, device=device, requires_grad=requires_grad))

# 生成一个实数张量作为输入的样本，返回一个生成器对象
def sample_inputs_view_as_real(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数 make_arg，部分应用 make_tensor 函数的设备、数据类型和是否需要梯度的参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 定义 sizes 变量，包含两个元组，每个元组表示一个张量的形状
    sizes = ((S, S), ())
    # 返回一个生成器对象，生成多个 SampleInput 对象，每个对象由 make_arg 函数生成的张量组成
    return (SampleInput(make_arg(size)) for size in sizes)

# 生成复杂错误输入的样本，返回一个生成器对象
def error_inputs_complex(op_info, device, is_ref=False, **kwargs):
    # 使用偏函数 make_arg，部分应用 make_tensor 函数的设备和数据类型参数
    make_arg = partial(make_tensor, dtype=torch.float32, device=device)

    # 根据 is_ref 参数选择不同的错误消息
    if is_ref:
        error_float = "Expected both inputs to be Half, Float or Double tensors but got torch.float32 and torch.int32"
        error_dtype = "Expected object of scalar type torch.float32 but got scalar type torch.float64 for second argument"
        error_out = "Expected out tensor to have dtype torch.complex128 but got torch.complex64 instead"
    else:
        error_float = "Expected both inputs to be Half, Float or Double tensors but got Float and Int"
        error_dtype = "Expected object of scalar type Float but got scalar type Double for second argument"
        error_out = "Expected object of scalar type ComplexDouble but got scalar type ComplexFloat for argument 'out'"

    # 返回一个生成器对象，生成多个 ErrorInput 对象，每个对象由 SampleInput 对象和对应的错误信息组成
    yield ErrorInput(SampleInput(make_arg(M, S), make_arg(M, S, dtype=torch.int)),
                     error_type=RuntimeError, error_regex=error_float)

    yield ErrorInput(SampleInput(make_arg(M, S), make_arg(M, S, dtype=torch.float64)),
                     error_type=RuntimeError, error_regex=error_dtype)

    yield ErrorInput(SampleInput(make_arg(M, S, dtype=torch.float64), make_arg(M, S, dtype=torch.float64),
                                 out=make_arg(M, S, dtype=torch.complex64)),
                     error_type=RuntimeError, error_regex=error_out)

# 生成 logaddexp 操作的样本输入，返回一个生成器对象
def sample_inputs_logaddexp(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数 make_arg，部分应用 make_tensor 函数的设备、数据类型和是否需要梯度的参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 定义形状为 (S, S) 的张量形状
    shape = (S, S)
    # 返回一个生成器对象，生成一个 SampleInput 对象，由两个 make_arg 函数生成的张量组成
    yield SampleInput(make_arg(shape), make_arg(shape))

# 生成累积乘积操作的样本输入，返回一个生成器对象
def sample_inputs_prod(op_info, device, dtype, requires_grad, **kwargs):
    # 定义生成张量的函数 make_arg，其形状为 shape
    def make_arg(shape):
        # 使用 make_tensor 函数生成一个指定形状的张量，数据类型为 dtype，设备为 device，且值范围在 [-1, 1] 内，是否需要梯度为 requires_grad
        # 用于在 gradgradcheck 中提高精度
        return make_tensor(shape, dtype=dtype, device=device, low=-1, high=+1, requires_grad=requires_grad)

    # 定义一个生成含有单个零值的张量的函数
    def prod_single_zero():
        # 生成一个形状为 (2*S,) 的张量
        result = make_arg(2 * (S,))
        # 将结果张量的第一行第二列的值设置为 0
        result[0, 1] = 0
        return result

    # 遍历 sample_inputs_cumprod 函数生成的样本输入生成器对象的每个样本
    for sample in sample_inputs_cumprod(op_info, device, dtype, requires_grad):
        # 仅生成张量样本，忽略其他输入
        yield SampleInput(sample.input.clone().requires_grad_(requires_grad))
        # 生成每个样本
        yield sample

    # 生成带有 keepdim=True 参数的样本
    for sample in sample_inputs_cumprod(op_info, device, dtype, requires_grad):
        # 将 keepdim 参数设为 True
        sample.kwargs['keepdim'] = True
        # 生成每个样本
        yield sample

    # 返回一个含有单个零值的张量的 SampleInput 对象
    yield SampleInput(prod_single_zero())
    # 生成一个带有特定参数的SampleInput对象，参数是一个元组 (3, 3, 3)，args参数为 (1,)
    yield SampleInput(make_arg((3, 3, 3)), args=(1,))
    # 生成一个带有特定参数的SampleInput对象，参数是一个元组 (3, 3, 3)，args参数为 (1,)，kwargs参数为 {'keepdim': True}
    yield SampleInput(make_arg((3, 3, 3)), args=(1,), kwargs={'keepdim': True})

    # 生成一个带有特定参数的SampleInput对象，参数是一个元组 (3, 0)，args参数为 (1,)
    yield SampleInput(make_arg((3, 0)), args=(1,))
    # 生成一个带有特定参数的SampleInput对象，参数是一个元组 (3, 0)，args参数为 (1,)，kwargs参数为 {'keepdim': True}
    yield SampleInput(make_arg((3, 0)), args=(1,), kwargs={'keepdim': True})

    # 创建一个浮点数张量，包含元素 [2., 3, 0, 0]，指定dtype和device，并设置requires_grad为指定值
    yield SampleInput(torch.tensor([2., 3, 0, 0], dtype=dtype, device=device, requires_grad=requires_grad))

    # 测试零标量张量
    zero = make_arg(())
    # 将零标量张量原地置零
    zero.zero_()
    # 生成一个带有特定参数的SampleInput对象，参数是零标量张量的克隆，并设置requires_grad为指定值
    yield SampleInput(zero.clone().requires_grad_(requires_grad))
    # 生成一个带有特定参数的SampleInput对象，参数是零标量张量的克隆，并设置requires_grad为指定值，args参数为 (0,)
    yield SampleInput(zero.clone().requires_grad_(requires_grad), args=(0,))
    # 生成一个带有特定参数的SampleInput对象，参数是零标量张量的克隆，并设置requires_grad为指定值，args参数为 (0,)，kwargs参数为 {'keepdim': True}
    yield SampleInput(zero.clone().requires_grad_(requires_grad),
                      args=(0,),
                      kwargs={'keepdim': True})
def error_inputs_neg(op_info, device, **kwargs):
    # 创建一个布尔张量样本输入对象
    si = SampleInput(torch.tensor((False, True), device=device))
    # 错误消息，说明布尔张量上的取反操作不支持，提供正确的操作建议
    msg = ("Negation, the `\\-` operator, on a bool tensor is not supported."
           " If you are trying to invert a mask, use the `\\~` or"
           " `logical_not\\(\\)` operator instead.")
    # 生成一个错误输入对象，匹配错误消息的正则表达式
    yield ErrorInput(si, error_regex=msg)

def sample_inputs_diag(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个生成张量的函数，部分参数已预设
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    # 生成并返回一个主对角线的样本输入对象
    yield SampleInput(make_arg(M))

    # 不同形状的张量
    tensors = (
        make_arg((M, M)),
        make_arg((3, 5)),
        make_arg((5, 3)),
    )

    # 不同的参数组合
    args = ((), (2,), (-2,), (1,), (2,))

    # 对每个张量和参数组合进行组合生成样本输入对象
    for tensor, arg in product(tensors, args):
        yield SampleInput(tensor.clone().requires_grad_(requires_grad), *arg)

def reference_inputs_diagonal_diag_embed(op_info, device, dtype, requires_grad, **kwargs):
    # 调用并返回主对角线和 diag_embed 的样本输入对象
    yield from sample_inputs_diagonal_diag_embed(
        op_info, device, dtype, requires_grad, **kwargs)

    # 创建生成张量的函数，部分参数已预设
    make_arg = partial(
        make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 不同维度的形状
    shapes1d = ((0,), (1,))
    shapes2d = ((L, M),)
    shapes3d = ((L, M, S),)

    # 不同的参数字典
    kwargs1d = {}

    kwargs2d = (
        # dim1 > dim2 is allowed
        dict(dim1=1, dim2=0),
        # negative dims are allowed
        dict(dim1=-2, dim2=-1),
        # one dim negative and the other nonnegative is allowed
        dict(dim1=-1, dim2=0),
        # out of bounds offset should return an empty tensor in diagonal and
        # offset the diagonal in diag_embed
        dict(offset=100),
    )

    kwargs3d = kwargs2d + (
        # make sure we can use non-sequential dims
        dict(offset=-1, dim1=0, dim2=2),
    )

    # 生成不同形状和参数的样本输入对象
    samples1d = product(shapes1d, kwargs1d)
    samples2d = product(shapes2d, kwargs2d)
    samples3d = product(shapes3d, kwargs3d)

    for shape, kwargs in chain(samples1d, samples2d, samples3d):
        if 'diagonal' in op_info.name:
            # 对于主对角线操作，生成错误输入对象
            if shape in ((0,), (1,)):
                continue
        yield SampleInput(input=make_arg(shape), kwargs=kwargs)


def sample_inputs_diagonal_scatter(op_info, device, dtype, requires_grad, **kwargs):
    # 创建生成张量的函数，部分参数已预设
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 2D张量的形状
    shapes_2d = ((M, M), (3, 5), (5, 3))

    # 3D张量的形状
    shapes_3d = ((M, M, M),)

    # 对2D张量的参数组合
    args_2d = ((), (2,), (-2,), (1,))
    # 对3D张量的参数组合
    args_3d = ((1, 1, 2), (2, 0, 1), (-2, 0, 1))
    # 对于每个二维形状和其对应的参数，或者每个三维形状和其对应的参数，生成输入和参数组合
    for input_shape, arg in chain(product(shapes_2d, args_2d), product(shapes_3d, args_3d)):
        # 创建输入对象
        input_ = make_arg(input_shape)
        
        # 程序化确定 src 的正确形状：
        # 它应该与 input_.diagonal(*arg_tuple) 的大小相同
        if not isinstance(arg, tuple):
            arg_tuple = (arg,)
        else:
            arg_tuple = arg
        
        # 计算 src 的形状
        src_shape = input_.diagonal(*arg_tuple).size()
        
        # 创建 src 对象
        src = make_arg(src_shape)
        
        # 生成一个 SampleInput 实例，其中包含 input_ 作为输入，src 和 arg_tuple 作为参数
        yield SampleInput(input_, args=(src, *arg_tuple))
# 生成稀疏输入样本集合的生成器函数，每次迭代生成一个样本输入
def sample_inputs_to_sparse(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数创建张量生成函数，固定了设备、数据类型和梯度需求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 生成一个稀疏样本输入，带有元数据输出处理函数，将输出稀疏张量转换为密集张量
    yield SampleInput(make_arg((S, S))).with_metadata(output_process_fn_grad=lambda x: x.to_dense())
    
    # 生成另一个稀疏样本输入，带有元数据输出处理函数，同样将输出稀疏张量转换为密集张量
    yield SampleInput(make_arg((S, S)), 1).with_metadata(output_process_fn_grad=lambda x: x.to_dense())


# 生成交叉熵损失函数的输入样本集合的生成器函数
def sample_inputs_cross_entropy(op_info, device, dtype, requires_grad, **kwargs):
    batch_size, num_classes = shape = (2, 3)
    reductions = ("mean", "sum", "none")

    # 定义输入形状和相关参数的列表
    input_shape_and_kwargs: List[Tuple[Tuple[int, ...], Dict[str, Any]]] = [
        (shape, {}),
        ((*shape, 1), {}),
        ((*shape, 1, 2), {}),
        ((*shape, 1, 2, 3), {}),
        *[(shape, dict(reduction=reduction)) for reduction in reductions],
        *[
            (
                shape,
                dict(
                    weight=make_tensor((num_classes,), device=device, dtype=dtype),
                    reduction=reduction,
                ),
            )
            for reduction in reductions
        ],
        (shape, dict(ignore_index=1)),
    ]

    # 生成输入形状和参数组合的笛卡尔积，同时考虑是否使用概率目标
    for (input_shape, kwargs), probabilities_target in itertools.product(input_shape_and_kwargs, (False, True)):
        # 创建张量输入，根据设备、数据类型和梯度需求生成
        input = make_tensor(input_shape, device=device, dtype=dtype, requires_grad=requires_grad)

        if probabilities_target:
            # 如果目标是概率值，忽略指标不受支持
            if "ignore_index" in kwargs:
                continue

            # 创建概率目标张量，值范围在 0 到 1 之间
            target = make_tensor(
                input_shape,
                low=0,
                high=1,
                device=device,
                dtype=dtype,
                requires_grad=requires_grad,
            )
        else:
            # 创建分类目标张量，值范围在 0 到 num_classes-1 之间
            target = make_tensor(
                (batch_size, *input_shape[2:]),
                low=0,
                high=num_classes,
                device=device,
                dtype=torch.long,
            )

            # 如果指定了忽略索引，并且目标张量全等于忽略索引值
            if "ignore_index" in kwargs and torch.all(target == kwargs["ignore_index"]):
                # 确保目标张量中至少有一项不被忽略
                target[0] = random.sample(sorted(set(range(num_classes)) - {kwargs["ignore_index"]}), 1)[0]

        # 生成一个样本输入，包括输入和目标张量及其他参数
        yield SampleInput(input, target, **kwargs)


# 生成逻辑回归函数的输入样本集合的生成器函数
def sample_inputs_logit(op_info, device, dtype, requires_grad, **kwargs):
    low, high = op_info.domain

    # 注意：在接近域起始和结束点时，操作符对于浮点数或复数非常敏感，
    # 当 domain_eps 设置为 1e-5 时，会导致 float16 类型的 NaN 值
    if dtype.is_floating_point or dtype.is_complex:
        domain_eps = op_info._domain_eps if dtype != torch.float16 else 3e-2

        # 调整低值和高值，使其不过于接近域的边界
        low = low + domain_eps
        high = high - domain_eps

    # 使用偏函数创建张量生成函数，固定了数据类型、设备、取值范围和梯度需求
    make_arg = partial(make_tensor, dtype=dtype, device=device, low=low, high=high, requires_grad=requires_grad)

    # 生成逻辑回归函数的输入样本，输入形状为 (S, S, S)
    yield SampleInput(make_arg((S, S, S)))
    
    # 生成逻辑回归函数的输入样本，输入形状为 (S, S, S)，带有 0.2 的附加参数
    yield SampleInput(make_arg((S, S, S)), 0.2)
    
    # 生成逻辑回归函数的输入样本，输入形状为空元组
    yield SampleInput(make_arg(()))
    # 使用 make_arg 函数生成一个空元组作为参数，然后将其作为参数传递给 SampleInput 函数，并生成一个权重为 0.2 的输入样本
    yield SampleInput(make_arg(()), 0.2)
# 生成用于测试的输入样本，返回一个生成器对象
def sample_inputs_isin(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了 make_tensor 函数的函数对象 make_arg，固定了 device、dtype 和 requires_grad 参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    
    # 第一个样本输入，使用 make_arg 创建大小为 (L,) 的张量，作为主元素，和一个大小为 (S,) 的张量作为测试元素
    yield SampleInput(make_arg((L,)), args=(make_arg((S,)),))
    
    # 第二个样本输入，如果 elements 的元素数量小于 10 * pow(test_elements 的元素数量, 0.145)，则交换参数顺序
    yield SampleInput(make_arg((S,)), args=(make_arg((L,)),))

# 生成用于测试的输入样本，返回一个生成器对象
def sample_inputs_masked_scatter(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了 make_tensor 函数的函数对象 make_arg，固定了 device、dtype 和 requires_grad 参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 第一个样本输入，创建一个大小为 (S, S) 的张量，使用随机生成的布尔掩码张量和另一个大小为 (S, S) 的张量
    yield SampleInput(make_arg((S, S)), args=(torch.randn(S, S, device=device) > 0, make_arg((S, S))))
    
    # 第二个样本输入，创建一个大小为 (S, S) 的张量，使用随机生成的布尔掩码张量和一个大小为 (S,) 的张量
    yield SampleInput(make_arg((S, S)), args=(torch.randn((S,), device=device) > 0, make_arg((S, S))))
    
    # 第三个样本输入，创建一个大小为 (S, S) 的张量，使用随机生成的 Bernoulli 标量张量和另一个大小为 (S, S) 的张量
    yield SampleInput(make_arg((S, S)), args=(bernoulli_scalar().to(device), make_arg((S, S))))
    
    # 第四个样本输入，创建一个大小为 (S,) 的张量，使用随机生成的布尔掩码张量和一个大小为 (S, S) 的张量，并广播输入
    yield SampleInput(make_arg((S,)),
                      args=(torch.randn(S, S, device=device) > 0, make_arg((S, S))),
                      broadcasts_input=True)

# 生成用于测试的错误输入样本，返回一个生成器对象
def error_inputs_masked_scatter(op_info, device, **kwargs):
    # 创建一个部分应用了 make_tensor 函数的函数对象 make_arg，固定了 device 参数，并使用 torch.float 类型
    make_arg = partial(make_tensor, device=device, dtype=torch.float)
    
    # 遍历 mask_dtype 可能的取值 [torch.float, torch.uint8]
    for mask_dtype in [torch.float, torch.uint8]:
        # 生成一个错误输入，使用 make_arg 创建大小为 (1, 3) 的张量，布尔掩码为全 1，和一个大小为 (3, 4) 的张量
        yield ErrorInput(SampleInput(make_arg(1, 3), args=(torch.ones(1, 3, device=device, dtype=mask_dtype),
                                                           make_arg(3, 4))),
                         error_regex=r"masked_scatter_ only supports boolean masks")

# 生成用于测试的输入样本，返回一个生成器对象
def sample_inputs_masked_fill(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了 make_tensor 函数的函数对象 make_arg，固定了 device、dtype 和 requires_grad 参数
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 第一个样本输入，创建一个大小为 (S, S) 的张量，使用随机生成的布尔掩码张量和标量值 10
    yield SampleInput(make_arg((S, S)), args=(torch.randn(S, S, device=device) > 0, 10))
    
    # 第二个样本输入，创建一个大小为 (S, S) 的张量，使用随机生成的布尔掩码张量和一个大小为 () 的张量
    yield SampleInput(make_arg((S, S)), args=(torch.randn(S, S, device=device) > 0, make_arg(())))
    
    # 第三个样本输入，创建一个大小为 (S, S) 的张量，使用随机生成的布尔掩码张量和标量值 10
    yield SampleInput(make_arg((S, S)), args=(torch.randn(S, device=device) > 0, 10))
    
    # 第四个样本输入，创建一个大小为 () 的张量，使用随机生成的布尔掩码张量和标量值 10
    yield SampleInput(make_arg(()), args=(torch.randn((), device=device) > 0, 10))
    
    # 第五个样本输入，创建一个大小为 () 的张量，使用随机生成的布尔掩码张量和一个大小为 () 的张量
    yield SampleInput(make_arg(()), args=(torch.randn((), device=device) > 0, make_arg(())))
    
    # 第六个样本输入，创建一个大小为 (S, S) 的张量，使用随机生成的布尔掩码张量和标量值 10，并广播输入
    yield SampleInput(make_arg((S,)),
                      args=(torch.randn((), device=device) > 0, 10),
                      broadcasts_input=True)
    
    # 第七个样本输入，创建一个大小为 (S, S) 的张量，使用随机生成的布尔掩码张量和一个大小为 () 的张量，并广播输入
    yield SampleInput(make_arg((S,)),
                      args=(torch.randn(S, S, device=device) > 0, make_arg(())),
                      broadcasts_input=True)

    # 如果设备为 CUDA 类型
    if torch.device(device).type == 'cuda':
        # 第八个样本输入，在 CUDA 上执行，创建一个大小为 (S, S) 的张量，使用随机生成的布尔掩码张量和一个大小为 () 的随机张量
        yield SampleInput(make_arg((S, S)), args=(torch.randn(S, S, device=device) > 0, torch.randn(())))

# 生成用于测试的错误输入样本，返回一个生成器对象
def error_inputs_masked_fill(op_info, device, **kwargs):
    # 创建一个部分应用了 make_tensor 函数的函数对象 make_arg，固定了 device 参数，并使用 torch.float 类型和 requires_grad=False
    make_arg = partial(make_tensor, device=device, dtype=torch.float, requires_grad=False)
    
    # 错误输入，标量值 `value` 不是 0 维张量
    # 此处缺少具体的 ErrorInput 对象生成，需要根据实际情况添加代码补全
    # 生成一个 ErrorInput 对象，表示输入样本和预期的错误输出
    yield ErrorInput(SampleInput(make_arg((2, 2)), args=(make_arg(()) > 0, make_arg((1,)))),
                     error_regex="only supports a 0-dimensional value tensor, but got tensor with 1 dimension")
    # 降级复杂值（标量重载）

    # 生成一个 ErrorInput 对象，表示输入样本和预期的错误输出
    yield ErrorInput(SampleInput(make_arg((2, 2)), args=(make_arg(()) > 0, 1j)),
                     error_regex=r"value cannot be converted to type .* without overflow")
    # 降级复杂值（张量重载）

    # 生成一个 ErrorInput 对象，表示输入样本和预期的错误输出
    yield ErrorInput(torch.ones(2, dtype=torch.long, device=device),
                     args=(make_arg(()) > 0, torch.tensor(1j, device=device))),
                     error_regex=r"value cannot be converted to type .* without overflow")
    # 如果设备是 CUDA，则...

    # 检查当前设备是否为 CUDA
    if torch.device(device).type == 'cuda':
        # `self` 和 `mask` 在 CPU 上，但 `value` 是 CUDA 标量张量。
        # 生成一个 ErrorInput 对象，表示输入样本和预期的错误输出
        yield ErrorInput(SampleInput(torch.randn((S, S), device='cpu'),
                                     args=(torch.randn(S, S, device='cpu') > 0,
                                           torch.randn((), device='cuda'))),
                         error_regex=r"to be on same device")
# 定义一个生成器函数，生成带有掩码选择的样本输入
def sample_inputs_masked_select(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数定义一个创建张量的函数，指定设备、数据类型、是否需要梯度，以及数据范围为None到None
    make_arg = partial(
        make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)

    # 生成一个样本输入，包括一个由 make_arg 创建的 MxM 的张量和一个由 torch.randn 生成的 MxM 大小的布尔类型张量
    yield SampleInput(make_arg((M, M)), torch.randn(M, M, device=device) > 0)

    # 生成一个样本输入，包括一个由 make_arg 创建的 MxM 的张量和一个由 torch.randn 生成的 M 大小的布尔类型张量
    yield SampleInput(make_arg((M, M)), torch.randn((M,), device=device) > 0)

    # 生成一个样本输入，包括一个由 make_arg 创建的 M 大小的张量和一个由 torch.randn 生成的 MxM 大小的布尔类型张量
    yield SampleInput(make_arg((M,)), torch.randn((M, M), device=device) > 0)

    # 生成一个样本输入，包括一个由 make_arg 创建的 Mx1xM 大小的张量和一个由 torch.randn 生成的 MxM 大小的布尔类型张量
    yield SampleInput(make_arg((M, 1, M)), torch.randn((M, M), device=device) > 0)

    # 生成一个样本输入，包括一个由 make_arg 创建的大小为空的张量和一个由 torch.tensor 创建的大小为1的布尔类型张量
    yield SampleInput(make_arg(()), torch.tensor(1, device=device, dtype=torch.bool))

    # 生成一个样本输入，包括一个由 make_arg 创建的 MxM 的张量和一个由 torch.tensor 创建的大小为1的布尔类型张量
    yield SampleInput(make_arg((M, M)), torch.tensor(1, device=device, dtype=torch.bool))

    # 生成一个样本输入，包括一个由 make_arg 创建的大小为空的张量和一个由 torch.randn 生成的 MxM 大小的布尔类型张量
    yield SampleInput(make_arg(()), torch.randn((M, M), device=device) > 0)


# 定义一个生成器函数，生成矩阵指数操作的样本输入
def sample_inputs_matrix_exp(op_info, device, dtype, requires_grad, **kwargs):
    # 使用偏函数定义一个创建张量的函数，指定设备、数据类型、是否需要梯度
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    
    # 生成一个样本输入，包括一个由 make_arg 创建的大小为SxS的张量
    yield SampleInput(make_arg((S, S)))
    
    # 生成一个样本输入，包括一个由 make_arg 创建的大小为SxSxS的张量
    yield SampleInput(make_arg((S, S, S)))


# 定义一个生成器函数，生成矩阵乘法操作的样本输入
def sample_inputs_matmul(op_info, device, dtype, requires_grad, is_rmatmul=False, **kwargs):
    # 使用偏函数定义一个创建张量的函数，指定数据类型、设备、数据范围为None到None，是否需要梯度
    make_arg = partial(make_tensor, dtype=dtype, device=device, low=None,
                       high=None, requires_grad=requires_grad)
    
    # 定义多个矩阵乘法的测试用例
    test_cases = (((L,), (L,)),
                  ((S, M), (M,)),
                  ((M,), (M, S)),
                  ((S, M), (M, S)),
                  ((S, 0), (0, M)),
                  ((S, S, M), (M,)),
                  ((S, S, M), (M, S)),
                  ((S, S, 0), (0, S)),
                  ((M,), (S, M, S)),
                  ((S, M), (S, M, S)),
                  ((0, 0), (S, 0, 0)),
                  ((S, S, M, M), (S, S, M, S)),
                  ((S, S, M, M), (M,)),
                  ((M,), (S, S, M, S)),
                  ((S, S, S), (1, S, S))
                  )
    
    # 遍历每个测试用例，生成相应的样本输入
    for lhs_shape, rhs_shape in test_cases:
        lhs = make_arg(lhs_shape)
        rhs = make_arg(rhs_shape)
        if not is_rmatmul:
            yield SampleInput(lhs, rhs)
        else:
            yield SampleInput(rhs, lhs)


# 定义一个生成器函数，生成网格点操作的样本输入
def sample_inputs_meshgrid(op_info: OpInfo, device: torch.device, dtype: torch.dtype,
                           requires_grad: bool,
                           *, variant: str, **kwargs) -> List[SampleInput]:
    # 根据不同的变体类型选择不同的输入创建函数
    if variant == 'variadic':
        # 定义一个创建输入的函数，接受一个张量列表，返回张量或张量列表以及一个张量元组
        def make_inputs(
                tensors: List[torch.Tensor]) -> Tuple[Union[torch.Tensor,
                                                            List[torch.Tensor]],
                                                      Tuple[torch.Tensor, ...]]:
            return tensors
    elif variant == 'list':
        # 定义一个创建输入的函数，接受一个张量列表，返回一个包含列表的列表
        def make_inputs(
                tensors: List[torch.Tensor]) -> Tuple[Union[torch.Tensor,
                                                            List[torch.Tensor]],
                                                      Tuple[torch.Tensor, ...]]:
            return [tensors]
    else:
        raise ValueError(
            'Unsupported variant, must be one of {"variadic", "list"}. '
            f'Got "{variant}".')


    # 如果 variant 不是 "variadic" 或 "list"，则抛出值错误异常
    raise ValueError(
        'Unsupported variant, must be one of {"variadic", "list"}. '
        f'Got "{variant}".')



    SCALAR = torch.Size([])
    VECTOR = torch.Size([3])


    # 定义标量和向量的 torch.Size 对象
    SCALAR = torch.Size([])
    VECTOR = torch.Size([3])



    test_cases: List[List[torch.Size]] = [
        [SCALAR],
        [VECTOR],
        [VECTOR, SCALAR],
        [VECTOR, SCALAR, VECTOR],
        [VECTOR, SCALAR, VECTOR, SCALAR],
    ]


    # 定义测试用例，每个测试用例是一个包含 torch.Size 对象的列表
    test_cases: List[List[torch.Size]] = [
        [SCALAR],                       # 包含一个标量的列表
        [VECTOR],                       # 包含一个向量的列表
        [VECTOR, SCALAR],               # 包含一个向量和一个标量的列表
        [VECTOR, SCALAR, VECTOR],       # 包含两个向量和一个标量的列表
        [VECTOR, SCALAR, VECTOR, SCALAR]# 包含两个向量和两个标量的列表
    ]



    for shapes, indexing in itertools.product(test_cases, {'xy', 'ij'}):


    # 使用 itertools.product 对 test_cases 和 {'xy', 'ij'} 的笛卡尔积进行迭代
    for shapes, indexing in itertools.product(test_cases, {'xy', 'ij'}):



        args = make_inputs(
            [make_tensor(shape, dtype=dtype, device=device, requires_grad=requires_grad)
             for shape in shapes])


        # 使用 make_tensor 函数根据 shapes 列表中的每个 shape 创建张量，并通过 make_inputs 函数生成输入参数
        args = make_inputs(
            [make_tensor(shape, dtype=dtype, device=device, requires_grad=requires_grad)
             for shape in shapes])



        yield SampleInput(*args, indexing=indexing)


        # 生成一个 SampleInput 对象，传入 args 和 indexing 作为参数
        yield SampleInput(*args, indexing=indexing)
# 定义一个函数，生成用于测试 `mvlgamma` 函数的输入样本
# `op_info`：操作信息
# `device`：指定的设备
# `dtype`：数据类型
# `requires_grad`：是否需要梯度
# `**kwargs`：其他关键字参数
def sample_inputs_mvlgamma(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用的函数 `make_arg`，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 定义不同张量的形状
    tensor_shapes = ((S, S), ())
    # 定义不同的 `n` 值
    ns = (1, 2, 3, 4, 5)

    # 定义计算 `min_val` 的函数，依赖于 `n` 的值
    def compute_min_val(p):
        return (p - 1.) / 2

    # 遍历所有形状和 `n` 值的组合
    for shape, n in product(tensor_shapes, ns):
        # 计算 `min_val`，根据数据类型是否为浮点数进行不同的调整
        min_val = compute_min_val(n)
        if not dtype.is_floating_point:
            # 对于整数数据类型，向上取整 `min_val`
            min_val += 1
        else:
            # 对于浮点数据类型，加上两倍的数据类型 `eps` 增量
            min_val += 2 * torch.finfo(dtype).eps
        # 生成一个样本输入，并使用 `make_arg` 函数生成张量
        yield SampleInput(make_arg(shape, low=min_val), args=(n,))


# 定义一个函数，用于生成 `mvlgamma` 函数测试时的跳过信息
# `skip_redundant`：是否跳过冗余测试
def skips_mvlgamma(skip_redundant=False):
    # 定义跳过的测试条目
    skips = (
        # 对于 `mvlgamma` 操作，超出定义域的值将导致硬错误
        DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_float_domains'),
        # 预期失败的测试条目
        DecorateInfo(unittest.expectedFailure, 'TestUnaryUfuncs', 'test_reference_numerics_extremal'),
        # 针对特定数据类型和 `p` 值的大数值测试条目
        DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large', dtypes=(torch.float16, torch.int8)),
        # 针对特定数据类型和 `p` 值的小数值测试条目
        DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_small', dtypes=(torch.int8,)),
    )
    if skip_redundant:
        # 如果需要跳过冗余测试，则添加额外的跳过条目
        skips = skips + (
            DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestJit'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon'),
        )
    return skips


# 定义一个函数，用于生成 `mvlgamma` 函数的测试配置信息
# `variant_test_name`：变体测试名称
# `domain`：测试的定义域
# `skips`：跳过的测试条目
# `sample_kwargs`：样本参数
def make_mvlgamma_opinfo(variant_test_name, domain, skips, sample_kwargs):
    # 返回一个 UnaryUfuncInfo 对象，用于描述 'mvlgamma' 函数的信息
    return UnaryUfuncInfo('mvlgamma',
                          # 如果 TEST_SCIPY 为真，则使用 reference_mvlgamma 作为参考函数，否则为 None
                          ref=reference_mvlgamma if TEST_SCIPY else None,
                          # 别名列表，包括 'special.multigammaln'
                          aliases=('special.multigammaln',),
                          # 变体测试名称
                          variant_test_name=variant_test_name,
                          # 函数适用的域
                          domain=domain,
                          # 修饰器列表，这里包含一个精度覆盖修饰器，针对 torch.float16 类型设置精度为 5e-2
                          decorators=(precisionOverride({torch.float16: 5e-2}),),
                          # 数据类型列表，包括所有类型和 torch.half, torch.bfloat16
                          dtypes=all_types_and(torch.half, torch.bfloat16),
                          # 如果在 CUDA 环境下，数据类型列表限定为 torch.float16, torch.bfloat16
                          dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),
                          # 用于生成样本输入的函数
                          sample_inputs_func=sample_inputs_mvlgamma,
                          # 是否支持前向自动求导
                          supports_forward_ad=True,
                          # 是否支持前向梯度和反向梯度传播
                          supports_fwgrad_bwgrad=True,
                          # 是否支持将整数自动提升为浮点数
                          promotes_int_to_float=True,
                          # 跳过的测试用例列表
                          skips=skips,
                          # 样本输入的关键字参数
                          sample_kwargs=sample_kwargs)
# 定义一个生成器函数，生成累积操作的示例输入
def sample_inputs_cumulative_ops(op_info, device, dtype, requires_grad, supports_dtype_kwargs=True, **kwargs):
    # 定义一个内部辅助函数，用于创建张量
    def _make_tensor_helper(shape, low=None, high=None):
        return make_tensor(shape, dtype=dtype, device=device, low=low, high=high, requires_grad=requires_grad)

    # 生成并返回三个不同形状的张量示例输入
    yield SampleInput(_make_tensor_helper((S, S, S)), 0)
    yield SampleInput(_make_tensor_helper((S, S, S)), 1)
    yield SampleInput(_make_tensor_helper(()), 0)

    # 如果支持 dtype 关键字参数，则生成一个具有特定 dtype 的张量示例输入
    if supports_dtype_kwargs:
        # 注意：如果 dtype 与输入张量的类型不同，那么原地操作的变体会失败，例如累加操作时会报错
        yield SampleInput(_make_tensor_helper((S, S, S)), 1, dtype=dtype)


# 定义一个生成器函数，生成展开操作的示例输入
def sample_inputs_unfold(op_info, device, dtype, requires_grad, **kwargs):
    # 预定义一系列测试用例，每个测试用例包含一个形状和对应的展开参数
    test_cases = (
        ((), (0, 1, 1)),
        ((S, S, S, S), (0, 3, 1)),
        ((S, S, S, S), (1, 3, 1)),
        ((S, S, S, S), (2, 3, 1)),
        ((S, S, S, S), (3, 3, 1)),
        ((S, S, S, S), (0, 3, 2)),
        ((S, S, S, S), (1, 3, 2)),
        ((S, S, S, S), (2, 3, 2)),
        ((S, S, S, S), (3, 3, 2)),
        ((S, S, S, S), (0, 4, 1)),
        ((S, S, S, S), (1, 4, 1)),
        ((S, S, S, S), (2, 4, 1)),
        ((S, S, S, S), (3, 4, 1)),
        ((M,), (0, 3, 1)),
        ((M,), (0, 3, 2)),
        ((M,), (0, 3, 3)),
        ((1000,), (0, 3, 11)),
        ((1000,), (0, 2, 27)),
        ((10, 10), (0, 1, 2)),
        ((10, 10), (1, 2, 3)),
        ((10, 10), (1, 2, 2)),
        ((S, S, S), (2, 3, 2)),
    )

    # 遍历所有测试用例，并生成对应的张量示例输入
    for shape, arguments in test_cases:
        yield SampleInput(make_tensor(shape, dtype=dtype, device=device,
                                      low=None, high=None,
                                      requires_grad=requires_grad),
                          *arguments)


# 定义一个生成器函数，生成分割操作的示例输入
def sample_inputs_split(op_info, device, dtype, requires_grad, *, list_args=False, **kwargs):
    # 部分应用 make_tensor 函数，生成具有部分固定参数的新函数 make_arg
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 根据 list_args 参数不同，选择不同的测试用例集合
    if list_args:
        cases = (
            ((S, S, S), (torch.Size([int(S / 3), S - int(S / 3) * 2, int(S / 3)]),)),
            ((S, S, S), (torch.Size([int(S / 2), S - int(S / 2) * 2, int(S / 2)]), 2),),
            ((S, S, S), (torch.Size([int(S / 2), S - int(S / 2) * 2, int(S / 2)]), -2),)
        )
    else:
        cases = (  # type: ignore[assignment]
            ((S, S, S), (2,)),
            ((S, S, S), (S, 1)),
        )

    # 遍历所有测试用例，并生成对应的张量示例输入
    for shape, args in cases:
        yield SampleInput(make_arg(shape), args=args)


# 定义一个生成器函数，生成带有尺寸参数的分割操作的示例输入
def sample_inputs_split_with_sizes(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用 make_tensor 函数，生成具有部分固定参数的新函数 make_arg
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 定义测试用例集合，每个元组包含两个元素：shape 和 args
    cases = (((S, S, S), (torch.Size([int(S / 3), S - int(S / 3) * 2, int(S / 3)]),)),  # 第一个测试用例
             ((S, S, S), (torch.Size([int(S / 3), S - int(S / 3), 0]),)),  # 第二个测试用例
             ((S, S, S), (torch.Size([int(S / 3), S - int(S / 3) * 2, int(S / 3)]), 2)),  # 第三个测试用例，带有额外参数
             ((S, S, S), (torch.Size([int(S / 3), S - int(S / 3) * 2, int(S / 3)]), -2)),  # 第四个测试用例，带有额外参数
             )

    # 遍历测试用例集合
    for shape, args in cases:
        # 使用 SampleInput 创建一个样本输入对象，传入 shape 和 args 参数
        yield SampleInput(make_arg(shape), args=args)
def sample_inputs_msort(op_info, device, dtype, requires_grad, **kwargs):
    # 定义内部函数 apply_grad，用于根据指定的 dtype 和 requires_grad 属性设置张量的梯度计算要求
    def apply_grad(t):
        if dtype in floating_types_and(torch.float16, torch.bfloat16):
            t.requires_grad_(requires_grad)

    # 定义生成具有唯一整数的大型一维张量的函数
    def large_1d_unique(dtype, device):
        # 生成具有大小 L * L * L 的随机排列整数张量，设备为指定的 device，数据类型为 torch.int64
        res = torch.randperm(L * L * L, dtype=torch.int64, device=device)
        # 转换张量的数据类型为指定的 dtype
        res = res.to(dtype)
        # 调用 apply_grad 函数，根据参数设置是否需要计算梯度
        apply_grad(res)
        # 返回处理后的张量
        return res

    # 测试用例，生成大型一维唯一整数张量的样本输入，并使用 yield 语句返回 SampleInput 对象
    yield SampleInput(large_1d_unique(dtype, device))

    # 生成测试用例，创建指定形状和属性的张量输入，使用 make_tensor 函数
    yield SampleInput(make_tensor((S, M, S), dtype=dtype, device=device,
                                  low=None, high=None,
                                  requires_grad=requires_grad))

def sample_inputs_lerp(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用 make_tensor 函数，创建具有指定 dtype、device 和 requires_grad 属性的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不进行广播的测试用例
    yield SampleInput(make_arg((S, S)), make_arg((S, S)), 0.4)
    # rhs 进行广播的测试用例
    yield SampleInput(make_arg((S, S)), make_arg((S,)), 0.4)
    # 标量张量的测试用例
    yield SampleInput(make_arg(()), make_arg(()), 0.4)
    # rhs 为标量张量时进行广播的测试用例
    yield SampleInput(make_arg((S, S)), make_arg(()), 0.4)
    # rhs 为权重张量时进行广播的测试用例
    yield SampleInput(make_arg((S, S)), make_arg((S,)), make_arg((S, S)))
    # rhs 和权重张量都进行广播的测试用例
    yield SampleInput(make_arg((S, S)), make_arg((S, 1)), make_arg((S,)))
    # lhs 进行广播的测试用例
    yield SampleInput(make_arg((S,)), make_arg((S, S)), 0.4).with_metadata(broadcasts_input=True)
    # 标量 lhs 进行广播的测试用例
    yield SampleInput(make_arg(()), make_arg((S, S)), 0.4).with_metadata(broadcasts_input=True)
    # 全部进行广播的测试用例
    yield SampleInput(make_arg((S, 1)), make_arg((S, S)), 0.4).with_metadata(broadcasts_input=True)
    # 张量全部进行广播的测试用例
    yield SampleInput(make_arg((S, 1)), make_arg((S, S)), make_arg((S, 1))).with_metadata(
        broadcasts_input=True)
    # 不进行广播的测试用例，同时包含权重张量
    yield SampleInput(make_arg((S, S)), make_arg((S, S)), make_arg((S, S)))
    # lhs 进行广播的测试用例，同时包含权重张量
    yield SampleInput(make_arg((S,)), make_arg((S, S)), make_arg((S, S))).with_metadata(
        broadcasts_input=True)
    # lhs 进行广播的测试用例，同时包含权重张量，具体形状不同
    yield SampleInput(make_arg((S,)), make_arg((S, S, S)), make_arg((S, S))).with_metadata(
        broadcasts_input=True)
    # lhs 进行广播的测试用例，同时包含权重张量，rhs 形状不同
    yield SampleInput(make_arg((S, S)), make_arg((S, S, S)), make_arg((S,))).with_metadata(
        broadcasts_input=True)
    # 如果数据类型是复数类型，则执行以下操作
    if dtype.is_complex:
        # 不进行广播，生成带有复数参数的样本输入
        yield SampleInput(make_arg((S, S)), make_arg((S, S)), 0.4j)
        yield SampleInput(make_arg((S, S)), make_arg((S, S)), 1.2 + 0.1j)
        # 对右操作数进行广播，生成带有复数参数的样本输入
        yield SampleInput(make_arg((S, S)), make_arg((S,)), 0.4j)
        yield SampleInput(make_arg((S, S)), make_arg((S, S)), 5.4 + 9j)
        # 标量张量，生成带有复数参数的样本输入
        yield SampleInput(make_arg(()), make_arg(()), 0.4j)
        yield SampleInput(make_arg(()), make_arg(()), 6.1 + 0.004j)
        # 对右操作数进行广播，生成标量与张量的复数参数的样本输入
        yield SampleInput(make_arg((S, S)), make_arg(()), 0.4j)
        yield SampleInput(make_arg((S, S)), make_arg(()), 1 + 2j)
# 定义一个生成器函数，生成用于测试tensordot操作的输入样本
def sample_inputs_tensordot(self, device, dtype, requires_grad, **kwargs):
    # 不同的测试用例，每个测试用例包含两个张量的形状和需要压缩的维度
    cases = (
        ((2, 2, 2), (2, 2, 2), (2)),  # 第一个测试用例：两个形状为 (2, 2, 2) 的张量，压缩维度为 2
        ((2, 2, 1), (2, 1, 2), ([0, 1], [2, 0])),  # 第二个测试用例：两个张量形状分别为 (2, 2, 1) 和 (2, 1, 2)，指定压缩维度列表
    )
    # 遍历每个测试用例
    for first_shape, second_shape, dims in cases:
        # 生成一个SampleInput对象作为生成器的输出，包含两个通过make_tensor生成的张量和压缩维度参数
        yield SampleInput(make_tensor(first_shape, dtype=dtype, device=device,
                                      requires_grad=requires_grad),
                          make_tensor(second_shape, dtype=dtype, device=device,
                                      requires_grad=requires_grad),
                          dims=dims)

# 定义一个生成器函数，生成用于测试kron操作的输入样本
def sample_inputs_kron(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用make_tensor的函数，生成具有指定形状和其他属性的张量
    make_arg = partial(
        make_tensor, dtype=dtype, device=device, requires_grad=requires_grad, low=None, high=None)
    # 不同的测试用例，每个测试用例包含两个形状的元组
    test_cases = (
        ((S, S), (M, L)),  # 第一个测试用例：两个形状分别为 (S, S) 和 (M, L) 的张量
    )
    # 遍历每个测试用例
    for input_shape, other_shape in test_cases:
        # 生成一个SampleInput对象作为生成器的输出，包含两个通过make_arg生成的张量
        input = make_arg(input_shape)
        other = make_arg(other_shape)
        yield SampleInput(input, other)

# 定义一个生成器函数，生成用于测试inner操作的输入样本
def sample_inputs_inner(self, device, dtype, requires_grad, **kwargs):
    # 部分应用make_tensor的函数，生成具有指定形状和其他属性的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 生成一个SampleInput对象作为生成器的输出，包含两个形状为 (S,) 的张量
    yield SampleInput(make_arg(S), make_arg(S))
    # 生成一个SampleInput对象作为生成器的输出，包含一个空张量和一个形状为 (S, S) 的张量
    yield SampleInput(make_arg(), make_arg(S, S))

# 定义一个生成器函数，生成用于测试scatter操作的输入样本
def sample_inputs_scatter(op_info, device, dtype, requires_grad, **kwargs):
    # 定义一个生成张量的局部函数，可以指定形状、dtype和其他属性
    def _tensor(shape, dtype=dtype, low=None, high=None):
        return make_tensor(shape, dtype=dtype, device=device, low=low, high=high, requires_grad=requires_grad)

    # 定义一个使用gather_variable生成索引张量的局部函数
    def _gather(shape, index_dim, max_indices):
        return gather_variable(shape, index_dim, max_indices, device=device)

    # 创建一个整数张量，作为索引使用
    zero = torch.tensor(0, dtype=torch.long, device=device)
    # 不同的测试用例，每个测试用例包含一个张量和其他参数的元组
    test_cases = (
        (_tensor((M, S)), (0, _gather((S, S), 1, M), _tensor((S, S)))),  # 第一个测试用例：包含一个形状为 (M, S) 的张量，一个形状为 (S, S) 的索引张量和一个形状为 (S, S) 的张量
        (_tensor((M, S)), (1, _gather((S, S), 0, S), _tensor((S, S)))),  # 第二个测试用例：包含一个形状为 (M, S) 的张量，一个形状为 (S, S) 的索引张量和一个形状为 (S, S) 的张量
        (_tensor((M, S)), (-1, _gather((S, S), 0, S), _tensor((S, S)))),  # 第三个测试用例：包含一个形状为 (M, S) 的张量，一个形状为 (S, S) 的索引张量和一个形状为 (S, S) 的张量
        (_tensor((M, S)), (0, _gather((M, S // 2), 1, M), _tensor((M, S // 2)))),  # 第四个测试用例：包含一个形状为 (M, S) 的张量，一个形状为 (M, S/2) 的索引张量和一个形状为 (M, S/2) 的张量
        (_tensor((M, S)), (1, _gather((M, S // 2), 0, S), _tensor((M, S // 2)))),  # 第五个测试用例：包含一个形状为 (M, S) 的张量，一个形状为 (M, S/2) 的索引张量和一个形状为 (M, S/2) 的张量
        (_tensor((M, S)), (-1, _gather((M, S // 2), 0, S), _tensor((M, S // 2)))),  # 第六个测试用例：包含一个形状为 (M, S) 的张量，一个形状为 (M, S/2) 的索引张量和一个形状为 (M, S/2) 的张量
        (_tensor(()), (0, zero.clone().detach(), _tensor(()))),  # 第七个测试用例：包含一个空张量，一个复制零张量和一个空张量
        (_tensor(()), (0, zero.clone().detach(), 2.5)),  # 第八个测试用例：包含一个空张量，一个复制零张量和一个标量 2.5
    )

    # 遍历每个测试用例
    for tensor, args in test_cases:
        # 生成一个SampleInput对象作为生成器的输出，包含一个张量和其他参数
        yield SampleInput(tensor, *args)

        # 如果不需要梯度，生成一个SampleInput对象，包含一个张量的克隆副本和其他参数，并指定reduce='add'
        if not requires_grad:
            yield SampleInput(tensor.clone().detach(), *args, reduce='add')

            # 如果dtype是浮点数，生成一个SampleInput对象，包含一个张量的克隆副本和其他参数，并指定reduce='multiply'
            if dtype.is_floating_point:
                yield SampleInput(tensor.clone().detach(), *args, reduce='multiply')

# 定义一个生成器函数，生成用于测试scatter_add操作的输入样本
def sample_inputs_scatter_add(op_info, device, dtype, requires_grad, **kwargs):
    # 定义一个生成张量的局部函数，可以指定形状、dtype和其他属性
    def _tensor(shape, dtype=dtype, low=None, high=None):
        return make_tensor(shape, dtype=dtype, device=device, low=low, high=high, requires_grad=requires_grad)

    # 定义一个使用gather_variable生成索引张量的局部函数
    def _gather(shape, index_dim, max_indices):
        return gather_variable(shape, index_dim, max_indices, device=device)
    # 创建一个值为0的长整型张量，使用指定的设备（device）
    zero = torch.tensor(0, dtype=torch.long, device=device)
    # 返回一个SampleInput对象，参数为(M, S)的张量、0、(S, S)形状的_gather结果、(S, S)形状的张量
    yield SampleInput(_tensor((M, S)), 0, _gather((S, S), 1, M), _tensor((S, S)))
    # 返回一个SampleInput对象，参数为(M, S)的张量、1、(S, S)形状的_gather结果、(S, S)形状的张量
    yield SampleInput(_tensor((M, S)), 1, _gather((S, S), 0, S), _tensor((S, S)))
    # 返回一个SampleInput对象，参数为(M, S)的张量、-1、(S, S)形状的_gather结果、(S, S)形状的张量
    yield SampleInput(_tensor((M, S)), -1, _gather((S, S), 0, S), _tensor((S, S)))
    # 返回一个SampleInput对象，参数为(M, S)的张量、0、(M, S//2)形状的_gather结果、(M, S//2)形状的张量
    yield SampleInput(_tensor((M, S)), 0, _gather((M, S // 2), 1, M), _tensor((M, S // 2)))
    # 返回一个SampleInput对象，参数为(M, S)的张量、1、(M, S//2)形状的_gather结果、(M, S//2)形状的张量
    yield SampleInput(_tensor((M, S)), 1, _gather((M, S // 2), 0, S), _tensor((M, S // 2)))
    # 返回一个SampleInput对象，参数为(M, S)的张量、-1、(M, S//2)形状的_gather结果、(M, S//2)形状的张量
    yield SampleInput(_tensor((M, S)), -1, _gather((M, S // 2), 0, S), _tensor((M, S // 2)))
    # 返回一个SampleInput对象，参数为()的张量、0、zero张量的克隆结果、()的张量
    yield SampleInput(_tensor(()), 0, zero.clone().detach(), _tensor(()))
# 定义函数，生成用于测试的输入样本，用于散列减少操作
def sample_inputs_scatter_reduce(op_info, device, dtype, requires_grad, **kwargs):
    # 创建部分函数，用于生成具有指定属性的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 创建部分函数，用于收集操作
    gather = partial(gather_variable, device=device)

    # 创建零张量，用作测试用例的一部分
    zero = torch.tensor(0, dtype=torch.long, device=device)
    # 定义多个测试用例，每个用例包含输入形状、维度、索引、源张量形状和是否包括自身的信息
    test_cases = (
        ((M, S), 0, gather((S, S), 1, M), (S, S)),     # 情况1
        ((M, S), 1, gather((S, S), 0, S), (S, S)),     # 情况2
        ((M, S), -1, gather((S, S), 0, S), (S, S)),    # 情况3
        ((M, S), 0, gather((M, S // 2), 1, M), (M, S // 2)),  # 情况4
        ((M, S), 1, gather((M, S // 2), 0, S), (M, S // 2)),  # 情况5
        ((M, S), -1, gather((M, S // 2), 0, S), (M, S // 2)), # 情况6
        ((), 0, zero.clone().detach(), ()),           # 情况7
    )

    # 获取操作的减少变体名称
    reduce = op_info.variant_test_name
    # 生成每个测试用例及其是否包含自身的所有组合
    for (inp_shape, dim, index, src_shape), include_self in product(test_cases, [False, True, False]):
        # 返回一个样本输入对象，用于测试
        yield SampleInput(make_arg(inp_shape),
                          args=(dim, index, make_arg(src_shape), reduce),
                          kwargs={'include_self': include_self})

    # 用于测试反向传播的边缘情况的样本输入
    # 检查在prod操作中，当self/src中存在零时，梯度是否正确传播
    if requires_grad and reduce == 'prod':
        # 这个样本测试以下情况的梯度传播：
        # (a) 减少了1个零（来自src（self[0, 1], self[1, 1]），来自self（self[0, 0], self[2, 0]））
        # (b) 减少了2个零（1个来自src和1个来自self（self[1, 0]））
        # (c) 没有减少零（self（[2, 1]））
        # (d) 减少了2个零（都来自src）在test/test_autograd.py中进行测试，
        #     test_scatter_index_reduce_prod_gradgrad_error，因为这种情况不支持gradgrad
        input = torch.tensor([[0, 13], [0, 17], [0, 19]], dtype=dtype, device=device, requires_grad=requires_grad)
        src = torch.tensor([[0, 1, 2, 3], [0, 4, 0, 1], [2, 3, 5, 6]], dtype=dtype, device=device, requires_grad=requires_grad)
        idx = torch.tensor([[1, 1, 0, 0], [0, 0, 1, 1], [0, 0, 0, 1]], dtype=torch.long, device=device)

        yield SampleInput(input,
                          args=(1, idx, src, reduce),
                          kwargs={'include_self': True})

# 定义函数，生成用于测试的输入样本，用于段减少操作
def sample_inputs_segment_reduce(op_info, device, dtype, requires_grad, *, mode='lengths', **kwargs):
    # 定义内部函数，生成指定形状的张量
    def _tensor(shape, dtype=dtype, low=None, high=None):
        return make_tensor(shape, dtype=dtype, device=device, low=low, high=high, requires_grad=requires_grad)

    # 创建零张量，用作测试用例的一部分
    zero = torch.tensor(0, dtype=torch.long, device=device)
    test_cases = (
        # 定义测试用例元组
        # inp_shape, dim, lengths, unsafe
        ((S,), 0, [0, 1, 2, 2], False),
        ((S,), 0, [0, 1, 2, 2], True),
        ((S,), 0, [2, 0, 3, 0], False),
        ((S, S), 0, [0, 1, 2, 2], False),
        # 当 lengths 不等于 dim 大小时的测试
        ((M, S, S), 0, [1, 2, 0, 6, 0], True),
        # 高维度测试
        ((S, S), 1, [[0, 1, 2, 2] for _ in range(S)], False),
        ((S, S), 1, [[2, 0, 3, 0], [0, 1, 2, 2], [3, 0, 2, 0], [1, 1, 1, 2], [0, 1, 2, 2]], False),
        ((S, S, S), 1, [[0, 1, 2, 2] for _ in range(S)], False),
        ((S, S, S), 1, [[2, 0, 3, 0], [0, 1, 2, 2], [3, 0, 2, 0], [1, 1, 1, 2], [0, 1, 2, 2]], False),
    )

    reductions = ["max", "mean", "min", "sum", "prod"]
    # 使用 product 函数生成所有可能的参数组合
    for args, reduce, initial in product(test_cases, reductions, [1, 2]):
        # 解包参数元组
        inp_shape, dim, lengths, unsafe = args
        # 将 lengths 转换为 torch.tensor，并指定设备和数据类型
        lengths_t = torch.tensor(lengths, dtype=torch.long, device=device)
        # 定义 sample_input_kwargs 字典，包含参数 axis, unsafe, initial
        sample_input_kwargs = {'axis': dim, 'unsafe': unsafe, 'initial': initial}
        if mode == 'lengths':
            # 如果 mode 是 'lengths'，添加 'lengths' 到 sample_input_kwargs
            sample_input_kwargs['lengths'] = lengths_t
        elif mode == 'offsets':
            # 如果 mode 是 'offsets'
            zeros_shape = list(lengths_t.shape)
            zeros_shape[dim] = 1
            # 创建 offsets_t，首先填充零，然后按 dim 维度累加
            offsets_t = torch.cat((lengths_t.new_zeros(zeros_shape), lengths_t), dim).cumsum_(dim)
            sample_input_kwargs['offsets'] = offsets_t
        else:
            # 如果 mode 不是 'offsets' 或 'lengths'，抛出运行时错误
            raise RuntimeError(f"mode most be one of 'offsets' or 'lengths' got '{mode}'.")
        # 使用 yield 生成 SampleInput 对象，包括 _tensor(inp_shape), reduce, sample_input_kwargs
        yield SampleInput(_tensor(inp_shape),
                          args=(reduce,),
                          kwargs=sample_input_kwargs)
def sample_inputs_ravel(op_info, device, dtype, requires_grad, **kwargs):
    # 创建部分函数 make_arg，用于生成张量
    make_arg = partial(make_tensor, dtype=dtype, device=device,
                       low=None, high=None, requires_grad=requires_grad)
    # 生成并返回一个张量的 SampleInput 对象，形状为 (S, S, S)
    yield SampleInput(make_arg((S, S, S)))
    # 生成并返回一个张量的 SampleInput 对象，形状为空元组 ()
    yield SampleInput(make_arg(()))
    # 生成并返回一个张量的 SampleInput 对象，形状为 (S, S, S)，并指定为非连续
    yield SampleInput(make_arg((S, S, S), noncontiguous=True))

def sample_inputs_unravel_index(op_info, device, dtype, requires_grad, **kwargs):
    # 创建部分函数 make_arg，用于生成张量
    make_arg = partial(make_tensor, dtype=dtype, device=device,
                       low=None, high=None, requires_grad=requires_grad)
    # 生成并返回一个张量的 SampleInput 对象，形状为 (2, 3)，值为指定的二维索引
    yield SampleInput(
        torch.tensor(
            [[3, 8, 13], [0, 5, 10]],
            device=device,
            dtype=dtype),
        (4, 5))
    # 生成并返回一个张量的 SampleInput 对象，形状为 (2, 3)，但列数超过限制
    yield SampleInput(
        torch.tensor([[3, 8, 13], [0, 5, 10]], device=device, dtype=dtype),
        (4, 2**30))
    # 生成并返回一个张量的 SampleInput 对象，形状为 (2, 3)，但行数超过限制
    yield SampleInput(
        torch.tensor([[3, 8, 13], [0, 5, 10]], device=device, dtype=dtype),
        (2**30, 4))
    # 生成并返回一个张量的 SampleInput 对象，形状为 (2, 2)，值为指定的标量
    yield SampleInput(
        torch.tensor(2, device=device, dtype=dtype),
        (2, 2))
    # 计算最大值，用于生成张量
    max_val = 2**(8 * dtype.itemsize - (1 if dtype.is_signed else 0)) - 1
    # 生成并返回一个张量的 SampleInput 对象，形状为 (1, max_val)，值接近最大值
    yield SampleInput(
        torch.tensor(max_val - 1, device=device, dtype=dtype),
        (1, max_val))
    # 生成并返回一个张量的 SampleInput 对象，形状为 (3,)，值为指定的一维索引
    yield SampleInput(
        torch.tensor([22, 41, 37], device=device, dtype=dtype),
        (7, 6))
    # 生成并返回一个张量的 SampleInput 对象，形状为 (4, 6, 7, 8)，值为指定的一维索引
    yield SampleInput(
        torch.tensor(min(1621, max_val), device=device, dtype=dtype),
        (6, 7, 8, 9))
    # 生成并返回一个张量的 SampleInput 对象，形状为 (10, 3, 5)，值为空的张量
    yield SampleInput(
        torch.tensor([], device=device, dtype=dtype),
        (10, 3, 5))
    # 生成并返回一个张量的 SampleInput 对象，形状为 (2, 6)，值为指定的二维索引
    yield SampleInput(
        torch.tensor(
            [[1, 0, 1, 2, 3, 4], [1, 6, 1, 3, 2, 0]],
            device=device,
            dtype=dtype),
        (5, 8))
    # 生成并返回一个张量的 SampleInput 对象，形状为 (3, 5, 8, 10)，值为指定的三维索引
    yield SampleInput(
        torch.tensor(
            [[1, 0, 1, 2, 3, 4], [1, 6, 1, 3, 2, 0], [1, 3, 1, 0, 9, 5]],
            device=device,
            dtype=dtype),
        (5, 8, 10))
    # 生成并返回一个张量的 SampleInput 对象，形状为空元组 ()，值为指定的标量
    yield SampleInput(
        torch.tensor(0, device=device, dtype=dtype),
        ())

    # 创建两个 NumPy 数组 a 和 b
    a = np.array([[2, 4, 5, 6], [7, 8, 1, 15]])
    b = np.array([[3, 2, 7, 6], [10, 12, 8, 9]])
    # 计算两个数组的交集，并返回相应的索引
    _, i1, i2 = np.intersect1d(a, b, assume_unique=True, return_indices=True)
    # 生成并返回一个张量的 SampleInput 对象，形状为 (2,)，值为指定的一维索引
    yield SampleInput(torch.tensor(i1, device=device, dtype=dtype), a.shape)
    # 生成并返回一个张量的 SampleInput 对象，形状为 (2,)，值为指定的一维索引
    yield SampleInput(torch.tensor(i2, device=device, dtype=dtype), b.shape)

    # 创建两个 NumPy 数组 a 和 b
    a = np.array([[2, 4, 5, 6, 6], [4, 7, 8, 7, 2]])
    b = np.array([[3, 2, 7, 7], [10, 12, 8, 7]])
    # 计算两个数组的交集，并返回相应的索引
    _, i1, i2 = np.intersect1d(a, b, return_indices=True)
    # 生成并返回一个张量的 SampleInput 对象，形状为 (3,)，值为指定的一维索引
    yield SampleInput(torch.tensor(i1, device=device, dtype=dtype), a.shape)
    # 生成并返回一个张量的 SampleInput 对象，形状为 (2,)，值为指定的一维索引
    yield SampleInput(torch.tensor(i2, device=device, dtype=dtype), b.shape)


def sample_inputs_tril_triu(op_info, device, dtype, requires_grad, **kwargs):
    # 创建部分函数 make_arg，用于生成张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 定义测试用例集合，每个测试用例包含一个形状元组和参数元组
    cases = (((M, M), ()),           # 二维矩阵形状，无参数
             ((M, M), (2,)),         # 二维矩阵形状，参数为2
             ((M, S), ()),           # 一维矩阵形状，无参数
             ((M, S), (-1,)),        # 一维矩阵形状，参数为-1
             ((M, M), (2,)),         # 二维矩阵形状，参数为2
             ((S, M, S), ()),        # 三维矩阵形状，无参数
             ((S, M, S), (2,)),      # 三维矩阵形状，参数为2
             ((3, 3, S, S), ()),)    # 多维矩阵形状，无参数

    # 遍历测试用例集合
    for shape, args in cases:
        # 使用函数 make_arg() 根据形状生成参数，并将参数元组传入
        yield SampleInput(make_arg(shape), args=args)
def error_inputs_tril_triu(opinfo, device, **kwargs):
    # 创建一个部分应用了设备和数据类型参数的函数make_tensor，用于生成张量
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    # 生成错误的输入，当输入张量的维度小于等于2时报错
    yield ErrorInput(SampleInput(make_arg((4,))), error_regex="input tensor must have at least 2 dimensions")

def sample_inputs_trilu_indices(op_info, device, dtype, requires_grad, **kwargs):
    # 定义包含各种输入参数的元组列表，用于测试trilu_indices函数
    args_list = ((0, 0),
                 (20, 0),
                 (0, 20),
                 (20, 21, 0),
                 (20, 21, 7),
                 (20, 21, -7),
                 # 下面的大型测试案例故意被注释掉，以加快CI测试速度并避免OOM错误。
                 # 在修改tril_indices和triu_indices的实现时，请启用这些测试并确保它们通过。
                 # (2, 68435455, 3),
                 # (5000, 5000),
                 # (5000, 5000, 1234),
                 # (5000, 5000, -1233),
                 )
    for args in args_list:
        # 生成一个SampleInput对象，用于表示trilu_indices的输入样本
        yield SampleInput(args[0], args=args[1:], kwargs={"dtype": dtype, "device": device})

def sample_inputs_clone_contiguous(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了数据类型、设备和梯度需求参数的函数make_tensor，用于生成张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 生成克隆和连续张量的输入样本
    yield SampleInput(make_arg((S, M, S)))
    yield SampleInput(make_arg(()))

def reference_inputs_clone_contiguous(op, device, dtype, requires_grad, **kwargs):
    # 注意：克隆操作的默认内存格式是torch.preserve_format，而连续张量是torch.contiguous_format
    # 利用默认值来测试克隆中的torch.preserve_format，同时避免在测试连续性时出错
    yield from sample_inputs_clone_contiguous(op, device, dtype, requires_grad, **kwargs)

    # 定义多种形状的输入张量样本
    shapes = (
        (3, 5, 6),
        (1, 1, 3, 5, 6),
        (1, 1, 3, 5, 6, 1, 1),
        (1, 0, 3, 5, 0, 2),
        (1, 0, 3, 5, 0, 0, 1, 1, 2),
        (),
    )

    # 创建一个部分应用了数据类型、设备和梯度需求参数的函数make_tensor，用于生成张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    
    # 遍历不同形状的输入张量样本，生成对应的SampleInput对象
    for shape in shapes:
        yield SampleInput(make_arg(shape))
        yield SampleInput(make_arg(shape).transpose(0, -1))
        yield SampleInput(make_arg(shape, noncontiguous=True))
        yield SampleInput(make_arg(shape, noncontiguous=True).transpose(0, -1))

        # 在指定内存格式为torch.contiguous_format的情况下，生成对应的SampleInput对象
        yield SampleInput(make_arg(shape), kwargs={'memory_format': torch.contiguous_format})
        yield SampleInput(make_arg(shape).transpose(0, -1), kwargs={'memory_format': torch.contiguous_format})
        yield SampleInput(make_arg(shape, noncontiguous=True), kwargs={'memory_format': torch.contiguous_format})
        yield SampleInput(make_arg(shape, noncontiguous=True).transpose(0, -1), kwargs={'memory_format': torch.contiguous_format})

    # shape, strides, offset
    # 定义一个元组 strided_cases，包含多个元组作为元素，每个元组包含三个元素：shape、strides 和 offset
    strided_cases = (
        ((5, 6, 2), (1, 1, 7), 2),    # 第一个元组
        ((5, 5, 4), (1, 1, 7), 2),    # 第二个元组
        ((5, 5, 2), (4, 5, 7), 3),    # 第三个元组
        ((5, 5, 2), (5, 5, 7), 3),    # 第四个元组
        ((5, 5, 2), (5, 5, 5), 3),    # 第五个元组
        ((9, 5, 2), (0, 1, 7), 3),    # 第六个元组
    )

    # 遍历 strided_cases 元组中的每个元组，生成 SampleInput 对象
    for shape, strides, offset in strided_cases:
        # 使用 make_arg 函数生成一个 as_strided 的输入示例，作为 yield 的第一个参数
        yield SampleInput(make_arg(500,).as_strided(shape, strides, offset))
        # 使用 make_arg 函数生成一个 as_strided 的输入示例，并指定 memory_format 为 torch.contiguous_format，作为 yield 的第一个参数
        yield SampleInput(make_arg(500,).as_strided(shape, strides, offset), kwargs={'memory_format': torch.contiguous_format})

    # channels last 2D
    # 生成一个 channels_last 的输入示例，作为 yield 的第一个参数
    yield SampleInput(make_arg((2, 2, 2, 2)), kwargs={'memory_format': torch.channels_last})
    # 创建一个张量 a，通过 permute 将通道维度置换到指定位置，并作为 yield 的第一个参数
    a = make_arg((2, 2, 2, 2)).permute(0, 3, 1, 2)
    yield SampleInput(a, kwargs={'memory_format': torch.channels_last})

    # channels last 3D
    # 生成一个 channels_last_3d 的输入示例，作为 yield 的第一个参数
    yield SampleInput(make_arg((2, 2, 2, 2, 2)), kwargs={'memory_format': torch.channels_last_3d})
    # 创建一个张量 a，通过 permute 将通道维度置换到指定位置，并作为 yield 的第一个参数
    a = make_arg((2, 2, 2, 2, 2)).permute(0, 4, 1, 2, 3)
    yield SampleInput(a, kwargs={'memory_format': torch.channels_last_3d})
def sample_inputs_sum_to_size(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了 make_tensor 函数的函数 make_arg，用于创建具有指定参数的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义示例输入和输出张量的形状的列表
    sample_shapes = [
        ((), ()),           # 空元组到空元组
        ((S,), (1,)),       # 形状为 (S,) 的输入到形状为 (1,) 的输出
        ((S, S), (1, 1)),   # 形状为 (S, S) 的输入到形状为 (1, 1) 的输出
        ((S, S), (1, S)),   # 形状为 (S, S) 的输入到形状为 (1, S) 的输出
        ((S, S), (S, S)),   # 形状为 (S, S) 的输入到形状为 (S, S) 的输出
        ((S, S, S), (S, 1, S)),  # 形状为 (S, S, S) 的输入到形状为 (S, 1, S) 的输出
    ]

    # 遍历示例形状，并生成 SampleInput 对象
    for input_shape, output_shape in sample_shapes:
        yield SampleInput(make_arg(input_shape), args=(output_shape,))
        # 如果输出形状是空元组，则跳过后续步骤
        if output_shape == ():
            continue
        yield SampleInput(make_arg(input_shape), args=(list(output_shape),))
        yield SampleInput(make_arg(input_shape), args=(*output_shape,))


def error_inputs_sum_to_size(op_info, device, **kwargs):
    # 定义错误输入的形状和错误信息
    shape = (M, S, M)
    err_msg = "is not expandable to size"
    # 创建 SampleInput 对象，使用 make_tensor 函数创建具有指定参数的张量
    si = SampleInput(make_tensor(shape, device=device, dtype=torch.float32), args=(M, M))
    yield ErrorInput(si, error_regex=err_msg)

    shape = (M + 1, S, S, M)
    err_msg = "is not expandable to size"
    si = SampleInput(make_tensor(shape, device=device, dtype=torch.float32), args=(M + 1, 1))
    yield ErrorInput(si, error_regex=err_msg)


def sample_inputs_resize_ops(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了 make_tensor 函数的函数 make_arg，用于创建具有指定参数的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device)
    # 定义不同的调整操作示例
    cases = (((S, S, S), (S * S, S)),  # resize_ 操作示例
             ((), ()),                 # resize_ 操作空输入示例
             ((), (1, 1, 1)),          # resize_ 操作空输入到 (1, 1, 1) 示例
             )

    # 遍历不同的示例形状和参数
    for shape, args_or_shape in cases:
        # 根据操作符更新参数 args
        if op_info.name == 'resize_':
            # resize_ 操作使用形状或整数元组作为参数
            args = (args_or_shape, )
        elif op_info.name == 'resize_as_':
            # resize_as_ 操作使用另一个张量作为参数
            args = (make_arg(shape, requires_grad=False), )  # type:ignore[assignment]
        else:
            raise ValueError("sample_inputs_resize_ops is being used with incorrect operator")

        # 生成 SampleInput 对象，使用 make_arg 函数创建输入张量
        yield SampleInput(make_arg(shape, requires_grad=requires_grad), args=args)


def sample_inputs_view_reshape(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用了 make_tensor 函数的函数 make_arg，用于创建具有指定参数的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义不同的视图和重塑操作示例
    cases = (
        ((S, S, S), (S * S, S), True),     # 支持张量的正常视图示例
        ((S * S, S), (S, S, S), True),     # 支持张量的正常重塑示例
        ((S * S, S), (S, -1, S), False),   # 不支持的负索引示例
        ((S * S * 2, S), (S, -1), False),  # 不支持的负索引示例
        ((S,), (S,), True),               # 支持张量的正常视图示例
        ((), (), False),                  # 空输入，不支持示例
        ((), (1,), True),                 # 空输入到 (1,) 支持示例
    )

    # 遍历不同的示例形状和参数
    for a, b, is_tensor_supported in cases:
        # 如果有指定 tensor_arg 参数且不支持，则跳过该示例
        if kwargs.get("tensor_arg") and not is_tensor_supported:
            continue

        # 如果有指定 tensor_arg 参数，则将 b 转换为张量
        if kwargs.get("tensor_arg"):
            b = make_arg(b, requires_grad=False)

        # 生成 SampleInput 对象，使用 make_arg 函数创建输入张量
        yield SampleInput(make_arg(a), args=(b,))
    # 从 sample_inputs_view_reshape 函数生成迭代器的结果
    yield from sample_inputs_view_reshape(op, device, dtype, requires_grad, **kwargs)

    # 定义一系列测试用例
    cases = (
        # a, b, is_tensor_supported
        ((125,), (25, 5), True),
        ((25, 25), (1, 5, 5, 1, 5, 1, 5, 1), True),
        ((16, 32), (2, 4, 1, 4, 4, 1, 4), True),
        ((16, 12), (12, 16), True),
        ((1, 16, 12), (12, 16), True),
        ((1, 5, 1, 5), (25, 1), True),
        ((2, 4, 2), (4, 4), True),
        ((1, 4), (1, 1, 2, 1, 2), True),
        ((3, 5, 7), (7, 5, 3), True),
        ((1,), (), False),  # empty
        ((5, 0, 2, 3), (5, 0, 2, 3), True),
        ((2, 1, 0, 3, 1), (5, 0), True),
        ((1,), (), False),  # empty
        ((4, 5, 6), (4, 5, 6, 1, 1, 1), True),
        ((), (1, 1, 1, 1), False),  # empty
    )

    # 定义一些不可逆的测试用例
    irreversible_cases = (
        ((), (-1,), False),  # neg index, empty
        ((4, 7, 9, 1, 1), (1, 4, 3, -1, 1), False),  # neg index
    )

    # 使用偏函数创建 make_arg 函数，用于创建张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    
    # 遍历所有可逆的测试用例
    for a, b, is_tensor_supported in cases:
        # 如果当前测试用例不受支持且需要张量参数，则跳过
        if kwargs.get("tensor_arg") and not is_tensor_supported:
            continue

        if kwargs.get("tensor_arg"):
            # 如果需要张量参数，则生成两个 SampleInput 对象，分别对应 a 和 b
            yield SampleInput(make_arg(a), args=(make_arg(b, requires_grad=False),))
            yield SampleInput(make_arg(b), args=(make_arg(a, requires_grad=False),))
        else:
            # 否则生成两个 SampleInput 对象，一个是 a，一个是 b
            yield SampleInput(make_arg(a), args=(b,))
            yield SampleInput(make_arg(b), args=(a,))

    # 遍历所有不可逆的测试用例
    for a, b, is_tensor_supported in irreversible_cases:
        # 如果当前测试用例不受支持且需要张量参数，则跳过
        if kwargs.get("tensor_arg") and not is_tensor_supported:
            continue

        # 如果需要张量参数，则将 b 转换为张量
        if kwargs.get("tensor_arg"):
            b = make_arg(b, requires_grad=False)

        # 生成一个 SampleInput 对象，对应 a 和 b
        yield SampleInput(make_arg(a), args=(b,))
def error_inputs_view_reshape(op, device, **kwargs):
    # 定义不同情况下的输入和是否支持张量操作的元组列表
    cases = (
        # a, b, is_tensor_supported
        # Reshape to different numel
        ((2,), (), False),  # 空数组
        ((1, 3, 0), (), False),  # 空数组
        ((4, 3), (4, 2), True),  # 可以reshape
        ((1, 3, 5), (5, 2, 2), True),  # 可以reshape
        # No valid inference
        ((1, 3, 5), (5, -1, 2), False),  # 负索引
        # Two inferred shapes
        ((1, 3, 5), (5, -1, -1), False),  # 负索引
        ((1), (0, -1), False),  # 负索引
        ((0, 5), (0, -1), False),  # 负索引
    )

    # 创建一个部分应用了make_tensor的函数，用于创建张量
    make_arg = partial(make_tensor, dtype=torch.float32, device=device, requires_grad=False)
    
    # 遍历所有情况
    for a, b, is_tensor_supported in cases:
        # 如果设置了tensor_arg参数并且当前情况不支持张量操作，则跳过
        if kwargs.get("tensor_arg") and not is_tensor_supported:
            continue

        # 设置错误正则表达式以匹配不同情况的异常信息
        if b == (5, -1, -1):
            error_regex = "only one dimension can be inferred"
        elif a == (0, 5):
            error_regex = (r"cannot reshape tensor of 0 elements into shape "
                           r"\[0, -1\] because the unspecified dimension size "
                           r"-1 can be any value and is ambiguous")
        else:
            # 组合形状和大小以构建错误正则表达式
            shape = ', '.join(map(str, b))
            size = a if type(a) is int else functools.reduce(operator.mul, a, 1)
            error_regex = rf"shape '\[{shape}\]' is invalid for input of size {size}"

        # 如果设置了tensor_arg参数，则将b转换为张量
        if kwargs.get("tensor_arg"):
            b = make_arg(b, requires_grad=False)

        # 生成一个ErrorInput对象，包含SampleInput和异常信息的正则表达式
        yield ErrorInput(SampleInput(make_arg(a), args=(b,)), error_type=Exception,
                         error_regex=error_regex)


def sample_inputs_atleast1d2d3d(op_info, device, dtype, requires_grad, **kwargs):
    # 定义不同形状的输入列表
    input_list = []
    shapes = ((S, S, S, S), (S, S, S), (S, S), (S, ), (),)
    # 部分应用make_tensor函数，用于创建张量
    make_tensor_partial = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 遍历所有形状，并生成SampleInput对象
    for shape in shapes:
        yield SampleInput(make_tensor_partial(shape))
    # 生成包含多个张量的SampleInput对象
    yield SampleInput([make_tensor_partial(shape) for shape in shapes])


def sample_inputs_column_stack(op_info, device, dtype, requires_grad, **kwargs):
    # 定义不同形状对的元组列表
    cases: Tuple[tuple, tuple] = (  # type: ignore[assignment]
        ((S, 2, 1), (S, 3, 1)),
        ((S), (S, 5)), ((), (1, S))
    )
    # 部分应用make_tensor函数，用于创建张量
    make_tensor_partial = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 遍历所有形状对，并生成SampleInput对象
    for shape1, shape2 in cases:
        yield SampleInput([make_tensor_partial(shape1), make_tensor_partial(shape2)])


def sample_inputs_flatten(op_info, device, dtype, requires_grad, **kwargs):
    # 定义不同形状的输入列表
    shapes = ((S, S, S), (S, S), (S, ), (),)
    # 部分应用make_tensor函数，用于创建张量
    make_tensor_partial = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    # 遍历所有形状，并生成SampleInput对象
    for shape in shapes:
        yield SampleInput(make_tensor_partial(shape))
        # 如果形状的维数大于1，则生成带有指定起始和结束维度的SampleInput对象
        if len(shape) > 1:
            yield SampleInput(make_tensor_partial(shape), start_dim=1, end_dim=-1)
# 生成器函数，用于生成扁平化的输入样本，通过调用sample_inputs_flatten函数实现
def reference_inputs_flatten(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_flatten(op, device, dtype, requires_grad, **kwargs)

    # 定义不同情况下的shape、起始维度和结束维度的元组
    cases = (
        ((5, 4, 0, 1, 3, 7), 1, 3),       # 第一种情况
        ((5, 4, 0, 1, 3, 7), 4, 5),       # 第二种情况
        ((5, 4, 1, 1, 3, 7), 2, 3),       # 第三种情况
        ((), 0, -1),                    # 第四种情况
        ((1,), 0, -1),                  # 第五种情况
        ((3, 7, 5), 1, 2),               # 第六种情况
        ((4, 5), 1, 1),                  # 第七种情况
        ((1, 5, 5, 1, 5, 1, 5, 1), 0, 2), # 第八种情况
        ((1, 5, 5, 1, 5, 1, 5, 1), 3, -1),# 第九种情况
        ((1, 5, 5, 1, 5, 7, 5, 1), -2, -1),# 第十种情况
        ((2, 4, 2), 0, 1),               # 第十一种情况
        ((4, 2, 2), 1, 2),               # 第十二种情况
        ((0, 3, 4, 5), 1, 3),            # 第十三种情况
    )

    # 部分应用make_tensor函数，创建特定参数的张量生成函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 遍历所有情况，生成对应的SampleInput实例
    for shape, start, end in cases:
        yield SampleInput(make_arg(shape), args=(start, end,))
        yield SampleInput(make_arg(shape, noncontiguous=True).transpose(0, -1), args=(start, end,))
        yield SampleInput(make_arg(shape).transpose(0, -1), args=(start, end,))


# 生成器函数，用于生成解扁平化输入样本，通过调用make_tensor函数实现
def sample_inputs_unflatten(op_info, device, dtype, requires_grad, **kwargs):
    # 定义不同情况下的输入形状、维度和大小的元组
    args = (((8,), 0, (8,)),              # 第一种情况
            ((8,), 0, (4, 2)),            # 第二种情况
            ((8,), -1, (2, 2, 2)),        # 第三种情况
            ((8,), -1, (-1, 2)),          # 第四种情况
            ((3, 6, 2), 1, (2, 3)),       # 第五种情况
            ((3, 6, 2), -2, (2, 3)),      # 第六种情况
            ((3, 6, 2), -2, (-1, 3)),     # 第七种情况
            ((3, 2, 12), 2, (3, 2, 2)),   # 第八种情况
            ((4, 0), 0, (2, 2)),          # 第九种情况
            ((4, 0), 1, (2, 0, 0, 0)),    # 第十种情况
            )
    
    # 部分应用make_tensor函数，创建特定参数的张量生成函数
    make_tensor_partial = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 遍历所有情况，生成对应的SampleInput实例
    for in_shape, dim, sizes in args:
        yield SampleInput(make_tensor_partial(in_shape), args=(dim, sizes))


# 生成器函数，用于生成选择操作的输入样本，通过调用make_tensor函数实现
def sample_inputs_select(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用make_tensor函数，创建特定参数的张量生成函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义不同情况下的形状和选择参数的元组
    cases = (((S, S, S), (1, 2)),          # 第一种情况
             ((S, S, S), (-1, 2)),         # 第二种情况
             ((S, S, S), (-1, -1)),        # 第三种情况
             ((S, S, S), (1, -1)),         # 第四种情况
             ((S,), (0, 2))                # 第五种情况
             )

    # 遍历所有情况，生成对应的SampleInput实例
    for shape, args in cases:
        yield SampleInput(make_arg(shape), args=args)


# 生成器函数，用于生成选择散布操作的输入样本，通过调用make_tensor函数实现
def sample_inputs_select_scatter(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用make_tensor函数，创建特定参数的张量生成函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义不同情况下的输入形状、源形状和选择参数的元组
    cases = (((S, S, S), (S, S), (1, 2)),        # 第一种情况
             ((S, S, S), (S, S), (-1, 2)),       # 第二种情况
             ((S, S, S), (S, S), (-1, -1)),      # 第三种情况
             ((S, S, S), (S, S), (1, -1)),       # 第四种情况
             ((S,), (), (0, 2))                 # 第五种情况
             )

    # 遍历所有情况，生成对应的SampleInput实例
    for input_shape, src_shape, args in cases:
        input_ = make_arg(input_shape)
        src = make_arg(src_shape)
        yield SampleInput(input_, args=(src, *args))


# 生成器函数，用于生成切片散布操作的输入样本，通过调用make_tensor函数实现
def sample_inputs_slice_scatter(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用make_tensor函数，创建特定参数的张量生成函数
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    cases = (((L, L, L), (L, L, L,), (0, 0, L, 1)),
             ((L, L, L), (L // 2, L, L,), (0, L // 2, L, 1)),
             ((L, L, L), (L // 4, L, L,), (0, L // 2, L, 2)),
             ((L, L, L), (L, L, L,), (1, 0, L, 1)),
             ((L, L, L), (L, L // 2, L,), (1, L // 2, L, 1)),
             ((L, L, L), (L, L // 4, L,), (1, L // 2, L, 2)),
             ((L, L, L), (L, L, L,), (2, 0, L, 1)),
             ((L, L, L), (L, L, L // 2,), (2, L // 2, L, 1)),
             ((L, L, L), (L, L, L // 4,), (2, L // 2, L, 2)),
             )

```    
    for input_shape, src_shape, args in cases:
        # 使用 make_arg 函数创建输入参数 input_
        input_ = make_arg(input_shape)
        # 使用 make_arg 函数创建源参数 src
        src = make_arg(src_shape)
        # 生成一个 SampleInput 对象并使用 yield 返回
        yield SampleInput(input_, args=(src, *args))
# 定义一个函数，用于生成扩展的样本输入数据
def sample_inputs_expand(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于生成具有指定设备、数据类型和梯度属性的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义不同的案例，每个案例包含输入张量的形状和传递给函数的参数
    cases = (((S, 1, 1), (S, S, S)),
             ((S, 1, S), (S, S, S)),
             ((S, 1, S), (-1, S, -1)),
             ((S, 1, S), (-1, S, S)),
             ((S, 1), (S, S, S)),
             ((1,), (S, S, S)),
             ((1, S), (1, 1, S)),
             ((), ()),
             ((), (1, 3, 2)),
             )

    # 遍历每个案例
    for case in cases:
        shape, args = case
        # 生成一个 SampleInput 对象，并使用 make_arg 函数生成输入张量，设置 args 参数
        yield SampleInput(make_arg(shape), args=(args,))

# 定义一个函数，用于生成转换操作的样本输入数据
def sample_inputs_conversion(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于生成具有指定设备、数据类型和梯度属性的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义不同的形状和内存格式选项的组合
    shapes = ((),
              (2, 3))
    memory_format_options = [None, torch.contiguous_format]

    # 生成每种形状和内存格式选项的 SampleInput 对象
    for shape, memory_format in itertools.product(shapes, memory_format_options):
        yield SampleInput(make_arg(shape),
                          kwargs={'memory_format': memory_format} if memory_format else {})
    # 生成一个特殊的 SampleInput 对象，使用 channels_last 内存格式
    yield SampleInput(make_arg((2, 3, 2, 3)), kwargs={'memory_format': torch.channels_last})

# 定义一个函数，用于生成根据另一个张量扩展形状的样本输入数据
def sample_inputs_expand_as(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于生成具有指定设备的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device)

    # 定义不同的案例，每个案例包含要扩展的张量形状和作为参考的另一个张量形状
    cases = (((S, 1, 1), (S, S, S)),
             ((), ()),
             ((), (1, 1)),
             )

    # 遍历每个案例
    for shape, shape_other in cases:
        # 生成一个 SampleInput 对象，并使用 make_arg 函数生成输入张量，设置 args 参数
        yield SampleInput(make_arg(shape, requires_grad=requires_grad),
                          args=(make_arg(shape_other, requires_grad=False),))

# 定义一个函数，用于生成根据条件生成掩码的样本输入数据
def sample_inputs_where(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于生成具有指定设备、数据类型和梯度属性的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 定义一个函数，用于生成布尔类型的掩码张量
    def make_bool_mask(shape):
        # 生成一个布尔类型的张量，确保至少有一个非零元素，空张量除外
        mask_t = make_tensor(shape, dtype=torch.bool, device=device, requires_grad=False)

        if mask_t.numel() == 0:
            return mask_t
        elif mask_t.numel() == 1:
            mask_t.fill_(True)
            return mask_t

        if mask_t.sum() == 0:
            # 如果掩码张量全为 False，则随机选择一个索引，将其设置为 True
            def random_index(shape):
                return tuple(random.randrange(0, max_idx) for max_idx in shape)

            mask_t[random_index(mask_t.shape)] = True
            return mask_t

        return mask_t

    # 定义不同的案例，每个案例包含输入张量的形状、掩码张量的形状、另一个张量的形状和是否进行广播输入的标志
    cases = (((M, M), (M, M), (M, M), False),
             ((M, 1, M), (M, M), (M, M, 1), True),
             ((), (), (), False),
             ((M, 1, M), (), (M, M, 1), True),
             ((), (M, M), (), True),
             ((), (2), (1, 1), True),
             )

    # 遍历每个案例
    for shape, mask_shape, other_shape, broadcasts_input in cases:
        # 生成一个 SampleInput 对象，并使用 make_arg 函数生成输入张量，设置 args 参数和 broadcasts_input 参数
        yield SampleInput(make_arg(shape),
                          args=(make_bool_mask(mask_shape), make_arg(other_shape)),
                          broadcasts_input=broadcasts_input)
# 生成器函数，产生符合条件的输入样本
def reference_inputs_where(op, device, dtype, requires_grad, **kwargs):
    # 从sample_inputs_where函数中生成输入样本
    yield from sample_inputs_where(op, device, dtype, requires_grad, **kwargs)

    # 创建部分函数，用于生成张量
    make_cond = partial(make_tensor, dtype=torch.bool, device=device, requires_grad=requires_grad)
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 创建非连续张量
    c = make_cond((10, 3), noncontiguous=True)  # 创建形状为(10, 3)的布尔类型张量，非连续
    a = make_arg((10, 1), noncontiguous=True)   # 创建形状为(10, 1)的指定数据类型张量，非连续
    b = make_arg((3, 10, 3)).transpose(0, -1)   # 创建形状为(3, 10, 3)的张量并转置

    # 注意：where操作的OpInfo要求样本的形式是a, cond, b
    yield SampleInput(a, args=(c, b))  # 生成一个SampleInput对象，作为输出的一部分

    # 类型提升
    other_dtype = torch.double if dtype is not torch.double else torch.long
    c = make_cond((10, 3), noncontiguous=True)  # 创建形状为(10, 3)的布尔类型张量，非连续
    a = make_arg((10, 1), dtype=torch.long)     # 创建形状为(10, 1)的长整型张量
    b = make_arg((10, 1))                       # 创建形状为(10, 1)的张量

    yield SampleInput(a, args=(c, b))  # 生成一个SampleInput对象，作为输出的一部分

    # 两个Python标量
    c = make_cond((10, 3), noncontiguous=True)  # 创建形状为(10, 3)的布尔类型张量，非连续
    a = make_arg((1,)).item()                   # 创建一个Python标量
    b = make_arg((1,)).item()                   # 创建一个Python标量

    yield SampleInput(a, args=(c, b))  # 生成一个SampleInput对象，作为输出的一部分

    # NaN传播
    if dtype.is_floating_point or dtype.is_complex:
        if dtype.is_floating_point:
            nan = float('nan')  # 如果数据类型是浮点数，则nan为浮点数NaN
        else:
            # dtype.is_complex
            nan = complex(float('nan'), float('nan'))  # 如果数据类型是复数，则nan为复数NaN
        c = make_cond((1, 10, 3))     # 创建形状为(1, 10, 3)的布尔类型张量
        a = make_arg((10, 3), noncontiguous=True)   # 创建形状为(10, 3)的指定数据类型张量，非连续
        a[2, 1] = nan                # 在张量a的特定位置设置NaN值
        b = make_arg((1, 3))         # 创建形状为(1, 3)的张量
        b[0, 2] = nan                # 在张量b的特定位置设置NaN值

        yield SampleInput(a, args=(c, b))  # 生成一个SampleInput对象，作为输出的一部分

    # Python标量类型提升
    for scalar in (0, 0.0, 2j, False):
        yield SampleInput(scalar, args=(c, b))  # 生成一个SampleInput对象，作为输出的一部分
        yield SampleInput(a, args=(c, scalar))  # 生成一个SampleInput对象，作为输出的一部分


# 错误输入示例生成器函数
def error_inputs_where(op_info, device, **kwargs):
    shape = (S,)   # 定义一个形状元组
    err_msg = "Expected all tensors to be on the same device"  # 错误消息
    for devices in product(('cpu', device), repeat=3):  # 遍历设备组合的笛卡尔积
        if len(set(devices)) == 2:  # 如果设备组合有两种不同的设备
            si = SampleInput(
                make_tensor(shape, device=devices[0], dtype=torch.float32),  # 在指定设备上创建浮点张量
                args=(make_tensor(shape, dtype=torch.bool, device=devices[1]),  # 在指定设备上创建布尔张量
                      make_tensor(shape, device=devices[2], dtype=torch.float32)))  # 在指定设备上创建浮点张量
            yield ErrorInput(si, error_regex=err_msg)  # 生成一个ErrorInput对象，作为输出的一部分


# 非零输入示例生成函数
def sample_inputs_nonzero(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    sizes = ((), (S,), (S, S), (S, S, S), (S, 1, S), (S, 0, S))  # 定义不同形状的尺寸元组

    inputs = []  # 输入列表
    for shape in sizes:
        # 构造全零元素的输入
        zeros = torch.zeros(shape, dtype=dtype, device=device, requires_grad=requires_grad)  # 创建全零张量
        inputs.append(zeros)  # 添加到输入列表中

        # 构造混合零和非零元素的输入
        mixed = make_arg(shape).requires_grad_(False)  # 创建指定形状的张量并设置不需要梯度
        mask_t = make_tensor(shape, dtype=torch.bool, device=device, requires_grad=False)  # 创建布尔类型的遮罩张量
        mixed[mask_t] = 0  # 将非零元素设置为零
        inputs.append(mixed)  # 添加到输入列表中
    # 使用 product 函数生成 inputs 和 [False, True] 的笛卡尔积，并进行迭代
    for input_t, as_tuple in product(inputs, [False, True]):
        # 生成一个新的 SampleInput 对象并 yield 返回，克隆 input_t，并根据 requires_grad 设置 requires_grad
        yield SampleInput(input_t.clone().requires_grad_(requires_grad),
                          # 将 as_tuple 参数作为字典 kwargs 的一个键值对传递给 SampleInput 构造函数
                          kwargs=dict(as_tuple=as_tuple))
def sample_inputs_nonzero_static(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于创建具有指定参数的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同的张量形状
    sizes = ((), (S,), (S, S), (S, S, S), (S, 1, S), (S, 0, S))

    inputs = []
    for shape in sizes:
        # 构造所有元素为零的输入张量
        zeros = torch.zeros(shape, dtype=dtype, device=device, requires_grad=requires_grad)
        inputs.append(zeros)

        # 构造包含混合零和非零元素的输入张量
        mixed = make_arg(shape).requires_grad_(False)
        mask_t = make_tensor(shape, dtype=torch.bool, device=device, requires_grad=False)
        mixed[mask_t] = 0
        inputs.append(mixed)

    # 非零元素的大小选项
    nonzero_sizes = [0, 1, XS, S, M]

    # 对于每个输入张量和每个非零大小选项，生成一个样本输入
    for input_t, nonzero_size in product(inputs, nonzero_sizes):
        yield SampleInput(input_t.clone().requires_grad_(requires_grad),
                          kwargs=dict(size=nonzero_size))

def sample_inputs_chunk(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分应用函数，用于创建具有指定参数的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同的案例，每个案例包含形状和参数元组
    cases = (((S, S, S), (2,)),
             ((S, S, S), (S, 1)),
             ((S, S, S), (S, -1)))

    # 对于每个案例，生成一个样本输入
    for case in cases:
        shape, args = case
        yield SampleInput(make_arg(shape), args=args)

def reference_inputs_chunk(op, device, dtype, requires_grad, **kwargs):
    # 从样本输入块生成引用输入
    yield from sample_inputs_chunk(op, device, dtype, requires_grad, **kwargs)

    # 创建一个部分应用函数，用于创建具有指定参数的张量
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    # 不同的案例，每个案例包含形状、块数和维度
    cases = (
        ((13, 9, 11), 17, -1),
        ((13, 9, 11), 11, -1),
        ((13,), 12, -1),
        ((15,), 12, -1),
        ((15,), 7, 0),
        ((15,), 9, 0),
        ((3, 7), 9, 1),
        ((3, 7), 9, 0),
        ((3, 7), 2, 0),
        ((3, 7), 3, 0),
        ((3, 7), 1, 0),
        ((3, 7), 1, 1),
        ((4, 4), 2, 0),
    )

    # 对于每个案例，生成一个样本输入
    for shape, chunks, dim in cases:
        yield SampleInput(make_arg(shape), args=(chunks, dim))

def sample_inputs_kthvalue(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个内部函数，用于生成具有指定参数的张量
    def _tensor(shape, dtype=dtype, low=None, high=None):
        return make_tensor(shape, dtype=dtype, device=device, low=low, high=high, requires_grad=requires_grad)

    # 测试案例的列表，每个案例包含张量形状和参数元组
    test_cases = [
        ((S, S, S), (2,)),
        ((S, S, S), (2, 1,)),
        ((S, S, S), (2, -1,)),
        ((S, S, S), (2, 1, True,)),
        ((S, S, S), (2, -1, True,)),
        ((S,), (2, 0,)),
        ((S,), (2, 0, True,)),
        ((), (1,)),
        ((), (1, 0,)),
        ((), (1, 0, True)),
    ]

    # 为每个测试案例生成一个样本输入
    yield from (SampleInput(_tensor(tensor), *args) for tensor, args in test_cases)

def error_inputs_kthvalue(op_info, device, **kwargs):
    # 测试重叠输出失败的情况
    t = make_tensor(10, dtype=torch.float32, device=device)
    indices = torch.empty((), device=device, dtype=torch.long)
    # 使用 ErrorInput 类生成一个异常输入对象，包含特定的样本输入和错误正则表达式
    yield ErrorInput(SampleInput(t, 5, out=(t, indices)),
                     error_regex="unsupported operation")

    # 定义一个错误消息，描述 k 超出维度范围的情况
    k_out_of_range_err = "selected number k out of range for dimension"
    # 使用 ErrorInput 类生成异常输入对象，包含一个随机生成的张量和一个超出范围的 k 值
    yield ErrorInput(SampleInput(torch.randn(2, 2, device=device), 3, 0),
                     error_regex=k_out_of_range_err)
    # 使用 ErrorInput 类生成异常输入对象，包含一个随机生成的张量和一个超出范围的 k 值
    yield ErrorInput(SampleInput(torch.randn(2, 2, device=device), 3),
                     error_regex=k_out_of_range_err)
    # 使用 ErrorInput 类生成异常输入对象，包含一个标量张量和一个超出范围的 k 值
    yield ErrorInput(SampleInput(torch.tensor(2, device=device), 3),
                     error_regex=k_out_of_range_err)
def sample_inputs_embedding(op_info, device, dtype, requires_grad, **kwargs):
    def make_input(shape):
        return make_tensor(shape, device=device, dtype=dtype, requires_grad=requires_grad)

    def make_long_input(shape, *, low, high):
        return make_tensor(shape, device=device, dtype=torch.long, low=low, high=high)

    # 0-D index tensor
    idx = make_long_input((), low=0, high=M)
    # 返回一个 SampleInput 对象，包含一个形状为 (M, S) 的张量和一个参数为 idx 的元组
    yield SampleInput(make_input((M, S)), args=(idx,),)

    # 1-D index tensor
    idx = make_long_input((S,), low=0, high=M)
    # 返回一个 SampleInput 对象，包含一个形状为 (M, S) 的张量和一个参数为 idx 的元组
    yield SampleInput(make_input((M, S)), args=(idx,),)

    # 2-D index tensor
    idx = make_long_input((S, S), low=0, high=M)
    # 返回一个 SampleInput 对象，包含一个形状为 (M, S) 的张量和一个参数为 idx 的元组
    yield SampleInput(make_input((M, S)), args=(idx,),)
    # 如果不需要计算梯度，则执行以下操作
    if not requires_grad:
        # 以下输入返回与数值梯度不同的梯度。
        # 这是预期的行为，并且在 `test_nn.py` 中存在相关的测试。

        # 梯度向量在 `padding_idx` 处未被更新。
        idx = make_long_input((2, 2), low=0, high=S)
        idx[0, 0] = 2
        idx[1, 1] = 2
        # 生成一个带有指定参数的样本输入
        yield SampleInput(make_input((S, S)), args=(idx,), kwargs={'padding_idx': 2},)

        idx = make_long_input((2, 2), low=0, high=S)
        idx[0, 0] = 4
        idx[1, 1] = 4
        yield SampleInput(make_input((S, S)), args=(idx,), kwargs={'padding_idx': -1},)

        # 由于权重的原位重新归一化，数值梯度与解析梯度不匹配。
        idx = make_long_input((2, 2), low=0, high=S)
        weights = make_input((S, S)) * 2
        yield SampleInput(weights, args=(idx,), kwargs={'max_norm': 1.},)

        idx = make_long_input((2, 2), low=0, high=S)
        weights = make_input((S, S)) * 2
        yield SampleInput(weights, args=(idx,), kwargs={'max_norm': 1., 'norm_type': 1.0},)

        # 根据特定索引的逆频率缩放梯度。
        idx = make_long_input((2, 2), low=0, high=S)
        idx[0, 0] = 1
        idx[0, 1] = 1
        weights = make_input((S, S))
        yield SampleInput(weights, args=(idx,), kwargs={'scale_grad_by_freq': True},)

        # 稀疏张量的梯度检查未实现。
        idx = make_long_input((2, 2), low=0, high=S)
        weights = make_input((S, S))
        yield SampleInput(weights, args=(idx,), kwargs={'sparse': True})

        idx = make_long_input((3, 3), low=0, high=S)
        idx[0, 0] = 1  # 频率大于1
        idx[0, 1] = 1  # 频率大于1
        idx[1, 0] = 0  # 填充索引
        weights = make_input((S, S)) * 2
        yield SampleInput(weights, args=(idx,),
                          kwargs={'sparse': True, 'scale_grad_by_freq': True,
                                  'padding_idx': 0, 'max_norm': 1.})
# 生成具有不同形状和类别数的样本输入，并返回生成器对象
def sample_inputs_one_hot(op_info, device, dtype, requires_grad, **kwargs):
    # 定义生成输入张量的函数
    def make_input(shape, *, low, high):
        return make_tensor(shape, device=device, dtype=dtype, low=low, high=high, requires_grad=requires_grad)

    # 定义不同形状和类别数的组合
    shapes = ((), (S,), (L, M, S))
    num_classess = (-1, 10)

    # 使用itertools.product生成所有形状和类别数的组合的SampleInput对象
    return (
        SampleInput(
            make_input(
                shape,
                low=0,
                high=10 if num_classes == -1 else num_classes // 2,
            ),
            kwargs=dict(num_classes=num_classes),
        )
        for shape, num_classes in itertools.product(shapes, num_classess)
    )


# 生成具有不同形状和参数的损失函数输入样本，并返回生成器对象
def sample_inputs_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 获取是否需要计算梯度的参数
    rhs_requires_grad = kwargs.get('rhs_requires_grad', requires_grad)
    # 使用偏函数创建_make_tensor函数
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同形状和参数的损失函数输入样本的组合
    shapes_and_kwargs = (
        ((), None),
        ((S,), dict(reduction="mean")),
        ((S,), dict(reduction="sum")),
        ((S,), dict(reduction="none")),
        ((S, S), None),
        ((S, S, S), None),
    )

    # 使用yield生成所有形状和参数组合的SampleInput对象
    for shape, kwargs in shapes_and_kwargs:
        yield SampleInput(_make_tensor(shape),
                          args=(_make_tensor(shape, requires_grad=rhs_requires_grad),),
                          kwargs=kwargs)


# 生成具有不同形状和参数的grid_sample函数输入样本，并返回生成器对象
def sample_inputs_grid_sample(op_info, device, dtype, requires_grad, **kwargs):
    # 改变张量值的范围以获取更好的测试效果
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad,
                           low=-2, high=2)

    batch_size = 2
    num_channels = 3
    modes = ("bilinear", "nearest")
    align_cornerss = (False, True)
    padding_modes = ("zeros", "border", "reflection")

    # 针对二维和三维的不同情况生成grid_sample函数的输入样本
    for dim in (2, 3):
        modes_ = (*modes, "bicubic") if dim == 2 else modes
        for mode, padding_mode, align_corners in itertools.product(modes_, padding_modes, align_cornerss):
            yield SampleInput(
                _make_tensor((batch_size, num_channels, *[S] * dim)),
                _make_tensor((batch_size, *[S] * dim, dim)),
                mode=mode,
                padding_mode=padding_mode,
                align_corners=align_corners,
            )


# 生成具有固定参数的grid_sample函数的参考输入样本，并返回生成器对象
def reference_inputs_grid_sample(op_info, device, dtype, requires_grad, **kwargs):
    batch_size = 2
    num_channels = 3
    height = 345
    width = 456
    modes = ("bilinear", "nearest", "bicubic")
    align_cornerss = (False, True)
    padding_modes = ('zeros', 'border', 'reflection')

    # 创建一个仿射变换矩阵
    a = torch.deg2rad(torch.tensor(45.0))
    ca, sa = torch.cos(a), torch.sin(a)  # 计算旋转角度的余弦和正弦
    s1, s2 = 1.23, 1.34  # 设置缩放比例

    theta = torch.tensor([[
        [ca / s1, sa, 0.0],  # 构造仿射变换矩阵的第一行
        [-sa, ca / s2, 0.0],  # 构造仿射变换矩阵的第二行
    ]], dtype=dtype, device=device)
    theta = theta.expand(batch_size, 2, 3).contiguous()  # 扩展矩阵使其适应批处理大小

    x = torch.arange(batch_size * num_channels * height * width, device=device)  # 创建一维张量 x
    x = x.reshape(batch_size, num_channels, height, width).to(torch.uint8)  # 将 x 重塑为指定形状并转换为 uint8 类型
    x = x.to(dtype=dtype)  # 将 x 张量转换为指定数据类型
    x.requires_grad_(requires_grad)  # 设置 x 张量是否需要梯度计算

    for mode, padding_mode, align_corners in itertools.product(modes, padding_modes, align_cornerss):
        grid = torch.nn.functional.affine_grid(
            theta, size=(batch_size, num_channels, height, width), align_corners=align_corners
        )  # 根据仿射变换参数创建仿射网格
        yield SampleInput(
            x,
            grid,
            mode,
            padding_mode,
            align_corners,
        )  # 生成一个 SampleInput 实例并返回
# 定义一个生成二维采样输入的函数，用于测试
def sample_inputs_grid_sampler_2d(op_info, device, dtype, requires_grad, **kwargs):
    # 调整数值范围以获得更好的测试结果，设置值范围为[-2, 2]
    # 因为对于 grid（第二个张量参数），"有用"的范围是[-1, 1]，这样可以得到更好的超出范围和在范围内的测试用例组合
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad,
                           low=-2, high=2)

    # 定义批量大小、通道数、模式、对齐角标志和填充模式
    batch_size = 2
    num_channels = 3
    modes = (0, 1, 2)
    align_cornerss = (False, True)
    padding_modes = (0, 1, 2)

    # 使用 itertools 的 product 函数遍历模式、填充模式和对齐角的组合
    for mode, padding_mode, align_corners in itertools.product(modes, padding_modes, align_cornerss):
        # 生成一个采样输入对象，并使用 _make_tensor 生成张量作为参数
        yield SampleInput(
            _make_tensor((batch_size, num_channels, S, L)),  # 第一个参数为张量
            _make_tensor((batch_size, M + 3, M, 2)),         # 第二个参数为张量
            mode,                                           # 采样模式
            padding_mode,                                   # 填充模式
            align_corners,                                  # 对齐角标志
        )

# 定义一个生成余弦嵌入损失函数输入的函数，用于测试
def sample_inputs_cosine_embedding_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 使用 partial 函数设置 make_tensor 的设备、数据类型和梯度需求
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义生成目标张量的函数
    def make_target(shape):
        shape = () if len(shape) == 1 else (shape[0], )
        # 生成一个随机整数张量 t，取值范围为0到1，乘以2后减去1得到标签为-1或1
        t = torch.randint(0, 2, shape, device=device, dtype=torch.long)
        t = t * 2 - 1
        # 转换为指定数据类型的目标张量，并设置为不需要梯度
        target = t.to(dtype=dtype).detach_().requires_grad_(requires_grad)
        return target

    # 定义形状和减少方式的组合
    shapes = ((S, S), (S,))
    reductions = ('none', 'mean', 'sum')

    # 使用 product 函数遍历形状和减少方式的组合
    for s, r in product(shapes, reductions):
        # 生成一个余弦嵌入损失函数输入对象
        yield SampleInput(
            make_input(s),                                  # 第一个参数为输入张量
            args=(make_input(s), make_target(s)),           # 附加参数为输入张量和目标张量
            kwargs=dict(reduction=r, margin=random.uniform(-1, 1))  # 关键字参数为减少方式和随机边界
        )

# 定义一个生成 CTC 损失函数输入的函数，用于测试
def sample_inputs_ctc_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 定义输入长度、批量大小、字符数和目标长度
    input_length = 50
    batch = 16
    num_char = 20
    target_length = 30

    # 定义生成对数概率的函数
    def make_log_probs(s):
        t = make_tensor(s, device=device, dtype=dtype)
        # 对张量进行 log_softmax 操作，并设置为指定设备和数据类型，并设置不需要梯度
        log_probs = t.log_softmax(2).to(device=device, dtype=dtype).detach().requires_grad_(requires_grad)
        return log_probs

    # 定义减少方式、零无穷标志和长度类型的组合
    reductions = ('none', 'mean', 'sum')
    zero_inf = (True, False)
    lengths_type = (list, torch.Tensor)
    # 对于给定的 reductions、zero_inf 和 lengths_type 的每一组组合，执行以下操作：
    for r, z, lt in product(reductions, zero_inf, lengths_type):
        # 创建对数概率张量，形状为 (input_length, batch, num_char)
        log_probs = make_log_probs((input_length, batch, num_char))
        # 随机生成目标张量，形状为 (batch, target_length)，元素取值范围为 [1, num_char)
        targets = torch.randint(1, num_char, (batch, target_length), dtype=torch.long, device=device)
        # 创建输入长度张量，形状为 (batch, )，每个元素的值为 input_length
        input_lengths = torch.full((batch, ), input_length, dtype=torch.long, device=device)
        # 随机生成目标长度张量，形状为 (batch, )，元素取值范围为 [10, target_length)
        target_lengths = torch.randint(10, target_length, (batch, ), dtype=torch.long, device=device)

        # 如果 lengths_type 是 list 类型且 reduction 是 "none" 或 "sum" 之一
        if lt is list and r in ["none", "sum"]:
            # 将 input_lengths 和 target_lengths 转换为 Python 列表类型
            input_lengths = input_lengths.tolist()
            target_lengths = target_lengths.tolist()

        # 生成 SampleInput 对象，包含 log_probs 作为输入的对数概率张量，
        # 其他参数作为位置参数 args 和 reduction、zero_infinity 作为关键字参数 kwargs
        yield SampleInput(log_probs, args=(targets, input_lengths, target_lengths,), kwargs=dict(reduction=r, zero_infinity=z))
def sample_inputs_nll_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 定义形状为 (2, 3) 的张量形状
    shape = (2, 3)
    # 获取类别数，即形状的第二个维度大小
    num_classes = shape[1]
    # 部分函数化，创建输入张量的函数，并指定设备、数据类型和是否需要梯度
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # FIXME: 对权重的导数尚未实现
    # 部分函数化，创建权重张量的函数，指定类别数、设备和数据类型，并且不需要梯度
    make_weight = partial(make_tensor, num_classes, device=device, dtype=dtype, requires_grad=False)

    def make_target(shape, zeros=False):
        # 若形状大于一维，则根据指定条件返回零张量或者全零的目标张量
        s = (shape[0], *shape[2:]) if len(shape) > 1 else ()
        if zeros:
            return torch.zeros(s, device=device, dtype=torch.long)
        else:
            # 创建目标张量，根据形状和指定范围内的随机数
            return make_tensor(s,
                               low=0,
                               high=shape[1] if len(shape) > 1 else shape[0],
                               device=device,
                               dtype=torch.long)

    def gen_shape_kwargs():
        # 定义不同形状和减少方式的生成器函数
        # shapes 包括 batched、non-batched 和 2d
        shapes = (shape, (num_classes,), shape + (2, 2))
        reductions = ('none', 'mean', 'sum')
        for reduction, s in product(reductions, shapes):
            # 生成输入张量、目标张量和关键字参数字典
            yield make_input(s), make_target(s), dict(reduction=reduction)
            yield make_input(s), make_target(s), dict(weight=make_weight(), reduction=reduction)
            yield make_input(s), make_target(s), dict(weight=make_weight(low=0), reduction=reduction)
            yield make_input(s), make_target(s), dict(weight=make_weight(high=0), reduction=reduction)
            t = make_target(s)
            ignore = num_classes // 2
            # 如果目标张量全为 ignore，且减少方式为 "mean"，则将目标张量置零
            if t.eq(ignore).all() and reduction == "mean":
                t.fill_(0)
            yield make_input(s), t, dict(ignore_index=num_classes // 2, reduction=reduction)
            yield make_input(s), t, dict(ignore_index=num_classes // 2, reduction=reduction, weight=make_weight())
            # 测试忽略所有目标值
            # 如果减少方式不是 "mean"，则生成输入张量和全零目标张量的测试样本
            if reduction != "mean":
                yield make_input(s), make_target(s, zeros=True), dict(ignore_index=0, reduction=reduction)

    # 生成所有形状和减少方式的输入样本
    for input, target, kwargs in gen_shape_kwargs():
        yield SampleInput(input, args=(target,), kwargs=kwargs)

    # 创建单独的测试样本，包含指定目标张量的输入张量和关键字参数
    target = torch.tensor([-1, 2], device=device, dtype=torch.long)
    yield SampleInput(make_input(shape), args=(target,), kwargs={'ignore_index': -1})



def sample_inputs_binary_cross_entropy_with_logits(
    op_info, device, dtype, requires_grad, **kwargs
):
    # 部分函数化，创建张量的函数，指定设备和数据类型
    make = partial(make_tensor, device=device, dtype=dtype)
    # 部分函数化，创建概率张量的函数，指定范围在 [0, 1] 之间
    make_prob = partial(make, low=0, high=1)
    # 定义减少方式的元组
    reductions = ("mean", "sum", "none")

    def make_weight_shape_kwargs():
        kwargs = []
        # 遍历不同形状的元组，并生成关于形状和减少方式的参数字典
        for shape in ((1,), (1, S), (S), (S, S)):
            kwargs.extend([((S, S), dict(reduction=reduction, weight=make(shape))) for reduction in reductions])
        return kwargs
    # 定义一个列表，包含多种形状和参数字典
    shapes_and_kwargs = [
        *[(shape, None) for shape in ((), (1,), (S,), (S, S), (S, S, S))],
        # 生成形状为(S, S)的样本输入，并指定缩减操作
        *[((S, S), dict(reduction=reduction)) for reduction in reductions],
        # 调用make_weight_shape_kwargs函数生成形状和参数字典
        *make_weight_shape_kwargs(),
        # 生成形状为(S, S)的样本输入，并指定缩减操作和正权重
        *[((S, S), dict(reduction=reduction, pos_weight=make((S,), low=0))) for reduction in reductions],
        # 生成形状为(S, S)的样本输入，并指定缩减操作、权重和正权重
        *[((S, S), dict(reduction=reduction, weight=make((S, S)), pos_weight=make((S,), low=0))) for reduction in reductions],
    ]

    # 遍历shapes_and_kwargs列表中的每个元素
    for shape, kwargs in shapes_and_kwargs:
        # 使用SampleInput类创建一个样本输入对象，包括数据、参数和关键字参数
        yield SampleInput(
            make(shape, requires_grad=requires_grad),  # 生成数据张量，指定是否需要梯度
            args=(make_prob(shape, requires_grad=requires_grad),),  # 生成概率张量，作为位置参数
            kwargs=kwargs,  # 使用预定义的参数字典作为关键字参数
        )
# 生成带有特定参数的样本输入，使用生成器函数
def sample_inputs_argwhere(op_info, device, dtype, requires_grad, **kwargs):
    # 生成并返回一个样本输入，包含指定的张量数据
    yield SampleInput(torch.tensor([1, 0, 2, 0], dtype=dtype, device=device, requires_grad=requires_grad))
    
    # 创建布尔类型的掩码张量
    mask = torch.tensor([[0, 1, 0, 1, 0],
                         [1, 1, 1, 1, 0],
                         [0, 0, 0, 1, 0],
                         [1, 0, 1, 1, 0],
                         [1, 0, 0, 1, 0]], dtype=torch.bool, device=device)
    
    # 使用make_tensor函数创建一个指定形状的张量，并将掩码位置上的值设为0
    t = make_tensor((S, S), dtype=dtype, device=device, requires_grad=requires_grad)
    t[mask] = 0
    yield SampleInput(t)

    # 创建一个非连续的张量，并将掩码位置上的值设为0
    t = make_tensor((S, S), dtype=dtype, device=device, requires_grad=requires_grad, noncontiguous=True)
    t[mask] = 0
    yield SampleInput(t)

    # 创建一个形状为(S, 0)的张量，并作为样本输入返回
    t = make_tensor((S, 0), dtype=dtype, device=device, requires_grad=requires_grad)
    yield SampleInput(t)

    # 返回一个全为0的形状为(S,)的张量作为样本输入
    yield SampleInput(torch.zeros((S,), dtype=dtype, device=device, requires_grad=requires_grad))
    
    # 使用make_tensor函数创建一个标量张量，并作为样本输入返回
    yield SampleInput(make_tensor((), dtype=dtype, device=device, requires_grad=requires_grad))

# 生成形状和约简选项的样本输入
def _generate_sample_shape_reduction():
    # 指定形状和约简选项的组合
    shapes = ((S,), (S, S), (S, S, S))
    reductions = ('none', 'mean', 'sum')
    # 生成并返回形状和约简选项的笛卡尔积
    yield from product(shapes, reductions)

# 生成高斯负对数似然损失函数的样本输入
def sample_inputs_gaussian_nll_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 偏函数_make_tensor，固定了设备、数据类型和梯度需求参数
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 偏函数make_var，设置低于0.1的值，以避免梯度检查时意外下降到0以下
    make_var = partial(make_tensor, low=0.1, device=device, dtype=dtype, requires_grad=requires_grad)

    # 生成特定形状的样本输入
    def gen_shape(shape):
        yield shape
        # 广播形状
        yield (*shape[:-1], 1)
        yield shape[:-1]

    # 生成带有形状和参数选项的样本输入
    def gen_shape_kwargs():
        for s, r in _generate_sample_shape_reduction():
            for t_s, v_s in product(gen_shape(s), gen_shape(s)):
                yield _make_tensor(s), _make_tensor(t_s), make_var(v_s), dict(reduction=r)
                yield (
                    _make_tensor(s), _make_tensor(t_s), make_var(v_s),
                    dict(full=True, reduction=r)
                )
                yield (
                    _make_tensor(s), _make_tensor(t_s), make_var(v_s),
                    dict(eps=random.uniform(1e-6, 1e-3), reduction=r)
                )
                yield (
                    _make_tensor(s), _make_tensor(t_s), make_var(v_s),
                    dict(full=True, eps=random.uniform(1e-6, 1e-3), reduction=r)
                )

    # 生成并返回所有形状和参数选项的样本输入
    for input, target, var, kwargs in gen_shape_kwargs():
        yield SampleInput(input, args=(target, var, ), kwargs=kwargs)

# 生成高斯负对数似然损失函数的错误输入
def error_inputs_gaussian_nll_loss(op_info, device, **kwargs):
    # 偏函数_make，固定了设备为指定设备，数据类型为32位浮点数
    _make = partial(make_tensor, device=device, dtype=torch.float32)

    # 返回一个错误类型为ValueError的错误输入，说明约简值无效
    yield ErrorInput(SampleInput(_make(10, 2, 3), _make(10, 2, 3), _make((10, 2, 3), low=0), reduction="abc"),
                     error_type=ValueError, error_regex="abc is not valid")

    # 变量var的形状不正确
    # 这行代码需要继续完善注释，以解释其作用
    yield ErrorInput(SampleInput(_make(10, 2, 3), _make(10, 2, 3), _make((10, 2, 3), low=0), reduction="abc"),
                     error_type=ValueError, error_regex="abc is not valid")
    # 生成一个 ErrorInput 对象，其中 SampleInput 是构造函数的参数
    # _make(10, 2, 3) 用于生成一个特定形状的示例输入
    # error_type 指定为 ValueError，表示预期的错误类型
    # error_regex 是一个正则表达式，用于匹配错误消息中的特定文本
    yield ErrorInput(SampleInput(_make(10, 2, 3), _make(10, 2, 3), _make((10, 2, 2), low=0)),
                     error_type=ValueError, error_regex="var is of incorrect size")

    # 生成另一个 ErrorInput 对象，与上一个类似但参数略有不同
    # _make(10, 2, 2) 用于生成另一种形状的示例输入
    # error_type 指定为 RuntimeError，表示预期的错误类型
    # error_regex 是一个复杂的正则表达式，用于匹配错误消息中的特定文本
    # 此正则表达式用于检查张量形状不匹配的错误消息
    yield ErrorInput(SampleInput(_make(10, 2, 3), _make(10, 2, 2), _make((10, 2, 3), low=0)),
                     error_type=RuntimeError,
                     error_regex=(r"The size of tensor a \(3\) must match the size of tensor b \(2\) "
                                  r"at non-singleton dimension 2"))
# 生成神经网络损失函数样本输入的辅助函数，生成包含样本数据、形状缩减方式的生成器
def _generate_sample_inputs_nn_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 偏函数，用于创建张量，固定设备、数据类型、梯度需求
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 遍历生成样本形状缩减方式的生成器的结果
    for s, r in _generate_sample_shape_reduction():
        # 生成两个张量及对应的形状缩减方式字典，并返回作为生成器的一部分
        yield _make_tensor(s), _make_tensor(s), dict(reduction=r)

# 生成 Hinge Embedding 损失函数的样本输入的生成器
def sample_inputs_hinge_embedding_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 遍历神经网络损失函数样本输入生成器的结果
    for input, target, d in _generate_sample_inputs_nn_loss(op_info, device, dtype, requires_grad, **kwargs):
        # 目标张量应包含文档中指定的值（1 或 -1）
        mask = torch.rand_like(target) > 0.5  # 创建一个与目标张量相同形状的随机掩码
        target[mask] = 1  # 将掩码位置上的值设置为1
        target[~mask] = -1  # 将非掩码位置上的值设置为-1
        d['margin'] = random.uniform(-9, 9)  # 向字典中添加 'margin' 键，其值为随机浮点数（-9 到 9）
        yield SampleInput(input, args=(target, ), kwargs=d)  # 返回样本输入对象

    # 创建偏函数，用于创建张量，固定设备、数据类型、梯度需求
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 返回一个包含标量输入和目标的样本输入对象
    yield SampleInput(_make_tensor(()), args=(_make_tensor(()), ))

# Hinge Embedding 损失函数的错误输入生成器
def error_inputs_hinge_embedding_loss(op, device, **kwargs):
    # 偏函数，用于创建张量，固定设备为指定设备
    make_input = partial(make_tensor, device=device, dtype=torch.float32)
    # 返回一个错误输入对象，其中包含一个样本输入对象、ValueError 错误类型和错误正则表达式
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4),), kwargs={'reduction': 'abc'}),
                     error_type=ValueError, error_regex='is not a valid value')

# Hinge Embedding 损失函数的参考输入生成器
def reference_inputs_hinge_embedding_loss(op, device, dtype, requires_grad, **kwargs):
    # 返回从 Hinge Embedding 损失函数样本输入生成器中得到的结果
    yield from sample_inputs_hinge_embedding_loss(op, device, dtype, requires_grad, **kwargs)
    # 偏函数，用于创建张量，固定设备、数据类型、梯度需求
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 遍历缩减方式 ('sum', 'mean', 'none')
    for reduction in ('sum', 'mean', 'none'):
        # 如果数据类型是浮点数，则支持 NaN 传播
        if dtype.is_floating_point:
            # 创建一个张量，并将第三个位置设置为 NaN
            inp = make_input((10, ))
            inp[2] = float('nan')
            target = make_input((10, ))
            # 目标张量应包含文档中指定的值（1 或 -1）
            mask = torch.rand_like(target) > 0.5
            target[mask] = -1
            target[~mask] = 1
            yield SampleInput(inp, args=(target,), kwargs={'reduction': reduction})

            # 创建一个张量，并将第五个位置设置为正无穷
            inp = make_input((10, ))
            inp[4] = float('inf')
            target = make_input((10, ))
            mask = torch.rand_like(target) > 0.5
            target[mask] = -1
            target[~mask] = 1
            yield SampleInput(inp, args=(target,), kwargs={'reduction': reduction})

        # 广播操作
        inp = make_input((5, 5))
        target = make_input((1, 5))
        mask = torch.rand_like(target) > 0.5
        target[mask] = -1
        target[~mask] = 1
        yield SampleInput(inp, args=(target,), kwargs={'reduction': reduction})

# Huber 损失函数的样本输入生成器
def sample_inputs_huber_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 遍历神经网络损失函数样本输入生成器的结果
    for input, target, d in _generate_sample_inputs_nn_loss(op_info, device, dtype, requires_grad, **kwargs):
        d['delta'] = random.uniform(1e-3, 9)  # 向字典中添加 'delta' 键，其值为随机浮点数（1e-3 到 9）
        yield SampleInput(input, args=(target, ), kwargs=d)
# 定义一个函数，用于生成带错误输入的 Huber Loss 函数
def error_inputs_huber_loss(op, device, **kwargs):
    # 创建一个部分函数，用于生成指定设备和数据类型的张量
    make_input = partial(make_tensor, device=device, dtype=torch.float32)
    
    # 错误消息，用于指示无效的缩减值
    err = 'is not a valid value for reduction'
    
    # 生成一个错误输入对象，其中包含指定的样本输入、错误类型和错误正则表达式
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4),), kwargs={'reduction': 'abc'}),
                     error_type=ValueError, error_regex=err)
    
    # 循环遍历不同的 delta 值
    for delta in (0, -1):
        # 错误消息，指示 delta 值必须为正数
        err = 'huber_loss does not support non-positive values for delta.'
        
        # 生成另一个错误输入对象，包含不同的样本输入、错误类型和错误正则表达式
        yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4),), kwargs={'delta': delta}),
                         error_type=RuntimeError, error_regex=err)

# 定义一个函数，生成带有泊松负对数似然损失函数的样本输入
def sample_inputs_poisson_nll_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个部分函数，用于生成指定设备、数据类型和梯度属性的张量
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义一个生成器函数，生成不同形状和缩减方式的参数组合
    def gen_shape_kwargs():
        for s, r in _generate_sample_shape_reduction():
            for li in (True, False):
                for f in (True, False):
                    # 生成输入张量和目标张量
                    i1 = _make_tensor(s)
                    i2 = _make_tensor(s)
                    
                    # 对于泊松负对数似然损失，目标张量假定为泊松分布的正样本
                    t1 = _make_tensor(s, low=0)
                    t2 = _make_tensor(s, low=0)

                    # 如果不是 log_input，则对输入张量取绝对值
                    if not li:
                        i1.abs_()
                        i2.abs_()
                    t1.abs_()
                    t2.abs_()

                    # 生成包含输入张量、目标张量和其他参数的字典
                    yield (
                        i1, t1,
                        dict(log_input=li, full=f, reduction=r)
                    )
                    yield (
                        i2, t2,
                        dict(log_input=li, full=f,
                             eps=random.uniform(1e-8, 1e-3),
                             reduction=r)
                    )

    # 遍历生成的参数组合，生成相应的样本输入对象
    for input, target, kwargs in gen_shape_kwargs():
        yield SampleInput(input, args=(target, ), kwargs=kwargs)

    # 测试 INT_TO_FLOAT 类型提升
    if dtype.is_complex:
        # 对于布尔和整型张量类型，生成相应的样本输入对象
        for d in (torch.bool, torch.int64):
            yield SampleInput(_make_tensor(dtype=dtype), args=(_make_tensor(dtype=d),))
            yield SampleInput(_make_tensor(dtype=d), args=(_make_tensor(dtype=dtype),))

# 定义一个函数，生成带有泊松负对数似然损失函数的错误输入
def error_inputs_poisson_nll_loss(op_info, device, **kwargs):
    # 创建一个部分函数，用于生成指定设备和数据类型的张量
    make = partial(make_tensor, device=device, dtype=torch.float32)

    # 错误消息，指示无效的缩减值
    yield ErrorInput(SampleInput(make(5, 4), args=(make(5, 4),),
                     kwargs={'reduction': 'abc'}),
                     error_type=ValueError,
                     error_regex='abc is not a valid value for reduction')
    # 无效的输入形状
    # 使用 yield 关键字生成一个 ErrorInput 对象，包含一个 SampleInput 对象和额外的参数 args=(make(5,),)
    yield ErrorInput(
        # 创建一个 SampleInput 对象，其中 make(5, 4) 作为输入值， args 参数为 make(5,) 
        SampleInput(make(5, 4), args=(make(5,),)),
        # 设置 error_regex 参数，包含两个正则表达式模式，用于匹配特定错误信息：
        # 1. 匹配 "Attempting to broadcast a dimension of length"
        # 2. 匹配 "The size of tensor a \(5\) must match the size of tensor b \(4\) at non-singleton dimension 1"
        error_regex=(
            r'(Attempting to broadcast a dimension of length|'
            r'The size of tensor a \(5\) must match the '
            r'size of tensor b \(4\) at non-singleton '
            r'dimension 1)'
        )
    )
# 定义一个函数用于生成带有错误输入的软边界损失函数测试样本
def error_inputs_soft_margin_loss(op_info, device, **kwargs):
    # 使用 make_tensor 函数创建一个部分应用了 device 和 dtype 参数的函数 make
    make = partial(make_tensor, device=device, dtype=torch.float32)

    # 生成一个错误输入示例，验证当 reduction 参数为 'abc' 时是否会引发 ValueError 异常
    yield ErrorInput(SampleInput(make(5, 4), args=(make(5, 4),),
                     kwargs={'reduction': 'abc'}),
                     error_type=ValueError,
                     error_regex='abc is not a valid value for reduction')

    # 生成一个错误输入示例，验证在输入张量形状不匹配时是否会引发相应的异常
    yield ErrorInput(SampleInput(make(5, 4), args=(make(5,),)),
                     error_regex=(r'(Attempting to broadcast a dimension of length|'
                                  r'The size of tensor a \(4\) must match the '
                                  r'size of tensor b \(5\) at non-singleton '
                                  r'dimension 1)'))

# 定义一个函数用于生成三元组间隔损失函数的样本输入
def sample_inputs_triplet_margin_loss(op_info, device, dtype, requires_grad, with_distance=False, **kwargs):
    # 使用 make_tensor 函数创建一个部分应用了 (S, M)、device、dtype 和 requires_grad 参数的函数 make
    make = partial(make_tensor, (S, M), device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义一组关键字参数的列表
    kwargss = (
        *[dict(margin=margin) for margin in (1e-6, 1.0, 10.0)],
        dict(swap=True),
        *[dict(reduction=reduction) for reduction in ("mean", "sum", "none")],
    )

    # 对于每个关键字参数组合，生成一个样本输入
    for kwargs in kwargss:
        input = make()
        args = (make(), make())
        # 如果 with_distance 为 True，则设置 distance_function 参数为 torch.nn.PairwiseDistance()
        if with_distance:
            kwargs["distance_function"] = torch.nn.PairwiseDistance()
        yield SampleInput(input, args=args, kwargs=kwargs)

# 定义一个函数用于生成带有错误输入的三元组间隔损失函数测试样本
def error_inputs_triplet_margin_loss(op_info, device, **kwargs):
    # 使用 make_tensor 函数创建一个部分应用了 device 和 dtype 参数的函数 make_input
    make_input = partial(make_tensor, device=device, dtype=torch.float32)
    samples = (
        # 定义一组测试样本，每个样本包含以下内容：
        # input: 输入数据，由 make_input 函数生成
        # args: 参数列表，包括两个由 make_input 函数生成的输入数据
        # kwargs: 关键字参数字典，指定了 reduction 或 margin 等参数
        # error_type: 预期抛出的异常类型，可能是 ValueError 或 RuntimeError
        # error_regex: 异常信息的正则表达式模式，用于匹配异常信息中的特定文本

        # invalid reduction
        (make_input(3, 4), (make_input(3, 4), make_input(3, 4)),
         dict(reduction="abc"),
         ValueError, "abc is not a valid value for reduction"),

        # invalid margin
        (make_input(3, 4), (make_input(3, 4), make_input(3, 4)),
         dict(margin=-1.0),
         ValueError, "margin must be greater than 0, got -1.0"),

        # shape mismatch
        (make_input(3, 5), (make_input(3, 4), make_input(3, 4)),
         dict(),
         RuntimeError,
         (r'(Attempting to broadcast a dimension of length|'
          r"The size of tensor a \(5\) must match the size of tensor b \(4\) "
          r"at non-singleton dimension 1)")),
        (make_input(3, 4), (make_input(3, 5), make_input(3, 4)),
         dict(),
         RuntimeError,
         (r'(Attempting to broadcast a dimension of length|'
          r"The size of tensor a \(4\) must match the size of tensor b \(5\) "
          r"at non-singleton dimension 1)")),
        (make_input(3, 4), (make_input(3, 4), make_input(3, 5)),
         dict(),
         RuntimeError,
         (r'(Attempting to broadcast a dimension of length|'
          r"The size of tensor a \(4\) must match the size of tensor b \(5\) "
          r"at non-singleton dimension 1)")),

        # different dimensions
        (make_input(3,), (make_input(3, 4), make_input(3, 4)),
         dict(),
         RuntimeError,
         (r"The anchor, positive, and negative tensors are expected to have "
          r"the same number of dimensions, but got: anchor 1D, positive 2D, "
          r"and negative 2D inputs")),
        (make_input(3, 4), (make_input(3,), make_input(3, 4)),
         dict(),
         RuntimeError,
         (r"The anchor, positive, and negative tensors are expected to have "
          r"the same number of dimensions, but got: anchor 2D, positive 1D, "
          r"and negative 2D inputs")),
        (make_input(3, 4), (make_input(3, 4), make_input(3,)),
         dict(),
         RuntimeError,
         (r"The anchor, positive, and negative tensors are expected to have "
          r"the same number of dimensions, but got: anchor 2D, positive 2D, "
          r"and negative 1D inputs")),
    )

    # 遍历样本列表，逐个生成 ErrorInput 对象并 yield 返回
    for input, args, kwargs, error_type, error_regex in samples:
        yield ErrorInput(SampleInput(input, args=args, kwargs=kwargs),
                         error_type=error_type, error_regex=error_regex)
# 定义一个生成器函数，生成缩放后的输入样本用于某种操作
def sample_inputs_scaled_mm(op_info, device, dtype, requires_grad, **kwargs):
    # 创建部分函数，用于生成特定设备、数据类型和梯度属性的张量
    make_mat_e4m3 = partial(make_tensor, device=device, dtype=torch.float8_e4m3fn, requires_grad=requires_grad)
    make_mat_e5m2 = partial(make_tensor, device=device, dtype=torch.float8_e5m2, requires_grad=requires_grad)
    
    # 定义矩阵维度 M, N, K
    M, N, K = 15, 32, 16
    samples = []

    # 生成两个 e4m3 类型的矩阵
    mat1 = make_mat_e4m3((M, K))
    mat2 = make_mat_e4m3((K, N)).t().contiguous().t()
    samples.append(SampleInput(mat1, mat2))

    # 生成一个 e4m3 类型的矩阵和一个 e5m2 类型的矩阵
    mat1 = make_mat_e4m3((M, K))
    mat2 = make_mat_e5m2((K, N)).t().contiguous().t()
    samples.append(SampleInput(mat1, mat2))

    # 生成一个 e5m2 类型的矩阵和一个 e4m3 类型的矩阵
    mat1 = make_mat_e5m2((M, K))
    mat2 = make_mat_e4m3((K, N)).t().contiguous().t()
    samples.append(SampleInput(mat1, mat2))

    # 使用生成器的 yield from 语法返回样本列表
    yield from samples


# 定义另一个生成器函数，生成带有点积注意力的输入样本
def sample_inputs_scaled_dot_product_attention(op_info, device, dtype, requires_grad, **kwargs):
    make = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    batch, seq_q, seq_kv, num_heads, head_dim = 4, 3, 6, 4, 8

    # 定义不同维度的形状
    dim_3_q_shape = (batch, seq_q, head_dim)
    dim_3_kv_shape = (batch, seq_kv, head_dim)
    dim_4_q_shape = (batch, num_heads, seq_q, head_dim)
    dim_4_kv_shape = (batch, num_heads, seq_kv, head_dim)

    # 定义广播元组
    broadcast_tuple = ((num_heads, seq_q, head_dim), (batch, num_heads, seq_kv, head_dim))

    # 构造不同的 qkv 形状及其特性的样本
    qkv_shapes = [(dim_3_q_shape, dim_3_kv_shape), (dim_4_q_shape, dim_4_kv_shape), broadcast_tuple]
    samples = []
    for qkv_shape, is_causal, dropout_p in product(
            qkv_shapes, [True, False], [0.0, 0.5]):
        shape_q, shape_kv = qkv_shape
        samples.append(SampleInput(
            make(shape_q),
            make(shape_kv),
            make(shape_kv),
            is_causal=is_causal,
            dropout_p=dropout_p
        ))

    # 添加非标准形状的样本
    diff_v_head_dim = SampleInput(
        make((batch, num_heads, seq_q, head_dim)),
        make((batch, num_heads, seq_kv, head_dim)),
        make((batch, num_heads, seq_kv, head_dim + 8)),
        is_causal=is_causal,
        dropout_p=dropout_p
    )

    # 添加一个注意力掩码的样本
    samples.append(
        SampleInput(
            make((batch, num_heads, seq_q, head_dim)),
            make((batch, num_heads, seq_kv, head_dim)),
            make((batch, num_heads, seq_kv, head_dim)),
            attn_mask=make((seq_q, seq_kv)),
            is_causal=False,
            dropout_p=0.0)
    )

    # 使用生成器的 yield from 语法返回样本列表
    yield from samples


def sample_inputs_efficient_attention_forward(op_info, device, dtype, requires_grad, **kwargs):
    make = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    batch, num_heads, head_dim = 4, 4, 8
    seq_q = 11
    seq_kv = 32

    dim_4_q_shape = (batch, num_heads, seq_q, head_dim)
    dim_4_kv_shape = (batch, num_heads, seq_kv, head_dim)

    qkv_shapes = [(dim_4_q_shape, dim_4_kv_shape)]
    samples = []
    mask_types = [1, 2]  # UpperLeft, LowerRight
    scales = [None, 1.0]

    # 此处缺少具体的生成代码，需要根据上下文补充完整

    # 使用生成器的 yield from 语法返回样本列表
    yield from samples
    # 使用 product 函数生成多个参数组合，用于迭代
    for qkv_shape, is_causal, dropout_p, mask_type, scale in product(
            qkv_shapes, [True, False], [0.0, 0.5], mask_types, scales):
        shape_q, shape_kv = qkv_shape
        # 创建 SampleInput 对象并添加到 samples 列表中，包括输入的形状和参数设置
        samples.append(SampleInput(
            make(shape_q).transpose(1, 2),  # 创建形状为 shape_q 的张量，并进行转置
            make(shape_kv).transpose(1, 2),  # 创建形状为 shape_kv 的张量，并进行转置
            make(shape_kv).transpose(1, 2),  # 创建形状为 shape_kv 的张量，并进行转置
            bias=None,  # 偏置项设置为 None
            cu_seqlens_q=None,  # cu_seqlens_q 设置为 None
            cu_seqlens_k=None,  # cu_seqlens_k 设置为 None
            max_seqlen_q=None,  # max_seqlen_q 设置为 None
            max_seqlen_k=None,  # max_seqlen_k 设置为 None
            dropout_p=dropout_p,  # dropout_p 设置为当前的 dropout_p 值
            custom_mask_type=mask_type,  # 自定义掩码类型设置为当前的 mask_type 值
            compute_log_sumexp=requires_grad,  # 计算 log_sumexp 标志设置为 requires_grad
            scale=scale,  # 缩放因子设置为当前的 scale 值
            seqlen_k=None  # seqlen_k 设置为 None
        ))

    # 添加非标准形状的 SampleInput 对象到 samples 列表中
    diff_v_head_dim = SampleInput(
        make((batch, seq_q, num_heads, head_dim)),  # 创建形状为 (batch, seq_q, num_heads, head_dim) 的张量
        make((batch, seq_kv, num_heads, head_dim)),  # 创建形状为 (batch, seq_kv, num_heads, head_dim) 的张量
        make((batch, seq_kv, num_heads, head_dim + 8)),  # 创建形状为 (batch, seq_kv, num_heads, head_dim + 8) 的张量
        bias=None,  # 偏置项设置为 None
        cu_seqlens_q=None,  # cu_seqlens_q 设置为 None
        cu_seqlens_k=None,  # cu_seqlens_k 设置为 None
        max_seqlen_q=None,  # max_seqlen_q 设置为 None
        max_seqlen_k=None,  # max_seqlen_k 设置为 None
        dropout_p=dropout_p,  # dropout_p 设置为当前的 dropout_p 值
        custom_mask_type=0,  # 自定义掩码类型设置为 0，表示无掩码
        compute_log_sumexp=requires_grad,  # 计算 log_sumexp 标志设置为 requires_grad
        scale=None,  # 缩放因子设置为 None
        seqlen_k=None  # seqlen_k 设置为 None
    )

    # 添加一个带有注意力掩码的 SampleInput 对象到 samples 列表中
    samples.append(
        SampleInput(
            make((batch, seq_q, num_heads, head_dim)),  # 创建形状为 (batch, seq_q, num_heads, head_dim) 的张量
            make((batch, seq_kv, num_heads, head_dim)),  # 创建形状为 (batch, seq_kv, num_heads, head_dim) 的张量
            make((batch, seq_kv, num_heads, head_dim)),  # 创建形状为 (batch, seq_kv, num_heads, head_dim) 的张量
            bias=make(batch, num_heads, seq_q, seq_kv),  # 创建形状为 (batch, num_heads, seq_q, seq_kv) 的张量作为偏置项
            cu_seqlens_q=None,  # cu_seqlens_q 设置为 None
            cu_seqlens_k=None,  # cu_seqlens_k 设置为 None
            max_seqlen_q=None,  # max_seqlen_q 设置为 None
            max_seqlen_k=None,  # max_seqlen_k 设置为 None
            dropout_p=dropout_p,  # dropout_p 设置为当前的 dropout_p 值
            custom_mask_type=0,  # 自定义掩码类型设置为 0，表示无掩码
            compute_log_sumexp=requires_grad,  # 计算 log_sumexp 标志设置为 requires_grad
            scale=None,  # 缩放因子设置为 None
            seqlen_k=None  # seqlen_k 设置为 None
        )
    )

    # 添加带有查询/键偏移的 jagged 样本到 samples 列表中
    cu_seqlens_k = torch.arange(-1, 32 * 2 + 1, 2, dtype=torch.int32, device=device)  # 创建一个查询序列长度张量 cu_seqlens_k
    cu_seqlens_k[-1] = 62  # 修改 cu_seqlens_k 张量的最后一个元素为 62
    cu_seqlens_k[0] = 0  # 修改 cu_seqlens_k 张量的第一个元素为 0
    samples.append(
        SampleInput(
            make((32, 2, 64)).view(-1, 8, 8).unsqueeze(0),  # 创建形状为 (32, 2, 64) 的张量并进行视图变形和 unsqueeze 操作
            make((64, 64)).view(-1, 8, 8).unsqueeze(0),  # 创建形状为 (64, 64) 的张量并进行视图变形和 unsqueeze 操作
            make((64, 64)).view(-1, 8, 8).unsqueeze(0),  # 创建形状为 (64, 64) 的张量并进行视图变形和 unsqueeze 操作
            bias=None,  # 偏置项设置为 None
            cu_seqlens_q=torch.arange(0, 32 * 2 + 2, 2, dtype=torch.int32, device=device),  # 创建一个查询序列长度张量 cu_seqlens_q
            cu_seqlens_k=cu_seqlens_k,  # 使用上面创建的 cu_seqlens_k 张量作为 cu_seqlens_k
            max_seqlen_q=2,  # max_seqlen_q 设置为 2
            max_seqlen_k=2,  # max_seqlen_k 设置为 2
            dropout_p=0.0,  # dropout_p 设置为 0.0
            custom_mask_type=0,  # 自定义掩码类型设置为 0，表示无掩码
            compute_log_sumexp=requires_grad,  # 计算 log_sumexp 标志设置为 requires_grad
            scale=None,  # 缩放因子设置为 None
            seqlen_k=None,  # seqlen_k 设置为 None
        )
    )

    # 使用生成器语法 yield from 返回 samples 列表中的所有样本
    yield from samples
# 定义一个生成器函数，生成输入样本用于闪烁注意力前向传播
def sample_inputs_flash_attention_forward(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数，用于生成张量，设定设备、数据类型和梯度需求
    make = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    # 定义一些常量
    batch, num_heads, head_dim = 4, 4, 8
    seq_q = 11
    seq_kv = 32

    # 定义维度为4的查询和键值对的形状
    dim_4_q_shape = (batch, num_heads, seq_q, head_dim)
    dim_4_kv_shape = (batch, num_heads, seq_kv, head_dim)

    # 将查询和键值对形状放入列表
    qkv_shapes = [(dim_4_q_shape, dim_4_kv_shape)]
    # 初始化样本列表
    samples = []
    # 定义不同的缩放比例
    scales = [None, 1.0]

    # 使用 product 函数遍历查询-键值对形状、是否因果、dropout 概率和缩放比例
    for qkv_shape, is_causal, dropout_p, scale in product(
            qkv_shapes, [True, False], [0.0, 0.5], scales):
        shape_q, shape_kv = qkv_shape
        # 添加样本到列表中，包括查询、键和值的张量，以及其他相关参数
        samples.append(SampleInput(
            make(shape_q).transpose(1, 2),
            make(shape_kv).transpose(1, 2),
            make(shape_kv).transpose(1, 2),
            cum_seq_q=None,
            cum_seq_k=None,
            max_q=seq_q,
            max_k=seq_kv,
            dropout_p=dropout_p,
            is_causal=is_causal,
            return_debug_mask=False,
            scale=scale,
        ))

    # 返回所有生成的样本
    yield from samples

# 定义一个生成器函数，生成输入样本用于配对距离计算
def sample_inputs_pairwise_distance(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数，用于生成张量，设定设备、数据类型和梯度需求
    make = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同形状的张量及其参数组合
    shape = (3,)
    batched_shape = (2, *shape)
    shapes_and_kwargs = [
        (shape, None),
        (batched_shape, None),
        (shape, dict(keepdim=True)),
        (batched_shape, dict(keepdim=True)),
        (shape, dict(p=5.0)),
        (shape, dict(p=-1.0)),
        (shape, dict(eps=1.0)),
    ]

    # 使用生成器表达式返回每种形状及参数组合的输入样本
    return (
        SampleInput(make(shape), args=(make(shape),), kwargs=kwargs) for shape, kwargs in shapes_and_kwargs
    )

# 定义一个生成器函数，生成输入样本用于像素混洗操作
def sample_inputs_pixel_shuffle(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数，用于生成张量，设定设备、数据类型和梯度需求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 使用生成器表达式返回每个缩放因子下的输入样本
    yield from (
        SampleInput(make_arg((1, 9, 2, 2)), upscale_factor=upscale_factor)
        for upscale_factor in (1, 3)
    )
    # 使用生成器表达式返回每种形状下的输入样本，缩放因子为1
    yield from (
        SampleInput(make_arg(shape), upscale_factor=1)
        for shape in [
            (1, 0, 1, 1),
            (1, 1, 0, 1),
            (1, 1, 1, 0),
        ]
    )

# 定义一个生成器函数，生成输入样本用于像素反混洗操作
def sample_inputs_pixel_unshuffle(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数，用于生成张量，设定设备、数据类型和梯度需求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 使用生成器表达式返回每个缩放因子下的输入样本
    yield from (
        SampleInput(make_arg((1, 1, 6, 6)), downscale_factor=downscale_factor)
        for downscale_factor in (1, 3)
    )
    # 使用生成器表达式返回每种形状下的输入样本，缩放因子为1
    yield from (
        SampleInput(make_arg(shape), downscale_factor=1)
        for shape in [
            (1, 0, 1, 1),
            (1, 1, 0, 1),
            (1, 1, 1, 0),
        ]
    )

# 定义一个生成器函数，生成输入样本用于通道混洗操作
def sample_inputs_channel_shuffle(op_info, device, dtype, requires_grad, **kwargs):
    # 创建一个偏函数，用于生成张量，设定设备、数据类型和梯度需求
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 定义不同形状和组数的张量
    shapes_groups = [
        ((1, 4, 10, 10), 2),
        ((2, 6, 8, 8), 3),
        ((2, 8, 5, 5), 4),
    ]

    # 未完成的代码段，缺少生成器表达式和循环体
    # 使用生成器函数生成一系列 SampleInput 对象
    yield from (
        # 调用 SampleInput 构造函数生成一个 SampleInput 对象，传入参数 shape 和 groups
        SampleInput(make_arg(shape), args=(groups,))
        # 遍历 shapes_groups 中的每一对 shape 和 groups
        for shape, groups in shapes_groups
    )
# 定义一个生成带有二进制交叉熵样本输入的函数
def sample_inputs_binary_cross_entropy(op_info, device, dtype, requires_grad, logits=False, **kwargs):
    # 使用 partial 函数创建 make_tensor 函数的一个版本，指定设备和数据类型
    make = partial(make_tensor, device=device, dtype=dtype)
    
    # 创建一个 make_prob 函数，是 make 的一个部分应用，但在范围低于1e-6和高于1之间
    # 生成概率值，用于概率分布的输入
    make_prob = partial(make, low=1e-6, high=1)

    # 定义减少方法的元组
    reductions = ("mean", "sum", "none")

    # 定义形状和关键字参数的列表
    shapes_and_kwargs = [
        *[(shape, None) for shape in ((), (1,), (S,), (S, S), (S, S, S))],
        *[((S, S), dict(reduction=reduction)) for reduction in reductions],
        *[((S, S), dict(reduction=reduction, weight=make((S, S)))) for reduction in reductions],
    ]

    # 如果 logits 为 True，添加额外的形状和关键字参数
    if logits:
        shapes_and_kwargs.extend(
            [((S, S), dict(reduction=reduction, pos_weight=make((S,), low=0))) for reduction in reductions]
        )

    # 遍历形状和关键字参数的列表，生成 SampleInput 实例
    for shape, kwargs in shapes_and_kwargs:
        yield SampleInput(
            # 如果 logits 为 True，使用 make，否则使用 make_prob 生成张量
            (make if logits else make_prob)(shape, requires_grad=requires_grad),
            args=(make_prob(shape, requires_grad=requires_grad),),
            kwargs=kwargs,
        )

# 定义一个生成所有近似输入的函数
def sample_inputs_allclose(op_info, device, dtype, requires_grad, **kwargs):
    sample_shapes = [(), (S), (S, S, S)]
    atols = [1e-2, 1e-16]
    rtols = [1e-1, 0.5]
    eps = 1e-8
    # 使用 product 函数生成所有形状、相对容差和绝对容差的组合
    for s, rtol, atol in product(sample_shapes, rtols, atols):
        # 创建张量 t，其值为 make_tensor 生成的张量加上绝对容差，并分离出来，要求梯度
        t = make_tensor(s, device=device, dtype=dtype, requires_grad=requires_grad)
        close = (t + atol).detach().requires_grad_(requires_grad)
        yield SampleInput(t, close, rtol=rtol, atol=atol)

        # 创建随机张量 a 和 b，用于比较是否接近
        a = make_tensor(s, device=device, dtype=dtype, requires_grad=requires_grad)
        b = make_tensor(s, device=device, dtype=dtype, requires_grad=requires_grad)
        yield SampleInput(a, b, rtol=rtol, atol=atol)


# 定义一个生成 L1 损失输入的函数
def sample_inputs_l1_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 从 sample_inputs_loss 函数生成输入
    yield from sample_inputs_loss(op_info, device, dtype, requires_grad, **kwargs)

    # 如果数据类型是复数类型，测试 COMPLEX_TO_FLOAT 提升
    if dtype.is_complex:
        # 创建一个 make 函数，是 make_tensor 的一个部分应用，只有设备和要求梯度的参数
        make = partial(make_tensor, (), device=device, requires_grad=requires_grad)
        yield SampleInput(make(dtype=dtype), args=(make(dtype=torch.double),))
        yield SampleInput(make(dtype=torch.double), args=(make(dtype=dtype),))


# 定义 L1 损失输入错误的函数
def error_inputs_l1_loss(op_info, device, **kwargs):
    make = partial(make_tensor, device=device, dtype=torch.float32)

    # 无效的减少值
    yield ErrorInput(SampleInput(make(5, 4), args=(make(5, 4),),
                     kwargs={'reduction': 'abc'}),
                     error_type=ValueError,
                     error_regex='abc is not a valid value for reduction')
    # 无效的输入形状
    # 使用 yield 生成一个 ErrorInput 对象的实例
    yield ErrorInput(
        # 调用 SampleInput 函数创建 SampleInput 对象，并传入参数
        SampleInput(
            # 调用 make 函数生成一个参数为 (5, 4) 的对象
            make(5, 4),
            # 将参数 make(5,) 作为 args 传递给 SampleInput 对象
            args=(make(5,),)
        ),
        # 设置 error_regex 参数为一个正则表达式，用于匹配错误信息
        error_regex=(
            # 匹配字符串 'Attempting to broadcast a dimension of length' 或者
            # 'The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1'
            r'(Attempting to broadcast a dimension of length|'
            r'The size of tensor a \(4\) must match the '
            r'size of tensor b \(5\) at non-singleton '
            r'dimension 1)'
        )
    )
def sample_inputs_smooth_l1_loss(op_info, device, dtype, requires_grad, **kwargs):
    # 继承自sample_inputs_loss函数的输入生成器
    yield from sample_inputs_loss(op_info, device, dtype, requires_grad, **kwargs)

    # 创建一个部分应用了make_tensor的函数，用于创建指定设备和数据类型的张量
    make = partial(make_tensor, (S, S), device=device, dtype=dtype, requires_grad=requires_grad)

    # 这个测试用例总是触发平滑条件，因为输入和目标的绝对差小于beta
    yield SampleInput(make(low=0, high=2), args=(make(low=-2, high=0),), kwargs=dict(beta=5))
    yield SampleInput(make(), args=(make(),), kwargs=dict(beta=0))

def sample_inputs_kl_div(op_info, device, dtype, requires_grad, **kwargs):
    # kl_div函数要求输入在[0, 1]范围内（概率分布的概率密度函数）
    # log [0, 1] = (-inf, 0]，因此这是在对数空间进行操作
    make_arg = partial(make_tensor, low=0., device=device, dtype=dtype, requires_grad=requires_grad)

    # 创建对数空间的张量
    def make_log(shape):
        out = torch.nn.functional.log_softmax(make_arg(shape), -1)
        out.requires_grad_(requires_grad)
        return out

    # 创建概率空间的张量
    def make_prob(shape):
        out = torch.nn.functional.softmax(make_arg(shape), -1)
        out.requires_grad_(requires_grad)
        return out

    shapes = ((2,), (2, 3))
    reductions = ("none", "mean", "batchmean", "sum")
    for shape, reduction, log_target in product(shapes, reductions, (True, False)):
        input = make_log(shape)
        target = make_log(shape) if log_target else make_prob(shape)
        yield SampleInput(input, args=(target,), kwargs=dict(reduction=reduction, log_target=log_target))

def sample_inputs_pdist(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用make_tensor函数，用于创建指定设备和数据类型的张量
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 生成所有可能的形状组合的输入样本
    yield from (SampleInput(make_input((n, m))) for n, m in itertools.product((1, S), repeat=2))
    # 生成不同的p值的输入样本
    yield from (SampleInput(make_input((S, S)), kwargs=dict(p=p)) for p in (0.0, 1.0, 2.0, 10.0, float("inf")))

def reference_pdist(input, p=2):
    # pdist函数来自scipy.spatial.distance.pdist
    if p == 0:
        output = pdist(input, "hamming") * input.shape[1]
    elif p == float("inf"):
        output = pdist(input, lambda x, y: np.abs(x - y).max())
    else:
        output = pdist(input, "minkowski", p=p)
    return output.astype(input.dtype)

def sample_inputs_diagflat(op_info, device, dtype, requires_grad, **kwargs):
    # 部分应用make_tensor函数，用于创建指定设备和数据类型的张量
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    # 生成对角扁平化输入样本
    yield SampleInput(make_input(()))
    yield SampleInput(make_input((2,)))
    yield SampleInput(make_input((2, 2)))
    yield SampleInput(make_input((2,)), offset=1)
    yield SampleInput(make_input((2,)), offset=-1)

def sample_inputs_max_unpool(op_info, device, dtype, requires_grad, **kwargs):
    # 定义一个字典，将最大非池化函数的名称映射到对应的最大池化方法
    unpool_name_to_pool_method_dict = {
        'nn.functional.max_unpool1d': torch.nn.functional.max_pool1d,
        'nn.functional.max_unpool2d': torch.nn.functional.max_pool2d,
        'nn.functional.max_unpool3d': torch.nn.functional.max_pool3d
    }
    }

    # 定义一个字典，将池化方法的名称映射到对应的维度
    unpool_name_to_dim = {
        'nn.functional.max_unpool1d': 1,
        'nn.functional.max_unpool2d': 2,
        'nn.functional.max_unpool3d': 3
    }

    # 使用字典推导式创建一个字典，将解池化方法的名称映射到池化方法的完整路径字符串
    unpool_to_pool_name_dict = {k: f'nn.functional.{v.__name__}' for k, v in unpool_name_to_pool_method_dict.items()}

    # 从操作信息中获取池化的维度
    pool_dim = unpool_name_to_dim[op_info.name]
    # 从操作信息中获取池化方法
    pool_method = unpool_name_to_pool_method_dict[op_info.name]

    # 复制操作信息对象，并修改其名称为对应的池化方法名称
    pool_op_info = copy.copy(op_info)
    pool_op_info.name = unpool_to_pool_name_dict[op_info.name]

    # 遍历经过最大池化处理的样本输入
    for sample in sample_inputs_max_pool(pool_op_info, device, dtype, requires_grad, **kwargs):
        # 对于维度为 (C, ...) 的样本输入，当前不支持
        # 参考 https://github.com/pytorch/pytorch/issues/68337
        # TODO: 解决此问题后删除此部分
        if sample.input.dim() != pool_dim + 2:
            continue

        # 对于最大解池化，不支持 dilation > 1
        # 参考 https://github.com/pytorch/pytorch/issues/68420
        if sample.kwargs['dilation'] != 1:
            continue

        # 如果样本输入需要返回 indices，不能进行解池化
        if sample.kwargs['return_indices']:
            # 执行池化操作，获取池化结果和索引
            pool, indices = pool_method(sample.input, **sample.kwargs)
            # 将池化结果设置为叶张量，并根据需要设置梯度属性
            arg = pool.detach().requires_grad_(requires_grad)
            # 准备样本输入的关键字参数
            sample_kwargs = {
                'kernel_size': sample.kwargs['kernel_size'],
                'stride': sample.kwargs['stride'],
                'padding': sample.kwargs['padding'],
                # 输出大小可能为 None，但我们在此显式指定，以补偿池化操作中由于 floor/ceil 运算导致的信息丢失
                'output_size': sample.input.size()
            }

            # 生成一个 SampleInput 对象，包含处理后的参数和关键字参数
            yield SampleInput(arg, args=(indices,), kwargs=sample_kwargs)
def sample_inputs_max_unpool_grad(op_info, device, dtype, requires_grad, **kwargs):
    # 使用 sample_inputs_max_unpool 函数生成样本
    for sample in sample_inputs_max_unpool(op_info, device, dtype, requires_grad, **kwargs):
        # 获取索引信息
        indices = sample.args[0]
        # 对于 max_unpool 的样本生成，来自 max_pool 输入的单个元素可能映射到其输出的多个位置。
        # 这种情况会导致梯度检查失败，因为有限差分算法会逐个扰动输出元素，
        # 而不是按照输入中相同位置的元素组成的等价类来扰动。
        # 因此，有两种解决此问题的方式：
        # 1. 提取一个元素的扰动，并将其应用于同一等价类中的所有元素，
        # 2. 确保等价类都是单一的，即索引张量必须仅包含唯一的索引。
        # 在这里，我们选择解决方案 2，也是最简单的方式。
        if indices.unique().numel() == indices.numel():
            # 返回符合条件的样本
            yield sample

def sample_inputs_multi_head_attention_forward(opinfo, device, dtype, requires_grad, **kwargs):
    # 创建 tensor 的辅助函数，使用指定的设备、数据类型和是否需要梯度
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    if requires_grad:
        # 对于需要计算梯度的情况，由于反向测试耗时过长，可能导致作业超时。
        bsz = 2
        is_batcheds = (True,)
        use_separate_proj_weights = (False,)
        emb_sizes = (2,)
        src_lens = (XS,)
        tgt_lens = (XS,)
        heads = (2,)
        dropouts = (0.5,)
        mask_types = ("2d",)
    else:
        # 对于不需要计算梯度的情况
        bsz = 2
        is_batcheds = (False, True)
        use_separate_proj_weights = (False, True)
        emb_sizes = (2, 4)
        src_lens = (XS,)
        tgt_lens = (XS, S)
        heads = (1, 2)
        dropouts = (0.0, 0.5)
        mask_types = (None, "2d", "3d")

    # 使用 itertools.product 生成各种组合的参数
    for is_batched, use_separate_proj_weight, mask_type, emb_size, src_len, tgt_len, num_heads, dropout_p in itertools.product(
        is_batcheds, use_separate_proj_weights, mask_types, emb_sizes, src_lens, tgt_lens, heads, dropouts
        ):
        # 初始化注意力掩码为 None
        attn_mask = None
        # 根据 mask_type 类型生成不同形状的注意力掩码
        if mask_type == "2d":
            attn_mask = make_input(src_len, tgt_len)
        elif mask_type == "3d":
            attn_mask = make_input((bsz if is_batched else 1) * num_heads, src_len, tgt_len)

        # 根据是否批量处理选择不同形状的查询（q）、键（k）、值（v）张量
        if is_batched:
            q = make_input(src_len, bsz, emb_size)
            k = make_input(tgt_len, bsz, emb_size)
            v = make_input(tgt_len, bsz, emb_size)
        else:
            q = make_input(src_len, emb_size)
            k = make_input(tgt_len, emb_size)
            v = make_input(tgt_len, emb_size)

        # 根据是否使用独立的投影权重选择不同形状的投影权重张量
        if use_separate_proj_weight:
            in_proj_weight = None
            q_proj_weight = make_input(emb_size, emb_size)
            k_proj_weight = make_input(emb_size, emb_size)
            v_proj_weight = make_input(emb_size, emb_size)
        else:
            in_proj_weight = make_input(emb_size * 3, emb_size)
            q_proj_weight = None
            k_proj_weight = None
            v_proj_weight = None

        # 初始化偏置项张量
        bias_k = make_input(emb_size)
        bias_v = make_input(emb_size)
        in_proj_bias = make_input(emb_size * 3)
        out_proj_weight = make_input(emb_size, emb_size)
        out_proj_bias = make_input(emb_size)

        # 构造样本参数和关键字参数用于生成 SampleInput 实例
        sample_args = (
            k, v, emb_size, num_heads, in_proj_weight,
            in_proj_bias, bias_k, bias_v, False,
            dropout_p, out_proj_weight, out_proj_bias
        )
        sample_kwargs = {
            "q_proj_weight" : q_proj_weight,
            "k_proj_weight" : k_proj_weight,
            "v_proj_weight" : v_proj_weight,
            "attn_mask" : attn_mask,
            "training" : True if dropout_p > 0.0 else False,
            "use_separate_proj_weight" : use_separate_proj_weight
        }

        # 返回 SampleInput 的生成器，包含查询张量 q、参数和关键字参数
        yield SampleInput(q, args=sample_args, kwargs=sample_kwargs)
# 设置一个整数常量，表示要创建的张量数量，确保 N * N 不是 4 的倍数，这样可以测试向量化和非向量化的内核代码路径。
NUM_SIZE0_TENSORS = 10000
# 根据 TEST_WITH_SLOW 变量的布尔值选择不同的列表作为 foreach_num_tensors 的初始值
foreach_num_tensors = [20, 23] if not TEST_WITH_SLOW else [23, 30, 300]
# 设置默认的 foreach 函数输入参数的关键字参数字典
_foreach_inputs_default_kwargs = {"noncontiguous": False, "same_size": False, "low": None, "high": None}


class ForeachRightmostArgType(enum.Enum):
    # 定义一个枚举类，表示 foreach 函数的最右边参数的类型
    TensorList = enum.auto()
    ScalarList = enum.auto()
    Scalar = enum.auto()
    Tensor = enum.auto()


class ForeachSampleInput(SampleInput):
    # ForeachSampleInput 类继承自 SampleInput 类，表示 foreach 函数的样本输入
    # 对于 TensorList <op> Scalar/Tensor，我们通过将其转换为 TensorList <op> ScalarList/TensorList
    # 然后转换为多个 Tensor <op> Scalar/Tensor 来计算参考值
    # ref_args 包含转换为 TensorList <op> ScalarList/TensorList 的参数
    ref_args: Any
    # 是否禁用快速路径的标志
    disable_fastpath: bool

    def __init__(self, *args, disable_fastpath=False, ref_args=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.ref_args = ref_args or self.args
        self.disable_fastpath = disable_fastpath


class foreach_inputs_sample_func:
    # foreach_inputs_sample_func 类用于生成 foreach 函数的样本输入
    def __init__(
        self,
        arity: int,
        rightmost_supports_scalar: bool,
        rightmost_supports_scalarlist: bool,
        rightmost_supports_tensor: bool = False,
    ) -> None:
        # 初始化函数，设置 arity（函数的参数个数）和支持的最右边参数类型列表
        self.arity = arity
        self._set_rightmost_arg_types(
            rightmost_supports_scalar, rightmost_supports_scalarlist, rightmost_supports_tensor,
        )
        self._intersperse_empty = (True, False)

    def _set_rightmost_arg_types(
        self,
        rightmost_supports_scalar: bool,
        rightmost_supports_scalarlist: bool,
        rightmost_supports_tensor: bool,
    ) -> None:
        # 根据传入的参数设置最右边参数的支持类型列表
        self._rightmost_arg_types = [ForeachRightmostArgType.TensorList]
        if self.arity > 1:
            if rightmost_supports_scalar:
                self._rightmost_arg_types.append(ForeachRightmostArgType.Scalar)
            if rightmost_supports_scalarlist:
                self._rightmost_arg_types.append(ForeachRightmostArgType.ScalarList)
            if rightmost_supports_tensor:
                self._rightmost_arg_types.append(ForeachRightmostArgType.Tensor)
    # 从函数参数中获取右侧最后一个参数的样本，根据其类型生成不同的样本数据
    def _sample_rightmost_arg(self, opinfo, rightmost_arg_type, device, dtype, num_tensors, **_foreach_inputs_kwargs):
        # 如果右侧最后一个参数的类型是 TensorList
        if rightmost_arg_type == ForeachRightmostArgType.TensorList:
            # 返回一个列表，其中包含使用指定参数生成的 TensorList 样本数据
            return [sample_inputs_foreach(None, device, dtype, num_tensors, **_foreach_inputs_kwargs)]
        # 如果右侧最后一个参数的类型是 Tensor
        if rightmost_arg_type == ForeachRightmostArgType.Tensor:
            # 返回一个列表，包含使用指定参数生成的 Tensor 样本数据
            return [make_tensor(
                (), device=device, dtype=dtype,
                noncontiguous=_foreach_inputs_kwargs["noncontiguous"],
                requires_grad=_foreach_inputs_kwargs.get("requires_grad", False),
            )]
        
        # 检查是否应使用更简单的标量数据类型，例如在 _foreach_pow 函数中，且数据类型为 torch.float16 或 torch.bfloat16 时
        should_use_simpler_scalars = opinfo.name == "_foreach_pow" and dtype in (torch.float16, torch.bfloat16)

        def sample_float():
            # 生成一个随机浮点数
            s = random.random()
            if should_use_simpler_scalars:
                # 如果应该使用更简单的标量数据类型，则返回 1.0 或 2.0
                return 1.0 if s > 0.5 else 2.0
            else:
                # 否则返回一个接近于 1.0 的浮点数
                return 1.0 - s

        # 如果应该使用更简单的标量数据类型，则设置 high 为 2，否则为 9
        high = 2 if should_use_simpler_scalars else 9
        
        # 如果右侧最后一个参数的类型是 ScalarList
        if rightmost_arg_type == ForeachRightmostArgType.ScalarList:
            # 返回包含不同类型标量样本数据的列表
            return [
                [random.randint(0, high) + 1 for _ in range(num_tensors)],  # 整数列表
                [sample_float() for _ in range(num_tensors)],  # 浮点数列表
                [complex(sample_float(), sample_float()) for _ in range(num_tensors)],  # 复数列表
                [True for _ in range(num_tensors)],  # 布尔值列表
                [1, 2.0, 3.0 + 4.5j] + [3.0 for _ in range(num_tensors - 3)],  # 混合类型列表
                [True, 1, 2.0, 3.0 + 4.5j] + [3.0 for _ in range(num_tensors - 4)],  # 更复杂的混合类型列表
            ]
        
        # 如果右侧最后一个参数的类型是 Scalar
        if rightmost_arg_type == ForeachRightmostArgType.Scalar:
            # 返回一个元组，包含不同类型的标量样本数据
            return (
                random.randint(1, high + 1),  # 整数
                sample_float(),  # 浮点数
                True,  # 布尔值
                complex(sample_float(), sample_float()),  # 复数
            )
        
        # 如果代码执行到这里，抛出一个断言错误，显示无效的 rightmost_arg_type
        raise AssertionError(f"Invalid rightmost_arg_type of {rightmost_arg_type}")

    # 根据操作信息、右侧最后一个参数和其类型，生成用于操作的关键字参数字典
    def _sample_kwargs(self, opinfo, rightmost_arg, rightmost_arg_type, dtype):
        kwargs = {}
        # 如果右侧最后一个参数的类型是 TensorList，且操作支持 alpha 参数
        if rightmost_arg_type == ForeachRightmostArgType.TensorList and opinfo.supports_alpha_param:
            # 根据数据类型设置 alpha 参数的值
            if dtype in integral_types_and(torch.bool):
                kwargs["alpha"] = 3
            elif dtype.is_complex:
                kwargs["alpha"] = complex(3, 3)
            else:
                kwargs["alpha"] = 3.14
        
        # 如果函数的参数个数大于 1
        if self.arity > 1:
            # 根据函数的判断，决定是否禁用快速路径
            kwargs["disable_fastpath"] = self._should_disable_fastpath(opinfo, rightmost_arg, rightmost_arg_type, dtype)
        
        # 返回生成的关键字参数字典
        return kwargs
    # 定义一个方法，用于生成零大小张量的样本输入
    def sample_zero_size_tensor_inputs(self, opinfo, device, dtype, requires_grad, **kwargs):
        # 断言确保参数中不包含"num_input_tensors"
        assert "num_input_tensors" not in kwargs
        # 从默认参数字典中提取键值对，同时将其从kwargs中移除
        _foreach_inputs_kwargs = {k: kwargs.pop(k, v) for k, v in _foreach_inputs_default_kwargs.items()}
        # 将"requires_grad"参数设置为方法参数中的值
        _foreach_inputs_kwargs["requires_grad"] = requires_grad
        # 遍历存储在self._rightmost_arg_types中的每个右侧参数类型
        for rightmost_arg_type in self._rightmost_arg_types:
            # 深拷贝foreach输入参数字典
            zero_size_foreach_inputs_kwargs = copy.deepcopy(_foreach_inputs_kwargs)
            # 将"zero_size"参数设置为True
            zero_size_foreach_inputs_kwargs["zero_size"] = True
            # 调用sample_inputs_foreach方法生成零大小张量的样本输入
            input = sample_inputs_foreach(None, device, dtype, NUM_SIZE0_TENSORS, **zero_size_foreach_inputs_kwargs)
            # 如果操作的参数个数大于1
            if self.arity > 1:
                # 生成(self.arity - 2)个零大小张量的样本输入作为args列表的一部分
                args = [
                    sample_inputs_foreach(None, device, dtype, NUM_SIZE0_TENSORS, **zero_size_foreach_inputs_kwargs)
                    for _ in range(self.arity - 2)
                ]
                # 添加最右侧参数的样本输入到args列表中
                args.append(
                    self._sample_rightmost_arg(
                        opinfo, ForeachRightmostArgType.TensorList, device, dtype, NUM_SIZE0_TENSORS,
                        **zero_size_foreach_inputs_kwargs)[0])
                # 通过_sample_kwargs方法生成适当的kwargs字典
                kwargs = self._sample_kwargs(
                    opinfo, args[-1], ForeachRightmostArgType.TensorList, dtype)
            else:
                # 如果操作的参数个数为1，则args为空列表，kwargs为空字典
                args = []
                kwargs = {}
                # 如果操作函数是torch.abs或torch.neg，则设置"disable_fastpath"为False；否则根据dtype设置
                if opinfo.ref in (torch.abs, torch.neg):
                    kwargs["disable_fastpath"] = False
                else:
                    kwargs["disable_fastpath"] = dtype in integral_types_and(torch.bool)
            # 生成一个ForeachSampleInput对象，包括input、args和kwargs，并yield返回
            yield ForeachSampleInput(input, *args, **kwargs)
    # 定义一个 __call__ 方法，使对象可以被调用，接受一些参数并返回迭代器
    def __call__(self, opinfo, device, dtype, requires_grad, **kwargs):
        # 检查是否传入了参数 num_input_tensors
        num_input_tensors_specified = "num_input_tensors" in kwargs
        # 如果指定了 num_input_tensors，则取出并移除这个参数
        num_input_tensors = kwargs.pop("num_input_tensors") if num_input_tensors_specified else foreach_num_tensors
        # 确保 num_input_tensors 是一个列表
        assert isinstance(num_input_tensors, list)
        # 构建 _foreach_inputs_kwargs 字典，从 _foreach_inputs_default_kwargs 中取值，同时设置 requires_grad 和 zero_size 属性
        _foreach_inputs_kwargs = {k: kwargs.pop(k, v) for k, v in _foreach_inputs_default_kwargs.items()}
        _foreach_inputs_kwargs["requires_grad"] = requires_grad
        _foreach_inputs_kwargs["zero_size"] = False

        # 通过 itertools.product 生成 num_input_tensors、self._rightmost_arg_types 和 _intersperse_empty 的笛卡尔积
        for num_tensors, rightmost_arg_type, intersperse_empty_tensors in itertools.product(
                num_input_tensors, self._rightmost_arg_types, self._intersperse_empty):
            # 如果 intersperse_empty_tensors 为真且不在 CPU 设备上，跳过生成空张量的步骤，以减少冗余
            if intersperse_empty_tensors and (num_tensors != max(num_input_tensors) or str(device) == 'cpu'):
                continue
            # 设置 _foreach_inputs_kwargs 中的 intersperse_empty_tensors 属性
            _foreach_inputs_kwargs["intersperse_empty_tensors"] = intersperse_empty_tensors
            # 调用 sample_inputs_foreach 函数生成输入数据 input
            input = sample_inputs_foreach(
                None, device, dtype, num_tensors, **_foreach_inputs_kwargs)
            args = []
            # 如果操作的参数个数大于 1，则生成多个参数组合
            if self.arity > 1:
                args = [
                    sample_inputs_foreach(
                        None, device, dtype, num_tensors, **_foreach_inputs_kwargs)
                    for _ in range(self.arity - 2)
                ]
                # 生成右侧参数列表
                rightmost_arg_list = self._sample_rightmost_arg(
                    opinfo, rightmost_arg_type, device, dtype, num_tensors,
                    **_foreach_inputs_kwargs)
                # 将右侧参数添加到参数列表中，并生成 ForeachSampleInput 实例
                for rightmost_arg in rightmost_arg_list:
                    args.append(rightmost_arg)
                    # 生成 _sample_kwargs 函数的关键字参数
                    kwargs = self._sample_kwargs(opinfo, rightmost_arg, rightmost_arg_type, dtype)
                    ref_args = args
                    # 如果右侧参数是标量或张量，则替换最后一个参数为 num_tensors 个副本
                    if rightmost_arg_type in (ForeachRightmostArgType.Scalar, ForeachRightmostArgType.Tensor):
                        ref_args = args[:-1] + [[args[-1] for _ in range(num_tensors)]]
                    # 创建 ForeachSampleInput 实例并生成
                    sample = ForeachSampleInput(input, *args, ref_args=ref_args, **kwargs)
                    yield sample
                    args.pop()
            else:
                # 如果操作的参数个数为 1，则直接生成 ForeachSampleInput 实例
                yield ForeachSampleInput(
                    input,
                    *args,
                    disable_fastpath=self._should_disable_fastpath(opinfo, None, None, dtype),
                )
# 定义一个继承自foreach_inputs_sample_func的类foreach_max_sample_func
class foreach_max_sample_func(foreach_inputs_sample_func):
    
    # 初始化方法，设置类的属性
    def __init__(
        self,
        arity: int,
        rightmost_supports_scalar: bool,
        rightmost_supports_scalarlist: bool,
        rightmost_supports_tensor: bool = False,
    ) -> None:
        # 调用父类foreach_inputs_sample_func的初始化方法
        super().__init__(arity, rightmost_supports_scalar, rightmost_supports_scalarlist, rightmost_supports_tensor)
        # 设置类特有的属性
        self._intersperse_empty = (False,)
    
    # 定义一个方法sample_zero_size_tensor_inputs，用于生成零尺寸张量的输入样本
    def sample_zero_size_tensor_inputs(self, opinfo, device, dtype, requires_grad, **kwargs):
        # 返回一个空列表，表示没有零尺寸张量的输入
        return []

    # 定义一个私有方法_should_disable_fastpath，用于判断是否禁用快速路径
    def _should_disable_fastpath(self, opinfo, rightmost_arg, rightmost_arg_type, dtype):
        # 总是返回False，表示不禁用快速路径
        return False


# 定义一个继承自foreach_inputs_sample_func的类foreach_norm_sample_func
class foreach_norm_sample_func(foreach_inputs_sample_func):
    
    # 定义方法sample_zero_size_tensor_inputs，生成零尺寸张量的输入样本
    def sample_zero_size_tensor_inputs(self, opinfo, device, dtype, requires_grad, **kwargs):
        # 断言条件，确保kwargs中不存在"num_input_tensors"
        assert "num_input_tensors" not in kwargs
        # 创建一个字典_foreach_inputs_kwargs，用于存储输入的关键字参数
        _foreach_inputs_kwargs = {k: kwargs.pop(k, v) for k, v in _foreach_inputs_default_kwargs.items()}
        # 将requires_grad添加到_foreach_inputs_kwargs中
        _foreach_inputs_kwargs["requires_grad"] = requires_grad
        # 遍历指定的顺序ord列表，生成对应的输入样本
        for ord in (0, 1, 2, -1, -2, float('inf'), float('-inf')):
            # 调用sample_inputs_foreach函数生成一个输入input
            input = sample_inputs_foreach(None, device, dtype, NUM_SIZE0_TENSORS, zero_size=True, **_foreach_inputs_kwargs)
            # 默认禁用快速路径
            disable_fastpath = True
            # 如果ord在(1, 2, float('inf'))中且dtype在浮点数类型中
            if ord in (1, 2, float('inf')) and dtype in floating_types_and(torch.half, torch.bfloat16):
                # 不禁用快速路径
                disable_fastpath = False
            # 生成一个ForeachSampleInput对象，包含输入input、顺序ord和是否禁用快速路径disable_fastpath
            yield ForeachSampleInput(input, ord=ord, disable_fastpath=disable_fastpath)
    # 定义一个特殊方法 __call__，用于实例对象的调用操作
    def __call__(self, opinfo, device, dtype, requires_grad, **kwargs):
        # 从 kwargs 中弹出 "num_input_tensors" 参数，如果不存在则使用默认值 foreach_num_tensors
        num_input_tensors = kwargs.pop("num_input_tensors", foreach_num_tensors)
        # 断言 num_input_tensors 是一个列表
        assert isinstance(num_input_tensors, list)
        
        # 构建 _foreach_inputs_kwargs 字典，从 kwargs 中获取每个键对应的值，如果不存在则使用默认值 _foreach_inputs_default_kwargs 中的值
        _foreach_inputs_kwargs = {k: kwargs.pop(k, v) for k, v in _foreach_inputs_default_kwargs.items()}
        # 将 requires_grad 参数添加到 _foreach_inputs_kwargs 中
        _foreach_inputs_kwargs["requires_grad"] = requires_grad

        # 使用 product 函数生成 num_input_tensors、ord 和 out_dtype 的所有组合
        for num_tensors, ord, out_dtype in product(
            num_input_tensors,
            (0, 1, 2, -1, -2, float('inf'), float('-inf')),
            (None,) + (torch.complex128,) if dtype in complex_types() else (torch.float64,),
        ):
            # 生成一个输入样本，调用 sample_inputs_foreach 函数
            input = sample_inputs_foreach(None, device, dtype, num_tensors, zero_size=False, **_foreach_inputs_kwargs)
            # 默认禁用快速路径
            disable_fastpath = True
            # 如果 ord 是 1、2 或者无穷大，并且 dtype 是浮点类型之一，不包括 torch.half 和 torch.bfloat16，则不禁用快速路径
            if ord in (1, 2, float('inf')) and dtype in floating_types_and(torch.half, torch.bfloat16):
                disable_fastpath = False
            # 生成一个 ForeachSampleInput 对象，作为生成器的输出
            yield ForeachSampleInput(input, ord=ord, disable_fastpath=disable_fastpath, dtype=out_dtype)

        # 如果 requires_grad 是 False，测试 NaN 值的传播情况，但跳过自动求导测试
        if not requires_grad:
            # 定义一组包含 NaN 的输入列表
            nan_inputs = [
                [float('nan')],
                [float('nan'), 1.0],
                [1.0, float('nan')],
                [1.0, 2.0, 3.0, float('nan'), float('nan'), 7.0, float('nan'), float('nan'), -1.5, 6.0],
                [7.0, 3.0, float('nan'), float('nan'), -1.5, 6.0],
                [3.0, float('nan'), float('nan'), -1.5, 6.0],
            ]
            # 遍历 NaN 输入列表
            for input in nan_inputs:
                # 创建一个张量 x，包含 NaN 值，存储在指定设备上
                x = torch.tensor(input, device=device)
                # 默认禁用快速路径
                disable_fastpath = True
                # 如果 ord 是 1、2 或者无穷大，并且 dtype 是浮点类型之一，不包括 torch.half 和 torch.bfloat16，则不禁用快速路径
                if ord in (1, 2, float('inf')) and dtype in floating_types_and(torch.half, torch.bfloat16):
                    disable_fastpath = False
                # 生成一个 ForeachSampleInput 对象，作为生成器的输出
                yield ForeachSampleInput([x], ord=ord, disable_fastpath=disable_fastpath)
class foreach_lerp_sample_func(foreach_inputs_sample_func):
    # 继承自 foreach_inputs_sample_func 类，用于执行线性插值采样函数的类

    def _sample_rightmost_arg(self, opinfo, rightmost_arg_type, device, dtype, num_tensors, **_foreach_inputs_kwargs):
        # 根据 opinfo 和 rightmost_arg_type 采样右边最后一个参数
        if rightmost_arg_type == ForeachRightmostArgType.TensorList:
            # 如果 rightmost_arg_type 是 TensorList 类型
            return [sample_inputs_foreach(None, device, dtype, num_tensors, **_foreach_inputs_kwargs)]
            # 返回一个包含样本输入的列表，每个输入样本是一个 TensorList

        if rightmost_arg_type == ForeachRightmostArgType.ScalarList:
            # 如果 rightmost_arg_type 是 ScalarList 类型
            return [
                [random.randint(0, 9) + 1 for _ in range(num_tensors)],  # 整数列表
                [1.0 - random.random() for _ in range(num_tensors)],     # 浮点数列表
                [complex(1.0 - random.random(), 1.0 - random.random()) for _ in range(num_tensors)],  # 复数列表
                [True for _ in range(num_tensors)],                      # 布尔值列表
                [1, 2.0, 3.0 + 4.5j] + [3.0 for _ in range(num_tensors - 3)],  # 混合类型列表
                [True, 1, 2.0, 3.0 + 4.5j] + [3.0 for _ in range(num_tensors - 4)],  # 混合类型列表
            ]
            # 返回包含不同类型标量值列表的列表

        if rightmost_arg_type == ForeachRightmostArgType.Scalar:
            # 如果 rightmost_arg_type 是 Scalar 类型
            return [random.random()]
            # 返回一个包含随机标量值的列表

        raise AssertionError(f"Invalid rightmost_arg_type of {rightmost_arg_type}")
        # 如果 rightmost_arg_type 类型无效，抛出断言错误

class foreach_pointwise_sample_func(foreach_inputs_sample_func):
    # 继承自 foreach_inputs_sample_func 类，用于执行逐点采样函数的类

    def __init__(
        self,
        arity: int = 3,
        rightmost_supports_scalar: bool = False,
        rightmost_supports_scalarlist: bool = False,
    ):
        super().__init__(arity, rightmost_supports_scalar, rightmost_supports_scalarlist)
        # 初始化函数，设置函数的参数和父类继承

    def _should_disable_fastpath(self, opinfo, rightmost_arg, rightmost_arg_type, dtype):
        # 判断是否禁用快速路径函数
        return dtype in integral_types_and(torch.bool) and opinfo.ref in (torch.addcmul,)
        # 如果数据类型是整数类型或布尔类型，并且 opinfo.ref 是 torch.addcmul，则禁用快速路径

    def sample_zero_size_tensor_inputs(self, opinfo, device, dtype, requires_grad, **kwargs):
        # 生成零尺寸张量输入样本
        assert "num_input_tensors" not in kwargs
        # 断言确保 kwargs 中没有 num_input_tensors 参数
        _foreach_inputs_kwargs = {k: kwargs.pop(k, v) for k, v in _foreach_inputs_default_kwargs.items()}
        # 从 _foreach_inputs_default_kwargs 中提取参数到 _foreach_inputs_kwargs 中
        _foreach_inputs_kwargs["requires_grad"] = requires_grad
        # 设置 requires_grad 参数为函数参数的 requires_grad 值
        input = sample_inputs_foreach(None, device, dtype, NUM_SIZE0_TENSORS, zero_size=True, **_foreach_inputs_kwargs)
        # 采样零尺寸的输入张量样本
        args = [
            sample_inputs_foreach(None, device, dtype, NUM_SIZE0_TENSORS, zero_size=True, **_foreach_inputs_kwargs)
            for _ in range(2)
        ]
        # 生成两次零尺寸的输入张量样本
        if "scalars" in kwargs:
            del kwargs["scalars"]
        # 如果 kwargs 中有 scalars 参数，则删除它
        kwargs.update(self._sample_kwargs(opinfo, args[-1], ForeachRightmostArgType.TensorList, dtype))
        # 使用 opinfo 和最后一个参数 args[-1] 的样本类型更新 kwargs 参数
        yield ForeachSampleInput(input, *args, **kwargs)
        # 返回逐个采样输入
    # 定义一个调用方法，用于生成多个输入样本
    def __call__(self, opinfo, device, dtype, requires_grad, **kwargs):
        # 检查是否指定了 num_input_tensors 参数
        num_input_tensors_specified = "num_input_tensors" in kwargs
        # 如果指定了 num_input_tensors 参数，则获取其值并移除 kwargs 中的该参数
        num_input_tensors = kwargs.pop("num_input_tensors") if num_input_tensors_specified else foreach_num_tensors
        # 确保 num_input_tensors 是一个列表
        assert isinstance(num_input_tensors, list)
        # 根据默认的 _foreach_inputs_default_kwargs 创建 _foreach_inputs_kwargs 字典，并加入 requires_grad 参数
        _foreach_inputs_kwargs = {k: kwargs.pop(k, v) for k, v in _foreach_inputs_default_kwargs.items()}
        _foreach_inputs_kwargs["requires_grad"] = requires_grad

        # 使用 itertools.product 生成 num_input_tensors 和 self._rightmost_arg_types 的笛卡尔积
        for num_tensors, rightmost_arg_type in itertools.product(num_input_tensors, self._rightmost_arg_types):
            # 调用 sample_inputs_foreach 函数生成输入样本 input
            input = sample_inputs_foreach(None, device, dtype, num_tensors, zero_size=False, **_foreach_inputs_kwargs)
            # 根据 rightmost_arg_type 的值生成对应的参数 args
            args = [
                sample_inputs_foreach(None, device, dtype, num_tensors, zero_size=False, **_foreach_inputs_kwargs)
                for _ in range(2 - int(rightmost_arg_type == ForeachRightmostArgType.TensorList))
            ]
            # 调用 _sample_rightmost_arg 方法生成 rightmost_arg_list
            rightmost_arg_list = self._sample_rightmost_arg(
                opinfo, rightmost_arg_type, device, dtype, num_tensors, zero_size=False, **_foreach_inputs_kwargs)
            # 遍历 rightmost_arg_list，为每个 rightmost_arg 生成参数 kwargs，并合并额外的 kwargs
            for rightmost_arg in rightmost_arg_list:
                kwargs = {}
                if rightmost_arg_type == ForeachRightmostArgType.TensorList:
                    args.append(rightmost_arg)
                elif rightmost_arg_type in [ForeachRightmostArgType.Tensor, ForeachRightmostArgType.ScalarList]:
                    kwargs["scalars"] = rightmost_arg
                else:
                    kwargs["value"] = rightmost_arg
                kwargs.update(self._sample_kwargs(opinfo, rightmost_arg, rightmost_arg_type, dtype))
                # 断言 args 的长度为 2
                assert len(args) == 2, f"{len(args)=}"
                # 创建 ForeachSampleInput 对象 sample，包含 input、args 和 kwargs
                sample = ForeachSampleInput(input, *args, **kwargs)
                # 生成 sample
                yield sample
                # 如果 rightmost_arg_type 是 ForeachRightmostArgType.TensorList，则移除最后一个参数
                if rightmost_arg_type == ForeachRightmostArgType.TensorList:
                    args.pop()
foreach_unary_op_db: List[OpInfo] = [
    # 创建一个包含操作信息的列表，每个操作信息包括函数名、输入样本生成函数、是否需要反向传播结果等信息
    ForeachFuncInfo(
        'exp',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        backward_requires_result=True,
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            # 添加装饰器信息，用于指定在单元测试中预期的失败情况及相关测试信息
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
        ),
    ),
    # 同上，设置另一个函数 'acos' 的操作信息
    ForeachFuncInfo(
        'acos',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
        ),
    ),
    # 同上，设置另一个函数 'asin' 的操作信息
    ForeachFuncInfo(
        'asin',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
        ),
    ),
]
    # 创建一个 ForeachFuncInfo 对象，用于函数 'atan'
    # 使用 foreach_inputs_sample_func 函数生成输入样本数据
    # 支持自动求导和原地自动求导
    # 支持前向自动微分
    # 添加装饰器信息，标记为预期的测试失败，用于测试 'atan' 函数的元信息分发和原地操作
    # 装饰器要求数据类型是整数和布尔型
    ForeachFuncInfo(
        'atan',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
        ),
    ),
    
    # 创建一个 ForeachFuncInfo 对象，用于函数 'cos'
    # 使用 foreach_inputs_sample_func 函数生成输入样本数据
    # 支持自动求导和原地自动求导
    # 支持前向自动微分
    # 添加装饰器信息，标记为预期的测试失败，用于测试 'cos' 函数的元信息分发和原地操作
    # 装饰器要求数据类型是整数和布尔型
    ForeachFuncInfo(
        'cos',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
        ),
    ),
    
    # 创建一个 ForeachFuncInfo 对象，用于函数 'cosh'
    # 使用 foreach_inputs_sample_func 函数生成输入样本数据
    # 支持自动求导和原地自动求导
    # 支持前向自动微分
    # 添加装饰器信息，标记为预期的测试失败，用于测试 'cosh' 函数的元信息分发和原地操作
    # 装饰器要求数据类型是整数和布尔型
    ForeachFuncInfo(
        'cosh',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
        ),
    ),
    ForeachFuncInfo(
        'log',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
        ),
    ),



    ForeachFuncInfo(
        'log10',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
        ),
    ),



    ForeachFuncInfo(
        'log2',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool,),
            ),
        ),
    ),



每个代码块表示一个函数信息对象的初始化，用于处理不同的数学函数（'log'、'log10'、'log2'）。
每个函数信息对象包含以下内容：
- 函数名称：字符串，例如 'log'、'log10'、'log2'
- sample_inputs_func：用于生成输入样本的函数
- supports_autograd：是否支持自动微分
- supports_inplace_autograd：是否支持原地自动微分
- supports_forward_ad：是否支持前向自动微分
- decorators：装饰器信息元组，包含多个 DecorateInfo 对象
  - 每个 DecorateInfo 对象指定一个装饰器的信息，包括：
    - 装饰器函数（这里是 unittest.expectedFailure）
    - 相关的测试类名 ("TestMeta")
    - 测试函数名 ("test_dispatch_meta_inplace", "test_dispatch_symbolic_meta_inplace", "test_meta_inplace")
    - dtypes：数据类型限制，这里是整数类型和布尔类型的组合
    ForeachFuncInfo(
        'tan',  # 调用 ForeachFuncInfo 类的构造函数，指定函数名为 'tan'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 设置样本输入函数为 foreach_inputs_sample_func(1, False, False)
        backward_requires_result=True,  # 设置需要反向传播结果为 True
        supports_autograd=True,  # 设置支持自动求导为 True
        supports_inplace_autograd=True,  # 设置支持原地自动求导为 True
        supports_forward_ad=True,  # 设置支持前向自动求导为 True
        decorators=(  # 定义装饰器元组开始
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 指定测试类为 "TestMeta"
                "test_dispatch_meta_inplace",  # 指定测试方法为 "test_dispatch_meta_inplace"
                dtypes=integral_types_and(torch.bool,),  # 设置数据类型为整数和 torch.bool 类型的组合
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 指定测试类为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 指定测试方法为 "test_dispatch_symbolic_meta_inplace"
                dtypes=integral_types_and(torch.bool,),  # 设置数据类型为整数和 torch.bool 类型的组合
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 指定测试类为 "TestMeta"
                "test_meta_inplace",  # 指定测试方法为 "test_meta_inplace"
                dtypes=integral_types_and(torch.bool,),  # 设置数据类型为整数和 torch.bool 类型的组合
            ),
            DecorateInfo(
                toleranceOverride(  # 使用 toleranceOverride 装饰器
                    {
                        torch.complex64: tol(atol=3e-04, rtol=2e-05)  # 设置 torch.complex64 类型的容差参数
                    }
                ),
                'TestForeach',  # 指定测试类为 "TestForeach"
                'test_parity',  # 指定测试方法为 "test_parity"
                device_type='cuda'  # 设置设备类型为 'cuda'
            ),
        ),  # 定义装饰器元组结束
    ),
    ForeachFuncInfo(
        'tanh',  # 调用 ForeachFuncInfo 类的构造函数，指定函数名为 'tanh'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 设置样本输入函数为 foreach_inputs_sample_func(1, False, False)
        backward_requires_result=True,  # 设置需要反向传播结果为 True
        supports_autograd=True,  # 设置支持自动求导为 True
        supports_inplace_autograd=True,  # 设置支持原地自动求导为 True
        supports_forward_ad=True,  # 设置支持前向自动求导为 True
        decorators=(  # 定义装饰器元组开始
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 指定测试类为 "TestMeta"
                "test_dispatch_meta_inplace",  # 指定测试方法为 "test_dispatch_meta_inplace"
                dtypes=integral_types_and(torch.bool,),  # 设置数据类型为整数和 torch.bool 类型的组合
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 指定测试类为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 指定测试方法为 "test_dispatch_symbolic_meta_inplace"
                dtypes=integral_types_and(torch.bool,),  # 设置数据类型为整数和 torch.bool 类型的组合
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 指定测试类为 "TestMeta"
                "test_meta_inplace",  # 指定测试方法为 "test_meta_inplace"
                dtypes=integral_types_and(torch.bool,),  # 设置数据类型为整数和 torch.bool 类型的组合
            ),
            DecorateInfo(
                toleranceOverride(  # 使用 toleranceOverride 装饰器
                    {torch.complex64: tol(atol=5e-03, rtol=1e-04)}  # 设置 torch.complex64 类型的容差参数
                ),
                'TestForeach',  # 指定测试类为 "TestForeach"
                'test_parity',  # 指定测试方法为 "test_parity"
                device_type='cuda'  # 设置设备类型为 'cuda'
            ),
        ),  # 定义装饰器元组结束
    ),
    ForeachFuncInfo(
        'sin',  # 创建一个 ForeachFuncInfo 对象，针对函数 'sin'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 设置样本输入函数为指定的函数调用结果
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地自动求导
        supports_forward_ad=True,  # 支持前向自动求导
        decorators=(  # 设置装饰器列表，用于对测试函数进行修饰
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_meta_inplace",  # 测试方法名为 "test_dispatch_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 指定数据类型为整数类型和布尔类型的结合
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 测试方法名为 "test_dispatch_symbolic_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 指定数据类型为整数类型和布尔类型的结合
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_meta_inplace",  # 测试方法名为 "test_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 指定数据类型为整数类型和布尔类型的结合
            ),
        ),
    ),
    ForeachFuncInfo(
        'sinh',  # 创建一个 ForeachFuncInfo 对象，针对函数 'sinh'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 设置样本输入函数为指定的函数调用结果
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地自动求导
        supports_forward_ad=True,  # 支持前向自动求导
        decorators=(  # 设置装饰器列表，用于对测试函数进行修饰
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_meta_inplace",  # 测试方法名为 "test_dispatch_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 指定数据类型为整数类型和布尔类型的结合
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 测试方法名为 "test_dispatch_symbolic_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 指定数据类型为整数类型和布尔类型的结合
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_meta_inplace",  # 测试方法名为 "test_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 指定数据类型为整数类型和布尔类型的结合
            ),
        ),
    ),
    ForeachFuncInfo(
        'neg',  # 设置函数名称为 'neg'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 使用给定的参数调用 foreach_inputs_sample_func 函数，获取样本输入函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地操作的自动求导
        supports_forward_ad=True,  # 支持前向自动微分
        decorators=(  # 装饰器元组开始
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_meta_inplace",  # 测试方法名称为 "test_dispatch_meta_inplace"
                dtypes=(torch.bool,),  # 输入数据类型限定为 torch.bool
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_meta_outplace",  # 测试方法名称为 "test_dispatch_meta_outplace"
                dtypes=(torch.bool,),  # 输入数据类型限定为 torch.bool
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 测试方法名称为 "test_dispatch_symbolic_meta_inplace"
                dtypes=(torch.bool,),  # 输入数据类型限定为 torch.bool
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_symbolic_meta_outplace",  # 测试方法名称为 "test_dispatch_symbolic_meta_outplace"
                dtypes=(torch.bool,),  # 输入数据类型限定为 torch.bool
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_meta_inplace",  # 测试方法名称为 "test_meta_inplace"
                dtypes=(torch.bool,),  # 输入数据类型限定为 torch.bool
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_meta_outplace",  # 测试方法名称为 "test_meta_outplace"
                dtypes=(torch.bool,),  # 输入数据类型限定为 torch.bool
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestForeach",  # 测试类名称为 "TestForeach"
                "test_unary_op_tensors_on_different_devices",  # 测试方法名称为 "test_unary_op_tensors_on_different_devices"
                device_type="cuda",  # 设备类型为 "cuda"
                dtypes=(torch.bool,),  # 输入数据类型限定为 torch.bool
            ),
        ),  # 装饰器元组结束
    ),
    ForeachFuncInfo(
        'sqrt',  # 设置函数名称为 'sqrt'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 使用给定的参数调用 foreach_inputs_sample_func 函数，获取样本输入函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地操作的自动求导
        supports_forward_ad=True,  # 支持前向自动微分
        backward_requires_result=True,  # 后向传播要求结果
        decorators=(  # 装饰器元组开始
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_meta_inplace",  # 测试方法名称为 "test_dispatch_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 输入数据类型限定为整数类型和 torch.bool
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 测试方法名称为 "test_dispatch_symbolic_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 输入数据类型限定为整数类型和 torch.bool
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器，预期该测试会失败
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_meta_inplace",  # 测试方法名称为 "test_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 输入数据类型限定为整数类型和 torch.bool
            ),
        ),  # 装饰器元组结束
    ),
    ForeachFuncInfo(
        'ceil',  # 设置函数名称为 'ceil'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 使用给定的函数生成样本输入数据
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地操作的自动求导
        supports_forward_ad=True,  # 支持前向自动求导
        decorators=(  # 使用装饰器对以下测试进行修饰
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器，期望测试失败
                "TestMeta",  # 测试所属的元信息测试类
                "test_dispatch_meta_inplace",  # 测试方法：测试原地分发元信息
                dtypes=complex_types_and(torch.bool),  # 测试数据类型包括复杂类型和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器，期望测试失败
                "TestMeta",  # 测试所属的元信息测试类
                "test_dispatch_meta_outplace",  # 测试方法：测试非原地分发元信息
                dtypes=complex_types_and(torch.bool),  # 测试数据类型包括复杂类型和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器，期望测试失败
                "TestMeta",  # 测试所属的元信息测试类
                "test_dispatch_symbolic_meta_inplace",  # 测试方法：测试符号元信息的原地分发
                dtypes=complex_types_and(torch.bool),  # 测试数据类型包括复杂类型和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器，期望测试失败
                "TestMeta",  # 测试所属的元信息测试类
                "test_dispatch_symbolic_meta_outplace",  # 测试方法：测试符号元信息的非原地分发
                dtypes=complex_types_and(torch.bool),  # 测试数据类型包括复杂类型和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器，期望测试失败
                "TestMeta",  # 测试所属的元信息测试类
                "test_meta_inplace",  # 测试方法：测试原地元信息
                dtypes=complex_types_and(torch.bool),  # 测试数据类型包括复杂类型和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器，期望测试失败
                "TestMeta",  # 测试所属的元信息测试类
                "test_meta_outplace",  # 测试方法：测试非原地元信息
                dtypes=complex_types_and(torch.bool),  # 测试数据类型包括复杂类型和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器，期望测试失败
                "TestForeach",  # 测试所属的循环测试类
                "test_parity",  # 测试方法：测试奇偶性
                device_type="cuda",  # 测试设备类型为 CUDA
                dtypes=complex_types(),  # 测试数据类型为复杂类型
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),  # 当 noncontiguous 参数为 False 时激活测试
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器，期望测试失败
                "TestForeach",  # 测试所属的循环测试类
                "test_autodiff",  # 测试方法：测试自动微分
                device_type="cuda",  # 测试设备类型为 CUDA
                dtypes=(torch.complex128,),  # 测试数据类型为 torch.complex128
            ),
        ),
    ),
    ForeachFuncInfo(
        'erf',  # 使用 'erf' 函数进行测试
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 获取用于测试的样本输入函数
        supports_autograd=True,  # 支持自动微分
        supports_inplace_autograd=True,  # 支持原地自动微分
        supports_forward_ad=True,  # 支持前向自动微分
        decorators=(  # 装饰器列表开始
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_meta_inplace",  # 测试方法名称为 "test_dispatch_meta_inplace"
                dtypes=integral_types_and(torch.bool) + complex_types(),  # 测试涉及的数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_meta_outplace",  # 测试方法名称为 "test_dispatch_meta_outplace"
                dtypes=complex_types(),  # 测试涉及的数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 测试方法名称为 "test_dispatch_symbolic_meta_inplace"
                dtypes=integral_types_and(torch.bool) + complex_types(),  # 测试涉及的数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_dispatch_symbolic_meta_outplace",  # 测试方法名称为 "test_dispatch_symbolic_meta_outplace"
                dtypes=complex_types(),  # 测试涉及的数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_meta_inplace",  # 测试方法名称为 "test_meta_inplace"
                dtypes=integral_types_and(torch.bool) + complex_types(),  # 测试涉及的数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名称为 "TestMeta"
                "test_meta_outplace",  # 测试方法名称为 "test_meta_outplace"
                dtypes=complex_types(),  # 测试涉及的数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestForeach",  # 测试类名称为 "TestForeach"
                "test_parity",  # 测试方法名称为 "test_parity"
                device_type="cuda",  # 设备类型为 CUDA
                dtypes=complex_types(),  # 测试涉及的数据类型为复数类型
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),  # 活动条件为非非连续张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestForeach",  # 测试类名称为 "TestForeach"
                "test_autodiff",  # 测试方法名称为 "test_autodiff"
                device_type="cuda",  # 设备类型为 CUDA
                dtypes=(torch.complex128,),  # 测试涉及的数据类型为复数类型的 torch.complex128
            ),
        ),  # 装饰器列表结束
    ),
    ForeachFuncInfo(
        'erfc',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool) + complex_types(),
            ),  # 标记为预期的测试失败，用于测试 dispatch_meta_inplace 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_outplace",
                dtypes=complex_types(),
            ),  # 标记为预期的测试失败，用于测试 dispatch_meta_outplace 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool) + complex_types(),
            ),  # 标记为预期的测试失败，用于测试 dispatch_symbolic_meta_inplace 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_outplace",
                dtypes=complex_types(),
            ),  # 标记为预期的测试失败，用于测试 dispatch_symbolic_meta_outplace 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool) + complex_types(),
            ),  # 标记为预期的测试失败，用于测试 meta_inplace 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_outplace",
                dtypes=complex_types(),
            ),  # 标记为预期的测试失败，用于测试 meta_outplace 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestForeach",
                "test_parity",
                device_type="cuda",
                dtypes=complex_types(),
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),
            ),  # 标记为预期的测试失败，用于测试 parity 函数，仅在条件满足时激活
            DecorateInfo(
                unittest.expectedFailure,
                "TestForeach",
                "test_autodiff",
                device_type="cuda",
                dtypes=(torch.complex128,),
            ),  # 标记为预期的测试失败，用于测试 autodiff 函数，限定数据类型为 complex128
        ),
    ),
    ForeachFuncInfo(
        'expm1',
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        backward_requires_result=True,
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool),
            ),  # 标记为预期的测试失败，用于测试 dispatch_meta_inplace 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool),
            ),  # 标记为预期的测试失败，用于测试 dispatch_symbolic_meta_inplace 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool),
            ),  # 标记为预期的测试失败，用于测试 meta_inplace 函数
        ),
    ),
    ForeachFuncInfo(
        'floor',  # 调用 ForeachFuncInfo 构造函数，指定函数名为 'floor'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 设置样本输入函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地操作的自动求导
        supports_forward_ad=True,  # 支持前向自动微分
        decorators=(  # 设置装饰器元组，用于测试预期失败的情况
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_meta_inplace",  # 测试方法名为 "test_dispatch_meta_inplace"
                dtypes=complex_types_and(torch.bool),  # 支持的数据类型为复数类型和布尔类型的张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_meta_outplace",  # 测试方法名为 "test_dispatch_meta_outplace"
                dtypes=complex_types_and(torch.bool),  # 支持的数据类型为复数类型和布尔类型的张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 测试方法名为 "test_dispatch_symbolic_meta_inplace"
                dtypes=complex_types_and(torch.bool),  # 支持的数据类型为复数类型和布尔类型的张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_symbolic_meta_outplace",  # 测试方法名为 "test_dispatch_symbolic_meta_outplace"
                dtypes=complex_types_and(torch.bool),  # 支持的数据类型为复数类型和布尔类型的张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_meta_inplace",  # 测试方法名为 "test_meta_inplace"
                dtypes=complex_types_and(torch.bool),  # 支持的数据类型为复数类型和布尔类型的张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_meta_outplace",  # 测试方法名为 "test_meta_outplace"
                dtypes=complex_types_and(torch.bool),  # 支持的数据类型为复数类型和布尔类型的张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestForeach",  # 测试类名为 "TestForeach"
                "test_parity",  # 测试方法名为 "test_parity"
                device_type="cuda",  # 设备类型为 "cuda"
                dtypes=complex_types(),  # 支持的数据类型为复数类型的张量
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),  # 活动条件为非不连续张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestForeach",  # 测试类名为 "TestForeach"
                "test_autodiff",  # 测试方法名为 "test_autodiff"
                device_type="cuda",  # 设备类型为 "cuda"
                dtypes=(torch.complex128,),  # 支持的数据类型为 torch.complex128 类型的张量
            ),
        ),
    ),
    ForeachFuncInfo(
        'log1p',  # 调用 ForeachFuncInfo 构造函数，指定函数名为 'log1p'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 设置样本输入函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地操作的自动求导
        supports_forward_ad=True,  # 支持前向自动微分
        decorators=(  # 设置装饰器元组，用于测试预期失败的情况
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_meta_inplace",  # 测试方法名为 "test_dispatch_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 支持的数据类型为整数类型和布尔类型的张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 测试方法名为 "test_dispatch_symbolic_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 支持的数据类型为整数类型和布尔类型的张量
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类名为 "TestMeta"
                "test_meta_inplace",  # 测试方法名为 "test_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 支持的数据类型为整数类型和布尔类型的张量
            ),
        ),
    ),
    ForeachFuncInfo(
        'round',  # 使用'round'函数进行测试
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 设置输入样本函数，返回非迭代对象的样本
        supports_autograd=True,  # 支持自动微分
        supports_inplace_autograd=True,  # 支持原地自动微分
        supports_forward_ad=True,  # 支持前向自动微分
        decorators=(  # 装饰器元组开始
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期的测试失败
                "TestMeta",  # 测试类为'TestMeta'
                "test_dispatch_meta_inplace",  # 测试方法为'test_dispatch_meta_inplace'
                dtypes=complex_types_and(torch.bool),  # 支持复杂类型和布尔类型的数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期的测试失败
                "TestMeta",  # 测试类为'TestMeta'
                "test_dispatch_meta_outplace",  # 测试方法为'test_dispatch_meta_outplace'
                dtypes=complex_types_and(torch.bool),  # 支持复杂类型和布尔类型的数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期的测试失败
                "TestMeta",  # 测试类为'TestMeta'
                "test_dispatch_symbolic_meta_inplace",  # 测试方法为'test_dispatch_symbolic_meta_inplace'
                dtypes=complex_types_and(torch.bool),  # 支持复杂类型和布尔类型的数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期的测试失败
                "TestMeta",  # 测试类为'TestMeta'
                "test_dispatch_symbolic_meta_outplace",  # 测试方法为'test_dispatch_symbolic_meta_outplace'
                dtypes=complex_types_and(torch.bool),  # 支持复杂类型和布尔类型的数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期的测试失败
                "TestMeta",  # 测试类为'TestMeta'
                "test_meta_inplace",  # 测试方法为'test_meta_inplace'
                dtypes=complex_types_and(torch.bool),  # 支持复杂类型和布尔类型的数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期的测试失败
                "TestMeta",  # 测试类为'TestMeta'
                "test_meta_outplace",  # 测试方法为'test_meta_outplace'
                dtypes=complex_types_and(torch.bool),  # 支持复杂类型和布尔类型的数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期的测试失败
                "TestForeach",  # 测试类为'TestForeach'
                "test_parity",  # 测试方法为'test_parity'
                device_type="cuda",  # 在CUDA设备上测试
                dtypes=complex_types(),  # 支持复杂类型的数据类型
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),  # 当非不连续的情况下激活
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期的测试失败
                "TestForeach",  # 测试类为'TestForeach'
                "test_autodiff",  # 测试方法为'test_autodiff'
                device_type="cuda",  # 在CUDA设备上测试
                dtypes=(torch.complex128,),  # 支持复杂128位的数据类型
            ),
        ),  # 装饰器元组结束
    ),
    # 使用 ForeachFuncInfo 类创建一个函数信息对象 'frac'
    ForeachFuncInfo(
        'frac',
        # 定义 sample_inputs_func 参数为一个生成输入样本函数的调用结果
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        # 支持自动求导
        supports_autograd=True,
        # 支持原地自动求导
        supports_inplace_autograd=True,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 设置装饰器信息元组，包括多个 DecorateInfo 对象
        decorators=(
            # 第一个装饰器，使用 unittest.expectedFailure 装饰，用于测试 'TestMeta' 中的 'test_dispatch_meta_inplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                dtypes=integral_types_and(torch.bool) + complex_types(),
            ),
            # 第二个装饰器，使用 unittest.expectedFailure 装饰，用于测试 'TestMeta' 中的 'test_dispatch_meta_outplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_outplace",
                dtypes=integral_types_and(torch.bool) + complex_types(),
            ),
            # 第三个装饰器，使用 unittest.expectedFailure 装饰，用于测试 'TestMeta' 中的 'test_dispatch_symbolic_meta_inplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool) + complex_types(),
            ),
            # 第四个装饰器，使用 unittest.expectedFailure 装饰，用于测试 'TestMeta' 中的 'test_dispatch_symbolic_meta_outplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_outplace",
                dtypes=integral_types_and(torch.bool) + complex_types(),
            ),
            # 第五个装饰器，使用 unittest.expectedFailure 装饰，用于测试 'TestMeta' 中的 'test_meta_inplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool) + complex_types(),
            ),
            # 第六个装饰器，使用 unittest.expectedFailure 装饰，用于测试 'TestMeta' 中的 'test_meta_outplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_outplace",
                dtypes=integral_types_and(torch.bool) + complex_types(),
            ),
            # 第七个装饰器，使用 unittest.expectedFailure 装饰，用于测试 'TestForeach' 中的 'test_parity'，设备类型为 'cuda'
            DecorateInfo(
                unittest.expectedFailure,
                "TestForeach",
                "test_parity",
                device_type="cuda",
                dtypes=complex_types(),
                # 根据参数 kwargs 的 'noncontiguous' 值决定装饰器是否激活
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),
            ),
            # 第八个装饰器，使用 unittest.expectedFailure 装饰，用于测试 'TestForeach' 中的 'test_autodiff'，设备类型为 'cuda'，数据类型为 torch.complex128
            DecorateInfo(
                unittest.expectedFailure,
                "TestForeach",
                "test_autodiff",
                device_type="cuda",
                dtypes=(torch.complex128,),
            ),
        ),
    ),
    ForeachFuncInfo(
        'reciprocal',  # 调用的函数名称为'reciprocal'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 使用给定的函数生成样本输入
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地自动求导
        supports_forward_ad=True,  # 支持前向自动微分
        backward_requires_result=True,  # 后向传播需要结果
        decorators=(  # 装饰器列表开始
            DecorateInfo(
                unittest.expectedFailure,  # 使用unittest.expectedFailure装饰器
                "TestMeta",  # 测试类名称为'TestMeta'
                "test_dispatch_meta_inplace",  # 测试方法名称为'test_dispatch_meta_inplace'
                dtypes=integral_types_and(torch.bool),  # 测试的数据类型为整数类型和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用unittest.expectedFailure装饰器
                "TestMeta",  # 测试类名称为'TestMeta'
                "test_dispatch_symbolic_meta_inplace",  # 测试方法名称为'test_dispatch_symbolic_meta_inplace'
                dtypes=integral_types_and(torch.bool),  # 测试的数据类型为整数类型和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用unittest.expectedFailure装饰器
                "TestMeta",  # 测试类名称为'TestMeta'
                "test_meta_inplace",  # 测试方法名称为'test_meta_inplace'
                dtypes=integral_types_and(torch.bool),  # 测试的数据类型为整数类型和布尔类型
            ),
        ),  # 装饰器列表结束
    ),
    ForeachFuncInfo(
        'sigmoid',  # 设置函数名为 'sigmoid'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 使用给定参数调用 foreach_inputs_sample_func 函数，获取样本输入函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地操作的自动求导
        supports_forward_ad=True,  # 支持前向自动微分
        backward_requires_result=True,  # 后向传播需要结果
        decorators=(  # 装饰器元组开始
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类为 "TestMeta"
                "test_dispatch_meta_inplace",  # 测试方法为 "test_dispatch_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 数据类型包括整数类型和 torch.bool 类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类为 "TestMeta"
                "test_dispatch_meta_inplace",  # 测试方法为 "test_dispatch_meta_inplace"
                device_type="cuda",  # 在 CUDA 设备上运行
                dtypes=complex_types(),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类为 "TestMeta"
                "test_dispatch_meta_outplace",  # 测试方法为 "test_dispatch_meta_outplace"
                device_type="cuda",  # 在 CUDA 设备上运行
                dtypes=complex_types(),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 测试方法为 "test_dispatch_symbolic_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 数据类型包括整数类型和 torch.bool 类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 测试方法为 "test_dispatch_symbolic_meta_inplace"
                device_type="cuda",  # 在 CUDA 设备上运行
                dtypes=complex_types(),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类为 "TestMeta"
                "test_dispatch_symbolic_meta_outplace",  # 测试方法为 "test_dispatch_symbolic_meta_outplace"
                device_type="cuda",  # 在 CUDA 设备上运行
                dtypes=complex_types(),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类为 "TestMeta"
                "test_meta_inplace",  # 测试方法为 "test_meta_inplace"
                dtypes=integral_types_and(torch.bool),  # 数据类型包括整数类型和 torch.bool 类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类为 "TestMeta"
                "test_meta_inplace",  # 测试方法为 "test_meta_inplace"
                device_type="cuda",  # 在 CUDA 设备上运行
                dtypes=complex_types(),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestMeta",  # 测试类为 "TestMeta"
                "test_meta_outplace",  # 测试方法为 "test_meta_outplace"
                device_type="cuda",  # 在 CUDA 设备上运行
                dtypes=complex_types(),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestForeach",  # 测试类为 "TestForeach"
                "test_parity",  # 测试方法为 "test_parity"
                device_type="cuda",  # 在 CUDA 设备上运行
                dtypes=complex_types(),  # 数据类型为复数类型
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),  # 如果关键字参数中没有 "noncontiguous" 或其值为 False，则激活
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器
                "TestForeach",  # 测试类为 "TestForeach"
                "test_autodiff",  # 测试方法为 "test_autodiff"
                device_type="cuda",  # 在 CUDA 设备上运行
                dtypes=(torch.complex128,),  # 数据类型为 torch.complex128
            ),
        ),  # 装饰器元组结束
    ),
    # 调用 ForeachFuncInfo 函数，配置 'trunc' 操作的参数和装饰器
    ForeachFuncInfo(
        'trunc',
        # 设置样本输入生成函数及其参数
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        # 支持自动微分
        supports_autograd=True,
        # 支持原地自动微分
        supports_inplace_autograd=True,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 设置装饰器列表，用于对特定测试函数进行装饰
        decorators=(
            # 装饰器：期望测试失败，应用于 "TestMeta" 类的 "test_dispatch_meta_inplace" 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                # 指定数据类型为复数及布尔型
                dtypes=complex_types_and(torch.bool),
            ),
            # 装饰器：期望测试失败，应用于 "TestMeta" 类的 "test_dispatch_meta_outplace" 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_outplace",
                # 指定数据类型为复数及布尔型
                dtypes=complex_types_and(torch.bool),
            ),
            # 装饰器：期望测试失败，应用于 "TestMeta" 类的 "test_dispatch_symbolic_meta_inplace" 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                # 指定数据类型为复数及布尔型
                dtypes=complex_types_and(torch.bool),
            ),
            # 装饰器：期望测试失败，应用于 "TestMeta" 类的 "test_dispatch_symbolic_meta_outplace" 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_outplace",
                # 指定数据类型为复数及布尔型
                dtypes=complex_types_and(torch.bool),
            ),
            # 装饰器：期望测试失败，应用于 "TestMeta" 类的 "test_meta_inplace" 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                # 指定数据类型为复数及布尔型
                dtypes=complex_types_and(torch.bool),
            ),
            # 装饰器：期望测试失败，应用于 "TestMeta" 类的 "test_meta_outplace" 函数
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_outplace",
                # 指定数据类型为复数及布尔型
                dtypes=complex_types_and(torch.bool),
            ),
            # 装饰器：期望测试失败，应用于 "TestForeach" 类的 "test_parity" 函数
            # 设置设备类型为 "cuda"，数据类型为复数，不包含非连续张量的条件激活
            DecorateInfo(
                unittest.expectedFailure,
                "TestForeach",
                "test_parity",
                device_type="cuda",
                dtypes=complex_types(),
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),
            ),
            # 装饰器：期望测试失败，应用于 "TestForeach" 类的 "test_autodiff" 函数
            # 设置设备类型为 "cuda"，数据类型为 torch.complex128
            DecorateInfo(
                unittest.expectedFailure,
                "TestForeach",
                "test_autodiff",
                device_type="cuda",
                dtypes=(torch.complex128,),
            ),
        ),
    ),
    # 使用 ForeachFuncInfo 对象创建一个函数信息对象，函数名为 'abs'
    ForeachFuncInfo(
        'abs',
        # 使用 foreach_inputs_sample_func 函数生成输入样本函数，并设置参数
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        # 支持自动求导
        supports_autograd=True,
        # 支持原地操作的自动求导
        supports_inplace_autograd=True,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 支持前向梯度和反向梯度
        supports_fwgrad_bwgrad=True,
        # 添加装饰器信息
        decorators=(
            # 使用 unittest.expectedFailure 装饰器，用于测试 'test_dispatch_symbolic_meta_inplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                # 指定复杂类型的数据类型
                dtypes=complex_types(),
            ),
            # 使用 unittest.expectedFailure 装饰器，用于测试 'test_dispatch_meta_inplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                # 指定复杂类型的数据类型
                dtypes=complex_types(),
            ),
            # 使用 unittest.expectedFailure 装饰器，用于测试 'test_dispatch_meta_outplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_outplace",
                # 指定 CPU 设备类型和 torch.bool 数据类型
                device_type="cpu",
                dtypes=(torch.bool,),
            ),
            # 使用 unittest.expectedFailure 装饰器，用于测试 'test_dispatch_symbolic_meta_inplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                # 指定 CPU 设备类型和 torch.bool 数据类型
                device_type="cpu",
                dtypes=(torch.bool,),
            ),
            # 使用 unittest.expectedFailure 装饰器，用于测试 'test_dispatch_symbolic_meta_outplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_outplace",
                # 指定 CPU 设备类型和 torch.bool 数据类型
                device_type="cpu",
                dtypes=(torch.bool,),
            ),
            # 使用 unittest.expectedFailure 装饰器，用于测试 'test_meta_inplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                # 指定 CPU 设备类型和 torch.bool 数据类型
                device_type="cpu",
                dtypes=(torch.bool,),
            ),
            # 使用 unittest.expectedFailure 装饰器，用于测试 'test_meta_outplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_outplace",
                # 指定 CPU 设备类型和 torch.bool 数据类型
                device_type="cpu",
                dtypes=(torch.bool,),
            ),
            # 使用 unittest.expectedFailure 装饰器，用于测试 'test_dispatch_meta_inplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_inplace",
                # 指定 CPU 设备类型和 torch.bool 数据类型
                device_type="cpu",
                dtypes=(torch.bool,),
            ),
            # 使用 unittest.expectedFailure 装饰器，用于测试 'test_meta_inplace'
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                # 指定复杂类型的数据类型
                dtypes=complex_types(),
            ),
        ),
    ),
    # 使用 ForeachFuncInfo 对象创建一个函数信息对象，函数名为 'zero'
    ForeachFuncInfo(
        'zero',
        # 使用 foreach_inputs_sample_func 函数生成输入样本函数，并设置参数
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),
        # 支持自动求导
        supports_autograd=True,
        # 支持原地操作的自动求导
        supports_inplace_autograd=True,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 不支持输出
        supports_out=False,
    ),
    ForeachFuncInfo(
        'sign',  # 指定要执行的函数名为 'sign'
        sample_inputs_func=foreach_inputs_sample_func(1, False, False),  # 提供一个生成样本输入的函数，生成1个样本
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地自动求导
        supports_forward_ad=True,  # 支持前向自动微分
        decorators=(  # 函数装饰器列表开始
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 所属测试类名为 "TestMeta"
                "test_dispatch_meta_inplace",  # 要装饰的测试方法名为 "test_dispatch_meta_inplace"
                dtypes=complex_types(),  # 指定测试的数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 所属测试类名为 "TestMeta"
                "test_dispatch_meta_outplace",  # 要装饰的测试方法名为 "test_dispatch_meta_outplace"
                dtypes=complex_types(),  # 指定测试的数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 所属测试类名为 "TestMeta"
                "test_dispatch_symbolic_meta_inplace",  # 要装饰的测试方法名为 "test_dispatch_symbolic_meta_inplace"
                dtypes=complex_types(),  # 指定测试的数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 所属测试类名为 "TestMeta"
                "test_dispatch_symbolic_meta_outplace",  # 要装饰的测试方法名为 "test_dispatch_symbolic_meta_outplace"
                dtypes=complex_types(),  # 指定测试的数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 所属测试类名为 "TestMeta"
                "test_meta_inplace",  # 要装饰的测试方法名为 "test_meta_inplace"
                dtypes=complex_types(),  # 指定测试的数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 所属测试类名为 "TestMeta"
                "test_meta_outplace",  # 要装饰的测试方法名为 "test_meta_outplace"
                dtypes=complex_types(),  # 指定测试的数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestForeach",  # 所属测试类名为 "TestForeach"
                "test_parity",  # 要装饰的测试方法名为 "test_parity"
                device_type="cuda",  # 指定设备类型为 "cuda"
                dtypes=complex_types(),  # 指定测试的数据类型为复数类型
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),  # 仅在非不连续参数情况下激活
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestForeach",  # 所属测试类名为 "TestForeach"
                "test_autodiff",  # 要装饰的测试方法名为 "test_autodiff"
                device_type="cuda",  # 指定设备类型为 "cuda"
                dtypes=(torch.complex128,),  # 指定测试的数据类型为 torch 的复数128位类型
            ),
        ),  # 函数装饰器列表结束
    ),
# 定义一个列表，存储用于二进制操作数据库的操作信息对象
foreach_binary_op_db: List[OpInfo] = [
    # 定义一个用于 "add" 操作的函数信息对象
    ForeachFuncInfo(
        "add",
        # 获取用于 foreach_inputs_sample_func 的样本输入函数，生成2个参数的示例，支持alpha参数，支持自动微分和原地自动微分，支持前向自动微分
        sample_inputs_func=foreach_inputs_sample_func(2, True, True, True),
        supports_alpha_param=True,
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            # 标记以下测试预期失败：aten._local_scalar_dense 尚未实现
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace"),
            # 样本具有复杂类型，且仅在dtype为复数时才支持原地操作
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
        ),
    ),
    # 定义一个用于 "sub" 操作的函数信息对象
    ForeachFuncInfo(
        "sub",
        # 获取用于 foreach_inputs_sample_func 的样本输入函数，生成2个参数的示例，支持alpha参数，支持自动微分和原地自动微分，支持前向自动微分
        sample_inputs_func=foreach_inputs_sample_func(2, True, True),
        supports_alpha_param=True,
        supports_autograd=True,
        supports_inplace_autograd=True,
        supports_forward_ad=True,
        decorators=(
            # 标记以下测试预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides"),
        ),
    ),
    ForeachFuncInfo(
        "mul",
        sample_inputs_func=foreach_inputs_sample_func(2, True, True, True),  # 设置样本输入函数为一个返回包含多个参数的函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地自动求导
        supports_forward_ad=True,  # 支持前向自动求导
        decorators=(  # 装饰器列表开始
            # 以下装饰器用于标记某些测试在特定条件下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 测试在指定数据类型下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 测试在指定数据类型下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 测试在指定数据类型下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 测试在指定数据类型下预期失败
        ),  # 装饰器列表结束
    ),  # ForeachFuncInfo对象1结束

    ForeachFuncInfo(
        "div",
        sample_inputs_func=foreach_inputs_sample_func(2, True, True, True),  # 设置样本输入函数为一个返回包含多个参数的函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地自动求导
        supports_forward_ad=True,  # 支持前向自动求导
        decorators=(  # 装饰器列表开始
            # 以下装饰器用于标记某些测试在特定条件下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 测试在指定数据类型下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 测试在指定数据类型下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 测试在指定数据类型下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 测试在指定数据类型下预期失败
            # 以下装饰器用于标记某些测试在特定条件下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace",
                         dtypes=(torch.float16,), device_type='cpu'),  # 测试在指定数据类型和设备类型下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace",
                         dtypes=(torch.float16,), device_type='cpu'),  # 测试在指定数据类型和设备类型下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace",
                         dtypes=(torch.float16,), device_type='cpu'),  # 测试在指定数据类型和设备类型下预期失败
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides",
                         dtypes=(torch.float16,), device_type='cpu'),  # 测试在指定数据类型和设备类型下预期失败
        ),  # 装饰器列表结束
    ),  # ForeachFuncInfo对象2结束
    ForeachFuncInfo(
        "clamp_min",  # 调用 ForeachFuncInfo 构造函数，指定函数名为 "clamp_min"
        sample_inputs_func=foreach_inputs_sample_func(2, True, True),  # 设置 sample_inputs_func 参数为返回特定样本输入的函数
        supports_autograd=True,  # 支持自动微分
        supports_inplace_autograd=True,  # 支持原地自动微分
        supports_forward_ad=True,  # 支持前向自动微分
        decorators=(  # 设置装饰器的元组，用于指定多个装饰器
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace"),  # 添加预期失败的装饰器，针对特定测试类和测试方法
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace"),  # 同上，不过测试方法不同
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace"),  # 同上，不过测试方法不同
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace"),  # 同上，不过测试方法不同
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace"),  # 同上，不过测试方法不同
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace"),  # 同上，不过测试方法不同
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides"),  # 同上，不过测试方法不同
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides"),  # 同上，不过测试方法不同
            DecorateInfo(
                unittest.expectedFailure,  # 添加预期失败的装饰器
                "TestForeach",  # 测试类名
                "test_parity",  # 测试方法名
                device_type="cuda",  # 指定设备类型为 CUDA
                dtypes=complex_types(),  # 设置数据类型为复数类型
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),  # 设置 active_if 函数，根据参数条件激活
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 添加预期失败的装饰器
                "TestForeach",  # 测试类名
                "test_autodiff",  # 测试方法名
                device_type="cuda",  # 指定设备类型为 CUDA
                dtypes=(torch.complex128,),  # 设置数据类型为 torch.complex128
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 添加预期失败的装饰器
                "TestForeach",  # 测试类名
                "test_binary_op_scalar_with_overlapping_tensors",  # 测试方法名
                dtypes=complex_types(),  # 设置数据类型为复数类型
            ),
        ),
    ),
    # 对 ForeachFuncInfo 函数调用，传递如下参数：
    # - "clamp_max"：函数名
    # - sample_inputs_func：调用 foreach_inputs_sample_func(2, True, True) 返回的样本输入函数
    # - supports_autograd=True：支持自动求导
    # - supports_inplace_autograd=True：支持原地操作的自动求导
    # - supports_forward_ad=True：支持前向自动微分

    # 使用 decorators 元组装饰 ForeachFuncInfo 的调用：
    # - DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace")
    #   等效于 @unittest.expectedFailure 装饰器，用于测试预期的失败情况
    # - DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace")
    #   等效于 @unittest.expectedFailure 装饰器，用于测试预期的失败情况
    # - ... （依次类推，以下注释略去重复）

    # DecorateInfo 的参数说明：
    # - unittest.expectedFailure：表示预期的失败情况
    # - "TestMeta" 或 "TestForeach"：测试类名，指定装饰器应用的测试类
    # - "test_dispatch_meta_inplace" 等：具体的测试方法名
    # - device_type="cuda"：指定 CUDA 设备类型
    # - dtypes=complex_types() 或 (torch.complex128,)：指定数据类型为复数类型
    # - active_if=lambda kwargs: not kwargs.get("noncontiguous", False)：条件函数，根据 kwargs 决定是否激活装饰器
    # 调用 ForeachFuncInfo 函数，传入参数 "minimum" 作为功能名称
    ForeachFuncInfo(
        "minimum",
        # 使用 foreach_inputs_sample_func 函数生成样本输入函数，并传入特定参数
        sample_inputs_func=foreach_inputs_sample_func(2, True, True),
        # 支持自动求导
        supports_autograd=True,
        # 不支持原地自动求导
        supports_inplace_autograd=False,
        # 不支持前向自动微分
        supports_forward_ad=False,
        # 装饰器列表，包含多个 DecorateInfo 对象，用于装饰测试用例
        decorators=(
            # 以下装饰器用于标记预期的测试失败，并指定测试类和方法名称
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides"),
            # 以下装饰器针对 CUDA 设备执行，传入复杂类型的数据
            DecorateInfo(
                unittest.expectedFailure,
                "TestForeach",
                "test_parity",
                device_type="cuda",
                dtypes=complex_types(),
                # 使用 active_if 参数定义一个 lambda 函数，根据 kwargs 判断是否非连续
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),
            ),
            # 以下装饰器也针对 CUDA 设备执行，传入 torch.complex128 类型的数据
            DecorateInfo(
                unittest.expectedFailure,
                "TestForeach",
                "test_autodiff",
                device_type="cuda",
                dtypes=(torch.complex128,),
            ),
            # 以下装饰器不指定设备类型，但传入复杂类型的数据
            DecorateInfo(
                unittest.expectedFailure,
                "TestForeach",
                "test_binary_op_scalar_with_overlapping_tensors",
                dtypes=complex_types(),
            ),
        ),
    ),
    # note(crcrpar): forward ad not implemented.
    # 注释：未实现前向自动微分功能。
    ForeachFuncInfo(
        "maximum",  # 调用 ForeachFuncInfo 构造函数，指定函数名称为 "maximum"
        sample_inputs_func=foreach_inputs_sample_func(2, True, True),  # 设置 sample_inputs_func 参数为 foreach_inputs_sample_func(2, True, True) 的返回值，用于生成样本输入
        supports_autograd=True,  # 设置 supports_autograd 参数为 True，表示支持自动求导
        supports_forward_ad=False,  # 设置 supports_forward_ad 参数为 False，表示不支持前向自动求导
        supports_inplace_autograd=False,  # 设置 supports_inplace_autograd 参数为 False，表示不支持原地自动求导
        decorators=(  # 设置 decorators 参数为一个元组，包含多个 DecorateInfo 对象作为装饰器信息
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace"),  # 添加一个装饰器信息，标记预期的单元测试失败，针对 "TestMeta" 类的 "test_dispatch_meta_inplace" 方法
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace"),  # 添加一个装饰器信息，标记预期的单元测试失败，针对 "TestMeta" 类的 "test_dispatch_symbolic_meta_inplace" 方法
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace"),  # 添加一个装饰器信息，标记预期的单元测试失败，针对 "TestMeta" 类的 "test_meta_inplace" 方法
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace"),  # 添加一个装饰器信息，标记预期的单元测试失败，针对 "TestMeta" 类的 "test_dispatch_meta_outplace" 方法
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace"),  # 添加一个装饰器信息，标记预期的单元测试失败，针对 "TestMeta" 类的 "test_dispatch_symbolic_meta_outplace" 方法
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace"),  # 添加一个装饰器信息，标记预期的单元测试失败，针对 "TestMeta" 类的 "test_meta_outplace" 方法
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides"),  # 添加一个装饰器信息，标记预期的单元测试失败，针对 "TestMeta" 类的 "test_dispatch_symbolic_meta_inplace_all_strides" 方法
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides"),  # 添加一个装饰器信息，标记预期的单元测试失败，针对 "TestMeta" 类的 "test_dispatch_symbolic_meta_outplace_all_strides" 方法
            DecorateInfo(
                unittest.expectedFailure,  # 标记预期的单元测试失败
                "TestForeach",  # 指定测试类为 "TestForeach"
                "test_parity",  # 指定测试方法为 "test_parity"
                device_type="cuda",  # 设置 device_type 参数为 "cuda"
                dtypes=complex_types(),  # 设置 dtypes 参数为 complex_types() 的返回值，表示复数类型数据类型
                active_if=lambda kwargs: not kwargs.get("noncontiguous", False),  # 设置 active_if 参数为一个 lambda 函数，根据 kwargs 中的 "noncontiguous" 参数决定是否激活测试
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记预期的单元测试失败
                "TestForeach",  # 指定测试类为 "TestForeach"
                "test_autodiff",  # 指定测试方法为 "test_autodiff"
                device_type="cuda",  # 设置 device_type 参数为 "cuda"
                dtypes=(torch.complex128,),  # 设置 dtypes 参数为一个包含 torch.complex128 类型的元组，表示复数类型数据类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记预期的单元测试失败
                "TestForeach",  # 指定测试类为 "TestForeach"
                "test_binary_op_scalar_with_overlapping_tensors",  # 指定测试方法为 "test_binary_op_scalar_with_overlapping_tensors"
                dtypes=complex_types(),  # 设置 dtypes 参数为 complex_types() 的返回值，表示复数类型数据类型
            ),
        ),
    ),
    ForeachFuncInfo(
        "pow",  # 调用的函数名称为 "pow"
        supports_alpha_param=False,  # 不支持 alpha 参数
        supports_scalar_self_arg=True,  # 支持标量作为自身参数
        sample_inputs_func=foreach_inputs_sample_func(2, True, True),  # 设置样本输入函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地操作的自动求导
        supports_forward_ad=True,  # 支持前向自动微分

        decorators=(  # 装饰器元组开始
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace",  # 预期测试失败装饰器，用于测试分发元数据的原地操作
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace",  # 预期测试失败装饰器，用于测试分发符号化元数据的原地操作
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace",  # 预期测试失败装饰器，用于测试元数据的原地操作
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides",  # 预期测试失败装饰器，用于测试分发符号化元数据的原地操作（所有步长）
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace",  # 预期测试失败装饰器，用于测试元数据的非原地操作
                         dtypes=(torch.bool,)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace",  # 预期测试失败装饰器，用于测试分发元数据的非原地操作
                         dtypes=(torch.bool,)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace",  # 预期测试失败装饰器，用于测试分发符号化元数据的非原地操作
                         dtypes=(torch.bool,)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides",  # 预期测试失败装饰器，用于测试分发符号化元数据的非原地操作（所有步长）
                         dtypes=(torch.bool,)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace",  # 预期测试失败装饰器，用于测试元数据的非原地操作
                         dtypes=(torch.half,), device_type="cpu"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace",  # 预期测试失败装饰器，用于测试分发元数据的非原地操作
                         dtypes=(torch.half,), device_type="cpu"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace",  # 预期测试失败装饰器，用于测试分发符号化元数据的非原地操作
                         dtypes=(torch.half,), device_type="cpu"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides",  # 预期测试失败装饰器，用于测试分发符号化元数据的非原地操作（所有步长）
                         dtypes=(torch.half,), device_type="cpu"),
            DecorateInfo(unittest.skip("flaky"), "TestForeach", "test_parity", device_type="cpu", dtypes=(torch.complex64,)),  # 跳过装饰器，用于测试复杂64位类型的平行性
            DecorateInfo(
                unittest.expectedFailure,  # 预期测试失败装饰器
                "TestForeach",  # 测试类名称为 "TestForeach"
                "test_binary_op_with_scalar_self_support",  # 测试函数名称为 "test_binary_op_with_scalar_self_support"
                device_type="cuda",  # 设备类型为 CUDA
                dtypes=(torch.bool,),  # 数据类型为布尔型
                active_if=lambda kwargs: kwargs["is_fastpath"],  # 如果条件为快速路径
            ),
        ),  # 装饰器元组结束
        backward_requires_result=True,  # 后向传播需要结果
    ),
    # 使用 ForeachFuncInfo 函数创建一个名为 "copy" 的函数信息对象，
    # 提供了关于该函数的各种支持信息和样本输入函数的配置参数。
    ForeachFuncInfo(
        "copy",
        sample_inputs_func=foreach_inputs_sample_func(2, False, False),
        supports_out=False,
        supports_forward_ad=False,
        supports_autograd=False,
        supports_inplace_autograd=False,
    )
# 创建一个空的列表，用于存储 ForeachFuncInfo 对象
foreach_pointwise_op_db: List[ForeachFuncInfo] = [
    # 创建一个 ForeachFuncInfo 对象，描述操作为 "addcmul"
    ForeachFuncInfo(
        "addcmul",
        # 设置 sample_inputs_func 属性为特定函数返回的结果
        sample_inputs_func=foreach_pointwise_sample_func(4, True, True),
        # 支持自动求导
        supports_autograd=True,
        # 支持原地操作的自动求导
        supports_inplace_autograd=True,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 设置修饰器，用于标记预期的测试失败
        decorators=(
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace",
                         # 传入包含所有数据类型以及 torch.bool, torch.bfloat16, torch.float16 的数据类型集合
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            # 样本具有复杂的类型，仅当数据类型为复数时才支持原地操作
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),
        ),
    ),
    ForeachFuncInfo(
        "addcdiv",
        sample_inputs_func=foreach_pointwise_sample_func(4, True, True),  # 使用给定参数生成样本输入函数
        supports_autograd=True,  # 支持自动微分
        supports_inplace_autograd=True,  # 支持原地操作的自动微分
        supports_forward_ad=True,  # 支持前向自动微分

        decorators=(
            # 以下是各个装饰器，用于标记预期的单元测试失败情况，测试方法位于 TestMeta 类中
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 针对指定类型的数据类型进行测试
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 针对指定类型的数据类型进行测试
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 针对指定类型的数据类型进行测试
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_inplace_all_strides",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 针对指定类型的数据类型进行测试
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 针对指定类型的数据类型进行测试
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 针对指定类型的数据类型进行测试
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 针对指定类型的数据类型进行测试
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides",
                         dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16)),  # 针对指定类型的数据类型进行测试
        ),
    ),
# 定义一个名为 foreach_reduce_op_db 的列表，存储 ForeachFuncInfo 对象
foreach_reduce_op_db: List[ForeachFuncInfo] = [
    # 第一个 ForeachFuncInfo 对象，表示 max 函数相关信息
    ForeachFuncInfo(
        "max",  # 函数名称为 max
        sample_inputs_func=foreach_max_sample_func(1, False, False),  # 获取 max 函数的示例输入函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地自动求导
        supports_forward_ad=True,  # 支持前向自动微分
        decorators=(  # 装饰器列表，用于标记预期的测试失败情况
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestForeach",  # 测试类为 TestForeach
                "test_autodiff",  # 测试方法为 test_autodiff
                dtypes=(torch.complex128, torch.complex64),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestForeach",  # 测试类为 TestForeach
                "test_foreach_reduce_large_input",  # 测试方法为 test_foreach_reduce_large_input
                dtypes=(torch.complex128, torch.complex64),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_dispatch_symbolic_meta_outplace",  # 测试方法为 test_dispatch_symbolic_meta_outplace
                dtypes=(torch.complex128, torch.complex64),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_meta_outplace",  # 测试方法为 test_meta_outplace
                dtypes=(torch.complex128, torch.complex64),  # 数据类型为复数类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_dispatch_meta_outplace",  # 测试方法为 test_dispatch_meta_outplace
                dtypes=(torch.complex128, torch.complex64),  # 数据类型为复数类型
            ),
        ),
    ),
    # 第二个 ForeachFuncInfo 对象，表示 norm 函数相关信息
    ForeachFuncInfo(
        "norm",  # 函数名称为 norm
        sample_inputs_func=foreach_norm_sample_func(1, False, False),  # 获取 norm 函数的示例输入函数
        supports_autograd=True,  # 支持自动求导
        supports_inplace_autograd=True,  # 支持原地自动求导
        supports_forward_ad=True,  # 支持前向自动微分
        decorators=(  # 装饰器列表，用于标记预期的测试失败情况
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_dispatch_meta_inplace",  # 测试方法为 test_dispatch_meta_inplace
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_dispatch_meta_outplace",  # 测试方法为 test_dispatch_meta_outplace
                dtypes=integral_types_and(torch.bool),  # 数据类型为整数和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_dispatch_symbolic_meta_inplace",  # 测试方法为 test_dispatch_symbolic_meta_inplace
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_dispatch_symbolic_meta_outplace",  # 测试方法为 test_dispatch_symbolic_meta_outplace
                dtypes=integral_types_and(torch.bool),  # 数据类型为整数和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_meta_inplace",  # 测试方法为 test_meta_inplace
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_meta_outplace",  # 测试方法为 test_meta_outplace
                dtypes=integral_types_and(torch.bool),  # 数据类型为整数和布尔类型
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestMeta",  # 测试类为 TestMeta
                "test_dispatch_symbolic_meta_inplace_all_strides",  # 测试方法为 test_dispatch_symbolic_meta_inplace_all_strides
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest 的 expectedFailure 装饰器
                "TestForeach",  # 测试类为 TestForeach
                "test_foreach_reduce_large_input",  # 测试方法为 test_foreach_reduce_large_input
                device_type="cuda",  # 设备类型为 CUDA
                dtypes=integral_types_and(torch.bool),  # 数据类型为整数和布尔类型
            ),
        ),
    ),
]
# 创建一个列表 `foreach_other_op_db`，包含多个 `ForeachFuncInfo` 对象
foreach_other_op_db: List[ForeachFuncInfo] = [
    # 第一个 `ForeachFuncInfo` 对象，代表函数 "lerp"
    ForeachFuncInfo(
        "lerp",
        # 设置 `sample_inputs_func` 属性为特定的函数调用结果
        sample_inputs_func=foreach_lerp_sample_func(3, True, False),
        # 支持自动求导
        supports_autograd=True,
        # 支持原地自动求导
        supports_inplace_autograd=True,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 装饰器信息元组，包含多个 `DecorateInfo` 对象
        decorators=(
            DecorateInfo(
                unittest.expectedFailure,  # 装饰器函数 `unittest.expectedFailure`
                "TestMeta",  # 测试类名
                "test_dispatch_meta_inplace",  # 测试方法名
                dtypes=integral_types_and(torch.bool),  # 数据类型条件
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_meta_outplace",
                dtypes=integral_types_and(torch.bool),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_outplace",
                dtypes=integral_types_and(torch.bool),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_dispatch_symbolic_meta_inplace",
                dtypes=integral_types_and(torch.bool),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_inplace",
                dtypes=integral_types_and(torch.bool),
            ),
            DecorateInfo(
                unittest.expectedFailure,
                "TestMeta",
                "test_meta_outplace",
                dtypes=integral_types_and(torch.bool),
            ),
        ),
    ),
]

# 定义函数 `reference_sign(x)`，用于计算输入 `x` 的符号
def reference_sign(x):
    if x.dtype == np.bool_:
        # 如果 `x` 的数据类型是布尔类型，返回报错信息
        # `np.sign` 不支持布尔类型。
        # >>> np.sign(True)
        # ufunc 'sign' did not contain a loop
        # with signature matching types dtype('bool') -> dtype('bool')
        return np.sign(x, dtype=np.uint8).astype(np.bool_)
    # 对于其他数据类型，使用 `np.sign` 函数计算符号并返回结果
    return np.sign(x)

# 定义函数 `reference_sgn(x)`，用于计算输入 `x` 的符号函数值
def reference_sgn(x):
    # 对于复数数据类型，NumPy 没有类似 `torch.sgn` 的等价函数
    if x.dtype not in [np.complex64, np.complex128]:
        return reference_sign(x)

    # 对于复数输入，计算其符号函数值
    out = (x / np.abs(x))
    if out.ndim == 0:
        # 处理 `x` 为标量的情况，当 `x == 0` 时
        if (x == 0):
            # 不能直接赋值给 `np.complex` 对象，需要创建一个新的对象
            return np.array(complex(0, 0), dtype=x.dtype)
        return out

    # 处理 `x` 为数组的情况，当 `x == 0` 时
    mask = (x == 0)
    out[mask] = complex(0, 0)
    return out

# 定义函数 `reference_sigmoid(x)`，计算输入 `x` 的 sigmoid 函数值
def reference_sigmoid(x):
    # 对于复数数据类型，'scipy.special.expit' 不支持
    if x.dtype in [np.complex64, np.complex128]:
        return (1 / (1 + np.exp(-x)))
    # 对于其他数据类型，使用 `scipy.special.expit` 函数计算 sigmoid 函数值
    return scipy.special.expit(x)

# 定义函数 `reference_logsigmoid(x)`，计算输入 `x` 的 log-sigmoid 函数值
def reference_logsigmoid(x):
    return np.where(
        x < 0,
        x - np.log1p(np.exp(x)),
        -np.log1p(np.exp(-x)))

# 定义函数 `reference_hardsigmoid(x)`，计算输入 `x` 的硬 sigmoid 函数值
def reference_hardsigmoid(x):
    intermediate = x / 6 + 0.5
    y = np.clip(intermediate, 0, None)
    return np.where(y > 1, 1, y).astype(x.dtype)

# 定义函数 `reference_lgamma(x)`，计算输入 `x` 的对数 gamma 函数值
    # scipy.special.gammaln 函数在输入为 `-inf` 时返回 `-inf`。
    # 而 Pytorch、C 和 C++ 在输入为 `-inf` 时返回 `inf`。
    # 参考资料：
    # https://en.cppreference.com/w/cpp/numeric/math/lgamma
    # https://en.cppreference.com/w/c/numeric/math/lgamma
    
    # 为了处理上述差异，
    # 我们将 `-inf` 替换为 `inf`，以使原本为 `-inf` 的值映射到期望的 `inf`。
    if x.dtype.kind == 'f':
        x = np.where(x == float('-inf'), np.array(float('inf'), dtype=x.dtype), x)
    
    # 调用 scipy.special.gammaln 计算输入张量 x 的伽玛对数
    out = scipy.special.gammaln(x)
    
    if x.dtype == np.float16:
        # 当输入为 float16 时，`scipy.special.gammaln` 返回 float32 的输出，
        # 而 `torch.lgamma` 保留为 `float16`。但由于 float16 的范围较小，
        # Pytorch 版本输出 `inf`，而 SciPy 返回有限值。
        # 因此在这种情况下，将输出转换为 `np.float16` 类型。
        out = out.astype(np.float16)
    
    # 返回计算结果
    return out
# 计算 x 的多维伽马函数对数，返回结果的数据类型为 np.float16
def reference_mvlgamma(x, d):
    if x.dtype == np.float16:
        return scipy.special.multigammaln(x, d).astype(np.float16)

    # 如果 x 的数据类型不是 np.float16，则直接计算多维伽马函数对数
    return scipy.special.multigammaln(x, d)


# 计算 softplus 函数的输出
# 对于 input 中每个元素，如果其乘以 beta 小于等于 threshold，则使用简化的 softplus 计算方式
def reference_softplus(input, beta=1, threshold=20):
    non_linear = input * beta <= threshold
    output = input.copy()
    output[non_linear] = np.log(1 + np.exp(beta * input[non_linear])) / beta
    return output


# 计算 GELU 激活函数的输出，可以选择是否使用 tanh 近似
def reference_gelu(X, *, approximate='none'):
    def _gelu_ref(X):
        return X * stats.norm.cdf(X)

    def _tanh_gelu_ref(X):
        M_SQRT_2_PI = math.sqrt(2 / math.pi)
        Z = M_SQRT_2_PI * (X + 0.044715 * np.power(X, 3.0))
        return 0.5 * X * (1.0 + np.tanh(Z))

    if approximate == 'tanh':
        return _tanh_gelu_ref(X)
    else:
        return _gelu_ref(X)


# 将输入数组 a 转换为 one-hot 编码的形式，返回一个二维数组
def reference_one_hot(a: np.ndarray, num_classes: int = -1) -> np.ndarray:
    if num_classes == -1:
        num_classes = int(np.amax(a) + 1)

    idcs = a.reshape(-1) + np.arange(0, a.size, dtype=np.int64) * num_classes
    one_hot = np.zeros((a.size, num_classes), dtype=a.dtype)
    np.put(one_hot, idcs, 1)
    return one_hot.reshape(*a.shape, -1)


# 计算输入和目标之间的均方误差损失
# reduction 参数控制如何计算损失的总和或平均值，或者保留未减少的每个损失值
def reference_mse_loss(input, target, reduction="mean"):
    se = (input - target) ** 2
    if reduction == "mean":
        return np.mean(se)
    elif reduction == "sum":
        return np.sum(se)
    else:  # reduction == "none"
        return se


# 对输入进行 layer normalization 处理，并返回处理后的结果
def reference_layer_norm(inp: np.ndarray, normalized_shape: Tuple[int], weight=None, bias=None, eps=1e-5):
    return reference_native_layer_norm(inp, normalized_shape, weight, bias, eps)[0]


# 实现 layer normalization 的具体计算过程，返回规范化后的结果、均值和标准差的倒数
def reference_native_layer_norm(inp: np.ndarray, normalized_shape: Tuple[int], weight, bias, eps):
    feature_size = np.prod(normalized_shape)
    inp_view = inp.reshape(-1, feature_size)  # type: ignore[call-overload]
    mean = inp_view.mean(axis=-1, keepdims=True)
    var = inp_view.var(axis=-1, ddof=0, keepdims=True)
    Y = (inp_view - mean) / np.sqrt(var + eps)
    if weight is None and bias is not None:
        Y = Y + bias.reshape(-1)
    elif weight is not None and bias is None:
        Y = Y * weight.reshape(-1)
    elif weight is not None and bias is not None:
        Y = Y * weight.reshape(-1) + bias.reshape(-1)
    axis = inp.ndim - len(normalized_shape)
    stat_shape = inp.shape[:axis] + (1,) * len(normalized_shape)
    return Y.reshape(*inp.shape), mean.reshape(stat_shape), (1.0 / np.sqrt(var + eps)).reshape(stat_shape)


# 对输入进行 rms normalization 处理，并返回处理后的结果
def reference_rms_norm(inp: np.ndarray, normalized_shape: Tuple[int], weight=None, eps=None):
    if eps is None:
        eps = torch.finfo(numpy_to_torch_dtype(inp.dtype)).eps
    feature_size = np.prod(normalized_shape)
    inp_view = inp.reshape(-1, feature_size)  # type: ignore[call-overload]
    rms = np.sqrt((inp_view**2).mean(axis=-1, keepdims=True) + eps)
    Y = inp_view / rms
    if weight is not None:
        Y = Y * weight.reshape(-1)
    return Y.reshape(*inp.shape)
# 定义一个函数，对输入的 numpy 数组进行分组归一化操作，支持权重和偏置项
def reference_group_norm(inp: np.ndarray, num_groups: int, weight=None, bias=None, eps=1e-5):
    # 将输入数组视图赋值给 inp_view
    inp_view = inp
    # 如果输入数组的元素数量不为零，则重新整形为 (inp.shape[0], num_groups, -1) 的形状
    if np.prod(inp.shape) != 0:
        inp_view = inp.reshape((inp.shape[0], num_groups, -1))
    # 计算 inp_view 沿着最后一个轴的均值
    mean = inp_view.mean(axis=-1, keepdims=True)
    # 计算 inp_view 沿着最后一个轴的方差
    var = inp_view.var(axis=-1, ddof=0, keepdims=True)
    # 对 inp_view 进行归一化操作，Y = (inp_view - mean) / sqrt(var + eps)
    Y = (inp_view - mean) / np.sqrt(var + eps)
    # 将 Y 重新整形为原始输入的形状
    Y = Y.reshape(inp.shape)
    # 如果有权重 weight，则根据 Y 的维度扩展权重的维度并乘以 Y
    if weight is not None:
        if len(Y.shape) > 2:
            weight = np.expand_dims(weight, [0] + [idx + 2 for idx in range(inp.ndim - 2)])
        Y = Y * weight
    # 如果有偏置 bias，则根据 Y 的维度扩展偏置的维度并加到 Y 上
    if bias is not None:
        if len(Y.shape) > 2:
            bias = np.expand_dims(bias, [0] + [idx + 2 for idx in range(inp.ndim - 2)])
        Y = Y + bias
    # 返回归一化后的结果 Y
    return Y


# 定义一个自定义的搜索排序函数，处理 numpy 中 searchsorted 方法不支持多维数组的问题
# 支持选择搜索方向 'left' 或 'right'，并能选择输出整数类型 int32
def reference_searchsorted(sorted_sequence, boundary, out_int32=False, right=False, side='left', sorter=None):
    # 根据 right 和 side 参数设置搜索方向 side
    side = 'right' if (right or side == 'right') else 'left'
    # 如果 sorted_sequence 是一维数组
    if len(sorted_sequence.shape) == 1:
        # 直接调用 searchsorted 进行搜索，并根据 out_int32 决定返回类型
        ret = np.searchsorted(sorted_sequence, boundary, side=side, sorter=sorter)
        return ret.astype(np.int32) if out_int32 else ret
    # 如果 sorted_sequence 是空数组
    elif sorted_sequence.shape[0] == 0:
        # 将 sorter 展平处理后再调用 searchsorted 进行搜索
        if sorter is not None:
            sorter = sorter.flatten()
        ret = np.searchsorted(sorted_sequence.flatten(), boundary.flatten(), side=side, sorter=sorter)
        ret = ret.astype(np.int32) if out_int32 else ret
        # 将结果重新整形成 boundary 的形状并返回
        return ret.reshape(boundary.shape)
    else:
        # numpy 的 searchsorted 方法仅支持一维输入，因此需要对多维输入进行拆分处理
        orig_shape = boundary.shape
        num_splits = np.prod(sorted_sequence.shape[:-1])
        splits = range(0, num_splits)
        # 将 sorted_sequence 和 boundary 拆分为 num_splits 个子数组
        sorted_sequence, boundary = sorted_sequence.reshape(num_splits, -1), boundary.reshape(num_splits, -1)
        if sorter is not None:
            sorter = sorter.reshape(num_splits, -1)

        # 分别对每个子数组调用 searchsorted 方法进行搜索
        split_sequence = [sorted_sequence[i] for i in splits]
        split_boundary = [boundary[i] for i in splits]
        split_sorter = [sorter[i] if (sorter is not None) else None for i in splits]

        split_ret = [np.searchsorted(s_seq, b, side=side, sorter=s_sort)
                     for (s_seq, b, s_sort) in zip(split_sequence, split_boundary, split_sorter)]
        split_ret = [i.astype(np.int32) for i in split_ret] if out_int32 else split_ret
        # 将拆分后的结果堆叠并重新整形成原始形状并返回
        return np.stack(split_ret).reshape(orig_shape)
    # 定义一个装饰器函数，用于包装输入的函数 fn
    def wrapper(input, target, *, size_average=None, reduce=None, reduction="mean", **other_kwargs):
        # 如果 size_average 或 reduce 不为 None，则抛出运行时异常
        if size_average is not None or reduce is not None:
            raise RuntimeError(
                "The keyword arguments 'size_average' and 'reduce' are deprecated and not supported by this wrapper"
            )
        
        # 调用输入的函数 fn，并传入参数 input, target，以及其他关键字参数 other_kwargs
        output = fn(input, target, **other_kwargs)
        
        # 根据 reduction 参数的值进行不同的处理
        if reduction == "mean":
            # 如果 reduction 是 "mean"，则返回 output 的平均值
            return np.mean(output)
        elif reduction == "sum":
            # 如果 reduction 是 "sum"，则返回 output 的总和
            return np.sum(output)
        else:
            # 如果 reduction 是 "none"，则直接返回 output
            return output
    
    # 返回装饰器函数 wrapper，使其可以被应用于其他函数
    return wrapper
# 包装器函数，用于降低参考平滑 L1 损失
@loss_reference_reduction_wrapper
def reference_smooth_l1_loss(input, target, beta=1.0):
    # 计算输入与目标之间的差异
    diff = input - target
    # 计算差异的绝对值
    abs_diff = np.abs(diff)
    # 根据阈值 beta 判断哪些差异大于等于阈值
    above_threshold = abs_diff >= beta

    # 创建与输入相同形状的空数组用于存储损失值
    loss = np.empty_like(input)
    # 对于大于等于阈值的差异，计算平滑 L1 损失
    loss[above_threshold] = abs_diff[above_threshold] - 0.5 * beta
    # 对于小于阈值的差异，计算平方损失
    loss[~above_threshold] = diff[~above_threshold] ** 2 / (2 * beta)

    return loss

# 返回 NumPy 的无偏/修正 kwargs 对应的函数
def reference_std_var(f):
    """将无偏/修正参数转发为 NumPy 的等效 ddof 参数"""
    g = reference_reduction_numpy(f)

    @wraps(g)
    def wrapper(x: np.ndarray, *args, **kwargs):
        # 确保 kwargs 中不同时出现 'unbiased' 和 'correction'
        assert not ('unbiased' in kwargs and 'correction' in kwargs)

        # 如果 kwargs 中有 'unbiased'，将其转换为 'ddof'
        if 'unbiased' in kwargs:
            kwargs['ddof'] = int(kwargs.pop('unbiased'))
        elif 'correction' in kwargs:
            kwargs['ddof'] = kwargs.pop('correction')

        return g(x, *args, **kwargs)

    return wrapper

# 为 std/var 运算符生成无偏/修正参数的 kwargs
def generate_std_var_kwargs(t: torch.Tensor, **kwargs):
    """为 std/var 运算符生成无偏/修正参数的 kwargs"""
    yield ((), {'unbiased': True})   # 生成无偏参数为 True 的 kwargs
    yield ((), {'unbiased': False})  # 生成无偏参数为 False 的 kwargs

    # 当提供了 'dim' 和 'keepdim' 时，允许使用修正参数
    if 'dim' in kwargs and 'keepdim' in kwargs:
        yield ((), {'correction': 0})  # 生成修正参数为 0 的 kwargs
        yield ((), {'correction': 1})  # 生成修正参数为 1 的 kwargs

        # 计算维度相关的元素数量
        numel = torch.tensor(t.shape)[kwargs.get('dim')].prod()
        yield ((), {'correction': numel // 2})  # 生成修正参数为元素数量一半的 kwargs

# 生成关于错误输入均值的消息和样例
def error_inputs_mean(op_info, device, is_ref=False, **kwargs):
    # 如果是参考实现，生成对应的错误消息
    if is_ref:
        err_msg1 = (r"mean\(\): could not infer output dtype. "
                    r"Input dtype must be either a floating point or complex dtype. "
                    r"Got: torch.int64")
    else:
        err_msg1 = (r"mean\(\): could not infer output dtype. "
                    r"Input dtype must be either a floating point or complex dtype. "
                    r"Got: Long")
    # 生成一个 ErrorInput 对象，包含相关的错误消息和样例输入
    yield ErrorInput(
        SampleInput(make_tensor((3, 4, 5), dtype=torch.int64, device=device), []),
        error_regex=err_msg1,
    )

    # 如果是参考实现，生成对应的错误消息
    if is_ref:
        err_msg2 = (r"mean\(\): could not infer output dtype. "
                    r"Optional dtype must be either a floating point or complex dtype. "
                    r"Got: torch.int64")
    else:
        err_msg2 = (r"mean\(\): could not infer output dtype. "
                    r"Optional dtype must be either a floating point or complex dtype. "
                    r"Got: Long")
    # 生成一个 ErrorInput 对象，包含相关的错误消息和样例输入
    yield ErrorInput(
        SampleInput(
            make_tensor((3, 4, 5), dtype=torch.float32, device=device),
            [],
            dtype=torch.int64),
        error_regex=err_msg2
    )

    # 如果是参考实现，生成对应的错误消息
    if is_ref:
        err_msg3 = "Expected out tensor to have dtype torch.float64, but got torch.float32 instead"
    else:
        err_msg3 = "Expected out tensor to have dtype double, but got float instead"
    # 生成一个 ErrorInput 对象，包含相关的错误消息和样例输入
    yield ErrorInput(
        SampleInput(make_tensor((3, 4, 5), dtype=torch.float32, device=device), []),
        error_regex=err_msg3
    )
    # 生成器函数，用于生成 ErrorInput 对象
    yield ErrorInput(
        # 使用 SampleInput 构造一个样本输入对象
        SampleInput(
            # 调用 make_tensor 函数创建一个形状为 (3, 4, 5)，数据类型为 torch.int64 的张量，位于指定设备上
            make_tensor((3, 4, 5), dtype=torch.int64, device=device),
            # 空列表作为第二个参数，表示没有附加信息
            [],
            # 指定数据类型为 torch.float64
            dtype=torch.float64,
            # 调用 make_tensor 函数创建一个空张量，数据类型为 torch.float32，位于指定设备上
            out=make_tensor([], dtype=torch.float32, device=device),
        ),
        # 错误正则表达式，用于匹配错误消息
        error_regex=err_msg3
    )
# numpy implementation of torch.flatten
# unfortunately there's no np.flatten. we figure out the desired shape and call np.reshape
def reference_flatten(input, start_dim=0, end_dim=-1):
    # 获取输入张量的形状
    in_shape = input.shape
    # 获取输入张量的秩（即维度数）
    in_rank = len(in_shape)
    # 检查起始和结束维度是否在有效范围内
    for d in start_dim, end_dim:
        if not ((in_rank == 0 and d in (-1, 0)) or -in_rank <= d < in_rank):
            raise IndexError(f"Dimension out of range (expected to be in range of [{-in_rank}, {in_rank-1}], but got {d}")
    # 根据负索引调整结束维度的值
    end_dim = end_dim if end_dim >= 0 else in_rank + end_dim
    # 根据负索引调整起始维度的值
    start_dim = start_dim if start_dim >= 0 else in_rank + start_dim
    # 如果输入张量是标量（零维张量），起始和结束维度相等
    if in_rank == 0:
        end_dim = start_dim
    # 检查结束维度是否在起始维度之后，若不是则抛出错误
    if end_dim < start_dim:
        raise RuntimeError("flatten() has invalid args: start_dim cannot come after end_dim")
    # 计算展平后的张量的总元素数
    flatten_bit_dim = functools.reduce(operator.mul, in_shape[start_dim:end_dim + 1], 1)
    # 计算展平后的张量的形状
    out_shape = in_shape[:start_dim] + (flatten_bit_dim,) + in_shape[end_dim + 1:]
    # 使用 np.reshape 函数将输入张量展平为指定形状
    return np.reshape(input, out_shape)


def sample_inputs_alias_copy(op_info, device, dtype, requires_grad, **kwargs):
    # 生成一个带有指定属性的张量示例作为 SampleInput 对象
    yield SampleInput(make_tensor((S,), dtype=dtype, device=device, requires_grad=requires_grad))
    # 生成一个标量张量示例作为 SampleInput 对象
    yield SampleInput(make_tensor((), dtype=dtype, device=device, requires_grad=requires_grad))


# Operator database (sorted alphabetically)
op_db: List[OpInfo] = [
    # NOTE: CPU complex acos produces incorrect outputs (https://github.com/pytorch/pytorch/issues/42952)
    # NOTE: the derivative for inplace acosh is not implemented
    UnaryUfuncInfo('acosh',  # 创建一个 UnaryUfuncInfo 对象，处理 acosh 函数的信息
                   aliases=('arccosh', ),  # 别名为 arccosh
                   ref=np.arccosh,  # 参考实现使用 NumPy 的 arccosh 函数
                   domain=(1, None),  # 定义域为 x >= 1
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型，包括布尔型、半精度浮点和 bfloat16
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),  # CUDA 环境下支持的数据类型
                   decorators=(precisionOverride({torch.bfloat16: 5e-2}),),  # 修饰器，针对 bfloat16 类型设置精度修正
                   supports_inplace_autograd=False,  # 不支持原地自动求导
                   supports_forward_ad=True,  # 支持前向自动求导
                   supports_fwgrad_bwgrad=True,  # 支持前向-反向梯度传播
                   promotes_int_to_float=True,  # 支持整型自动提升为浮点型
                   skips=(  # 跳过以下测试用例的装饰信息
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_normal',
                                    device_type='cuda', dtypes=[torch.cdouble], active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cuda', dtypes=[torch.cdouble], active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cuda', dtypes=[torch.cdouble],
                                    active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cuda', dtypes=[torch.cdouble],
                                    active_if=IS_WINDOWS),
                       # 在至少某些 Windows 作业中由于虚部符号错误而失败
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_small',
                                    device_type='cuda', dtypes=[torch.cdouble],
                                    active_if=IS_WINDOWS),
                   ),
                   # 对于实数 x < 1，acosh 未定义
                   reference_numerics_filter=NumericsFilter(
                       condition=lambda x: (x < 1 if not x.is_complex() else torch.zeros_like(x, dtype=torch.bool)),
                       safe_val=2)),  # 当 x < 1 时，返回安全值 2
    BinaryUfuncInfo('add',
                    # NumPy没有内置参考alpha关键字的方法，但可以很容易地模拟
                    ref=lambda input, other, *, alpha=1: np.add(input, other) if alpha == 1 \
                    else np.add(input, np.multiply(alpha, other)),
                    # 定义数据类型集合，包括所有标准类型和复数类型以及特定的torch类型
                    dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16,
                                                     torch.float16, torch.chalf),
                    # 断言是否自动微分
                    assert_autodiffed=True,
                    # 用于生成输入样本的函数
                    sample_inputs_func=sample_inputs_add_sub,
                    # 支持前向梯度和后向梯度计算
                    supports_fwgrad_bwgrad=True,
                    # 支持前向自动求导
                    supports_forward_ad=True,
                    # 支持两个Python标量
                    supports_two_python_scalars=True,
                    # 装饰器列表，用于修饰测试
                    decorators=(
                        DecorateInfo(
                            # 对chalf类型设置特定的容差覆盖
                            toleranceOverride({torch.chalf: tol(atol=1e-2, rtol=0)}),
                            'TestBinaryUfuncs', 'test_reference_numerics'),
                    ),
                    # 跳过的测试列表
                    skips=(
                        # 布尔型alpha参数处理不正确时的预期测试失败
                        DecorateInfo(unittest.expectedFailure,
                                     'TestNNCOpInfo',
                                     'test_nnc_correctness',
                                     dtypes=(torch.bool,)),
                        # 跳过测试，因为复数类型不支持的情况
                        DecorateInfo(unittest.skip("Skipped!"),
                                     'TestCommon',
                                     'test_numpy_refs',
                                     dtypes=(torch.complex128,)),
                        # 跳过测试，因为复数类型在极端值情况下不支持的情况
                        DecorateInfo(unittest.skip("Skipped!"),
                                     'TestBinaryUfuncs',
                                     'test_reference_numerics_extremal_values',
                                     dtypes=(torch.complex64, torch.complex128)),
                    )),
    # 创建 OpInfo 对象，并传入多个参数
    OpInfo(
        'item',  # 操作的名称为 'item'
        op=lambda inp, *args, **kwargs: wrapper_set_seed(torch.Tensor.item, inp, *args, **kwargs),  # 操作的实现方法，使用 wrapper_set_seed 进行封装
        ref=np.ndarray.item,  # 引用的参考实现为 np.ndarray.item
        method_variant=None,  # 操作的方法变体为 None
        dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16, torch.chalf, torch.bool),  # 支持的数据类型，包括特定的 Torch 类型
        supports_out=False,  # 不支持输出参数
        supports_autograd=False,  # 不支持自动求导
        error_inputs_func=error_inputs_item,  # 用于生成错误输入的函数为 error_inputs_item
        sample_inputs_func=sample_inputs_item,  # 用于生成样本输入的函数为 sample_inputs_item
        skips=(  # 跳过的测试装饰器信息列表
            # 'item' 函数变体的错误测试
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32, torch.complex64)),
            # FX 未能规范化该操作 - 将此操作添加到 op_skip 列表中
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
            # 运行时错误: 组合兼容性检查失败，上述为错误信息
            DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_operator'),
            # 布尔值不匹配: AssertionError: False 不是 True
            DecorateInfo(unittest.expectedFailure, 'TestFakeTensor', 'test_fake_autocast'),
            # 布尔值不匹配: AssertionError: False 不是 True
            DecorateInfo(unittest.expectedFailure, 'TestFakeTensor', 'test_fake'),
        ),
    ),
    OpInfo('arange',
           dtypes=all_types_and(torch.bfloat16, torch.float16),  # 定义支持的数据类型，包括 torch.bfloat16 和 torch.float16
           supports_out=True,  # 指示支持输出参数
           supports_autograd=False,  # 指示不支持自动求导
           is_factory_function=True,  # 指示是工厂函数
           error_inputs_func=error_inputs_arange,  # 指定错误输入处理函数
           sample_inputs_func=sample_inputs_arange,  # 指定样本输入生成函数
           skips=(
               # 下面是一系列需要跳过的测试用例，每个 DecorateInfo 表示一个跳过的测试条件

               # Issue link: https://github.com/pytorch/pytorch/issues/81774
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),

               # 需要输入为张量或张量序列的测试用例
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),

               # Lazy tensor failures
               DecorateInfo(unittest.expectedFailure, 'TestLazyOpInfo', 'test_dispatched_to_lazy'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestLazyOpInfo', 'test_correctness'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestLazyOpInfo', 'test_correctness_with_reusing_ir'),

               # 来自于 analyzeImpl 引发的异常，出现在 alias_analysis.cpp 的特定行
               # 此处没有 aten::arange 的运算，但它不是特殊情况
               # 参数类型包括 bool, bool, bool, int, int, Device, boo
               DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_nnc_correctness'),

               # 捕获的图不包含 aten::arange（对复杂类型成功）
               # g: graph():
               #   %25 : Long(1, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value={1}]()
               #   return (%25)
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),

               # 没有触发 UserWarning：调整了非空张量的大小，但没有发出警告
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
           )),
    OpInfo('cauchy',
           # 定义操作名称为 'cauchy' 的 OpInfo 对象
           op=lambda inp, *args, **kwargs: wrapper_set_seed(torch.Tensor.cauchy_, inp, *args, **kwargs),
           # 设置操作函数为 lambda 表达式，调用 wrapper_set_seed 对 torch.Tensor.cauchy_ 进行封装
           inplace_variant=torch.Tensor.cauchy_,
           # 指定不支持原地操作的 cauchy_ 变体
           dtypes=floating_types_and(torch.float16, torch.bfloat16),
           # 支持的数据类型为浮点数类型，包括 torch.float16 和 torch.bfloat16
           supports_out=False,
           # 不支持输出参数的使用
           supports_autograd=False,
           # 不支持自动求导
           allow_cow_input_materialize_forward=[0],
           # 仅允许在第一个输入上使用 copy-on-write 输入材料化前向
           sample_inputs_func=sample_inputs_cauchy,
           # 样本输入函数为 sample_inputs_cauchy
           error_inputs_func=error_inputs_cauchy,
           # 错误输入函数为 error_inputs_cauchy
           skips=(
               # 下面是一系列跳过的测试用例信息
               # Tests that assume input tensor has a meaningful effect on output tensor
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),

               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),

               # AssertionError: Tensor-likes are not close!
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),

               # FX failed to normalize op - add the op to the op_skip list.
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),

               # vmap: calling random operator not supported
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_vmap_exhaustive"),
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_op_has_batch_rule"),

               DecorateInfo(unittest.skip("make_traced() doesn't set seed properly!"), 'TestCommon', 'test_python_ref_executor'),

               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick'),
           )),
           # 结束 skips 元组
    OpInfo('exponential',  # 创建一个 OpInfo 对象，用于描述指数分布操作
           op=lambda inp, *args, **kwargs: wrapper_set_seed(torch.Tensor.exponential_, inp, *args, **kwargs),  # 设置操作的函数，用于生成指数分布随机数，并且可以设置随机种子
           inplace_variant=torch.Tensor.exponential_,  # 指定支持原地操作的变体函数
           dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 指定支持的数据类型，包括浮点数类型和特定的浮点数类型
           supports_out=False,  # 不支持输出张量的特性
           supports_autograd=False,  # 不支持自动求导
           allow_cow_input_materialize_forward=[0],  # 允许按需复制的输入，用于正向计算
           sample_inputs_func=sample_inputs_exponential,  # 提供生成指数分布样本的函数
           error_inputs_func=error_inputs_exponential,  # 提供生成错误输入的函数
           skips=(  # 跳过以下测试用例
               # Tests that assume input tensor has a meaningful effect on output tensor
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),  # 预期某些测试失败，因为假定输入张量对输出张量有显著影响
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 预期某些测试失败，因为负视图测试

               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期 JIT 测试失败，因为 JIT 测试不执行任何逻辑

               # AssertionError: Tensor-likes are not close!
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),  # 跳过输出不确定性的比较 CPU 测试

               # FX failed to normalize op - add the op to the op_skip list.
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期某些规范化运算符测试失败，因为 FX 未能规范化该操作

               # vmap: calling random operator not supported
               DecorateInfo(unittest.expectedFailure, "TestVmapOperatorsOpInfo", "test_vmap_exhaustive"),  # 预期 vmap 运算符测试失败，因为不支持调用随机运算符
               DecorateInfo(unittest.expectedFailure, "TestVmapOperatorsOpInfo", "test_op_has_batch_rule"),  # 预期 vmap 运算符测试失败，因为操作没有批处理规则

               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick'),  # 预期某些分解测试失败，快速测试
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),  # 跳过输出不确定性的比较 CPU 测试
           )),
    OpInfo('geometric',  # 定义一个操作信息对象，针对几何分布的操作
           op=lambda inp, *args, **kwargs: wrapper_set_seed(torch.Tensor.geometric_, inp, *args, **kwargs),  # 设置操作的函数或者lambda表达式
           inplace_variant=torch.Tensor.geometric_,  # 原地操作的变体
           dtypes=floating_types_and(torch.float16, torch.bfloat16, torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8),  # 支持的数据类型
           supports_out=False,  # 不支持输出参数
           supports_autograd=False,  # 不支持自动求导
           allow_cow_input_materialize_forward=[0],  # 允许输入数据共享和前向实例化
           sample_inputs_func=sample_inputs_geometric,  # 生成几何分布操作的样本输入的函数
           error_inputs_func=error_inputs_geometric,  # 生成几何分布操作的错误输入的函数
           skips=(  # 跳过的测试用例集合
               # Tests that assume input tensor has a meaningful effect on output tensor
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),  # 预期失败的测试用例：输入张量对输出张量有意义的一致性测试
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 预期失败的测试用例：数学位测试中的负视图测试

               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例：JIT一致性测试

               # AssertionError: Tensor-likes are not close!
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),  # 跳过的测试用例：CPU比较测试，输出不确定性

               # FX failed to normalize op - add the op to the op_skip list.
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期失败的测试用例：归一化操作器详尽测试

               # vmap: calling random operator not supported
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_vmap_exhaustive"),  # 跳过的测试用例：vmap操作器详尽测试，期望张量输入
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_op_has_batch_rule"),  # 跳过的测试用例：操作器有批处理规则测试，期望张量输入

               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick'),  # 预期失败的测试用例：分解测试中的快速测试
           )),
    OpInfo('log_normal',
           # 设置操作为 log_normal，定义操作函数为 wrapper_set_seed，并传递输入 inp 以及其他参数和关键字参数
           op=lambda inp, *args, **kwargs: wrapper_set_seed(torch.Tensor.log_normal_, inp, *args, **kwargs),
           # 设置就地操作变体为 torch.Tensor.log_normal_
           inplace_variant=torch.Tensor.log_normal_,
           # 设置数据类型为浮点类型以及 torch.float16 和 torch.bfloat16
           dtypes=floating_types_and(torch.float16, torch.bfloat16),
           # 不支持输出参数
           supports_out=False,
           # 不支持自动求导
           supports_autograd=False,
           # 允许 Copy-on-Write (COW) 输入，然后在前向传播时材料化 [0] 索引处的输入
           allow_cow_input_materialize_forward=[0],
           # 用于生成示例输入的函数为 sample_inputs_log_normal
           sample_inputs_func=sample_inputs_log_normal,
           # 用于生成错误输入的函数为 error_inputs_log_normal
           error_inputs_func=error_inputs_log_normal,
           # 跳过以下测试：
           skips=(
               # 预期失败的测试，这些测试假定输入张量对输出张量有意义的影响
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),

               # 断言错误：JIT 测试未执行任何逻辑
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),

               # 断言错误：张量类似对象不接近！
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
               # FX 未能规范化操作 - 将操作添加到 op_skip 列表中。
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),

               # vmap：不支持调用随机运算符
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_vmap_exhaustive"),
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_op_has_batch_rule"),
               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick'),
           )),
    OpInfo('normal',
           variant_test_name='in_place',
           op=lambda inp, *args, **kwargs: wrapper_set_seed(torch.Tensor.normal_, inp, *args, **kwargs),
           inplace_variant=torch.Tensor.normal_,
           dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           supports_out=False,
           supports_autograd=False,
           allow_cow_input_materialize_forward=[0],
           sample_inputs_func=sample_inputs_normal,
           error_inputs_func=error_inputs_normal,
           skips=(
               # Tests that assume input is a tensor or sequence of tensors
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestCommon", "test_noncontiguous_samples"),

               # Tests that assume input tensor has a meaningful effect on output tensor
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick'),
               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # AssertionError: Tensor-likes are not close!
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
               # FX failed to normalize op - add the op to the op_skip list.
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # vmap: calling random operator not supported
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_vmap_exhaustive"),
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_op_has_batch_rule"),
           )),


注释：

    OpInfo('normal',  # 创建一个 OpInfo 对象，用于描述正态分布的操作
           variant_test_name='in_place',  # 操作的变体名称为 'in_place'
           op=lambda inp, *args, **kwargs: wrapper_set_seed(torch.Tensor.normal_, inp, *args, **kwargs),  # op 参数是一个 lambda 函数，调用 wrapper_set_seed 包装 torch.Tensor.normal_ 操作
           inplace_variant=torch.Tensor.normal_,  # inplace_variant 指定为 torch.Tensor.normal_，表示支持原地操作
           dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),  # dtypes 参数指定操作支持的数据类型，包括浮点数和复数类型
           supports_out=False,  # supports_out 指定为 False，表示不支持输出张量的特性
           supports_autograd=False,  # supports_autograd 指定为 False，表示不支持自动求导特性
           allow_cow_input_materialize_forward=[0],  # allow_cow_input_materialize_forward 参数指定为列表 [0]
           sample_inputs_func=sample_inputs_normal,  # sample_inputs_func 指定为 sample_inputs_normal 函数，用于提供正态分布操作的示例输入
           error_inputs_func=error_inputs_normal,  # error_inputs_func 指定为 error_inputs_normal 函数，用于提供正态分布操作的错误输入
           skips=(  # skips 是一个元组，包含多个 DecorateInfo 对象，用于跳过某些测试用例
               # 下面是各个 DecorateInfo 对象的注释说明
               # Tests that assume input is a tensor or sequence of tensors
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestCommon", "test_noncontiguous_samples"),
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick'),
               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # AssertionError: Tensor-likes are not close!
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
               # FX failed to normalize op - add the op to the op_skip list.
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # vmap: calling random operator not supported
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_vmap_exhaustive"),
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_op_has_batch_rule"),
           )),
    OpInfo('uniform',
           # 定义操作为 uniform，使用 torch.Tensor.uniform_ 方法，支持设置种子
           op=lambda inp, *args, **kwargs: wrapper_set_seed(torch.Tensor.uniform_, inp, *args, **kwargs),
           method_variant=None,
           # 操作的原地变体为 torch.Tensor.uniform_
           inplace_variant=torch.Tensor.uniform_,
           # 支持的数据类型包括浮点数和复数类型以及 torch.bfloat16 和 torch.float16
           dtypes=floating_and_complex_types_and(torch.bfloat16, torch.float16),
           supports_out=False,
           supports_autograd=False,
           is_factory_function=False,
           # 允许 cow_input 在前向传播中 materialize 的位置为 0
           allow_cow_input_materialize_forward=[0],
           # 采样输入函数为 sample_inputs_uniform
           sample_inputs_func=sample_inputs_uniform,
           # 错误输入函数为 error_inputs_uniform
           error_inputs_func=error_inputs_uniform,
           skips=(
               # FX 未能规范化此操作 - 将此操作添加到 op_skip 列表中
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # 测试假设输入张量对输出张量有意义的情况
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
               # AssertionError: JIT 测试没有执行任何逻辑
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # aten.uniform 未被分解
               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick'),
               # 跳过输出是非确定性的测试
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
           )),
    BinaryUfuncInfo('clamp_max',
                    # 参考实现为 _clamp_max_numpy
                    ref=_clamp_max_numpy,
                    # 支持的数据类型包括所有类型以及 torch.bool, torch.float16, torch.bfloat16
                    dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),
                    supports_forward_ad=True,
                    supports_rhs_python_scalar=False,
                    supports_fwgrad_bwgrad=True,
                    # 右手边的 make_tensor_kwargs 参数设置，排除零值
                    rhs_make_tensor_kwargs=dict(exclude_zero=False),
                    skips=(
                        # RuntimeError: "max_elementwise_cuda" 在 'ComplexFloat' 类型上未实现
                        DecorateInfo(unittest.expectedFailure,
                                     'TestBinaryUfuncs',
                                     'test_type_promotion',
                                     device_type='cuda'),
                        # 到 lazy 测试的分发失败
                        DecorateInfo(unittest.expectedFailure, 'TestLazyOpInfo', 'test_dispatched_to_lazy'),
                        # 测试错误被禁用，因为支持非张量 Python 标量作为 rhs
                        DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_errors'),
                    )),
    # 定义一个名为 'clamp_min' 的二元函数信息对象，用于描述有关函数 clamp_min 的各种属性和特性
    BinaryUfuncInfo('clamp_min',
                    # 引用标准库中的 clamp_min_numpy 函数作为参考实现
                    ref=_clamp_min_numpy,
                    # 支持的数据类型包括所有类型和 torch.bool、torch.float16、torch.bfloat16
                    dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 不支持右手边的 Python 标量作为输入
                    supports_rhs_python_scalar=False,
                    # 支持前向梯度与后向梯度的流动
                    supports_fwgrad_bwgrad=True,
                    # 右手边参数生成张量时的额外参数设置，排除零值
                    rhs_make_tensor_kwargs=dict(exclude_zero=False),
                    # 跳过的测试用例列表
                    skips=(
                        # 在 CUDA 设备上，'ComplexFloat' 类型尚未实现 "min_elementwise_cuda"，期望测试失败
                        DecorateInfo(unittest.expectedFailure,
                                     'TestBinaryUfuncs',
                                     'test_type_promotion',
                                     device_type='cuda'),
                        # 无法正确分派到惰性测试，期望测试失败
                        DecorateInfo(unittest.expectedFailure, 'TestLazyOpInfo', 'test_dispatched_to_lazy'),
                        # 测试错误已禁用，由于支持非张量的 Python 标量作为右手边参数
                        DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_errors'),
                    )),
    # 定义一个名为 'mul' 的二元函数信息对象，同时 'multiply' 也作为别名
    BinaryUfuncInfo('mul',
                    # 支持的数据类型包括所有类型、复数类型以及 torch.chalf、torch.float16、torch.bfloat16、torch.bool
                    dtypes=all_types_and_complex_and(torch.chalf, torch.float16, torch.bfloat16, torch.bool),
                    # 断言自动微分的正确性
                    assert_autodiffed=True,
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 支持前向梯度与后向梯度的流动
                    supports_fwgrad_bwgrad=True,
                    # 支持两个 Python 标量作为参数
                    supports_two_python_scalars=True,
                    # 稀疏输入函数中的错误输入处理函数为 error_inputs_sparse_mul
                    error_inputs_sparse_func=error_inputs_sparse_mul,
                    # 以稀疏 COO 格式为布局的稀疏输入样本函数
                    sample_inputs_sparse_coo_func=partial(sample_inputs_sparse_mul, layout=torch.sparse_coo),
                    # 以稀疏 CSR 格式为布局的稀疏输入样本函数
                    sample_inputs_sparse_csr_func=partial(sample_inputs_sparse_mul, layout=torch.sparse_csr),
                    # 以稀疏 CSC 格式为布局的稀疏输入样本函数
                    sample_inputs_sparse_csc_func=partial(sample_inputs_sparse_mul, layout=torch.sparse_csc),
                    # 以稀疏 BSR 格式为布局的稀疏输入样本函数
                    sample_inputs_sparse_bsr_func=partial(sample_inputs_sparse_mul, layout=torch.sparse_bsr),
                    # 以稀疏 BSC 格式为布局的稀疏输入样本函数
                    sample_inputs_sparse_bsc_func=partial(sample_inputs_sparse_mul, layout=torch.sparse_bsc)),
    BinaryUfuncInfo('sub',
                    # NumPy has no builtin reference for the alpha kwarg, but it is easy enough to emulate
                    ref=lambda input, other, *, alpha=1: np.subtract(input, np.multiply(alpha, other)),
                    # 'subtract' 别名
                    aliases=('subtract',),
                    # 所有数据类型及复数类型，包括 torch.bfloat16, torch.float16, torch.chalf
                    dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16, torch.chalf),
                    # 断言自动微分
                    assert_autodiffed=True,
                    # 支持正向自动微分
                    supports_forward_ad=True,
                    # 支持前向梯度反向传播
                    supports_fwgrad_bwgrad=True,
                    # 获取输入样本的函数，用于加法和减法
                    sample_inputs_func=sample_inputs_add_sub,
                    # 支持两个 Python 标量作为输入
                    supports_two_python_scalars=True,
                    # 装饰器信息列表
                    decorators=(
                        DecorateInfo(
                            # 覆盖容差，对于 torch.float16 使用 atol=1e-2, rtol=0
                            toleranceOverride({torch.float16: tol(atol=1e-2, rtol=0),
                                               torch.bfloat16: tol(atol=1e-5, rtol=5e-3),
                                               torch.complex32: tol(atol=1e-5, rtol=1e-3)}),
                            'TestBinaryUfuncs', 'test_reference_numerics'),
                        DecorateInfo(
                            # 覆盖容差，对于 torch.chalf 使用 atol=1e-2, rtol=0
                            toleranceOverride({torch.chalf: tol(atol=1e-2, rtol=0)}),
                            'TestCommon', 'test_complex_half_reference_testing', device_type='cpu'),
                        DecorateInfo(
                            # 覆盖容差，对于 torch.chalf 使用 atol=5e-3, rtol=0
                            toleranceOverride({torch.chalf: tol(atol=5e-3, rtol=0)}),
                            'TestDecomp', 'test_comprehensive', device_type='cpu'),
                        DecorateInfo(
                            # 覆盖容差，对于 torch.chalf 使用 atol=5e-3, rtol=0
                            toleranceOverride({torch.chalf: tol(atol=5e-3, rtol=0)}),
                            'TestDecomp', 'test_quick', device_type='cpu'),
                    ),
                    # 跳过的测试信息列表
                    skips=(
                        DecorateInfo(unittest.skip("Skipped!"),
                                     'TestBinaryUfuncs',
                                     'test_reference_numerics',
                                     # 跳过的数据类型为 torch.uint8
                                     dtypes=(torch.uint8,)),
                        DecorateInfo(unittest.skip("Skipped!"),
                                     'TestBinaryUfuncs',
                                     'test_reference_numerics_small_values',
                                     # 跳过的数据类型为 torch.uint8
                                     dtypes=(torch.uint8,)),
                    )),
    OpInfo('addmm',
           # 当 alpha 和 beta 不同时等于 1 时使用的 addmm OpInfo。
           # 特别测试 alpha=beta=1 的情况，因为这种特殊情况会触发 JIT 通过的 addmm 分解。
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           dtypesIfROCM=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           assert_autodiffed=True,  # 断言支持自动微分
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 梯度检查的非确定性容差
           sample_inputs_func=sample_inputs_addmm,  # 获取样本输入的函数
           skips=(
               # 存在与 torch 调度相关的共轭问题，详见 https://github.com/pytorch/pytorch/issues/82479
               DecorateInfo(
                   unittest.skip("Skipped!"),
                   'TestSchemaCheckModeOpInfo',
                   'test_schema_correctness',
                   dtypes=(torch.complex64, torch.complex128)),
           )),
    OpInfo('addmm',
           # 当 alpha=beta=1 作为编译时常数时，JIT 将 addmm 分解为 mm 和 add。
           variant_test_name='decomposed',  # 变体测试名称为 decomposed
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           assert_autodiffed=True,  # 断言支持自动微分
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 梯度检查的非确定性容差
           autodiff_nonfusible_nodes=['aten::add', 'aten::mm'],  # 自动微分不可融合节点列表
           sample_inputs_func=partial(sample_inputs_addmm, alpha=1, beta=1),  # 获取样本输入的函数，设置 alpha=1, beta=1
           skips=(
               # 存在与 torch 调度相关的共轭问题，详见 https://github.com/pytorch/pytorch/issues/82479
               DecorateInfo(
                   unittest.skip("Skipped!"),
                   'TestSchemaCheckModeOpInfo',
                   'test_schema_correctness',
                   dtypes=(torch.complex64, torch.complex128)),
               # https://github.com/pytorch/pytorch/issues/71784
               DecorateInfo(unittest.skip('Skipped!'), 'TestNNCOpInfo', 'test_nnc_correctness',
                            device_type='cpu', dtypes=(torch.float16,)),
           )),
    OpInfo('addmv',
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16),
           dtypesIfCUDA=floating_types_and(torch.float16, torch.complex64, torch.complex128,
                                           torch.bfloat16),
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           decorators=[
               DecorateInfo(
                   toleranceOverride({torch.half: tol(atol=1e-5, rtol=3e-3)}),
                   'TestInductorOpInfo', 'test_comprehensive', device_type='cpu'),
           ],
           sample_inputs_func=sample_inputs_addmv),  # 获取样本输入的函数
    # 定义 OpInfo 对象，用于描述 addbmm 操作的详细信息和测试配置
    OpInfo('addbmm',
           # 定义 ref 参数，lambda 函数，计算 addbmm 操作的参考实现
           ref=lambda M, batch1, batch2, beta=1, alpha=1: np.add(np.multiply(np.asarray(beta, dtype=M.dtype), M),
                                                                 np.multiply(np.asarray(alpha, dtype=batch1.dtype),
                                                                             np.sum(np.matmul(batch1, batch2), axis=0))),
           # 指定操作支持的数据类型，包括所有标量和复数类型以及 torch.bfloat16 和 torch.float16
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16),
           # 如果是 CUDA 环境，还要考虑特定的数据类型，如 torch.float16 和（根据条件决定）torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16,
                                                       *[torch.bfloat16]
                                                       if SM53OrLater or TEST_WITH_ROCM else []),
           # 在慢速的 gradcheck 模式下运行测试，或者可以减少输入大小作为替代
           gradcheck_fast_mode=True,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向梯度和后向梯度的一致性测试
           supports_fwgrad_bwgrad=True,
           # 用装饰器列表装饰 OpInfo，每个 DecorateInfo 对象描述一个测试装饰器
           decorators=[
               # 装饰器：重写指定数据类型的容差，针对 'TestCommon' 模块中的 'test_numpy_refs' 测试
               DecorateInfo(
                   toleranceOverride({torch.float32: tol(atol=1.3e-05, rtol=1.3e-05),
                                      torch.complex64: tol(atol=1e-05, rtol=1.2e-03)}),
                   'TestCommon', 'test_numpy_refs'),
               # 装饰器：重写指定数据类型的容差，针对 'TestCommon' 模块中的 'test_numpy_ref_mps' 测试
               # MPS 的精度稍差，是否可接受？
               DecorateInfo(
                   toleranceOverride({torch.float32: tol(atol=1.3e-04, rtol=1.3e-04),
                                      torch.complex64: tol(atol=1e-05, rtol=1.2e-03)}),
                   'TestCommon', 'test_numpy_ref_mps'),
               # 装饰器：重写指定数据类型的容差，针对 'TestConsistency' 模块中的 'test_output_match' 测试
               DecorateInfo(
                   toleranceOverride({torch.float32: tol(atol=1e-5, rtol=1e-5)}),
                   'TestConsistency',
                   'test_output_match',
               ),
               # 装饰器：重写指定数据类型的容差，针对 'TestCommon' 模块中的 'test_out' 测试
               DecorateInfo(
                   toleranceOverride({torch.float32: tol(atol=1.5e-05, rtol=1e-05)}),
                   'TestCommon', 'test_out'),
               # 装饰器：对于 'cpu' 设备，重写指定数据类型的容差，针对 'TestInductorOpInfo' 模块中的 'test_comprehensive' 测试
               DecorateInfo(
                   toleranceOverride({torch.half: tol(atol=6e-3, rtol=6e-3)}),
                   'TestInductorOpInfo', 'test_comprehensive', device_type='cpu'),
           ],
           # 跳过某些测试条件，用于条件不满足时的测试跳过策略
           skips=(
               # 如果 SM < 5.3，则跳过此测试（仅适用于 CUDA 设备）
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_dtypes', device_type='cuda', active_if=not SM53OrLater),
               # 对于 addbmm 操作，当 resizing out= 输入时未正确发出警告
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               # 暂时跳过的测试，详细信息请参见 GitHub 问题链接
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager'),
           ),
           # 指定 sample_inputs_func 用于生成 addbmm 操作的样本输入
           sample_inputs_func=sample_inputs_addbmm),
    OpInfo('baddbmm',
           # 指定操作名称为'baddbmm'
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16),
           # 定义适用的数据类型，包括所有类型、复数类型以及torch.bfloat16和torch.float16
           dtypesIfCUDA=floating_types_and(torch.float16, torch.complex64, torch.complex128,
                                           torch.bfloat16),
           # 定义CUDA环境下适用的数据类型，包括浮点类型和复数类型以及torch.float16、torch.complex64、torch.complex128、torch.bfloat16
           backward_dtypesIfCUDA=floating_types_and(torch.float16,
                                                    *[torch.bfloat16] if SM53OrLater or TEST_WITH_ROCM else [],
                                                    torch.complex64, torch.complex128),
           # 定义CUDA环境下反向传播时适用的数据类型，包括浮点类型、根据条件是否包含torch.bfloat16以及torch.complex64、torch.complex128
           # 在gradcheck慢时运行较慢 - 可以选择减小输入大小以替代
           gradcheck_fast_mode=True,
           # 使用快速模式进行gradcheck
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向梯度和反向梯度
           decorators=[
               DecorateInfo(
                   # 设置torch.complex64的容差覆盖，指定atol=1e-05，rtol=1.2e-03
                   toleranceOverride({torch.complex64: tol(atol=1e-05, rtol=1.2e-03)}),
                   'TestCommon', 'test_variant_consistency_eager', device_type='cuda'),
               DecorateInfo(
                   # 设置torch.complex64的容差覆盖，指定atol=1e-05，rtol=1.2e-03
                   toleranceOverride({torch.complex64: tol(atol=1e-05, rtol=1.2e-03)}),
                   'TestMathBits', 'test_conj_view', device_type='cuda'),
           ],
           sample_inputs_func=sample_inputs_baddbmm,
           # 设置用于采样输入的函数为sample_inputs_baddbmm
           skips=(
               # 存在torch.dispatch和conj相关的问题，跳过此测试
               DecorateInfo(
                   unittest.skip("Skipped!"),
                   'TestSchemaCheckModeOpInfo',
                   'test_schema_correctness',
                   dtypes=(torch.complex64, torch.complex128)),
           )),
    OpInfo('dot',
           # 指定操作名称为'dot'
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           # 定义适用的数据类型，包括所有类型、复数类型以及torch.float16和torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           # 定义CUDA环境下适用的数据类型，包括浮点类型和复数类型以及torch.float16和torch.bfloat16
           assert_autodiffed=True,
           # 断言自动微分已启用
           sample_inputs_func=sample_inputs_dot_vdot,
           # 设置用于采样输入的函数为sample_inputs_dot_vdot
           error_inputs_func=error_inputs_dot_vdot,
           # 设置用于错误输入的函数为error_inputs_dot_vdot
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向梯度和反向梯度
           skips=(
               # 存在torch.dispatch和conj相关的问题，跳过此测试
               DecorateInfo(
                   unittest.skip("Skipped!"),
                   'TestSchemaCheckModeOpInfo',
                   'test_schema_correctness',
                   dtypes=(torch.complex64, torch.complex128)),
           )),
    OpInfo('vdot',
           # 操作名称为 'vdot'
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           # 支持所有浮点类型和复数类型，包括 torch.float16 和 torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           # 如果在 CUDA 上，支持浮点类型和复数类型，包括 torch.float16 和 torch.bfloat16
           sample_inputs_func=sample_inputs_dot_vdot,
           # 用于生成样例输入的函数为 sample_inputs_dot_vdot
           error_inputs_func=error_inputs_dot_vdot,
           # 用于生成错误输入的函数为 error_inputs_dot_vdot
           supports_forward_ad=True,
           # 支持前向自动求导
           supports_fwgrad_bwgrad=True,
           # 支持前向梯度和后向梯度
           skips=(
               # 存在 torch.dispatch 中 conj 和 torch 的问题，详见 https://github.com/pytorch/pytorch/issues/82479
               DecorateInfo(
                   unittest.skip("Skipped!"),
                   'TestSchemaCheckModeOpInfo',
                   'test_schema_correctness',
                   dtypes=(torch.complex64, torch.complex128)),
               # 跳过的测试用例信息，用于测试模式和模式检查的正确性
           )),
    OpInfo('bmm',
           # 操作名称为 'bmm'
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           # 支持所有浮点类型和复数类型，包括 torch.float16 和 torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16,
                                                       *[torch.bfloat16]
                                                       if SM53OrLater or TEST_WITH_ROCM else []),
           # 如果在 CUDA 上，支持浮点类型和复数类型，包括 torch.float16 和根据条件可能包括 torch.bfloat16
           assert_autodiffed=True,
           # 自动微分断言为 True
           assert_jit_shape_analysis=True,
           # JIT 形状分析断言为 True
           supports_forward_ad=True,
           # 支持前向自动求导
           supports_fwgrad_bwgrad=True,
           # 支持前向梯度和后向梯度
           skips=(
               # 如果 SM >= 5.3，仅 NVIDIA 确保支持 bfloat16 的 bmm 操作
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_dtypes', device_type='cuda', active_if=not SM53OrLater),
               # 如果不是 SM53OrLater，则跳过对 CUDA 设备上的测试
               DecorateInfo(toleranceOverride({torch.float32: tol(atol=1e-5, rtol=1e-5)}),
                            "TestCommon", "test_out")
           ),
           # 跳过的测试用例信息，包括设备类型为 cuda 且未达到 SM53 版本限制的测试用例
           sample_inputs_func=sample_inputs_bmm),
           # 用于生成样例输入的函数为 sample_inputs_bmm
    OpInfo('mv',
           # 操作名称为 'mv'
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           # 支持所有浮点类型和复数类型，包括 torch.float16 和 torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           # 如果在 CUDA 上，支持浮点类型和复数类型，包括 torch.float16 和 torch.bfloat16
           assert_autodiffed=True,
           # 自动微分断言为 True
           supports_forward_ad=True,
           # 支持前向自动求导
           supports_fwgrad_bwgrad=True,
           # 支持前向梯度和后向梯度
           sample_inputs_func=sample_inputs_mv),
           # 用于生成样例输入的函数为 sample_inputs_mv
    OpInfo('addr',
           # 操作名称为 'addr'
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),
           # 支持所有类型，包括 torch.bool, torch.bfloat16 和 torch.float16
           # 参考：https://github.com/pytorch/pytorch/issues/50747
           supports_forward_ad=True,
           # 支持前向自动求导
           supports_fwgrad_bwgrad=True,
           # 支持前向梯度和后向梯度
           skips=(
               # 参考：https://github.com/pytorch/pytorch/issues/50747
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager',
                            dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16)),
           ),
           # 跳过的测试用例信息，包括测试变体一致性和急切模式的测试用例
           sample_inputs_func=sample_inputs_addr,
           # 用于生成样例输入的函数为 sample_inputs_addr
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL),
           # 梯度检查的非确定性容差为 GRADCHECK_NONDET_TOL
    # 定义 OpInfo 对象，描述 torch.addcmul 操作的测试信息
    OpInfo('addcmul',
           # 指定支持的数据类型为所有浮点类型以及 torch.float16 和 torch.bfloat16
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           # 断言自动求导已启用
           assert_autodiffed=True,
           # 支持正向自动求导
           supports_forward_ad=True,
           # 支持正向和反向梯度的一致性测试
           supports_fwgrad_bwgrad=True,
           # 忽略指定测试用例，使用 DecorateInfo 包装的 unittest.expectedFailure
           skips=(
               # TODO: 更新带有 for_inplace_variant 关键字参数的示例输入，以支持此测试
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
           ),
           # 指定用于生成示例输入的函数
           sample_inputs_func=sample_inputs_addcmul_addcdiv,
           # 指定用于生成参考输入的函数，部分应用 reference_inputs_elementwise_ternary 函数
           reference_inputs_func=partial(
               reference_inputs_elementwise_ternary, sample_inputs_func=reference_inputs_addcmul_addcdiv)),
    # 定义 OpInfo 对象，描述 torch.addcdiv 操作的测试信息
    OpInfo('addcdiv',
           # 指定支持的数据类型为浮点类型、复数类型以及 torch.float16 和 torch.bfloat16
           dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           # 支持正向自动求导
           supports_forward_ad=True,
           # 支持正向和反向梯度的一致性测试
           supports_fwgrad_bwgrad=True,
           # 忽略指定测试用例，使用 DecorateInfo 包装的 unittest.expectedFailure
           skips=(
               # TODO: 更新带有 for_inplace_variant 关键字参数的示例输入，以支持此测试
               DecorateInfo(unittest.expectedFailure,
                            'TestCommon',
                            'test_variant_consistency_eager'),
           ),
           # 指定用于生成示例输入的函数
           sample_inputs_func=sample_inputs_addcmul_addcdiv,
           # 指定用于生成参考输入的函数，部分应用 reference_inputs_elementwise_ternary 函数
           reference_inputs_func=partial(
               reference_inputs_elementwise_ternary, sample_inputs_func=reference_inputs_addcmul_addcdiv)),
    UnaryUfuncInfo('asin',
                   aliases=('arcsin', ),  # 设置别名 'arcsin'
                   ref=np.arcsin,  # 参考实现为 numpy 的 arcsin 函数
                   domain=(-1, 1),  # 输入定义域为 [-1, 1]
                   supports_sparse=True,  # 支持稀疏输入
                   supports_sparse_csr=True,  # 支持稀疏 CSR 格式输入
                   supports_sparse_csc=True,  # 支持稀疏 CSC 格式输入
                   supports_sparse_bsr=True,  # 支持稀疏 BSR 格式输入
                   supports_sparse_bsc=True,  # 支持稀疏 BSC 格式输入
                   supports_forward_ad=True,  # 支持自动微分的前向模式
                   supports_fwgrad_bwgrad=True,  # 支持自动微分的前向和反向梯度计算
                   promotes_int_to_float=True,  # 将整数类型自动提升为浮点数类型
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括所有标准类型和复数类型，以及 torch 的 bool、half 和 bfloat16 类型
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),  # CUDA 下支持的数据类型与上面类似，但包含了 torch 的 chalf 类型
                   assert_autodiffed=True,  # 自动微分时会执行断言
                   decorators=[  # 装饰器列表开始
                       DecorateInfo(
                           toleranceOverride({torch.float16: tol(atol=1e-05, rtol=1e-03)}),  # 为 torch.float16 类型设置容差
                           'TestUnaryUfuncs', device_type='cuda'),  # 针对 'TestUnaryUfuncs' 的 CUDA 设备测试
                       precisionOverride({torch.bfloat16: 1e-2}),  # 针对 torch.bfloat16 类型设置精度覆盖
                   ],  # 装饰器列表结束
                   skips=(  # 跳过列表开始
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',  # 跳过的测试信息：'test_reference_numerics_extremal'
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),  # 在 CPU 上对 torch.cfloat 和 torch.cdouble 类型进行测试
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',  # 跳过的测试信息：'test_reference_numerics_large'
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),  # 在 CPU 上对 torch.cfloat 和 torch.cdouble 类型进行测试
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',  # 跳过的测试信息：'test_reference_numerics_extremal'
                                    device_type='cuda', dtypes=[torch.cdouble],  # 在 CUDA 上对 torch.cdouble 类型进行测试
                                    active_if=IS_WINDOWS),  # 仅在 Windows 环境下生效
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',  # 跳过的测试信息：'test_reference_numerics_large'
                                    device_type='cuda', dtypes=[torch.cdouble],  # 在 CUDA 上对 torch.cdouble 类型进行测试
                                    active_if=IS_WINDOWS),  # 仅在 Windows 环境下生效
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),  # 跳过的测试信息：'sparse backward not supported'
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),  # 在 'TestSparseUnaryUfuncs' 的 'test_sparse_fn_grad' 测试中
                   )),  # 跳过列表结束
    # NOTE: derivative for inplace asinh is not implemented  # 注意：对于 inplace asinh 没有实现导数
    UnaryUfuncInfo('asinh',  # 创建一个 UnaryUfuncInfo 对象，表示 arcsinh 函数的信息
                   aliases=('arcsinh', ),  # 别名为 'arcsinh'
                   ref=np.arcsinh,  # 参考实现为 numpy 库中的 arcsinh 函数
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型，包括所有类型以及 torch 中的布尔型、半精度浮点型和 bfloat16
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),  # CUDA 环境下支持的数据类型，包括 torch 中的复数半精度浮点型、布尔型、半精度浮点型和 bfloat16
                   decorators=(precisionOverride({torch.bfloat16: 5e-2}),),  # 装饰器，设置 torch.bfloat16 数据类型的精度为 5e-2
                   supports_inplace_autograd=False,  # 不支持原地自动求导
                   supports_forward_ad=True,  # 支持前向自动求导
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
                   supports_sparse=True,  # 支持稀疏张量
                   supports_sparse_csr=True,  # 支持稀疏 CSR 格式
                   supports_sparse_csc=True,  # 支持稀疏 CSC 格式
                   supports_sparse_bsr=True,  # 支持稀疏 BSR 格式
                   supports_sparse_bsc=True,  # 支持稀疏 BSC 格式
                   promotes_int_to_float=True,  # 将整数升级为浮点数
                   skips=(  # 跳过的测试用例列表
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',  # 跳过的极端数值测试用例，CPU 环境，数据类型为复数浮点数和双精度复数浮点数
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',  # 跳过的大数值测试用例，CPU 环境，数据类型为复数浮点数和双精度复数浮点数
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_small',  # 跳过的小数值测试用例，CPU 环境，数据类型为复数浮点数和双精度复数浮点数
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_normal',  # 跳过的正常数值测试用例，CPU 环境，数据类型为复数浮点数和双精度复数浮点数
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',  # 跳过的极端数值测试用例，CUDA 环境，数据类型为双精度复数浮点数，仅在 Windows 平台生效
                                    device_type='cuda', dtypes=[torch.cdouble],
                                    active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',  # 跳过的大数值测试用例，CUDA 环境，数据类型为双精度复数浮点数，仅在 Windows 平台生效
                                    device_type='cuda', dtypes=[torch.cdouble],
                                    active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),  # 跳过的稀疏反向梯度不支持的测试用例
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),
                   )),
    # 定义 UnaryUfuncInfo 对象，用于描述一元函数 'atan'
    UnaryUfuncInfo('atan',
                   # 别名列表
                   aliases=('arctan', ),
                   # 参考实现为 np.arctan
                   ref=np.arctan,
                   # 支持的数据类型包括所有类型以及特定的 Torch 数据类型
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 如果在 CUDA 下，支持的数据类型
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),
                   # 断言自动微分已启用
                   assert_autodiffed=True,
                   # 支持正向自动微分
                   supports_forward_ad=True,
                   # 支持正向反向梯度传播
                   supports_fwgrad_bwgrad=True,
                   # 支持稀疏张量
                   supports_sparse=True,
                   # 支持稀疏 CSR 格式
                   supports_sparse_csr=True,
                   # 支持稀疏 CSC 格式
                   supports_sparse_csc=True,
                   # 支持稀疏 BSR 格式
                   supports_sparse_bsr=True,
                   # 支持稀疏 BSC 格式
                   supports_sparse_bsc=True,
                   # 支持整数到浮点数的提升
                   promotes_int_to_float=True,
                   # 装饰器，对特定 Torch.bfloat16 类型设置精度覆盖
                   decorators=(precisionOverride({torch.bfloat16: 1e-2}),),
                   # 跳过的测试用例信息，标记为跳过
                   skips=(
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_small',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cuda', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cuda', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),
                   )),
    # 定义 BinaryUfuncInfo 对象，用于描述二元函数 'atan2'
    BinaryUfuncInfo('atan2',
                    # 别名列表
                    aliases=('arctan2',),
                    # 支持的数据类型包括所有类型以及特定的 Torch 数据类型
                    dtypes=all_types_and(torch.bool, torch.bfloat16, torch.half),
                    # 支持正向自动微分
                    supports_forward_ad=True,
                    # 支持正向反向梯度传播
                    supports_fwgrad_bwgrad=True,
                    # 支持整数到浮点数的提升
                    promotes_int_to_float=True,
                    # 不支持右操作数为 Python 标量
                    supports_rhs_python_scalar=False,
                    # 跳过的测试用例信息，标记为预期失败
                    skips=(
                        # 尝试使用标量作为第二个参数，但不正确地尝试使用
                        DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_jit_alias_remapping'),
                    )),
    UnaryUfuncInfo('atanh',  # 定义一元函数的信息对象，此处为反双曲正切函数
                   aliases=('arctanh', ),  # 别名为 'arctanh'
                   ref=np.arctanh,  # 参考实现为 NumPy 中的 arctanh 函数
                   domain=(-1, 1),  # 定义定义域为 (-1, 1)
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型，包括布尔型、半精度和 bfloat16
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),  # CUDA 环境下支持的数据类型，包括复数半精度、布尔型、半精度和 bfloat16
                   decorators=(precisionOverride({torch.bfloat16: 1e-2}),),  # 修饰器列表，针对 bfloat16 类型的精度修正为 1e-2
                   supports_inplace_autograd=False,  # 不支持原地自动求导
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
                   supports_sparse=True,  # 支持稀疏张量
                   supports_sparse_csr=True,  # 支持 CSR 格式的稀疏张量
                   supports_sparse_csc=True,  # 支持 CSC 格式的稀疏张量
                   supports_sparse_bsr=True,  # 支持 BSR 格式的稀疏张量
                   supports_sparse_bsc=True,  # 支持 BSC 格式的稀疏张量
                   promotes_int_to_float=True,  # 支持将整数提升为浮点数
                   skips=(  # 跳过的测试信息列表
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_small',  # 跳过的测试信息：测试小数值参考数值计算
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),  # 在 CPU 上针对复数浮点数和双精度浮点数类型
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',  # 跳过的测试信息：测试极端值参考数值计算
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),  # 在 CPU 上针对复数浮点数和双精度浮点数类型
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',  # 跳过的测试信息：测试大数值参考数值计算
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),  # 在 CPU 上针对复数浮点数和双精度浮点数类型
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',  # 跳过的测试信息：测试极端值参考数值计算
                                    device_type='cuda', dtypes=[torch.cfloat, torch.cdouble],  # 在 CUDA 上针对复数浮点数和双精度浮点数类型，仅在 Windows 环境下激活
                                    active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',  # 跳过的测试信息：测试大数值参考数值计算
                                    device_type='cuda', dtypes=[torch.cfloat],  # 在 CUDA 上针对单精度复数浮点数类型，仅在 Windows 环境下激活
                                    active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),  # 跳过的测试信息：稀疏张量的反向传播不支持
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),  # 在稀疏一元函数测试中的梯度函数测试
                   )),
    OpInfo('allclose',  # 定义操作信息对象，此处为 allclose 操作
           dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),  # 支持的数据类型，包括浮点数和复数类型以及 torch.float16 和 torch.bfloat16
           ref=np.allclose,  # 参考实现为 NumPy 中的 allclose 函数
           supports_autograd=False,  # 不支持自动求导
           supports_forward_ad=False,  # 不支持前向自动微分
           sample_inputs_func=sample_inputs_allclose,  # 用于 allclose 操作的示例输入函数
           skips=(  # 跳过的测试信息列表
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),  # 跳过的测试信息：JIT 变体一致性测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo', 'test_nnc_correctness'),  # 跳过的测试信息：NNC 操作信息正确性测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestCudaFuserOpInfo'),  # 跳过的测试信息：CUDA 融合器操作信息测试
           ),
           supports_out=False),  # 不支持输出张量作为参数
    OpInfo('broadcast_to',
           ref=np.broadcast_to,  # 使用 NumPy 中的 broadcast_to 函数作为参考实现
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括所有类型以及特定的 torch 类型
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,  # 不检查批量前向梯度
           sample_inputs_func=sample_inputs_broadcast_to),  # 使用 sample_inputs_broadcast_to 函数生成示例输入

    OpInfo('broadcast_shapes',
           op=torch.broadcast_shapes,  # 使用 torch 中的 broadcast_shapes 操作
           ref=np.broadcast_shapes if np.lib.NumpyVersion(np.__version__) >= '1.20.0' else None,  # 如果 NumPy 版本大于等于 1.20.0，则使用 NumPy 中的 broadcast_shapes 函数作为参考实现，否则为 None
           dtypes=_dispatch_dtypes((torch.float32,)),  # 分派给操作的数据类型为 torch.float32
           supports_out=False,  # 不支持输出参数
           supports_gradgrad=False,  # 不支持二阶梯度
           assert_autodiffed=False,  # 不断言已自动微分
           supports_autograd=False,  # 不支持自动微分
           supports_scripting=False,  # 不支持脚本化
           sample_inputs_func=sample_inputs_broadcast_shapes,  # 使用 sample_inputs_broadcast_shapes 函数生成示例输入
           skips=(
               # https://github.com/pytorch/pytorch/issues/64997
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 标记为预期失败的单元测试，测试方法为 'TestNormalizeOperators' 中的 'test_normalize_operator_exhaustive'
               # 跳过数据类型测试，因为 broadcast_shape 不依赖于设备
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_dtypes'),  # 跳过 'TestCommon' 中的 'test_dtypes' 测试
               # 跳过这些测试，因为我们有非张量输入
               DecorateInfo(unittest.skip('Skipped!'), "TestCommon", "test_noncontiguous_samples"),  # 跳过 'TestCommon' 中的 'test_noncontiguous_samples' 测试
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_variant_consistency_eager'),  # 跳过 'TestCommon' 中的 'test_variant_consistency_eager' 测试
               DecorateInfo(unittest.skip('Skipped!'), 'TestJit', 'test_variant_consistency_jit'),  # 跳过 'TestJit' 中的 'test_variant_consistency_jit' 测试
           )),

    OpInfo('broadcast_tensors',
           ref=np.broadcast_arrays,  # 使用 NumPy 中的 broadcast_arrays 函数作为参考实现
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括所有类型以及特定的 torch 类型
           sample_inputs_func=sample_inputs_broadcast_tensors,  # 使用 sample_inputs_broadcast_tensors 函数生成示例输入
           reference_inputs_func=reference_inputs_broadcast_tensors,  # 使用 reference_inputs_broadcast_tensors 函数生成参考输入
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,  # 不检查批量前向梯度
           skips=(
               # https://github.com/pytorch/pytorch/issues/64997
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 标记为预期失败的单元测试，测试方法为 'TestNormalizeOperators' 中的 'test_normalize_operator_exhaustive'
               # JIT 不支持可变张量。
               # RuntimeError: input->type()->kind() == TypeKind::OptionalType
               # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,
               # please report a bug to PyTorch.
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=[torch.float32]),  # 标记为预期失败的单元测试，测试方法为 'TestJit' 中的 'test_variant_consistency_jit'，针对数据类型为 torch.float32
           )),
    OpInfo('block_diag',  # 创建 OpInfo 对象，表示 block_diag 操作的信息
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 支持的数据类型包括所有类型以及特定类型
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           # 默认的批处理规则在具有 TensorList 参数的操作中不适用
           check_batched_forward_grad=False,
           skips=(
               # https://github.com/pytorch/pytorch/issues/64997
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 标记为预期失败的测试用例
               # JIT 不支持可变张量。
               # RuntimeError: input->type()->kind() == TypeKind::OptionalType
               # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,
               # please report a bug to PyTorch.
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=[torch.float32]),  # 标记为预期失败的测试用例，特定数据类型为 torch.float32
           ),
           sample_inputs_func=sample_inputs_block_diag),  # 指定用于 block_diag 操作的示例输入函数

    UnaryUfuncInfo('bitwise_not',  # 创建 UnaryUfuncInfo 对象，表示 bitwise_not 操作的信息
                   ref=np.bitwise_not,  # 参考实现为 numpy 的 bitwise_not 函数
                   dtypes=integral_types_and(torch.bool),  # 支持的数据类型包括整数类型和布尔类型
                   operator_variant=operator.invert,  # 操作符变体为按位取反
                   supports_autograd=False),  # 不支持自动微分

    BinaryUfuncInfo('bitwise_left_shift',  # 创建 BinaryUfuncInfo 对象，表示 bitwise_left_shift 操作的信息
                    op=torch.bitwise_left_shift,  # 使用 torch 的 bitwise_left_shift 操作符
                    dtypes=integral_types(),  # 支持的数据类型为整数类型
                    dtypesIfCUDA=integral_types(),  # 如果在 CUDA 上，则支持的数据类型为整数类型
                    operator_variant=operator.lshift,  # 操作符变体为左移
                    inplace_operator_variant=operator.ilshift,  # 原地操作符变体为原地左移
                    supports_autograd=False,  # 不支持自动微分
                    supports_one_python_scalar=True,  # 支持单个 Python 标量
                    rhs_make_tensor_kwargs=dict(low=0),  # 右操作数生成张量的参数设置，最小值为 0
                    skips=(
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs', 'test_type_promotion'),  # 标记为跳过的测试用例
                        # https://github.com/pytorch/pytorch/issues/70904
                        DecorateInfo(unittest.skip("Some inputs produce undefined outputs"), 'TestCommon', 'test_compare_cpu'),  # 标记为跳过的测试用例
                    )),

    BinaryUfuncInfo('bitwise_right_shift',  # 创建 BinaryUfuncInfo 对象，表示 bitwise_right_shift 操作的信息
                    op=torch.bitwise_right_shift,  # 使用 torch 的 bitwise_right_shift 操作符
                    dtypes=integral_types(),  # 支持的数据类型为整数类型
                    dtypesIfCUDA=integral_types(),  # 如果在 CUDA 上，则支持的数据类型为整数类型
                    operator_variant=operator.rshift,  # 操作符变体为右移
                    inplace_operator_variant=operator.irshift,  # 原地操作符变体为原地右移
                    supports_autograd=False,  # 不支持自动微分
                    supports_one_python_scalar=True,  # 支持单个 Python 标量
                    rhs_make_tensor_kwargs=dict(low=0),  # 右操作数生成张量的参数设置，最小值为 0
                    skips=(
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs', 'test_type_promotion'),  # 标记为跳过的测试用例
                        # https://github.com/pytorch/pytorch/issues/70904
                        DecorateInfo(unittest.skip("Some inputs produce undefined outputs"), 'TestCommon', 'test_compare_cpu'),  # 标记为跳过的测试用例
                    )),
    OpInfo('combinations',  # 定义操作信息对象 'combinations'
           op=torch.combinations,  # 操作为 torch 库中的 combinations 函数
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括所有类型和复杂类型以及指定的 torch 数据类型
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向后向梯度
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           supports_out=False,  # 不支持输出参数
           sample_inputs_func=sample_inputs_combinations),  # 采样输入函数为 sample_inputs_combinations
    OpInfo('cartesian_prod',  # 定义操作信息对象 'cartesian_prod'
           op=torch.cartesian_prod,  # 操作为 torch 库中的 cartesian_prod 函数
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括所有类型和复杂类型以及指定的 torch 数据类型
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向后向梯度
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           sample_inputs_func=sample_inputs_cartesian_prod,  # 采样输入函数为 sample_inputs_cartesian_prod
           skips=(  # 跳过以下测试用例
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 在 'TestMathBits' 中的 'test_neg_view' 测试用例预期失败
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 在 'TestMathBits' 中的 'test_conj_view' 测试用例预期失败
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 在 'TestNormalizeOperators' 中的 'test_normalize_operator_exhaustive' 测试用例预期失败
               # 以下测试用例由于特定错误而预期失败
               # RuntimeError: input->type()->kind() == TypeKind::OptionalType
               # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270
               DecorateInfo(unittest.expectedFailure,
                            'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),
           )),
    OpInfo('cdist',  # 定义操作信息对象 'cdist'
           dtypes=floating_types(),  # 支持的数据类型为浮点类型
           supports_out=False,  # 不支持输出参数
           supports_gradgrad=False,  # 不支持二阶梯度计算
           assert_autodiffed=False,  # 不断言自动微分
           sample_inputs_func=sample_inputs_cdist),  # 采样输入函数为 sample_inputs_cdist
    UnaryUfuncInfo('ceil',  # 定义一元函数信息对象 'ceil'
                   ref=np.ceil,  # 参考实现为 numpy 库中的 ceil 函数
                   dtypes=all_types_and(torch.half, torch.bfloat16),  # 支持的数据类型包括所有类型和 torch 的半精度和 bfloat16 类型
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向后向梯度
                   skips=(  # 跳过以下测试用例
                       DecorateInfo(unittest.expectedFailure,
                                    'TestNNCOpInfo',
                                    'test_nnc_correctness',
                                    dtypes=tuple(t for t in integral_types() if t != torch.uint8)),  # 在 'TestNNCOpInfo' 中的 'test_nnc_correctness' 测试用例预期失败，数据类型排除 torch.uint8
                   ),
                   supports_sparse=True,  # 支持稀疏张量
                   supports_sparse_csr=True,  # 支持 CSR 格式的稀疏张量
                   supports_sparse_csc=True,  # 支持 CSC 格式的稀疏张量
                   supports_sparse_bsr=True,  # 支持 BSR 格式的稀疏张量
                   supports_sparse_bsc=True,  # 支持 BSC 格式的稀疏张量
                   assert_autodiffed=True),  # 断言自动微分
    OpInfo('cholesky',  # 定义操作信息对象 'cholesky'
           dtypes=floating_and_complex_types(),  # 支持的数据类型为浮点数和复数类型
           sample_inputs_func=sample_inputs_linalg_cholesky,  # 采样输入函数为 sample_inputs_linalg_cholesky
           gradcheck_wrapper=gradcheck_wrapper_hermitian_input,  # 梯度检查包装器为 gradcheck_wrapper_hermitian_input
           decorators=[skipCUDAIfNoMagma, skipCPUIfNoLapack],),  # 使用装饰器 skipCUDAIfNoMagma 和 skipCPUIfNoLapack
    OpInfo('cholesky_inverse',  # 创建一个名为 'cholesky_inverse' 的操作信息对象
           dtypes=floating_and_complex_types(),  # 指定支持的数据类型为浮点数和复数类型
           backward_dtypes=floating_and_complex_types(),  # 指定反向传播时支持的数据类型为浮点数和复数类型
           # 设置 gradcheck 快速模式以加快梯度检查速度
           gradcheck_fast_mode=True,
           supports_fwgrad_bwgrad=True,  # 表明支持前向和后向梯度传播
           supports_forward_ad=True,  # 表明支持自动区分的前向传播
           check_batched_gradgrad=True,  # 检查批处理的梯度-梯度
           sample_inputs_func=sample_inputs_linalg_cholesky_inverse,  # 设置样本输入函数为 linalg cholesky inverse 的样本输入生成函数
           gradcheck_wrapper=gradcheck_wrapper_triangular_input_real_positive_diagonal,  # 设置梯度检查包装器函数
           decorators=[skipCUDAIfNoMagma, skipCPUIfNoLapack],  # 添加装饰器用于跳过没有 Magma 的 CUDA 和没有 Lapack 的 CPU
           skips=(
               # 标记为跳过的测试用例，原因是原始步幅和现在的步幅不同
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
           )),
    OpInfo('cholesky_solve',  # 创建一个名为 'cholesky_solve' 的操作信息对象
           op=torch.cholesky_solve,  # 设置操作为 torch 中的 cholesky_solve 函数
           dtypes=floating_and_complex_types(),  # 指定支持的数据类型为浮点数和复数类型
           sample_inputs_func=sample_inputs_cholesky_solve,  # 设置样本输入函数为 cholesky_solve 的样本输入生成函数
           check_batched_gradgrad=False,  # 不检查批处理的梯度-梯度
           supports_forward_ad=True,  # 表明支持自动区分的前向传播
           supports_fwgrad_bwgrad=True,  # 表明支持前向和后向梯度传播
           # 设置 gradcheck_wrapper 为一个 lambda 函数，用于包装三角输入的梯度检查
           gradcheck_wrapper=lambda *args, **kwargs: gradcheck_wrapper_triangular_input(*args, idx=1, **kwargs),
           decorators=[skipCUDAIfNoMagma, skipCPUIfNoLapack],  # 添加装饰器用于跳过没有 Magma 的 CUDA 和没有 Lapack 的 CPU
           ),
    OpInfo('chunk',  # 创建一个名为 'chunk' 的操作信息对象
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),  # 指定支持的所有数据类型，包括特定类型
           sample_inputs_func=sample_inputs_chunk,  # 设置样本输入函数为 chunk 的样本输入生成函数
           reference_inputs_func=reference_inputs_chunk,  # 设置参考输入函数为 chunk 的参考输入生成函数
           supports_forward_ad=True,  # 表明支持自动区分的前向传播
           supports_fwgrad_bwgrad=True,  # 表明支持前向和后向梯度传播
           supports_out=False,  # 不支持输出
           ),
    OpInfo('unsafe_chunk',  # 创建一个名为 'unsafe_chunk' 的操作信息对象
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),  # 指定支持的所有数据类型，包括特定类型
           sample_inputs_func=sample_inputs_chunk,  # 设置样本输入函数为 chunk 的样本输入生成函数
           check_batched_forward_grad=False,  # 不检查批处理的前向梯度
           reference_inputs_func=reference_inputs_chunk,  # 设置参考输入函数为 chunk 的参考输入生成函数
           supports_forward_ad=True,  # 表明支持自动区分的前向传播
           supports_fwgrad_bwgrad=True,  # 表明支持前向和后向梯度传播
           supports_out=False,  # 不支持输出
           ),
    OpInfo('clone',  # 创建一个名为 'clone' 的操作信息对象
           ref=np.copy,  # 设置参考实现为 NumPy 的 copy 函数
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),  # 指定支持的所有数据类型，包括特定类型
           sample_inputs_func=sample_inputs_clone_contiguous,  # 设置样本输入函数为 clone 的样本输入生成函数
           reference_inputs_func=reference_inputs_clone_contiguous,  # 设置参考输入函数为 clone 的参考输入生成函数
           supports_forward_ad=True,  # 表明支持自动区分的前向传播
           supports_fwgrad_bwgrad=True,  # 表明支持前向和后向梯度传播
           supports_out=False,  # 不支持输出
           skips=(
               # 标记为跳过的测试用例，原因是 _copy_dispatcher() 函数不支持 'memory_format' 参数
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_numpy_ref'),
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_numpy_ref_mps'),
           ),
           ),
    OpInfo('contiguous',
           # 定义操作为 x.contiguous(*args, **kwargs)
           op=lambda x, *args, **kwargs: x.contiguous(*args, **kwargs),
           # 支持的数据类型包括所有类型以及 torch.bool, torch.bfloat16, torch.float16, torch.chalf
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
           # 生成样本输入函数为 sample_inputs_clone_contiguous
           sample_inputs_func=sample_inputs_clone_contiguous,
           # 生成参考输入函数为 reference_inputs_clone_contiguous
           reference_inputs_func=reference_inputs_clone_contiguous,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向梯度
           supports_fwgrad_bwgrad=True,
           # 自动微分可融合的节点包括 'aten::contiguous'
           autodiff_fusible_nodes=['aten::contiguous'],
           # 断言 JIT 形状分析为 True
           assert_jit_shape_analysis=True,
           # 不支持输出
           supports_out=False,
           # 跳过的测试包括 DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive')
           skips=(
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
           )),
    OpInfo('sum_to_size',
           # 定义操作为 x.sum_to_size(*args, **kwargs)
           op=lambda x, *args, **kwargs: x.sum_to_size(*args, **kwargs),
           # 支持的数据类型包括所有类型以及 torch.bool, torch.float16, torch.bfloat16
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),
           # 生成样本输入函数为 sample_inputs_sum_to_size
           sample_inputs_func=sample_inputs_sum_to_size,
           # 生成错误输入函数为 error_inputs_sum_to_size
           error_inputs_func=error_inputs_sum_to_size,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向梯度
           supports_fwgrad_bwgrad=True,
           # 不支持输出
           supports_out=False,
           # 跳过的测试包括 DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive") 和 DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float,))
           skips=(
               # lambda 实现
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float,)),
           )),
    OpInfo('clamp',
           # 别名包括 'clip'
           aliases=('clip',),
           # 参考实现为 _clamp_numpy
           ref=_clamp_numpy,
           # 支持的数据类型包括所有类型和 torch.bfloat16, torch.half
           dtypes=all_types_and(torch.bfloat16, torch.half),
           # 生成样本输入函数为 sample_inputs_clamp
           sample_inputs_func=sample_inputs_clamp,
           # 参考输入函数为 partial(reference_inputs_elementwise_ternary, sample_inputs_func=sample_inputs_clamp)
           reference_inputs_func=partial(reference_inputs_elementwise_ternary, sample_inputs_func=sample_inputs_clamp),
           # 断言自动微分为 True
           assert_autodiffed=True,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向梯度
           supports_fwgrad_bwgrad=True,
           # 跳过的测试包括 DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_nnc_correctness', dtypes=(torch.bool,))
           skips=(
               # NNC 似乎不处理布尔型 clamp
               DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_nnc_correctness', dtypes=(torch.bool,)),
           )),
    UnaryUfuncInfo('positive',
                   # 参考实现为 np.positive
                   ref=np.positive,
                   # 支持的数据类型包括所有类型和 torch.half, torch.bfloat16, torch.chalf
                   dtypes=all_types_and_complex_and(torch.half, torch.bfloat16, torch.chalf),
                   # 不支持输出
                   supports_out=False,
                   # 支持前向自动微分
                   supports_forward_ad=True,
                   # 支持前向和反向梯度
                   supports_fwgrad_bwgrad=True,
                   # 支持稀疏张量
                   supports_sparse=True,
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   ),
    # 创建 UnaryUfuncInfo 对象，用于描述一元操作函数的信息，此处为 'conj' 操作
    UnaryUfuncInfo('conj',
                   ref=np.conj,  # 引用 NumPy 的 conj 函数
                   dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16,
                                                    torch.half, torch.chalf),  # 支持的数据类型包括所有类型和复数类型
                   supports_sparse=True,  # 支持稀疏张量
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
                   # 查看 https://github.com/pytorch/pytorch/pull/78358
                   check_batched_forward_grad=False,  # 不检查批处理前向梯度
                   supports_out=False),  # 不支持输出张量指定
    
    # 创建 UnaryUfuncInfo 对象，描述 'conj_physical' 操作
    UnaryUfuncInfo('conj_physical',
                   decomp_aten_name='_conj_physical',  # 对应的 ATen 函数名
                   ref=np.conj,  # 引用 NumPy 的 conj 函数
                   dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16,
                                                    torch.half, torch.chalf),  # 支持的数据类型包括所有类型和复数类型
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
                   supports_sparse=True,  # 支持稀疏张量
                   supports_sparse_csr=True,  # 支持稀疏张量的 CSR 格式
                   supports_sparse_csc=True,  # 支持稀疏张量的 CSC 格式
                   supports_sparse_bsr=True,  # 支持稀疏张量的 BSR 格式
                   supports_sparse_bsc=True,  # 支持稀疏张量的 BSC 格式
                   skips=(
                       # 对于以下情况进行跳过：
                       DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32, )),
                       # 跳过的测试用例信息：unittest.skip("Skipped! conj_physical_ not implemented for sparse")
                       DecorateInfo(unittest.skip("Skipped! conj_physical_ not implemented for sparse"),
                                    'TestSparseUnaryUfuncs', 'test_inplace'),
                   )),
    
    # 创建 OpInfo 对象，描述 'resolve_conj' 操作
    OpInfo('resolve_conj',
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括所有类型和复数类型
           sample_inputs_func=sample_inputs_view_as_real,  # 样本输入函数为 sample_inputs_view_as_real
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           supports_out=False,  # 不支持输出张量指定
           ),
    
    # 创建 OpInfo 对象，描述 'resolve_neg' 操作
    OpInfo('resolve_neg',
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型包括所有类型和复数类型
           sample_inputs_func=sample_inputs_view_as_real,  # 样本输入函数为 sample_inputs_view_as_real
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           supports_out=False,  # 不支持输出张量指定
           ),
    
    # 创建 OpInfo 对象，描述 'view_as_real' 操作
    OpInfo('view_as_real',
           dtypes=complex_types(),  # 支持的数据类型为复数类型
           supports_forward_ad=True,  # 支持前向自动微分
           supports_out=False,  # 不支持输出张量指定
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           sample_inputs_func=sample_inputs_view_as_real,  # 样本输入函数为 sample_inputs_view_as_real
           test_conjugated_samples=False,  # 不测试共轭样本
           ),
    OpInfo('view_as_complex',
           # 定义操作名称和相关特性
           dtypes=floating_types_and(torch.half),
           # 不支持输出张量
           supports_out=False,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向梯度和反向梯度
           supports_fwgrad_bwgrad=True,
           # 不测试负数视图
           test_neg_view=False,
           # 定义用于生成样本输入的函数
           sample_inputs_func=sample_inputs_view_as_complex,
           # 跳过的测试用例列表
           skips=(
               # 当测试非连续样本时会抛出 RuntimeError: Tensor must have a last dimension with stride 1
               DecorateInfo(unittest.expectedFailure, "TestCommon", "test_noncontiguous_samples"),
               # 当操作涉及到 'ComplexHalf' 类型时，会抛出 RuntimeError: "eq_cpu" not implemented for 'ComplexHalf'
               DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo', 'test_nnc_correctness', dtypes=(torch.half,)),
               # 当视图大小与输入张量的大小和步长不兼容时会抛出 RuntimeError: view size is not compatible with input tensor's size and stride
               DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides"),
           )),
    BinaryUfuncInfo('complex',
                    # 定义操作名称和相关特性
                    dtypes=floating_types_and(torch.half),
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 支持前向梯度和反向梯度
                    supports_fwgrad_bwgrad=True,
                    # 不支持右侧的 Python 标量
                    supports_rhs_python_scalar=False,
                    # 定义错误输入的生成函数
                    error_inputs_func=error_inputs_complex,
                    # 跳过的测试用例列表
                    skips=(
                        # 测试未考虑到复数类型提升语义
                        DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),
                        # 在 MPS 设备上跳过该测试
                        DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_out', device_type='mps'),
                        # 测试二元ufuncs的混合数据类型时预期失败
                        DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_binary_ufuncs_mixed_dtype'),)),
    BinaryUfuncInfo('copysign',
                    # 定义操作名称和相关特性
                    dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
                    # 将整数提升为浮点数
                    promotes_int_to_float=True,
                    # 对梯度检查使用快速模式
                    gradcheck_fast_mode=True,
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 支持前向梯度和反向梯度
                    supports_fwgrad_bwgrad=True),
    OpInfo('corrcoef',
           # 定义操作名称和相关特性
           dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),
           # 定义用于生成样本输入的函数
           sample_inputs_func=sample_inputs_corrcoef,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向梯度和反向梯度
           supports_fwgrad_bwgrad=True,
           # 关闭批处理前向梯度检查
           check_batched_forward_grad=False,
           # 跳过的测试用例列表
           skips=(
               # 存在与 'conj' 和 torch 分派相关的问题，详情见 https://github.com/pytorch/pytorch/issues/82479
               DecorateInfo(
                   unittest.skip("Skipped!"),
                   'TestSchemaCheckModeOpInfo',
                   'test_schema_correctness',
                   dtypes=(torch.complex64, torch.complex128)),
           ),
           # 不支持输出张量
           supports_out=False),
    # 定义一个包含一元函数信息的对象，这里是 'cos'
    UnaryUfuncInfo('cos',
                   
                   # 参考实现使用 numpy 中的 cos 函数
                   ref=np.cos,
                   
                   # 适用的数据类型，包括所有类型和复数，以及指定的 torch 类型
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   
                   # 如果是 CUDA，适用的数据类型，包括所有类型和复数，以及指定的 torch 类型
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),
                   
                   # 断言自动微分已启用
                   assert_autodiffed=True,
                   
                   # 不支持大浮点数操作
                   handles_large_floats=False,
                   
                   # 支持前向自动微分
                   supports_forward_ad=True,
                   
                   # 支持前向后向自动微分
                   supports_fwgrad_bwgrad=True,
                   
                   # 将整数提升为浮点数
                   promotes_int_to_float=True,
                   
                   # 装饰器，用于 torch.bfloat16 数据类型的精度覆盖
                   decorators=(precisionOverride({torch.bfloat16: 1e-2}),),
                   
                   # 跳过的测试用例列表
                   skips=(
                       # 在 Windows 下，跳过指定条件的测试用例
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=(torch.cfloat, torch.cdouble,), device_type='cpu', active_if=IS_WINDOWS),
                                   
                       # 在 CUDA 下，跳过指定条件的测试用例，但在 ROCm 下通过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=(torch.cdouble,), device_type='cuda'),
                                   
                       # 在 Windows 下，跳过极端数值测试用例
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=[torch.cfloat, torch.cdouble], active_if=IS_WINDOWS),
                                   
                       # 在 macOS 下，跳过指定条件的 CPU 测试用例
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu',
                                    dtypes=[torch.cfloat, torch.cdouble], active_if=IS_MACOS),
                                   
                       # 在 Windows 下，CUDA 设备上的指定测试用例预期失败
                       DecorateInfo(unittest.expectedFailure, 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cuda',
                                    dtypes=(torch.chalf,), active_if=IS_WINDOWS),
                   )),
    UnaryUfuncInfo('cosh',
                   # 使用 np.cosh 函数作为参考实现的封装器
                   ref=np_unary_ufunc_integer_promotion_wrapper(np.cosh),
                   # 包含所有数据类型和复数类型，并且排除了 torch.bool, torch.half, torch.bfloat16
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 如果是 CUDA，包含所有数据类型和复数类型，并且包括了 torch.chalf, torch.bool, torch.half, torch.bfloat16
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),
                   # 断言自动微分被支持
                   assert_autodiffed=True,
                   # 支持正向自动微分
                   supports_forward_ad=True,
                   # 支持正反向传播梯度
                   supports_fwgrad_bwgrad=True,
                   # 将整数提升为浮点数
                   promotes_int_to_float=True,
                   # 跳过以下测试用例
                   skips=(
                       # 参考：https://github.com/pytorch/pytorch/issues/48641
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=[torch.int8]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=[torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=[torch.cfloat, torch.cdouble], active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=[torch.cfloat, torch.cdouble], active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu',
                                    dtypes=[torch.cfloat, torch.cdouble], active_if=IS_MACOS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu',
                                    dtypes=[torch.cfloat, torch.cdouble], active_if=IS_MACOS),
                       # 预期 AssertionError: 张量不接近！
                       # 最大的绝对差异: 在索引 (6000,) 处为 nan (允许最大 1e-05)
                       # 最大的相对差异: 在索引 (6000,) 处为 nan (允许最大 0.001)
                       DecorateInfo(unittest.expectedFailure, 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cuda',
                                    dtypes=(torch.chalf,), active_if=IS_WINDOWS),
                   )),
    OpInfo('cov',  # 创建一个名为 'cov' 的 OpInfo 对象
           dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),  # 指定支持的数据类型
           sample_inputs_func=sample_inputs_cov,  # 设置样本输入函数为 sample_inputs_cov
           error_inputs_func=error_inputs_cov,  # 设置错误输入函数为 error_inputs_cov
           supports_out=False,  # 不支持输出
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           skips=(  # 定义需要跳过的测试装饰器元组
               # Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479
               DecorateInfo(
                   unittest.skip("Skipped!"),  # 使用 unittest.skip 装饰器跳过测试
                   'TestSchemaCheckModeOpInfo',  # 测试类名
                   'test_schema_correctness',  # 测试方法名
                   dtypes=(torch.complex64, torch.complex128)),  # 指定测试的数据类型
               # Float did not match double
               DecorateInfo(unittest.expectedFailure, 'TestBwdGradients', 'test_fn_grad'),  # 使用 unittest.expectedFailure 装饰器标记预期的测试失败
               # Jacobian mismatch
               DecorateInfo(unittest.expectedFailure, 'TestBwdGradients', 'test_fn_gradgrad'),  # 使用 unittest.expectedFailure 装饰器标记预期的测试失败
               DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', 'test_forward_mode_AD'),  # 使用 unittest.expectedFailure 装饰器标记预期的测试失败
               DecorateInfo(unittest.skip("Barely fails"), 'TestFwdGradients', 'test_fn_fwgrad_bwgrad'),  # 使用 unittest.skip 装饰器跳过测试
               # JIT test not working for tensor kwargs (https://github.com/pytorch/pytorch/issues/58507)
               # RuntimeError:
               # undefined value tensor:
               #   File "<string>", line 3
               # def the_method(i0):
               #     return torch.cov(i0, correction=0, fweights=None, aweights=tensor([0.0518, 0.4681], dtype=torch.float32, requires_grad=True)) # noqa: B950
               #                                                                ~~~~~~ <--- HERE
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 使用 unittest.expectedFailure 装饰器标记预期的测试失败
           )),
    OpInfo('cross',  # 创建一个名为 'cross' 的 OpInfo 对象
           dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),  # 指定支持的数据类型
           sample_inputs_func=sample_inputs_cross,  # 设置样本输入函数为 sample_inputs_cross
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           supports_out=True,  # 支持输出
           supports_forward_ad=True),  # 支持前向自动微分
    OpInfo('cumsum',  # 创建一个名为 'cumsum' 的 OpInfo 对象
           dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),  # 指定支持的数据类型
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           skips=(  # 定义需要跳过的测试装饰器元组
               # cumsum does not handle correctly out= dtypes
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),  # 使用 unittest.expectedFailure 装饰器标记预期的测试失败
           ),
           sample_inputs_func=sample_inputs_cumulative_ops),  # 设置样本输入函数为 sample_inputs_cumulative_ops
    OpInfo('cumprod',  # 创建一个名为 'cumprod' 的 OpInfo 对象
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),  # 指定支持的数据类型
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           skips=(  # 定义需要跳过的测试装饰器元组
               # cumprod does not handle correctly out= dtypes
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),  # 使用 unittest.expectedFailure 装饰器标记预期的测试失败
           ),
           # gradgradcheck fails in fast_mode=True: #56275
           sample_inputs_func=sample_inputs_cumprod,  # 设置样本输入函数为 sample_inputs_cumprod
           gradcheck_fast_mode=False),  # 关闭快速模式的梯度检查
    OpInfo('cummax',  # 定义名为 'cummax' 的操作信息对象
           dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型
           sample_inputs_func=partial(sample_inputs_cumulative_ops, supports_dtype_kwargs=False),  # 样本输入函数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           skips=(  # 跳过的测试集
           ),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL),  # 梯度检查的非确定性容差值

    OpInfo('cummin',  # 定义名为 'cummin' 的操作信息对象
           dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型
           sample_inputs_func=partial(sample_inputs_cumulative_ops, supports_dtype_kwargs=False),  # 样本输入函数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           skips=(  # 跳过的测试集
           ),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL),  # 梯度检查的非确定性容差值

    UnaryUfuncInfo('deg2rad',  # 定义名为 'deg2rad' 的一元通用函数信息对象
                   ref=np.radians,  # 参考实现为 numpy 中的 radians 函数
                   decorators=(precisionOverride({torch.bfloat16: 7e-1,
                                                  torch.float16: 7e-1}),),  # 修饰器，用于不同精度的浮点数
                   dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
                   supports_sparse=True,  # 支持稀疏张量
                   supports_sparse_csr=True,  # 支持 CSR 格式的稀疏张量
                   supports_sparse_csc=True,  # 支持 CSC 格式的稀疏张量
                   supports_sparse_bsr=True,  # 支持 BSR 格式的稀疏张量
                   supports_sparse_bsc=True,  # 支持 BSC 格式的稀疏张量
                   promotes_int_to_float=True),  # 将整数提升为浮点数

    OpInfo('diff',  # 定义名为 'diff' 的操作信息对象
           op=torch.diff,  # 操作为 torch 中的 diff 函数
           # np.diff 的默认值为 np._NoValue，如果 prepend 和 append 设置为 None，则会导致与参考实现的比较出错
           ref=lambda input, n=1, dim=-1, prepend=np._NoValue, append=np._NoValue: (
               np.diff(input, n, dim, np._NoValue if prepend is None else prepend, np._NoValue if append is None else append)
           ),
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型
           gradcheck_fast_mode=True,  # 在快速梯度检查模式下运行（用于慢速运行的 gradcheck）
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           sample_inputs_func=sample_inputs_diff,  # 样本输入函数
           error_inputs_func=error_inputs_diff,  # 错误输入函数
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           skips=(  # 跳过的测试集
           )),
    # 创建 BinaryUfuncInfo 对象，表示除法操作
    BinaryUfuncInfo('div',
                    # 别名包括 'divide'
                    aliases=('divide',),
                    # 变体测试名称为 'no_rounding_mode'
                    variant_test_name='no_rounding_mode',
                    # 适用的数据类型包括所有标准类型以及 torch.bool, torch.half, torch.bfloat16
                    dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                    # 如果是 CUDA，还包括 torch.chalf 类型
                    dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
                    # 在慢速梯度检查上运行速度很慢 - 可以减小输入大小来代替
                    gradcheck_fast_mode=True,
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 支持前向-后向自动微分
                    supports_fwgrad_bwgrad=True,
                    # 支持两个 Python 标量的操作
                    supports_two_python_scalars=True,
                    # 断言已进行自动微分
                    assert_autodiffed=True,
                    # 右侧操作数生成张量的参数，排除零值
                    rhs_make_tensor_kwargs=dict(exclude_zero=True),),
    # 创建另一个 BinaryUfuncInfo 对象，表示除法操作
    BinaryUfuncInfo('div',
                    # 别名包括 'divide'
                    aliases=('divide',),
                    # 变体测试名称为 'trunc_rounding'
                    variant_test_name='trunc_rounding',
                    # 适用的数据类型包括 torch.half, torch.bfloat16
                    dtypes=all_types_and(torch.half, torch.bfloat16),
                    # 用于生成样本输入的函数，部分应用的参数包括 'rounding_mode="trunc"'
                    sample_inputs_func=partial(sample_inputs_elementwise_binary, sample_kwargs=dict(rounding_mode="trunc")),
                    # 针对的 GitHub 问题链接，处理速度慢的梯度检查
                    gradcheck_fast_mode=True,
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 支持前向-后向自动微分
                    supports_fwgrad_bwgrad=True,
                    # 支持两个 Python 标量的操作
                    supports_two_python_scalars=True,
                    # 断言已进行自动微分
                    assert_autodiffed=True,
                    # 右侧操作数生成张量的参数，排除零值
                    rhs_make_tensor_kwargs=dict(exclude_zero=True),
                    # 装饰器包括的信息，用于预期失败的测试情况
                    decorators=(
                        # 查看 GitHub 问题链接，解决类型提升的问题
                        DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),
                    ),
                    # 跳过的情况，针对特定的运行时错误
                    skips=(
                        # 运行时错误: MALFORMED INPUT: Unhandled node kind (in computeValue): aten::div
                        DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_working'),
                    )),
    BinaryUfuncInfo('div',  # 创建 BinaryUfuncInfo 对象，表示除法运算的信息
                    aliases=('divide',),  # 别名为 'divide'
                    variant_test_name='floor_rounding',  # 变体测试名称为 'floor_rounding'
                    dtypes=all_types_and(torch.half, torch.bfloat16),  # 支持所有数据类型和 torch.half, torch.bfloat16
                    sample_inputs_func=partial(sample_inputs_elementwise_binary, sample_kwargs=dict(rounding_mode="floor")),  # 使用特定的采样函数和参数字典来生成样本输入
                    # GitHub 上的问题链接：https://github.com/pytorch/pytorch/issues/80411
                    gradcheck_fast_mode=True,  # 使用快速模式进行梯度检查
                    supports_forward_ad=True,  # 支持前向自动求导
                    supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
                    supports_two_python_scalars=True,  # 支持两个 Python 标量的操作
                    assert_autodiffed=True,  # 自动推断断言为真
                    rhs_make_tensor_kwargs=dict(exclude_zero=True),  # 右操作数生成张量的参数字典，排除零值
                    decorators=(
                        # 查看 https://github.com/pytorch/pytorch/issues/111126
                        DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),  # 使用装饰器标记的测试信息，预期是失败的测试
                    ),
                    skips=(
                        # 运行时错误：MALFORMED INPUT: Unhandled node kind (in computeValue): aten::div
                        DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_working'),  # 使用装饰器标记的跳过信息，预期是失败的测试
                    )),
    BinaryUfuncInfo('true_divide',  # 创建 BinaryUfuncInfo 对象，表示真除法运算的信息
                    dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持所有数据类型、复数以及 torch.bool, torch.half, torch.bfloat16
                    dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 如果是 CUDA，则支持的数据类型扩展
                    supports_forward_ad=True,  # 支持前向自动求导
                    promotes_int_to_float=True,  # 将整数提升为浮点数
                    supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
                    supports_two_python_scalars=True,  # 支持两个 Python 标量的操作
                    rhs_make_tensor_kwargs=dict(exclude_zero=True)),  # 右操作数生成张量的参数字典，排除零值
    OpInfo('equal',  # 创建 OpInfo 对象，表示等于运算的信息
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持所有数据类型、复数以及 torch.bool, torch.float16, torch.bfloat16
           ref=lambda input, other: (input == other).all(),  # 参考实现为所有元素是否相等
           sample_inputs_func=sample_inputs_equal,  # 使用特定的采样函数生成等于运算的样本输入
           supports_autograd=False,  # 不支持自动求导
           supports_tracing=False,  # 不支持跟踪
           skips=(
           )),  # 跳过的测试信息为空
    UnaryUfuncInfo('exp',
                   # 设置对应的 NumPy 参考函数及其包装器
                   ref=np_unary_ufunc_integer_promotion_wrapper(np.exp),
                   # 涵盖所有数据类型及复数类型，以及特定的 Torch 数据类型（bool、half、bfloat16）
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 如果在 CUDA 下，也支持额外的 Torch 数据类型
                   dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
                   skips=(
                       # 标记一些需要跳过的测试用例，参考 GitHub issue 的相关信息
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                   ),
                   assert_autodiffed=True,  # 断言自动微分功能正常工作
                   supports_forward_ad=True,  # 支持正向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向和后向自动微分
                   promotes_int_to_float=True),  # 支持整数提升为浮点数
    
    OpInfo('expand',
           # 定义操作及其对应的 Torch 实现
           op=lambda self, shape: self.expand(shape),
           # 涵盖所有数据类型及复数类型，以及特定的 Torch 数据类型（bool、half、bfloat16）
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
           sample_inputs_func=sample_inputs_expand,  # 提供用于扩展操作的样本输入函数
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向自动微分
           assert_jit_shape_analysis=True,  # 断言 JIT 形状分析功能正常
           supports_out=False,  # 不支持输出参数
           skips=(
               # 标记一些需要跳过的测试用例，使用 unittest 的预期失败装饰器
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
           )),
    
    OpInfo('expand_as',
           # 定义操作及其对应的 Torch 实现
           op=lambda self, other: self.expand_as(other),
           # 涵盖所有数据类型及复数类型，以及特定的 Torch 数据类型（bool、half、bfloat16）
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向自动微分
           sample_inputs_func=sample_inputs_expand_as,  # 提供用于扩展操作的样本输入函数
           supports_out=False,  # 不支持输出参数
           skips=(
               # 标记一些需要跳过的测试用例，使用 unittest 的预期失败装饰器
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
           )),
    
    OpInfo('diag',
           # 设置对应的 NumPy 参考函数
           ref=np.diag,
           # 涵盖所有数据类型及复数类型，以及特定的 Torch 数据类型（bool、bfloat16、float16）
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),
           # 如果在 CUDA 下，也支持额外的 Torch 数据类型
           dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向自动微分
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           sample_inputs_func=sample_inputs_diag,  # 提供用于对角操作的样本输入函数
           error_inputs_func=error_inputs_diag),  # 提供用于对角操作的错误输入函数
    OpInfo('diag_embed',
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
           supports_out=False,
           # 在慢速梯度检查时运行非常缓慢 - 或者可以减少输入大小作为替代
           gradcheck_fast_mode=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           sample_inputs_func=sample_inputs_diagonal_diag_embed,
           reference_inputs_func=reference_inputs_diagonal_diag_embed,
           error_inputs_func=error_inputs_diagonal_diag_embed),
    # 定义对角线操作信息，包括对应的反向操作名称
    OpInfo('diagonal',
           aten_backward_name='diagonal_backward',
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           sample_inputs_func=sample_inputs_diagonal_diag_embed,
           reference_inputs_func=reference_inputs_diagonal_diag_embed,
           error_inputs_func=error_inputs_diagonal_diag_embed),
    # 定义对角线复制操作信息
    OpInfo('diagonal_copy',
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           sample_inputs_func=sample_inputs_diagonal_diag_embed,
           reference_inputs_func=reference_inputs_diagonal_diag_embed,
           error_inputs_func=error_inputs_diagonal_diag_embed),
    # 定义对角线散列操作信息
    OpInfo('diagonal_scatter',
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           sample_inputs_func=sample_inputs_diagonal_scatter),
    # 定义别名复制操作信息
    OpInfo('alias_copy',
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
           sample_inputs_func=sample_inputs_alias_copy,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True),
    # 定义等值操作信息
    BinaryUfuncInfo('eq',
                    ref=np.equal,
                    dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
                    always_returns_bool=True,
                    supports_autograd=False,
                    sample_inputs_func=sample_inputs_comparison_ops,
                    skips=(
                    )),
    # 定义最大值操作信息
    BinaryUfuncInfo('fmax',
                    op=torch.fmax,
                    dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),
                    supports_forward_ad=True,
                    supports_fwgrad_bwgrad=True,
                    supports_rhs_python_scalar=False,
                    skips=(
                        # RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs', 'test_type_promotion'),
                    )),
    BinaryUfuncInfo('fmin',
                    op=torch.fmin,
                    dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),
                    supports_forward_ad=True,
                    supports_fwgrad_bwgrad=True,
                    supports_rhs_python_scalar=False,
                    skips=(
                        # 在 'ComplexFloat' 类型上未实现 "min_elementwise_cuda"，因此跳过测试
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs', 'test_type_promotion'),
                    )),
    BinaryUfuncInfo('fmod',
                    ref=np.fmod,
                    dtypes=all_types_and(torch.float16, torch.bfloat16),
                    dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),
                    # issue链接: https://github.com/pytorch/pytorch/issues/80411
                    gradcheck_fast_mode=True,
                    supports_forward_ad=True,
                    supports_fwgrad_bwgrad=True,
                    assert_autodiffed=None,
                    rhs_make_tensor_kwargs={'exclude_zero': True},
                    decorators=(
                        # 跳过以下测试用例，因为在 torch.bfloat16 类型上未实现对应功能
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                                     'test_contig_vs_every_other',
                                     dtypes=(torch.bfloat16,)),
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                                     'test_non_contig',
                                     dtypes=(torch.bfloat16,)),
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                                     'test_reference_numerics',
                                     dtypes=(torch.bfloat16,)),
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                                     'test_reference_numerics_small_values',
                                     dtypes=(torch.uint8,)),
                    )),
    # 创建一个 BinaryUfuncInfo 对象，用于描述二进制函数的信息，这里是 'remainder'
    BinaryUfuncInfo('remainder',
                    # 引用的函数来自 numpy 的 remainder 函数
                    ref=np.remainder,
                    # 所有数据类型和 torch.float16, torch.bfloat16 的交集
                    dtypes=all_types_and(torch.float16, torch.bfloat16),
                    # 如果是 CUDA，支持的数据类型是所有数据类型和 torch.float16, torch.bfloat16 的交集
                    dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),
                    # 设置为 True，用于快速梯度检查模式
                    gradcheck_fast_mode=True,
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 支持前向后向梯度
                    supports_fwgrad_bwgrad=True,
                    # 自动微分后进行断言的设置，这里为 None
                    assert_autodiffed=None,
                    # 使用 operator 模块的 mod 运算符变量
                    operator_variant=operator.mod,
                    # 使用 operator 模块的 imod 运算符变量，原地操作
                    inplace_operator_variant=operator.imod,
                    # 支持使用一个 Python 标量进行张量运算
                    supports_one_python_scalar=True,
                    # 右操作数为张量时的参数设置，排除零值的情况
                    rhs_make_tensor_kwargs={'exclude_zero': True},
                    # 修饰器设置，包含多个 DecorateInfo 对象的元组
                    decorators=(
                        # 装饰器信息：跳过测试，测试类为 'TestBinaryUfuncs'，测试方法为 'test_contig_vs_every_other'，数据类型为 torch.bfloat16
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                                     'test_contig_vs_every_other',
                                     dtypes=(torch.bfloat16,)),
                        # 装饰器信息：跳过测试，测试类为 'TestBinaryUfuncs'，测试方法为 'test_non_contig'，数据类型为 torch.bfloat16
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                                     'test_non_contig',
                                     dtypes=(torch.bfloat16,)),
                        # 装饰器信息：跳过测试，测试类为 'TestBinaryUfuncs'，测试方法为 'test_reference_numerics'，数据类型为 torch.bfloat16
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                                     'test_reference_numerics',
                                     dtypes=(torch.bfloat16,)),
                        # 装饰器信息：跳过测试，测试类为 'TestBinaryUfuncs'，测试方法为 'test_reference_numerics_small_values'，数据类型为 torch.uint8
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                                     'test_reference_numerics_small_values',
                                     dtypes=(torch.uint8,)),
                        # 装饰器信息：跳过测试，测试类为 'TestNNCOpInfo'，测试方法为 'test_nnc_correctness'，数据类型为 torch.bfloat16
                        DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo',
                                     'test_nnc_correctness',
                                     dtypes=(torch.bfloat16,)),
                        # 装饰器信息：跳过测试，测试类为 'TestOpInfo'，设备类型为 'xla'，数据类型为 torch.long
                        DecorateInfo(unittest.skip("Skipped!"), 'TestOpInfo', device_type='xla', dtypes=(torch.long,)),
                    )),
    # 定义 UnaryUfuncInfo 对象，表示一元函数的信息，这里是 'frac'
    UnaryUfuncInfo('frac',
                   # 引用函数定义，计算输入张量的分数部分
                   ref=lambda x: np.modf(x)[0],
                   # 支持的数据类型为浮点类型以及 torch 中的半精度浮点类型
                   dtypes=floating_types_and(torch.bfloat16, torch.float16),
                   # 如果是 CUDA 加速的话，支持的数据类型是半精度浮点和 bfloat16
                   dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
                   # 断言自动微分已启用
                   assert_autodiffed=True,
                   # 支持前向自动微分
                   supports_forward_ad=True,
                   # 支持前向-后向自动微分
                   supports_fwgrad_bwgrad=True,
                   # 支持稀疏张量
                   supports_sparse=True,
                   # 支持 CSR 格式的稀疏张量
                   supports_sparse_csr=True,
                   # 支持 CSC 格式的稀疏张量
                   supports_sparse_csc=True,
                   # 支持 BSR 格式的稀疏张量
                   supports_sparse_bsr=True,
                   # 支持 BSC 格式的稀疏张量
                   supports_sparse_bsc=True,
                   # 跳过的测试信息
                   skips=(
                       # 在指定的测试中跳过，提示信息为 "Skipped!"
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    # 支持的数据类型包括 bfloat16, float16, float32, float64
                                    dtypes=(torch.bfloat16, torch.float16, torch.float32, torch.float64)),
                       # 76047
                       # 预期测试失败的装饰信息，提示信息为 unittest.expectedFailure
                       DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_nnc_correctness',
                                    # 支持的数据类型包括 bfloat16, float32, float64
                                    dtypes=(torch.bfloat16, torch.float32, torch.float64)),
                   )),
    # 定义 OpInfo 对象，表示操作的信息，这里是 'stft'
    OpInfo('stft',
           # 装饰器函数列表，如果没有 FFT 支持则跳过
           decorators=[
               skipCPUIfNoFFT,
               # 在指定的测试中跳过，提示信息为 "Skipped! stft does not match the native function"
               DecorateInfo(unittest.skip("Skipped! stft does not match the native function"),
                            'TestJit', 'test_variant_consistency_jit'),
           ],
           # 支持的数据类型为浮点和复数类型
           dtypes=floating_and_complex_types(),
           # 获取样本输入函数
           sample_inputs_func=sample_inputs_stft,
           # 在慢速 gradcheck 下运行较慢 - 可以选择减少输入大小来加速
           gradcheck_fast_mode=True,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向-后向自动微分
           supports_fwgrad_bwgrad=True,
           # 不检查批处理前向梯度
           check_batched_forward_grad=False,
           # 不检查批处理梯度
           check_batched_grad=False,
           # 不检查批处理二阶梯度
           check_batched_gradgrad=False,
           # 不支持输出参数
           supports_out=False,
           # gradcheck 的非确定性容差值
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           ),
    # 定义 OpInfo 对象，表示操作的信息，这里是 'istft'
    OpInfo('istft',
           # 支持的数据类型为复数类型
           dtypes=complex_types(),
           # 获取样本输入函数
           sample_inputs_func=sample_inputs_istft,
           # 在慢速 gradcheck 下运行较慢 - 可以选择减少输入大小来加速
           gradcheck_fast_mode=True,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向-后向自动微分
           supports_fwgrad_bwgrad=True,
           # 不检查批处理前向梯度
           check_batched_forward_grad=False,
           # 不检查批处理梯度
           check_batched_grad=False,
           # 不检查批处理二阶梯度
           check_batched_gradgrad=False,
           # 不支持输出参数
           supports_out=False,
           # 装饰器列表
           decorators=(
               # 在指定的测试中跳过，提示信息为 "Skipped! istft does not match the native function"
               DecorateInfo(unittest.skip("Skipped! istft does not match the native function"),
                            'TestJit', 'test_variant_consistency_jit'),
           ),
           # 跳过的测试信息
           skips=(
               # 如果没有 FFT 支持则跳过
               skipCPUIfNoFFT,
               # 在 ROCm 平台上 gradcheck 失败 (gh-68429)
               # 权重张量的梯度计算错误
               DecorateInfo(unittest.expectedFailure, 'TestBwdGradients', 'test_fn_grad'),
               # 存在预先存在的条件问题 (调用 .item); 需要修复
               DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_backward'),
           )),
    UnaryUfuncInfo('floor',  # 定义一元ufunc信息，用于向下取整操作
                   ref=np.floor,  # 参考实现为NumPy的向下取整函数
                   dtypes=all_types_and(torch.half, torch.bfloat16),  # 支持的数据类型包括半精度和bfloat16
                   supports_forward_ad=True,  # 支持前向自动求导
                   supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度的计算
                   skips=(  # 跳过的测试条件
                       DecorateInfo(unittest.expectedFailure,  # 使用unittest的expectedFailure装饰器
                                    'TestNNCOpInfo',  # 测试类名称
                                    'test_nnc_correctness',  # 测试方法名称
                                    dtypes=tuple(t for t in integral_types() if t != torch.uint8)),  # 整型类型，但不包括uint8
                   ),
                   supports_sparse=True,  # 支持稀疏张量
                   supports_sparse_csr=True,  # 支持CSR格式的稀疏张量
                   supports_sparse_csc=True,  # 支持CSC格式的稀疏张量
                   supports_sparse_bsr=True,  # 支持BSR格式的稀疏张量
                   supports_sparse_bsc=True,  # 支持BSC格式的稀疏张量
                   assert_autodiffed=True),  # 断言自动求导的正确性

    OpInfo('flip',  # 定义操作信息，用于张量翻转操作
           op=torch.flip,  # 实现操作为torch库中的flip函数
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括复数、布尔型、半精度和bfloat16
           sample_inputs_func=sample_inputs_flip,  # 提供样本输入的函数
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度的计算
           supports_out=False),  # 不支持out参数

    OpInfo('fliplr',  # 定义操作信息，用于左右翻转操作
           op=torch.fliplr,  # 实现操作为torch库中的fliplr函数
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括复数、布尔型、半精度和bfloat16
           sample_inputs_func=sample_inputs_fliplr_flipud,  # 提供样本输入的函数
           error_inputs_func=error_inputs_fliplr,  # 提供错误输入的函数
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度的计算
           supports_out=False),  # 不支持out参数

    OpInfo('flipud',  # 定义操作信息，用于上下翻转操作
           op=torch.flipud,  # 实现操作为torch库中的flipud函数
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括复数、布尔型、半精度和bfloat16
           sample_inputs_func=sample_inputs_fliplr_flipud,  # 提供样本输入的函数
           error_inputs_func=error_inputs_flipud,  # 提供错误输入的函数
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度的计算
           supports_out=False),  # 不支持out参数

    UnaryUfuncInfo('i0',  # 定义一元ufunc信息，用于修改后的贝塞尔函数i0操作
                   ref=np_unary_ufunc_integer_promotion_wrapper(  # 参考实现为NumPy的整数提升包装后的i0函数
                       scipy.special.i0) if TEST_SCIPY else None,  # 如果测试中使用了SciPy，则使用SciPy中的i0函数，否则为None
                   aliases=('special.i0',),  # 别名为special.i0
                   decorators=(precisionOverride({torch.bfloat16: 3e-1,  # 精度覆盖装饰器，对bfloat16设置精度
                                                  torch.float16: 5e-1}),),  # 对float16设置精度
                   dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括布尔型、半精度和bfloat16
                   backward_dtypes=floating_types(),  # 后向传播时支持的数据类型为浮点数类型
                   supports_forward_ad=True,  # 支持前向自动求导
                   supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度的计算
                   promotes_int_to_float=True,  # 将整数提升为浮点数
                   sample_inputs_func=sample_inputs_i0_i1,  # 提供样本输入的函数
                   skips=(  # 跳过的测试条件
                       DecorateInfo(unittest.skip("Skipped!"),  # 使用unittest的skip装饰器
                                    'TestUnaryUfuncs',  # 测试类名称
                                    'test_reference_numerics_large',  # 测试方法名称
                                    dtypes=(torch.int8,)),  # 数据类型为torch.int8
                   )),
    BinaryUfuncInfo('floor_divide',  # 创建一个 BinaryUfuncInfo 对象，名称为 'floor_divide'
                    ref=_floor_divide_np,  # 使用 _floor_divide_np 作为参考实现
                    dtypes=all_types_and(torch.half, torch.bfloat16),  # 支持所有类型和 torch.half、torch.bfloat16
                    supports_autograd=False,  # 不支持自动求导
                    rhs_make_tensor_kwargs=dict(exclude_zero=True),  # 右操作数创建张量的参数，排除零值
                    supports_two_python_scalars=True,  # 支持两个 Python 标量的操作
                    skips=(  # 跳过以下测试用例
                        # 原始模型和导出/导入版本模型结果不一致导致的 AssertionError
                        DecorateInfo(unittest.skip('Skipped!'), 'TestJit', 'test_variant_consistency_jit'),
                        # bfloat16 的 floor_divide 与 float32 参考结果不一致时的跳过
                        DecorateInfo(unittest.skip('Skipped!'), 'TestBinaryUfuncs',
                                     dtypes=(torch.bfloat16,)),
                        # int8 的 floor divide 在 -128 // -1 与 NumPy 结果不同时的跳过
                        DecorateInfo(unittest.skip('Skipped!'), 'TestBinaryUfuncs', 'test_reference_numerics_small_values',
                                     dtypes=(torch.int8,)),
                        # 以下测试在某些任务上失败
                        DecorateInfo(unittest.skip('Skipped!'), 'TestBinaryUfuncs', 'test_reference_numerics_extremal_values',
                                     dtypes=(torch.float16,)),
                        # 对于 test_reference_numerics 测试，使用 torch.float16 的容差覆盖
                        DecorateInfo(toleranceOverride({torch.float16: tol(atol=1e-3, rtol=5e-3)}),
                                     'TestBinaryUfuncs', 'test_reference_numerics'),
                    )),
    # 定义一个描述一元函数的信息对象，函数名称为 'frexp'
    UnaryUfuncInfo('frexp',
                   # 操作符为 torch.frexp
                   op=torch.frexp,
                   # 参考实现为 np.frexp
                   ref=np.frexp,
                   # 支持的数据类型包括浮点类型和 torch.half、torch.bfloat16
                   dtypes=floating_types_and(torch.half, torch.bfloat16),
                   # 如果在 CUDA 下，则支持的数据类型仅为浮点类型和 torch.half
                   dtypesIfCUDA=floating_types_and(torch.half),
                   # 装饰器为空列表，表示没有额外的修饰器
                   decorators=[],
                   # 支持正向自动求导
                   supports_forward_ad=True,
                   # 支持正向反向自动求导
                   supports_fwgrad_bwgrad=True,
                   # 跳过以下测试，因为 torch.frexp 返回类似元组 (mantissa, exponent) 的输出，
                   # 而这些测试当前需要输出为单个张量
                   skips=(
                       # 跳过测试 'test_batch_vs_slicing'，标记为跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_batch_vs_slicing'),
                       # 跳过测试 'test_contig_vs_every_other'，标记为跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_contig_vs_every_other'),
                       # 跳过测试 'test_contig_vs_transposed'，标记为跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_contig_vs_transposed'),
                       # 跳过测试 'test_non_contig_expand'，标记为跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_non_contig_expand'),
                       # 跳过测试 'test_variant_consistency'，标记为跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_variant_consistency'),
                       # 跳过测试 'test_out_arg_all_dtypes'，标记为跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_out_arg_all_dtypes'),

                       # 因 Windows CI 中出现错误，跳过测试 'test_reference_numerics_small'
                       # 因为 np.frexp 在 Windows 平台上返回 np.intc 类型的指数，
                       # 而 np.intc 在 torch 中没有对应的数据类型
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_small',
                                    active_if=IS_WINDOWS),
                       # 跳过测试 'test_reference_numerics_large'，标记为跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    active_if=IS_WINDOWS),
                       # 跳过测试 'test_reference_numerics_extremal'，标记为跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    active_if=IS_WINDOWS),
                   )),
    # 定义一个描述一元函数的信息对象，函数名称为 'log1p'
    UnaryUfuncInfo('log1p',
                   # 参考实现为 np.log1p
                   ref=np.log1p,
                   # 别名为 'special.log1p'
                   aliases=('special.log1p',),
                   # 定义域为 (-1, 正无穷)
                   domain=(-1, None),
                   # 支持所有数据类型，包括复数和 torch.bool、torch.half、torch.bfloat16
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 使用 precisionOverride 装饰器来覆盖 torch.bfloat16 的精度
                   decorators=(precisionOverride({torch.bfloat16: 1e-1}),),
                   # 支持正向自动求导
                   supports_forward_ad=True,
                   # 支持正向反向自动求导
                   supports_fwgrad_bwgrad=True,
                   # 支持稀疏张量
                   supports_sparse=True,
                   # 支持稀疏 CSR 格式的张量
                   supports_sparse_csr=True,
                   # 支持稀疏 CSC 格式的张量
                   supports_sparse_csc=True,
                   # 支持稀疏 BSR 格式的张量
                   supports_sparse_bsr=True,
                   # 支持稀疏 BSC 格式的张量
                   supports_sparse_bsc=True,
                   # 自动微分后进行断言检查
                   assert_autodiffed=True,
                   # 将整数提升为浮点数
                   promotes_int_to_float=True),
    # 创建 BinaryUfuncInfo 对象，表示二元函数的信息，这里是 'ge' (greater_equal) 函数
    BinaryUfuncInfo('ge',
                    ref=np.greater_equal,
                    aliases=('greater_equal',),
                    dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16),
                    always_returns_bool=True,
                    supports_autograd=False,
                    skips=(
                    )),
    # 创建 OpInfo 对象，表示特定操作的信息，这里是 'geqrf' QR 分解操作
    OpInfo('geqrf',
           dtypes=floating_and_complex_types(),
           sample_inputs_func=sample_inputs_linalg_qr_geqrf,
           decorators=[skipCUDAIfNoMagmaAndNoCusolver, skipCPUIfNoLapack],
           supports_autograd=False,
           skips=(
               # FIXME: geqrf can't forward with complex inputs that require grad
               # 表明 geqrf 操作在处理需要梯度的复数输入时无法前向传播
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_dtypes'),
               # Strides are not the same!
               # 表明在某些情况下，geqrf 操作的步幅不一致导致测试预期失败
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
           )),
    # 创建 BinaryUfuncInfo 对象，表示二元函数的信息，这里是 'gt' (greater) 函数
    BinaryUfuncInfo('gt',
                    ref=np.greater,
                    aliases=('greater',),
                    dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16),
                    always_returns_bool=True,
                    supports_autograd=False,
                    skips=(
                    )),
    # 创建 UnaryUfuncInfo 对象，表示一元函数的信息，这里是 'imag' (imaginary part) 函数
    UnaryUfuncInfo('imag',
                   ref=np.imag,
                   dtypes=complex_types_and(torch.chalf),
                   supports_out=False,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   # See https://github.com/pytorch/pytorch/issues/66357
                   # RuntimeError: view_as_real doesn't work on unresolved conjugated tensors.
                   # 查看链接中的问题描述，说明在未解析的共轭张量上，view_as_real 函数会出现运行时错误
                   check_batched_forward_grad=False,
                   skips=(
                       # Skip since real and imag don't have out variants.
                       # 由于 real 和 imag 函数没有 out 变体，所以跳过这个测试
                       DecorateInfo(unittest.expectedFailure, 'TestUnaryUfuncs', 'test_out_arg_all_dtypes'),
                   )),
    # 定义 OpInfo 对象，用于描述 PyTorch 操作 'gradient'
    OpInfo('gradient',
           # 支持的数据类型包括浮点数和复数类型以及整型 torch.int8, torch.int16, torch.int32, torch.int64,
           # torch.bfloat16, torch.half
           dtypes=floating_and_complex_types_and(torch.int8, torch.int16,
                                                 torch.int32, torch.int64,
                                                 torch.bfloat16, torch.half),
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           # 查看相关讨论链接，禁用批次化前向梯度检查
           check_batched_forward_grad=False,
           skips=(
               # 在以下测试中预期失败，使用装饰器标记
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # 以下测试在运行时会出现未定义值张量的运行时错误，参见讨论链接
               # https://github.com/pytorch/pytorch/issues/56660
               # RuntimeError:
               # Arguments for call are not valid.
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32, torch.complex64)),  # noqa: B950
               DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo', 'test_nnc_correctness'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestCudaFuserOpInfo'),
           ),
           supports_inplace_autograd=False,  # 不支持原地自动求导
           sample_inputs_func=sample_inputs_gradient,  # 梯度操作的样本输入函数
           error_inputs_func=error_inputs_gradient),  # 梯度操作的错误输入函数
    # 定义 OpInfo 对象，用于描述 PyTorch 操作 'isin'
    OpInfo('isin',
           dtypes=all_types(),  # 所有数据类型都支持
           dtypesIfCUDA=all_types_and(torch.half),  # 如果是 CUDA，则支持所有类型和半精度类型
           supports_autograd=False,  # 不支持自动求导
           sample_inputs_func=sample_inputs_isin),  # isin 操作的样本输入函数
    # 定义 OpInfo 对象，用于描述 PyTorch 操作 'kthvalue'
    OpInfo('kthvalue',
           dtypes=all_types_and(torch.bfloat16, torch.float16),  # 所有数据类型和半精度类型支持
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           sample_inputs_func=sample_inputs_kthvalue,  # kthvalue 操作的样本输入函数
           error_inputs_func=error_inputs_kthvalue),  # kthvalue 操作的错误输入函数
    # 定义 BinaryUfuncInfo 对象，用于描述二元通用函数 'le'
    BinaryUfuncInfo('le',
                    ref=np.less_equal,  # 参考实现为 numpy 的 less_equal 函数
                    aliases=('less_equal',),  # 别名为 less_equal
                    dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16),  # 所有数据类型和布尔、半精度类型支持
                    always_returns_bool=True,  # 总是返回布尔值
                    supports_autograd=False,  # 不支持自动求导
                    skips=(
                    )),  # 没有跳过的测试
    OpInfo('linspace',
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16),
           is_factory_function=True,
           supports_out=True,
           supports_autograd=False,
           error_inputs_func=error_inputs_linspace,
           sample_inputs_func=sample_inputs_linspace,
           skips=(
               # FX failed to normalize op - add the op to the op_skip list.
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # Tests that assume input is a tensor or sequence of tensors
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),

               # Same failure as arange: cannot find linspace in captured graph
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),

               # UserWarning not triggered : Resized a non-empty tensor but did not warn about it.
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               # UserWarning: CUDA caching allocator reports a memory leak not verified by the driver API
               # in __main__.TestJitCUDA.test_variant_consistency_jit_logspace_cuda_complex64!
               # Caching allocator allocated memory was 0 and is now reported as 307200 on device 0.
               # CUDA driver allocated memory was 1254555648 and is now 1242955776.
               # Skip this test due to CUDA memory leak warning.
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit',
                            dtypes=(torch.cfloat,), device_type="cuda"),
           )),


注释：
- `OpInfo('linspace', ...)`：定义一个名为 'linspace' 的操作信息对象，描述了该操作的各种特性和行为。
- `dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16)`：指定该操作适用的数据类型，包括所有类型以及复数类型、torch.bfloat16 和 torch.float16。
- `is_factory_function=True`：表明这是一个工厂函数，用于创建对象实例。
- `supports_out=True`：表示该操作支持输出参数。
- `supports_autograd=False`：表示该操作不支持自动求导。
- `error_inputs_func=error_inputs_linspace`：指定了用于生成错误输入的函数。
- `sample_inputs_func=sample_inputs_linspace`：指定了用于生成示例输入的函数。
- `skips=(...)`：定义了一组装饰信息，用于跳过测试中的特定情况或失败预期。
    - `DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive')`：跳过预期失败的测试，由于 FX 无法规范化该操作。
    - `DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager')`：跳过预期失败的测试，测试假设输入为张量或张量序列。
    - 其余的 `DecorateInfo` 行也都是跳过预期失败的测试，各自描述了测试和失败的具体情况。
    - `DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,))`：跳过预期失败的测试，因为在捕获的图中找不到 linspace。
    - `DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning')`：跳过预期失败的测试，因为没有触发 UserWarning。
    - `DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.cfloat,), device_type="cuda")`：跳过带有 CUDA 内存泄漏警告的测试，说明 CUDA 缓存分配器报告了一个内存泄漏。
    OpInfo('linspace',  # 创建一个 OpInfo 对象，用于描述名为 'linspace' 的操作
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16),  # 指定支持的数据类型，包括所有类型、复数类型以及 torch.bfloat16 和 torch.float16
           is_factory_function=True,  # 表示 'linspace' 是一个工厂函数
           supports_out=True,  # 表示 'linspace' 支持输出参数
           supports_autograd=False,  # 表示 'linspace' 不支持自动求导
           error_inputs_func=error_inputs_linspace,  # 指定错误输入的处理函数为 error_inputs_linspace
           sample_inputs_func=sample_inputs_linspace_tensor_overload,  # 指定生成示例输入的函数为 sample_inputs_linspace_tensor_overload
           variant_test_name="tensor_overload",  # 指定变体测试名称为 "tensor_overload"
           skips=(  # 定义一组需要跳过的测试装饰器信息列表
               # 以下是各个需要跳过的测试装饰器信息
               # FX failed to normalize op - add the op to the op_skip list.
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # TypeError: 'int' object is not subscriptable
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               # Same failure as arange: cannot find linspace in captured graph
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),
               # UserWarning not triggered : Resized a non-empty tensor but did not warn about it.
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               # UserWarning: CUDA caching allocator reports a memory leak not verified by the driver API
               # in __main__.TestJitCUDA.test_variant_consistency_jit_logspace_cuda_complex64!
               # Caching allocator allocated memory was 0 and is now reported as 307200 on device 0.
               # CUDA driver allocated memory was 1254555648 and is now 1242955776.
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit',
                            dtypes=(torch.cfloat,), device_type="cuda"),
           )),
    OpInfo('logspace',  # 创建一个 OpInfo 对象，表示 logspace 操作的信息
           dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),  # 支持的数据类型包括半精度浮点数和 bfloat16
           is_factory_function=True,  # 标记这是一个工厂函数
           supports_out=True,  # 支持输出参数
           supports_autograd=False,  # 不支持自动求导
           error_inputs_func=error_inputs_linspace,  # 错误输入生成函数是 error_inputs_linspace
           sample_inputs_func=sample_inputs_logspace,  # 样本输入生成函数是 sample_inputs_logspace
           skips=(  # 以下是需要跳过的测试用例的列表
               # FX 失败于规范化操作 - 将该操作添加到 op_skip 列表中
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # 假设输入是张量或张量序列的测试
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
               # 与 arange 相同的失败：无法在捕获的图中找到 linspace
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),

               # 未触发 UserWarning：调整了非空张量的大小，但没有警告
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),

               # 浮点数转整数时的 off-by-one 问题
               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick',
                            dtypes=(torch.int16, torch.int32, torch.int64), device_type="cuda"),
               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_comprehensive',
                            dtypes=(torch.int16, torch.int32, torch.int64), device_type="cuda"),
               # UserWarning: CUDA 缓存分配器报告内存泄漏，驱动 API 未验证
               # 在 __main__.TestJitCUDA.test_variant_consistency_jit_logspace_cuda_complex64 中！
               # 缓存分配器分配的内存从 0 增加到 307200 在设备 0 上。
               # CUDA 驱动程序分配的内存从 1254555648 减少到 1242955776。
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit',
                            dtypes=(torch.cfloat,), device_type="cuda"),
           )),
    OpInfo('logspace',  # 创建一个 OpInfo 对象，指定操作为 'logspace'
           dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),  # 指定操作支持的数据类型，包括半精度和 bfloat16
           is_factory_function=True,  # 标记这是一个工厂函数
           supports_out=True,  # 操作支持输出参数
           supports_autograd=False,  # 操作不支持自动求导
           error_inputs_func=error_inputs_linspace,  # 指定错误输入生成函数
           sample_inputs_func=sample_inputs_logspace_tensor_overload,  # 指定样本输入生成函数
           variant_test_name="tensor_overload",  # 指定变体测试名称为 "tensor_overload"
           skips=(  # 设置测试跳过的情况列表
               # 下面是各个具体的测试跳过情况及其原因
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick',
                            dtypes=(torch.int16, torch.int32, torch.int64), device_type="cuda"),
               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_comprehensive',
                            dtypes=(torch.int16, torch.int32, torch.int64), device_type="cuda"),
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit',
                            dtypes=(torch.cfloat,), device_type="cuda"),
           )),
    # 定义对数函数的测试信息，包括函数名 'log'，参考实现 np.log，定义域 (0, None)，支持的数据类型包括所有标量和复数类型以及特定的 torch 类型
    UnaryUfuncInfo('log',
                   ref=np.log,
                   domain=(0, None),
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
                   backward_dtypesIfCUDA=floating_and_complex_types_and(torch.half, torch.bfloat16, torch.chalf),
                   assert_autodiffed=True,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   promotes_int_to_float=True,
                   decorators=(precisionOverride({torch.bfloat16: 5e-2}),),
                   skips=(
                       # 添加一个装饰信息，用于指定 torch.bfloat16 精度为 5e-2
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=IS_WINDOWS),
                   ),
                   # 当输入值 |z| 接近 0 时，log(z) 的参考数值应该是 -∞
                   reference_numerics_filter=NumericsFilter(condition=lambda x: torch.abs(x) < 0.1, safe_val=1)),
    # 定义对数函数的测试信息，包括函数名 'log10'，参考实现 np.log10，定义域 (0, None)，支持的数据类型包括所有标量和复数类型以及特定的 torch 类型
    UnaryUfuncInfo('log10',
                   ref=np.log10,
                   domain=(0, None),
                   decorators=(precisionOverride({torch.bfloat16: 5e-2}),),
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   assert_autodiffed=True,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   promotes_int_to_float=True,
                   skips=(
                       # 添加一个装饰信息，用于指定 torch.bfloat16 精度为 5e-2
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=IS_WINDOWS),
                   ),
                   # 当输入值 |z| 接近 0 时，log10(z) 的参考数值应该是 -∞
                   reference_numerics_filter=NumericsFilter(condition=lambda x: torch.abs(x) < 0.1, safe_val=1)),
    # 定义对数函数的测试信息，包括函数名 'log2'，参考实现 np.log2，定义域 (0, None)，支持的数据类型包括所有标量和复数类型以及特定的 torch 类型
    UnaryUfuncInfo('log2',
                   ref=np.log2,
                   domain=(0, None),
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   assert_autodiffed=True,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   promotes_int_to_float=True,
                   decorators=(precisionOverride({torch.bfloat16: 1e-1}),),
                   skips=(
                       # 添加一个装饰信息，用于指定 torch.bfloat16 精度为 1e-1
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=[torch.cfloat, torch.cdouble]),
                   ),
                   # 当输入值 |z| 接近 0 时，log2(z) 的参考数值应该是 -∞
                   reference_numerics_filter=NumericsFilter(condition=lambda x: torch.abs(x) < 0.1, safe_val=1)),
    BinaryUfuncInfo('ldexp',
                    dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                    # 在慢速 gradcheck 上运行非常缓慢，可以通过减少输入大小来替代
                    gradcheck_fast_mode=True,
                    supports_forward_ad=True,
                    supports_fwgrad_bwgrad=True,
                    supports_inplace_autograd=False,
                    promotes_int_to_float=True,
                    supports_out=True,
                    supports_rhs_python_scalar=False,
                    skips=(
                        # RuntimeError: mul(): functions with out=... arguments don't support
                        # automatic differentiation, but one of the arguments requires grad
                        # https://github.com/pytorch/pytorch/issues/68966
                        # 在这些测试中预期会失败，因此跳过它们
                        DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
                        DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
                        DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
                        DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
                    ),
                    decorators=[
                        # 对于特定的 torch.complex64 类型，覆盖默认的容差设置
                        DecorateInfo(
                            toleranceOverride({
                                torch.complex64: tol(atol=1e-05, rtol=1e-05)
                            }),
                            'TestCommon', device_type='cpu',
                        ),
                    ], ),
    BinaryUfuncInfo('logaddexp',
                    dtypes=floating_and_complex_types_and(torch.bfloat16, torch.float16),
                    dtypesIfCUDA=floating_types_and(torch.bfloat16, torch.float16),
                    supports_forward_ad=True,
                    supports_fwgrad_bwgrad=True,
                    supports_rhs_python_scalar=False,
                    skips=(
                        # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
                        # 对于 CUDA 设备上的特定测试，预期会失败，因此跳过它
                        DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion', device_type='cuda'),
                    )),
    OpInfo('logaddexp2',
           dtypes=floating_types_and(torch.bfloat16, torch.half),
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 使用特定函数生成样本输入数据
           sample_inputs_func=sample_inputs_logaddexp),
    # 定义一元通用函数信息对象 'logical_not'
    UnaryUfuncInfo('logical_not',
                   # 参考实现为 numpy 的 logical_not 函数
                   ref=np.logical_not,
                   # 装饰器，用于指定精度覆盖的参数
                   decorators=(precisionOverride({torch.bfloat16: 7e-1,
                                                  torch.float16: 5e-1}),),
                   # 支持的数据类型，包括所有类型和复杂类型以及 torch.bool、torch.half、torch.bfloat16
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 不支持自动求导
                   supports_autograd=False,
                   # 跳过的测试用例，包括两个 DecorateInfo 对象
                   skips=(
                       # 函数变体始终返回 BoolTensor
                       # 原地变体保留输入的数据类型。
                       # 示例代码和测试用例被跳过以确保一致性。
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_variant_consistency',
                                    dtypes=all_types_and_complex_and(torch.half, torch.bfloat16)),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager',
                                    dtypes=all_types_and_complex_and(torch.half, torch.bfloat16)),
                   )),
    # 定义二元通用函数信息对象 'lt'
    BinaryUfuncInfo('lt',
                    # 参考实现为 numpy 的 less 函数
                    ref=np.less,
                    # 别名为 'less'
                    aliases=('less',),
                    # 支持的数据类型，包括所有类型和 torch.bool、torch.bfloat16、torch.float16
                    dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16),
                    # 始终返回布尔值
                    always_returns_bool=True,
                    # 不支持自动求导
                    supports_autograd=False,
                    # 跳过的测试用例为空
                    skips=(
                    )),
    # 定义操作信息对象 'lu_unpack'
    OpInfo('lu_unpack',
           # 对应的 PyTorch 操作为 torch.lu_unpack
           op=torch.lu_unpack,
           # 支持的数据类型为浮点数和复杂数类型
           dtypes=floating_and_complex_types(),
           # 在慢速 gradcheck 下运行速度较慢 - 可以减少输入大小以加快速度
           gradcheck_fast_mode=True,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向梯度与后向梯度
           supports_fwgrad_bwgrad=True,
           # 跳过的情况，如果没有 LAPACK 支持则跳过
           skips=(skipCPUIfNoLapack,),
           # 样本输入函数为 sample_inputs_lu_unpack
           sample_inputs_func=sample_inputs_lu_unpack),
    OpInfo('lu',  # 定义操作信息对象 'lu'
           op=torch.lu,  # 指定操作函数为 torch.lu
           dtypes=floating_and_complex_types(),  # 指定数据类型为浮点数和复数类型
           gradcheck_fast_mode=True,  # 启用快速梯度检查模式
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           check_batched_forward_grad=False,  # 禁用批处理前向梯度检查
           sample_inputs_func=sample_inputs_lu,  # 使用 sample_inputs_lu 函数生成示例输入
           decorators=[skipCUDAIfNoMagmaAndNoCusolver, skipCPUIfNoLapack],  # 设置装饰器列表
           skips=(  # 设置跳过的测试用例元组
               # 忽略 JIT 测试，因为 `lu` 是一个 torch 函数
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # 预期忽略 RuntimeError：在输入设备为 CPU 且输出设备为 CUDA 时
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
               # 预期忽略 UserWarning：调整非空张量大小但未发出警告
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
           )),
    OpInfo('lu_solve',  # 定义操作信息对象 'lu_solve'
           op=torch.lu_solve,  # 指定操作函数为 torch.lu_solve
           dtypes=floating_and_complex_types(),  # 指定数据类型为浮点数和复数类型
           supports_forward_ad=True,  # 支持正向自动微分
           check_batched_forward_grad=False,  # 禁用批处理前向梯度检查
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           sample_inputs_func=sample_inputs_lu_solve,  # 使用 sample_inputs_lu_solve 函数生成示例输入
           skips=(  # 设置跳过的测试用例元组
               # 在 'mps' 设备类型和 torch.float32 数据类型下跳过 'test_out' 测试用例
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_out',
                            device_type='mps', dtypes=[torch.float32]),
               # 在 'mps' 设备类型和 torch.float32 数据类型下跳过 'test_variant_consistency_eager' 测试用例
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager',
                            device_type='mps', dtypes=[torch.float32]),
               # 在 'mps' 设备类型和 torch.float32 数据类型下跳过 'test_variant_consistency_jit' 测试用例
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit',
                            device_type='mps', dtypes=[torch.float32]),
               # 跳过不同反向路径的测试用例
               DecorateInfo(unittest.skip("Tests different backward paths"),
                            "TestCommon", "test_floating_inputs_are_differentiable"),
           ),
           decorators=[skipCPUIfNoLapack, skipCUDAIfNoMagmaAndNoCusolver]),  # 设置装饰器列表
    OpInfo('masked_fill',  # 定义操作信息对象 'masked_fill'
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 指定数据类型
           sample_inputs_func=sample_inputs_masked_fill,  # 使用 sample_inputs_masked_fill 函数生成示例输入
           error_inputs_func=error_inputs_masked_fill,  # 使用 error_inputs_masked_fill 函数生成错误输入
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           check_batched_forward_grad=False,  # 禁用批处理前向梯度检查
           supports_out=False),  # 禁用输出参数
    OpInfo('masked_scatter',  # 定义 OpInfo 对象，表示 masked_scatter 操作的信息
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型，包括布尔型、半精度和 bfloat16
           sample_inputs_func=sample_inputs_masked_scatter,  # 用于生成输入样本的函数
           error_inputs_func=error_inputs_masked_scatter,  # 用于生成错误输入的函数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度计算
           # https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           supports_out=False,  # 不支持输出参数
           skips=(
           )),  # 跳过的测试情况

    OpInfo('masked_select',  # 定义 OpInfo 对象，表示 masked_select 操作的信息
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度计算
           sample_inputs_func=sample_inputs_masked_select,  # 用于生成输入样本的函数
           error_inputs_func=error_inputs_masked_select,  # 用于生成错误输入的函数
           skips=(
               # ROCm 上的编译器问题，可能需要跳过直到 ROCm5.5
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_non_standard_bool_values',
                            dtypes=[torch.bool], active_if=TEST_WITH_ROCM),  # 标记要跳过的测试用例信息
           )),

    OpInfo('matrix_exp',  # 定义 OpInfo 对象，表示 matrix_exp 操作的信息
           dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),  # 支持的浮点数和复数类型，包括 float16 和 bfloat16
           aliases=('linalg.matrix_exp',),  # 别名
           sample_inputs_func=sample_inputs_matrix_exp,  # 用于生成输入样本的函数
           # 需要构造一个 2nx2n 矩阵，通过 copy_ 函数复制
           check_batched_grad=False,  # 不检查批处理梯度
           check_batched_gradgrad=False,  # 不检查批处理梯度的梯度
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度计算
           # https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           skips=(
               # mexp 不支持 bf16 和 fp16
               DecorateInfo(unittest.skip('Skipped!'), 'TestInductorOpInfo', 'test_comprehensive',
                            dtypes=[torch.half], device_type="cpu"),  # 标记要跳过的测试用例信息
           ),
           supports_out=False,  # 不支持输出参数
           ),

    OpInfo('max',  # 定义 OpInfo 对象，表示 max 操作的信息
           variant_test_name='reduction_with_dim',  # 变体测试名称
           dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型
           sample_inputs_func=sample_inputs_max_min_reduction_with_dim,  # 用于生成输入样本的函数
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度计算
           skips=(
           ),  # 跳过的测试情况
           supports_forward_ad=True),  # 支持前向自动微分

    OpInfo('max',  # 定义 OpInfo 对象，表示 max 操作的信息
           variant_test_name='reduction_no_dim',  # 变体测试名称
           dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型
           supports_out=True,  # 支持输出参数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度计算
           sample_inputs_func=sample_inputs_max_min_reduction_no_dim,  # 用于生成输入样本的函数
           skips=(
           ),  # 跳过的测试情况
           ),

    OpInfo('median',  # 定义 OpInfo 对象，表示 median 操作的信息
           dtypes=all_types_and(torch.bfloat16, torch.float16),  # 支持的数据类型
           # TODO: some signatures of median do support out
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度计算
           error_inputs_func=error_inputs_median,  # 用于生成错误输入的函数
           sample_inputs_func=partial(sample_inputs_reduction, supports_multiple_dims=False)),  # 用于生成输入样本的函数
    OpInfo('nanmedian',
           dtypes=all_types_and(torch.bfloat16, torch.float16),
           # TODO: some signatures of nanmedian do support out
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           sample_inputs_func=partial(sample_inputs_reduction, supports_multiple_dims=False)),



    OpInfo('var_mean',
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),
           sample_inputs_func=sample_inputs_std_var,
           # TODO: some signatures of var_mean do support out
           supports_out=False,
           supports_forward_ad=True,
           check_batched_forward_grad=False,
           supports_fwgrad_bwgrad=True,
           decorators=(
               DecorateInfo(toleranceOverride({torch.float64: tol(atol=2e-7, rtol=2e-7)}),
                            "TestDecomp", "test_comprehensive", device_type="cuda"),
           )),



    OpInfo('var_mean',
           variant_test_name='unbiased',
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),
           sample_inputs_func=sample_inputs_std_var_unbiased,
           # TODO: some signatures of var_mean do support out
           supports_out=False,
           supports_forward_ad=True,
           check_batched_forward_grad=False,
           supports_fwgrad_bwgrad=True,
           decorators=(
               DecorateInfo(toleranceOverride({torch.float64: tol(atol=2e-7, rtol=2e-7)}),
                            "TestDecomp", "test_comprehensive", device_type="cuda"),
           )),



    OpInfo('std_mean',
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),
           sample_inputs_func=sample_inputs_std_var,
           # TODO: some signatures of std_mean do support out
           supports_out=False,
           supports_forward_ad=True,
           check_batched_forward_grad=False,
           supports_fwgrad_bwgrad=True,
           decorators=(
               DecorateInfo(toleranceOverride({torch.float64: tol(atol=2e-7, rtol=2e-7)}),
                            "TestDecomp", "test_comprehensive", device_type="cuda"),
           )),



    OpInfo('std_mean',
           variant_test_name='unbiased',
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),
           sample_inputs_func=sample_inputs_std_var_unbiased,
           # TODO: some signatures of var_mean do support out
           supports_out=False,
           supports_forward_ad=True,
           check_batched_forward_grad=False,
           supports_fwgrad_bwgrad=True,
           decorators=(
               DecorateInfo(toleranceOverride({torch.float64: tol(atol=2e-7, rtol=2e-7)}),
                            "TestDecomp", "test_comprehensive", device_type="cuda"),
           )),
    OpInfo('meshgrid',  # 创建一个 OpInfo 对象，用于描述 'meshgrid' 操作
           variant_test_name='variadic_tensors',  # 操作的测试变体名称为 'variadic_tensors'
           ref=np.meshgrid,  # 参考实现使用 numpy 的 np.meshgrid 函数
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.bool, torch.float16),  # 支持的数据类型包括所有类型和指定的 torch 类型
           sample_inputs_func=partial(sample_inputs_meshgrid, variant='variadic'),  # 用于生成示例输入的函数为 sample_inputs_meshgrid，使用 'variadic' 变体
           skips=[
               # 跳过以下测试用例，因为 JIT 不支持可变数量的张量参数
               # 出现 RuntimeError: input->type()->kind() == TypeKind::OptionalType
               # 在 "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp" 的位置，报告此 bug 给 PyTorch。
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),
               # 跳过此测试用例，因为 meshgrid 在 torch.functional 中定义为接受可变数量的张量，而可变参数与 normalize 操作的测试不兼容
               DecorateInfo(unittest.skip("Skipped!"), 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # 跳过运算符模式测试，因为这是一个函数而不是运算符
               DecorateInfo(unittest.skip("Skipped!"), 'TestOperatorSignatures', 'test_get_torch_func_signature_exhaustive'),
           ],
           supports_out=False,  # 不支持输出参数
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           supports_forward_ad=True,  # 支持前向自动微分
           # 参考链接详见 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,),  # 不检查批处理的前向梯度

    OpInfo('meshgrid',  # 创建一个 OpInfo 对象，用于描述 'meshgrid' 操作
           variant_test_name='list_of_tensors',  # 操作的测试变体名称为 'list_of_tensors'
           # 与上面的变体不同，这里不使用 np.meshgrid 作为参考，因为它不正式支持 numpy 数组的列表
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.bool, torch.float16),  # 支持的数据类型包括所有类型和指定的 torch 类型
           sample_inputs_func=partial(sample_inputs_meshgrid, variant='list'),  # 用于生成示例输入的函数为 sample_inputs_meshgrid，使用 'list' 变体
           skips=[
               # 跳过此测试用例，因为 meshgrid 在 torch.functional 中定义为接受可变数量的张量，而可变参数与 normalize 操作的测试不兼容
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
           ],
           assert_autodiffed=True,  # 断言自动微分已执行
           supports_out=False,  # 不支持输出参数
           autodiff_nonfusible_nodes=[],  # 自动微分的非可融合节点为空列表
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           supports_forward_ad=True,  # 支持前向自动微分
           # 参考链接详见 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,),  # 不检查批处理的前向梯度

    OpInfo('min',  # 创建一个 OpInfo 对象，用于描述 'min' 操作
           variant_test_name='reduction_with_dim',  # 操作的测试变体名称为 'reduction_with_dim'
           dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型包括所有类型和指定的 torch 类型
           sample_inputs_func=sample_inputs_max_min_reduction_with_dim,  # 用于生成示例输入的函数为 sample_inputs_max_min_reduction_with_dim
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           supports_forward_ad=True,  # 支持前向自动微分
           skips=(
           ))  # 无需跳过任何测试用例
    OpInfo('min',
           variant_test_name='reduction_no_dim',
           dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),
           supports_out=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           sample_inputs_func=sample_inputs_max_min_reduction_no_dim,
           skips=(
           )),


    # 定义操作信息对象，表示最小值操作
    OpInfo(
        'min',  # 操作名称为 'min'
        variant_test_name='reduction_no_dim',  # 变体测试名称为 'reduction_no_dim'
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型包括 float16、bfloat16 和 bool
        supports_out=True,  # 支持输出参数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        sample_inputs_func=sample_inputs_max_min_reduction_no_dim,  # 样本输入生成函数为 sample_inputs_max_min_reduction_no_dim
        skips=(),  # 无需跳过任何测试
    ),


    OpInfo('quantile',
           dtypes=floating_types(),
           sample_inputs_func=sample_inputs_reduction_quantile,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # See https://github.com/pytorch/pytorch/issues/66357
           # Relies on copy_ to broadcast, but the forward AD path calls broadcast_to which
           # does not have a batching rule in core
           check_batched_forward_grad=False),


    # 定义操作信息对象，表示分位数操作
    OpInfo(
        'quantile',  # 操作名称为 'quantile'
        dtypes=floating_types(),  # 支持的数据类型为浮点数类型
        sample_inputs_func=sample_inputs_reduction_quantile,  # 样本输入生成函数为 sample_inputs_reduction_quantile
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        # 下面是关于梯度计算的注释，详细说明了相关的问题和限制
        # See https://github.com/pytorch/pytorch/issues/66357
        # Relies on copy_ to broadcast, but the forward AD path calls broadcast_to which
        # does not have a batching rule in core
        check_batched_forward_grad=False,  # 检查批处理前向梯度时需要关闭批处理规则
    ),


    OpInfo('nanquantile',
           dtypes=floating_types(),
           sample_inputs_func=sample_inputs_reduction_quantile,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # See https://github.com/pytorch/pytorch/issues/66357
           # Relies on copy_ to broadcast, but the forward AD path calls broadcast_to which
           # does not have a batching rule in core
           check_batched_forward_grad=False),


    # 定义操作信息对象，表示带有 NaN 的分位数操作
    OpInfo(
        'nanquantile',  # 操作名称为 'nanquantile'
        dtypes=floating_types(),  # 支持的数据类型为浮点数类型
        sample_inputs_func=sample_inputs_reduction_quantile,  # 样本输入生成函数为 sample_inputs_reduction_quantile
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        # 下面是关于梯度计算的注释，详细说明了相关的问题和限制
        # See https://github.com/pytorch/pytorch/issues/66357
        # Relies on copy_ to broadcast, but the forward AD path calls broadcast_to which
        # does not have a batching rule in core
        check_batched_forward_grad=False,  # 检查批处理前向梯度时需要关闭批处理规则
    ),


    BinaryUfuncInfo(
        'max',
        aliases=('maximum',),
        variant_test_name='binary',
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        assert_autodiffed=True,
        ref=np.maximum,
        supports_rhs_python_scalar=False,
        skips=(
            # Incorrectly attempts to use a scalar for the second argument
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_jit_alias_remapping'),
            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion', device_type='cuda'),
        )),


    # 定义二元ufunc信息对象，表示最大值操作
    BinaryUfuncInfo(
        'max',  # ufunc名称为 'max'
        aliases=('maximum',),  # 别名包括 'maximum'
        variant_test_name='binary',  # 二元操作的测试变体名称为 'binary'
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型包括 float16、bfloat16 和 bool
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        assert_autodiffed=True,  # 断言已自动微分
        ref=np.maximum,  # 参考实现使用 NumPy 的 maximum 函数
        supports_rhs_python_scalar=False,  # 不支持右侧标量值作为操作数
        # 跳过某些测试的装饰信息，详细说明了为何跳过
        skips=(
            # Incorrectly attempts to use a scalar for the second argument
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_jit_alias_remapping'),
            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion', device_type='cuda'),
        ),
    ),


    BinaryUfuncInfo(
        'maximum',
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        ref=np.maximum,
        supports_rhs_python_scalar=False,
        skips=(
            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion', device_type='cuda'),
        )),


    # 定义二元ufunc信息对象，表示最大值操作（使用 'maximum' 作为名称）
    BinaryUfuncInfo(
        'maximum',  # ufunc名称为 'maximum'
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型包括 float16、bfloat16 和 bool
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        ref=np.maximum,  # 参考实现使用 NumPy 的 maximum 函数
        supports_rhs_python_scalar=False,  # 不支持右侧标量值作为操作数
        # 跳过某些测试的装饰信息，详细说明了为何跳过
        skips=(
            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion', device_type='cuda'),
        ),
    ),
    BinaryUfuncInfo(
        'min',  # 设置函数名为'min'
        aliases=('minimum',),  # 别名为'minimum'
        variant_test_name='binary',  # 测试名称变量为'binary'
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型包括 torch.float16, torch.bfloat16, torch.bool
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        assert_autodiffed=True,  # 自动微分断言为真
        ref=np.minimum,  # 参考实现为 np.minimum
        supports_rhs_python_scalar=False,  # 不支持右侧Python标量
        skips=(
            # DecorateInfo包含一个unittest.expectedFailure修饰的注释，用于测试'TestJit'的'test_jit_alias_remapping'
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_jit_alias_remapping'),
            # DecorateInfo包含一个unittest.expectedFailure修饰的注释，用于测试'TestBinaryUfuncs'的'test_type_promotion'，设备类型为'cuda'
            DecorateInfo(unittest.expectedFailure,
                         'TestBinaryUfuncs',
                         'test_type_promotion',
                         device_type='cuda'),
        )),
    BinaryUfuncInfo(
        'minimum',  # 设置函数名为'minimum'
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型包括 torch.float16, torch.bfloat16, torch.bool
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        ref=np.minimum,  # 参考实现为 np.minimum
        supports_rhs_python_scalar=False,  # 不支持右侧Python标量
        skips=(
            # DecorateInfo包含一个unittest.expectedFailure修饰的注释，用于测试'TestBinaryUfuncs'的'test_type_promotion'，设备类型为'cuda'
            DecorateInfo(unittest.expectedFailure,
                         'TestBinaryUfuncs',
                         'test_type_promotion',
                         device_type='cuda'),
        ),
    ),
    BinaryUfuncInfo('logical_and',  # 设置函数名为'logical_and'
                    ref=np.logical_and,  # 参考实现为 np.logical_and
                    dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括 torch.bool, torch.half, torch.bfloat16
                    supports_autograd=False,  # 不支持自动梯度
                    always_returns_bool=True,  # 总是返回布尔值
                    supports_rhs_python_scalar=False),  # 不支持右侧Python标量
    BinaryUfuncInfo('logical_or',  # 设置函数名为'logical_or'
                    ref=np.logical_or,  # 参考实现为 np.logical_or
                    dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括 torch.bool, torch.half, torch.bfloat16
                    supports_autograd=False,  # 不支持自动梯度
                    always_returns_bool=True,  # 总是返回布尔值
                    supports_rhs_python_scalar=False),  # 不支持右侧Python标量
    BinaryUfuncInfo('logical_xor',  # 设置函数名为'logical_xor'
                    ref=np.logical_xor,  # 参考实现为 np.logical_xor
                    dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括 torch.bool, torch.half, torch.bfloat16
                    supports_autograd=False,  # 不支持自动梯度
                    always_returns_bool=True,  # 总是返回布尔值
                    supports_rhs_python_scalar=False,  # 不支持右侧Python标量
                    skips=(
                    )),  # 空的跳过元组
    BinaryUfuncInfo('bitwise_and',  # 创建一个 BinaryUfuncInfo 对象，表示按位与操作的信息
                    ref=np.bitwise_and,  # 引用 numpy 中的 bitwise_and 函数
                    dtypes=integral_types_and(torch.bool),  # 支持的数据类型为整数和布尔类型
                    operator_variant=operator.and_,  # 对应的操作符是 Python 中的 and 操作
                    inplace_operator_variant=operator.iand,  # 对应的原地操作符是 Python 中的 iand 操作
                    supports_autograd=False,  # 不支持自动微分
                    supports_one_python_scalar=True,  # 支持单个 Python 标量
                    skips=(  # 跳过的测试信息，指明 CUDA 设备上的特定错误情况
                        DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs',
                                     'test_type_promotion', device_type='cuda'),
                    )),
    BinaryUfuncInfo('bitwise_or',  # 创建一个 BinaryUfuncInfo 对象，表示按位或操作的信息
                    ref=np.bitwise_or,  # 引用 numpy 中的 bitwise_or 函数
                    dtypes=integral_types_and(torch.bool),  # 支持的数据类型为整数和布尔类型
                    operator_variant=operator.or_,  # 对应的操作符是 Python 中的 or 操作
                    inplace_operator_variant=operator.ior,  # 对应的原地操作符是 Python 中的 ior 操作
                    supports_autograd=False,  # 不支持自动微分
                    supports_one_python_scalar=True,  # 支持单个 Python 标量
                    skips=(  # 跳过的测试信息，指明 CUDA 设备上的特定错误情况
                        # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
                        DecorateInfo(unittest.expectedFailure,
                                     'TestBinaryUfuncs',
                                     'test_type_promotion',
                                     device_type='cuda'),
                    )),
    BinaryUfuncInfo('bitwise_xor',  # 创建一个 BinaryUfuncInfo 对象，表示按位异或操作的信息
                    ref=np.bitwise_xor,  # 引用 numpy 中的 bitwise_xor 函数
                    dtypes=integral_types_and(torch.bool),  # 支持的数据类型为整数和布尔类型
                    operator_variant=operator.xor,  # 对应的操作符是 Python 中的 xor 操作
                    inplace_operator_variant=operator.ixor,  # 对应的原地操作符是 Python 中的 ixor 操作
                    supports_autograd=False,  # 不支持自动微分
                    supports_one_python_scalar=True,  # 支持单个 Python 标量
                    skips=(  # 跳过的测试信息，指明 CUDA 设备上的特定错误情况
                        # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
                        DecorateInfo(unittest.expectedFailure,
                                     'TestBinaryUfuncs',
                                     'test_type_promotion',
                                     device_type='cuda'),
                    )),
    BinaryUfuncInfo('heaviside',
                    ref=lambda a, b: (
                        # 当 a 和 b 的数据类型为 int64 时，修正 np.heaviside 返回 float64 的问题
                        np.int64(np.heaviside(a, b)) if a.dtype == np.int64 and b.dtype == np.int64 else np.heaviside(a, b)
                    ),
                    dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),  # 指定支持的数据类型
                    supports_autograd=False,  # 不支持自动求导
                    supports_rhs_python_scalar=False,  # 不支持右侧的 Python 标量
                    skips=(
                        # 测试用例: test_type_promotion 预期会抛出 RuntimeError
                        DecorateInfo(unittest.expectedFailure,
                                     'TestBinaryUfuncs',
                                     'test_type_promotion'),
                        # 测试用例: test_binary_ufuncs_mixed_dtype 预期会抛出 RuntimeError
                        DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_binary_ufuncs_mixed_dtype'),
                        # 测试用例: test_reference_numerics_extremal_values 跳过执行，标记为 Skipped!
                        # PyTorch 的 heaviside 函数似乎不会传播 NaN
                        DecorateInfo(unittest.skip("Skipped!"),
                                     'TestBinaryUfuncs',
                                     'test_reference_numerics_extremal_values'),
                    )),
    
    BinaryUfuncInfo('lcm',
                    ref=np.lcm,  # 使用 numpy 的 lcm 函数作为参考实现
                    dtypes=integral_types_and(),  # 指定支持的整数类型数据
                    supports_autograd=False,  # 不支持自动求导
                    supports_rhs_python_scalar=False),  # 不支持右侧的 Python 标量
    
    BinaryUfuncInfo('gcd',
                    ref=np.gcd,  # 使用 numpy 的 gcd 函数作为参考实现
                    dtypes=integral_types_and(),  # 指定支持的整数类型数据
                    supports_autograd=False,  # 不支持自动求导
                    supports_rhs_python_scalar=False,
                    skips=(
                        # 测试用例: test_reference_numerics_small_values，对于 torch.int8 类型数据，预期会抛出 RuntimeError
                        DecorateInfo(unittest.expectedFailure,
                                     'TestBinaryUfuncs',
                                     'test_reference_numerics_small_values',
                                     dtypes=(torch.int8,)),)),
    # 定义 BinaryUfuncInfo 对象，描述 numpy 的 isclose 函数的信息
    BinaryUfuncInfo('isclose',
                    ref=np.isclose,  # 引用 numpy 的 isclose 函数
                    dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型
                    sample_inputs_func=sample_inputs_isclose,  # 生成 isclose 函数的样本输入的函数
                    error_inputs_func=error_inputs_isclose,  # 生成 isclose 函数错误输入的函数
                    supports_autograd=False,  # 不支持自动求导
                    supports_out=False,  # 不支持输出张量
                    supports_rhs_python_scalar=False,  # 不支持 Python 标量作为右操作数
                    skips=(
                        # 标记为预期失败的测试信息
                        DecorateInfo(unittest.expectedFailure,
                                     'TestCommon',
                                     'test_numpy_refs', dtypes=(torch.complex128,)),
                        # 运行时错误：Short did not match Int
                        DecorateInfo(unittest.expectedFailure,
                                     'TestBinaryUfuncs',
                                     'test_type_promotion'),
                        DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_binary_ufuncs_mixed_dtype'),
                        DecorateInfo(unittest.skip("Skipped!"),
                                     'TestBinaryUfuncs',
                                     'test_reference_numerics_extremal_values'),
                    )),
    
    # OpInfo 对象描述 softmax 函数的信息，支持有无 dtype 参数两种情况
    OpInfo('softmax',
           aliases=('special.softmax', 'nn.functional.softmax',),
           aten_name='softmax',  # 对应的 ATen 函数名
           aten_backward_name='_softmax_backward_data',  # 反向传播时对应的 ATen 函数名
           dtypes=floating_types_and(torch.half, torch.bfloat16),  # 支持的数据类型
           sample_inputs_func=sample_inputs_softmax_variant,  # 生成 softmax 函数样本输入的函数
           assert_jit_shape_analysis=True,  # 断言 JIT 形状分析为 True
           assert_autodiffed=True,  # 断言自动微分为 True
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向后向梯度计算
           supports_out=True),  # 支持输出张量

    # OpInfo 对象描述带有 dtype 参数的 softmax 变体的信息
    OpInfo('softmax',
           aliases=('special.softmax', 'nn.functional.softmax',),
           variant_test_name="with_dtype",  # 变体测试名称
           aten_name='softmax',  # 对应的 ATen 函数名
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型
           sample_inputs_func=partial(sample_inputs_softmax_variant, with_dtype=True),  # 生成 softmax 函数样本输入的函数
           assert_autodiffed=True,  # 断言自动微分为 True
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向后向梯度计算
           supports_out=True),  # 支持输出张量
    OpInfo(
        '_softmax_backward_data',  # 操作的名称是 _softmax_backward_data
        op=torch.ops.aten._softmax_backward_data,  # 操作函数来自于 torch.ops.aten._softmax_backward_data
        aten_name='_softmax_backward_data',  # 对应的 ATen 函数名称是 _softmax_backward_data
        dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 支持的数据类型包括浮点类型以及 torch.bfloat16 和 torch.float16
        sample_inputs_func=sample_inputs_softmax_backward_data,  # 获取样本输入的函数是 sample_inputs_softmax_backward_data
        assert_autodiffed=True,  # 断言支持自动微分
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        supports_out=False,  # 不支持输出参数
        skips=(  # 跳过的测试包括以下情况：
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_noncontiguous_samples', device_type='cpu'),  # 在 'TestCommon' 的 'test_noncontiguous_samples' 中预期失败，设备类型为 'cpu'
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),  # 在 'TestJit' 的 'test_variant_consistency_jit' 中预期失败，数据类型为 torch.float32
        ),
    ),
    # `softmin` 根据是否传递 `dtype` 参数支持不同的数据类型，因此有两个 OpInfo 条目，一个带有 dtype，另一个没有。
    # https://github.com/pytorch/pytorch/issues/68752
    OpInfo('nn.functional.softmin',  # 操作的名称是 nn.functional.softmin
           aten_name='softmin',  # 对应的 ATen 函数名称是 softmin
           dtypes=floating_types_and(torch.half, torch.bfloat16),  # 支持的数据类型包括半精度浮点和 torch.bfloat16
           sample_inputs_func=sample_inputs_softmax_variant,  # 获取样本输入的函数是 sample_inputs_softmax_variant
           assert_jit_shape_analysis=False,  # 不断言 JIT 的形状分析
           assert_autodiffed=False,  # 不断言支持自动微分
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           supports_out=False),  # 不支持输出参数
    OpInfo('nn.functional.softmin',  # 另一个 softmin 的 OpInfo 条目，用于测试带有 dtype 的情况
           variant_test_name="with_dtype",  # 变体测试的名称是 "with_dtype"
           aten_name='softmin',  # 对应的 ATen 函数名称是 softmin
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),  # 支持所有类型，包括复杂类型以及 torch.float16 和 torch.bfloat16
           sample_inputs_func=partial(sample_inputs_softmax_variant, with_dtype=True),  # 获取样本输入的函数是带有 dtype 的 sample_inputs_softmax_variant
           assert_autodiffed=False,  # 不断言支持自动微分
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           supports_out=False),  # 不支持输出参数
    OpInfo(
        "nn.functional.cross_entropy",  # 操作的名称是 nn.functional.cross_entropy
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 支持的数据类型包括浮点类型以及 torch.float16 和 torch.bfloat16
        sample_inputs_func=sample_inputs_cross_entropy,  # 获取样本输入的函数是 sample_inputs_cross_entropy
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        decorators=(  # 使用的装饰器包括以下情况：
            DecorateInfo(  # 装饰信息：
                toleranceOverride({torch.float32: tol(atol=1e-5, rtol=1e-3)}),  # 设置容差覆盖，对 torch.float32 使用 atol 和 rtol 容差
                "TestJit",  # 测试类是 "TestJit"
                "test_variant_consistency_jit",  # 测试方法是 "test_variant_consistency_jit"
                device_type="cpu",  # 设备类型为 "cpu"
            ),
        ),
        skips=(  # 跳过的测试包括以下情况：
            # AssertionError: False is not true : Scalars failed to compare as equal! 0 != 1536
            # test_ops.TestJitCUDA.test_variant_consistency_jit_nn_functional_cross_entropy_cuda_float32 leaked
            # 1536 bytes CUDA memory on device 0
            DecorateInfo(  # 装饰信息：
                unittest.expectedFailure,  # 预期失败的测试
                "TestJit",  # 测试类是 "TestJit"
                "test_variant_consistency_jit",  # 测试方法是 "test_variant_consistency_jit"
                device_type="cuda",  # 设备类型为 "cuda"
            ),
            DecorateInfo(unittest.skip("FP16 corss_entropy cases have not been enabled on MPS yet"),  # 跳过的信息是 "FP16 corss_entropy cases have not been enabled on MPS yet"
                         dtypes=(torch.half,),  # 数据类型为 torch.half
                         device_type="mps"),  # 设备类型为 "mps"
        )
    ),
    # 定义 OpInfo 对象，描述 nn.functional.normalize 操作的元信息
    OpInfo('nn.functional.normalize',
           # 指定支持的数据类型为浮点数和复数类型，并且包括 torch.half 和 torch.bfloat16
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),
           # 指定用于生成样本输入的函数为 sample_inputs_normalize
           sample_inputs_func=sample_inputs_normalize,
           # 标识该操作支持前向自动求导
           supports_forward_ad=True,
           # 标识该操作支持前向到前向和前向到后向的梯度传播
           supports_fwgrad_bwgrad=True),

    # 定义 OpInfo 对象，描述 aminmax 操作的元信息
    OpInfo('aminmax',
           # 定义参考函数 ref，用于计算输入张量沿指定维度的最小值和最大值
           ref=lambda x, dim=None, keepdim=False: (np.amin(x, axis=dim, keepdims=keepdim), np.amax(x, axis=dim, keepdims=keepdim)),
           # 指定支持的数据类型为所有类型，并且包括 torch.bool, torch.float16, torch.bfloat16
           dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),
           # 使用 onlyNativeDeviceTypes 装饰器限制仅支持本地设备类型的测试
           decorators=(onlyNativeDeviceTypes,),
           # 标识不支持自动求导
           supports_autograd=False,
           # 指定用于生成样本输入的函数为 sample_inputs_aminmax
           sample_inputs_func=sample_inputs_aminmax,
           # 指定用于生成错误输入的函数为 error_inputs_aminmax_amax_amin
           error_inputs_func=error_inputs_aminmax_amax_amin),

    # 定义 OpInfo 对象，描述 as_strided 操作的元信息
    OpInfo('as_strided',
           # 指定支持的数据类型为所有类型、复数类型，并且包括 torch.bool, torch.float16, torch.bfloat16, torch.chalf
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           # 标识不支持输出参数
           supports_out=False,
           # 标识支持前向自动求导
           supports_forward_ad=True,
           # 标识支持前向到前向和前向到后向的梯度传播
           supports_fwgrad_bwgrad=True,
           # 设置 vmap 不支持就地视图
           check_inplace_batched_forward_grad=False,
           # 指定用于生成样本输入的函数为 sample_inputs_as_strided
           sample_inputs_func=sample_inputs_as_strided,
           # 跳过特定的测试用例，详细描述见下面的 DecorateInfo 注释
           skips=(
               # 注意: 此 xfail 是合理的 -- 这是 as_strided 工作方式的固有属性
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_noncontiguous_samples'),
               # AssertionError: False is not true : Scalars failed to compare as equal!
               DecorateInfo(unittest.skip("Errors when storage_offset is included"),
                            'TestCommon', 'test_variant_consistency_eager'),
               # Not close
               DecorateInfo(unittest.skip("Errors when storage_offset is included"),
                            'TestCommon', 'test_complex_half_reference_testing'),
               # Not close
               DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.skip("Numerous errors"), 'TestFwdGradients'),
               DecorateInfo(unittest.skip("Numerous errors"), 'TestBwdGradients'),
           )),
    OpInfo('as_strided_copy',
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           supports_out=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # vmap does not support inplace views
           check_inplace_batched_forward_grad=False,
           sample_inputs_func=sample_inputs_as_strided,
           skips=(
               # 注意：这个 xfail 是可以接受的，因为它与 as_strided 的工作方式有关
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_noncontiguous_samples'),
               # AssertionError: False is not true : Scalars failed to compare as equal!
               DecorateInfo(unittest.skip("Errors when storage_offset is included"),
                            'TestCommon', 'test_variant_consistency_eager'),
               # Not close
               DecorateInfo(unittest.skip("Errors when storage_offset is included"),
                            'TestCommon', 'test_complex_half_reference_testing'),
               # Not close
               DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.skip("Numerous errors"), 'TestFwdGradients'),
               DecorateInfo(unittest.skip("Numerous errors"), 'TestBwdGradients'),
           )),
    OpInfo('native_layer_norm',  # 创建一个 OpInfo 对象，用于记录 native_layer_norm 操作的信息
           aten_name='native_layer_norm',  # 设置操作的 ATen 名称为 native_layer_norm
           ref=reference_native_layer_norm,  # 设置参考实现函数为 reference_native_layer_norm
           dtypes=floating_types_and(torch.half, torch.bfloat16),  # 设置支持的数据类型为半精度浮点数和 bfloat16
           supports_out=False,  # 不支持输出张量参数
           assert_jit_shape_analysis=True,  # 断言 JIT 形状分析为 True
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           sample_inputs_func=sample_inputs_native_layer_norm,  # 设置用于生成样本输入的函数为 sample_inputs_native_layer_norm
           error_inputs_func=error_inputs_native_layer_norm,  # 设置用于生成错误输入的函数为 error_inputs_native_layer_norm
           skips=(  # 设置测试跳过的情况列表
               # IndexError: tuple index out of range 时跳过该测试
               DecorateInfo(unittest.skip('Skipped!'), 'TestFwdGradients', 'test_forward_mode_AD'),
               # 当 weight=None 而 bias 被定义时，预期测试失败
               # 参考：https://github.com/pytorch/pytorch/issues/79705
               DecorateInfo(unittest.expectedFailure, 'TestBwdGradients', 'test_fn_gradgrad'),
               # JIT 测试还尝试进行双向传播，这会导致失败
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # 目前在 MPS 上不支持的情况，跳过测试
               DecorateInfo(unittest.skip("Unsupported on MPS for now"), 'TestCommon', 'test_numpy_ref_mps'),
           )),
    OpInfo('native_batch_norm',  # 创建一个 OpInfo 对象，描述了 native_batch_norm 操作的信息
           aten_name='native_batch_norm',  # 指定了操作在 ATen 中的名称
           dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 指定了支持的数据类型，包括 torch.float16 和 torch.bfloat16
           supports_forward_ad=True,  # 标记此操作支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 标记此操作支持前向和后向梯度的一致性检查
           assert_jit_shape_analysis=True,  # 断言需要进行 JIT 形状分析
           allow_cow_input_materialize_forward=[3, 4],  # 允许共享写入（COW）输入在前向材料化时的特定维度
           allow_cow_input_materialize_backward=[3, 4],  # 允许共享写入（COW）输入在后向材料化时的特定维度
           sample_inputs_func=sample_inputs_native_batch_norm,  # 指定一个函数来生成 native_batch_norm 操作的示例输入
           skips=(
               # 下面是一系列装饰信息，指定了应该跳过的测试用例，每个 DecorateInfo 对象包含了跳过的理由和测试的详细信息
               # NotImplementedError: Could not run 'aten::native_batch_norm.out' with arguments from the 'CPU' backend.
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning', device_type="cpu"),
               # RuntimeError: out_invstd.dim() == 1 && out_invstd.is_contiguous() && out_invstd.sizes()[0]
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out', device_type="cuda"),
               # Problem with _get_numerical_jacobian
               # IndexError: tuple index out of range
               DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients', 'test_forward_mode_AD'),
               # RuntimeError: deepEquals(input.iValue, deepCopiedInput) INTERNAL ASSERT FAILED
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # https://github.com/pytorch/pytorch/issues/85960
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_compare_cpu'),
               # AssertionError: Booleans mismatch: True is not False
               DecorateInfo(unittest.skip("Skipped!"), 'TestFakeTensor', 'test_fake_autocast'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestFakeTensor', 'test_fake'),
               # 指定了针对不同数据类型 torch.float32 的容差设置
               DecorateInfo(toleranceOverride({torch.float32: tol(atol=5e-5, rtol=5e-5)}),
                            "TestCompositeCompliance", "test_forward_ad"),
           )
           ),
    OpInfo('_native_batch_norm_legit',  # 定义操作名称为 '_native_batch_norm_legit'
           aten_name='_native_batch_norm_legit',  # 设置操作的 ATen 函数名称
           dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 操作支持的数据类型，包括 torch.float16 和 torch.bfloat16
           supports_forward_ad=True,  # 操作支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 操作支持前向梯度和后向梯度
           assert_jit_shape_analysis=True,  # 断言进行 JIT 形状分析
           allow_cow_input_materialize_forward=[3, 4],  # 允许对输入进行写时复制（COW）并进行前向材料化
           allow_cow_input_materialize_backward=[3, 4],  # 允许对输入进行写时复制（COW）并进行后向材料化
           sample_inputs_func=sample_inputs__native_batch_norm_legit,  # 提供生成样本输入的函数
           skips=(  # 定义跳过的测试用例列表
               # NotImplementedError: Could not run
               # 'aten::native_batch_norm.out' with arguments from the 'CPU' backend.
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning', device_type="cpu"),  # 对使用 CPU 后端运行的测试 'TestCommon.test_out_warning' 进行期望失败装饰
               # RuntimeError: out_invstd.dim() == 1 && out_invstd.is_contiguous() && out_invstd.sizes()[0]
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out', device_type="cuda"),  # 对使用 CUDA 后端运行的测试 'TestCommon.test_out' 进行期望失败装饰
               # Problem with _get_numerical_jacobian
               # IndexError: tuple index out of range
               DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients', 'test_forward_mode_AD'),  # 跳过测试 'TestFwdGradients.test_forward_mode_AD'，并注明原因为 "Skipped!"
               # RuntimeError: deepEquals(input.iValue, deepCopiedInput) INTERNAL ASSERT FAILED
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 对测试 'TestJit.test_variant_consistency_jit' 进行期望失败装饰
               # https://github.com/pytorch/pytorch/issues/85960
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_compare_cpu'),  # 对测试 'TestCommon.test_compare_cpu' 进行期望失败装饰
               DecorateInfo(toleranceOverride({torch.float32: tol(atol=5e-5, rtol=5e-5)}),
                            "TestCompositeCompliance", "test_forward_ad"),  # 对测试 'TestCompositeCompliance.test_forward_ad' 应用容差覆盖
           )
           ),
    # 定义 OpInfo 对象，描述 _batch_norm_with_update 操作的信息
    OpInfo('_batch_norm_with_update',
           # 指定 PyTorch 的底层实现函数
           op=torch.ops.aten._batch_norm_with_update,
           # 指定在 ATen 中使用的名称
           aten_name='_batch_norm_with_update',
           # 操作支持的数据类型，包括浮点类型和 torch.float16、torch.bfloat16 类型
           dtypes=floating_types_and(torch.float16, torch.bfloat16),
           # 操作支持前向自动微分
           supports_forward_ad=True,
           # 操作支持前向反向传播自动微分
           supports_fwgrad_bwgrad=True,
           # 对 JIT 形状分析进行断言
           assert_jit_shape_analysis=True,
           # 允许在前向传播时将指定索引的输入视为可写复制
           allow_cow_input_materialize_forward=[3, 4],
           # 允许在反向传播时将指定索引的输入视为可写复制
           allow_cow_input_materialize_backward=[3, 4],
           # 提供生成示例输入的函数
           sample_inputs_func=sample_inputs__batch_norm_with_update,
           # 跳过特定的测试用例，使用装饰器 DecorateInfo 标记为预期失败或跳过
           skips=(
               # 装饰器指定的测试用例出现 NotImplementedError，并标记为预期失败
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning', device_type="cpu"),
               # 装饰器指定的测试用例出现 RuntimeError，并标记为预期失败
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out', device_type="cuda"),
               # 装饰器指定的测试用例出现 IndexError，并跳过该测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients', 'test_forward_mode_AD'),
               # 装饰器指定的测试用例出现 RuntimeError，并标记为预期失败
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # 装饰器指定的测试用例提供特定的数值容差，并用于浮点数值比较
               DecorateInfo(toleranceOverride({torch.float32: tol(atol=5e-5, rtol=5e-5)}),
                            "TestCompositeCompliance", "test_forward_ad"),
               # 装饰器指定的测试用例出现运行时错误，并标记为预期失败
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_noncontiguous_samples', device_type="cuda"),
               # 装饰器指定的测试用例出现运行时错误，并标记为预期失败
               DecorateInfo(unittest.expectedFailure,
                            'TestMeta', 'test_dispatch_symbolic_meta_outplace_all_strides', device_type="cuda"),
               # 装饰器指定的测试用例由于缺少 Python 绑定而被跳过
               DecorateInfo(unittest.skip("Skipped!"), 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # 装饰器指定的测试用例出现运行时错误，并标记为预期失败
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
               # 装饰器指定的测试用例出现运行时错误，并标记为预期失败
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
           )
           ),
    
    # 定义 OpInfo 对象，描述 nn.functional.cosine_similarity 操作的信息
    OpInfo('nn.functional.cosine_similarity',
           # 指定 ATen 中使用的名称
           aten_name="cosine_similarity",
           # 操作支持的数据类型，包括浮点类型、torch.half 和 torch.bfloat16 类型
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           # 操作不支持输出张量的指定
           supports_out=False,
           # 操作支持前向自动微分
           supports_forward_ad=True,
           # 操作支持前向反向传播自动微分
           supports_fwgrad_bwgrad=True,
           # 提供生成示例输入的函数
           sample_inputs_func=sample_inputs_cosine_similarity),
    OpInfo('nn.functional.adaptive_avg_pool1d',
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           error_inputs_func=error_inputs_adaptive_avg_pool1d,
           sample_inputs_func=sample_inputs_adaptive_avg_pool1d),
    # 定义操作信息对象，描述了 nn.functional.adaptive_avg_pool1d 函数的特性
    # 设置数据类型为浮点类型和 torch.half, torch.bfloat16
    # 不支持输出参数
    # 支持正向自动求导
    # 支持正向-反向梯度传播
    # 梯度检查非确定性容忍度为 GRADCHECK_NONDET_TOL
    # 定义错误输入生成函数为 error_inputs_adaptive_avg_pool1d
    # 定义样例输入生成函数为 sample_inputs_adaptive_avg_pool1d

    OpInfo('nn.functional.adaptive_avg_pool2d',
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           decorators=(
               # 设置装饰器信息，用于修饰 nn.functional.adaptive_avg_pool2d 函数
               # 该修饰器处理了一个特定的 RuntimeError 错误
               # 描述了期望参数 'output_size' 的类型应为 'List[int]'
               # 但实际上找到的是 'Tuple[NoneType, int]'
               # 修饰器相关信息包含 DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit')
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           error_inputs_func=error_inputs_adaptive_avg_pool2d,
           sample_inputs_func=sample_inputs_adaptive_avg_pool2d),
    # 定义操作信息对象，描述了 nn.functional.adaptive_avg_pool2d 函数的特性
    # 设置数据类型为浮点类型和 torch.half, torch.bfloat16
    # 设置了一个装饰器，处理特定的 RuntimeError 错误
    # 不支持输出参数
    # 支持正向自动求导
    # 支持正向-反向梯度传播
    # 梯度检查非确定性容忍度为 GRADCHECK_NONDET_TOL
    # 定义错误输入生成函数为 error_inputs_adaptive_avg_pool2d
    # 定义样例输入生成函数为 sample_inputs_adaptive_avg_pool2d

    OpInfo('nn.functional.adaptive_avg_pool3d',
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),
           decorators=(
               # 设置装饰器信息，用于修饰 nn.functional.adaptive_avg_pool3d 函数
               # 该修饰器处理了一个特定的 RuntimeError 错误
               # 描述了期望参数 'output_size' 的类型应为 'List[int]'
               # 但实际上找到的是 'Tuple[NoneType, NoneType, NoneType]'
               # 修饰器相关信息包含 DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit')
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           # 在慢速梯度检查模式下运行很慢 - 或者减少输入大小作为替代
           gradcheck_fast_mode=True,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           error_inputs_func=error_inputs_adaptive_avg_pool3d,
           sample_inputs_func=sample_inputs_adaptive_avg_pool3d),
    # 定义操作信息对象，描述了 nn.functional.adaptive_avg_pool3d 函数的特性
    # 设置数据类型为浮点类型和 torch.half, torch.bfloat16
    # 如果在CUDA环境下，也使用相同的数据类型设置
    # 设置了一个装饰器，处理特定的 RuntimeError 错误
    # 描述了期望参数 'output_size' 的类型应为 'List[int]'
    # 但实际上找到的是 'Tuple[NoneType, NoneType, NoneType]'
    # 修饰器相关信息包含 DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit')
    # 在梯度检查快速模式下运行
    # 不支持输出参数
    # 支持正向自动求导
    # 支持正向-反向梯度传播
    # 梯度检查非确定性容忍度为 GRADCHECK_NONDET_TOL
    # 定义错误输入生成函数为 error_inputs_adaptive_avg_pool3d
    # 定义样例输入生成函数为 sample_inputs_adaptive_avg_pool3d),
    OpInfo('nn.functional.adaptive_max_pool1d',
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 禁用批处理前向梯度检查
           check_batched_forward_grad=False,
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           error_inputs_func=error_inputs_adaptive_max_pool1d,
           sample_inputs_func=sample_inputs_adaptive_max_pool1d),
    
    OpInfo('nn.functional.adaptive_max_pool2d',
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           decorators=(
               # 修饰信息：预期失败的测试用例（unittest.expectedFailure），用于测试 JIT 的变体一致性
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 禁用批处理前向梯度检查
           check_batched_forward_grad=False,
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           error_inputs_func=error_inputs_adaptive_max_pool2d,
           sample_inputs_func=sample_inputs_adaptive_max_pool2d),
    
    OpInfo('nn.functional.adaptive_max_pool3d',
           dtypes=floating_types_and(torch.bfloat16),
           dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),
           decorators=(
               # 修饰信息：预期失败的测试用例（unittest.expectedFailure），用于测试 JIT 的变体一致性
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 禁用批处理前向梯度检查
           check_batched_forward_grad=False,
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           error_inputs_func=error_inputs_adaptive_max_pool3d,
           sample_inputs_func=sample_inputs_adaptive_max_pool3d),
    OpInfo('nn.functional.avg_pool1d',
           aten_name='avg_pool1d',
           supports_autograd=True,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           dtypes=floating_types_and(torch.int64, torch.float16, torch.bfloat16),
           dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           error_inputs_func=error_inputs_avg_pool1d,
           sample_inputs_func=sample_inputs_avgpool1d),

对 `nn.functional.avg_pool1d` 的操作信息进行配置，包括池化操作的设置，自动求导支持，不支持输出，前向自动求导和前向-后向自动求导的支持，数据类型设置为浮点类型和 `torch.int64`，在 CUDA 下的数据类型设置为浮点类型。同时设置了梯度检查的非确定性容差值，错误输入函数和样本输入函数。


    OpInfo('nn.functional.avg_pool3d',
           aten_name='avg_pool3d',
           supports_autograd=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           dtypes=floating_types_and(torch.int64),
           dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           error_inputs_func=error_inputs_avg_pool3d,
           sample_inputs_func=sample_inputs_avgpool3d,
           skips=(
               # AssertionError: Tensor-likes are not close!
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out', device_type='cpu'),
           )),

对 `nn.functional.avg_pool3d` 的操作信息进行配置，包括池化操作的设置，自动求导支持，前向-后向自动求导的支持，数据类型设置为 `torch.int64`，在 CUDA 下的数据类型设置为浮点类型和 `torch.bfloat16`。同时设置了梯度检查的非确定性容差值，错误输入函数和样本输入函数，并且标记了一个测试跳过的装饰信息。


    OpInfo(
        "nn.functional.binary_cross_entropy_with_logits",
        aten_name="binary_cross_entropy_with_logits",
        supports_autograd=True,
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        supports_out=False,
        dtypes=floating_types_and(torch.half, torch.bfloat16),
        gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
        sample_inputs_func=sample_inputs_binary_cross_entropy_with_logits,
        skips=(
            DecorateInfo(
                unittest.skip("Skipped!"),
                'TestJit',
                'test_variant_consistency_jit',
                dtypes=(torch.float32,)
            ),
        ),
    ),

对 `nn.functional.binary_cross_entropy_with_logits` 的操作信息进行配置，包括二元交叉熵损失的设置，自动求导支持，前向-后向自动求导的支持，不支持输出，数据类型设置为半精度浮点和 `torch.bfloat16`。同时设置了梯度检查的非确定性容差值，样本输入函数，并且标记了一个测试跳过的装饰信息。


    UnaryUfuncInfo(
        'nn.functional.relu',
        aten_name="relu",
        ref=lambda a: np.where(a <= 0, 0, a),
        supports_autograd=True,
        supports_sparse=True,
        supports_sparse_csr=True,
        supports_sparse_csc=True,
        supports_sparse_bsr=True,
        supports_sparse_bsc=True,
        dtypes=all_types_and(torch.half, torch.bfloat16),
        sample_inputs_func=sample_inputs_nn_activation_relu,
        supports_out=False,
        supports_fwgrad_bwgrad=True,
        supports_forward_ad=True),

对 `nn.functional.relu` 的一元函数信息进行配置，包括 ReLU 激活函数的设置，自动求导支持，稀疏张量支持，支持不同的稀疏格式，数据类型设置为半精度浮点和 `torch.bfloat16`。同时设置了样本输入函数，不支持输出，前向-后向自动求导的支持和前向自动求导的支持。
    OpInfo('nn.functional.conv_transpose1d',
           # `ref` for this function is backward of
           # corresponding `conv*d`
           # 使用 partial 函数创建 conv_transpose1d 的参考函数，用于反向计算
           ref=partial(conv_transpose_ref, fn=torch.nn.functional.conv_transpose1d),
           # 设置 ATen 函数的名称为 conv_transpose1d
           aten_name='conv_transpose1d',
           # 别名包括 'conv_transpose1d'
           aliases=('conv_transpose1d',),
           # 定义支持的数据类型，包括浮点数和复数类型，以及 torch.int64, torch.float16, torch.bfloat16
           dtypes=floating_and_complex_types_and(torch.int64, torch.float16, torch.bfloat16),
           # 如果在 CUDA 下，支持的数据类型包括浮点数和复数类型，以及 torch.float16, torch.chalf, torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.chalf,
                                                       torch.bfloat16),
           # 采样输入函数为 sample_inputs_conv_transpose1d
           sample_inputs_func=sample_inputs_conv_transpose1d,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向梯度和反向梯度一致性测试
           supports_fwgrad_bwgrad=True,
           # 断言 JIT 形状分析的正确性
           assert_jit_shape_analysis=True,
           # 梯度检查的非确定性容差值为 GRADCHECK_NONDET_TOL
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           # 装饰器列表包括不同的测试装饰器，每个装饰器提供不同的容差覆盖和设备类型
           decorators=(
               DecorateInfo(
                   toleranceOverride({torch.float32: tol(atol=1e-04, rtol=1.3e-06), }),
                   'TestCommon', 'test_variant_consistency_eager', device_type='cuda'),
               DecorateInfo(
                   toleranceOverride({torch.chalf: tol(atol=5e-2, rtol=5e-2), }),
                   'TestCommon', 'test_complex_half_reference_testing'),
               DecorateInfo(
                   toleranceOverride({torch.float: tol(atol=1.5e-5, rtol=1.5e-5), }),
                   'TestCommon', 'test_numpy_ref_mps'),
               DecorateInfo(
                   toleranceOverride({torch.half: tol(atol=1e-3, rtol=2e-3), }),
                   'TestInductorOpInfo', 'test_comprehensive', device_type='cpu'),
           ),
           # 跳过列表包括不同的测试跳过原因和数据类型
           skips=(
               # 由于问题 https://github.com/pytorch/pytorch/pull/79694#issuecomment-1186949486 跳过
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit',
                            dtypes=(torch.complex64,)),
               # 对于 torch.complex64 和 torch.complex128 数据类型的预期失败，原因是 RuntimeError: UNSUPPORTED DTYPE: complex
               DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_nnc_correctness',
                            dtypes=(torch.complex64, torch.complex128)),
               # 对于 torch.float 数据类型的预期失败，原因是 RuntimeError: !lhs.isAliasOf(rhs)INTERNAL ASSERT FAILED at ...
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',
                            dtypes=(torch.float,)),
               # 对于 torch.int64 数据类型的预期失败，原因是 "slow_conv2d_cpu_grad_input" not implemented for 'Long'
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_numpy_ref',
                            dtypes=(torch.int64,)),
           ),
           # 不支持输出
           supports_out=False,),
    OpInfo('nn.functional.conv1d',  # 创建一个 OpInfo 对象，用于存储关于 nn.functional.conv1d 的信息
           aliases=('conv1d',),  # 设置 conv1d 的别名为 conv1d
           aten_name='conv1d',  # 设置底层 ATen 函数的名称为 conv1d
           dtypes=floating_and_complex_types_and(torch.int64, torch.float16, torch.bfloat16),  # 支持的数据类型包括浮点数和复数类型以及 torch.int64, torch.float16, torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.chalf,  # 在 CUDA 下支持的数据类型包括 torch.float16, torch.chalf, torch.bfloat16
                                                       torch.bfloat16),
           sample_inputs_func=sample_inputs_conv1d,  # 设置用于生成 conv1d 输入样本的函数为 sample_inputs_conv1d
           error_inputs_func=error_inputs_conv1d,  # 设置用于 conv1d 错误输入的函数为 error_inputs_conv1d
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向梯度与后向梯度的一致性检查
           assert_jit_shape_analysis=True,  # 对 JIT 形状分析进行断言
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 设置梯度检查中非确定性部分的容差阈值为 GRADCHECK_NONDET_TOL
           decorators=(  # 设置修饰器信息，这里包含两个 DecorateInfo 对象
               DecorateInfo(  # 第一个修饰器对象，用于复杂半精度测试的通用测试
                   toleranceOverride({torch.chalf: tol(atol=1e-2, rtol=5e-2)}),  # 设置 torch.chalf 类型的容差参数
                   'TestCommon', 'test_complex_half_reference_testing'  # 指定测试类和方法
               ),
               DecorateInfo(  # 第二个修饰器对象，用于全面测试归纳操作信息
                   toleranceOverride({torch.float16: tol(atol=2e-3, rtol=1e-3)}),  # 设置 torch.float16 类型的容差参数
                   'TestInductorOpInfo', 'test_comprehensive', device_type='cuda',  # 指定测试类、方法及设备类型为 cuda
               ),
           ),
           skips=(  # 设置跳过的测试信息，这里包含三个 DecorateInfo 对象
               # 跳过 JIT 变体一致性测试的信息
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),
               # 预期测试自定义规则 dtype (torch.complex64, torch.complex128) 失败的信息
               DecorateInfo(unittest.expectedFailure, 'TestDtypeCustomRules',
                            'test_custom_rules', dtypes=(torch.complex64, torch.complex128)),
               # 测试 NNC 正确性时预期的 dtype (torch.complex64, torch.complex128) 失败的信息
               DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo',
                            'test_nnc_correctness', dtypes=(torch.complex64, torch.complex128)),
           ),
           supports_expanded_weight=True,  # 支持扩展权重
           supports_out=False,)  # 不支持输出
    OpInfo('nn.functional.conv2d',
           # 定义操作信息对象，针对 nn.functional.conv2d 函数
           aliases=('conv2d',),
           # 别名列表包括 'conv2d'
           aten_name='conv2d',
           # ATen 函数名称为 'conv2d'
           dtypes=floating_and_complex_types_and(torch.int64, torch.float16, torch.bfloat16),
           # 支持的数据类型包括浮点数和复数类型，以及 torch.int64, torch.float16, torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.chalf,
                                                       torch.bfloat16),
           # CUDA 下支持的数据类型包括浮点16位，复数类型 torch.chalf，以及 torch.bfloat16
           sample_inputs_func=partial(sample_inputs_conv2d),
           # 使用 partial 函数设置 sample_inputs_func，用于生成 conv2d 的示例输入
           error_inputs_func=error_inputs_conv2d,
           # 设置 error_inputs_func，用于生成 conv2d 的错误输入
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           # 设置梯度检查的非确定性容差
           # 在慢速梯度检查上运行得很慢 - 或者可以缩小输入大小作为替代
           gradcheck_fast_mode=True,
           # 使用快速模式进行梯度检查
           supports_forward_ad=True,
           # 支持向前自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向梯度和反向梯度
           assert_jit_shape_analysis=True,
           # 断言 JIT 形状分析为 True
           decorators=(
               DecorateInfo(
                   toleranceOverride({torch.chalf: tol(atol=6e-2, rtol=5e-2)}),
                   'TestCommon', 'test_complex_half_reference_testing',
               ),
           ),
           # 装饰器信息，用于测试复杂半浮点参考测试
           skips=(
               # 在某些配置上工作！跳过此测试
               DecorateInfo(unittest.skip("Works on some configs!"), 'TestJit', 'test_variant_consistency_jit'),
               # 参考：https://github.com/pytorch/pytorch/issues/75309
               # 预期失败：None 不匹配：torch.complex128 不为 None
               DecorateInfo(unittest.expectedFailure, 'TestDtypeCustomRules',
                            'test_custom_rules', dtypes=(torch.complex64, torch.complex128)),
               # 运行时错误：不支持的数据类型：complex
               DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo',
                            'test_nnc_correctness', dtypes=(torch.complex64, torch.complex128)),
           ),
           # 跳过的测试用例信息，针对不同的错误或不支持的数据类型
           supports_expanded_weight=True,
           # 支持扩展权重
           supports_out=False,
           # 不支持输出结果，
    ),
    OpInfo('nn.functional.conv3d',  # 定义操作信息对象，针对 nn.functional.conv3d 函数
           aliases=('conv3d',),  # 别名为 'conv3d'
           aten_name='conv3d',  # 底层 ATen 函数名为 'conv3d'
           dtypes=floating_and_complex_types_and(torch.int64, torch.bfloat16, torch.float16),  # 支持的数据类型包括浮点数和复数类型，以及 torch.int64, torch.bfloat16, torch.float16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.chalf, torch.bfloat16),  # 在 CUDA 环境下支持的数据类型包括 torch.float16, torch.chalf, torch.bfloat16
           sample_inputs_func=sample_inputs_conv3d,  # 用于生成 conv3d 函数的示例输入的函数名为 sample_inputs_conv3d
           error_inputs_func=error_inputs_conv3d,  # 用于生成 conv3d 函数的错误输入的函数名为 error_inputs_conv3d
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 非确定性梯度检查的容差阈值
           gradcheck_fast_mode=True,  # 使用快速模式进行梯度检查
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           decorators=(  # 装饰器信息元组开始
               DecorateInfo(
                   toleranceOverride({torch.chalf: tol(atol=6e-2, rtol=5e-2)}),  # 覆盖容差信息，针对 torch.chalf 类型设置绝对误差 atol=6e-2, 相对误差 rtol=5e-2
                   'TestCommon', 'test_complex_half_reference_testing',  # 测试类 'TestCommon' 中的 'test_complex_half_reference_testing' 测试方法
               ),
               # TF32
               DecorateInfo(
                   toleranceOverride({torch.float32: tol(atol=5e-3, rtol=1e-3)}),  # 覆盖容差信息，针对 torch.float32 类型设置绝对误差 atol=5e-3, 相对误差 rtol=1e-3
                   'TestCommon', 'test_noncontiguous_samples',  # 测试类 'TestCommon' 中的 'test_noncontiguous_samples' 测试方法
               ),
               DecorateInfo(
                   toleranceOverride({torch.complex64: tol(atol=5e-5, rtol=5e-6)}),  # 覆盖容差信息，针对 torch.complex64 类型设置绝对误差 atol=5e-5, 相对误差 rtol=5e-6
                   'TestMathBits', 'test_conj_view',  # 测试类 'TestMathBits' 中的 'test_conj_view' 测试方法
               ),
               DecorateInfo(
                   toleranceOverride({torch.float32: tol(atol=5e-5, rtol=5e-6)}),  # 覆盖容差信息，针对 torch.float32 类型设置绝对误差 atol=5e-5, 相对误差 rtol=5e-6
                   'TestOperators', 'test_vjpvmap',  # 测试类 'TestOperators' 中的 'test_vjpvmap' 测试方法
               ),
           ),  # 装饰器信息元组结束
           skips=(  # 跳过的测试信息元组开始
               # RuntimeError: !lhs.isAliasOf(rhs) INTERNAL ASSERT FAILED at
               # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":103, please report a bug to PyTorch.
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),  # 跳过 'TestJit' 类中的 'test_variant_consistency_jit' 测试方法，并附带跳过原因
               # RuntimeError: UNSUPPORTED DTYPE: complex
               DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_nnc_correctness',  # 预期测试失败，测试类 'TestNNCOpInfo' 中的 'test_nnc_correctness' 方法，针对复数类型 (torch.complex64, torch.complex128)
                            dtypes=(torch.complex64, torch.complex128)),
               # AssertionError: Tensor-likes are not close!
               # break slow tests
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_compare_cpu'),  # 跳过 'TestCommon' 类中的 'test_compare_cpu' 测试方法，并附带跳过原因
           ),  # 跳过的测试信息元组结束
           supports_expanded_weight=True,  # 支持扩展权重
           supports_out=False,)  # 不支持输出
    OpInfo('nn.functional.group_norm',
           # 创建操作信息对象，描述 nn.functional.group_norm 函数的特性
           aten_name='group_norm',
           # 指定对应的 ATen 名称
           aliases=('group_norm',),
           # 别名列表，包括 'group_norm'
           ref=reference_group_norm,
           # 参考实现函数的引用
           dtypes=floating_types_and(torch.float16, torch.bfloat16),
           # 支持的数据类型，包括浮点类型和 torch.float16、torch.bfloat16
           supports_out=False,
           # 不支持输出张量的梯度计算
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向和后向梯度计算
           error_inputs_func=error_inputs_group_norm,
           # 错误输入函数，用于测试异常情况
           decorators=[
               # 修饰器列表，用于装饰测试函数
               # RuntimeError: Cannot insert a Tensor that requires grad as a constant.
               # Consider making it a parameter or input, or detaching the gradient
               # 标记预期的单元测试失败，用于 torch.float32 类型
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,))
           ],
           sample_inputs_func=sample_inputs_group_norm,
           # 样本输入函数，用于生成测试样本
           reference_inputs_func=reference_inputs_group_norm,
           # 参考输入函数，生成参考输入用于测试
           supports_expanded_weight=True,),
           # 支持扩展权重
    OpInfo('nn.functional.instance_norm',
           # 创建操作信息对象，描述 nn.functional.instance_norm 函数的特性
           # no ref because instance_norm will often have numerical instability (large numbers or nan)
           # 由于 instance_norm 经常会出现数值不稳定性（大数或 NaN），没有参考实现函数
           dtypes=floating_types_and(torch.float16, torch.bfloat16),
           # 支持的数据类型，包括浮点类型和 torch.float16、torch.bfloat16
           supports_out=False,
           # 不支持输出张量的梯度计算
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向和后向梯度计算
           allow_cow_input_materialize_forward=['running_mean', 'running_var'],
           # 允许 COW 输入材料化前向传递，包括 'running_mean', 'running_var'
           decorators=[
               # 修饰器列表，用于装饰测试函数
               # RuntimeError: Cannot insert a Tensor that requires grad as a constant.
               # Consider making it a parameter or input, or detaching the gradient
               # 标记预期的单元测试失败，用于 torch.float32 类型
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),
           ],
           sample_inputs_func=sample_inputs_instance_norm,
           # 样本输入函数，用于生成测试样本
           supports_expanded_weight=True,),
           # 支持扩展权重
    OpInfo('nn.functional.layer_norm',
           # 创建操作信息对象，描述 nn.functional.layer_norm 函数的特性
           aten_name='layer_norm',
           # 指定对应的 ATen 名称
           aten_backward_name='layer_norm_backward',
           # 指定反向传播时的 ATen 名称
           aliases=('layer_norm',),
           # 别名列表，包括 'layer_norm'
           ref=reference_layer_norm,
           # 参考实现函数的引用
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           # 支持的数据类型，包括浮点类型和 torch.half、torch.bfloat16
           supports_out=False,
           # 不支持输出张量的梯度计算
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向和后向梯度计算
           assert_jit_shape_analysis=True,
           # 断言 JIT 形状分析为真
           decorators=[
               # 修饰器列表，用于装饰测试函数
               # 设置对 torch.float32 数据类型的容差覆盖，绝对误差容差为 1e-05，相对误差容差为 1e-03
               DecorateInfo(
                   toleranceOverride({torch.float32: tol(atol=1e-05, rtol=1e-03)}),
                   'TestCommon', 'test_numpy_refs'
               ),
               # 跳过因 MPS 后端中的 bug 而导致的单元测试失败
               DecorateInfo(unittest.skip("Bug in MPS backend!"), 'TestCommon', 'test_numpy_ref_mps'),
           ],
           sample_inputs_func=sample_inputs_layer_norm,
           # 样本输入函数，用于生成测试样本
           supports_expanded_weight=True,),
           # 支持扩展权重
    OpInfo('nn.functional.rms_norm',
           # 创建操作信息对象，描述 nn.functional.rms_norm 函数的特性
           aten_name='rms_norm',
           # 指定对应的 ATen 名称
           aliases=('rms_norm',),
           # 别名列表，包括 'rms_norm'
           ref=reference_rms_norm,
           # 参考实现函数的引用
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),
           # 支持的数据类型，包括浮点类型和复数类型，以及 torch.half、torch.bfloat16
           supports_out=False,
           # 不支持输出张量的梯度计算
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向和后向梯度计算
           sample_inputs_func=sample_inputs_rms_norm,
           # 样本输入函数，用于生成测试样本
           error_inputs_func=error_inputs_rms_norm,),
           # 错误输入函数，用于测试异常情况
    OpInfo('nn.functional.local_response_norm',
           # 定义操作信息，指定函数名和参数类型
           dtypes=floating_types_and(torch.int64, torch.float16, torch.bfloat16),
           # CUDA环境下的数据类型限制
           dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           supports_out=False,  # 不支持输出
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向后向梯度一致性检查
           decorators=[
               # 修饰器信息，用于特定测试情况下的装饰
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),
           ],
           sample_inputs_func=sample_inputs_local_response_norm,),  # 样本输入生成函数
    OpInfo('constant_pad_nd',
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向后向梯度一致性检查
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half),  # 所有数据类型及复杂类型
           sample_inputs_func=sample_inputs_constant_pad_nd,  # 样本输入生成函数
           supports_out=False,  # 不支持输出
           skips=(
               # 布尔类型不能传递给标量参数在JIT跟踪器中，因为BoolType不是ScalarType的子类型。
               DecorateInfo(
                   unittest.expectedFailure, 'TestNNCOpInfo',
                   'test_nnc_correctness', dtypes=(torch.bool,)),
           )),
    OpInfo('nn.functional.pad',
           variant_test_name='constant',  # 变体测试名称为常量
           aten_name='constant_pad_nd',  # 对应的ATen操作名
           # 在慢速梯度检查上运行非常慢 - 或者减少输入大小作为替代方法
           gradcheck_fast_mode=True,
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向后向梯度一致性检查
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half),  # 所有数据类型及复杂类型
           sample_inputs_func=partial(sample_inputs_nn_pad, mode='constant'),  # 部分应用的样本输入生成函数，使用常量模式
           supports_out=False),  # 不支持输出
    OpInfo('nn.functional.pad',
           variant_test_name='reflect',  # 变体测试名称为反射
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向后向梯度一致性检查
           dtypes=all_types_and_complex_and(torch.bfloat16),  # 所有数据类型及复杂类型，但仅限于torch.bfloat16
           dtypesIfCUDA=all_types_and_complex_and(torch.half, torch.bfloat16),  # CUDA环境下的数据类型限制
           sample_inputs_func=partial(sample_inputs_nn_pad, mode='reflect'),  # 部分应用的样本输入生成函数，使用反射模式
           skips=(
               # 没有对应的ATen操作符。
               # RuntimeError: falseINTERNAL ASSERT FAILED at
               # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),
           ),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 梯度检查的非确定性公差
           supports_out=False),  # 不支持输出
    # 定义 OpInfo 对象，描述 nn.functional.pad 操作的特定变体 'replicate'
    OpInfo('nn.functional.pad',
           variant_test_name='replicate',
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向自动求导
           dtypes=all_types_and_complex_and(torch.bfloat16),  # 所有数据类型及复杂数据类型（torch.bfloat16）
           dtypesIfCUDA=all_types_and_complex_and(torch.half, torch.bfloat16),  # 如果在CUDA环境下，支持的数据类型
           sample_inputs_func=partial(sample_inputs_nn_pad, mode='replicate'),  # 生成样本输入的函数，使用 'replicate' 模式
           skips=(
               # 没有对应的原生操作符
               # 运行时错误: falseINTERNAL ASSERT FAILED at
               # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185，请向 PyTorch 报告错误。
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),
           ),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 梯度检查中的非确定性容差
           supports_out=False),  # 不支持输出

    # 定义 OpInfo 对象，描述 nn.functional.pad 操作的特定变体 'replicate_negative'
    OpInfo('nn.functional.pad',
           variant_test_name='replicate_negative',
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向自动求导
           dtypes=all_types_and_complex_and(torch.bfloat16),  # 所有数据类型及复杂数据类型（torch.bfloat16）
           dtypesIfCUDA=all_types_and_complex_and(torch.half, torch.bfloat16),  # 如果在CUDA环境下，支持的数据类型
           sample_inputs_func=sample_inputs_nn_pad_replicate_negative,  # 生成样本输入的函数
           skips=(
               # 没有对应的原生操作符
               # 运行时错误: falseINTERNAL ASSERT FAILED at
               # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185，请向 PyTorch 报告错误。
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),
               # 一些负面填充情况在 MPS 上导致段错误
               DecorateInfo(unittest.skip("Not fully supported on MPS"), 'TestConsistency'),
           ),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 梯度检查中的非确定性容差
           supports_out=False),  # 不支持输出

    # 定义 OpInfo 对象，描述 nn.functional.pad 操作的特定变体 'circular'
    OpInfo('nn.functional.pad',
           variant_test_name='circular',
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half),  # 所有数据类型及复杂数据类型（torch.bool, torch.bfloat16, torch.half）
           sample_inputs_func=partial(sample_inputs_nn_pad, mode='circular'),  # 生成样本输入的函数，使用 'circular' 模式
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向自动求导
           check_batched_grad=False,  # 不检查批处理梯度
           # https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           skips=(
               # 没有对应的原生操作符
               # 运行时错误: falseINTERNAL ASSERT FAILED at
               # "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185，请向 PyTorch 报告错误。
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit', dtypes=(torch.float32,)),
               # 与 <type> 的差异与输出 0 上的新空置分解 new_empty_strided.default 大于原始值
               DecorateInfo(unittest.skip("Expected: new_empty_strided is not comparable"), 'TestDecomp', 'test_comprehensive'),
           ),
           supports_out=False),  # 不支持输出
    OpInfo('nn.functional.hardswish',
           aten_name="hardswish",
           aten_backward_name='hardswish_backward',
           supports_autograd=True,
           assert_autodiffed=True,
           sample_inputs_func=sample_inputs_hardswish,
           dtypes=floating_types_and(torch.bfloat16, torch.half),
           supports_gradgrad=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           supports_out=False,
           autodiff_nonfusible_nodes=["aten::hardswish"]),
    # 描述 'nn.functional.hardswish' 操作的信息，包括各种支持情况和输入样本生成函数

    OpInfo('nn.functional.unfold',
           aten_name='im2col',
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),
           dtypesIfCUDA=floating_and_complex_types_and(torch.half, torch.bfloat16),
           sample_inputs_func=sample_inputs_nn_unfold,
           # 在慢速 gradcheck 上运行速度非常慢 - 或者可以减少输入大小来加快速度
           gradcheck_fast_mode=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           supports_out=False,
           skips=(
               # 注意：此失败在不同系统上可能无法重现
               # false INTERNAL ASSERT FAILED at "...torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185
               DecorateInfo(unittest.skip("Internal assert failed!"), 'TestJit', 'test_variant_consistency_jit'),
           )),
    # 描述 'nn.functional.unfold' 操作的信息，包括数据类型、样本输入函数和跳过的测试信息

    OpInfo('nn.functional.interpolate',
           aten_name="interpolate",
           variant_test_name='nearest',
           supports_autograd=True,
           supports_fwgrad_bwgrad=True,
           supports_forward_ad=True,
           dtypes=floating_types_and(torch.uint8, torch.half, torch.bfloat16),
           sample_inputs_func=partial(sample_inputs_interpolate, 'nearest'),
           skips=(
               # 运行时错误: false
               # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
               # 请向 PyTorch 报告错误。
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           supports_out=False),
    # 描述 'nn.functional.interpolate' 操作的信息，包括数据类型、样本输入函数和跳过的测试信息
    OpInfo('nn.functional.interpolate',
           aten_name="interpolate",
           variant_test_name='nearest-exact',
           supports_autograd=True,
           supports_fwgrad_bwgrad=True,
           supports_forward_ad=True,
           dtypes=floating_types_and(torch.half, torch.bfloat16, torch.uint8),
           sample_inputs_func=partial(sample_inputs_interpolate, 'nearest-exact'),
           skips=(
               # 下面是一些针对特定情况的测试跳过信息，原因如下：

               # 在 unittest 中，期望此测试失败，因为出现了 RuntimeError
               # 相关报错信息：false
               # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
               # 请向 PyTorch 报告此 Bug。
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),

               # 在 unittest 中，期望此测试失败，因为出现了 RuntimeError
               # 相关报错信息：aten::_upsample_nearest_exact*d hit the vmap fallback which is currently disabled
               DecorateInfo(unittest.expectedFailure, 'TestOperators', 'test_vmapjvpall_has_batch_rule'),
               DecorateInfo(unittest.expectedFailure, 'TestOperators', 'test_vmapvjp_has_batch_rule'),

               # 在 unittest 中，期望此测试失败，因为出现了 RuntimeError
               # 相关报错信息：The operator 'aten::_upsample_nearest_exact3d.out' is not currently implemented
               # for the MPS device.
               DecorateInfo(unittest.expectedFailure, 'TestConsistency'),
           ),
           supports_out=False),
    OpInfo('nn.functional.interpolate',
           aten_name="interpolate",
           variant_test_name='linear',
           supports_autograd=True,
           supports_fwgrad_bwgrad=True,
           supports_forward_ad=True,
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           sample_inputs_func=partial(sample_inputs_interpolate, 'linear'),
           skips=(
               # 下面是一些针对特定情况的测试跳过信息，原因如下：

               # 在 unittest 中，期望此测试失败，因为出现了 RuntimeError
               # 相关报错信息：false
               # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
               # 请向 PyTorch 报告此 Bug。
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           supports_out=False),
    OpInfo('nn.functional.interpolate',
           aten_name="interpolate",
           variant_test_name='bilinear',
           supports_fwgrad_bwgrad=True,
           supports_autograd=True,
           supports_forward_ad=True,
           dtypes=floating_types_and(torch.uint8, torch.half, torch.bfloat16),
           dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           sample_inputs_func=partial(sample_inputs_interpolate, 'bilinear'),
           reference_inputs_func=partial(reference_inputs_interpolate, 'bilinear'),
           skips=(
               # 在测试中跳过此变体，因为出现运行时错误和内部断言失败
               # 详细错误信息在 RuntimeError 和 INTERNAL ASSERT FAILED 提供的位置，请向 PyTorch 报告此 bug。
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           supports_out=False),

    OpInfo('nn.functional.interpolate',
           aten_name="interpolate",
           variant_test_name='bicubic',
           supports_autograd=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           dtypes=floating_types_and(torch.uint8, torch.half, torch.bfloat16),
           dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           sample_inputs_func=partial(sample_inputs_interpolate, 'bicubic'),
           reference_inputs_func=partial(reference_inputs_interpolate, 'bicubic'),
           skips=(
               # 在测试中跳过此变体，因为出现运行时错误和内部断言失败
               # 详细错误信息在 RuntimeError 和 INTERNAL ASSERT FAILED 提供的位置，请向 PyTorch 报告此 bug。
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           supports_out=False),

    OpInfo('nn.functional.interpolate',
           aten_name="interpolate",
           variant_test_name='trilinear',
           supports_autograd=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           sample_inputs_func=partial(sample_inputs_interpolate, 'trilinear'),
           skips=(
               # 在测试中跳过此变体，因为出现运行时错误和内部断言失败
               # 详细错误信息在 RuntimeError 和 INTERNAL ASSERT FAILED 提供的位置，请向 PyTorch 报告此 bug。
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           supports_out=False),
    # 定义 OpInfo 对象，描述了 nn.functional.interpolate 函数的操作信息
    OpInfo('nn.functional.interpolate',
           # 指定在 PyTorch ATen 层的名称
           aten_name="interpolate",
           # 指定测试变体的名称为 'area'
           variant_test_name='area',
           # 指定是否支持自动求导
           supports_autograd=True,
           # 指定是否支持前向自动微分
           supports_forward_ad=True,
           # 指定是否支持前向-反向梯度
           supports_fwgrad_bwgrad=True,
           # 指定数据类型为浮点类型和 torch.half、torch.bfloat16 的交集
           dtypes=floating_types_and(torch.half, torch.bfloat16),
           # 在 CUDA 上指定数据类型为浮点类型和 torch.half、torch.bfloat16 的交集
           dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),
           # 指定采样输入函数，使用 partial 函数固定 'area' 参数
           sample_inputs_func=partial(sample_inputs_interpolate, 'area'),
           # 梯度检查非确定性容差设置为预定义的 GRADCHECK_NONDET_TOL
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           # 跳过的测试用例列表，包含了详细的跳过信息
           skips=(
               # 由于错误 RuntimeError: false
               # 在 "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185 处内部断言失败
               # 建议向 PyTorch 报告此 bug
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           # 不支持输出张量
           supports_out=False),

    # 定义 OpInfo 对象，描述了 nn.functional.upsample_bilinear 函数的操作信息
    OpInfo('nn.functional.upsample_bilinear',
           # 指定是否支持自动求导
           supports_autograd=True,
           # 指定是否支持前向自动微分
           supports_forward_ad=True,
           # 指定是否支持前向-反向梯度
           supports_fwgrad_bwgrad=True,
           # 指定数据类型为浮点类型和 torch.uint8、torch.half、torch.bfloat16 的交集
           dtypes=floating_types_and(torch.uint8, torch.half, torch.bfloat16),
           # 在 CUDA 上指定数据类型为浮点类型和 torch.half、torch.bfloat16 的交集
           dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),
           # 梯度检查非确定性容差设置为预定义的 GRADCHECK_NONDET_TOL
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           # 指定采样输入函数，使用 partial 函数固定 'bilinear' 参数
           sample_inputs_func=partial(sample_inputs_upsample, 'bilinear'),
           # 指定参考输入函数，使用 partial 函数固定 'bilinear' 参数
           reference_inputs_func=partial(reference_inputs_upsample, 'bilinear'),
           # 跳过的测试用例列表，包含了详细的跳过信息
           skips=(
               # 由于错误 RuntimeError: false
               # 在 "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185 处内部断言失败
               # 建议向 PyTorch 报告此 bug
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           # 不支持输出张量
           supports_out=False),

    # 定义 OpInfo 对象，描述了 _upsample_bilinear2d_aa 操作的信息
    OpInfo('_upsample_bilinear2d_aa',
           # 指定操作为 torch.ops.aten._upsample_bilinear2d_aa
           op=torch.ops.aten._upsample_bilinear2d_aa,
           # 指定在 PyTorch ATen 层的名称为 '_upsample_bilinear2d_aa'
           aten_name='_upsample_bilinear2d_aa',
           # 指定是否支持自动求导
           supports_autograd=True,
           # 指定是否支持前向自动微分
           supports_forward_ad=True,
           # 指定是否支持前向-反向梯度
           supports_fwgrad_bwgrad=True,
           # 指定数据类型为浮点类型和 torch.uint8 的交集
           dtypes=floating_types_and(torch.uint8),
           # 在 CUDA 上指定数据类型为浮点类型和 torch.half、torch.bfloat16 的交集
           dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),
           # 梯度检查非确定性容差设置为预定义的 GRADCHECK_NONDET_TOL
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           # 指定采样输入函数，使用 partial 函数固定 'bilinear' 参数
           sample_inputs_func=partial(sample_inputs_upsample_aa, 'bilinear'),
           # 不支持输出张量
           supports_out=False,
           # 跳过的测试用例列表，包含了详细的跳过信息
           skips=(
               # 以下测试用例由于不同原因被标记为预期失败
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               DecorateInfo(unittest.expectedFailure, 'TestDTensorOps', 'test_dtensor_op_db'),
               DecorateInfo(unittest.expectedFailure, 'TestEagerFusionOpInfo', 'test_aot_autograd_symbolic_exhaustive'),
               DecorateInfo(unittest.expectedFailure, 'TestInductorOpInfo', 'test_comprehensive'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
           )),
    OpInfo(
        "nn.functional.soft_margin_loss",  # 定义操作信息对象，对应于 nn.functional.soft_margin_loss 函数
        dtypes=floating_types_and(torch.half, torch.bfloat16),  # 支持的数据类型为浮点类型和 torch.half、torch.bfloat16
        supports_out=False,  # 不支持输出张量
        supports_forward_ad=True,  # 支持前向自动求导
        # 不支持目标张量的梯度计算
        sample_inputs_func=partial(sample_inputs_loss, rhs_requires_grad=False),  # 使用部分函数 sample_inputs_loss 生成样本输入，其中 rhs_requires_grad=False
        error_inputs_func=error_inputs_soft_margin_loss,  # 生成 soft_margin_loss 函数的错误输入
    ),
    OpInfo('nn.functional.upsample_nearest',  # 定义操作信息对象，对应于 nn.functional.upsample_nearest 函数
           supports_autograd=True,  # 支持自动求导
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度的计算
           dtypes=floating_types_and(torch.uint8, torch.half, torch.bfloat16),  # 支持的数据类型为浮点类型、torch.uint8、torch.half、torch.bfloat16
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 梯度检查时的非确定性容差值
           sample_inputs_func=partial(sample_inputs_upsample, 'nearest'),  # 使用部分函数 sample_inputs_upsample 生成 'nearest' 类型的上采样样本输入
           skips=(
               # 测试不通过时的跳过信息
               # RuntimeError: false
               # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,
               # please report a bug to PyTorch.
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 标记为预期失败的测试用例装饰信息
           ),
           supports_out=False),  # 不支持输出张量
    OpInfo(
        "nn.functional.margin_ranking_loss",  # 定义操作信息对象，对应于 nn.functional.margin_ranking_loss 函数
        dtypes=all_types_and(torch.half, torch.bfloat16),  # 支持的数据类型为所有类型以及 torch.half、torch.bfloat16
        supports_out=False,  # 不支持输出张量
        sample_inputs_func=sample_inputs_margin_ranking_loss,  # 生成 margin_ranking_loss 函数的样本输入
        error_inputs_func=error_inputs_margin_ranking_loss,  # 生成 margin_ranking_loss 函数的错误输入
        reference_inputs_func=reference_inputs_margin_ranking_loss,  # 生成 margin_ranking_loss 函数的参考输入
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True),  # 支持前向梯度和反向梯度的计算
    OpInfo(
        "nn.functional.multi_margin_loss",  # 定义操作信息对象，对应于 nn.functional.multi_margin_loss 函数
        dtypes=floating_types(),  # 支持的数据类型为浮点类型
        dtypesIfCUDA=floating_types_and(torch.bfloat16, torch.float16),  # 如果在CUDA环境下，还支持 torch.bfloat16 和 torch.float16 类型
        supports_out=False,  # 不支持输出张量
        supports_gradgrad=False,  # 不支持二阶梯度计算
        sample_inputs_func=sample_inputs_multi_margin_loss,  # 生成 multi_margin_loss 函数的样本输入
        reference_inputs_func=reference_inputs_multi_margin_loss,  # 生成 multi_margin_loss 函数的参考输入
        error_inputs_func=error_inputs_multi_margin_loss,  # 生成 multi_margin_loss 函数的错误输入
        decorators=(
            DecorateInfo(
                toleranceOverride({torch.float32: tol(atol=1e-4, rtol=1e-4)}),  # 设置容差覆盖值，对于 torch.float32 类型使用指定的绝对容差和相对容差
                "TestJit",
                "test_variant_consistency_jit",
            ),
        ),
    ),
    OpInfo(
        "nn.functional.multilabel_margin_loss",  # 定义操作信息对象，对应于 nn.functional.multilabel_margin_loss 函数
        dtypes=floating_types(),  # 支持的数据类型为浮点类型
        dtypesIfCUDA=floating_types_and(torch.bfloat16, torch.float16),  # 如果在CUDA环境下，还支持 torch.bfloat16 和 torch.float16 类型
        supports_out=False,  # 不支持输出张量
        supports_gradgrad=False,  # 不支持二阶梯度计算
        sample_inputs_func=sample_inputs_multilabel_margin_loss,  # 生成 multilabel_margin_loss 函数的样本输入
        reference_inputs_func=reference_inputs_multilabel_margin_loss,  # 生成 multilabel_margin_loss 函数的参考输入
        error_inputs_func=error_inputs_multilabel_margin_loss,  # 生成 multilabel_margin_loss 函数的错误输入
    ),
    # 定义 OpInfo 对象，描述 nn.functional.leaky_relu 函数的操作信息
    OpInfo('nn.functional.leaky_relu',
           aliases=None,
           aten_name="leaky_relu",
           aten_backward_name='leaky_relu_backward',
           sample_inputs_func=sample_inputs_leaky_relu,
           dtypes=floating_types_and(torch.bfloat16, torch.float16),
           inplace_variant=lambda x, negative_slope=0.01:
               torch.nn.functional.leaky_relu(x, negative_slope, inplace=True),
           supports_autograd=True,
           assert_autodiffed=True,
           supports_gradgrad=True,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           autodiff_nonfusible_nodes=["aten::leaky_relu"]),
    
    # 定义 OpInfo 对象，描述 nn.functional.multilabel_soft_margin_loss 函数的操作信息
    OpInfo(
        "nn.functional.multilabel_soft_margin_loss",
        supports_out=False,
        dtypes=floating_types_and(torch.half, torch.bfloat16),
        sample_inputs_func=sample_inputs_multilabel_soft_margin_loss,
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        decorators=(
            # 添加修饰信息，指定测试框架和测试方法名
            DecorateInfo(
                toleranceOverride({torch.float32: tol(atol=1e-4, rtol=1e-4)}),
                "TestJit",
                "test_variant_consistency_jit",
            ),
        ),
        skips=(
            # 添加跳过信息，说明为什么在特定条件下跳过测试
            DecorateInfo(
                # 通过 unittest.skip 标记此测试跳过，给出跳过原因
                unittest.skip("Skipped!"),
                "TestJit",
                "test_variant_consistency_jit",
                device_type="cuda",
            ),
        ),
    ),
    
    # 定义 OpInfo 对象，描述 nn.functional.avg_pool2d 函数的操作信息
    OpInfo('nn.functional.avg_pool2d',
           aten_name='avg_pool2d',
           supports_autograd=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           dtypes=floating_types_and(torch.int64, torch.float16, torch.bfloat16),
           dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           error_inputs_func=error_inputs_avg_pool2d,
           sample_inputs_func=sample_inputs_avgpool2d,
           skips=(
               # 添加跳过信息，说明此测试预期会失败
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out', device_type='cuda'),
           )),
    OpInfo('nn.functional.fractional_max_pool2d',
           supports_autograd=True,  # 支持自动求导
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度与反向梯度
           op=lambda input, *args, **kwargs:
               wrapper_set_seed(torch.nn.functional.fractional_max_pool2d, input, *args, **kwargs),  # 使用包装函数设置种子
           # vmap does not support random operations
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 支持的数据类型包括 torch.bfloat16 和 torch.float16
           test_neg_view=False,  # 不测试负视图
           sample_inputs_func=sample_inputs_fractional_max_pool2d,  # 采样输入函数
           decorators=(
               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
               # 错误修正信息：断言错误，张量比较不相等
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # RuntimeError: input->type()->kind() == TypeKind::OptionalType
               # 内部断言失败：类型不匹配 OptionalType
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit')),
           skips=(
               # unittest.skip('output is non-deterministic'): 输出是非确定性的，跳过测试
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),)),
    OpInfo('nn.functional.fractional_max_pool3d',
           supports_autograd=True,  # 支持自动求导
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度与反向梯度
           op=lambda input, *args, **kwargs:
               wrapper_set_seed(torch.nn.functional.fractional_max_pool3d, input, *args, **kwargs),  # 使用包装函数设置种子
           # vmap does not support random operations
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 支持的数据类型包括 torch.bfloat16 和 torch.float16
           test_neg_view=False,  # 不测试负视图
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 梯度检查的非确定性容差值
           sample_inputs_func=sample_inputs_fractional_max_pool3d,  # 采样输入函数
           decorators=(
               # FIXME: both derivatives are implemented incorrectly
               # https://github.com/pytorch/pytorch/issues/69322
               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
               # 错误修正信息：导数实现错误，张量比较不相等
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # RuntimeError: input->type()->kind() == TypeKind::OptionalType
               # 内部断言失败：类型不匹配 OptionalType
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit')),
           skips=(
               # unittest.skip('output is non-deterministic'): 输出是非确定性的，跳过测试
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),)),
    OpInfo('nn.functional.max_pool1d',
           aten_name='max_pool1d',
           supports_autograd=True,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 对于 aten::flatten 使用整数的批处理规则尚未实现
           check_batched_forward_grad=False,
           # TODO: 添加形状检查
           assert_jit_shape_analysis=False,
           dtypes=floating_types_and(torch.bfloat16, torch.float16),
           dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           skips=(
               # 存在的先决条件；需要修复
               DecorateInfo(unittest.skip("在某些配置上有效"), 'TestNNCOpInfo',
                            'test_nnc_correctness', dtypes=(torch.bfloat16,)),
               # RuntimeError: 张量具有非零元素数，但其数据尚未分配
               # Caffe2 使用延迟分配，因此您需要调用 mutable_data() 或 raw_mutable_data()
               # 来实际分配内存
               DecorateInfo(unittest.skip("跳过！"), 'TestTags', 'test_tags'),
           ),
           error_inputs_func=error_inputs_max_pool1d,
           sample_inputs_func=sample_inputs_max_pool),
    
    OpInfo('nn.functional.max_pool2d',
           aten_name='max_pool2d',
           # 在慢速 gradcheck 上运行非常缓慢 - 或者减少输入大小
           gradcheck_fast_mode=True,
           # Vmap 不支持非连续（channels_last）的输入
           check_batched_gradgrad=False,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 对于 aten::flatten 使用整数的批处理规则尚未实现
           check_batched_forward_grad=False,
           assert_jit_shape_analysis=True,
           dtypes=all_types_and(torch.float16, torch.bfloat16),
           dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           error_inputs_func=error_inputs_max_pool2d,
           sample_inputs_func=sample_inputs_max_pool),
    OpInfo('max_pool2d_with_indices_backward',
           op=max_pool2d_backward,
           # 我们定义了一个自定义操作，因此没有对应的 ATen 操作
           aten_name=None,
           method_variant=None,
           inplace_variant=None,
           operator_variant=None,
           inplace_operator_variant=None,
           check_batched_gradgrad=False,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           check_batched_forward_grad=False,
           assert_jit_shape_analysis=False,
           # 使用浮点类型和 torch.bfloat16、torch.float16 的数据类型
           dtypes=floating_types_and(torch.bfloat16, torch.float16),
           # 使用 sample_inputs_max_pool 函数生成样本输入
           sample_inputs_func=sample_inputs_max_pool,
           skips=(
               # 我们在这里定义了一个自定义操作，不处理接收 out kwarg 的情况
               DecorateInfo(unittest.skip("Skipped!"), "TestCommon", "test_out"),
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               # FX 未能规范化操作 - 将该操作添加到 op_skip 列表中。
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # 对象没有 max_pool2d_with_indices_backward 属性（在 torch 上不可用，因此是预期的）
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit')
           )),
    OpInfo('nn.functional.max_pool3d',
           # 对应的 ATen 操作为 max_pool3d
           aten_name='max_pool3d',
           # 在慢速 gradcheck 上运行非常慢 - 或者可以减少输入大小
           gradcheck_fast_mode=True,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 对于 aten::flatten.using_ints，未实现批处理规则
           check_batched_forward_grad=False,
           # TODO: 添加形状检查
           assert_jit_shape_analysis=False,
           # 使用所有类型和 torch.bfloat16、torch.float16 的数据类型
           dtypes=all_types_and(torch.bfloat16, torch.float16),
           # 如果是 CUDA，使用浮点类型和 torch.float16、torch.bfloat16 的数据类型
           dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           # TODO: 调查非确定性
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           # 使用 error_inputs_max_pool3d 函数生成错误输入
           error_inputs_func=error_inputs_max_pool3d,
           # 使用 sample_inputs_max_pool 函数生成样本输入
           sample_inputs_func=sample_inputs_max_pool),
    # 定义一个 OpInfo 对象，描述 nn.functional.max_unpool1d 操作的信息
    OpInfo('nn.functional.max_unpool1d',
           # 指定原始函数名称
           aten_name='max_unpool1d',
           # 支持自动求导
           supports_autograd=True,
           # 支持正向自动微分
           supports_forward_ad=True,
           # 支持前向梯度和反向梯度
           supports_fwgrad_bwgrad=True,
           # 不支持输出参数
           supports_out=False,
           # 不断言 JIT 形状分析
           assert_jit_shape_analysis=False,
           # 数据类型为浮点类型
           dtypes=floating_types(),
           # 如果是 CUDA，则数据类型为浮点类型和 torch.float16
           dtypesIfCUDA=floating_types_and(torch.float16),
           # 获取示例输入的函数为 sample_inputs_max_unpool
           sample_inputs_func=sample_inputs_max_unpool,
           # 跳过以下测试用例，因为在某些情况下存在非确定性
           skips=(
               # 梯度测试在 `variant_test_name=grad` 时进行。
               # 下面跳过的测试用例是因为在 backward 中使用 gather 时存在非确定性，
               # 特别是当有多个索引指向相同的内存位置时，
               # gradcheck 无法同时扰动它们（详见 sample_inputs_max_unpool_grad）。
               DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients', 'test_fn_grad'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients', 'test_fn_gradgrad'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients', 'test_forward_mode_AD',
                            # 如果不是 macOS，则激活该测试
                            active_if=(not IS_MACOS)),
               DecorateInfo(unittest.skip("Skipped!"), 'TestCompositeCompliance', 'test_forward_ad',
                            # 设备类型为 CPU 时激活该测试
                            device_type='cpu'),
           )),
    # 定义另一个 OpInfo 对象，针对 nn.functional.max_unpool1d 操作的梯度测试
    OpInfo('nn.functional.max_unpool1d',
           # 变体测试名称为 grad
           variant_test_name='grad',
           # 指定原始函数名称
           aten_name='max_unpool1d',
           # 支持自动求导
           supports_autograd=True,
           # 支持正向自动微分
           supports_forward_ad=True,
           # 支持前向梯度和反向梯度
           supports_fwgrad_bwgrad=True,
           # 不支持输出参数
           supports_out=False,
           # 不断言 JIT 形状分析
           assert_jit_shape_analysis=False,
           # 数据类型为浮点类型
           dtypes=floating_types(),
           # 如果是 CUDA，则数据类型为浮点类型和 torch.float16
           dtypesIfCUDA=floating_types_and(torch.float16),
           # 获取示例输入的函数为 sample_inputs_max_unpool_grad
           sample_inputs_func=sample_inputs_max_unpool_grad),
    # 定义 OpInfo 对象，描述 nn.functional.max_unpool2d 函数的信息
    OpInfo('nn.functional.max_unpool2d',
           # 指定原始的 ATen 函数名称
           aten_name='max_unpool2d',
           # 是否支持自动微分
           supports_autograd=True,
           # 是否支持前向自动微分
           supports_forward_ad=True,
           # 是否支持前向-后向梯度
           supports_fwgrad_bwgrad=True,
           # 不支持输出参数
           supports_out=False,
           # 关闭 JIT 形状分析断言
           assert_jit_shape_analysis=False,
           # 数据类型为浮点数类型
           dtypes=floating_types(),
           # 如果是 CUDA，支持浮点数和 torch.float16 类型
           dtypesIfCUDA=floating_types_and(torch.float16),
           # 获取用于样本输入的函数，这里是 sample_inputs_max_unpool
           sample_inputs_func=sample_inputs_max_unpool,
           # 跳过的测试用例，详细理由如下：
           skips=(
               # 梯度测试在下面的 `variant_test_name=grad` 中已经进行
               # 在使用 gather 时存在非确定性，当多个索引指向相同内存位置时，
               # gradcheck 无法同时扰动所有这些索引，因此跳过这些测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients', 'test_forward_mode_AD',
                            active_if=(not IS_MACOS)),
               DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients', 'test_fn_gradgrad'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients', 'test_fn_grad'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestCompositeCompliance', 'test_forward_ad'),
           )),
    # 定义 OpInfo 对象，用于描述 nn.functional.max_unpool2d 函数的梯度变体测试信息
    OpInfo('nn.functional.max_unpool2d',
           # 指定变体测试的名称为 'grad'
           variant_test_name='grad',
           # 指定原始的 ATen 函数名称
           aten_name='max_unpool2d',
           # 使用快速模式进行梯度检查，用于缓解慢速的 gradcheck
           gradcheck_fast_mode=True,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向-后向梯度
           supports_fwgrad_bwgrad=True,
           # Vmap 对非连续的输入（如 channels_last）不友好，因此不检查批量化梯度
           check_batched_grad=False,
           # 不支持输出参数
           supports_out=False,
           # 关闭 JIT 形状分析断言
           assert_jit_shape_analysis=False,
           # 数据类型为浮点数类型
           dtypes=floating_types(),
           # 如果是 CUDA，支持浮点数和 torch.float16 类型
           dtypesIfCUDA=floating_types_and(torch.float16),
           # 获取用于梯度样本输入的函数，这里是 sample_inputs_max_unpool_grad
           sample_inputs_func=sample_inputs_max_unpool_grad),
    OpInfo('nn.functional.max_unpool3d',
           aten_name='max_unpool3d',
           # 在慢速梯度检查上运行非常缓慢 - 或者可以减少输入大小来替代
           gradcheck_fast_mode=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           supports_out=False,
           assert_jit_shape_analysis=False,
           dtypes=floating_types(),  # 使用浮点类型进行数据类型检查
           dtypesIfCUDA=floating_types_and(torch.float16),  # 如果是CUDA，则使用浮点类型和torch.float16进行数据类型检查
           sample_inputs_func=sample_inputs_max_unpool,  # 获取用于max_unpool的样本输入函数
           skips=(
               # 在`variant_test_name=grad`中测试梯度。
               # 我们在这里跳过测试，因为在使用gather时存在非确定性的反向传播，
               # 当写入相同内存位置并且多个索引指向相同内存时，
               # gradcheck对此毫无察觉，并且无法同时扰动它们（有关更多信息，请查看sample_inputs_max_unpool_grad）。
               DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients', 'test_forward_mode_AD',
                            active_if=(not IS_MACOS)),  # 如果不是MACOS，则激活
               DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients', 'test_fn_gradgrad'),  # 跳过梯度的二阶测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients', 'test_fn_grad'),  # 跳过梯度的一阶测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestCompositeCompliance', 'test_forward_ad'),  # 跳过前向自动微分的测试
           )),
    OpInfo('nn.functional.max_unpool3d',
           variant_test_name='grad',  # 变体测试名称为'grad'
           aten_name='max_unpool3d',
           supports_autograd=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           supports_out=False,
           assert_jit_shape_analysis=False,
           dtypes=floating_types(),  # 使用浮点类型进行数据类型检查
           dtypesIfCUDA=floating_types_and(torch.float16),  # 如果是CUDA，则使用浮点类型和torch.float16进行数据类型检查
           sample_inputs_func=sample_inputs_max_unpool_grad),  # 获取用于max_unpool梯度的样本输入函数
    OpInfo('nn.functional.linear',
           aten_name='linear',
           supports_autograd=True,
           supports_gradgrad=True,
           sample_inputs_func=sample_inputs_linear,
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           dtypesIfROCM=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           backward_dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           # linear calls mm under the hood which is nondeterministic on CUDA
           # https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # See https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,
           supports_expanded_weight=True,
           decorators=(
               # Strides are not the same!
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
           )),

对 `nn.functional.linear` 函数的信息描述，包括其操作名称、是否支持自动求导和双重自动求导，以及提供样本输入函数。定义了函数的数据类型，特别是在不同的设备（CUDA或ROCM）上的数据类型。设置了在CUDA上进行梯度检查时的非确定性容忍度。还指出了它是否支持前向自动求导和前向-反向梯度计算，以及是否支持扩展权重和特定的装饰器信息。


    OpInfo('nn.functional.bilinear',
           aten_name='bilinear',
           supports_autograd=True,
           sample_inputs_func=sample_inputs_bilinear,
           dtypes=all_types_and(torch.float16, torch.bfloat16),
           dtypesIfCUDA=floating_types_and(torch.float16,
                                           *[torch.bfloat16] if SM53OrLater or TEST_WITH_ROCM else []),
           decorators=(
               DecorateInfo(toleranceOverride({torch.float16: tol(atol=5e-05, rtol=1e-03)}),
                            'TestInductorOpInfo', 'test_comprehensive', device_type='cpu'),
           ),
           skips=(
               # NVIDIA only assures that bfloat16 is supported by bmm if SM >= 5.3
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_dtypes', device_type='cuda', active_if=not SM53OrLater),
               DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo', 'test_nnc_correctness', dtypes=(torch.bfloat16,)),
           ),
           # Runs very slowly on slow gradcheck - alternatively reduce input sizes
           gradcheck_fast_mode=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           supports_out=False),

对 `nn.functional.bilinear` 函数的信息描述，包括其操作名称、是否支持自动求导，提供样本输入函数。定义了函数的数据类型，特别是在CUDA上的数据类型，并根据条件选择性地包括 `torch.bfloat16` 类型。设置了一个特定的装饰器信息来覆盖浮点数值的公差。指出了在特定条件下跳过测试的信息，以及设置梯度检查为快速模式。还说明了是否支持前向自动求导和前向-反向梯度计算，以及是否支持输出。


    OpInfo('nn.functional.glu',
           aten_name='glu',
           # Runs very slowly on slow gradcheck - alternatively reduce input sizes
           gradcheck_fast_mode=True,
           sample_inputs_func=sample_inputs_glu,
           dtypes=floating_types_and(torch.bfloat16, torch.float16),
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           supports_out=False),

对 `nn.functional.glu` 函数的信息描述，包括其操作名称。指出了梯度检查在慢速模式下运行时的性能问题，并提出了减少输入大小的替代方案。定义了函数的数据类型，特别是浮点数类型。说明了是否支持前向自动求导和前向-反向梯度计算，以及是否支持输出。
    # 定义一个 UnaryUfuncInfo 对象，表示 nn.functional.elu 函数的信息
    UnaryUfuncInfo(
        'nn.functional.elu',  # 函数名称为 nn.functional.elu
        aten_backward_name='elu_backward',  # 对应的 ATen 后向函数名称为 elu_backward
        ref=lambda x, alpha=1.0, inplace=False:
            np.maximum(0., x) + np.minimum(0., alpha * (np.exp(x) - 1)),  # 参考实现，计算 ELU 函数的结果
        dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 支持的数据类型包括浮点数类型和 torch.bfloat16 和 torch.float16
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        supports_autograd=True,  # 支持自动微分
        assert_autodiffed=False,  # 自动微分结果是否被断言为 False
        supports_gradgrad=True,  # 支持二阶梯度
        supports_out=False,  # 不支持指定输出
        sample_kwargs=lambda device, dtype, input:
            ({'alpha': 0.8}, {'alpha': 0.8}),  # 示例参数为 alpha=0.8
        inplace_variant=lambda x, alpha=1.0:
            torch.nn.functional.elu(x, alpha, inplace=True),  # 支持 inplace 操作的 ELU 变体
        decorators=[
            DecorateInfo(
                toleranceOverride({  # 设置容差修正器，针对不同的数据类型设置不同的容差
                    torch.float16: tol(atol=1e-03, rtol=1.2e-03),
                    torch.bfloat16: tol(atol=1e-03, rtol=1.2e-03)
                }),
                'TestUnaryUfuncs', device_type='cuda',  # 使用 CUDA 运行测试
            ), ],
    ),

    # 标记为 Unary 函数，因为它在第二个参数上有一些奇怪的广播语义
    UnaryUfuncInfo(
        'nn.functional.prelu',  # 函数名称为 nn.functional.prelu
        aten_backward_name='_prelu_kernel_backward',  # 对应的 ATen 后向函数名称为 _prelu_kernel_backward
        ref=lambda x, weight:
            np.maximum(0., x) + np.minimum(0., x) *
            (weight if x.ndim == 1 else weight.reshape([weight.size if i == 1 else 1 for i in range(0, x.ndim)])),  # 参考实现，计算 PReLU 函数的结果
        dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 支持的数据类型包括浮点数类型和 torch.bfloat16 和 torch.float16
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        supports_autograd=True,  # 支持自动微分
        assert_autodiffed=False,  # 自动微分结果是否被断言为 False
        supports_gradgrad=True,  # 支持二阶梯度
        supports_out=False,  # 不支持指定输出
        sample_kwargs=sample_kwargs_prelu_scalar_weight,  # 示例参数函数，用于测试权重张量是标量的情况
        error_inputs_func=error_inputs_prelu,  # 错误输入生成函数，用于测试错误输入情况
        sample_inputs_func=sample_inputs_prelu,  # 示例输入生成函数，用于测试
        reference_inputs_func=reference_inputs_prelu,  # 参考输入生成函数，用于测试
        decorators=[
            # 预期的失败装饰器，用于测试 JIT 一致性
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'), ],
    ),
    UnaryUfuncInfo(
        'nn.functional.celu',  # 指定函数名为 'nn.functional.celu'
        ref=lambda x, alpha=1.0, inplace=False:  # 定义参考实现的匿名函数，计算 CELU 函数的值
            np.maximum(0., x) + np.minimum(0., alpha * (np.exp(x / alpha) - 1)),
        dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 指定支持的数据类型为浮点类型和 torch.bfloat16、torch.float16
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度的自动微分
        supports_autograd=True,  # 支持自动微分
        assert_autodiffed=False,  # 不断言自动微分已完成
        supports_gradgrad=True,  # 支持二阶梯度计算
        supports_out=False,  # 不支持输出张量指定位置操作
        sample_kwargs=lambda device, dtype, input:  # 定义用于测试的参数设置函数，返回固定的 alpha 参数值
            ({'alpha': 0.8}, {'alpha': 0.8}),
        inplace_variant=lambda x, alpha=1.0:  # 定义支持原地操作的变体函数，使用 torch.nn.functional.celu 实现
            torch.nn.functional.celu(x, alpha, inplace=True),
        decorators=[  # 装饰器列表，应用于测试环境的设置
            DecorateInfo(
                toleranceOverride({  # 设置容差覆盖函数，针对不同数据类型设置不同的容差
                    torch.float16: tol(atol=1e-03, rtol=1.2e-03),
                    torch.bfloat16: tol(atol=1e-03, rtol=1.2e-03)
                }),
                'TestUnaryUfuncs', device_type='cuda',  # 设置测试的设备类型为 'cuda'
            ),
        ],
    ),
    UnaryUfuncInfo(
        'nn.functional.rrelu',  # 使用 nn.functional.rrelu 函数
        aten_backward_name='rrelu_with_noise_backward',  # 对应的 ATen 后向传播函数名称
        op=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.rrelu, input, *args, **kwargs),  # 用于前向传播的包装函数，设置随机种子
        inplace_variant=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.rrelu, input, *args, inplace=True, **kwargs),  # 用于原地操作的包装函数，设置随机种子
        dtypes=floating_types_and(torch.bfloat16),  # 支持的数据类型，包括浮点数和 torch.bfloat16
        dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),  # 如果是 CUDA，支持的数据类型
        gradcheck_wrapper=wrapper_set_seed,  # 梯度检查的包装函数，设置随机种子
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        supports_out=False,  # 不支持输出参数
        sample_kwargs=lambda device, dtype, input:
            (dict(lower=0., upper=1., training=True), dict(lower=0., upper=1., training=True)),  # 用于样本参数的函数，返回设备、数据类型和输入的字典
        sample_inputs_func=sample_inputs_rrelu,  # 用于生成输入样本的函数
        error_inputs_func=error_inputs_rrelu,  # 用于错误输入的函数
        decorators=(
            DecorateInfo(
                toleranceOverride({
                    torch.float16: tol(atol=1e-03, rtol=1.2e-03),  # 浮点数类型的容差设置
                    torch.bfloat16: tol(atol=1e-03, rtol=1.2e-03)  # torch.bfloat16 类型的容差设置
                }),
                'TestUnaryUfuncs', device_type='cuda',  # 装饰器信息，测试一元函数，CUDA 设备
            ),),
        skips=(
            # lambda impl
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 跳过的测试信息：期望失败，标准化操作器测试中的穷举测试
            # lambda impl
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 跳过的测试信息：期望失败，JIT 变体一致性测试
            # In-place operations do not play well with forward AD
            # https://github.com/pytorch/pytorch/issues/77447
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients',
                         'test_inplace_forward_mode_AD'),  # 跳过的测试信息：期望失败，前向自动求导中的原地操作模式测试
            # The noise vector that's generated in these tests is not the same elementwise
            DecorateInfo(unittest.skip("Different noise"), 'TestUnaryUfuncs', 'test_batch_vs_slicing'),  # 跳过的测试信息：不同的噪声，批处理与切片测试
            DecorateInfo(unittest.skip("Different noise"), 'TestUnaryUfuncs', 'test_contig_vs_every_other'),  # 跳过的测试信息：不同的噪声，连续与每隔一个测试
            DecorateInfo(unittest.skip("Different noise"), 'TestUnaryUfuncs', 'test_non_contig_expand'),  # 跳过的测试信息：不同的噪声，非连续扩展测试
            DecorateInfo(unittest.skip("Different noise"), 'TestUnaryUfuncs', 'test_contig_vs_transposed'),  # 跳过的测试信息：不同的噪声，连续与转置测试
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'))),  # 跳过的测试信息：输出是非确定性的，CPU 比较测试
    UnaryUfuncInfo(
        'nn.functional.selu',  # 使用 SELU 激活函数
        ref=lambda x, inplace=False:
            1.0507009873554804934193349852946 * (  # SELU 公式的缩放系数
                np.maximum(0., x) + np.minimum(0., 1.6732632423543772848170429916717 * (np.exp(x) - 1))  # SELU 函数定义
            ),
        dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 支持的数据类型，包括浮点类型和 bfloat16、float16
        supports_forward_ad=True,  # 支持前向自动微分，依赖于 'elu'
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度计算
        supports_autograd=True,  # 支持自动微分
        assert_autodiffed=False,  # 不断言自动微分
        supports_gradgrad=True,  # 支持二阶梯度计算
        supports_out=False,  # 不支持输出张量的重用
        inplace_variant=lambda x: torch.nn.functional.selu(x, inplace=True),  # SELU 的原地变体
        decorators=[
            DecorateInfo(
                toleranceOverride({
                    torch.float16: tol(atol=1e-2, rtol=1.8e-2),  # 容差设置，用于浮点16位数据类型
                    torch.bfloat16: tol(atol=1e-2, rtol=1.8e-2)  # 容差设置，用于 bfloat16 数据类型
                }),
                'TestUnaryUfuncs', device_type='cuda',  # 测试装饰器信息，设备类型为 CUDA
            ),
        ],
    ),
    OpInfo(
        'torch._scaled_mm',  # 矩阵乘法的扩展操作
        sample_inputs_func=sample_inputs_scaled_mm,  # 用于获取 scaled_mm 操作的示例输入的函数
        dtypes=empty_types(),  # 不支持任何数据类型
        dtypesIfCUDA=empty_types() + (torch.float8_e4m3fn,),  # 如果是 CUDA，则支持 float8_e4m3fn 数据类型
        supports_out=True,  # 支持输出张量的重用
        supports_forward_ad=False,  # 不支持前向自动微分
        supports_autograd=False,  # 不支持自动微分
        decorators=[skipCUDAIf(not SM90OrLater or TEST_WITH_ROCM, 'Requires CUDA SM >= 9.0')],  # 装饰器，条件为 CUDA SM >= 9.0 才执行测试
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_dtypes', device_type='cuda'),  # 装饰器信息，跳过特定的测试用例
            DecorateInfo(unittest.skip("Skipped!"), 'TestSchemaCheckModeOpInfo', 'test_schema_correctness',
                         dtypes=(torch.float8_e4m3fn,)),  # 装饰器信息，跳过特定的测试用例，对应特定数据类型
        )
    ),
    OpInfo(
        'torch.ops.aten._flash_attention_forward',  # 定义操作名称为 _flash_attention_forward 的 OpInfo 对象
        sample_inputs_func=sample_inputs_flash_attention_forward,  # 设置样本输入函数为 sample_inputs_flash_attention_forward
        dtypes=empty_types(),  # 设置 dtypes 为空类型
        dtypesIfCUDA=custom_types(torch.float16)  # 如果不是 SM80 及更高版本，则设置 CUDA 下的 dtypes 为自定义类型 torch.float16
        if not SM80OrLater  # 条件判断：如果不是 SM80 或更高版本
        else custom_types(torch.float16, torch.bfloat16),  # 如果是 SM80 或更高版本，则设置 CUDA 下的 dtypes 为 torch.float16 和 torch.bfloat16 的自定义类型
        supports_out=False,  # 不支持输出参数
        supports_autograd=True,  # 支持自动求导
        supports_fwgrad_bwgrad=False,  # 不支持前向和后向梯度
        supports_forward_ad=False,  # 不支持前向自动分化
        check_batched_forward_grad=False,  # 不检查批处理前向梯度
        decorators=[skipCUDAIf(not PLATFORM_SUPPORTS_FLASH_ATTENTION, "This platform doesn't support Flash Attention")],  # 设置装饰器列表，条件为不支持 Flash Attention 平台时跳过 CUDA 测试
        skips=(
            # 装饰信息：预期失败的单元测试，测试名为 'TestFakeTensor'，方法为 'test_fake_autocast'，设备类型为 'cuda'
            DecorateInfo(unittest.expectedFailure, 'TestFakeTensor', 'test_fake_autocast', device_type='cuda'),
            # 装饰信息：预期失败的单元测试，测试名为 'TestFakeTensor'，方法为 'test_fake'，设备类型为 'cuda'
            DecorateInfo(unittest.expectedFailure, 'TestFakeTensor', 'test_fake', device_type='cuda'),
            # 装饰信息：预期失败的单元测试，测试名为 'TestMeta'，方法为 'test_meta_inplace'
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace"),
            # 装饰信息：预期失败的单元测试，测试名为 'TestMeta'，方法为 'test_meta_outplace'
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace"),
            # 装饰信息：预期失败的单元测试，测试名为 'TestMeta'，方法为 'test_dispatch_meta_outplace'
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace"),
            # 装饰信息：预期失败的单元测试，测试名为 'TestMeta'，方法为 'test_dispatch_symbolic_meta_outplace'
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace"),
            # 装饰信息：预期失败的单元测试，测试名为 'TestCompositeCompliance'，方法为 'test_operator'，设备类型为 'cuda'
            DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_operator', device_type='cuda'),
            # 装饰信息：预期失败的单元测试，测试名为 'TestCommon'，方法为 'test_noncontiguous_samples'，设备类型为 'cuda'
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_noncontiguous_samples', device_type='cuda'),
            # 装饰信息：预期失败的单元测试，测试名为 'TestJit'，方法为 'test_variant_consistency_jit'，设备类型为 'cuda'
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', device_type='cuda'),
            # 装饰信息：预期失败的单元测试，测试名为 'TestCompositeCompliance'，方法为 'test_backward'，设备类型为 'cuda'
            DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_backward', device_type='cuda'),
        )
    ),
    # 定义 OpInfo 对象，用于描述一个操作的信息
    OpInfo(
        'torch.ops.aten._efficient_attention_forward',  # 操作的名称或路径
        sample_inputs_func=sample_inputs_efficient_attention_forward,  # 生成输入样本的函数
        dtypes=empty_types(),  # 不同数据类型的输入参数
        dtypesIfCUDA=custom_types(torch.float16, torch.float32)
        if not SM80OrLater  # 根据条件选择不同的数据类型集合，如果不是 SM80 或更高版本的GPU
        else custom_types(torch.float16, torch.float32, torch.bfloat16),  # 如果是 SM80 或更高版本的GPU，则选择不同的数据类型集合
        supports_out=False,  # 是否支持输出参数
        supports_autograd=True,  # 是否支持自动求导
        supports_fwgrad_bwgrad=False,  # 是否支持前向和后向梯度
        supports_forward_ad=False,  # 是否支持自动微分的前向传播
        check_batched_forward_grad=False,  # 是否检查批处理前向梯度
        # TODO: 因某种原因导致 CUDA 非法内存访问，暂时跳过该项测试
        skip_cow_input_backward=True,
        # FIXME: 当 mask_type == 2 (LowerRight) 时存在问题
        decorators=[
            skipCUDAIf(not PLATFORM_SUPPORTS_MEM_EFF_ATTENTION, "This platform doesn't support efficient attention"),  # 如果平台不支持高效注意力机制，则跳过 CUDA 测试
            skipCUDAIf(TEST_WITH_ROCM, "Efficient attention on ROCM doesn't support custom_mask_type==2")  # 如果在 ROCM 上使用自定义 mask_type==2 则跳过 CUDA 测试
        ],
        skips=(
            # 设备不匹配，可能由于 philox 种子和偏移导致
            DecorateInfo(unittest.expectedFailure, 'TestFakeTensor', 'test_fake_autocast', device_type='cuda'),
            DecorateInfo(unittest.expectedFailure, 'TestFakeTensor', 'test_fake', device_type='cuda'),
            # 元实现在 fake_impls.py 中而不是元注册
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_inplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_meta_outplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_meta_outplace"),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace"),
            # 检查 philox 种子和偏移的标量值
            DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_operator', device_type='cuda'),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_noncontiguous_samples', device_type='cuda'),
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', device_type='cuda'),
            # None Mismatch Tensor
            DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_backward', device_type='cuda'),
        )
    ),
    UnaryUfuncInfo(
        'nn.functional.silu',  # 定义了一个名为 'nn.functional.silu' 的一元函数信息对象
        aten_backward_name='silu_backward',  # 对应的 ATen 后向名字为 'silu_backward'
        ref=lambda x, inplace=False: x / (1 + np.exp(-x)),  # 参考实现，计算 silu 函数的输出
        dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 支持的数据类型，包括浮点类型和 torch.bfloat16、torch.float16
        supports_forward_ad=True,  # 支持前向自动微分
        supports_autograd=True,  # 支持自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        assert_autodiffed=True,  # 断言已经自动微分
        supports_out=False,  # 不支持输出张量
        inplace_variant=lambda x: torch.nn.functional.silu(x, inplace=True),  # 原地变体，使用 inplace=True 调用 torch.nn.functional.silu
        decorators=[
            DecorateInfo(
                toleranceOverride({  # 设置容差覆盖，根据数据类型设置不同的容差值
                    torch.float16: tol(atol=1e-3, rtol=1e-3),  # torch.float16 数据类型的容差设置
                    torch.bfloat16: tol(atol=1e-4, rtol=1e-4)  # torch.bfloat16 数据类型的容差设置
                }),
                'TestUnaryUfuncs', device_type='cuda',  # 装饰器信息，测试一元函数在 CUDA 设备上的行为
            ),
        ],
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_normal',  # 跳过的测试信息，跳过测试参考数值正常情况
                         dtypes=(torch.cfloat,), device_type='cpu'),  # 跳过的数据类型为 torch.cfloat，在 CPU 设备上
        ),
        autodiff_nonfusible_nodes=["aten::silu"],  # 自动微分中不可融合节点，包括 "aten::silu"
    ),
    # TODO: combine this with the nn.functional.silu OpInfo when
    # complex autodiff for silu is supported or when
    # the forward bug is fixed
    # Note: silu errors when given inputs that require grad
    #   but it doesn't support grad in their dtype
   ```python
    # 当 silu 函数的复杂自动微分被支持或者前向错误被修复时，将此部分与 nn.functional.silu OpInfo 结合起来
    # 注意：当给定需要梯度的输入时，silu 函数会报错，但它不支持其数据类型的梯度
    #   这就是为什么上面的 dtypes 列表通过了 test_dtypes 测试的原因，
    #   因为它运气好，失败在前向，test_dtypes 将 requires_grad 设置为 True
    #   这是一个 BUG
    UnaryUfuncInfo(
        'nn.functional.silu',  # 定义 SILU（Sigmoid Linear Unit）函数的信息对象
        variant_test_name='complex',  # 复杂情况下的测试名称
        ref=lambda x, inplace=False:
            x / (1 + np.exp(-x)),  # 参考实现：非就地操作时计算 SILU 函数
        dtypes=complex_types(),  # 适用的数据类型：复数类型
        dtypesIfCUDA=complex_types(),  # CUDA 下适用的数据类型：复数类型
        supports_forward_ad=False,  # 不支持前向自动微分
        supports_autograd=False,  # 不支持自动微分
        assert_autodiffed=False,  # 不断言已进行自动微分
        supports_out=False,  # 不支持输出参数
        inplace_variant=lambda x: torch.nn.functional.silu(x, inplace=True),  # 就地操作的变体实现
        decorators=[
            DecorateInfo(
                toleranceOverride({  # 设置容差覆盖
                    torch.float16: tol(atol=1e-3, rtol=1e-3),  # 对于 float16 数据类型的容差
                    torch.bfloat16: tol(atol=1e-4, rtol=1e-4)  # 对于 bfloat16 数据类型的容差
                }),
                'TestUnaryUfuncs', device_type='cuda',  # 装饰器信息：在 CUDA 设备上进行测试
            ), ],
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_normal',
                         dtypes=(torch.cfloat,)),  # 跳过测试：普通参考数值测试，针对 torch.cfloat 数据类型
            # FIXME: 故意错误地报告数据类型
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_dtypes'),  # 预期失败：测试数据类型
            # FIXME: numpy 参考值发散：比较 (nan+nanj) 和 (-0+0j)
            DecorateInfo(unittest.skip("Skipped!"),
                         'TestUnaryUfuncs', 'test_reference_numerics_large',
                         dtypes=(torch.complex64, torch.cdouble)),  # 跳过测试：大数值参考数值测试，针对 torch.complex64 和 torch.cdouble 数据类型
            DecorateInfo(unittest.skip("Skipped!"),
                         'TestUnaryUfuncs', 'test_reference_numerics_small',
                         dtypes=(torch.complex64,)),  # 跳过测试：小数值参考数值测试，针对 torch.complex64 数据类型
            DecorateInfo(unittest.skip("Skipped!"),
                         'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                         dtypes=(torch.complex64,))  # 跳过测试：极端数值参考数值测试，针对 torch.complex64 数据类型
        )),
    UnaryUfuncInfo(
        'nn.functional.hardsigmoid',  # 定义硬 Sigmoid 函数的信息对象
        aten_backward_name='hardsigmoid_backward',  # ATen 后向名
        ref=reference_hardsigmoid,  # 参考实现：硬 Sigmoid 函数
        dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 数据类型：浮点数类型和 torch.bfloat16、torch.float16
        supports_autograd=True,  # 支持自动微分
        assert_autodiffed=False,  # 不断言已进行自动微分
        supports_gradgrad=False,  # 不支持二阶梯度
        supports_forward_ad=True,  # 支持前向自动微分
        supports_out=False,  # 不支持输出参数
        inplace_variant=partial(torch.nn.functional.hardsigmoid, inplace=True),  # 就地操作的变体实现
        decorators=[
            DecorateInfo(
                toleranceOverride({torch.float16: tol(atol=1e-04, rtol=0.001)}), 'TestUnaryUfuncs', device_type='cuda',  # 设置容差覆盖
            ), ],
        skips=[
            # 仍然希望测试一阶导数是否正常，尽管不支持二阶导数
            DecorateInfo(unittest.expectedFailure, 'TestBwdGradients', "test_inplace_gradgrad"),
            # 在 ROCM 上产生 0 而不是 NaN
            DecorateInfo(unittest.expectedFailure,
                         'TestUnaryUfuncs', "test_reference_numerics_extremal",
                         device_type='cuda',
                         active_if=(TEST_WITH_ROCM)),  # 预期失败：极端数值参考数值测试，在 ROCM 设备上
        ]
    ),
    UnaryUfuncInfo(
        'nn.functional.logsigmoid',
        aten_name="log_sigmoid",
        aten_backward_name='log_sigmoid_backward',
        ref=reference_logsigmoid,
        dtypes=floating_types_and(torch.half, torch.bfloat16),
        supports_autograd=True,
        assert_autodiffed=False,
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        supports_gradgrad=True,
        # autodiff_nonfusible_nodes=["aten::log_sigmoid"],
        decorators=[
            # 设置测试用例的精度覆盖，针对不同类型的数据
            DecorateInfo(
                precisionOverride({torch.float16: 1e-2, torch.bfloat16: 5e-3}),
                'TestUnaryUfuncs', 'test_reference_numerics_small'),
            DecorateInfo(
                precisionOverride({torch.float16: 1e-2, torch.bfloat16: 5e-3}),
                'TestUnaryUfuncs', 'test_reference_numerics_large'),
            DecorateInfo(
                precisionOverride({torch.float16: 1e-2, torch.bfloat16: 5e-3}),
                'TestUnaryUfuncs', 'test_reference_numerics_extremal'),
        ],
        skips=(
            # 标记测试用例为预期失败，针对某些条件
            # 例如在 CPU 设备上的特定测试条件
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning', device_type='cpu'),
        ),
    ),
    UnaryUfuncInfo(
        'nn.functional.mish',
        aten_backward_name='mish_backward',
        ref=lambda x: x * np.tanh(reference_softplus(x)),
        dtypes=floating_types_and(torch.bfloat16, torch.float16),
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        supports_autograd=True,
        assert_autodiffed=False,
        supports_gradgrad=True,
        supports_out=False,
        # 定义 inplace 变体的测试装饰器
        inplace_variant=partial(torch.nn.functional.mish, inplace=True),
        decorators=[
            # 设置测试用例的公差覆盖，针对不同类型的数据
            DecorateInfo(
                toleranceOverride({torch.float16: tol(atol=1e-02, rtol=1e-03)}), 'TestUnaryUfuncs',), ],
    ),
    UnaryUfuncInfo(
        'nn.functional.softsign',
        ref=lambda x: x / (np.abs(x) + 1),
        dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
        dtypesIfCUDA=all_types_and_complex_and(torch.float16, torch.bfloat16, torch.bool),
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        supports_autograd=True,
        assert_autodiffed=False,
        supports_gradgrad=True,
        supports_out=False,
        decorators=[
            # 设置测试用例的公差覆盖，针对不同类型的数据
            DecorateInfo(
                toleranceOverride({torch.float16: tol(atol=1e-03, rtol=1.3e-04)}), 'TestUnaryUfuncs',), ],
        skips=(
            # 标记测试用例为跳过，带有特定条件的测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_small',
                         dtypes=(torch.int, torch.int8)),),
    ),
    # 定义一个 UnaryUfuncInfo 对象，表示一元函数的信息
    UnaryUfuncInfo(
        'nn.functional.tanhshrink',  # 函数名称为 tanhshrink
        ref=lambda x: x - np.tanh(x),  # 参考实现是 x - tanh(x)
        dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),  # 支持的数据类型包括所有类型和复数类型以及半精度和 bfloat16
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向后向微分
        supports_autograd=True,  # 支持自动微分
        assert_autodiffed=False,  # 不断言已经自动微分
        supports_gradgrad=True,  # 支持二阶梯度
        supports_out=False,  # 不支持输出参数
        decorators=[
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_normal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),  # 装饰器信息，跳过测试
            DecorateInfo(
                toleranceOverride({torch.bfloat16: tol(atol=1e-02, rtol=1.6e-02)}), 'TestUnaryUfuncs',),  # 设置容差
            DecorateInfo(toleranceOverride({torch.complex64: tol(atol=6e-04, rtol=1e-05),
                                            torch.bfloat16: tol(atol=1e-02, rtol=1.6e-02)}),
                         'TestUnaryUfuncs', 'test_reference_numerics_extremal', device_type='cuda'),  # 设置复杂情况下的容差和设备类型
        ],
        skips=(
            # 在某些情况下，PyTorch 会产生 NaN，而 NumPy 不会
            DecorateInfo(unittest.skip("Fails on some jobs works on others!"),
                         'TestUnaryUfuncs', "test_reference_numerics_large",
                         dtypes=(torch.complex64, torch.complex128), active_if=(IS_MACOS)),  # 跳过的测试情况
            DecorateInfo(unittest.skip("Fails on some jobs works on others!"),
                         'TestUnaryUfuncs', "test_reference_numerics_extremal",
                         dtypes=(torch.complex64, torch.complex128), device_type='cpu',
                         active_if=(IS_MACOS or IS_WINDOWS)),  # 跳过的测试情况
        ),
        # tan(j * pi/2 * odd_number) 是 NaN，这也会导致 tanhshrink 是 NaN
        reference_numerics_filter=NumericsFilter(
            condition=lambda x: (close_to_int(x / (math.pi * 0.5j))
                                 if x.is_complex() else x.new_tensor(False, dtype=torch.bool)),  # 条件过滤器
            safe_val=0)  # 安全值设为 0
    ),
    # 定义另一个 UnaryUfuncInfo 对象，表示阈值函数的信息
    UnaryUfuncInfo(
        'nn.functional.threshold',  # 函数名称为 threshold
        ref=lambda x, threshold, value: np.where(x <= threshold, value, x).astype(x.dtype),  # 参考实现是 numpy 的 where 函数
        dtypes=all_types_and(torch.half, torch.bfloat16),  # 支持的数据类型包括所有类型、半精度和 bfloat16
        inplace_variant=lambda x, threshold, value:
            torch.nn.functional.threshold(x, threshold, value, inplace=True),  # 支持就地操作的变体
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向后向微分
        assert_autodiffed=False,  # 不断言已经自动微分
        supports_gradgrad=True,  # 支持二阶梯度
        supports_out=False,  # 不支持输出参数
        sample_kwargs=lambda device, dtype, input: ({'threshold': float.fromhex('0x1.3ap-3'),
                                                    'value': -9},
                                                    {'threshold': float.fromhex('0x1.3ap-3'),
                                                    'value': -9}),  # 示例参数
        # TODO(whc) should not need sample_inputs_func, but without it
        # kwargs aren't being hooked up properly
        sample_inputs_func=sample_inputs_threshold,  # 示例输入函数
    ),
    # 定义 OpInfo 对象，表示一个特定的操作信息
    OpInfo(
        "nn.functional.triplet_margin_loss",  # 操作的名称或路径
        sample_inputs_func=sample_inputs_triplet_margin_loss,  # 提供样本输入的函数
        error_inputs_func=error_inputs_triplet_margin_loss,  # 提供错误输入的函数
        dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),  # 支持的数据类型，包括半精度和 bfloat16
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向后向梯度计算
    ),
    # 定义另一个 OpInfo 对象，表示另一个特定的操作信息
    OpInfo(
        "nn.functional.triplet_margin_with_distance_loss",  # 操作的名称或路径
        sample_inputs_func=partial(sample_inputs_triplet_margin_loss, with_distance=True),  # 提供样本输入的函数，带有距离参数
        error_inputs_func=error_inputs_triplet_margin_loss,  # 提供错误输入的函数
        dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),  # 支持的数据类型，包括半精度和 bfloat16
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向后向梯度计算
        skips=(
            # 以下测试用例无法处理传递给 `distance_function` 的可调用对象。如果我们使用 `distance_function=None`，测试将通过。
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期失败的测试
                "TestJit",  # 测试所在的类
                "test_variant_consistency_jit",  # 具体的测试方法
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 标记为预期失败的测试
                "TestNormalizeOperators",  # 测试所在的类
                "test_normalize_operator_exhaustive",  # 具体的测试方法
            ),
        ),
    ),
    # 定义 BinaryUfuncInfo 对象，表示一个二元通用函数的信息
    BinaryUfuncInfo('nextafter',
                    dtypes=floating_types_and(torch.bfloat16, torch.half),  # 支持的数据类型，包括 bfloat16 和半精度
                    dtypesIfCUDA=floating_types_and(torch.bfloat16),  # 如果是 CUDA，支持的数据类型，仅限 bfloat16
                    supports_autograd=False,  # 不支持自动求导
                    supports_rhs_python_scalar=False),  # 不支持右侧 Python 标量
    # 定义另一个 OpInfo 对象，表示另一个特定的操作信息
    OpInfo(
        "to",  # 操作的名称或路径
        op=lambda x, *args, **kwargs: x.to(*args, **kwargs),  # 操作的具体实现，将对象转换到指定设备或数据类型
        dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16, torch.bool),  # 支持的数据类型，包括 bfloat16、float16 和布尔型
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向后向梯度计算
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_to,  # 提供样本输入的函数
        skips=(
            # RuntimeError: undefined value cpu
            DecorateInfo(
                unittest.skip("Skipped!"),  # 标记为跳过的测试
                "TestJit",  # 测试所在的类
                "test_variant_consistency_jit",  # 具体的测试方法
                device_type="cpu",  # 测试的设备类型为 CPU
            ),
            # NotImplementedError: Cannot copy out of meta tensor; no data!
            DecorateInfo(
                unittest.skip("Skipped!"),  # 标记为跳过的测试
                "TestMeta",  # 测试所在的类
                "test_meta_outplace",  # 具体的测试方法
            ),
            # https://github.com/pytorch/pytorch/issues/84335
            DecorateInfo(
                unittest.skip("Skipped!"),  # 标记为跳过的测试
                "TestProxyTensorOpInfo",  # 测试所在的类
                "test_make_fx_symbolic_exhaustive",  # 具体的测试方法
            ),
            DecorateInfo(
                unittest.skip("Skipped!"),  # 标记为跳过的测试
                "TestNormalizeOperators",  # 测试所在的类
                "test_normalize_operator_exhaustive",  # 具体的测试方法
            ),
        ),
    ),
    # 定义一个 OpInfo 对象，表示 topk 操作的测试信息
    OpInfo('topk',
           # 支持的数据类型包括所有类型和 torch.bfloat16、torch.float16
           dtypes=all_types_and(torch.bfloat16, torch.float16),
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向自动微分
           supports_fwgrad_bwgrad=True,
           # 断言 JIT 形状分析为真
           assert_jit_shape_analysis=True,
           # 提供用于样本输入的函数为 sample_inputs_topk
           sample_inputs_func=sample_inputs_topk),
    
    # 多个 batch_norm 变体，用于测试启用和禁用 cuDNN 的情况
    # 参考 https://github.com/pytorch/pytorch/pull/63218#discussion_r688549391 获取更多详情
    OpInfo('nn.functional.batch_norm',
           # ATen 中的函数名为 batch_norm
           aten_name='batch_norm',
           # 浮点数类型，包括 torch.float16 和 torch.bfloat16
           dtypes=floating_types_and(torch.float16, torch.bfloat16),
           # 不支持输出
           supports_out=False,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向自动微分
           supports_fwgrad_bwgrad=True,
           # 断言 JIT 形状分析为真
           assert_jit_shape_analysis=True,
           # 允许使用 copy-on-write 输入在前向传播时材料化第 1、2 个参数
           allow_cow_input_materialize_forward=[1, 2],
           # 允许使用 copy-on-write 输入在反向传播时材料化第 1、2 个参数
           allow_cow_input_materialize_backward=[1, 2],
           # 提供用于样本输入的函数为 sample_inputs_batch_norm
           sample_inputs_func=sample_inputs_batch_norm,
           # 跳过的测试包括以下内容
           skips=(
               # 参考 https://github.com/pytorch/pytorch/issues/71286
               DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_nnc_correctness'),
               DecorateInfo(unittest.skip('Skipped!'), 'TestNNCOpInfo', 'test_nnc_correctness',
                            device_type='cpu', dtypes=(torch.bfloat16, torch.float16)),
               DecorateInfo(toleranceOverride({torch.float32: tol(atol=5e-05, rtol=1e-05)}),
                            'TestCompositeCompliance', 'test_forward_ad', device_type="cpu"),
           )),
    
    # 这个变体测试在 CUDA 设备上禁用 cuDNN 的 batch_norm
    OpInfo('nn.functional.batch_norm',
           # 变体测试名为 without_cudnn
           variant_test_name='without_cudnn',
           # ATen 中的函数名为 batch_norm
           aten_name='batch_norm',
           # 空类型，即不指定数据类型
           dtypes=empty_types(),
           # 如果是 CUDA 设备，则支持的数据类型包括 torch.float16 和 torch.bfloat16
           dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           # 不支持输出
           supports_out=False,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向自动微分
           supports_fwgrad_bwgrad=True,
           # 允许使用 copy-on-write 输入在前向传播时材料化第 1、2 个参数
           allow_cow_input_materialize_forward=[1, 2],
           # 允许使用 copy-on-write 输入在反向传播时材料化第 1、2 个参数
           allow_cow_input_materialize_backward=[1, 2],
           # 使用的装饰器包括 onlyCUDA 和 disablecuDNN
           decorators=[onlyCUDA, disablecuDNN],
           # 跳过的测试包括以下内容
           skips=(
               # 使用容差重写，torch.float32 的绝对容差为 5e-05，相对容差为 1e-05
               DecorateInfo(toleranceOverride({torch.float32: tol(atol=1e-03, rtol=1e-04)}),
                            'TestJit', 'test_variant_consistency_jit'),
           ),
           # 提供用于样本输入的函数为 sample_inputs_batch_norm
           sample_inputs_func=sample_inputs_batch_norm),
    OpInfo(
        "nn.functional.binary_cross_entropy",
        aten_backward_name='binary_cross_entropy_backward',
        sample_inputs_func=sample_inputs_binary_cross_entropy,
        dtypes=floating_types_and(torch.float16, torch.bfloat16),
        dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
        supports_out=False,
        gradcheck_fast_mode=False,
        supports_autograd=True,
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        decorators=(
            # 标记：由于预期在位置0处得到整数，但实际传入的是张量（Tensor），导致运行时错误
            DecorateInfo(
                unittest.skip("Skipped!"),  # 跳过测试
                "TestCudaFuserOpInfo",  # 测试类名
            ),
            # 标记：由于预期在位置0处得到整数，但实际传入的是张量（Tensor），导致运行时错误
            DecorateInfo(
                unittest.skip("Skipped!"),  # 跳过测试
                "TestNNCOpInfo",  # 测试类名
                "test_nnc_correctness",  # 测试方法名
            ),
            # 由于未知原因失败：https://github.com/pytorch/pytorch/issues/120783
            DecorateInfo(
                unittest.skip("Skipped!"),  # 跳过测试
                "TestCompositeCompliance",  # 测试类名
                "test_cow_input",  # 测试方法名
                device_type='cuda',  # 测试设备类型为 CUDA
            ),
            DecorateInfo(
                toleranceOverride({torch.float32: tol(atol=1e-3, rtol=1e-3)}),  # 设置容差
                "TestJit",  # 测试类名
                "test_variant_consistency_jit",  # 测试方法名
            ),
            # 标记：由于输出形状为[]，不符合广播形状[5, 5]，导致运行时错误
            DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_meta_outplace'),
            DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_symbolic_meta_outplace'),
            DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_symbolic_meta_outplace_all_strides'),
        ),
        skips=(
            # 标记：由于预期在位置0处得到整数，但实际传入的是张量（Tensor），导致运行时错误
            DecorateInfo(
                unittest.expectedFailure,  # 预期测试失败
                "TestJit",  # 测试类名
                "test_variant_consistency_jit",  # 测试方法名
            ),
        ),
    ),
    # We have to add 2 OpInfo entry for `igamma` and `igammac`.First is the
    # standard entry, second is to run gradcheck tests on the second argument.
    BinaryUfuncInfo('igamma',
                    dtypes=floating_types_and(torch.bfloat16, torch.float16),
                    aliases=('torch.special.gammainc',),
                    dtypesIfCUDA=floating_types(),
                    # TODO: FIXME
                    supports_rhs_python_scalar=False,
                    supports_autograd=False,
                    skips=(
                        # FIXME: incorrectly tries to pass a rhs scalar
                        DecorateInfo(unittest.expectedFailure, 'TestJit',
                                     'test_jit_alias_remapping'),
                    )),
    # TODO: FIXME, ideally by implemented grad for both inputs
    # BinaryUfuncInfo('igamma',
    # 定义一个 BinaryUfuncInfo 对象，用于 igammac 函数的测试和信息收集
    BinaryUfuncInfo('igammac',
                    dtypes=floating_types_and(torch.bfloat16, torch.float16),
                    aliases=('torch.special.gammaincc',),
                    dtypesIfCUDA=floating_types(),
                    supports_autograd=False,
                    supports_rhs_python_scalar=False,
                    skips=(
                        # FIXME: 在 TestJit 中的 test_jit_alias_remapping 测试中，预期的失败
                        DecorateInfo(unittest.expectedFailure, 'TestJit',
                                     'test_jit_alias_remapping'),
                    )),
    # TODO: FIXME，理想情况下通过实现两个输入的梯度来解决
    # BinaryUfuncInfo 对象的另一种变体 'igammac'，用于 'grad_other' 测试
    # 自动梯度公式仅针对 'other' 实现，gradcheck 测试验证 SampleInput 中输入的公式，
    # 因此我们对参数进行了排列
    # 使用 lambda 表达式定义 op，实现 torch.igammac(other, self, **kwargs)
    # 定义一个 UnaryUfuncInfo 对象，描述了 nn.functional.softshrink 函数的信息
    UnaryUfuncInfo('nn.functional.softshrink',
                   aten_name="softshrink",
                   aten_backward_name='softshrink_backward',
                   dtypes=floating_types_and(torch.bfloat16, torch.float16),
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   assert_autodiffed=False,
                   sample_inputs_func=sample_inputs_softshrink,
                   error_inputs_func=error_inputs_softshrink),
    # 定义一个 UnaryUfuncInfo 对象，描述了 nn.functional.hardshrink 函数的信息
    UnaryUfuncInfo('nn.functional.hardshrink',
                   aten_name="hardshrink",
                   aten_backward_name='hardshrink_backward',
                   dtypes=floating_types_and(torch.bfloat16, torch.float16),
                   assert_autodiffed=True,
                   sample_inputs_func=sample_inputs_hardshrink,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   autodiff_nonfusible_nodes=["aten::hardshrink"]),
    UnaryUfuncInfo('nn.functional.hardtanh',  # 创建一个 UnaryUfuncInfo 对象，用于描述 nn.functional.hardtanh 函数的信息
                   aten_name="hardtanh",  # 指定对应的 ATen 函数名
                   aten_backward_name='hardtanh_backward',  # 指定反向传播时对应的 ATen 函数名
                   dtypes=floating_types_and(torch.int8, torch.int16, torch.int32, torch.int64, torch.half, torch.bfloat16),  # 支持的数据类型，包括浮点数和部分整数类型
                   backward_dtypes=all_types_and(torch.half, torch.bfloat16),  # 反向传播支持的数据类型
                   backward_dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),  # CUDA 环境下反向传播支持的数据类型
                   assert_autodiffed=True,  # 断言该函数已进行自动微分
                   sample_inputs_func=sample_inputs_hardtanh,  # 获取函数样本输入的函数
                   error_inputs_func=error_inputs_hardtanh,  # 获取错误输入的函数
                   supports_out=False,  # 不支持输出参数
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
                   autodiff_nonfusible_nodes=["aten::hardtanh"]),  # 自动微分不可融合的节点
    OpInfo('nn.functional.gelu',  # 创建一个 OpInfo 对象，用于描述 nn.functional.gelu 函数的信息
           aten_name="gelu",  # 指定对应的 ATen 函数名
           aten_backward_name='gelu_backward',  # 指定反向传播时对应的 ATen 函数名
           ref=reference_gelu if TEST_SCIPY else None,  # 参考实现（如果在测试模式下使用 SciPy）
           error_inputs_func=error_inputs_gelu,  # 获取错误输入的函数
           supports_autograd=True,  # 支持自动梯度
           assert_autodiffed=True,  # 断言该函数已进行自动微分
           sample_inputs_func=sample_inputs_gelu,  # 获取函数样本输入的函数
           dtypes=floating_types_and(torch.bfloat16, torch.half),  # 支持的数据类型，包括半精度浮点数和 BFLOAT16
           supports_gradgrad=True,  # 支持二阶梯度
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           autodiff_nonfusible_nodes=["aten::gelu"],  # 自动微分不可融合的节点
           skips=(  # 跳过的测试用例
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_out'),  # 跳过输出测试的装饰器信息
               DecorateInfo(unittest.skip("Unsupported on MPS for now"), 'TestCommon', 'test_numpy_ref_mps'),  # 跳过在 MPS 上不支持的装饰器信息
           )),
    UnaryUfuncInfo('nn.functional.relu6',  # 创建一个 UnaryUfuncInfo 对象，用于描述 nn.functional.relu6 函数的信息
                   aten_name="relu6",  # 指定对应的 ATen 函数名
                   dtypes=all_types_and(torch.half, torch.bfloat16),  # 支持的数据类型，包括半精度浮点数和 BFLOAT16
                   backward_dtypes=floating_types_and(torch.half, torch.bfloat16),  # 反向传播支持的数据类型
                   assert_autodiffed=True,  # 断言该函数已进行自动微分
                   supports_out=False,  # 不支持输出参数
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
                   autodiff_nonfusible_nodes=["aten::relu6"]),  # 自动微分不可融合的节点
    OpInfo('mm',  # 创建一个 OpInfo 对象，用于描述 mm（矩阵乘法）操作的信息
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),  # 支持的数据类型，包括所有类型和复数类型以及半精度浮点数和 BFLOAT16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),  # CUDA 环境下支持的数据类型，包括浮点数和复数类型以及半精度浮点数和 BFLOAT16
           assert_autodiffed=True,  # 断言该函数已进行自动微分
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           sample_inputs_func=sample_inputs_mm,  # 获取函数样本输入的函数
           skips=(  # 跳过的测试用例
               DecorateInfo(  # 跳过模式检查操作信息的测试用例
                   unittest.skip("Skipped!"),
                   'TestSchemaCheckModeOpInfo',
                   'test_schema_correctness',
                   dtypes=(torch.complex64, torch.complex128)),  # 指定跳过测试用例的数据类型为复数类型
           )),
    # 创建 OpInfo 对象，用于描述 torch.mode 操作的测试信息
    OpInfo('mode',
           op=torch.mode,
           dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           skips=(
               # 当对非空张量进行 resize 但没有警告时跳过此测试
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
           ),
           # 定义用于生成 mode 操作样本输入的函数
           sample_inputs_func=sample_inputs_mode,),
    # 创建 mvlgamma 操作的测试信息，变体为 'mvlgamma_p_1'
    make_mvlgamma_opinfo(variant_test_name='mvlgamma_p_1',
                         domain=(1, None),
                         skips=skips_mvlgamma(),
                         # 定义用于生成 mvlgamma 操作样本输入参数的 lambda 函数
                         sample_kwargs=lambda device, dtype, input: ({'p': 1}, {'d': 1})),
    # 创建 mvlgamma 操作的测试信息，变体为 'mvlgamma_p_3'
    make_mvlgamma_opinfo(variant_test_name='mvlgamma_p_3',
                         domain=(2, None),
                         skips=skips_mvlgamma(),
                         # 定义用于生成 mvlgamma 操作样本输入参数的 lambda 函数
                         sample_kwargs=lambda device, dtype, input: ({'p': 3}, {'d': 3})),
    # 创建 mvlgamma 操作的测试信息，变体为 'mvlgamma_p_5'
    make_mvlgamma_opinfo(variant_test_name='mvlgamma_p_5',
                         domain=(3, None),
                         skips=skips_mvlgamma(),
                         # 定义用于生成 mvlgamma 操作样本输入参数的 lambda 函数
                         sample_kwargs=lambda device, dtype, input: ({'p': 5}, {'d': 5})),
    # 创建 BinaryUfuncInfo 对象，用于描述 np.not_equal 函数的测试信息
    BinaryUfuncInfo('ne',
                    ref=np.not_equal,
                    aliases=('not_equal',),
                    dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),
                    always_returns_bool=True,
                    supports_autograd=False,
                    skips=(
                        # 此处没有特定的跳过信息
                    )),
    # 创建 OpInfo 对象，用于描述 torch.narrow 操作的测试信息
    OpInfo('narrow',
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 定义用于生成 narrow 操作样本输入的函数
           sample_inputs_func=partial(sample_inputs_narrow_narrow_copy, is_narrow=True),
           # 定义用于生成 narrow 操作参考输入的函数
           reference_inputs_func=partial(reference_inputs_narrow_narrow_copy, is_narrow=True),
           # 定义用于生成 narrow 操作错误输入的函数
           error_inputs_func=partial(error_inputs_narrow_narrow_copy, is_narrow=True, is_ref=False),
           skips=(
               # 使用 .item() 时的跳过信息
               DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_operator'),
               DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_backward'),
               DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_forward_ad'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
           )),
    OpInfo('narrow_copy',
           # 定义操作信息，用于描述 'narrow_copy' 操作的属性和特性
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
           # 支持的数据类型包括所有类型、复杂类型和特定的 torch 类型
           supports_out=True,
           # 支持输出张量作为参数
           supports_forward_ad=False,
           # 不支持前向自动微分
           supports_fwgrad_bwgrad=False,
           # 不支持前向-后向自动微分
           supports_autograd=False,
           # 不支持自动微分
           # https://github.com/pytorch/pytorch/issues/86931
           # 提供样本输入的函数，使用 partial 函数创建，参数 is_narrow=False
           sample_inputs_func=partial(sample_inputs_narrow_narrow_copy, is_narrow=False),
           # 提供参考输入的函数，使用 partial 函数创建，参数 is_narrow=False
           reference_inputs_func=partial(reference_inputs_narrow_narrow_copy, is_narrow=False),
           # 提供错误输入的函数，使用 partial 函数创建，参数 is_narrow=False, is_ref=False
           error_inputs_func=partial(error_inputs_narrow_narrow_copy, is_narrow=False, is_ref=False),
           # 跳过的测试用例元组
           skips=(
               # https://github.com/pytorch/pytorch/issues/84577
               # 预期失败的测试用例装饰信息，对应 'TestCommon' 下的 'test_out' 方法
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
               # 预期失败的测试用例装饰信息，对应 'TestCommon' 下的 'test_out_warning' 方法
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               # Lazy tensor 失败的测试用例装饰信息，对应 'TestLazyOpInfo' 下的 'test_correctness' 方法
               DecorateInfo(unittest.expectedFailure, 'TestLazyOpInfo', 'test_correctness'),
               # Lazy tensor 失败的测试用例装饰信息，对应 'TestLazyOpInfo' 下的 'test_correctness_with_reusing_ir' 方法
               DecorateInfo(unittest.expectedFailure, 'TestLazyOpInfo', 'test_correctness_with_reusing_ir'),
               # 'aten::narrow_copy.out' 在 'CUDA' 后端无法运行的测试用例装饰信息
               DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_meta_outplace',
                            device_type='cuda'),
               DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_meta_outplace',
                            device_type='cuda'),
               DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_symbolic_meta_outplace',
                            device_type='cuda'),
               DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_symbolic_meta_outplace_all_strides'),
           )),
    OpInfo('view_copy',
           # 定义操作信息，用于描述 'view_copy' 操作的属性和特性
           dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16),
           # 支持的数据类型包括所有类型和特定的 torch 类型
           ref=lambda x, newshape: np.reshape(x, newshape).copy(),
           # 参考实现为 numpy 的 reshape 函数后进行复制操作
           supports_out=True,
           # 支持输出张量作为参数
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向-后向自动微分
           supports_autograd=True,
           # 支持自动微分
           sample_inputs_func=sample_inputs_view_reshape,
           # 提供样本输入的函数，使用 sample_inputs_view_reshape 函数
           error_inputs_func=error_inputs_view_reshape),
           # 提供错误输入的函数，使用 error_inputs_view_reshape 函数
    UnaryUfuncInfo('neg',
                   # 定义一元操作函数 'neg' 的信息
                   aliases=('negative', ),
                   # 别名为 'negative'
                   ref=np.negative,
                   # 参考实现为 numpy 的 negative 函数
                   dtypes=all_types_and_complex_and(torch.half, torch.bfloat16, torch.chalf),
                   # 支持的数据类型包括所有类型、复杂类型和特定的 torch 类型
                   error_inputs_func=error_inputs_neg,
                   # 提供错误输入的函数，使用 error_inputs_neg 函数
                   supports_forward_ad=True,
                   # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,
                   # 支持前向-后向自动微分
                   supports_sparse=True,
                   # 支持稀疏张量
                   supports_sparse_csr=True,
                   # 支持 CSR 稀疏格式
                   supports_sparse_csc=True,
                   # 支持 CSC 稀疏格式
                   supports_sparse_bsr=True,
                   # 支持 BSR 稀疏格式
                   supports_sparse_bsc=True,
                   # 支持 BSC 稀疏格式
                   assert_autodiffed=True),
                   # 断言自动微分已完成
    OpInfo('dist',
           # 定义操作名称为 'dist'，关联的函数是 torch.dist
           op=torch.dist,
           # 支持的数据类型包括浮点数和复数类型以及 torch.half 和 torch.bfloat16
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),
           # 在慢速的梯度检查上运行速度非常慢，可以通过减小输入大小来加快速度
           gradcheck_fast_mode=True,
           # 不支持输出张量
           supports_out=False,
           # 支持正向自动微分
           supports_forward_ad=True,
           # 在批处理的正向梯度检查时发生错误时，不检查批处理的正向梯度
           check_batched_forward_grad=False,
           # 支持正向梯度和反向梯度
           supports_fwgrad_bwgrad=True,
           # 用于生成输入样本的函数是 sample_inputs_dist
           sample_inputs_func=sample_inputs_dist),

    OpInfo('outer',
           # 定义操作名称为 'outer'，关联的函数是 torch.outer，也称为 'ger'
           op=torch.outer,
           # 别名包括 'ger'
           aliases=('ger', ),
           # 支持所有类型和复数类型，还包括 torch.bool、torch.float16 和 torch.bfloat16
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),
           # 支持正向自动微分
           supports_forward_ad=True,
           # 支持正向梯度和反向梯度
           supports_fwgrad_bwgrad=True,
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           # 在批处理的正向梯度检查时发生错误时，不检查批处理的正向梯度
           check_batched_forward_grad=False,
           # 用于生成输入样本的函数是 sample_inputs_outer
           sample_inputs_func=sample_inputs_outer,),

    OpInfo('ormqr',
           # 定义操作名称为 'ormqr'，关联的函数是 torch.ormqr
           op=torch.ormqr,
           # 支持浮点数和复数类型的数据
           dtypes=floating_and_complex_types(),
           # 查看 https://github.com/pytorch/pytorch/issues/80411
           # 在慢速的梯度检查上运行速度非常慢
           gradcheck_fast_mode=True,
           # 不支持正向自动微分
           supports_forward_ad=False,
           # 不支持正向梯度和反向梯度
           supports_fwgrad_bwgrad=False,
           # 用于生成输入样本的函数是 sample_inputs_ormqr
           sample_inputs_func=sample_inputs_ormqr,
           # 用于装饰的函数列表，条件是没有 CUDA 的情况下无法使用 CuSolver
           decorators=[skipCUDAIfNoCusolver, skipCPUIfNoLapack],
           # 跳过测试用例 'TestCommon' 中的 'test_out'，因为步幅不同
           skips=(
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
           )),

    OpInfo('permute',
           # 定义操作名称为 'permute'，参考实现是 numpy 的 transpose 函数
           ref=np.transpose,
           # 支持所有类型和复数类型，还包括 torch.bool、torch.float16、torch.bfloat16 和 torch.chalf
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           # 不支持输出张量
           supports_out=False,
           # 断言自动微分已启用
           assert_autodiffed=True,
           # 可自动微分的节点不应该被合并
           autodiff_fusible_nodes=[],  
           # 可自动微分但不应该被合并的节点
           autodiff_nonfusible_nodes=[],  
           # 断言 JIT 形状分析已启用
           assert_jit_shape_analysis=True,
           # 支持正向自动微分
           supports_forward_ad=True,
           # 支持正向梯度和反向梯度
           supports_fwgrad_bwgrad=True,
           # 支持可变数量的参数
           supports_varargs=True,
           # 用于生成输入样本的函数是 sample_inputs_permute
           sample_inputs_func=sample_inputs_permute,
           # 用于生成参考输入的函数是 reference_inputs_permute
           reference_inputs_func=reference_inputs_permute),
    # 定义一个二元通用函数的信息对象，用于函数 'float_power'
    BinaryUfuncInfo('float_power',
                    # 引用的函数是 numpy 的 np.float_power
                    ref=np.float_power,
                    # 适用的数据类型包括所有类型以及 torch 中的半精度、bfloat16 和布尔型
                    dtypes=all_types_and_complex_and(torch.half, torch.bfloat16, torch.bool),
                    # 整数类型会被自动提升为浮点数类型
                    promotes_int_to_float=True,
                    # 在梯度检查中使用快速模式，参考 GitHub 问题链接
                    gradcheck_fast_mode=True,
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 支持前向-后向自动微分
                    supports_fwgrad_bwgrad=True,
                    # 支持使用单个 Python 标量
                    supports_one_python_scalar=True,
                    # 右手边的张量创建参数，针对不同类型设置低限为 0
                    rhs_make_tensor_kwargs=dict(low=0),
                    # 左手边的张量创建参数，针对不同类型设置低限为 0
                    lhs_make_tensor_kwargs=dict(low=0),
                    # 修饰器信息，包括测试二元通用函数的容差覆盖情况，针对复数类型设置公差
                    decorators=(
                        DecorateInfo(toleranceOverride({torch.complex64: tol(atol=1e-4, rtol=1.3e-05),
                                                        torch.complex128: tol(atol=1e-4, rtol=1.3e-05)}),
                                     'TestBinaryUfuncs', 'test_scalar_support'),
                    ),
                    # 被跳过的测试用例信息，包括跳过类型推广测试、JIT 中的变体一致性测试以及各种数值测试
                    skips=(
                        # 类型推广测试失败，跳过此测试
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs', 'test_type_promotion'),
                        # JIT 中的变体一致性测试失败，跳过此测试
                        DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),
                        # 对复数类型进行小数值参考数值测试，跳过此测试
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs', 'test_reference_numerics_small_values',
                                     dtypes=[torch.complex64, torch.complex128]),
                        # 对复数类型进行大数值参考数值测试，跳过此测试
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs', 'test_reference_numerics_large_values',
                                     dtypes=[torch.complex64, torch.complex128]),
                        # 对复数类型进行极值参考数值测试，跳过此测试
                        DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs', 'test_reference_numerics_extremal_values',
                                     dtypes=[torch.complex64, torch.complex128]),
                        # Inplace 操作总是提升到双精度，因此不支持其他浮点数类型的 inplace 操作
                        DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_meta_inplace',
                                     dtypes=[torch.bfloat16, torch.float16, torch.float32]),
                    )),
    # 定义一个操作信息对象，用于 QR 分解操作 'qr'
    OpInfo('qr',
           # 操作的函数是 torch.qr
           op=torch.qr,
           # 适用的数据类型包括所有浮点数和复数类型
           dtypes=floating_and_complex_types(),
           # 获取用于 QR 分解的样本输入函数
           sample_inputs_func=sample_inputs_linalg_qr_geqrf,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向-后向自动微分
           supports_fwgrad_bwgrad=True,
           # 不检查批量梯度-梯度的梯度
           check_batched_gradgrad=False,
           # 修饰器信息，包括根据硬件条件跳过 CUDA 和 CPU 上不支持的情况
           decorators=[skipCUDAIfNoCusolver, skipCPUIfNoLapack]),
    UnaryUfuncInfo('rad2deg',
                   ref=np.degrees,
                   decorators=(precisionOverride({torch.bfloat16: 7e-1,
                                                  torch.float16: 7e-1}),),
                   dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   supports_sparse=True,
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   promotes_int_to_float=True),


定义一个一元通用函数信息对象，表示将弧度转换为角度的操作。

- `ref=np.degrees`: 参考函数是 `np.degrees`，用于将角度从弧度转换为角度。
- `decorators=(precisionOverride(...),)`: 使用修饰器 `precisionOverride`，针对不同的数据类型（如 `torch.bfloat16` 和 `torch.float16`）设置精度。
- `dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16)`: 支持的数据类型包括所有数据类型，以及 `torch.bool`、`torch.half` 和 `torch.bfloat16`。
- `supports_forward_ad=True`: 支持前向自动微分。
- `supports_fwgrad_bwgrad=True`: 支持前向-后向梯度传播。
- `supports_sparse=True`: 支持稀疏张量。
- `supports_sparse_csr=True`: 支持稀疏的 CSR 格式。
- `supports_sparse_csc=True`: 支持稀疏的 CSC 格式。
- `supports_sparse_bsr=True`: 支持稀疏的 BSR 格式。
- `supports_sparse_bsc=True`: 支持稀疏的 BSC 格式。
- `promotes_int_to_float=True`: 支持将整数提升为浮点数。



    UnaryUfuncInfo('real',
                   ref=np.real,
                   dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf),
                   supports_out=False,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   # See https://github.com/pytorch/pytorch/issues/66357
                   check_batched_forward_grad=False,
                   skips=(
                       # Skip since real and imag don't have out variants.
                       DecorateInfo(unittest.expectedFailure, 'TestUnaryUfuncs', 'test_out_arg_all_dtypes'),
                   )),


定义一个一元通用函数信息对象，表示获取复数的实部的操作。

- `ref=np.real`: 参考函数是 `np.real`，用于获取复数的实部。
- `dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf)`: 支持的数据类型包括所有数据类型、复数类型以及 `torch.bool`、`torch.bfloat16`、`torch.half` 和 `torch.chalf`。
- `supports_out=False`: 不支持输出参数。
- `supports_forward_ad=True`: 支持前向自动微分。
- `supports_fwgrad_bwgrad=True`: 支持前向-后向梯度传播。
- `check_batched_forward_grad=False`: 不检查批量前向梯度（见 GitHub 问题链接）。
- `skips=(...)`: 跳过的测试条件，因为 `real` 和 `imag` 没有输出参数变体，使用 `unittest.expectedFailure` 修饰器标记为预期失败。



    OpInfo(
        "roll",
        ref=np.roll,
        dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf),
        error_inputs_func=error_inputs_roll,
        supports_out=False,
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        sample_inputs_func=sample_inputs_roll,
        decorators=(onlyNativeDeviceTypes,),
    ),


定义一个操作信息对象，表示数组元素滚动（`roll`）操作。

- `"roll"`: 操作名称是 `roll`。
- `ref=np.roll`: 参考函数是 `np.roll`，用于滚动数组元素。
- `dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf)`: 支持的数据类型包括所有数据类型、复数类型以及 `torch.bool`、`torch.bfloat16`、`torch.half` 和 `torch.chalf`。
- `error_inputs_func=error_inputs_roll`: 错误输入函数是 `error_inputs_roll`，用于生成滚动操作的错误输入。
- `supports_out=False`: 不支持输出参数。
- `supports_forward_ad=True`: 支持前向自动微分。
- `supports_fwgrad_bwgrad=True`: 支持前向-后向梯度传播。
- `sample_inputs_func=sample_inputs_roll`: 示例输入函数是 `sample_inputs_roll`，用于生成滚动操作的示例输入。
- `decorators=(onlyNativeDeviceTypes,)`: 使用修饰器 `onlyNativeDeviceTypes`，限制为仅原生设备类型。



    OpInfo(
        "rot90",
        dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half),
        error_inputs_func=error_inputs_rot90,
        # Runs very slowly on slow gradcheck - alternatively reduce input sizes
        gradcheck_fast_mode=True,
        supports_out=False,
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        sample_inputs_func=sample_inputs_rot90,
    ),


定义一个操作信息对象，表示90度旋转（`rot90`）操作。

- `"rot90"`: 操作名称是 `rot90`。
- `dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half)`: 支持的数据类型包括所有数据类型、复数类型以及 `torch.bool`、`torch.bfloat16`、`torch.half`。
- `error_inputs_func=error_inputs_rot90`: 错误输入函数是 `error_inputs_rot90`，用于生成90度旋转操作的错误输入。
- `gradcheck_fast_mode=True`: 使用快速模式进行梯度检查，因为在慢速模式下运行速度很慢。
- `supports_out=False`: 不支持输出参数。
- `supports_forward_ad=True`: 支持前向自动微分。
- `supports_fwgrad_bwgrad=True`: 支持前向-后向梯度传播。
- `sample_inputs_func=sample_inputs_rot90`: 示例输入函数是 `sample_inputs_rot90`，用于生成90度旋转操作的示例输入。



    # To test reference numerics against multiple values of argument `decimals`,
    # we make multiple OpInfo entries with each entry corresponding to different value of decimals.


用于针对参数 `decimals` 的多个值测试参考数值的 OpInfo 条目。

- 这是一条注释，说明了为了测试不同的 `decimals` 参数值的参考数值，我们可以创建多个 `OpInfo` 条目。
    # 定义一个名为 'round' 的一元函数信息对象，用于描述 round 函数的行为和特性
    UnaryUfuncInfo('round',
                   ref=np.round,  # 参考实现使用 NumPy 的 round 函数
                   aliases=('special.round',),  # 别名为 'special.round'
                   dtypes=all_types_and(torch.half, torch.bfloat16),  # 支持所有数据类型以及 torch.half 和 torch.bfloat16
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
                   skips=(  # 跳过特定条件下的测试
                       DecorateInfo(unittest.expectedFailure,  # 使用 unittest.expectedFailure 进行装饰
                                    'TestNNCOpInfo',  # 测试类名
                                    'test_nnc_correctness',  # 测试方法名
                                    dtypes=tuple(t for t in integral_types() if t != torch.uint8)),  # 跳过不支持 torch.uint8 的整数类型
                       DecorateInfo(unittest.skip("Skipped!"),  # 使用 unittest.skip 进行装饰，说明测试被跳过
                                    'TestNNCOpInfo',  # 测试类名
                                    'test_nnc_correctness',  # 测试方法名
                                    dtypes=(torch.bfloat16,)),  # 跳过不支持 torch.bfloat16 类型的测试
                   ),
                   supports_sparse=True,  # 支持稀疏张量
                   supports_sparse_csr=True,  # 支持稀疏 CSR 格式
                   supports_sparse_csc=True,  # 支持稀疏 CSC 格式
                   supports_sparse_bsr=True,  # 支持稀疏 BSR 格式
                   supports_sparse_bsc=True,  # 支持稀疏 BSC 格式
                   assert_autodiffed=True,  # 断言已进行自动微分
                   ),

    # 定义另一个名为 'round' 的一元函数信息对象，用于描述 round 函数的另一种变体
    UnaryUfuncInfo('round',
                   ref=np.round,  # 参考实现使用 NumPy 的 round 函数
                   variant_test_name='decimals_0',  # 变体测试名称为 'decimals_0'
                   aliases=('special.round',),  # 别名为 'special.round'
                   dtypes=floating_types_and(torch.half, torch.bfloat16),  # 仅支持浮点数类型以及 torch.half 和 torch.bfloat16
                   sample_kwargs=lambda device, dtype, input: ({'decimals': 0}, {'decimals': 0}),  # 提供样本参数字典，用于测试时的输入
                   sample_inputs_func=partial(sample_inputs_elementwise_unary, op_kwargs={'decimals': 0}),  # 提供样本输入的生成函数
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
                   assert_autodiffed=False,  # 不断言已进行自动微分
                   supports_sparse_csr=False),  # 不支持稀疏 CSR 格式
    # 创建一个 UnaryUfuncInfo 对象，表示 round 函数的测试信息
    UnaryUfuncInfo('round',
                   ref=np.round,  # 参考实现为 NumPy 中的 round 函数
                   variant_test_name='decimals_3',  # 测试变种名称为 decimals_3
                   aliases=('special.round',),  # 别名为 special.round
                   dtypes=floating_types_and(torch.bfloat16),  # 支持的数据类型为浮点类型和 torch.bfloat16
                   dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),  # CUDA 环境下支持的数据类型
                   sample_kwargs=lambda device, dtype, input: ({'decimals': 3}, {'decimals': 3}),  # 用于生成样本参数的函数
                   sample_inputs_func=partial(sample_inputs_elementwise_unary, op_kwargs={'decimals': 3}),  # 生成输入样本的函数
                   skips=(
                       # 跳过以下测试：
                       DecorateInfo(unittest.skip("Skipped!"), 'TestCommon'),  # TestCommon 测试类跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients'),  # TestFwdGradients 测试类跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients'),  # TestBwdGradients 测试类跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestJit'),  # TestJit 测试类跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits'),  # TestMathBits 测试类跳过
                       # CUDA 环境下特定条件的测试跳过
                       DecorateInfo(toleranceOverride({torch.bfloat16: tol(atol=1e-3, rtol=0.016)}),
                                    "TestUnaryUfuncs", "test_reference_numerics_extremal",
                                    device_type="cuda"),
                       DecorateInfo(toleranceOverride({torch.bfloat16: tol(atol=1e-3, rtol=0.016)}),
                                    "TestUnaryUfuncs", "test_reference_numerics_normal",
                                    device_type="cuda"),
                   ),
                   supports_forward_ad=True,  # 支持前向自动求导
                   supports_fwgrad_bwgrad=True,  # 支持前向和反向梯度
                   assert_autodiffed=False,  # 不需要验证自动求导
                   supports_sparse_csr=False),  # 不支持稀疏 CSR 格式的输入

    # 创建另一个 UnaryUfuncInfo 对象，表示 round 函数的另一种测试信息
    UnaryUfuncInfo('round',
                   ref=np.round,  # 参考实现为 NumPy 中的 round 函数
                   variant_test_name='decimals_neg_3',  # 测试变种名称为 decimals_neg_3
                   aliases=('special.round',),  # 别名为 special.round
                   dtypes=floating_types_and(torch.bfloat16),  # 支持的数据类型为浮点类型和 torch.bfloat16
                   dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),  # CUDA 环境下支持的数据类型
                   sample_kwargs=lambda device, dtype, input: ({'decimals': -3}, {'decimals': -3}),  # 用于生成样本参数的函数
                   sample_inputs_func=partial(sample_inputs_elementwise_unary, op_kwargs={'decimals': -3}),  # 生成输入样本的函数
                   skips=(
                       # 跳过以下测试：
                       DecorateInfo(unittest.skip("Skipped!"), 'TestCommon'),  # TestCommon 测试类跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients'),  # TestFwdGradients 测试类跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients'),  # TestBwdGradients 测试类跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestJit'),  # TestJit 测试类跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits'),  # TestMathBits 测试类跳过
                   ),
                   supports_forward_ad=True,  # 支持前向自动求导
                   supports_fwgrad_bwgrad=True,  # 支持前向和反向梯度
                   assert_autodiffed=False,  # 不需要验证自动求导
                   supports_sparse_csr=False),  # 不支持稀疏 CSR 格式的输入
    # 定义一个一元函数信息对象，函数名为 'sin'，参考实现为 numpy 的 sin 函数
    UnaryUfuncInfo('sin',
                   ref=np.sin,
                   # 支持的数据类型包括所有类型、复数类型以及指定的 torch 数据类型
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 如果是在 CUDA 下，支持的数据类型包括所有类型、复数类型以及指定的 torch 数据类型
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),
                   # 断言支持自动微分
                   assert_autodiffed=True,
                   # 不处理大浮点数
                   handles_large_floats=False,
                   # 支持稀疏张量
                   supports_sparse=True,
                   # 支持稀疏张量格式 CSR
                   supports_sparse_csr=True,
                   # 支持稀疏张量格式 CSC
                   supports_sparse_csc=True,
                   # 支持稀疏张量格式 BSR
                   supports_sparse_bsr=True,
                   # 支持稀疏张量格式 BSC
                   supports_sparse_bsc=True,
                   # 支持前向自动微分
                   supports_forward_ad=True,
                   # 支持前向-后向自动微分
                   supports_fwgrad_bwgrad=True,
                   # 将整数升级为浮点数
                   promotes_int_to_float=True,
                   # 跳过特定的测试用例
                   skips=(
                       # 在 CUDA 下失败但在 ROCm 下通过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=(torch.cdouble,), device_type='cuda'),
                       # 在 Windows 平台下，对 CPU 的复数类型测试跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=(torch.cfloat, torch.cdouble,), device_type='cpu', active_if=IS_WINDOWS),
                       # 在 Windows 平台下，对 CPU 的复数类型测试跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=(torch.cfloat, torch.cdouble,), device_type='cpu', active_if=IS_WINDOWS),
                       # 跳过稀疏张量的反向传播不支持的测试
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),
                   ),
                   # 使用特定的精度覆盖装饰器
                   decorators=(precisionOverride({torch.bfloat16: 1e-2}),)),

    # 定义一个一元函数信息对象，函数名为 'sinc'，参考实现为自定义的 np_sinc_with_fp16_as_fp32 函数
    UnaryUfuncInfo('sinc',
                   ref=np_sinc_with_fp16_as_fp32,
                   # 别名为 'special.sinc'
                   aliases=('special.sinc',),
                   # 支持的数据类型包括所有类型、复数类型以及指定的 torch 数据类型
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 不处理大浮点数
                   handles_large_floats=False,
                   # 支持前向自动微分
                   supports_forward_ad=True,
                   # 支持前向-后向自动微分
                   supports_fwgrad_bwgrad=True,
                   # 将整数升级为浮点数
                   promotes_int_to_float=True),
    UnaryUfuncInfo('sinh',
                   ref=np_unary_ufunc_integer_promotion_wrapper(np.sinh),
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),
                   assert_autodiffed=True,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   supports_sparse=True,
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   promotes_int_to_float=True,
                   decorators=(precisionOverride({torch.float16: 1e-2}),),
                   skips=(
                       # 在特定条件下跳过测试：当操作系统为 macOS 或 Windows 时跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=(IS_MACOS or IS_WINDOWS)),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=(IS_MACOS or IS_WINDOWS)),
                       # 在特定条件下跳过测试：当数据类型为 torch.cdouble 时跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=(torch.cdouble,)),
                       # 参考：https://github.com/pytorch/pytorch/issues/48641
                       # 在特定条件下跳过测试：当操作系统为 macOS 或 Windows 且数据类型为 torch.int8 时跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=[torch.int8]),
                       # 在特定条件下跳过测试：稀疏反向传播不受支持
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),
                   )),
    UnaryUfuncInfo('sign',
                   ref=reference_sign,
                   dtypes=all_types_and(torch.bool, torch.bfloat16, torch.half),
                   dtypesIfCUDA=all_types_and(torch.bool, torch.bfloat16, torch.half),
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   supports_sparse=True,
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   skips=(
                       # 参考：https://github.com/pytorch/pytorch/issues/41245
                       # 在特定条件下跳过测试：当数据类型为 torch.bfloat16, torch.float16, torch.float32, torch.float64 时跳过
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=[torch.bfloat16, torch.float16, torch.float32, torch.float64]),
                   )),
    UnaryUfuncInfo('sgn',
                   ref=reference_sgn,  # 设置参考实现函数为 reference_sgn
                   dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf),  # 定义支持的数据类型集合
                   backward_dtypes=floating_and_complex_types_and(torch.bfloat16, torch.half),  # 指定反向传播支持的数据类型
                   backward_dtypesIfCUDA=floating_and_complex_types_and(torch.bfloat16, torch.half, torch.chalf),  # 指定 CUDA 环境下的反向传播支持的数据类型
                   supports_forward_ad=True,  # 标识支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 标识支持前向梯度和反向梯度
                   supports_sparse=True,  # 标识支持稀疏张量
                   supports_sparse_csr=True,  # 标识支持 CSR 格式的稀疏张量
                   supports_sparse_csc=True,  # 标识支持 CSC 格式的稀疏张量
                   supports_sparse_bsr=True,  # 标识支持 BSR 格式的稀疏张量
                   supports_sparse_bsc=True,  # 标识支持 BSC 格式的稀疏张量
                   skips=(
                       # 引用：https://github.com/pytorch/pytorch/issues/41245
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=[torch.bfloat16, torch.float16, torch.float32, torch.float64]),  # 标识需要跳过的测试用例信息
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),  # 标识需要跳过的稀疏张量相关测试用例信息
                   )),
    OpInfo('split',
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool, torch.chalf),  # 定义支持的数据类型集合
           sample_inputs_func=partial(sample_inputs_split, list_args=False),  # 设置生成拆分操作样例输入的函数，不使用列表参数
           supports_forward_ad=True,  # 标识支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 标识支持前向梯度和反向梯度
           supports_out=False,  # 标识不支持输出参数
           autodiff_fusible_nodes=[],  # 不应该融合的自动微分节点列表，因为别名输入，不应该融合
           autodiff_nonfusible_nodes=[],  # 不应该融合的自动微分节点列表，因为别名输入，不应该融合
           assert_autodiffed=True),  # 断言自动微分已完成
    OpInfo('split',
           # 由于 test_variant_consistency_jit_split_list_args_cpu_float32 测试的存在，不能声明这个 aten_name
           decomp_aten_name='split_with_sizes',  # 指定拆分操作的分解操作名
           variant_test_name='list_args',  # 指定测试的变体名称为 list_args
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool),  # 定义支持的数据类型集合
           sample_inputs_func=partial(sample_inputs_split, list_args=True),  # 设置生成拆分操作样例输入的函数，使用列表参数
           supports_forward_ad=True,  # 标识支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 标识支持前向梯度和反向梯度
           supports_out=False),  # 标识不支持输出参数
    # `unsafe_split` 操作只支持 `int` 类型的 split_size 参数
    OpInfo('unsafe_split',
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool, torch.chalf),  # 定义支持的数据类型集合
           sample_inputs_func=partial(sample_inputs_split, list_args=False),  # 设置生成拆分操作样例输入的函数，不使用列表参数
           supports_forward_ad=True,  # 标识支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 标识支持前向梯度和反向梯度
           supports_out=False,  # 标识不支持输出参数
           autodiff_fusible_nodes=[],  # 不应该融合的自动微分节点列表，因为别名输入，不应该融合
           autodiff_nonfusible_nodes=[],  # 不应该融合的自动微分节点列表，因为别名输入，不应该融合
           assert_autodiffed=True,  # 断言自动微分已完成
           check_batched_forward_grad=False),  # 检查批处理前向梯度的参数设为 False
    OpInfo('split_with_sizes',
           # 定义操作信息，指定操作名称为'split_with_sizes'
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool, torch.chalf),
           # 指定数据类型，包括所有类型和复杂类型以及指定的几种特定类型
           sample_inputs_func=sample_inputs_split_with_sizes,
           # 指定用于生成样本输入的函数为sample_inputs_split_with_sizes
           autodiff_fusible_nodes=[],  # 别名输入，不应融合
           # 自动微分可融合节点为空列表，表示不融合别名输入
           autodiff_nonfusible_nodes=[],  # 别名输入，不应融合
           # 自动微分不可融合节点为空列表，表示不融合别名输入
           supports_out=False,
           # 不支持输出
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向梯度和反向梯度
           assert_autodiffed=True),
           # 断言自动微分完成
    OpInfo('split_with_sizes_copy',
           # 定义操作信息，指定操作名称为'split_with_sizes_copy'
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool, torch.chalf),
           # 指定数据类型，包括所有类型和复杂类型以及指定的几种特定类型
           sample_inputs_func=sample_inputs_split_with_sizes,
           # 指定用于生成样本输入的函数为sample_inputs_split_with_sizes
           supports_out=True,
           # 支持输出
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向梯度和反向梯度
           skips=(
               # 跳过的测试用例信息
               # 没有引发错误
               DecorateInfo(unittest.expectedFailure, "TestCommon", "test_out_requires_grad_error"),
           )),
    BinaryUfuncInfo('__radd__',
                    # 定义二元ufunc信息，指定操作名称为'__radd__'
                    op=torch.Tensor.__radd__,
                    # 操作为torch.Tensor的反向加法
                    dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool),
                    # 指定数据类型，包括所有类型和复杂类型以及指定的几种特定类型
                    supports_out=False,
                    # 不支持输出
                    skips=(
                        # 跳过的测试用例信息
                        DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
                        DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',),

                    ),
                    # 跳过的测试用例信息，涉及不支持的测试
                    assert_autodiffed=True,
                    # 断言自动微分完成
                    supports_forward_ad=True,
                    # 支持前向自动微分
                    supports_fwgrad_bwgrad=True,
                    # 支持前向梯度和反向梯度
                    autodiff_nonfusible_nodes=['aten::add'],),
                    # 自动微分不可融合节点包括'aten::add'
    BinaryUfuncInfo('__rdiv__',
                    # 定义二元ufunc信息，指定操作名称为'__rdiv__'
                    op=torch.Tensor.__rdiv__,
                    # 操作为torch.Tensor的反向除法
                    dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool),
                    # 指定数据类型，包括所有类型和复杂类型以及指定的几种特定类型
                    promotes_int_to_float=True,
                    # 将整数提升为浮点数
                    lhs_make_tensor_kwargs={'exclude_zero': True},
                    # 左操作数制作张量的关键字参数，排除零
                    gradcheck_fast_mode=True,
                    # 在慢速gradcheck上运行非常慢 - 或者可以减少输入大小
                    supports_out=False,
                    # 不支持输出
                    skips=(
                        # 跳过的测试用例信息
                        # https://github.com/pytorch/pytorch/issues/76806
                        DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),
                        DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
                        DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',),
                    ),
                    # 跳过的测试用例信息，涉及不支持的测试
                    supports_forward_ad=True,
                    # 支持前向自动微分
                    supports_fwgrad_bwgrad=True,
                    # 支持前向梯度和反向梯度
                    assert_autodiffed=True,
                    # 断言自动微分完成
                    autodiff_nonfusible_nodes=['aten::mul', 'aten::reciprocal'],),
                    # 自动微分不可融合节点包括'aten::mul', 'aten::reciprocal'
    BinaryUfuncInfo('__rmul__',  # 定义二元ufunc信息，用于右乘操作
                    op=torch.Tensor.__rmul__,  # 操作符为张量的右乘方法
                    dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool),  # 支持的数据类型包括所有类型、复数类型和指定的数据类型
                    supports_out=False,  # 不支持输出参数
                    skips=(  # 跳过的测试信息元组
                        DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期失败的测试装饰信息
                        DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',),  # 预期失败的 JIT 测试装饰信息
                    ),
                    assert_autodiffed=True,  # 断言自动微分已启用
                    supports_forward_ad=True,  # 支持正向自动微分
                    supports_fwgrad_bwgrad=True,  # 支持正向梯度和反向梯度
                    autodiff_nonfusible_nodes=['aten::mul'],  # 自动微分不融合节点包括 'aten::mul'
                    ),

    BinaryUfuncInfo('__rand__',  # 定义二元ufunc信息，用于按位与操作
                    op=torch.Tensor.__rand__,  # 操作符为张量的按位与方法
                    dtypes=integral_types_and(torch.bool),  # 支持的数据类型包括整数类型和布尔类型
                    supports_out=False,  # 不支持输出参数
                    supports_autograd=False,  # 不支持自动求导
                    supports_forward_ad=True,  # 支持正向自动微分
                    skips=(  # 跳过的测试信息元组
                        DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期失败的测试装饰信息
                    )),

    BinaryUfuncInfo('__ror__',  # 定义二元ufunc信息，用于按位或操作
                    op=torch.Tensor.__ror__,  # 操作符为张量的按位或方法
                    dtypes=integral_types_and(torch.bool),  # 支持的数据类型包括整数类型和布尔类型
                    supports_out=False,  # 不支持输出参数
                    supports_autograd=False,  # 不支持自动求导
                    supports_forward_ad=True,  # 支持正向自动微分
                    skips=(  # 跳过的测试信息元组
                        DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期失败的测试装饰信息
                    )),

    BinaryUfuncInfo('__rxor__',  # 定义二元ufunc信息，用于按位异或操作
                    op=torch.Tensor.__rxor__,  # 操作符为张量的按位异或方法
                    dtypes=integral_types_and(torch.bool),  # 支持的数据类型包括整数类型和布尔类型
                    supports_out=False,  # 不支持输出参数
                    supports_autograd=False,  # 不支持自动求导
                    supports_forward_ad=True,  # 支持正向自动微分
                    skips=(  # 跳过的测试信息元组
                        DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期失败的测试装饰信息
                    )),
    OpInfo('__rmatmul__',  # 定义特殊方法名称为 '__rmatmul__'
           op=torch.Tensor.__rmatmul__,  # 指定操作为 torch.Tensor 类的 '__rmatmul__' 方法
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16),  # 指定所有数据类型和复杂类型以及 torch.bfloat16 和 torch.float16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16,
                                                       *[torch.bfloat16]  # 如果是 SM53 或更新版本或者在 ROCm 下进行测试，则加入 torch.bfloat16
                                                       if SM53OrLater or TEST_WITH_ROCM else []),
           assert_autodiffed=True,  # 断言自动微分为 True
           sample_inputs_func=partial(sample_inputs_matmul, is_rmatmul=True),  # 使用 sample_inputs_matmul 的部分函数，标记为 is_rmatmul=True
           # 在慢速 gradcheck 上运行非常缓慢，或者可以减小输入尺寸作为替代方案
           gradcheck_fast_mode=True,  # 使用快速模式进行 gradcheck
           supports_out=False,  # 不支持输出张量 out
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           check_batched_forward_grad=False,  # 不检查批处理的前向梯度
           decorators=(  # 装饰器元组开始
               # 仅当 SM >= 5.3 时，NVIDIA 才确保支持 bfloat16
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_dtypes', device_type='cuda', active_if=not SM53OrLater),
               # 设置 torch.complex64 类型的容差覆盖为指定的公差
               DecorateInfo(toleranceOverride({torch.complex64: tol(atol=1e-05, rtol=1.2e-03)}),
                            'TestMathBits', 'test_conj_view'),
               # 设置 torch.float32 类型的容差覆盖为指定的公差
               DecorateInfo(toleranceOverride({torch.float32: tol(atol=1e-05, rtol=1.2e-03)}),
                            'TestCommon', 'test_noncontiguous_samples'),
               # 设置 torch.complex64 类型的容差覆盖为指定的公差，仅在 TEST_WITH_ROCM 为真时在 CUDA 设备上有效
               DecorateInfo(toleranceOverride({torch.complex64: tol(atol=1e-05, rtol=1e-05)}),
                            "TestDecomp", "test_comprehensive", device_type="cuda",
                            active_if=TEST_WITH_ROCM),
           ),
           skips=(  # 跳过装饰器元组开始
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',),
               # https://github.com/pytorch/pytorch/issues/67470
               DecorateInfo(unittest.skip("67470!"),
                            'TestCommon', 'test_noncontiguous_samples',
                            device_type='cpu', dtypes=(torch.long,)),
               # 在 XLA 上失败
               # AssertionError: False is not true : Tensors failed to compare as equal
               DecorateInfo(unittest.skip("Skipped!"), 'TestOpInfo', device_type='xla', dtypes=(torch.long,)),
               # https://github.com/pytorch/pytorch/issues/71774
               DecorateInfo(unittest.skip('Skipped!'), 'TestNNCOpInfo', 'test_nnc_correctness',
                            device_type='cpu', dtypes=(torch.long,)),
           )),  # 跳过装饰器元组结束
    # 定义二元ufunc操作的信息，此处为 '__rmod__' 操作
    BinaryUfuncInfo('__rmod__',
                    # 操作函数为 torch.Tensor.__rmod__
                    op=torch.Tensor.__rmod__,
                    # 操作涉及的数据类型，包括浮点类型和 torch.bfloat16, torch.half
                    dtypes=floating_types_and(torch.bfloat16, torch.half,),
                    # 如果是CUDA环境，支持的数据类型包括所有类型和 torch.bfloat16, torch.half
                    dtypesIfCUDA=all_types_and(torch.bfloat16, torch.half),
                    # 开启快速模式的梯度检查
                    gradcheck_fast_mode=True,
                    # 不支持输出张量作为参数
                    supports_out=False,
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 支持前向-反向梯度
                    supports_fwgrad_bwgrad=True,
                    # 支持单个Python标量作为参数
                    supports_one_python_scalar=True,
                    # 跳过的测试用例，指定为预期失败的测试用例
                    skips=(
                        DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
                        DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',),
                    ),
                    # 断言自动微分已启用
                    assert_autodiffed=True,
                    # 不可融合的自动微分节点
                    autodiff_nonfusible_nodes=['aten::remainder'],),

    # 定义二元ufunc操作的信息，此处为 '__rpow__' 操作
    BinaryUfuncInfo('__rpow__',
                    # 操作函数为 torch.Tensor.__rpow__
                    op=torch.Tensor.__rpow__,
                    # 涉及的数据类型包括所有类型和复数类型以及 torch.bfloat16, torch.half
                    dtypes=all_types_and_complex_and(torch.bfloat16, torch.half),
                    # 反向传播时的数据类型包括所有类型和复数类型以及 torch.bfloat16, torch.half
                    backward_dtypes=all_types_and_complex_and(torch.bfloat16, torch.half),
                    # 不支持输出张量作为参数
                    supports_out=False,
                    # 支持前向自动微分
                    supports_forward_ad=True,
                    # 支持前向-反向梯度
                    supports_fwgrad_bwgrad=True,
                    # 支持单个Python标量作为参数
                    supports_one_python_scalar=True,
                    # 跳过的测试用例，指定为预期失败的测试用例以及需要调整的测试用例
                    skips=(
                        DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
                        DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',),
                        # TODO: FIXME tolerance is too high
                        DecorateInfo(unittest.skip('Skipped!'), 'TestFwdGradients'),
                        DecorateInfo(unittest.skip('Skipped!'), 'TestBwdGradients'),
                    ),
                    # 断言自动微分已启用
                    assert_autodiffed=True,
                    # 不可融合的自动微分节点
                    autodiff_nonfusible_nodes=['aten::pow'],),
    BinaryUfuncInfo('__rsub__',
                    op=torch.Tensor.__rsub__,  # 定义二元反向减法运算的操作
                    dtypes=all_types_and_complex_and(torch.bfloat16, torch.half),  # 支持的数据类型
                    supports_forward_ad=True,  # 支持前向自动微分
                    supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
                    supports_out=False,  # 不支持输出张量作为参数
                    supports_one_python_scalar=True,  # 支持Python标量作为参数
                    skips=(
                        DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 跳过的测试信息
                        DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',),  # 跳过的测试信息
                    ),
                    assert_autodiffed=True,  # 断言已经自动微分
                    autodiff_nonfusible_nodes=['aten::rsub'],),  # 自动微分时不可融合的节点

    BinaryUfuncInfo('rsub',
                    dtypes=all_types_and_complex_and(torch.bfloat16, torch.half),  # 支持的数据类型
                    supports_forward_ad=True,  # 支持前向自动微分
                    supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
                    supports_out=False,  # 不支持输出张量作为参数
                    supports_inplace_autograd=False,  # 不支持原地自动微分
                    assert_autodiffed=None,  # 不断言已自动微分
                    sample_inputs_func=sample_inputs_add_sub),  # 获取示例输入的函数

    OpInfo('select',
           aten_backward_name='select_backward',  # ATen反向名称
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool, torch.chalf),  # 支持的数据类型
           sample_inputs_func=sample_inputs_select,  # 获取示例输入的函数
           assert_jit_shape_analysis=True,  # 断言JIT形状分析为真
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           supports_out=False),  # 不支持输出张量作为参数

    OpInfo('select_scatter',
           dtypes=all_types_and(torch.bfloat16, torch.half, torch.bool),  # 支持的数据类型
           sample_inputs_func=sample_inputs_select_scatter,  # 获取示例输入的函数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           supports_out=False),  # 不支持输出张量作为参数

    OpInfo('slice',
           op=torch.ops.aten.slice.Tensor,  # ATen张量切片操作
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.half, torch.bool, torch.chalf),  # 支持的数据类型
           sample_inputs_func=sample_inputs_slice,  # 获取示例输入的函数
           gradcheck_fast_mode=True,  # 使用快速梯度检查模式
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           supports_scripting=False,  # 不支持脚本化
           supports_inplace_autograd=False,  # 不支持原地自动微分
           supports_out=False),  # 不支持输出张量作为参数

    OpInfo('slice_scatter',
           dtypes=all_types_and(torch.bfloat16, torch.half, torch.bool),  # 支持的数据类型
           sample_inputs_func=sample_inputs_slice_scatter,  # 获取示例输入的函数
           # https://github.com/pytorch/pytorch/issues/80411
           gradcheck_fast_mode=True,  # 使用快速梯度检查模式
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           supports_out=True),  # 支持输出张量作为参数
    # 创建 UnaryUfuncInfo 对象，表示一元函数的信息，这里是 'signbit'
    UnaryUfuncInfo('signbit',
                   # 引用 NumPy 中的 np.signbit 函数作为参考实现
                   ref=np.signbit,
                   # 支持的数据类型，包括所有类型和 torch.bool, torch.bfloat16, torch.half
                   dtypes=all_types_and(torch.bool, torch.bfloat16, torch.half),
                   # 支持稀疏张量
                   supports_sparse=True,
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   # 不支持自动微分
                   supports_autograd=False,),
    # 创建 UnaryUfuncInfo 对象，表示一元函数的信息，这里是 'tan'
    UnaryUfuncInfo('tan',
                   # 引用 NumPy 中的 np.tan 函数作为参考实现
                   ref=np.tan,
                   # 支持的数据类型，包括所有类型和复数类型，以及 torch.bool, torch.half, torch.bfloat16
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 如果在 CUDA 下，支持的数据类型包括复数类型和 torch.chalf, torch.bool, torch.half, torch.bfloat16
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),
                   # 修饰信息，包括容忍性覆盖和测试相关的装饰器信息，针对 CUDA 设备
                   decorators=(DecorateInfo(
                               toleranceOverride({torch.complex64: tol(atol=1e-04, rtol=1e-05)}),
                               'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                               device_type='cuda'),),
                   # 断言已经进行了自动微分
                   assert_autodiffed=True,
                   # 支持前向自动微分
                   supports_forward_ad=True,
                   # 支持前向后向自动微分
                   supports_fwgrad_bwgrad=True,
                   # 支持稀疏张量
                   supports_sparse=True,
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   # 整数类型提升为浮点数类型
                   promotes_int_to_float=True,
                   # 跳过的测试信息，包括跳过的装饰器信息，用于特定的设备和数据类型条件
                   skips=(
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=(IS_MACOS or IS_WINDOWS)),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=(IS_MACOS or IS_WINDOWS)),
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),
                   ),
                   # 参考数值过滤器，条件是函数值接近整数倍的 π/2，结果为 math.pi
                   reference_numerics_filter=NumericsFilter(
                       condition=lambda x: close_to_int(x / (math.pi * 0.5)), safe_val=math.pi)),
    # 定义一个包含有关 tanh 函数的信息的对象
    UnaryUfuncInfo('tanh',
                   # 引用 NumPy 中的 tanh 函数
                   ref=np.tanh,
                   # ATen 反向传播函数的名称
                   aten_backward_name='tanh_backward',
                   # 别名列表
                   aliases=('nn.functional.tanh',),
                   # 装饰器列表，包括精度覆盖和装饰信息
                   decorators=(precisionOverride({torch.bfloat16: 1e-2}),
                               DecorateInfo(
                                   # 针对特定精度的容差覆盖
                                   toleranceOverride({torch.complex64: tol(atol=1e-04, rtol=2e-05)}),
                                   'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                   device_type='cuda'),),
                   # 所有数据类型和复数类型的列表
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 如果是 CUDA，支持的数据类型列表
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),
                   # 断言自动微分已启用
                   assert_autodiffed=True,
                   # 断言 JIT 形状分析已启用
                   assert_jit_shape_analysis=True,
                   # 支持前向自动求导
                   supports_forward_ad=True,
                   # 支持前向-后向梯度
                   supports_fwgrad_bwgrad=True,
                   # 支持稀疏张量
                   supports_sparse=True,
                   # 支持稀疏 CSR 格式
                   supports_sparse_csr=True,
                   # 支持稀疏 CSC 格式
                   supports_sparse_csc=True,
                   # 支持稀疏 BSR 格式
                   supports_sparse_bsr=True,
                   # 支持稀疏 BSC 格式
                   supports_sparse_bsc=True,
                   # 将整数提升为浮点数
                   promotes_int_to_float=True,
                   # 跳过的装饰信息，包括测试跳过和条件
                   skips=(
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=(IS_MACOS or IS_WINDOWS)),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                                    active_if=(IS_MACOS or IS_WINDOWS)),
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),
                   ),
                   # 参考数值过滤器，用于处理 tan(j * pi/2 * odd_number) 为 nan 的情况
                   reference_numerics_filter=NumericsFilter(
                       # 条件函数，用于检测是否接近整数倍的情况
                       condition=lambda x: (close_to_int(x / (math.pi * 0.5j))
                                            if x.is_complex() else x.new_tensor(False, dtype=torch.bool)),
                       # 安全值设为 0
                       safe_val=0)),
    OpInfo('tensor_split',
           ref=np.array_split,
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),
           dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           skips=(
               # 预先存在的条件；需要修复
               DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_operator'),
               DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_backward'),
               DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_forward_ad'),
           ),
           sample_inputs_func=sample_inputs_tensor_split,),


OpInfo('hsplit',
       dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.bfloat16, torch.float16),
       supports_out=False,
       supports_forward_ad=True,
       supports_fwgrad_bwgrad=True,
       # 查看 https://github.com/pytorch/pytorch/pull/78358
       check_batched_forward_grad=False,
       sample_inputs_func=sample_inputs_hsplit,
       error_inputs_func=error_inputs_hsplit,),


OpInfo('vsplit',
       dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.bfloat16, torch.float16),
       supports_out=False,
       supports_forward_ad=True,
       supports_fwgrad_bwgrad=True,
       # 查看 https://github.com/pytorch/pytorch/pull/78358
       check_batched_forward_grad=False,
       sample_inputs_func=sample_inputs_vsplit,
       error_inputs_func=error_inputs_vsplit,),


OpInfo('dsplit',
       dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.bfloat16, torch.float16),
       supports_out=False,
       supports_forward_ad=True,
       supports_fwgrad_bwgrad=True,
       # 查看 https://github.com/pytorch/pytorch/pull/78358
       check_batched_forward_grad=False,
       sample_inputs_func=sample_inputs_dsplit,
       error_inputs_func=error_inputs_dsplit,),
    OpInfo('triangular_solve',
           op=torch.triangular_solve,
           dtypes=floating_and_complex_types(),
           sample_inputs_func=sample_inputs_legacy_solve,
           check_batched_gradgrad=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           gradcheck_wrapper=lambda *args, **kwargs: gradcheck_wrapper_triangular_input(*args, idx=1, **kwargs),
           decorators=[skipCUDAIfNoMagma, skipCPUIfNoLapack],
           skips=(
               # 断言失败：标量不相等！
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
               # 梯度检查失败
               DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', 'test_fn_fwgrad_bwgrad',
                            dtypes=floating_and_complex_types()),
               # 跳过测试，设备类型为 'mps'，数据类型为 torch.float32
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_out',
                            device_type='mps', dtypes=[torch.float32]),
               # 跳过测试，设备类型为 'mps'，数据类型为 torch.float32
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager',
                            device_type='mps', dtypes=[torch.float32]),
               # 跳过测试，设备类型为 'mps'，数据类型为 torch.float32
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit',
                            device_type='mps', dtypes=[torch.float32]),
           )),
    UnaryUfuncInfo('trunc',
                   aliases=('fix', ),
                   ref=np.trunc,
                   dtypes=all_types_and(torch.half, torch.bfloat16),
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   supports_sparse=True,
                   skips=(
                       # 预期失败的装饰器，针对 'TestNNCOpInfo' 下的 'test_nnc_correctness' 测试
                       DecorateInfo(unittest.expectedFailure,
                                    'TestNNCOpInfo',
                                    'test_nnc_correctness',
                                    # 排除 torch.uint8 类型
                                    dtypes=tuple(t for t in integral_types() if t != torch.uint8)),
                   ),
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   assert_autodiffed=True),
    # 定义一个名为 'exp2' 的 UnaryUfuncInfo 对象，表示指数函数 2 的指数值
    UnaryUfuncInfo('exp2',
                   # 别名为 'special.exp2'
                   aliases=('special.exp2', ),
                   # 引用 numpy.exp2 函数作为参考实现
                   ref=np_unary_ufunc_integer_promotion_wrapper(np.exp2),
                   # 支持的数据类型包括所有类型、复数以及特定类型 torch.bool、torch.half、torch.bfloat16
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 支持正向自动微分
                   supports_forward_ad=True,
                   # 支持正向和反向梯度的计算
                   supports_fwgrad_bwgrad=True,
                   # 将整数类型提升为浮点数类型
                   promotes_int_to_float=True,
                   # 跳过的测试用例，包括在指定设备和数据类型上的测试，以及其他相关测试
                   skips=(
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=[torch.cdouble]),
                       # 参考链接：https://github.com/pytorch/pytorch/issues/48010
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
                   )),
    # 定义一个名为 'expm1' 的 UnaryUfuncInfo 对象，表示指数函数 e^x - 1
    UnaryUfuncInfo('expm1',
                   # 别名为 'special.expm1'
                   aliases=('special.expm1', ),
                   # 引用 numpy.expm1 函数作为参考实现
                   ref=np_unary_ufunc_integer_promotion_wrapper(np.expm1),
                   # 支持的数据类型包括所有类型、复数以及特定类型 torch.bool、torch.half、torch.bfloat16
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 支持正向自动微分
                   supports_forward_ad=True,
                   # 支持正向和反向梯度的计算
                   supports_fwgrad_bwgrad=True,
                   # 支持稀疏张量操作
                   supports_sparse=True,
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   # 将整数类型提升为浮点数类型
                   promotes_int_to_float=True,
                   # 断言自动微分后的结果正确
                   assert_autodiffed=True,
                   # 跳过的测试用例，包括在指定设备和数据类型上的测试，以及其他相关测试
                   skips=(
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cuda', dtypes=[torch.complex128]),
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),
                   )),
    UnaryUfuncInfo('nan_to_num',
                   # 操作名称为 nan_to_num，对应的参考实现是 numpy 的 nan_to_num 函数
                   ref=np.nan_to_num,
                   # 支持的数据类型包括所有类型以及 torch.half, torch.bool, torch.bfloat16
                   dtypes=all_types_and(torch.half, torch.bool, torch.bfloat16),
                   # 如果在 CUDA 下，支持的数据类型同上
                   dtypesIfCUDA=all_types_and(torch.half, torch.bool, torch.bfloat16),
                   # 支持正向自动求导
                   supports_forward_ad=True,
                   # 支持正向和反向自动求导之间的混合梯度
                   supports_fwgrad_bwgrad=True,
                   # 支持稀疏张量
                   supports_sparse=True,
                   # 跳过的测试：对于 'TestSparseUnaryUfuncs' 的 'test_sparse_fn_grad' 测试，使用 unittest 的 skip 装饰器标记为跳过
                   skips=(
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),
                   ),
                   # 通过 sample_kwargs 将 numpy_kwargs 传递，因为 numpy 在比较时使用 float 类型处理 BFloat16，因为目前不支持 BFloat16
                   # 参考：https://github.com/pytorch/pytorch/issues/57982#issuecomment-839150556
                   sample_kwargs=lambda device, dtype, input: ({},
                                                               {'posinf': torch.finfo(torch.bfloat16).max,
                                                                'neginf': torch.finfo(torch.bfloat16).min})
                   if dtype is torch.bfloat16 else ({}, {})),
    UnaryUfuncInfo('reciprocal',
                   # 操作名称为 reciprocal，通过 np_unary_ufunc_integer_promotion_wrapper 封装了 np.reciprocal 函数
                   ref=np_unary_ufunc_integer_promotion_wrapper(np.reciprocal),
                   # 支持的数据类型包括所有类型以及复数类型，还包括 torch.bool, torch.half, torch.bfloat16
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
                   # 断言自动微分已启用
                   assert_autodiffed=True,
                   # 支持正向自动求导
                   supports_forward_ad=True,
                   # 支持正向和反向自动求导之间的混合梯度
                   supports_fwgrad_bwgrad=True,
                   # 将整数提升为浮点数
                   promotes_int_to_float=True,
                   # 跳过的测试：对于 'TestUnaryUfuncs' 的 'test_reference_numerics_extremal' 测试，使用 unittest 的 skip 装饰器标记为跳过
                   skips=(
                       # 参考：https://github.com/pytorch/pytorch/issues/45690
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=[torch.cfloat, torch.cdouble]),
                   )),
    UnaryUfuncInfo('rsqrt',
                   ref=lambda x: np.reciprocal(np.sqrt(x)),
                   domain=(0, None),  # 定义输入域为大于等于 0 的实数
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括所有标量类型和复数类型以及 torch.bool, torch.half, torch.bfloat16
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),  # 如果在 CUDA 下，支持的数据类型包括 torch.chalf, torch.bool, torch.half, torch.bfloat16
                   decorators=(precisionOverride({torch.half: 5e-2}),),  # 使用 precisionOverride 装饰器，对 torch.half 类型的精度进行覆盖，设置为 5e-2
                   assert_autodiffed=True,  # 断言支持自动微分
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
                   promotes_int_to_float=True,  # 将整数提升为浮点数
                   skips=(
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=(torch.cfloat, torch.cdouble)),  # 跳过的测试信息，指明跳过 'TestUnaryUfuncs' 下的 'test_reference_numerics_extremal' 测试，针对 torch.cfloat 和 torch.cdouble 类型
                       # AssertionError: Tensor-likes are not close!
                       # Greatest absolute difference: nan at index (700,) (up to 0.01 allowed)
                       # Greatest relative difference: nan at index (700,) (up to 0.001 allowed)
                       DecorateInfo(unittest.expectedFailure, 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=(torch.chalf,)),  # 预期失败的测试信息，指明 'TestUnaryUfuncs' 下的 'test_reference_numerics_large' 测试预期失败，针对 torch.chalf 类型
                   )),
    UnaryUfuncInfo('sqrt',
                   ref=np.sqrt,  # 参考实现使用 numpy 的 sqrt 函数
                   supports_sparse=True,  # 支持稀疏张量
                   domain=(0, None),  # 定义输入域为大于等于 0 的实数
                   dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型包括所有标量类型和复数类型以及 torch.bool, torch.half, torch.bfloat16
                   dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),  # 如果在 CUDA 下，支持的数据类型包括 torch.chalf, torch.bool, torch.half, torch.bfloat16
                   assert_autodiffed=True,  # 断言支持自动微分
                   supports_forward_ad=True,  # 支持前向自动微分
                   supports_sparse_csr=True,  # 支持稀疏张量的 CSR 格式
                   supports_sparse_csc=True,  # 支持稀疏张量的 CSC 格式
                   supports_sparse_bsr=True,  # 支持稀疏张量的 BSR 格式
                   supports_sparse_bsc=True,  # 支持稀疏张量的 BSC 格式
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
                   promotes_int_to_float=True,  # 将整数提升为浮点数
                   decorators=(
                       precisionOverride({torch.bfloat16: 7e-2}),  # 使用 precisionOverride 装饰器，对 torch.bfloat16 类型的精度进行覆盖，设置为 7e-2
                       DecorateInfo(
                           toleranceOverride({torch.chalf: tol(atol=1e-2, rtol=0)}),  # 使用 toleranceOverride 装饰器，对 torch.chalf 类型的容差进行覆盖，设置为 atol=1e-2, rtol=0
                           'TestUnaryUfuncs', 'test_reference_numerics_large'),  # 装饰器应用于 'TestUnaryUfuncs' 下的 'test_reference_numerics_large' 测试
                   ),
                   skips=(
                       # Reference: https://github.com/pytorch/pytorch/issues/47358
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    device_type='cpu', dtypes=(torch.cfloat, torch.cdouble),
                                    active_if=IS_MACOS),  # 跳过的测试信息，指明跳过 'TestUnaryUfuncs' 下的 'test_reference_numerics_large' 测试，限制条件为在 macOS 下，并且在 CPU 设备上进行，针对 torch.cfloat 和 torch.cdouble 类型
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),  # 跳过的测试信息，指明跳过 'TestSparseUnaryUfuncs' 下的 'test_sparse_fn_grad' 测试
                   )),
    # 定义一个描述一元函数（UnaryUfunc）的信息对象，函数名为'square'
    UnaryUfuncInfo('square',
                   # 参考实现是numpy库中的square函数
                   ref=np.square,
                   # 支持的数据类型包括所有类型、复数类型以及特定的torch类型（bool, float16, bfloat16）
                   dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),
                   # 修饰器包括精度覆盖，针对复数64位浮点数和bfloat16类型的修正
                   decorators=(precisionOverride({torch.complex64: 3e-4, torch.bfloat16: 3e-1}),),
                   # 支持正向自动微分
                   supports_forward_ad=True,
                   # 支持正向与反向梯度的自动微分
                   supports_fwgrad_bwgrad=True,
                   # 跳过以下测试案例
                   skips=(
                       # 引用：https://github.com/pytorch/pytorch/issues/52549
                       # 跳过指定的单元测试，测试名为'TestUnaryUfuncs'，方法名为'test_reference_numerics_large'，数据类型为复数64位浮点数和复数128位双精度浮点数
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=[torch.cfloat, torch.cdouble]),
                       # 跳过指定的单元测试，测试名为'TestUnaryUfuncs'，方法名为'test_reference_numerics_extremal'，设备类型为cuda，数据类型为复数64位浮点数和复数128位双精度浮点数
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    device_type='cuda', dtypes=[torch.cfloat, torch.cdouble]),
                       # 预期该单元测试会失败，测试名为'TestMeta'，方法名为'test_meta_inplace'，数据类型为布尔类型
                       DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_meta_inplace',
                                    dtypes=[torch.bool]),
                       # 预期该单元测试会失败，测试名为'TestMeta'，方法名为'test_dispatch_meta_inplace'，数据类型为布尔类型
                       DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_meta_inplace',
                                    dtypes=[torch.bool]),
                       # 预期该单元测试会失败，测试名为'TestMeta'，方法名为'test_dispatch_symbolic_meta_inplace'，数据类型为布尔类型
                       DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_symbolic_meta_inplace',
                                    dtypes=[torch.bool]),
                   ),),
    
    # 定义一个描述操作（OpInfo）的信息对象，操作名为'lerp'
    OpInfo('lerp',
           # 支持的数据类型包括浮点数和复数类型，以及特定的torch类型（bfloat16, half）
           dtypes=floating_and_complex_types_and(torch.bfloat16, torch.half),
           # 如果在CUDA环境下，支持的数据类型包括浮点数和复数类型，以及特定的torch类型（chalf, half, bfloat16）
           dtypesIfCUDA=floating_and_complex_types_and(torch.chalf, torch.half, torch.bfloat16),
           # 采样输入函数为sample_inputs_lerp
           sample_inputs_func=sample_inputs_lerp,
           # 支持正向自动微分
           supports_forward_ad=True,
           # 支持正向与反向梯度的自动微分
           supports_fwgrad_bwgrad=True,
           # 断言自动微分正确性
           assert_autodiffed=True),
    # 定义一个名为 UnaryUfuncInfo 的类实例，用于描述一元通用函数的信息
    UnaryUfuncInfo(
        'angle',  # 函数名称为 angle
        ref=np.angle,  # 参考实现使用 numpy 库的 angle 函数
        dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),  # 支持的数据类型包括所有标量类型以及复数类型
        dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool),  # 如果在 CUDA 环境下，则还支持半精度浮点数和布尔类型
        decorators=(precisionOverride({torch.float16: 1e-2, torch.bfloat16: 1e-2}),),  # 使用精度覆盖修饰器，设置特定数据类型的精度
        backward_dtypes=floating_and_complex_types_and(torch.bfloat16, torch.float16),  # 支持反向传播的数据类型包括浮点数和复数类型以及半精度浮点数
        backward_dtypesIfCUDA=floating_and_complex_types_and(torch.chalf),  # 在 CUDA 环境下，还支持半精度复数类型
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        supports_sparse_csr=True,  # 支持 CSR 格式的稀疏矩阵
        supports_sparse_csc=True,  # 支持 CSC 格式的稀疏矩阵
        supports_sparse_bsr=True,  # 支持 BSR 格式的稀疏矩阵
        supports_sparse_bsc=True,  # 支持 BSC 格式的稀疏矩阵
        supports_complex_to_float=True,  # 支持复数到浮点数的转换
        skips=(
            # 引用：https://github.com/pytorch/pytorch/issues/78413
            DecorateInfo(
                unittest.expectedFailure,  # 使用 unittest.expectedFailure 装饰器标记测试失败的情况
                'TestUnaryUfuncs',  # 测试类名称为 TestUnaryUfuncs
                'test_reference_numerics_small',  # 测试方法名称为 test_reference_numerics_small
                dtypes=(torch.bfloat16, torch.float16, torch.float32, torch.float64),  # 测试失败的数据类型包括半精度浮点数和标准浮点数
            ),
        ),
    ),
    
    # 定义一个名为 UnaryUfuncInfo 的类实例，用于描述一元通用函数的信息
    UnaryUfuncInfo(
        'isfinite',  # 函数名称为 isfinite
        ref=np.isfinite,  # 参考实现使用 numpy 库的 isfinite 函数
        dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),  # 支持的数据类型包括所有标量类型以及复数类型和半精度浮点数
        supports_out=False,  # 不支持指定输出结果
        supports_autograd=False,  # 不支持自动微分
    ),
    
    # 定义一个名为 UnaryUfuncInfo 的类实例，用于描述一元通用函数的信息
    UnaryUfuncInfo(
        'isinf',  # 函数名称为 isinf
        ref=np.isinf,  # 参考实现使用 numpy 库的 isinf 函数
        dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),  # 支持的数据类型包括所有标量类型以及复数类型和半精度浮点数
        supports_out=False,  # 不支持指定输出结果
        supports_sparse=True,  # 支持稀疏矩阵
        supports_sparse_csr=True,  # 支持 CSR 格式的稀疏矩阵
        supports_sparse_csc=True,  # 支持 CSC 格式的稀疏矩阵
        supports_sparse_bsr=True,  # 支持 BSR 格式的稀疏矩阵
        supports_sparse_bsc=True,  # 支持 BSC 格式的稀疏矩阵
        supports_autograd=False,  # 不支持自动微分
    ),
    
    # 定义一个名为 UnaryUfuncInfo 的类实例，用于描述一元通用函数的信息
    UnaryUfuncInfo(
        'isposinf',  # 函数名称为 isposinf
        ref=np.isposinf,  # 参考实现使用 numpy 库的 isposinf 函数
        dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16),  # 支持的数据类型包括所有标量类型以及半精度浮点数和标准浮点数
        supports_sparse=True,  # 支持稀疏矩阵
        supports_sparse_csr=True,  # 支持 CSR 格式的稀疏矩阵
        supports_sparse_csc=True,  # 支持 CSC 格式的稀疏矩阵
        supports_sparse_bsr=True,  # 支持 BSR 格式的稀疏矩阵
        supports_sparse_bsc=True,  # 支持 BSC 格式的稀疏矩阵
        supports_autograd=False,  # 不支持自动微分
    ),
    
    # 定义一个名为 UnaryUfuncInfo 的类实例，用于描述一元通用函数的信息
    UnaryUfuncInfo(
        'isneginf',  # 函数名称为 isneginf
        ref=np.isneginf,  # 参考实现使用 numpy 库的 isneginf 函数
        dtypes=all_types_and(torch.bool, torch.bfloat16, torch.float16),  # 支持的数据类型包括所有标量类型以及半精度浮点数和标准浮点数
        supports_sparse=True,  # 支持稀疏矩阵
        supports_sparse_csr=True,  # 支持 CSR 格式的稀疏矩阵
        supports_sparse_csc=True,  # 支持 CSC 格式的稀疏矩阵
        supports_sparse_bsr=True,  # 支持 BSR 格式的稀疏矩阵
        supports_sparse_bsc=True,  # 支持 BSC 格式的稀疏矩阵
        supports_autograd=False,  # 不支持自动微分
    ),
    UnaryUfuncInfo('isreal',
                   ref=np.isreal,
                   dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
                   supports_out=False,
                   supports_autograd=False),
    # 定义一元函数信息，用于检查是否为实数
    # 使用 NumPy 的 np.isreal 作为参考实现
    # 支持的数据类型包括所有标准类型和复合类型，但不支持输出
    # 不支持自动求导功能

    UnaryUfuncInfo('isnan',
                   ref=np.isnan,
                   dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),
                   supports_out=False,
                   supports_sparse=True,
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   supports_autograd=False),
    # 定义一元函数信息，用于检查是否为 NaN
    # 使用 NumPy 的 np.isnan 作为参考实现
    # 支持的数据类型包括所有标准类型和复合类型，不支持输出
    # 支持稀疏张量操作，包括 CSR、CSC、BSR、BSC 格式
    # 不支持自动求导功能

    OpInfo('einsum',
           # 我们需要这个 lambda 函数，因为 SampleInput 需要将张量作为第一个参数输入
           # TODO(@heitorschueroff) 更新 SampleInput 以处理这种情况
           op=lambda tensors, equation: torch.einsum(equation, tensors),
           dtypes=all_types_and_complex_and(torch.half, torch.bfloat16),
           dtypesIfCUDA=floating_and_complex_types_and(torch.half, torch.bfloat16),
           backward_dtypesIfCUDA=floating_and_complex_types_and(torch.half, torch.bfloat16),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           check_batched_forward_grad=False,
           # 参见 https://github.com/pytorch/pytorch/issues/66357
           sample_inputs_func=sample_inputs_einsum,
           skips=(
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # 测试在传递 lambda 函数给 op 时不起作用
               # `test_jit.py` 中有一个测试 `test_einsum` 处理这种情况
               # AssertionError: JIT 测试未执行任何逻辑
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),
           )),
    # 定义 einsum 操作的信息
    # 使用 lambda 函数将方程和张量传递给 torch.einsum
    # 支持的数据类型包括半精度和 BF16（BrainFloat16）
    # 如果在 CUDA 上，则支持半精度和 BF16
    # 反向传播在 CUDA 上支持半精度和 BF16
    # 不支持输出
    # 支持前向自动微分
    # 支持前向梯度和后向梯度
    # 不检查批处理的前向梯度
    # 使用 sample_inputs_einsum 函数生成示例输入
    # 跳过以下测试：
    #   - TestNormalizeOperators 的 test_normalize_operator_exhaustive 期望失败
    #   - TestJit 的 test_variant_consistency_jit 被跳过
    OpInfo('svd',  # 创建一个 OpInfo 对象，用于描述 svd 操作的测试信息
           op=torch.svd,  # 指定操作为 torch 库中的 svd 函数
           dtypes=floating_and_complex_types(),  # 设置支持的数据类型为浮点数和复数类型
           sample_inputs_func=sample_inputs_svd,  # 设置样本输入生成函数为 sample_inputs_svd
           # 在 slow-gradcheck 模式下运行速度非常慢，可以通过减少输入大小来加快
           gradcheck_fast_mode=True,
           supports_forward_ad=True,  # 标识支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 标识支持前向-梯度-反向梯度
           check_batched_forward_grad=False,  # 关闭批处理前向梯度检查
           # 使用 at::allclose 进行比较，其没有批处理规则
           check_batched_grad=False,  # 关闭批处理梯度检查
           check_batched_gradgrad=False,  # 关闭批处理梯度-梯度检查
           decorators=[skipCUDAIfNoMagmaAndNoCusolver, skipCPUIfNoLapack, with_tf32_off],  # 添加装饰器列表，用于条件性跳过测试
           skips=(  # 设置跳过的测试用例列表
               # 存在 torch 分发和 conj 的问题，参见 https://github.com/pytorch/pytorch/issues/82479
               DecorateInfo(
                   unittest.skip("Skipped!"),  # 使用 unittest.skip 标记为跳过
                   'TestSchemaCheckModeOpInfo',  # 测试类名
                   'test_schema_correctness',  # 测试方法名
                   dtypes=(torch.complex64, torch.complex128)  # 指定测试的数据类型为复数类型
               ),
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_out',
                            device_type='mps', dtypes=[torch.float32]),  # 跳过的另一个测试用例
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager',
                            device_type='mps', dtypes=[torch.float32]),  # 跳过的另一个测试用例
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit',
                            device_type='mps', dtypes=[torch.float32]),  # 跳过的另一个测试用例
           )),
    OpInfo('svd_lowrank',  # 创建名为 'svd_lowrank' 的运算信息对象
           op=lambda *args, **kwargs: wrapper_set_seed(  # 定义操作函数，设置随机种子并调用 torch.svd_lowrank
               lambda a, b, **kwargs: torch.svd_lowrank(a @ b.mT, **kwargs),  # 对输入进行低秩SVD计算
               *args, **kwargs  # 传递所有位置参数和关键字参数
           ),
           dtypes=floating_and_complex_types(),  # 支持浮点数和复数类型的数据类型
           gradcheck_fast_mode=True,  # 使用快速模式进行梯度检查
           supports_out=False,  # 不支持输出张量
           check_batched_grad=False,  # 不检查批处理梯度
           check_batched_gradgrad=False,  # 不检查批处理二阶梯度
           check_batched_forward_grad=False,  # 不检查批处理前向梯度
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           supports_forward_ad=True,  # 支持自动微分中的前向传播
           sample_inputs_func=sample_inputs_svd_lowrank,  # 使用函数 sample_inputs_svd_lowrank 生成样本输入
           decorators=[  # 装饰器列表
               skipCUDAIfNoCusolver,  # 如果没有 Cusolver 则跳过 CUDA 测试
               skipCPUIfNoLapack,  # 如果没有 Lapack 则跳过 CPU 测试
               with_tf32_off,  # 关闭 TF32 精度优化
               DecorateInfo(  # 装饰信息对象，用于测试非连续样本
                   toleranceOverride({torch.float32: tol(atol=1e-03, rtol=1e-03),  # 设置浮点32位精度的公差
                                      torch.complex64: tol(atol=1e-02, rtol=1e-02)}),  # 设置复数64位精度的公差
                   'TestCommon', 'test_noncontiguous_samples'),  # 对 'TestCommon' 中的 'test_noncontiguous_samples' 进行测试
               # FIXME This should be the following, but the toleranceOverride does not seem to do anything!
               # DecorateInfo(toleranceOverride({torch.complex128: tol(atol=1e-04, rtol=1e-04)}),
               #              'TestFwdGradients', 'test_fn_fwgrad_bwgrad'),
               DecorateInfo(unittest.skip("See comment above"),  # 标记为跳过，查看上面的注释
                            'TestFwdGradients',  # 在 'TestFwdGradients' 中执行测试
                            'test_fn_fwgrad_bwgrad',  # 测试函数 'test_fn_fwgrad_bwgrad'
                            dtypes=[torch.complex128]),  # 仅限于复数128位的数据类型
               DecorateInfo(unittest.skip("See comment above"),  # 标记为跳过，查看上面的注释
                            'TestBwdGradientsCUDA',  # 在 'TestBwdGradientsCUDA' 中执行测试
                            'test_fn_gradgrad',  # 测试函数 'test_fn_gradgrad'
                            dtypes=[torch.complex128]),  # 仅限于复数128位的数据类型
           ],
           skips=(  # 跳过的测试列表
               DecorateInfo(unittest.expectedFailure,  # 标记为预期失败的测试
                            "TestNormalizeOperators",  # 在 'TestNormalizeOperators' 中执行测试
                            "test_normalize_operator_exhaustive"),  # 测试函数 'test_normalize_operator_exhaustive'
               DecorateInfo(unittest.expectedFailure,  # 标记为预期失败的测试
                            'TestJit',  # 在 'TestJit' 中执行测试
                            'test_variant_consistency_jit'),  # 测试函数 'test_variant_consistency_jit'
               DecorateInfo(unittest.skip('output is non-deterministic'),  # 标记为跳过，输出是不确定性的
                            'TestCommon',  # 在 'TestCommon' 中执行测试
                            'test_compare_cpu'),  # 测试函数 'test_compare_cpu'
               # Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479
               DecorateInfo(unittest.expectedFailure,  # 标记为预期失败的测试
                            'TestSchemaCheckModeOpInfo',  # 在 'TestSchemaCheckModeOpInfo' 中执行测试
                            'test_schema_correctness',  # 测试函数 'test_schema_correctness'
                            dtypes=(torch.complex64, torch.complex128)),  # 仅限于复数64位和128位的数据类型
               DecorateInfo(slowTest,  # 标记为慢速测试
                            'TestCompositeCompliance',  # 在 'TestCompositeCompliance' 中执行测试
                            'test_forward_ad'),  # 测试函数 'test_forward_ad'
           )),
    OpInfo('pca_lowrank',  # 创建一个名为 'pca_lowrank' 的操作信息对象
           op=lambda *args, **kwargs: wrapper_set_seed(  # 定义一个操作函数，设置了随机种子
               lambda a, b, **kwargs: torch.pca_lowrank(a @ b.mT, **kwargs),  # 内部调用 torch.pca_lowrank 函数
               *args, **kwargs  # 将所有参数和关键字参数传递给内部函数
           ),
           dtypes=floating_and_complex_types(),  # 操作支持的数据类型
           gradcheck_fast_mode=True,  # 使用快速模式进行梯度检查
           supports_out=False,  # 操作不支持输出张量
           check_batched_forward_grad=False,  # 不检查批处理前向传播的梯度
           check_batched_grad=False,  # 不检查批处理梯度
           check_batched_gradgrad=False,  # 不检查批处理梯度的梯度
           supports_forward_ad=True,  # 操作支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 操作支持前向梯度和反向梯度
           sample_inputs_func=sample_inputs_pca_lowrank,  # 提供用于测试的样本输入函数
           decorators=[  # 装饰器列表开始
               skipCUDAIfNoCusolver,  # 如果没有 CUSOLVER，则跳过 CUDA 测试
               skipCPUIfNoLapack,  # 如果没有 LAPACK，则跳过 CPU 测试
               with_tf32_off,  # 关闭 TF32 模式进行测试
               DecorateInfo(  # 创建装饰信息对象
                   toleranceOverride({torch.float32: tol(atol=1e-03, rtol=1e-03),  # 覆盖浮点数的容差
                                      torch.complex64: tol(atol=4e-02, rtol=4e-02)}),  # 覆盖复数的容差
                   'TestCommon', 'test_noncontiguous_samples'  # 指定装饰的测试类和方法
               ),
               DecorateInfo(unittest.skip("See comment above"),  # 跳过测试，显示上面的注释信息
                            'TestFwdGradients',  # 指定测试类
                            'test_fn_fwgrad_bwgrad',  # 指定测试方法
                            dtypes=[torch.complex128]  # 指定支持的数据类型
                            ),
               # FIXME This should be the following, but the toleranceOverride does not seem to do anything!
               # DecorateInfo(toleranceOverride({torch.complex128: tol(atol=1e-04, rtol=1e-04)}),
               #              'TestFwdGradients', 'test_fn_fwgrad_bwgrad'),
               DecorateInfo(unittest.skip("See comment above"),  # 跳过测试，显示上面的注释信息
                            'TestFwdGradients',  # 指定测试类
                            'test_fn_fwgrad_bwgrad',  # 指定测试方法
                            dtypes=[torch.complex128]  # 指定支持的数据类型
                            ),
               DecorateInfo(unittest.expectedFailure,  # 预期的测试失败
                            "TestNormalizeOperators",  # 指定测试类
                            "test_normalize_operator_exhaustive"  # 指定测试方法
                            ),
               DecorateInfo(unittest.expectedFailure,  # 预期的测试失败
                            'TestJit',  # 指定测试类
                            'test_variant_consistency_jit'  # 指定测试方法
                            ),
               DecorateInfo(unittest.expectedFailure,  # 预期的测试失败
                            'TestSchemaCheckModeOpInfo',  # 指定测试类
                            'test_schema_correctness',  # 指定测试方法
                            dtypes=(torch.complex64, torch.complex128)  # 指定支持的数据类型
                            ),
               DecorateInfo(unittest.skip('output is non-deterministic'),  # 跳过测试，输出是非确定性的
                            'TestCommon',  # 指定测试类
                            'test_compare_cpu'  # 指定测试方法
                            ),
           ],  # 装饰器列表结束
           skips=(  # 跳过的测试元组开始
               DecorateInfo(unittest.expectedFailure,  # 预期的测试失败
                            "TestNormalizeOperators",  # 指定测试类
                            "test_normalize_operator_exhaustive"  # 指定测试方法
                            ),
               DecorateInfo(unittest.expectedFailure,  # 预期的测试失败
                            'TestJit',  # 指定测试类
                            'test_variant_consistency_jit'  # 指定测试方法
                            ),
               DecorateInfo(unittest.expectedFailure,  # 预期的测试失败
                            'TestSchemaCheckModeOpInfo',  # 指定测试类
                            'test_schema_correctness',  # 指定测试方法
                            dtypes=(torch.complex64, torch.complex128)  # 指定支持的数据类型
                            ),
               DecorateInfo(unittest.skip('output is non-deterministic'),  # 跳过测试，输出是非确定性的
                            'TestCommon',  # 指定测试类
                            'test_compare_cpu'  # 指定测试方法
                            ),
           ),  # 跳过的测试元组结束
    ),
    # 定义一个 BinaryUfuncInfo 对象，描述一个二元通用函数的信息
    BinaryUfuncInfo('polar',
                    dtypes=floating_types(),
                    # 当 'abs' 值小于 0 时，该函数未定义
                    supports_forward_ad=True,
                    lhs_make_tensor_kwargs=dict(low=0),
                    supports_rhs_python_scalar=False,
                    skips=(
                        # 由于类型不匹配，跳过测试用例
                        DecorateInfo(unittest.skip('Skipped!'), 'TestBinaryUfuncs', 'test_type_promotion'),
                        DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_binary_ufuncs_mixed_dtype'),
                        # 梯度检查失败，前向模式计算的雅可比矩阵与反向模式不匹配
                        # 数值计算和分析计算的不匹配信息
                        DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', 'test_fn_fwgrad_bwgrad'),
                    )),
    # TODO(@kshitij12345): 重构成类似 `mvlgamma` 条目的形式
    # 用于对多个参数 `n` 的多个值进行参考数值测试，
    # 每个 OpInfo 条目对应不同的 `n` 值（目前为 0 到 4）
    # 我们仅对 `n=0` 运行 test_ops.py 中的操作测试，以避免测试的冗余
    UnaryUfuncInfo('polygamma',
                   op=lambda x, n, **kwargs: torch.polygamma(n, x, **kwargs),
                   variant_test_name='polygamma_n_0',
                   ref=reference_polygamma if TEST_SCIPY else None,
                   dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   dtypesIfCUDA=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   promotes_int_to_float=True,
                   sample_inputs_func=sample_inputs_polygamma,
                   skips=(
                       # 预期失败的测试用例，测试归一化运算符的详尽性
                       DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
                   ),
                   sample_kwargs=lambda device, dtype, input: ({'n': 0}, {'n': 0}),
                   # polygamma 函数在 x 为非正整数值时具有多个奇点
                   reference_numerics_filter=NumericsFilter(condition=lambda x: (x < 0.1) & ((x - x.round()).abs() < 1e-4),
                                                            safe_val=1)),
    # 对于每个 n_ 值在 (1, 2, 3, 4) 上，定义了 polygamma 函数的测试信息
    *(UnaryUfuncInfo('polygamma',
                     # 定义了操作 op，调用 torch.polygamma(n, x) 函数
                     op=lambda x, n, **kwargs: torch.polygamma(n, x, **kwargs),
                     # 测试变体名称，包含 n_ 的值作为一部分
                     variant_test_name=f'polygamma_n_{n_}',
                     # 如果 TEST_SCIPY 为真，参考值使用 reference_polygamma，否则为 None
                     ref=reference_polygamma if TEST_SCIPY else None,
                     # 支持的数据类型为所有类型加上 torch.bool 和 torch.bfloat16
                     dtypes=all_types_and(torch.bool, torch.bfloat16),
                     # 如果在 CUDA 上，还支持 torch.half 和 torch.bfloat16 类型
                     dtypesIfCUDA=all_types_and(torch.bool, torch.half, torch.bfloat16),
                     # 支持前向自动微分
                     supports_forward_ad=True,
                     # 支持前向和后向梯度计算
                     supports_fwgrad_bwgrad=True,
                     # 可以将整数推广为浮点数进行计算
                     promotes_int_to_float=True,
                     # 获取输入样本的函数为 sample_inputs_polygamma
                     sample_inputs_func=sample_inputs_polygamma,
                     # 装饰器信息，设置不同数据类型的容差值
                     decorators=(
                         DecorateInfo(toleranceOverride({torch.float32: tol(atol=1e-4, rtol=1e-3)}), 'TestUnaryUfuncs'),
                         DecorateInfo(toleranceOverride({torch.bfloat16: tol(atol=1e1, rtol=1e-1),
                                                         torch.float32: tol(atol=1e-4, rtol=1e-2)}),
                                      'TestUnaryUfuncs', 'test_reference_numerics_normal',
                                      active_if=IS_WINDOWS),
                     ),
                     # 跳过的测试用例信息
                     skips=(
                         # 跳过冗余的测试
                         DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients'),
                         DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients'),
                         DecorateInfo(unittest.skip("Skipped!"), 'TestJit'),
                         DecorateInfo(unittest.skip("Skipped!"), 'TestNormalizeOperators'),
                         DecorateInfo(unittest.skip("Skipped!"), 'TestCommon'),
                         # 不匹配的测试，具体原因是 issue https://github.com/pytorch/pytorch/issues/55357
                         DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal'),
                         DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large'),
                     ),
                     # 生成输入样本的关键字参数函数
                     sample_kwargs=lambda device, dtype, input: ({'n': n_}, {'n': n_}),
                     # polygamma 函数在 x 为非正整数值时有多个奇点
                     reference_numerics_filter=NumericsFilter(condition=lambda x: (x < 0.1) & ((x - x.round()).abs() < 1e-4),
                                                              safe_val=1))
      for n_ in (1, 2, 3, 4)),
    # OpInfo 对象，描述了 ravel 操作的测试信息
    OpInfo('ravel',
           # 参考实现为 numpy 中的 np.ravel 函数
           ref=np.ravel,
           # 支持的数据类型包括所有类型、复数类型以及 torch.bool、torch.float16、torch.bfloat16、torch.chalf
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           # 不支持输出参数 out
           supports_out=False,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和后向梯度计算
           supports_fwgrad_bwgrad=True,
           # 参考 https://github.com/pytorch/pytorch/pull/78358
           # 检查批处理前向梯度设置为 False
           check_batched_forward_grad=False,
           # 获取输入样本的函数为 sample_inputs_ravel
           sample_inputs_func=sample_inputs_ravel,
           ),
    OpInfo('unravel_index',  # 定义操作名称为 'unravel_index'
           ref=np.unravel_index,  # 引用 numpy 中的 unravel_index 函数
           dtypes=integral_types_and(),  # 支持的数据类型为整数类型
           supports_out=False,  # 不支持输出参数
           supports_autograd=False,  # 不支持自动求导
           sample_inputs_func=sample_inputs_unravel_index,  # 用于生成示例输入的函数
           ),
    OpInfo('reshape',  # 定义操作名称为 'reshape'
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 支持的数据类型为所有类型，包括复杂类型和特定的 PyTorch 类型
           sample_inputs_func=sample_inputs_view_reshape,  # 用于生成示例输入的函数
           reference_inputs_func=reference_inputs_view_reshape,  # 用于生成参考输入的函数
           error_inputs_func=error_inputs_view_reshape,  # 用于生成错误输入的函数
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和反向梯度
           ),
    OpInfo('reshape_as',  # 定义操作名称为 'reshape_as'
           op=lambda x, other: x.reshape_as(other),  # 操作为将 x 按照 other 的形状进行 reshape
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 支持的数据类型同上
           sample_inputs_func=partial(sample_inputs_view_reshape, tensor_arg=True),  # 用于生成示例输入的函数，针对张量参数
           reference_inputs_func=partial(reference_inputs_view_reshape, tensor_arg=True),  # 用于生成参考输入的函数，针对张量参数
           error_inputs_func=partial(error_inputs_view_reshape, tensor_arg=True),  # 用于生成错误输入的函数，针对张量参数
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和反向梯度
           skips=(  # 跳过以下测试
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 标记为预期失败的测试
           )),
    OpInfo('view',  # 定义操作名称为 'view'
           op=lambda x, shape: x.view(shape),  # 操作为将 x 按照给定形状 shape 进行 view
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型为所有类型，包括复杂类型和特定的 PyTorch 类型
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和反向梯度
           assert_jit_shape_analysis=True,  # 断言 JIT 形状分析为真
           sample_inputs_func=sample_inputs_view_reshape,  # 用于生成示例输入的函数
           reference_inputs_func=reference_inputs_view_reshape,  # 用于生成参考输入的函数
           error_inputs_func=error_inputs_view_reshape,  # 用于生成错误输入的函数
           skips=(  # 跳过以下测试
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 标记为预期失败的测试
               # 下面是注释，解释为什么要跳过这个测试
               # RuntimeError: view size is not compatible with input tensor's size and stride
               # (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
               DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides"),
           )),
    # 定义一个操作信息对象，名称为 'view_as'
    OpInfo('view_as',
           # 定义操作的函数，使用 lambda 表达式调用 x 的 view_as 方法，传入 other 参数
           op=lambda x, other: x.view_as(other),
           # 操作支持的数据类型，包括所有类型以及复杂类型和指定的数据类型
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),
           # 是否支持输出参数（out 参数）
           supports_out=False,
           # 是否支持前向自动微分（AD）
           supports_forward_ad=True,
           # 是否支持前向-反向梯度传播
           supports_fwgrad_bwgrad=True,
           # 提供样本输入的函数，使用 partial 函数预先填充 tensor_arg 参数
           sample_inputs_func=partial(sample_inputs_view_reshape, tensor_arg=True),
           # 提供参考输入的函数，使用 partial 函数预先填充 tensor_arg 参数
           reference_inputs_func=partial(reference_inputs_view_reshape, tensor_arg=True),
           # 提供错误输入的函数，使用 partial 函数预先填充 tensor_arg 参数
           error_inputs_func=partial(error_inputs_view_reshape, tensor_arg=True),
           # 跳过某些测试用例的信息，包括预期的失败信息和相关的错误描述
           skips=(
               # 标记为预期失败的装饰器信息，测试名为 "TestNormalizeOperators"，测试方法为 "test_normalize_operator_exhaustive"
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # 运行时错误信息：视图大小与输入张量的大小和步幅不兼容
               # 在 "TestMeta" 测试中，方法为 "test_dispatch_symbolic_meta_outplace_all_strides"
               DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides")
           )),

    # 定义一个操作信息对象，名称为 'atleast_1d'
    OpInfo('atleast_1d',
           # 操作支持的数据类型，包括所有类型以及复杂类型和指定的数据类型
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),
           # 在慢速 gradcheck 上运行非常慢 - 可以减少输入大小作为替代
           gradcheck_fast_mode=True,
           # 是否支持输出参数（out 参数）
           supports_out=False,
           # 是否支持前向自动微分（AD）
           supports_forward_ad=True,
           # 是否支持前向-反向梯度传播
           supports_fwgrad_bwgrad=True,
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           # 关闭批处理前向梯度检查
           check_batched_forward_grad=False,
           # 提供样本输入的函数，使用 sample_inputs_atleast1d2d3d 函数
           sample_inputs_func=sample_inputs_atleast1d2d3d,
           # 跳过某些测试用例的信息，包括预期的失败信息和相关的错误描述
           skips=(
               # JIT 不支持可变张量。
               # 运行时错误信息：input->type()->kind() == TypeKind::OptionalType
               # 在 "TestNormalizeOperators" 测试中，方法为 "test_normalize_operator_exhaustive"
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # 在 'TestJit' 测试中，方法为 'test_variant_consistency_jit'，数据类型为 [torch.float32]
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=[torch.float32]),
           ),
           ),

    # 定义一个操作信息对象，名称为 'atleast_2d'
    OpInfo('atleast_2d',
           # 操作支持的数据类型，包括所有类型以及复杂类型和指定的数据类型
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),
           # 在慢速 gradcheck 上运行非常慢 - 可以减少输入大小作为替代
           gradcheck_fast_mode=True,
           # 是否支持输出参数（out 参数）
           supports_out=False,
           # 是否支持前向自动微分（AD）
           supports_forward_ad=True,
           # 是否支持前向-反向梯度传播
           supports_fwgrad_bwgrad=True,
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           # 关闭批处理前向梯度检查
           check_batched_forward_grad=False,
           # 跳过某些测试用例的信息，包括预期的失败信息和相关的错误描述
           skips=(
               # 标记为预期失败的装饰器信息，在 "TestNormalizeOperators" 测试中，方法为 "test_normalize_operator_exhaustive"
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # 在 'TestJit' 测试中，方法为 'test_variant_consistency_jit'，数据类型为 [torch.float32]
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=[torch.float32]),
           ),
           # 提供样本输入的函数，使用 sample_inputs_atleast1d2d3d 函数
           sample_inputs_func=sample_inputs_atleast1d2d3d,
           ),
    OpInfo('atleast_3d',
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),
           # 在慢速梯度检查上运行非常缓慢 - 或者减少输入大小作为替代
           gradcheck_fast_mode=True,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,
           skips=(
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit', dtypes=[torch.float32]),
           ),
           sample_inputs_func=sample_inputs_atleast1d2d3d,
           ),

    OpInfo('flatten',
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           ref=reference_flatten,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,
           sample_inputs_func=sample_inputs_flatten,
           reference_inputs_func=reference_inputs_flatten,
           ),

    OpInfo('unflatten',
           op=torch.unflatten,
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           sample_inputs_func=sample_inputs_unflatten,
           ),

    OpInfo('column_stack',
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,
           sample_inputs_func=sample_inputs_column_stack,
           ),

    OpInfo('pinverse',
           op=torch.pinverse,
           dtypes=floating_and_complex_types(),
           check_batched_grad=False,
           check_batched_gradgrad=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           supports_out=False,
           sample_inputs_func=sample_inputs_linalg_invertible,
           decorators=[skipCUDAIfNoMagmaAndNoCusolver, skipCPUIfNoLapack],
           skips=(
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager',
                            device_type='mps', dtypes=[torch.float32]),
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit',
                            device_type='mps', dtypes=[torch.float32]),
           )),
    OpInfo('gather',
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),
           dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),
           sample_inputs_func=sample_inputs_gather,
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           error_inputs_func=error_inputs_gather,
           ),


    # 定义操作信息为 gather
    # 定义支持的数据类型为所有类型，并包括 torch.bool, torch.float16, torch.bfloat16
    # 如果是在 CUDA 下，支持的数据类型同上
    # 指定用于生成示例输入的函数为 sample_inputs_gather
    # 设置梯度检查的非确定性容忍度为 GRADCHECK_NONDET_TOL
    # 支持前向自动微分
    # 支持前向梯度后向梯度
    # 指定用于生成错误输入的函数为 error_inputs_gather



    OpInfo('index_fill',
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.complex32),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,
           skips=(
               # RuntimeError: Mismatch on aten._unique.default: Shapes torch.Size([2]) and torch.Size([1]) are not equal!
               DecorateInfo(unittest.expectedFailure, 'TestFakeTensor', 'test_fake_crossref_backward_no_amp'),
               # RuntimeError: Mismatch on aten._unique.default: Shapes torch.Size([2]) and torch.Size([1]) are not equal!
               DecorateInfo(unittest.expectedFailure, 'TestFakeTensor', 'test_fake_crossref_backward_amp'),
           ),
           sample_inputs_func=sample_inputs_index,
           reference_inputs_func=partial(sample_inputs_index, reference=True)),


    # 定义操作信息为 index_fill
    # 定义支持的数据类型为所有类型，并包括 torch.bool, torch.float16, torch.bfloat16, torch.complex32
    # 不支持输出参数（supports_out=False）
    # 支持前向自动微分
    # 支持前向梯度后向梯度
    # 关闭批处理前向梯度检查，因为存在已知问题 https://github.com/pytorch/pytorch/issues/66357
    # 跳过以下测试用例：
    #   - 在 'TestFakeTensor' 的 'test_fake_crossref_backward_no_amp' 中，期望出现 RuntimeError，因为形状不匹配
    #   - 在 'TestFakeTensor' 的 'test_fake_crossref_backward_amp' 中，期望出现 RuntimeError，因为形状不匹配
    # 指定用于生成示例输入的函数为 sample_inputs_index
    # 指定用于生成参考输入的函数为 sample_inputs_index 的部分应用（reference=True）



    OpInfo('index_copy',
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.complex32),
           supports_out=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,
           sample_inputs_func=sample_inputs_index,
           reference_inputs_func=partial(sample_inputs_index, reference=True),
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL),


    # 定义操作信息为 index_copy
    # 定义支持的数据类型为所有类型，并包括 torch.bool, torch.float16, torch.bfloat16, torch.complex32
    # 支持输出参数（supports_out=True）
    # 支持前向自动微分
    # 支持前向梯度后向梯度
    # 关闭批处理前向梯度检查，因为存在已知问题 https://github.com/pytorch/pytorch/issues/66357
    # 指定用于生成示例输入的函数为 sample_inputs_index
    # 指定用于生成参考输入的函数为 sample_inputs_index 的部分应用（reference=True）
    # 设置梯度检查的非确定性容忍度为 GRADCHECK_NONDET_TOL



    OpInfo('index_select',
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           backward_dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16, torch.chalf),
           sample_inputs_func=sample_inputs_index,
           reference_inputs_func=partial(sample_inputs_index, reference=True),
           error_inputs_func=error_inputs_index_select,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           assert_jit_shape_analysis=True,
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL),


    # 定义操作信息为 index_select
    # 定义支持的数据类型为所有类型，并包括 torch.bool, torch.float16, torch.bfloat16, torch.chalf
    # 如果在 CUDA 下，支持的反向数据类型包括浮点数和复数类型，并且包括 torch.float16, torch.bfloat16, torch.chalf
    # 指定用于生成示例输入的函数为 sample_inputs_index
    # 指定用于生成参考输入的函数为 sample_inputs_index 的部分应用（reference=True）
    # 指定用于生成错误输入的函数为 error_inputs_index_select
    # 支持前向自动微分
    # 支持前向梯度后向梯度
    # 断言 JIT 形状分析为真
    # 设置梯度检查的非确定性容忍度为 GRADCHECK_NONDET_TOL
    # 创建 OpInfo 对象，指定操作为 'index_add'
    OpInfo('index_add',
           # 指定支持的数据类型，包括所有类型和特定类型
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           # 支持输出张量
           supports_out=True,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向-后向梯度计算
           supports_fwgrad_bwgrad=True,
           # 禁用批处理的前向梯度检查，参考 GitHub 问题链接
           check_batched_forward_grad=False,
           # 指定用于生成示例输入的函数
           sample_inputs_func=sample_inputs_index,
           # 指定用于生成参考输入的函数，部分应用于 sample_inputs_index
           reference_inputs_func=partial(sample_inputs_index, reference=True),
           # 指定用于生成错误输入的函数
           error_inputs_func=error_inputs_index_add,
           # 标记跳过的测试用例，包括详细说明
           skips=(
               # 对于布尔型 alpha，未正确处理的装饰信息
               DecorateInfo(unittest.expectedFailure,
                            'TestNNCOpInfo',
                            'test_nnc_correctness',
                            dtypes=(torch.bool,)),
           ),
           # 梯度检查中的非确定性容差
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL),
    # 为多个不同的 'index_reduce' 操作创建 OpInfo 对象
    *(OpInfo('index_reduce',
             # 设置测试变体的名称，如缩减类型
             variant_test_name=reduction_type,
             # 指定支持的数据类型，包括所有类型和特定类型
             dtypes=all_types_and(torch.float16, torch.bfloat16),
             # 标记跳过的测试用例，包括详细说明
             skips=(
                 # 装饰信息，用于测试代码覆盖性
                 DecorateInfo(toleranceOverride({torch.float16: tol(atol=2e-3, rtol=3e-3)}),
                              'TestInductorOpInfo', 'test_comprehensive'),
             ),
             # 支持输出张量
             supports_out=True,
             # 指定用于生成示例输入的函数
             sample_inputs_func=sample_inputs_index_reduce,
             ) for reduction_type in ('mean', 'prod', 'amin', 'amax')),
    # 创建 OpInfo 对象，指定操作为 '_unsafe_masked_index'
    OpInfo('_unsafe_masked_index',
           # 指定支持的数据类型，包括所有类型和特定类型
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16, torch.bool),
           # 不支持输出张量
           supports_out=False,
           # 不支持就地自动微分
           supports_inplace_autograd=False,
           # 不支持脚本化
           supports_scripting=False,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向-后向梯度计算
           supports_fwgrad_bwgrad=True,
           # 指定用于生成示例输入的函数
           sample_inputs_func=sample_inputs__unsafe_masked_index),
    # 创建 OpInfo 对象，指定操作为 '_unsafe_masked_index_put_accumulate'
    OpInfo('_unsafe_masked_index_put_accumulate',
           # 指定支持的数据类型，包括所有类型和特定类型
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16, torch.bool),
           # 不支持输出张量
           supports_out=False,
           # 不支持就地自动微分
           supports_inplace_autograd=False,
           # 不支持脚本化
           supports_scripting=False,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向-后向梯度计算
           supports_fwgrad_bwgrad=True,
           # 指定用于生成示例输入的函数
           sample_inputs_func=sample_inputs__unsafe_masked_index_put_accumulate),
    OpInfo('__getitem__',
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           # 在慢速 gradcheck 上运行非常缓慢 - 可以减小输入大小作为替代方案
           gradcheck_fast_mode=True,
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           supports_inplace_autograd=False,
           supports_scripting=False,
           op=torch.Tensor.__getitem__,
           skips=(
               # 标记为预期失败的装饰器信息
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # AssertionError: False is not true : Scalars failed to compare as equal! 0 != 104448
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit', device_type='cuda'),),
           sample_inputs_func=sample_inputs_getitem),

    OpInfo('index_put',
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           supports_out=False,
           supports_inplace_autograd=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # https://github.com/pytorch/pytorch/issues/66357
           # 关闭批次化前向梯度检查
           check_batched_forward_grad=False,
           test_neg_view=False,
           sample_inputs_func=sample_inputs_index_put,
           skips=(
               # 被跳过的装饰器信息
               DecorateInfo(unittest.skip("Skipped"), 'TestBwdGradients', 'test_fn_grad', dtypes=[torch.float64],
                            device_type='cuda', active_if=(TEST_WITH_ROCM and TEST_WITH_TORCHINDUCTOR)),
           )),

    OpInfo('sort',
           dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),
           dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),
           sample_inputs_func=sample_inputs_sort,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           skips=(
               # 空的跳过装饰器信息
           )),

    OpInfo('unique',
           dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16, torch.uint16, torch.uint32, torch.uint64),
           dtypesIfCUDA=all_types_and(torch.bool, torch.float16, torch.uint16, torch.uint32, torch.uint64),
           sample_inputs_func=sample_inputs_unique,
           supports_out=False,
           supports_autograd=False,
           skips=(
               # lambda 实现
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               DecorateInfo(unittest.skip('Output order is undefined when sorted=False'), 'TestCommon', 'test_compare_cpu'),
           )),
    OpInfo('unique_consecutive',  # 创建一个名为 'unique_consecutive' 的操作信息对象
           dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型，包括布尔型、半精度浮点型和bfloat16
           dtypesIfCUDA=all_types_and(torch.bool, torch.float16),  # 在CUDA环境下支持的数据类型
           sample_inputs_func=sample_inputs_unique_consecutive,  # 用于生成样本输入的函数
           supports_out=False,  # 不支持输出
           supports_autograd=False,  # 不支持自动求导
           skips=(  # 被跳过的测试用例列表
               # lambda impl
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期测试失败的装饰器信息
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期测试失败的装饰器信息
           )),
    OpInfo('put',  # 创建一个名为 'put' 的操作信息对象
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型，包括复杂类型、布尔型、半精度浮点型和bfloat16
           supports_out=False,  # 不支持输出
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           check_batched_forward_grad=False,  # 检查批处理的前向梯度，但不支持
           check_batched_gradgrad=False,  # 检查批处理的梯度二阶导数，但不支持，vmap complains of the sizes
           sample_inputs_func=sample_inputs_put),  # 用于生成样本输入的函数
    OpInfo('take',  # 创建一个名为 'take' 的操作信息对象
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型，包括复杂类型、布尔型、半精度浮点型和bfloat16
           check_batched_grad=False,  # 检查批处理的梯度，但不支持，vmap complains of the sizes
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           sample_inputs_func=sample_inputs_take,  # 用于生成样本输入的函数
           error_inputs_func=error_inputs_take),  # 用于生成错误输入的函数
    OpInfo('scatter',  # 创建一个名为 'scatter' 的操作信息对象
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型，包括复杂类型、布尔型、半精度浮点型和bfloat16
           supports_forward_ad=True,  # 支持前向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
           sample_inputs_func=sample_inputs_scatter,  # 用于生成样本输入的函数
           error_inputs_func=error_inputs_scatter_and_scatter_add),  # 用于生成错误输入的函数
    UnaryUfuncInfo(  # 创建一个名为 'UnaryUfuncInfo' 的一元函数信息对象
        'bfloat16',  # 函数名称为 'bfloat16'
        op=lambda x, *args, **kwargs: x.bfloat16(*args, **kwargs),  # 函数操作，将输入 x 转换为 bfloat16 类型
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型，包括复杂类型、布尔型、半精度浮点型、bfloat16和chalf
        supports_out=False,  # 不支持输出
        sample_inputs_func=sample_inputs_conversion,  # 用于生成样本输入的函数
        skips=(  # 被跳过的测试用例列表
            # autograd tests don't handle operators that change dtype
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients'),  # 预期测试失败的装饰器信息
            DecorateInfo(unittest.expectedFailure, 'TestBwdGradients'),  # 预期测试失败的装饰器信息
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期测试失败的装饰器信息
            # RuntimeError: attribute lookup is not defined on builtin
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期测试失败的装饰器信息
            DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo', 'test_nnc_correctness'),  # 跳过的测试信息
        )),
    UnaryUfuncInfo(
        'bool',  # 指定操作为布尔类型
        op=lambda x, *args, **kwargs: x.bool(*args, **kwargs),  # 定义操作函数为 x.bool(*args, **kwargs)
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型列表
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_conversion,  # 用于生成样本输入的函数
        supports_autograd=False,  # 不支持自动求导
        skips=(  # 跳过的测试用例信息
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期失败的测试用例信息
            # RuntimeError: attributis not defined on builtin
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例信息
        )),
    UnaryUfuncInfo(
        'byte',  # 指定操作为字节类型
        op=lambda x, *args, **kwargs: x.byte(*args, **kwargs),  # 定义操作函数为 x.byte(*args, **kwargs)
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型列表
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_conversion,  # 用于生成样本输入的函数
        # The autograd test runner cannot handle functions that change dtype
        supports_autograd=False,  # 不支持自动求导
        skips=(  # 跳过的测试用例信息
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期失败的测试用例信息
            # RuntimeError: attribute lookup is not defined on builtin
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例信息
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),  # 跳过的测试用例信息
        )),
    UnaryUfuncInfo(
        'char',  # 指定操作为字符类型
        op=lambda x, *args, **kwargs: x.char(*args, **kwargs),  # 定义操作函数为 x.char(*args, **kwargs)
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型列表
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_conversion,  # 用于生成样本输入的函数
        # The autograd test runner cannot handle functions that change dtype
        supports_autograd=False,  # 不支持自动求导
        skips=(  # 跳过的测试用例信息
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期失败的测试用例信息
            # RuntimeError: attribute lookup is not defined on builtin
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例信息
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),  # 跳过的测试用例信息
        )),
    UnaryUfuncInfo(
        'double',  # 指定操作为双精度浮点数类型
        op=lambda x, *args, **kwargs: x.double(*args, **kwargs),  # 定义操作函数为 x.double(*args, **kwargs)
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型列表
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_conversion,  # 用于生成样本输入的函数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
        skips=(  # 跳过的测试用例信息
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期失败的测试用例信息
            # RuntimeError: attribute lookup is not defined on builtin
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例信息
        )),
    # 定义一个名为 UnaryUfuncInfo 的类实例，表示一元函数的信息
    UnaryUfuncInfo(
        # 指定操作类型为 'float'
        'float',
        # 使用 lambda 表达式定义操作，调用 x 对象的 float 方法
        op=lambda x, *args, **kwargs: x.float(*args, **kwargs),
        # 指定支持的数据类型，包括所有类型以及复杂类型，但不包括 torch.bool、torch.half、torch.bfloat16、torch.chalf
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
        # 不支持输出参数
        supports_out=False,
        # 指定生成样本输入的函数为 sample_inputs_conversion
        sample_inputs_func=sample_inputs_conversion,
        # 定义跳过的测试用例，这些用例中的操作符会导致错误或失败
        skips=(
            # autograd 测试不处理改变 dtype 的操作符
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients'),
            DecorateInfo(unittest.expectedFailure, 'TestBwdGradients'),
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
            # 在内建类型上查找属性时会出现 RuntimeError
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
        )),
    # 定义另一个 UnaryUfuncInfo 类实例，表示操作类型为 'half'
    UnaryUfuncInfo(
        'half',
        # 使用 lambda 表达式定义操作，调用 x 对象的 half 方法
        op=lambda x, *args, **kwargs: x.half(*args, **kwargs),
        # 指定支持的数据类型，包括所有类型以及复杂类型，但不包括 torch.bool、torch.half、torch.bfloat16
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
        # 不支持输出参数
        supports_out=False,
        # 指定生成样本输入的函数为 sample_inputs_conversion
        sample_inputs_func=sample_inputs_conversion,
        # 支持 autograd 测试
        supports_autograd=True,
        # 定义跳过的测试用例，这些用例中的操作符会导致错误或失败
        skips=(
            # autograd 测试不处理改变 dtype 的操作符
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients'),
            DecorateInfo(unittest.expectedFailure, 'TestBwdGradients'),
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
            # 在内建类型上查找属性时会出现 RuntimeError
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
        )),
    # 定义另一个 UnaryUfuncInfo 类实例，表示操作类型为 'int'
    UnaryUfuncInfo(
        'int',
        # 使用 lambda 表达式定义操作，调用 x 对象的 int 方法
        op=lambda x, *args, **kwargs: x.int(*args, **kwargs),
        # 指定支持的数据类型，包括所有类型以及复杂类型，但不包括 torch.bool、torch.half、torch.bfloat16
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
        # 不支持输出参数
        supports_out=False,
        # 指定生成样本输入的函数为 sample_inputs_conversion
        sample_inputs_func=sample_inputs_conversion,
        # 不支持 autograd 测试
        supports_autograd=False,
        # 定义跳过的测试用例，这些用例中的操作符会导致错误或失败
        skips=(
            # 在内建类型上查找属性时会出现 RuntimeError
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            # 定义跳过的测试用例，这些用例中的操作符会导致溢出问题
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),
        )),
    UnaryUfuncInfo(
        'long',  # 定义一个名为 'long' 的一元函数信息对象
        op=lambda x, *args, **kwargs: x.long(*args, **kwargs),  # 操作定义为调用 x 对象的 long 方法
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型列表
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_conversion,  # 获取示例输入的函数
        supports_autograd=False,  # 不支持自动求导
        skips=(  # 跳过的测试用例元组
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期失败的测试用例装饰信息
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例装饰信息
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),  # 跳过的测试用例装饰信息
        )),
    UnaryUfuncInfo(
        'short',  # 定义一个名为 'short' 的一元函数信息对象
        op=lambda x, *args, **kwargs: x.short(*args, **kwargs),  # 操作定义为调用 x 对象的 short 方法
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型列表
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_conversion,  # 获取示例输入的函数
        supports_autograd=False,  # 不支持自动求导
        skips=(  # 跳过的测试用例元组，包含三个 DecorateInfo 对象
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期失败的测试用例装饰信息
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例装饰信息
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),  # 跳过的测试用例装饰信息
        )),
    UnaryUfuncInfo(
        'cdouble',  # 定义一个名为 'cdouble' 的一元函数信息对象
        op=torch.Tensor.cdouble,  # 操作定义为 torch.Tensor 的 cdouble 方法
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型列表
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_conversion,  # 获取示例输入的函数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        skips=(  # 跳过的测试用例元组，包含三个 DecorateInfo 对象
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期失败的测试用例装饰信息
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例装饰信息
            DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo', 'test_nnc_correctness'),  # 跳过的测试用例装饰信息
        )),
    # 创建一个 UnaryUfuncInfo 对象，处理 'cfloat' 数据类型
    UnaryUfuncInfo(
        'cfloat',
        # 操作函数为 torch.Tensor.cfloat
        op=torch.Tensor.cfloat,
        # 支持的数据类型包括所有类型、复数以及指定的 torch 类型
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
        # 不支持输出参数
        supports_out=False,
        # 获取样本输入的函数为 sample_inputs_conversion
        sample_inputs_func=sample_inputs_conversion,
        # 跳过以下测试用例
        skips=(
            # autograd 测试不处理改变 dtype 的操作符
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients'),
            DecorateInfo(unittest.expectedFailure, 'TestBwdGradients'),
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
            # 运行时错误：在内置对象上未定义属性查找
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo', 'test_nnc_correctness'),
        )
    ),
    # 创建一个 UnaryUfuncInfo 对象，处理 'chalf' 数据类型
    UnaryUfuncInfo(
        'chalf',
        # 操作函数为 lambda 表达式，调用 x.chalf(*args, **kwargs)
        op=lambda x, *args, **kwargs: x.chalf(*args, **kwargs),
        # 支持的数据类型包括所有类型、复数以及指定的 torch 类型
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
        # 不支持输出参数
        supports_out=False,
        # 获取样本输入的函数为 sample_inputs_conversion
        sample_inputs_func=sample_inputs_conversion,
        # 跳过以下测试用例
        skips=(
            # autograd 测试不处理改变 dtype 的操作符
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients'),
            DecorateInfo(unittest.expectedFailure, 'TestBwdGradients'),
            # lambda 使用不适用于 test_normalize_operator_exhaustive
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
            # 运行时错误：'ComplexHalf' 上未实现 "sum_cpu"
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager',
                         device_type='cpu'),
            # 类型错误：'int' 对象不可迭代
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            # 运行时错误：'ComplexHalf' 上未实现 "sum_cpu"
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view',
                         device_type='cpu'),
            # 运行时错误：'ComplexHalf' 上未实现 "sum_cpu"
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view',
                         device_type='cpu'),
            # 运行时错误：'ComplexHalf' 上未实现 "sum_cpu" 和 "neg_conj_cuda"
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
        )
    ),
    OpInfo('empty_like',
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
           supports_out=False,
           sample_inputs_func=sample_inputs_like_fns,
           reference_inputs_func=reference_inputs_like_fns,
           supports_autograd=False,
           skips=(
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"),
                            "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_noncontiguous_samples'),
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_conj_view'),
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_view'),
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_conj_view'),
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo', 'test_nnc_correctness'),
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"), 'TestCudaFuserOpInfo'),
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_complex_half_reference_testing'),
               # 由于空张量数据是垃圾数据，很难进行比较。
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_non_standard_bool_values'),
               # 期望输出: empty_like 不可比较
               DecorateInfo(unittest.skip("Expected: empty_like is not comparable"), 'TestCompositeCompliance',
                            'test_operator'),
               # 输出是非确定性的
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
           )),
    # 创建一个 OpInfo 对象，用于描述操作 'zeros_like'
    OpInfo('zeros_like',
           # 操作支持的数据类型，包括所有标准类型和特定的 torch 类型
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
           # 不支持输出张量的情况
           supports_out=False,
           # 获取示例输入的函数
           sample_inputs_func=sample_inputs_like_fns,
           # 不支持自动求导
           supports_autograd=False,
           # 处理稀疏输入错误的函数
           error_inputs_sparse_func=error_inputs_sparse_like_fns,
           # 获取稀疏 COO 格式示例输入的函数
           sample_inputs_sparse_coo_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_coo),
           # 获取稀疏 CSR 格式示例输入的函数
           sample_inputs_sparse_csr_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_csr),
           # 获取稀疏 CSC 格式示例输入的函数
           sample_inputs_sparse_csc_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_csc),
           # 获取稀疏 BSR 格式示例输入的函数
           sample_inputs_sparse_bsr_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_bsr),
           # 获取稀疏 BSC 格式示例输入的函数
           sample_inputs_sparse_bsc_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_bsc),
           # 跳过的特定情况（这里为空）
           skips=(
           )),
    # 创建一个 OpInfo 对象，用于描述操作 'ones_like'
    OpInfo('ones_like',
           # 操作支持的数据类型，包括所有标准类型和特定的 torch 类型
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
           # 不支持输出张量的情况
           supports_out=False,
           # 获取示例输入的函数
           sample_inputs_func=sample_inputs_like_fns,
           # 不支持自动求导
           supports_autograd=False,
           # 跳过的特定情况（这里为空）
           skips=(
           )),
    OpInfo('randn',  # 创建一个 OpInfo 对象，描述随机生成正态分布的操作 'randn'
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16, torch.complex32),  # 指定支持的数据类型为浮点数和复数类型，包括半精度浮点数、bfloat16 和 complex32
           op=lambda *args, **kwargs: wrapper_set_seed(torch.randn, *args, **kwargs),  # 定义操作为使用指定种子生成随机正态分布的封装函数
           supports_out=True,  # 支持输出参数 'out'
           sample_inputs_func=sample_inputs_randn,  # 指定用于生成随机输入样本的函数为 sample_inputs_randn
           supports_autograd=False,  # 不支持自动求导
           skips=(  # 定义一组需要跳过的测试用例
               # 下面是各个具体的 DecorateInfo 对象，每个对象描述一个需要跳过的测试用例
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestCommon", "test_noncontiguous_samples"),  # 跳过需要张量输入的测试用例
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_vmap_exhaustive"),  # 跳过需要张量输入的测试用例
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_op_has_batch_rule"),  # 跳过需要张量输入的测试用例
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out', device_type='cpu'),  # 标记预期失败的测试用例，测试 CPU 下 randn 生成值与输出张量步幅相关
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),  # 标记预期失败的测试用例，测试 randn 在调整输出张量大小时是否警告
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 标记预期失败的测试用例，测试 FX 是否能够正常化操作
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),  # 标记预期失败的测试用例，测试变体一致性（Eager 模式）
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 标记预期失败的测试用例，测试负视图操作
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 标记预期失败的测试用例，测试共轭视图操作
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),  # 标记预期失败的测试用例，测试负共轭视图操作
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 标记预期失败的测试用例，测试变体一致性（JIT 模式）
               DecorateInfo(unittest.expectedFailure, 'TestDecomp', 'test_quick'),  # 标记预期失败的测试用例，测试快速分解
           )),
    OpInfo('randn_like',  # 创建一个 OpInfo 对象，名称为 'randn_like'
           dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16, torch.complex32),  # 指定支持的数据类型列表
           op=lambda inp, *args, **kwargs:  # 定义一个操作函数，接收输入 inp 和其他参数
               wrapper_set_seed(torch.randn_like, inp, *args, **kwargs),  # 调用包装函数 wrapper_set_seed，并传递给它 torch.randn_like 作为操作函数
           supports_out=False,  # 设置不支持输出参数
           sample_inputs_func=sample_inputs_like_fns,  # 指定一个函数用于生成示例输入
           supports_autograd=False,  # 设置不支持自动求导
           error_inputs_sparse_func=error_inputs_sparse_like_fns,  # 指定一个函数用于生成稀疏输入的错误情况
           sample_inputs_sparse_coo_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_coo),  # 指定用于 COO 格式稀疏输入的函数
           sample_inputs_sparse_csr_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_csr),  # 指定用于 CSR 格式稀疏输入的函数
           sample_inputs_sparse_csc_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_csc),  # 指定用于 CSC 格式稀疏输入的函数
           sample_inputs_sparse_bsr_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_bsr),  # 指定用于 BSR 格式稀疏输入的函数
           sample_inputs_sparse_bsc_func=partial(sample_inputs_sparse_like_fns, layout=torch.sparse_bsc),  # 指定用于 BSC 格式稀疏输入的函数
           skips=(  # 设置跳过的测试用例列表
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 标记特定测试用例预期失败
               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 标记特定测试用例预期失败
               DecorateInfo(unittest.skip("Expected: randn_like is not comparable between dtypes"),  # 跳过具有特定原因的测试用例
                            'TestCommon', 'test_complex_half_reference_testing'),
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),  # 跳过具有特定原因的测试用例
           )),
    OpInfo('rand_like',  # 创建一个 OpInfo 对象，名称为 'rand_like'
           dtypes=floating_types_and(torch.half, torch.bfloat16, torch.complex32, torch.complex64, torch.complex128),  # 指定支持的数据类型列表
           op=lambda inp, *args, **kwargs:  # 定义一个操作函数，接收输入 inp 和其他参数
               wrapper_set_seed(torch.randn_like, inp, *args, **kwargs),  # 调用包装函数 wrapper_set_seed，并传递给它 torch.randn_like 作为操作函数
           supports_out=False,  # 设置不支持输出参数
           sample_inputs_func=sample_inputs_like_fns,  # 指定一个函数用于生成示例输入
           supports_autograd=False,  # 设置不支持自动求导
           skips=(  # 设置跳过的测试用例列表
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 标记特定测试用例预期失败
               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 标记特定测试用例预期失败
               DecorateInfo(unittest.skip("Expected: randn_like is not comparable between dtypes"),  # 跳过具有特定原因的测试用例
                            'TestCommon', 'test_complex_half_reference_testing'),
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),  # 跳过具有特定原因的测试用例
           )),
    OpInfo('randint',
           dtypes=all_types_and(torch.half, torch.bfloat16),
           op=lambda *args, **kwargs:
               wrapper_set_seed(torch.randint, *args, **kwargs),
           supports_out=False,
           sample_inputs_func=sample_inputs_randint,
           supports_autograd=False,
           skips=(
               # 下面是一些需要跳过的测试用例，它们的条件或者期望会导致测试失败或不符合预期
               # Tests that assume input is a tensor or sequence of tensors
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestCommon", "test_noncontiguous_samples"),
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_vmap_exhaustive"),
               DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_op_has_batch_rule"),
               # CPU randint generates different values based on the strides of out tensor
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
               # randint fails to warn when resizing its out tensor
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               # FX failed to normalize op - add the op to the op_skip list.
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # Tests that assume input tensor has a meaningful effect on output tensor
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # Might need to skip until ROCm5.5
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_multiple_devices',
                            dtypes=[torch.float32, torch.int64], active_if=TEST_WITH_ROCM),
           )),
    OpInfo('randint_like',
           dtypes=all_types_and(torch.half, torch.bfloat16),
           op=lambda inp, *args, **kwargs:
               wrapper_set_seed(torch.randint_like, inp, *args, **kwargs),
           supports_out=False,
           sample_inputs_func=sample_inputs_randint_like,
           supports_autograd=False,
           skips=(
               # 下面是一些需要跳过的测试用例，它们的条件或者期望会导致测试失败或不符合预期
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # Output is non-deterministic, hence skipped
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
           )),
    OpInfo('full_like',  # 创建一个描述 'full_like' 操作的 OpInfo 对象
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型，包括布尔类型和半精度浮点数等
           supports_out=False,  # 不支持输出参数
           sample_inputs_func=sample_inputs_full_like,  # 用于生成示例输入的函数
           supports_autograd=False,  # 不支持自动求导
           skips=(  # 跳过的测试用例信息列表
           )),

    OpInfo('new_zeros',  # 创建一个描述 'new_zeros' 操作的 OpInfo 对象
           op=lambda x, *args, **kwargs: x.new_zeros(*args, **kwargs),  # 操作的具体实现，使用输入张量 x 的 new_zeros 方法
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型，包括特定复数类型
           supports_out=False,  # 不支持输出参数
           sample_inputs_func=sample_inputs_new_fns,  # 用于生成示例输入的函数
           skips=(  # 跳过的测试用例信息列表
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 指定跳过的测试用例
           ),
           supports_autograd=False),  # 不支持自动求导

    OpInfo('new_ones',  # 创建一个描述 'new_ones' 操作的 OpInfo 对象
           op=lambda x, *args, **kwargs: x.new_ones(*args, **kwargs),  # 操作的具体实现，使用输入张量 x 的 new_ones 方法
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型，包括特定复数类型
           supports_out=False,  # 不支持输出参数
           sample_inputs_func=sample_inputs_new_fns,  # 用于生成示例输入的函数
           skips=(  # 跳过的测试用例信息列表
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 指定跳过的测试用例
           ),
           supports_autograd=False),  # 不支持自动求导

    OpInfo('ones',  # 创建一个描述 'ones' 操作的 OpInfo 对象
           op=torch.ones,  # 操作的具体实现，使用 torch.ones 函数
           supports_autograd=False,  # 不支持自动求导
           supports_varargs=True,  # 支持可变参数
           is_factory_function=True,  # 是一个工厂函数
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型，包括特定复数类型
           supports_out=True,  # 支持输出参数
           sample_inputs_func=sample_inputs_ones_zeros,  # 用于生成示例输入的函数
           skips=(  # 跳过的测试用例信息列表
               # 下面是具体的跳过信息
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),  # 指定跳过的测试用例
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 指定跳过的测试用例
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 指定跳过的测试用例
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),  # 指定跳过的测试用例

               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),  # 指定跳过的测试用例

               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),  # 指定跳过的测试用例
           )),
    OpInfo('zeros',  # 定义名为'zeros'的操作信息对象
           op=torch.zeros,  # 操作函数为torch.zeros
           supports_autograd=False,  # 不支持自动求导
           is_factory_function=True,  # 是工厂函数
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型包括所有类型以及特定的几种
           supports_out=True,  # 支持输出参数
           sample_inputs_func=sample_inputs_ones_zeros,  # 样本输入函数为sample_inputs_ones_zeros
           skips=(  # 跳过以下测试用例
               # Tests that assume input is a tensor or sequence of tensors
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),  # 预期失败的测试用例，测试变体一致性（eager模式）
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 预期失败的测试用例，测试负数视图
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 预期失败的测试用例，测试共轭视图
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),  # 预期失败的测试用例，测试负数共轭视图

               # Same failure as arange: cannot find linspace in captured graph
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),  # 跳过的测试用例，测试变体一致性（JIT模式）

               # UserWarning not triggered : Resized a non-empty tensor but did not warn about it.
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),  # 预期失败的测试用例，测试输出警告
           )),
    OpInfo('full',  # 定义名为'full'的操作信息对象
           op=torch.full,  # 操作函数为torch.full
           supports_autograd=False,  # 不支持自动求导
           is_factory_function=True,  # 是工厂函数
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),  # 支持的数据类型包括所有类型以及特定的几种
           supports_out=True,  # 支持输出参数
           sample_inputs_func=sample_inputs_full,  # 样本输入函数为sample_inputs_full
           skips=(  # 跳过以下测试用例
               # Tests that assume input is a tensor or sequence of tensors
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_variant_consistency_eager'),  # 预期失败的测试用例，测试变体一致性（eager模式）
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 预期失败的测试用例，测试负数视图
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 预期失败的测试用例，测试共轭视图
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),  # 预期失败的测试用例，测试负数共轭视图
               # Same failure as arange: cannot find linspace in captured graph
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),  # 跳过的测试用例，测试变体一致性（JIT模式）
               # UserWarning not triggered : Resized a non-empty tensor but did not warn about it.
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),  # 预期失败的测试用例，测试输出警告
               # RuntimeError: UNSUPPORTED DTYPE: bool
               DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_nnc_correctness', dtypes=(torch.bool,)),  # 预期失败的测试用例，测试NNC操作信息正确性，特定数据类型为torch.bool
           )),
    OpInfo('new_empty',
           op=lambda x, *args, **kwargs: x.new_empty(*args, **kwargs),
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
           supports_out=False,
           sample_inputs_func=sample_inputs_new_fns,
           skips=(
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # 表示这个测试被标记为预期失败，因此会跳过执行
               DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),
               # 表示这个测试会被跳过，因为空的张量数据不具备有效性，难以进行比较
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager'),
               # 表示这个测试会被跳过，因为空的张量数据不具备有效性，难以进行比较
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_noncontiguous_samples'),
               # 表示这个测试会被跳过，因为空的张量数据不具备有效性，难以进行比较
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_conj_view'),
               # 表示这个测试会被跳过，因为空的张量数据不具备有效性，难以进行比较
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_view'),
               # 表示这个测试会被跳过，因为空的张量数据不具备有效性，难以进行比较
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_conj_view'),
               # 表示这个测试会被跳过，因为空的张量数据不具备有效性，难以进行比较
               DecorateInfo(unittest.skip("Skipped!"), 'TestNNCOpInfo', 'test_nnc_correctness'),
               # 表示这个测试会被跳过，因为空的张量数据不具备有效性，难以进行比较
               DecorateInfo(unittest.skip("Skipped!"), 'TestCudaFuserOpInfo'),
               # 表示这个测试会被跳过，因为空的张量数据不具备有效性，难以进行比较
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_non_standard_bool_values'),
               # 表示这个测试会被跳过，因为预期 'new_empty' 不可比较
               DecorateInfo(unittest.skip("Expected: new_empty is not comparable"), 'TestCompositeCompliance',
                            'test_operator'),
               # 表示这个测试会被跳过，因为预期 'new_empty' 不可比较
               DecorateInfo(unittest.skip("Expected: new_empty is not comparable"),
                            'TestCommon', 'test_complex_half_reference_testing'),
               # 表示这个测试会被跳过，因为输出是非确定性的
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
           ),
           supports_autograd=False),
    OpInfo('empty_strided',  # 定义操作信息对象，针对空扩展的张量操作
           op=lambda inp, *args, **kwargs: wrapper_set_seed(torch.empty_strided, inp, *args, **kwargs),  # 设置操作函数，使用包装器设置种子
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.bool, torch.half),  # 支持的数据类型，包括所有类型和复杂类型以及 bfloat16、bool 和 half
           supports_out=False,  # 不支持输出参数
           supports_autograd=False,  # 不支持自动求导
           sample_inputs_func=sample_inputs_empty_strided,  # 用于生成样本输入的函数
           skips=(  # 跳过的测试用例列表
               # 下面是各个跳过的测试用例信息
               # FX failed to normalize op - add the op to the op_skip list.
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # Empty tensor data is garbage so it's hard to make comparisons with it.
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_noncontiguous_samples'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_non_standard_bool_values'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_conj_view'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_view'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_conj_view'),
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_compare_cpu'),
               DecorateInfo(unittest.skip("Expected: empty is not comparable"), 'TestCompositeCompliance', 'test_operator'),
               # Lazy tensor failures
               DecorateInfo(unittest.skip("Expected: empty is not comparable"), 'TestLazyOpInfo'),
               # RuntimeError: unsupported operation: more than one element of the written-to tensor refers to a single
               # memory location. Please clone() the tensor before performing the operation.
               DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_meta_outplace'),
               DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_symbolic_meta_outplace'),
               DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_dispatch_symbolic_meta_outplace_all_strides'),
           )),
    OpInfo('eye',  # 创建一个 OpInfo 对象，指定操作为 'eye'
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),  # 指定操作支持的数据类型
           sample_inputs_func=sample_inputs_eye,  # 指定生成样本输入的函数
           error_inputs_func=error_inputs_eye,  # 指定生成错误输入的函数
           supports_out=True,  # 表示操作支持输出参数
           supports_autograd=False,  # 表示操作不支持自动求导
           skips=(  # 定义一组需要跳过的测试信息
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 标记一个测试预期会失败
               # TODO: 和这个问题相同？
               # https://github.com/pytorch/pytorch/issues/81774
               # 另外参见：arange, new_full
               # 在解释器中有效但未能匹配任何模式
               DecorateInfo(unittest.expectedFailure, 'TestOperatorSignatures', 'test_get_torch_func_signature_exhaustive'),  # 标记一个测试预期会失败
               # 在解释器中有效但未能匹配任何模式
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 标记一个测试预期会失败
               # 跳过这些测试因为我们有非张量输入
               DecorateInfo(unittest.skip('Skipped!'), "TestCommon", "test_noncontiguous_samples"),  # 标记一个测试需要跳过并附带跳过原因
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_variant_consistency_eager'),  # 标记一个测试需要跳过并附带跳过原因
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_conj_view'),  # 标记一个测试需要跳过并附带跳过原因
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_conj_view'),  # 标记一个测试需要跳过并附带跳过原因
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_view'),  # 标记一个测试需要跳过并附带跳过原因
               # 没有触发 UserWarning: 调整了非空张量但未警告。
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),  # 标记一个测试预期会失败
           )),
    # 创建 OpInfo 对象，描述 'scalar_tensor' 操作的信息
    OpInfo('scalar_tensor',
           # 定义允许的数据类型集合，包括所有类型、复杂类型以及指定的几种类型
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
           # 指定生成样本输入的函数为 sample_inputs_scalar_tensor
           sample_inputs_func=sample_inputs_scalar_tensor,
           # 指定不支持自动求导
           supports_autograd=False,
           # 指定不支持输出参数
           supports_out=False,
           # 定义跳过的测试用例集合，包括一系列 DecorateInfo 对象
           skips=(
               # 装饰信息：期望失败，应用于 'TestNormalizeOperators' 的 'test_normalize_operator_exhaustive' 测试方法
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # 装饰信息：期望失败，应用于 'TestOperatorSignatures' 的 'test_get_torch_func_signature_exhaustive' 测试方法
               # 尽管在解释器中工作，但未能匹配任何模式
               DecorateInfo(unittest.expectedFailure, 'TestOperatorSignatures', 'test_get_torch_func_signature_exhaustive'),
               # 装饰信息：期望失败，应用于 'TestJit' 的 'test_variant_consistency_jit' 测试方法
               # 跳过这些测试，因为我们有非张量输入
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # 装饰信息：跳过 'TestCommon' 的 'test_noncontiguous_samples' 测试方法，因为有非连续样本输入
               DecorateInfo(unittest.skip('Skipped!'), "TestCommon", "test_noncontiguous_samples"),
               # 装饰信息：跳过 'TestCommon' 的 'test_variant_consistency_eager' 测试方法，因为存在非张量输入
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_variant_consistency_eager'),
               # 装饰信息：跳过 'TestMathBits' 的 'test_conj_view' 测试方法
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_conj_view'),
               # 装饰信息：跳过 'TestMathBits' 的 'test_neg_conj_view' 测试方法
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_conj_view'),
               # 装饰信息：跳过 'TestMathBits' 的 'test_neg_view' 测试方法
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_view'),
           )),
    # 创建 OpInfo 对象，描述 'new_full' 操作的信息
    OpInfo('new_full',
           # 定义操作为 x.new_full(*args, **kwargs)
           op=lambda x, *args, **kwargs: x.new_full(*args, **kwargs),
           # 定义允许的数据类型集合，包括所有类型、复杂类型以及指定的几种类型
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
           # 指定不支持输出参数
           supports_out=False,
           # 指定生成样本输入的函数为 sample_inputs_new_full
           sample_inputs_func=sample_inputs_new_full,
           # 定义跳过的测试用例集合，只包含一个 DecorateInfo 对象
           skips=(
               # 装饰信息：期望失败，应用于 'TestNormalizeOperators' 的 'test_normalize_operator_exhaustive' 测试方法
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
           ),
           # 指定不支持自动求导
           supports_autograd=False),
    OpInfo('multinomial',
           # 定义操作为 'multinomial'，使用 wrapper_set_seed 对 torch.multinomial 进行包装
           op=lambda inp, *args, **kwargs:
               wrapper_set_seed(torch.multinomial, inp, *args, **kwargs),
           # 定义方法变体为 lambda 函数，使用 wrapper_set_seed 对 torch.Tensor.multinomial 进行包装
           method_variant=lambda inp, *args, **kwargs:
               wrapper_set_seed(torch.Tensor.multinomial, inp, *args, **kwargs),
           # 支持的数据类型包括浮点数类型和 torch.bfloat16、torch.half 类型
           dtypes=floating_types_and(torch.bfloat16, torch.half),
           # 支持输出参数
           supports_out=True,
           # 用于生成样本输入的函数为 sample_inputs_multinomial
           sample_inputs_func=sample_inputs_multinomial,
           # 用于生成错误输入的函数为 error_inputs_multinomial
           error_inputs_func=error_inputs_multinomial,
           # 跳过以下测试用例：
           skips=(
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # 跳过具体原因为“Strides are not the same!”的测试用例
               # 在 CI 环境下可能无法复现此问题
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_out'),
               # 预期失败的测试用例，AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # 预期失败的测试用例，UserWarning not triggered : Resized a non-empty tensor but did not warn about it.
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               # 跳过具体原因为“output is non-deterministic”的测试用例
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu')),
           # 不支持自动求导
           supports_autograd=False),
    OpInfo('normal',
           op=lambda inp, *args, **kwargs:
               wrapper_set_seed(torch.normal, inp, *args, **kwargs),
           # Tensor.normal_的就地变体与torch.normal不同
           inplace_variant=None,  # 就地变体为None
           dtypes=floating_types_and(torch.bfloat16, torch.half),  # 数据类型包括半精度和bfloat16
           dtypesIfCUDA=floating_types_and(torch.bfloat16, torch.half),  # CUDA环境下的数据类型同上
           supports_out=True,  # 支持输出参数
           sample_inputs_func=sample_inputs_normal_tensor_first,  # 用于生成正态分布张量的示例输入函数
           skips=(
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期的失败测试，测试正则化操作符的详尽性
               # Tensor-likes are not close! （张量类似物不相似！）
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),  # 预期的失败测试，测试输出操作
               # AssertionError: JIT Test does not execute any logic （断言错误：JIT测试未执行任何逻辑）
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期的失败测试，测试JIT变体的一致性
               # UserWarning not triggered : Resized a non-empty tensor but did not warn about it. （未触发用户警告：调整大小非空张量，但未发出警告）
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),  # 预期的失败测试，测试输出警告
               # Computed gradient is incorrect -- would be an exfail but gradgrad somehow passes （计算的梯度不正确 - 本来应该是失败测试但是gradgrad居然通过了）
               DecorateInfo(unittest.skip("Gradients are incorrect!"), 'TestFwdGradients'),  # 跳过测试，梯度不正确
               DecorateInfo(unittest.skip("Gradients are incorrect!"), 'TestBwdGradients'),  # 跳过测试，梯度不正确
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),  # 跳过测试，输出是非确定性的
               # RuntimeError: Difference from {dtype} is larger with decomposition （运行时错误：与分解相比{dtype}的差异较大）
               DecorateInfo(unittest.skip("Skipped!"), 'TestDecomp', 'test_comprehensive'),  # 跳过测试，全面测试分解
               DecorateInfo(unittest.skip("Skipped!"), 'TestDecomp', 'test_quick'),  # 跳过测试，快速测试分解
               # The inplace variant (Tensor.normal_) is different from torch.normal
               # inplace varaint Tensor.normal_ is decomposed using randn_like()
               DecorateInfo(unittest.skip("Skipped!"), 'TestMeta', 'test_dispatch_symbolic_meta_outplace_all_strides'))),
    OpInfo('normal',
           # This has its own variant b/c OpInfos assume the first arg is a Tensor but it is not here
           variant_test_name='number_mean',
           # 定义操作函数，用于生成正态分布的随机数，使用了自定义的包装器设置随机种子
           op=lambda std, mean, *args, **kwargs:
               wrapper_set_seed(torch.normal, mean, std, *args, **kwargs),
           # The inplace variant (Tensor.normal_) is different from torch.normal
           # 不支持就地操作的变体（inplace variant），因为它和 torch.normal 不同
           inplace_variant=None,
           # 指定数据类型为浮点类型，包括 torch.bfloat16 和 torch.half
           dtypes=floating_types_and(torch.bfloat16, torch.half),
           # 如果是在 CUDA 下，也支持上述的浮点类型
           dtypesIfCUDA=floating_types_and(torch.bfloat16, torch.half),
           # 支持输出张量作为参数
           supports_out=True,
           # 用于生成正态分布的张量的输入样本函数
           sample_inputs_func=sample_inputs_normal_tensor_second,
           # 跳过以下测试用例
           skips=(
               # 在 unittest 中预期失败的装饰器信息，用于指定跳过的测试用例
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # AssertionError: JIT Test does not execute any logic
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # 跳过测试：非连续样本的测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_noncontiguous_samples'),
               # 跳过测试：测试即时执行模式下的一致性变体
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager'),
               # 跳过测试：测试输出张量
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_out'),
               # 跳过测试：测试输出警告
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_out_warning'),
               # 跳过测试：测试反向传播
               DecorateInfo(unittest.skip("Skipped!"), 'TestCompositeCompliance', 'test_backward'),
               # 跳过测试：测试负视图
               DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_view'),
               # 跳过测试：测试前向梯度
               DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients'),
               # 跳过测试：测试反向梯度
               DecorateInfo(unittest.skip("Skipped!"), 'TestBwdGradients'),
               # 跳过测试：比较 CPU 的测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_compare_cpu'),
               # 跳过测试：即时融合操作信息
               DecorateInfo(unittest.skip("Skipped!"), 'TestEagerFusionOpInfo'),
               # 跳过测试：操作符测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestOperators'),
               # AssertionError：在 CUDA 变体中出现问题
               DecorateInfo(unittest.skip("Skipped!"), 'TestDecomp', 'test_comprehensive'),
               # AssertionError：在 CUDA 变体中出现问题
               DecorateInfo(unittest.skip("Skipped!"), 'TestDecomp', 'test_quick'),
               # AssertionError：在 CUDA 变体中出现问题
               DecorateInfo(unittest.skip("Skipped!"), 'TestFakeTensor', device_type='cuda'),
               # 跳过测试：设备工具测试
               DecorateInfo(unittest.skip("Skipped!"), 'TestDeviceUtils', 'test_device_mode_ops'))),
    OpInfo('bernoulli',
           op=lambda inp, *args, **kwargs:
               wrapper_set_seed(torch.bernoulli, inp, *args, **kwargs),
           # Tensor.bernoulli_的原位变体与torch.bernoulli不同
           inplace_variant=None,
           method_variant=lambda inp, *args, **kwargs:
               wrapper_set_seed(torch.Tensor.bernoulli, inp, *args, **kwargs),
           # 支持的数据类型包括浮点类型以及torch.bfloat16和torch.half
           dtypes=floating_types_and(torch.bfloat16, torch.half),
           supports_out=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           # 用于生成bernoulli分布的样本输入的函数
           sample_inputs_func=sample_inputs_bernoulli,
           # 用于bernoulli函数的错误输入的函数
           error_inputs_func=error_inputs_bernoulli,
           skips=(
               # vmap: 目前不支持在vmap内调用随机操作
               DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', 'test_forward_mode_AD'),
               # 单元测试预期失败：测试正向模式自动微分
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # 断言错误：JIT测试未执行任何逻辑
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # 预期的运行时错误：在将dtype为torch.float32的结果不安全地转换为dtype为torch.lon的输出时
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
               # 用户警告未触发：调整非空张量大小，但未发出警告
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               # 跳过测试：输出是非确定性的
               DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'))),
    OpInfo('scatter_add',
           # 支持的数据类型包括所有类型、复数类型以及torch.bool、torch.half、torch.bfloat16
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
           # 用于scatter_add操作的样本输入的函数
           sample_inputs_func=sample_inputs_scatter_add,
           # 用于scatter_add操作的错误输入的函数
           error_inputs_func=error_inputs_scatter_and_scatter_add,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           ),
    OpInfo('stack',
           # 支持的数据类型包括所有类型、复数类型以及torch.complex32、torch.bool、torch.float16、torch.bfloat16
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),
           assert_autodiffed=True,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           skips=(
               # https://github.com/pytorch/pytorch/issues/77046
               # 单元测试预期失败：测试共轭视图
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
               # 单元测试预期失败：测试负视图
               DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
           ),
           ),
    OpInfo('_chunk_cat',
           # 支持的数据类型包括所有类型、复数类型以及torch.complex32、torch.bool、torch.float16、torch.bfloat16
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),
           # 用于_chunk_cat操作的样本输入的函数
           sample_inputs_func=sample_inputs_chunk_cat,
           # 用于_chunk_cat操作的错误输入的函数
           error_inputs_func=error_inputs_chunk_cat,
           supports_autograd=False,
           supports_out=True,
           ),
    OpInfo('hstack',  # 创建一个 OpInfo 对象，表示 'hstack' 操作的信息
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),  # 指定支持的数据类型
           sample_inputs_func=sample_inputs_hstack_dstack_vstack,  # 提供生成样本输入的函数
           error_inputs_func=error_inputs_hstack_dstack_vstack,  # 提供生成错误输入的函数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
           ),
    BinaryUfuncInfo('hypot',  # 创建一个 BinaryUfuncInfo 对象，表示 'hypot' 函数的信息
                    dtypes=floating_types_and(torch.bfloat16, torch.half),  # 指定支持的数据类型
                    dtypesIfCUDA=floating_types_and(torch.half, torch.bfloat16),  # 指定在 CUDA 下支持的数据类型
                    supports_forward_ad=True,  # 支持前向自动微分
                    supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
                    supports_rhs_python_scalar=False),  # 不支持右侧的 Python 标量
    OpInfo('histogram',  # 创建一个 OpInfo 对象，表示 'histogram' 操作的信息
           dtypes=floating_types(),  # 指定支持的浮点数据类型
           dtypesIfCUDA=_dispatch_dtypes(),  # 指定在 CUDA 下支持的数据类型；histogram 只在 CPU 上实现
           sample_inputs_func=sample_inputs_histogram,  # 提供生成样本输入的函数
           supports_autograd=False,  # 不支持自动微分
           skips=(  # 跳过的测试项列表
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期 JIT 测试不通过
               DecorateInfo(unittest.skip("Skipped!"), 'TestOpInfo', device_type='xla'),  # 在 XLA 上未实现，跳过测试
           )),
    OpInfo('histogramdd',  # 创建一个 OpInfo 对象，表示 'histogramdd' 操作的信息
           dtypes=floating_types(),  # 指定支持的浮点数据类型
           dtypesIfCUDA=_dispatch_dtypes(),  # 指定在 CUDA 下支持的数据类型；histogramdd 只在 CPU 上实现
           sample_inputs_func=sample_inputs_histogramdd,  # 提供生成样本输入的函数
           error_inputs_func=error_inputs_histogramdd,  # 提供生成错误输入的函数
           supports_autograd=False,  # 不支持自动微分
           skips=(  # 跳过的测试项列表
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_errors', device_type='cuda'),  # 在 CUDA 上未实现，预期测试失败
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期 JIT 测试不通过
           )),
    # 定义 OpInfo 对象，用于描述特定操作的信息
    OpInfo('histc',
           # 支持的数据类型为浮点类型和 torch.bfloat16、torch.float16
           dtypes=floating_types_and(torch.bfloat16, torch.float16),
           # 如果在 CUDA 下，则支持的数据类型为整型和 torch.int8、torch.int16、torch.int32、torch.int64
           dtypesIfCUDA=floating_types_and(torch.int8, torch.int16, torch.int32, torch.int64),
           # 生成样本输入的函数为 sample_inputs_histc
           sample_inputs_func=sample_inputs_histc,
           # 支持输出结果（out 参数）
           supports_out=True,
           # 不支持自动求导
           supports_autograd=False,
           # 跳过的测试条件包含：
           # CUDA 下的 histc 返回一个浮点张量，但当传递整数类型的 out 张量时没有正确警告
           # 这个装饰器标志着 unittest 中的 test_out 函数为预期失败的测试用例
           skips=(
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out', device_type='cuda'),
           )),
    # OpInfo 对象描述 bincount 操作信息
    OpInfo('bincount',
           # 支持的数据类型为整型
           dtypes=integral_types_and(),
           # 生成样本输入的函数为 sample_inputs_bincount
           sample_inputs_func=sample_inputs_bincount,
           # 不支持输出结果（out 参数）
           supports_out=False,
           # 不支持自动求导
           supports_autograd=False,
           # 跳过的测试条件包含：
           # JIT 测试与 Tensor 关键字参数不兼容，因此跳过了此测试用例
           DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),
           )),
    # OpInfo 对象描述 bucketize 操作信息
    OpInfo('bucketize',
           # 支持的数据类型为所有类型和 torch.float16、torch.bfloat16
           dtypes=all_types_and(torch.float16, torch.bfloat16),
           # 如果在 CUDA 下，则支持的数据类型为所有类型和 torch.bfloat16、torch.float16
           dtypesIfCUDA=all_types_and(torch.bfloat16, torch.float16),
           # 生成样本输入的函数为 sample_inputs_bucketize
           sample_inputs_func=sample_inputs_bucketize,
           # 生成参考输入的函数为 reference_inputs_bucketize
           reference_inputs_func=reference_inputs_bucketize,
           # 错误输入的函数为 error_inputs_bucketize
           error_inputs_func=error_inputs_bucketize,
           # 不支持自动求导
           supports_autograd=False,
           # 跳过的测试条件包含：
           # JIT 测试与 Tensor 关键字参数不兼容，因此跳过了此测试用例
           DecorateInfo(unittest.skip("Expected failure!"), 'TestJit', 'test_variant_consistency_jit'),
           )),
    # OpInfo 对象描述 searchsorted 操作信息
    OpInfo('searchsorted',
           # 支持的数据类型为所有类型和 torch.bfloat16、torch.float16
           dtypes=all_types_and(torch.bfloat16, torch.float16),
           # 如果在 CUDA 下，则支持的数据类型为所有类型和 torch.bfloat16、torch.float16
           dtypesIfCUDA=all_types_and(torch.bfloat16, torch.float16),
           # 生成样本输入的函数为 sample_inputs_searchsorted
           sample_inputs_func=sample_inputs_searchsorted,
           # 不支持自动求导
           supports_autograd=False,
           # 参考实现为 reference_searchsorted
           ref=reference_searchsorted,
           # 跳过的测试条件包含：
           # JIT 测试与 Tensor 关键字参数不兼容，因此跳过了此测试用例
           DecorateInfo(unittest.skip("Expected failure!"), 'TestJit', 'test_variant_consistency_jit'),
           )),
    OpInfo('cat',
           ref=_cat_np,  # 设置操作的参考函数为 _cat_np
           aliases=('concat', 'concatenate'),  # 别名列表为 'concat', 'concatenate'
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.complex32),  # 支持的数据类型列表
           sample_inputs_func=sample_inputs_cat_concat,  # 用于生成样本输入的函数
           reference_inputs_func=reference_inputs_cat,  # 用于生成参考输入的函数
           error_inputs_func=error_inputs_cat,  # 用于生成错误输入的函数
           # https://github.com/pytorch/pytorch/issues/80411
           gradcheck_fast_mode=True,  # 使用快速模式进行梯度检查
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向-后向梯度
           # See https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,  # 禁用批处理前向梯度检查
           assert_autodiffed=True,  # 断言自动微分正确性
           skips=(
               # https://github.com/pytorch/pytorch/issues/89353
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_numpy_ref_mps'),  # 跳过具体的单元测试
               # RuntimeError: Arguments for call not valid.
               #               Expected a value of type 'List[Tensor]' for argument
               #               'tensors' but instead found type 'Tensor (inferred)'.
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_jit_alias_remapping'),  # 跳过具体的单元测试
               # see https://github.com/pytorch/pytorch/issues/71286
               DecorateInfo(unittest.expectedFailure, 'TestNNCOpInfo', 'test_nnc_correctness'),  # 跳过具体的单元测试
               # see https://github.com/pytorch/pytorch/issues/99806
               # RuntimeError: The size of tensor a (25) must match the size of tensor b (0) at non-singleton dimension 0.
               DecorateInfo(unittest.expectedFailure, 'TestBwdGradients', 'test_fn_gradgrad'),  # 跳过具体的单元测试
           )),
    OpInfo('unbind',
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型列表
           ref=reference_unbind,  # 设置操作的参考函数为 reference_unbind
           sample_inputs_func=sample_inputs_unbind,  # 用于生成样本输入的函数
           error_inputs_func=error_inputs_unbind,  # 用于生成错误输入的函数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向-后向梯度
           supports_gradgrad=True,  # 支持二阶梯度
           supports_out=False,  # 不支持输出张量
           ),
    OpInfo('vstack',
           aliases=('row_stack',),  # 别名列表为 'row_stack'
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型列表
           sample_inputs_func=sample_inputs_hstack_dstack_vstack,  # 用于生成样本输入的函数
           error_inputs_func=error_inputs_hstack_dstack_vstack,  # 用于生成错误输入的函数
           supports_forward_ad=True,  # 支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向-后向梯度
           skips=(
               # RuntimeError: _fn() Expected a value of type
               #   'Tensor (inferred)' for argument 't0' but instead found type 'tuple'.
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_jit_alias_remapping'),  # 跳过具体的单元测试
           )),
    OpInfo('dstack',
           # 定义操作名称为 'dstack' 的操作信息对象
           dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),
           # 支持的数据类型包括所有类型、复杂类型、以及指定的几种数据类型
           sample_inputs_func=sample_inputs_hstack_dstack_vstack,
           # 使用 sample_inputs_hstack_dstack_vstack 函数生成示例输入
           error_inputs_func=error_inputs_hstack_dstack_vstack,
           # 使用 error_inputs_hstack_dstack_vstack 函数生成错误输入
           supports_forward_ad=True,
           # 支持正向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持正向到反向梯度
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,
           # 不检查批处理的正向梯度
           ),
    
    OpInfo('unfold',
           # 定义操作名称为 'unfold' 的操作信息对象
           op=lambda x, *args: x.unfold(*args),
           # 操作为对输入 x 执行 unfold 操作
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           # 支持的数据类型包括所有类型、复杂类型，以及指定的几种数据类型
           backward_dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           # 反向传播时支持的数据类型为浮点数和复杂类型，并指定了具体类型
           gradcheck_fast_mode=True,
           # 在慢速 gradcheck 时运行速度非常慢，可以在快速模式下减少输入大小
           supports_out=False,
           # 不支持输出参数
           supports_forward_ad=True,
           # 支持正向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持正向到反向梯度
           check_batched_gradgrad=False,
           # 不检查批处理的 gradgrad
           # 查看 https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,
           # 不检查批处理的正向梯度
           skips=(
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               # 跳过由于预期失败而装饰的单元测试，具体测试为 test_normalize_operator_exhaustive
               # 跳过操作模式测试，因为这是一个功能性的操作，而不是运算符
               DecorateInfo(unittest.expectedFailure, 'TestOperatorSignatures', 'test_get_torch_func_signature_exhaustive'),
           ),
           sample_inputs_func=sample_inputs_unfold),
    
    OpInfo('unfold_copy',
           # 定义操作名称为 'unfold_copy' 的操作信息对象
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           # 支持的数据类型包括所有类型、复杂类型，以及指定的几种数据类型
           backward_dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           # 反向传播时支持的数据类型为浮点数和复杂类型，并指定了具体类型
           gradcheck_fast_mode=True,
           # 在慢速 gradcheck 时运行速度非常慢，可以在快速模式下减少输入大小
           supports_out=True,
           # 支持输出参数
           supports_forward_ad=True,
           # 支持正向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持正向到反向梯度
           check_batched_gradgrad=False,
           # 不检查批处理的 gradgrad
           # 查看 https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,
           sample_inputs_func=sample_inputs_unfold),
    
    OpInfo('msort',
           # 定义操作名称为 'msort' 的操作信息对象
           dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),
           # 支持的数据类型包括所有类型和指定的几种数据类型
           dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),
           # 如果是在 CUDA 下，则支持的数据类型包括所有类型和指定的几种数据类型
           check_batched_gradgrad=False,
           # 不检查批处理的 gradgrad
           supports_forward_ad=True,
           # 支持正向自动微分
           supports_fwgrad_bwgrad=True,
           sample_inputs_func=sample_inputs_msort,
           # 使用 sample_inputs_msort 函数生成示例输入
           skips=(
           )),
    # 定义 'movedim' 操作的信息
    OpInfo('movedim',
           aliases=('moveaxis',),  # 别名为 'moveaxis'
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 支持的数据类型
           supports_out=False,  # 不支持输出参数
           supports_forward_ad=True,  # 支持正向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,  # 禁用批处理前向梯度检查
           sample_inputs_func=sample_movedim_moveaxis,  # 样本输入生成函数
           reference_inputs_func=reference_movedim_moveaxis,  # 参考输入生成函数
           error_inputs_func=error_movedim_moveaxis),  # 错误输入生成函数
    # 定义 'renorm' 操作的信息
    OpInfo('renorm',
           dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),  # 浮点数和复数类型，包括半精度浮点数和 BF16
           sample_inputs_func=sample_inputs_renorm,  # 样本输入生成函数
           error_inputs_func=error_inputs_renorm,  # 错误输入生成函数
           supports_forward_ad=True,  # 支持正向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           skips=(
               # 运行时错误：linalg_vector_norm.default 的差异大于原始值
               # 在输出 0 上。
               # 原始最大差异：2.560596747969157e-07，
               # 分解后最大差异：1.8187482915266173e-06
               DecorateInfo(unittest.skip("不一致的精度"), 'TestDecomp', 'test_comprehensive',
                            device_type='cpu', dtypes=(torch.float16,)),
           )),
    # 定义 'repeat' 操作的形状函数信息
    ShapeFuncInfo('repeat',
                  op=lambda x, dims: x.repeat(dims),  # 操作函数为 x 沿指定维度重复
                  ref=np.tile,  # 参考实现为 numpy 的 tile 函数
                  dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型
                  # 查看 https://github.com/pytorch/pytorch/issues/80411
                  gradcheck_fast_mode=True,  # 使用快速梯度检查模式
                  supports_out=False,  # 不支持输出参数
                  supports_forward_ad=True,  # 支持正向自动求导
                  supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
                  sample_inputs_func=sample_repeat_tile,  # 样本输入生成函数
                  skips=(
                      DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
                  )),
    # 定义 'squeeze' 操作的信息
    OpInfo('squeeze',
           ref=_squeeze_ref,  # 参考实现为 _squeeze_ref 函数
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 支持的数据类型
           supports_out=False,  # 不支持输出参数
           assert_autodiffed=True,  # 断言自动求导完成
           autodiff_fusible_nodes=[],  # 别名输入，不应合并
           autodiff_nonfusible_nodes=[],  # 别名输入，不应合并
           assert_jit_shape_analysis=True,  # 断言 JIT 形状分析正确
           supports_forward_ad=True,  # 支持正向自动求导
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           # vmap 不支持原地视图
           check_inplace_batched_forward_grad=False,  # 禁用批处理前向梯度原地视图检查
           # 查看 https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,  # 禁用批处理前向梯度检查
           sample_inputs_func=sample_inputs_squeeze),  # 样本输入生成函数
    OpInfo('squeeze',  # 定义一个操作信息对象，描述squeeze操作的测试信息
           ref=_squeeze_ref,  # 参考实现函数
           variant_test_name="multiple",  # 测试变体名称为"multiple"
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 支持的数据类型列表
           supports_out=False,  # 不支持输出参数
           assert_autodiffed=True,  # 断言自动微分
           autodiff_fusible_nodes=[],  # 可自动微分的可融合节点为空列表，别名为输入，不应融合
           autodiff_nonfusible_nodes=[],  # 不可自动微分的不可融合节点为空列表，别名为输入，不应融合
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持正向梯度反向传播
           # vmap不支持原地视图
           check_inplace_batched_forward_grad=False,
           # https://github.com/pytorch/pytorch/issues/66357
           check_batched_forward_grad=False,
           sample_inputs_func=sample_inputs_squeeze_multiple),  # 样本输入生成函数为sample_inputs_squeeze_multiple

    UnaryUfuncInfo(  # 定义一个一元ufunc信息对象，描述fill操作的测试信息
        'fill',  # 操作名称为'fill'
        ref=_fill_np,  # 参考实现函数_fill_np
        method_variant=None,  # 方法变体为None
        sample_kwargs=_fill_sample_kwargs,  # 样本关键字参数_fill_sample_kwargs
        sample_inputs_func=partial(sample_inputs_elementwise_unary, op_kwargs={'value': True}),  # 样本输入生成函数为partial(sample_inputs_elementwise_unary, op_kwargs={'value': True})
        supports_forward_ad=True,  # 支持正向自动微分
        supports_fwgrad_bwgrad=True,  # 支持正向梯度反向传播
        # https://github.com/pytorch/pytorch/issues/66357
        check_batched_forward_grad=False,
        dtypes=all_types_and_complex_and(torch.complex32, torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型列表
        supports_out=False,  # 不支持输出参数
        skips=(  # 跳过以下测试
            # JIT在作为lambda传递时存在问题
            # AssertionError: JIT Test does not execute any logic
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            DecorateInfo(unittest.skip("No fill_ op"), 'TestCudaFuserOpInfo'),
            DecorateInfo(unittest.skip("No fill_ op"), 'TestNNCOpInfo'),
        )),

    OpInfo('resize_',  # 定义一个操作信息对象，描述resize_操作的测试信息
           op=lambda x, shape: x.clone().resize_(shape),  # 操作为lambda表达式，复制x并调整大小为shape
           method_variant=None,  # 方法变体为None
           inplace_variant=torch.Tensor.resize_,  # 就地变体为torch.Tensor.resize_
           # 测试失败，因为resize_与测试预期中的imag视图不兼容
           # https://github.com/pytorch/pytorch/issues/65945
           test_neg_view=False,
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型列表
           supports_out=False,  # 不支持输出参数
           supports_autograd=False,  # 不支持自动梯度
           skips=(  # 跳过以下测试
               # 不能调整需要梯度的变量
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_dtypes'),
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),
               DecorateInfo(unittest.skip("Allowed exception"), 'TestCompositeCompliance', 'test_operator'),
           ),
           sample_inputs_func=sample_inputs_resize_ops),  # 样本输入生成函数为sample_inputs_resize_ops
    OpInfo('resize_as_',  # 定义操作名称为'resize_as_'
           op=lambda x, other: torch.resize_as_(x.clone(), other),  # 操作函数为torch.resize_as_，克隆输入张量并调整尺寸
           method_variant=None,  # 方法变体为None
           inplace_variant=torch.Tensor.resize_as_,  # 原地操作变体为torch.Tensor.resize_as_
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括bool、float16和bfloat16
           supports_out=False,  # 不支持输出张量参数
           supports_autograd=False,  # 不支持自动求导
           skips=(
               # 跳过以下测试：
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_dtypes'),  # 在 'TestCommon' 的 'test_dtypes' 测试中预期失败
               DecorateInfo(unittest.skip('Allowed exemption'), 'TestCompositeCompliance', 'test_operator'),  # 允许在 'TestCompositeCompliance' 的 'test_operator' 测试中跳过
           ),
           sample_inputs_func=sample_inputs_resize_ops),  # 获取输入示例的函数为sample_inputs_resize_ops
    OpInfo('take_along_dim',  # 定义操作名称为'take_along_dim'
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括bool、float16和bfloat16
           dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 如果是CUDA环境，支持的数据类型同上
           supports_inplace_autograd=False,  # 不支持原地自动求导
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和反向微分
           # 参考 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,  # 不检查批处理的前向梯度
           sample_inputs_func=sample_inputs_take_along_dim,  # 获取输入示例的函数为sample_inputs_take_along_dim
           gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 梯度检查非确定性容差为GRADCHECK_NONDET_TOL
           decorators=(
               # 运行时错误：视图大小与输入张量的大小和步长不兼容
               DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides"),  # 在 'TestMeta' 的 'test_dispatch_symbolic_meta_outplace_all_strides' 测试中预期失败
           )),
    ShapeFuncInfo('tile',  # 定义形状函数名称为'tile'
                  ref=np.tile,  # 参考实现为numpy的tile函数
                  dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括bool、float16和bfloat16
                  # 参考 https://github.com/pytorch/pytorch/issues/80411
                  gradcheck_fast_mode=True,  # 使用快速梯度检查模式
                  supports_out=False,  # 不支持输出张量参数
                  supports_forward_ad=True,  # 支持正向自动微分
                  supports_fwgrad_bwgrad=True,  # 支持前向和反向微分
                  sample_inputs_func=sample_repeat_tile),  # 获取输入示例的函数为sample_repeat_tile
    OpInfo('trapz',  # 定义操作名称为'trapz'，TODO: 将来应将其作为'trapezoid'的真正别名
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),  # 支持的数据类型包括float16和bfloat16
           supports_out=False,  # 不支持输出张量参数
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和反向微分
           # 参考 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,  # 不检查批处理的前向梯度
           sample_inputs_func=sample_trapezoid),  # 获取输入示例的函数为sample_trapezoid
    OpInfo('trapezoid',  # 定义操作名称为'trapezoid'
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),  # 支持的数据类型包括float16和bfloat16
           supports_out=False,  # 不支持输出张量参数
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向和反向微分
           # 参考 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,  # 不检查批处理的前向梯度
           sample_inputs_func=sample_trapezoid),  # 获取输入示例的函数为sample_trapezoid
    OpInfo('cumulative_trapezoid',
           # 操作信息: 累积梯形积分
           dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16),
           # 支持的数据类型包括所有类型以及复数类型，还有 torch.bfloat16 和 torch.float16
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向和反向梯度计算
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,
           # 不检查批处理前向梯度
           supports_out=False,
           # 不支持输出
           sample_inputs_func=sample_cumulative_trapezoid,),
           # 样本输入函数为 sample_cumulative_trapezoid
    OpInfo('unsqueeze',
           # 操作信息: unsqueeze
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
           # 支持的数据类型包括所有类型以及复数类型，还有 torch.bool, torch.float16, torch.bfloat16, torch.chalf
           supports_out=False,
           # 不支持输出
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向和反向梯度计算
           # 查看 https://github.com/pytorch/pytorch/pull/78358
           check_batched_forward_grad=False,
           # 不检查批处理前向梯度
           # vmap 不支持原地视图
           check_inplace_batched_forward_grad=False,
           # 断言 JIT 形状分析为真
           assert_jit_shape_analysis=True,
           # 断言自动微分为真
           assert_autodiffed=True,
           # 自动微分可融合节点为空列表，不应该融合输入
           autodiff_fusible_nodes=[],  # 别名输入，不应该被融合
           autodiff_nonfusible_nodes=[],  # 别名输入，不应该被融合
           sample_inputs_func=sample_unsqueeze),
           # 样本输入函数为 sample_unsqueeze
    BinaryUfuncInfo('xlogy',
                    # 二元通用函数信息: xlogy，别名为 'special.xlogy'
                    dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
                    # 支持的数据类型包括所有类型以及 torch.bool, torch.half, torch.bfloat16
                    promotes_int_to_float=True,
                    # 将整数升级为浮点数
                    supports_forward_ad=True,
                    # 支持前向自动微分
                    supports_fwgrad_bwgrad=True,
                    # 支持前向和反向梯度计算
                    supports_one_python_scalar=True,
                    # 支持 Python 标量值为 1
                    # 我们不测试 0，因为梯度会是 NaN，会导致错误
                    rhs_make_tensor_kwargs=dict(low=0.01)),
                    # 右手边制造张量关键字参数，低于 0.01
    OpInfo('zero_',
           # 操作信息: zero_
           op=lambda x: torch.zero_(x.clone()),
           # 操作为 lambda 函数，对输入张量进行 zero_ 操作
           method_variant=None,
           inplace_variant=torch.Tensor.zero_,
           # 就地变体为 torch.Tensor.zero_
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),
           # 支持的数据类型包括所有类型以及复数类型，还有 torch.bool, torch.float16, torch.bfloat16
           # https://github.com/pytorch/pytorch/issues/80411
           gradcheck_fast_mode=True,
           # 使用快速模式进行梯度检查
           supports_out=False,
           # 不支持输出
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向和反向梯度计算
           supports_gradgrad=True,
           # 支持梯度的梯度计算
           skips=(
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
           ),
           # 跳过的装饰信息
           sample_inputs_func=sample_inputs_zero_),
           # 样本输入函数为 sample_inputs_zero_
    OpInfo('logsumexp',
           # 操作信息: logsumexp，别名为 'special.logsumexp'
           dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
           # 支持的数据类型包括所有类型以及 torch.bool, torch.half, torch.bfloat16
           assert_autodiffed=True,
           # 断言自动微分为真
           supports_forward_ad=True,
           # 支持前向自动微分
           supports_fwgrad_bwgrad=True,
           # 支持前向和反向梯度计算
           gradcheck_fast_mode=False,
           # 使用梯度检查的普通模式
           sample_inputs_func=sample_inputs_logsumexp,
           # 样本输入函数为 sample_inputs_logsumexp
           reference_inputs_func=reference_inputs_logsumexp),
           # 参考输入函数为 reference_inputs_logsumexp
    # 创建 OpInfo 对象，表示操作为 'trace'
    OpInfo('trace',
           # 指定所有数据类型和复杂类型
           dtypes=all_types_and_complex(),
           # 如果在 CUDA 下，还支持额外的数据类型
           dtypesIfCUDA=all_types_and_complex_and(torch.chalf, torch.bool, torch.half, torch.bfloat16),
           # 指定错误输入的处理函数
           error_inputs_func=error_inputs_trace,
           # 不支持原地自动求导
           supports_inplace_autograd=False,
           # 不支持输出参数
           supports_out=False,
           # 支持正向自动求导
           supports_forward_ad=True,
           # 支持正向和反向自动求导
           supports_fwgrad_bwgrad=True,
           # 提供样本输入数据的函数
           sample_inputs_func=sample_inputs_trace),

    # 创建 OpInfo 对象，表示操作为 'transpose'
    OpInfo('transpose',
           # 参考的 NumPy 中的 transpose 函数
           ref=_numpy_ref_transpose,
           # 别名包括 'swapdims' 和 'swapaxes'
           aliases=('swapdims', 'swapaxes'),
           # 断言 JIT 形状分析
           assert_jit_shape_analysis=True,
           # 指定所有数据类型和复杂类型，并包括额外的数据类型
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf),
           # 不支持输出参数
           supports_out=False,
           # 支持正向自动求导
           supports_forward_ad=True,
           # 支持正向和反向自动求导
           supports_fwgrad_bwgrad=True,
           # vmap 不支持原地视图
           # 不检查批处理的前向梯度
           check_inplace_batched_forward_grad=False,
           # 提供样本输入数据的函数
           sample_inputs_func=sample_inputs_transpose_swapdims),

    # 创建 OpInfo 对象，表示操作为 'T'
    OpInfo('T',
           # 使用 lambda 函数实现操作为转置
           op=lambda x: x.T,
           # 指定所有数据类型和复杂类型，并包括额外的数据类型
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf),
           # 不支持输出参数
           supports_out=False,
           # 支持正向自动求导
           supports_forward_ad=True,
           # 支持正向和反向自动求导
           supports_fwgrad_bwgrad=True,
           # 跳过的测试用例信息列表
           skips=(
               # lambda 实现
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               DecorateInfo(unittest.expectedFailure, "TestJit", "test_variant_consistency_jit"),),
           # 提供样本输入数据的函数
           sample_inputs_func=sample_inputs_T,
           # 提供错误输入数据的函数
           error_inputs_func=error_inputs_T),

    # 创建 OpInfo 对象，表示操作为 'H'
    OpInfo('H',
           # 使用 lambda 函数实现操作为共轭转置
           op=lambda x: x.H,
           # 指定所有数据类型和复杂类型，并包括额外的数据类型
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf),
           # 不支持输出参数
           supports_out=False,
           # 支持正向自动求导
           supports_forward_ad=True,
           # 支持正向和反向自动求导
           supports_fwgrad_bwgrad=True,
           # 不检查批处理的前向梯度
           check_batched_forward_grad=False,
           # 跳过的测试用例信息列表
           skips=(
               # lambda 实现
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               DecorateInfo(unittest.expectedFailure, "TestJit", "test_variant_consistency_jit"),),
           # 提供样本输入数据的函数
           sample_inputs_func=sample_inputs_T),

    # 创建 OpInfo 对象，表示操作为 'mT'
    OpInfo('mT',
           # 使用 lambda 函数实现操作为伴随转置
           op=lambda x: x.mT,
           # 指定所有数据类型和复杂类型，并包括额外的数据类型
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf),
           # 在慢速 gradcheck 模式下运行 - 或者减少输入大小
           gradcheck_fast_mode=True,
           # 不支持输出参数
           supports_out=False,
           # 支持正向自动求导
           supports_forward_ad=True,
           # 支持正向和反向自动求导
           supports_fwgrad_bwgrad=True,
           # 跳过的测试用例信息列表
           skips=(
               # lambda 实现
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               DecorateInfo(unittest.expectedFailure, "TestJit", "test_variant_consistency_jit"),),
           # 提供样本输入数据的函数
           sample_inputs_func=sample_inputs_adjoint),
    # OpInfo 类的实例化，用于描述操作的信息
    OpInfo('mH',
           # 定义操作的函数，这里是返回对象的 mH 属性
           op=lambda x: x.mH,
           # 别名列表，这里包含 'adjoint'
           aliases=('adjoint',),
           # 支持的数据类型，包括所有类型以及特定的 torch 类型
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.half, torch.chalf),
           # 在慢速梯度检查时使用快速模式，或者可以减少输入大小以提高速度
           gradcheck_fast_mode=True,
           # 不支持输出
           supports_out=False,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向梯度的一致性
           supports_fwgrad_bwgrad=True,
           # 查看链接以了解更多信息
           check_batched_forward_grad=False,
           # 跳过的测试用例列表，这里包含一些预期失败的测试用例
           skips=(
               # lambda 实现的预期失败测试
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               DecorateInfo(unittest.expectedFailure, "TestJit", "test_variant_consistency_jit"),
           ),
           # 采样输入函数，用于生成输入示例
           sample_inputs_func=sample_inputs_adjoint),
           
    # OpInfo 类的实例化，描述操作 'tril' 的信息
    OpInfo('tril',
           # 支持的数据类型，包括所有类型以及特定的 torch 类型
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向梯度的一致性
           supports_fwgrad_bwgrad=True,
           # 错误输入生成函数
           error_inputs_func=error_inputs_tril_triu,
           # 采样输入函数，用于生成输入示例
           sample_inputs_func=sample_inputs_tril_triu),

    # OpInfo 类的实例化，描述操作 'triu' 的信息
    OpInfo('triu',
           # 支持的数据类型，包括所有类型以及特定的 torch 类型
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf),
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向梯度的一致性
           supports_fwgrad_bwgrad=True,
           # 错误输入生成函数
           error_inputs_func=error_inputs_tril_triu,
           # 采样输入函数，用于生成输入示例
           sample_inputs_func=sample_inputs_tril_triu),

    # OpInfo 类的实例化，描述操作 'triu_indices' 的信息
    OpInfo('triu_indices',
           # 数据类型，这里根据 torch 的分发选择特定类型
           dtypes=_dispatch_dtypes((torch.int32, torch.int64)),
           # 采样输入函数，用于生成输入示例
           sample_inputs_func=sample_inputs_trilu_indices,
           # 参考实现函数，返回 np.triu_indices 的结果
           ref=lambda h, w, ofs=0, dtype=torch.long, device='cpu' : np.array(np.triu_indices(h, ofs, w), dtype=dtype),
           # 不支持输出
           supports_out=False,
           # 不支持自动微分
           supports_autograd=False,
           # 跳过的测试用例列表，这里包含一些预期失败的测试用例
           skips=(
               # 因为有非张量输入而跳过的测试用例
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_noncontiguous_samples'),
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.skip('Skipped!'), 'TestJit', 'test_variant_consistency_jit'),
               DecorateInfo(unittest.skip('Skipped!'), 'TestMathBits', 'test_neg_view'),
           )),
    # 定义 OpInfo 对象，描述 torch.tril_indices 函数的测试信息
    OpInfo('tril_indices',
           # 指定支持的数据类型为 torch.int32 和 torch.int64
           dtypes=_dispatch_dtypes((torch.int32, torch.int64)),
           # 指定生成样本输入的函数为 sample_inputs_trilu_indices
           sample_inputs_func=sample_inputs_trilu_indices,
           # 定义引用函数，生成 np.tril_indices 返回的 numpy 数组
           ref=lambda h, w, ofs=0, dtype=torch.long, device='cpu' : np.array(np.tril_indices(h, ofs, w), dtype=dtype),
           # 不支持输出参数
           supports_out=False,
           # 不支持自动微分
           supports_autograd=False,
           # 跳过以下测试，因为输入不是张量
           skips=(
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_noncontiguous_samples'),
               DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_variant_consistency_eager'),
               DecorateInfo(unittest.skip('Skipped!'), 'TestJit', 'test_variant_consistency_jit'),
               DecorateInfo(unittest.skip('Skipped!'), 'TestMathBits', 'test_neg_view'),
           )),
    # 定义 OpInfo 对象，描述 torch.kron 函数的测试信息
    OpInfo('kron',
           # 支持的数据类型包括所有类型和复数，并且包括 torch.bool, torch.half, torch.bfloat16
           dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
           # CUDA 支持的数据类型与上述相同
           dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16),
           # 快速梯度检查模式
           gradcheck_fast_mode=True,
           # 不支持原地自动微分
           supports_inplace_autograd=False,
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向梯度
           supports_fwgrad_bwgrad=True,
           # 指定生成样本输入的函数为 sample_inputs_kron
           sample_inputs_func=sample_inputs_kron,
           # 修饰器，预期这个测试会失败，因为视图大小与输入张量的大小和步幅不兼容
           decorators=(
               DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides"),
           )),
    # 定义 OpInfo 对象，描述 torch.inner 函数的测试信息
    OpInfo('inner',
           # 支持所有类型和复数，并且包括 torch.float16, torch.bfloat16
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           # 如果在 CUDA 环境下，支持的数据类型包括浮点数和复数类型，不包括 torch.float16 和 torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           # 如果在 ROCM 环境下，支持的数据类型包括半精度和 bfloat16 类型
           dtypesIfROCM=floating_and_complex_types_and(torch.half, torch.bfloat16),
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向梯度
           supports_fwgrad_bwgrad=True,
           # 不检查批处理的前向梯度
           check_batched_forward_grad=False,
           # 指定生成样本输入的函数为 sample_inputs_inner
           sample_inputs_func=sample_inputs_inner,
           ),
    # 定义 OpInfo 对象，描述 torch.tensordot 函数的测试信息
    OpInfo('tensordot',
           # 支持所有类型和复数，并且包括 torch.float16, torch.bfloat16
           dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),
           # 如果在 CUDA 环境下，支持的数据类型包括浮点数和复数类型，不包括 torch.float16 和 torch.bfloat16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),
           # 如果在 ROCM 环境下，支持的数据类型包括半精度和 bfloat16 类型
           dtypesIfROCM=floating_and_complex_types_and(torch.half, torch.bfloat16),
           # 支持前向自动微分
           supports_forward_ad=True,
           # 支持前向和反向梯度
           supports_fwgrad_bwgrad=True,
           # 不检查批处理的前向梯度
           check_batched_forward_grad=False,
           # 指定生成样本输入的函数为 sample_inputs_tensordot
           sample_inputs_func=sample_inputs_tensordot,
           # 跳过操作符模式测试，因为这是一个功能而不是一个操作符
           skips=(
               DecorateInfo(unittest.skip("Skipped!"), 'TestOperatorSignatures', 'test_get_torch_func_signature_exhaustive'),
           )
           ),
    OpInfo('to_sparse',  # 定义一个操作信息对象，名称为'to_sparse'
           op=lambda x, *args: x.to_sparse(*args),  # 操作函数定义为将输入 x 转换为稀疏张量的函数
           sample_inputs_func=sample_inputs_to_sparse,  # 样本输入生成函数为 sample_inputs_to_sparse
           dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括所有类型以及 torch.bool, torch.float16, torch.bfloat16
           backward_dtypes=floating_types(),  # 反向传播时支持的浮点数数据类型
           backward_dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),  # 如果在 CUDA 上，则支持的浮点数数据类型包括 torch.float16 和 torch.bfloat16
           supports_out=False,  # 不支持输出参数 out
           supports_sparse_csr=True,  # 支持稀疏格式 CSR
           supports_sparse_csc=True,  # 支持稀疏格式 CSC
           check_batched_grad=False,  # 不检查批量梯度
           check_batched_gradgrad=False,  # 不检查批量梯度二阶导数
           skips=(  # 跳过以下测试用例
               # NotImplementedError: Could not run 'aten::normal_' with arguments from the 'SparseCPU' backend
               DecorateInfo(unittest.skip(""), 'TestCommon', 'test_noncontiguous_samples'),  # 跳过测试用例 'TestCommon' 中的 'test_noncontiguous_samples'
               # TODO: FIXME: complex inputs requiring grad error in forward
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_dtypes'),  # 跳过测试用例 'TestCommon' 中的 'test_dtypes'
               # lambda impl
               DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 标记测试用例 'TestNormalizeOperators' 中的 'test_normalize_operator_exhaustive' 为预期失败
               # Allowed exception: sparse tensors don't have strides
               DecorateInfo(unittest.skip("Allowed exception"), 'TestCompositeCompliance', 'test_operator'),  # 跳过测试用例 'TestCompositeCompliance' 中的 'test_operator'
               DecorateInfo(unittest.skip("Allowed exception"), 'TestCompositeCompliance', 'test_backward'),  # 跳过测试用例 'TestCompositeCompliance' 中的 'test_backward'
               DecorateInfo(unittest.skip("Allowed exception"), 'TestTags', 'test_tags'),  # 跳过测试用例 'TestTags' 中的 'test_tags'
               # TODO: implement csr.to_sparse(sample_dim) where sampled_dim is 1.
               DecorateInfo(unittest.skip("csr.to_sparse(1) not implemented. Skipped!"),  # 跳过测试用例 'TestSparseCSR' 中的 'test_sparse_csr_consistency'，理由是 'csr.to_sparse(1)' 没有实现
                            'TestSparseCSR', 'test_sparse_csr_consistency'),
               # Compiler issue on ROCm. Might need to skip until ROCm5.5
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_non_standard_bool_values',  # 跳过测试用例 'TestCommon' 中的 'test_non_standard_bool_values'，在 ROCm 下可能有编译器问题，可能需要等到 ROCm 5.5
                            dtypes=[torch.bool], active_if=TEST_WITH_ROCM),
           )
           ),
    OpInfo('logcumsumexp',  # 定义操作信息对象，名称为'logcumsumexp'
           dtypes=floating_and_complex_types_and(torch.bfloat16, torch.half),  # 支持的数据类型包括浮点数和复数类型，以及特定的torch数据类型
           backward_dtypes=floating_and_complex_types_and(torch.bfloat16),  # 反向传播支持的数据类型包括浮点数和复数类型，以及特定的torch数据类型
           backward_dtypesIfCUDA=floating_and_complex_types_and(torch.bfloat16),  # 如果在CUDA下，反向传播支持的数据类型包括浮点数和复数类型，以及特定的torch数据类型
           supports_forward_ad=True,  # 支持正向自动微分
           supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
           skips=(  # 跳过的测试用例集合
               # 当未触发UserWarning时抛出AssertionError：“Resized a non-empty tensor but did not warn about it.”
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning', device_type='cuda'),
               # 当'ComplexDouble'类型未实现"max_values_cpu"操作时抛出RuntimeError，导致结果中出现NaN
               DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', 'test_forward_mode_AD', dtypes=[torch.complex128]),
               DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', 'test_fn_fwgrad_bwgrad', dtypes=[torch.complex128]),
           ),
           sample_inputs_func=sample_inputs_logcumsumexp,  # 样本输入函数为sample_inputs_logcumsumexp
           error_inputs_func=error_inputs_logcumsumexp),  # 错误输入函数为error_inputs_logcumsumexp

    UnaryUfuncInfo('sigmoid',  # 定义一元ufunc信息对象，名称为'sigmoid'
                   aliases=('special.expit', 'nn.functional.sigmoid'),  # 别名列表包括'special.expit'和'nn.functional.sigmoid'
                   aten_backward_name='sigmoid_backward',  # ATen反向传播函数名称为'sigmoid_backward'
                   ref=reference_sigmoid if TEST_SCIPY else None,  # 如果TEST_SCIPY为真，则参考实现为reference_sigmoid，否则为None
                   decorators=(  # 修饰器元组
                       precisionOverride({torch.float16: 1e-2,
                                          torch.complex64: 1e-1,
                                          torch.bfloat16: 1e-2}),  # 精度覆盖字典，指定不同类型的数值精度
                   ),
                   skips=(  # 跳过的测试用例集合
                       # 参考链接：https://github.com/pytorch/pytorch/issues/56012
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=[torch.complex64, torch.cdouble]),  # 当类型为torch.complex64或torch.cdouble时跳过'test_reference_numerics_extremal'
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=[torch.chalf, torch.complex64, torch.cdouble])),  # 当类型为torch.chalf、torch.complex64或torch.cdouble时跳过'test_reference_numerics_large'
                   dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括所有类型和复数，还有特定的torch数据类型
                   dtypesIfCUDA=all_types_and_complex_and(torch.complex32, torch.bool, torch.half, torch.bfloat16),  # 在CUDA下支持的数据类型包括所有类型和复数，还有特定的torch数据类型
                   supports_forward_ad=True,  # 支持正向自动微分
                   supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
                   promotes_int_to_float=True,  # 将整数类型提升为浮点数
                   assert_autodiffed=True,  # 断言自动微分已完成
                   # sigmoid(z) = 1 / (1 + exp(-z)), 当z = j * pi * 奇数时，分母为零
                   reference_numerics_filter=NumericsFilter(
                       condition=lambda x: (close_to_int(x / (math.pi * 1j))
                                            if x.is_complex() else x.new_tensor(False, dtype=torch.bool)),  # 数值过滤器条件函数，检查是否为复数，并且是否接近整数倍
                       safe_val=0)),  # 安全值为0，用于处理特殊情况
    UnaryUfuncInfo('digamma',
                   ref=scipy.special.digamma if TEST_SCIPY else None,
                   aliases=('special.psi', 'special.digamma',),
                   decorators=(precisionOverride({torch.float16: 5e-1}),),
                   dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   dtypesIfCUDA=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   promotes_int_to_float=True),

创建一个名为 'digamma' 的一元函数信息对象，包括参考实现、别名、修饰器、支持的数据类型、CUDA情况下的数据类型、是否支持前向自动微分、是否支持前向-梯度后向-梯度、是否将整数转换为浮点数。


    UnaryUfuncInfo('erf',
                   ref=scipy.special.erf if TEST_SCIPY else None,
                   aliases=('special.erf', ),
                   decorators=(precisionOverride({torch.float16: 1e-2,
                                                  torch.bfloat16: 1e-2}),),
                   skips=(
                       DecorateInfo(unittest.skip("Skipped! sparse backward not supported"),
                                    'TestSparseUnaryUfuncs', 'test_sparse_fn_grad'),

                   ),
                   dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   assert_autodiffed=True,
                   assert_jit_shape_analysis=True,
                   supports_sparse=True,
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   promotes_int_to_float=True),

创建一个名为 'erf' 的一元函数信息对象，包括参考实现、别名、修饰器、跳过的测试信息（用于指示某些测试被跳过）、支持的数据类型、自动微分断言、JIT形状分析断言、支持稀疏张量、支持的稀疏格式、是否支持前向自动微分、是否支持前向-梯度后向-梯度、是否将整数转换为浮点数。


    UnaryUfuncInfo('erfc',
                   ref=scipy.special.erfc if TEST_SCIPY else None,
                   aliases=('special.erfc', ),
                   decorators=(precisionOverride({torch.float16: 1e-2,
                                                  torch.bfloat16: 1e-2}),),
                   dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   assert_autodiffed=True,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   promotes_int_to_float=True),

创建一个名为 'erfc' 的一元函数信息对象，包括参考实现、别名、修饰器、支持的数据类型、自动微分断言、是否支持前向自动微分、是否支持前向-梯度后向-梯度、是否将整数转换为浮点数。
    UnaryUfuncInfo('erfinv',
                   ref=scipy.special.erfinv if TEST_SCIPY else None,
                   aliases=('special.erfinv', ),
                   decorators=(precisionOverride({torch.float16: 1e-2,
                                                  torch.bfloat16: 1e-2,
                                                  torch.float32: 1e-4}),),
                   dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   dtypesIfCUDA=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   supports_sparse_csr=True,
                   supports_sparse_csc=True,
                   supports_sparse_bsr=True,
                   supports_sparse_bsc=True,
                   supports_forward_ad=True,
                   supports_fwgrad_bwgrad=True,
                   promotes_int_to_float=True,
                   domain=(-1, 1),
                   skips=(
                       # 根据条件跳过特定测试用例，具体参考注释中的链接
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    active_if=TEST_SCIPY and version.parse(scipy.__version__) < version.parse("1.4.0")),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    active_if=TEST_SCIPY and version.parse(scipy.__version__) < version.parse("1.4.0")),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_small',
                                    active_if=TEST_SCIPY and version.parse(scipy.__version__) < version.parse("1.4.0")),
                   )),
    OpInfo("nn.functional.smooth_l1_loss",
           ref=reference_smooth_l1_loss,
           sample_inputs_func=sample_inputs_smooth_l1_loss,
           dtypes=floating_types_and(torch.float16, torch.bfloat16),
           backward_dtypes=floating_types_and(torch.bfloat16),
           dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           backward_dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
           supports_out=False,
           supports_forward_ad=True,
           supports_fwgrad_bwgrad=True,
           skips=(
               # 根据错误情况跳过特定测试用例，这是一个已知的 bug
               DecorateInfo(unittest.expectedFailure, "TestJit", "test_variant_consistency_jit"),)),
    # 定义 OpInfo 对象，描述了 nn.functional.l1_loss 操作的测试信息
    OpInfo(
        "nn.functional.l1_loss",
        # 设置参考函数为 loss_reference_reduction_wrapper，用于计算输入和目标之间的绝对差值
        ref=loss_reference_reduction_wrapper(lambda input, target: np.abs(input - target)),
        # 设置样本输入生成函数为 sample_inputs_l1_loss
        sample_inputs_func=sample_inputs_l1_loss,
        # 设置错误输入生成函数为 error_inputs_l1_loss
        error_inputs_func=error_inputs_l1_loss,
        # 指定支持的数据类型为浮点数和复数类型，以及 torch.float16 和 torch.bfloat16
        dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),
        # 不支持输出参数
        supports_out=False,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 支持前向梯度和反向梯度
        supports_fwgrad_bwgrad=True,
        # 定义跳过测试的情况，包括特定的错误和条件
        skips=(
            # 当出现特定 RuntimeError 错误时跳过测试
            DecorateInfo(
                unittest.expectedFailure,
                "TestJit",
                "test_variant_consistency_jit",
                dtypes=(torch.float32,),
            ),
        ),
    ),
    # 定义 UnaryUfuncInfo 对象，描述了 'lgamma' 操作的测试信息
    UnaryUfuncInfo('lgamma',
                   # 设置参考函数为 reference_lgamma（如果 TEST_SCIPY 为真）
                   ref=reference_lgamma if TEST_SCIPY else None,
                   # 设置别名为 'special.gammaln'
                   aliases=('special.gammaln', ),
                   # 设置修饰器为 precisionOverride，应用于 torch.float16 类型
                   decorators=(precisionOverride({torch.float16: 7e-1}),),
                   # 指定所有数据类型和 torch.bool、torch.half、torch.bfloat16
                   dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   # 指定 CUDA 环境下的数据类型
                   dtypesIfCUDA=all_types_and(torch.bool, torch.half, torch.bfloat16),
                   # 支持前向自动微分
                   supports_forward_ad=True,
                   # 支持前向梯度和反向梯度
                   supports_fwgrad_bwgrad=True,
                   # 将整数提升为浮点数
                   promotes_int_to_float=True,
                   # 定义跳过测试的情况，包括特定的测试类和方法，以及操作系统条件
                   skips=(
                       # 当满足特定条件时跳过测试，详细信息在链接中指定
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                                    dtypes=[torch.float32, torch.float64], active_if=IS_WINDOWS),
                       DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                                    dtypes=[torch.float32, torch.float64], active_if=IS_WINDOWS),
                   ),
                   # lgamma 在 x <= 0 时具有多个奇点
                   reference_numerics_filter=NumericsFilter(condition=lambda x: x < 0.1, safe_val=1)),
    # 定义 OpInfo 对象，描述了 'logdet' 操作的测试信息
    OpInfo(
        'logdet',
        # 指定浮点数和复数类型的数据类型
        dtypes=floating_and_complex_types(),
        # 不支持输出参数
        supports_out=False,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 支持前向梯度和反向梯度
        supports_fwgrad_bwgrad=True,
        # 设置样本输入生成函数为 sample_inputs_linalg_det_logdet_slogdet
        sample_inputs_func=sample_inputs_linalg_det_logdet_slogdet,
        # 设置修饰器为 skipCUDAIfNoMagma 和 skipCPUIfNoLapack
        decorators=[skipCUDAIfNoMagma, skipCPUIfNoLapack]),
    # 单独注释：`log_softmax` 操作基于是否传递 `dtype` 参数支持不同的数据类型。因此有两个 OpInfo 条目，一个带有 dtype，另一个没有。
    OpInfo(
        'log_softmax',  # 操作名称为 'log_softmax'
        aliases=('special.log_softmax', 'nn.functional.log_softmax'),  # 别名列表
        supports_out=True,  # 支持输出参数
        aten_backward_name='_log_softmax_backward_data',  # 在 ATen 后端的反向传播函数名称
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 支持的数据类型，包括浮点类型和 torch.float16, torch.bfloat16
        sample_inputs_func=sample_inputs_softmax_variant,  # 用于生成示例输入的函数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
        assert_autodiffed=True),  # 断言自动微分已正确实现
    
    OpInfo(
        'log_softmax',  # 操作名称为 'log_softmax'
        variant_test_name='with_dtype',  # 变体测试名称为 'with_dtype'
        aliases=('special.log_softmax', 'nn.functional.log_softmax'),  # 别名列表
        supports_out=True,  # 支持输出参数
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 支持的数据类型，包括所有类型以及复数和特定的 torch 类型
        sample_inputs_func=partial(sample_inputs_softmax_variant, with_dtype=True),  # 用于生成示例输入的函数，带有数据类型参数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
        assert_autodiffed=True),  # 断言自动微分已正确实现
    
    UnaryUfuncInfo(
        'logit',  # 操作名称为 'logit'
        aten_backward_name='logit_backward',  # 在 ATen 后端的反向传播函数名称
        ref=scipy.special.logit if TEST_SCIPY else None,  # 参考实现，若 TEST_SCIPY 为真则使用 scipy 的 logit 函数
        domain=(0, 1),  # 取值域为 (0, 1)
        aliases=('special.logit', ),  # 别名列表
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
        promotes_int_to_float=True,  # 提升整数到浮点数
        decorators=(precisionOverride({torch.bfloat16: 5e-1, torch.float16: 5e-1}), ),  # 修饰器，精度覆盖设置
        dtypes=all_types_and(torch.bool, torch.half, torch.bfloat16),  # 支持的数据类型，包括所有类型和特定的 torch 类型
        sample_inputs_func=sample_inputs_logit),  # 用于生成示例输入的函数
    
    OpInfo(
        'where',  # 操作名称为 'where'
        # 当前仅对 `input` 进行梯度检查。
        # 如果我们先传递 `condition`，则所有支持自动微分的输入将不会被测试。
        # 因此采用以下 lambda 函数。
        op=lambda self, condition, other, **kwargs: torch.where(condition, self, other, **kwargs),  # 操作实现的 lambda 函数
        ref=lambda self, condition, other: np.where(condition, self, other),  # 参考实现的函数
        sample_inputs_func=sample_inputs_where,  # 用于生成示例输入的函数
        reference_inputs_func=reference_inputs_where,  # 参考输入生成函数
        error_inputs_func=error_inputs_where,  # 错误输入生成函数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
        decorators=(  # 修饰器列表
            DecorateInfo(onlyCUDA, "TestCommon", 'test_errors'),  # 仅在 CUDA 环境下进行修饰
        ),
        skips=(  # 跳过测试的条件列表
            # lambda 实现
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期的测试失败
            DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),  # 被跳过的测试
        ),
        dtypes=all_types_and_complex_and(torch.bool, torch.half, torch.bfloat16, torch.chalf)  # 支持的数据类型，包括所有类型和特定的 torch 类型
    ),
    OpInfo('nonzero',
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
           sample_inputs_func=sample_inputs_nonzero,
           supports_autograd=False,
           skips=(
               DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
               # nonzero(): argument 'out' must be Tensor, not tuple
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
               # https://github.com/pytorch/pytorch/issues/67458
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
               # nonzero is not raising a warning when the out is resized
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               # Can't find schemas for this operator for some reason
               DecorateInfo(unittest.expectedFailure, 'TestOperatorSignatures', 'test_get_torch_func_signature_exhaustive'),
               # Compiler issue on ROCm. Might need to skip until ROCm5.5
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_non_standard_bool_values',
                            dtypes=[torch.bool], active_if=TEST_WITH_ROCM),
           )),



    OpInfo('nonzero_static',
           dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16, torch.chalf),
           sample_inputs_func=sample_inputs_nonzero_static,
           supports_out=False,
           supports_autograd=False,
           decorators=[onlyCPU],
           skips=(
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
               DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out_warning'),
               DecorateInfo(unittest.expectedFailure, 'TestDTensorOps', 'test_dtensor_op_db'),
               DecorateInfo(unittest.expectedFailure, 'TestInductorOpInfo', 'test_comprehensive'),
               DecorateInfo(unittest.expectedFailure, 'TestVmapOperatorsOpInfo', 'test_op_has_batch_rule'),
               DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_non_standard_bool_values',
                            dtypes=[torch.bool], active_if=TEST_WITH_ROCM),
           )),



    # Following tests are for jiterator's python interface
    # Jiterator can be used to author elementwise CUDA kernel
    # jiterator._create_jit_fn returns a callable that behaves like a regular pytorch op
    # See create_jit_fn in jiterator.py for more information
    # 定义一个包含一元函数信息的对象，用于 jiterator_unary 操作
    UnaryUfuncInfo(
        'jiterator_unary',  # 操作的名称为 jiterator_unary
        op=torch.cuda.jiterator._create_jit_fn("template <typename T> T unary(T x) { return x * x + x; }"),  # 创建并返回一个 JIT 函数，该函数对输入 x 执行 x * x + x 操作
        ref=lambda x: x * x + x,  # 参考实现的 Python 函数，执行 x * x + x 操作
        dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16, torch.bool),  # 支持的数据类型，包括 torch.bfloat16, torch.float16 和 torch.bool
        supports_out=False,  # 不支持输出参数
        supports_autograd=False,  # 不支持自动求导，因为 jiterator 操作没有定义反向传播
        decorators=[
            onlyCUDA,  # 仅在 CUDA 环境下运行
            DecorateInfo(toleranceOverride({torch.float16: tol(atol=1e-02, rtol=1e-02)}),
                         'TestUnaryUfuncs', 'test_reference_numerics_extremal'),  # 设置测试的数值容差和测试名称
            DecorateInfo(toleranceOverride({torch.float16: tol(atol=1e-02, rtol=1e-02)}),
                         'TestUnaryUfuncs', 'test_reference_numerics_hard'),  # 设置测试的数值容差和测试名称
            DecorateInfo(toleranceOverride({torch.float16: tol(atol=1e-02, rtol=1e-02)}),
                         'TestUnaryUfuncs', 'test_reference_numerics_normal'),  # 设置测试的数值容差和测试名称
            DecorateInfo(toleranceOverride({torch.float16: tol(atol=1e-02, rtol=1e-02)}),
                         'TestUnaryUfuncs', 'test_reference_numerics_small'),  # 设置测试的数值容差和测试名称
        ],
        skips=(
            # 不支持 neg 或 conj 视图
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 预期失败的测试用例，测试负视图
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 预期失败的测试用例，测试共轭视图
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),  # 预期失败的测试用例，测试负共轭视图
            # 不支持 CompositeCompliantTensor
            # 下面的测试用例应该预期失败，但在 CUDA 中会导致连锁失败，因此被跳过
            DecorateInfo(unittest.skip("skip"), 'TestCompositeCompliance', 'test_operator'),  # 跳过测试，测试操作符
            # 对于 bool 类型，跳过 reference_numerics 测试，因为定义的函数对 bool 类型不起作用
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                         dtypes=[torch.bool]),  # 跳过测试，测试极端数值
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_hard',
                         dtypes=[torch.bool]),  # 跳过测试，测试困难数值
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_normal',
                         dtypes=[torch.bool]),  # 跳过测试，测试普通数值
            # 对于 complex64，ROCm 生成 -inf+infj 而不是 nan+infj，因此部分结果预期失败
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_large',
                         dtypes=[torch.complex64], active_if=TEST_WITH_ROCM),  # 跳过测试，测试大数值
            # 预期失败：torch.jiterator_unary 不是一个有效的操作
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的 JIT 一致性测试
            # 跳过 Nvfuser 测试
            DecorateInfo(unittest.skip('Skipped!'), 'TestCudaFuserOpInfo'),  # 跳过 CUDA 合并操作信息测试
        ]
    ),
    BinaryUfuncInfo(
        'jiterator_binary',  # 定义二元ufunc的信息对象，名称为'jiterator_binary'
        op=torch.cuda.jiterator._create_jit_fn(  # 创建CUDA JIT函数，实现模板中的二元操作
            "template <typename T> T binary(T x, T y, T alpha) { return x + alpha * y; }", alpha=1),
        ref=lambda input, other, *, alpha=1: np.add(input, other) if alpha == 1 \
            else np.add(input, np.multiply(alpha, other)),  # 引用实现，根据alpha条件选择加法或加权加法
        dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16, torch.bool),  # 支持的数据类型
        sample_inputs_func=partial(sample_inputs_jiterator, num_inputs=2, alpha=-3.14),  # 生成样本输入的函数
        supports_out=False,  # 不支持输出张量的位置参数
        supports_autograd=False,  # 不支持自动求导
        supports_rhs_python_scalar=False,  # 不支持右侧Python标量
        decorators=[onlyCUDA],  # 使用CUDA装饰器修饰
        skips=(
            # 下列测试用例预期失败，因为jiterator操作不支持neg或conj视图
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
            # jiterator操作不支持CompositeCompliantTensor，此测试应该预期失败，但会导致CUDA中的级联失败，因此跳过
            DecorateInfo(unittest.skip("skip"), 'TestCompositeCompliance', 'test_operator'),
            # 预期失败：torch.jiterator_binary 不是有效操作
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            # 跳过Nvfuser
            DecorateInfo(unittest.skip('Skipped!'), 'TestCudaFuserOpInfo'),
        )
    ),
    OpInfo(
        # 定义操作名称为 'jiterator_4inputs_with_extra_args'
        'jiterator_4inputs_with_extra_args',
        # 使用 torch.cuda.jiterator._create_jit_fn 函数创建 JIT 函数对象，定义模板和参数 alpha=1, beta=1
        op=torch.cuda.jiterator._create_jit_fn(
            "template <typename T> T binary(T i0, T i1, T i2, T i3, T alpha, T beta) { return alpha * i0 + beta * i1 + i2 + i3; }",
            alpha=1, beta=1),
        # 定义操作的参考实现函数，计算 alpha * i0 + beta * i1 + i2 + i3，参数 alpha 和 beta 默认为 1
        ref=lambda i0, i1, i2, i3, *, alpha=1, beta=1: alpha * i0 + beta * i1 + i2 + i3,
        # 指定操作支持的数据类型，包括所有类型和 torch.bfloat16, torch.float16, torch.bool
        dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16, torch.bool),
        # 使用 partial 函数设置 sample_inputs_func，从 sample_inputs_jiterator 函数获取样本输入，num_inputs=4, alpha=3.14, beta=-4.20
        sample_inputs_func=partial(sample_inputs_jiterator, num_inputs=4, alpha=3.14, beta=-4.20),
        # 指定操作不支持输出
        supports_out=False,
        # 指定操作不支持自动微分
        supports_autograd=False,  # jiterator ops doesn't have backward defined
        # 设置装饰器，仅在 CUDA 环境下使用
        decorators=[onlyCUDA],
        # 设置跳过的测试用例元组
        skips=(
            # Jiterator 操作不支持负或共轭视图，标记 'TestMathBits' 测试类的 'test_neg_view' 为预期失败
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
            # 同上，标记 'test_conj_view' 为预期失败
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
            # 同上，标记 'test_neg_conj_view' 为预期失败
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
            # Jiterator 操作不支持 CompositeCompliantTensor，跳过 'TestCompositeCompliance' 的 'test_operator' 测试用例
            DecorateInfo(unittest.skip("skip"), 'TestCompositeCompliance', 'test_operator'),
            # 预期失败：torch.jiterator_4inputs_with_extra_args 不是有效的操作，标记 'TestJit' 的 'test_variant_consistency_jit' 测试用例为预期失败
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            # 跳过 Nvfuser 测试，标记 'TestCudaFuserOpInfo' 测试类
            DecorateInfo(unittest.skip('Skipped!'), 'TestCudaFuserOpInfo'),
        )
    ),
    # 创建一个 BinaryUfuncInfo 对象，描述一个二元操作的函数信息
    BinaryUfuncInfo(
        'jiterator_binary_return_by_ref',  # 函数名标识符
        op=torch.cuda.jiterator._create_multi_output_jit_fn(
            """
            template <typename T>
            void binary_return_by_ref(T i0, T i1, T& out0) {
                out0 = i0 + i1;
            }
            """,  # 使用 C++ 模板定义的函数，实现将 i0 和 i1 相加并将结果存储到 out0 中
            num_outputs=1),  # 函数输出的数量
        ref=operator.add,  # Python 中的加法运算符，作为参考实现
        dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16, torch.bool),  # 支持的数据类型
        sample_inputs_func=partial(sample_inputs_jiterator, num_inputs=2, alpha=-0.42),  # 生成示例输入的函数
        supports_out=False,  # 不支持输出参数
        supports_autograd=False,  # 不支持自动求导
        supports_rhs_python_scalar=False,  # 不支持右操作数为 Python 标量
        decorators=[onlyCUDA],  # 修饰符列表，只在 CUDA 环境下有效
        skips=(
            # 下面是一些测试的装饰信息，用于标记不同测试用例的预期结果
            # Jiterator 操作不支持负数或共轭视图
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
            # Jiterator 操作不支持 CompositeCompliantTensor，以下测试应该预期失败，
            # 但在 CUDA 中会引起连锁失败，因此被跳过
            DecorateInfo(unittest.skip("skip"), 'TestCompositeCompliance', 'test_operator'),
            # 预期失败：torch.jiterator_4inputs_with_extra_args 不是有效的操作
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            # 跳过 Nvfuser
            DecorateInfo(unittest.skip('Skipped!'), 'TestCudaFuserOpInfo'),
        )
    ),
    OpInfo(
        'jiterator_2inputs_2outputs',  # 操作名称为 'jiterator_2inputs_2outputs'
        op=torch.cuda.jiterator._create_multi_output_jit_fn(
            """
            template <typename T>
            void binary_2outputs(T i0, T i1, T& out0, T& out1) {
                out0 = i0 + i1;  // 计算输入 i0 和 i1 的和，结果存入 out0
                out1 = i0 - i1;  // 计算输入 i0 和 i1 的差，结果存入 out1
            }
            """,
            num_outputs=2),  # 声明操作有两个输出
        ref=lambda i0, i1, *, alpha=1: (i0 + i1, i0 - i1),  # 参考实现，用于验证操作的正确性
        dtypes=all_types_and_complex_and(torch.bfloat16, torch.float16, torch.bool),  # 支持的数据类型
        sample_inputs_func=partial(sample_inputs_jiterator, num_inputs=2),  # 生成样本输入的函数
        supports_out=False,  # 不支持输出参数
        supports_autograd=False,  # 不支持自动求导
        decorators=[onlyCUDA],  # 修饰器，仅限于 CUDA 环境
        skips=(
            # 不支持负视图或共轭视图
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
            # 不支持 CompositeCompliantTensor，以下测试应该失败，但在 CUDA 环境中跳过
            DecorateInfo(unittest.skip("skip"), 'TestCompositeCompliance', 'test_operator'),
            # 预期失败：torch.jiterator_4inputs_with_extra_args 不是有效的操作
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            # 跳过 Nvfuser
            DecorateInfo(unittest.skip('Skipped!'), 'TestCudaFuserOpInfo'),
        )
    ),
    # `torch.norm` 有多条代码路径，取决于 `p` 的值，支持的数据类型也不同。
    # JIT 支持大多数变体，但不支持所有，因此我们基于代码路径和 JIT 的支持，拆分 OpInfo 条目。
    OpInfo(
        "norm",  # 操作名称为 "norm"
        sample_inputs_func=sample_inputs_norm,  # 生成 norm 操作的样本输入的函数
        dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),  # 支持的浮点数和复数数据类型
        gradcheck_fast_mode=True,  # 使用快速模式进行梯度检查
        check_batched_forward_grad=False,  # 不检查批处理的前向梯度
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        skips=(
            # 在 Python 中分派到 vector_norm，不确定如何使此测试通过
            # 在 complex64 上偶尔通过，这也是一个谜
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',
                         dtypes=(torch.float32,)),)
    ),
    OpInfo('norm',  # 创建一个 OpInfo 对象，用于描述某种规范化操作的测试信息
           variant_test_name='nuc',  # 指定规范化操作的变体名称为 'nuc'
           sample_inputs_func=sample_inputs_norm_nuc,  # 设置获取样本输入的函数为 sample_inputs_norm_nuc
           decorators=[skipCUDAIfNoMagmaAndNoCusolver, skipCPUIfNoLapack],  # 添加装饰器函数列表，用于条件跳过测试
           check_batched_gradgrad=False,  # 禁用批量梯度检查
           check_batched_forward_grad=False,  # 禁用批量前向梯度检查
           supports_forward_ad=True,  # 指示支持前向自动微分
           supports_fwgrad_bwgrad=True,  # 指示支持前向梯度与反向梯度一致性测试
           dtypes=floating_and_complex_types(),  # 指定操作支持的数据类型为浮点数和复数类型
           dtypesIfCUDA=floating_and_complex_types(),  # 指定在CUDA环境下支持的数据类型与CPU环境一致
           skips=(  # 设置跳过的测试条件列表
               # 在 Python 中调度到 matrix_norm 时存在问题，未能解决该测试的方式尚不清楚
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',
                            dtypes=(torch.complex64, torch.float32,)),)
           ),
    OpInfo('norm',  # 创建另一个 OpInfo 对象，描述另一种规范化操作的测试信息
           variant_test_name='fro',  # 指定规范化操作的变体名称为 'fro'
           sample_inputs_func=sample_inputs_norm_fro,  # 设置获取样本输入的函数为 sample_inputs_norm_fro
           dtypes=floating_and_complex_types_and(torch.bfloat16, torch.float16),  # 指定操作支持的数据类型为浮点数、复数以及 bfloat16 和 float16
           dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16),  # 指定在CUDA环境下支持的数据类型
           supports_forward_ad=True,  # 指示支持前向自动微分
           check_batched_forward_grad=False,  # 禁用批量前向梯度检查
           supports_fwgrad_bwgrad=True,  # 指示支持前向梯度与反向梯度一致性测试
           skips=(  # 设置跳过的测试条件列表
               # 对于 float16 存在一些精度问题，将容差调整为原来的十分之一
               DecorateInfo(
                   toleranceOverride({torch.float16: tol(atol=1e-4, rtol=0.01)}),
                   'TestConsistency',
                   'test_output_match',
               ),
               # 存在与 conj 和 torch 调度相关的问题，详见 GitHub 上的 issue
               DecorateInfo(
                   unittest.skip("Skipped!"),
                   'TestSchemaCheckModeOpInfo',
                   'test_schema_correctness',
                   dtypes=(torch.complex64, torch.complex128)),
               # 在 Python 中调度到 vector_norm 时存在问题，未能解决该测试的方式尚不清楚
               DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit',
                            dtypes=(torch.complex64, torch.float32,)),)
           ),
    OpInfo(
        "norm",  # 操作类型为 "norm"
        variant_test_name="inf",  # 变体测试名称为 "inf"
        sample_inputs_func=sample_inputs_norm_inf,  # 使用 sample_inputs_norm_inf 函数生成样本输入
        dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),  # 数据类型包括浮点数和复数类型以及 torch.float16 和 torch.bfloat16
        supports_forward_ad=True,  # 支持前向自动求导
        check_batched_forward_grad=False,  # 不检查批处理的前向梯度
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
        gradcheck_fast_mode=False,  # 快速梯度检查模式关闭，避免产生 NaN
        skips=(  # 跳过的测试条件列表
            DecorateInfo(
                toleranceOverride({torch.float16: tol(atol=2e-3, rtol=1e-3)}),  # 设置容差覆盖，用于 torch.float16 类型的测试
                'TestInductorOpInfo', 'test_comprehensive', device_type='cuda',  # 指定设备类型为 'cuda' 的测试跳过条件
            ),
            DecorateInfo(
                unittest.expectedFailure,  # 预期的测试失败
                'TestJit', 'test_variant_consistency_jit',  # 在 'TestJit' 类的 'test_variant_consistency_jit' 方法中的测试跳过条件
                dtypes=(torch.float32,)  # 指定数据类型为 torch.float32 的测试跳过条件
            ),
        ),
    ),
    OpInfo(
        't',  # 操作类型为 't'
        sample_inputs_func=sample_inputs_t,  # 使用 sample_inputs_t 函数生成样本输入
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
        check_batched_forward_grad=False,  # 不检查批处理的前向梯度
        check_inplace_batched_forward_grad=False,  # 不检查就地批处理的前向梯度
        autodiff_fusible_nodes=[],  # 不应该融合的自动微分节点
        autodiff_nonfusible_nodes=[],  # 不应该融合的非自动微分节点
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 数据类型包括所有类型、复数类型以及 torch.bool, torch.float16, torch.bfloat16
        assert_autodiffed=True,  # 断言自动微分
        error_inputs_func=error_inputs_t  # 使用 error_inputs_t 函数生成错误输入
    ),
    OpInfo(
        "nn.functional.dropout",
        op=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.dropout, input, *args, **kwargs),
        dtypes=floating_types_and(torch.float16, torch.bfloat16),
        skips=(
            # 用 lambda 函数包装 op 参数，以确保设置了随机种子
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
            # 可能是因为这里使用了 lambda 函数作为 op 参数
            # AssertionError: JIT 测试没有执行任何逻辑
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            # inplace 变体分发到 dropout 内核，而在 CUDA 上
            # op 分发到 _fused_dropout（带有更多条件）
            # 因此，产生不同的值，因此在此处跳过测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_view', device_type='cuda'),
            # 输出是不确定的
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu')),
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        # https://github.com/pytorch/pytorch/issues/66357
        check_batched_forward_grad=False,
        supports_out=False,
        sample_inputs_func=sample_inputs_dropout,
        # 用 lambda 函数包装 inplace_variant 参数，以确保设置了随机种子且 inplace=True
        inplace_variant=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.dropout, input, *args, **kwargs, inplace=True)),
    OpInfo(
        "native_dropout_backward",
        op=torch.ops.aten.native_dropout_backward.default,
        aten_name="native_dropout_backward",
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),
        dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),
        supports_out=False,
        sample_inputs_func=sample_inputs_dropout_backward,
        skips=(
            # 跳过测试：Lazy tensor 失败
            DecorateInfo(unittest.skip('Skipped!'), 'TestJit', 'test_variant_consistency_jit'),
            # 这些测试仅在使用 ASAN 编译时失败
            DecorateInfo(unittest.skip("Fails with ASAN"), 'TestLazyOpInfo', 'test_correctness', active_if=TEST_WITH_ASAN),
            DecorateInfo(
                unittest.skip("Fails with ASAN"),
                'TestLazyOpInfo',
                'test_correctness_with_reusing_ir',
                active_if=TEST_WITH_ASAN
            ),
        ),
    ),
    OpInfo(
        "nn.functional.dropout2d",  # 定义操作信息对象，描述 dropout2d 函数的相关信息
        op=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.dropout2d, input, *args, **kwargs),  # 定义操作函数，添加种子以确保随机性可复现性
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 操作支持的数据类型包括浮点数和bfloat16
        skips=(
            # 下面是跳过的测试用例信息
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期失败的测试用例装饰信息
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的 JIT 一致性测试用例装饰信息
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu')  # 被跳过的 CPU 输出不确定性测试用例装饰信息
        ),
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度计算
        supports_out=False,  # 不支持输出参数
        check_batched_forward_grad=False,  # 不检查批处理前向梯度
        # 根据文档，有效的输入维度为 (3, 4)
        sample_inputs_func=partial(sample_inputs_dropout, valid_input_dim=(3, 4)),  # 提供样本输入的函数，指定有效的输入维度
        inplace_variant=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.dropout2d, input, *args, **kwargs, inplace=True)  # 定义 inplace 变体操作函数，确保随机性可复现性
    ),
    OpInfo(
        "nn.functional.dropout3d",  # 定义操作信息对象，描述 dropout3d 函数的相关信息
        op=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.dropout3d, input, *args, **kwargs),  # 定义操作函数，添加种子以确保随机性可复现性
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 操作支持的数据类型包括浮点数和bfloat16
        skips=(
            # 下面是跳过的测试用例信息
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期失败的测试用例装饰信息
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的 JIT 一致性测试用例装饰信息
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu')  # 被跳过的 CPU 输出不确定性测试用例装饰信息
        ),
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度计算
        supports_out=False,  # 不支持输出参数
        check_batched_forward_grad=False,  # 不检查批处理前向梯度
        # 根据文档，有效的输入维度为 (4, 5)
        sample_inputs_func=partial(sample_inputs_dropout, valid_input_dim=(4, 5)),  # 提供样本输入的函数，指定有效的输入维度
        inplace_variant=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.dropout3d, input, *args, **kwargs, inplace=True)  # 定义 inplace 变体操作函数，确保随机性可复现性
    ),
    # 定义 OpInfo 对象，用于描述 nn.functional.alpha_dropout 操作的相关信息
    OpInfo(
        "nn.functional.alpha_dropout",  # 操作名称为 nn.functional.alpha_dropout
        op=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.alpha_dropout, input, *args, **kwargs),  # 设置随机种子的包装器函数
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 支持的数据类型包括浮点类型和 torch.float16, torch.bfloat16
        gradcheck_wrapper=wrapper_set_seed,  # 梯度检查时使用的包装器函数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向-梯度-反向梯度
        supports_out=False,  # 不支持输出
        sample_inputs_func=sample_inputs_dropout,  # 用于生成输入样本的函数
        check_batched_forward_grad=False,  # 不检查批处理的前向梯度
        inplace_variant=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.alpha_dropout, input, *args, **kwargs, inplace=True),  # 就地操作的变体函数
        skips=(
            # 跳过以下测试用例：
            # - 对 'TestNormalizeOperators' 的 'test_normalize_operator_exhaustive' 测试使用 unittest.expectedFailure 装饰器
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
            # - 在 cuda11.7 下 'TestCommon' 的 'test_compare_cpu' 测试失败，报错信息为 "AssertionError: Tensor-likes are not close!"
            # - 详细错误日志请见 https://github.com/pytorch/pytorch/actions/runs/3440108478/jobs/5738475757
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_compare_cpu', device_type='cuda'),
            # - 在 'TestJit' 的 'test_variant_consistency_jit' 测试中使用 unittest.expectedFailure 装饰器
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
        ),
    ),
    # 在训练模式下，feature_alpha_dropout 当前不支持复数数据类型的输入
    # 与 train=False 不同，它支持复数输入，因此有两个 OpInfo 来覆盖所有情况
    OpInfo(
        "nn.functional.feature_alpha_dropout",  # 操作名称：特征 Alpha Dropout
        op=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.feature_alpha_dropout, input, *args, **kwargs),  # 设置随机种子的包装器函数
        variant_test_name="with_train",  # 变体测试名称：带有训练模式
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 数据类型：浮点类型以及 torch.float16 和 torch.bfloat16
        skips=(
            # 跳过的测试用例信息
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期失败的测试用例：TestNormalizeOperators 的 test_normalize_operator_exhaustive
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例：TestJit 的 test_variant_consistency_jit
            # torch.autograd.gradcheck.GradcheckError: While computing batched gradients, got:
            # vmap: We do not yet support calling random operations inside of vmap.
            # Please perform random operations outside of vmap as a workaround
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', "test_forward_mode_AD"),  # 预期失败的测试用例：TestFwdGradients 的 test_forward_mode_AD
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', "test_inplace_forward_mode_AD"),  # 预期失败的测试用例：TestFwdGradients 的 test_inplace_forward_mode_AD
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu')),  # 跳过的测试用例：TestCommon 的 test_compare_cpu，输出是非确定性的
        # 在慢速 gradcheck 上运行得很慢 - 或者可以减少输入大小作为替代
        gradcheck_fast_mode=True,  # gradcheck 快速模式为 True
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和反向梯度
        supports_out=False,  # 不支持输出
        # 根据文档，有效的输入维度为 (4, 5)
        sample_inputs_func=partial(sample_inputs_dropout, train=True, valid_input_dim=(4, 5)),  # 样本输入函数：使用 dropout，训练模式，有效输入维度为 (4, 5)
        inplace_variant=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.feature_alpha_dropout, input, *args, **kwargs, inplace=True)),  # 原地操作的包装器函数：使用 dropout，设置随机种子，原地操作为 True
    OpInfo(
        "nn.functional.feature_alpha_dropout",  # 操作名称：特征 Alpha Dropout
        op=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.feature_alpha_dropout, input, *args, **kwargs),  # 设置随机种子的包装器函数
        variant_test_name="without_train",  # 变体测试名称：不带训练模式
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 数据类型：所有类型、复杂类型以及 torch.bool、torch.float16、torch.bfloat16
        skips=(
            # 跳过的测试用例信息
            # lambda impl
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),  # 预期失败的测试用例：TestNormalizeOperators 的 test_normalize_operator_exhaustive
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期失败的测试用例：TestJit 的 test_variant_consistency_jit
        ),
        gradcheck_wrapper=wrapper_set_seed,  # gradcheck 包装器函数：设置随机种子的包装器函数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和反向梯度
        supports_out=False,  # 不支持输出
        sample_inputs_func=partial(sample_inputs_dropout, train=False),  # 样本输入函数：使用 dropout，非训练模式
        inplace_variant=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.feature_alpha_dropout, input, *args, **kwargs, inplace=True)),  # 原地操作的包装器函数：使用 dropout，设置随机种子，原地操作为 True
    OpInfo(
        "nn.functional.one_hot",  # 操作名称：one_hot
        ref=reference_one_hot,  # 参考实现函数：reference_one_hot
        supports_out=False,  # 不支持输出
        dtypes=_dispatch_dtypes((torch.int64,)),  # 数据类型：调度的数据类型为 torch.int64
        sample_inputs_func=sample_inputs_one_hot,  # 样本输入函数：one_hot 的样本输入函数
    ),
    OpInfo(
        "nn.functional.embedding",
        aten_backward_name="embedding_dense_backward",
        # 使用 lambda 重新排列位置参数。
        # 这是因为目前梯度测试仅测试 SampleInput 的 `input` 字段。
        op=lambda weight, idx, **kwargs: torch.nn.functional.embedding(idx, weight, **kwargs),
        dtypes=floating_types_and(torch.bfloat16, torch.float16),
        sample_inputs_func=sample_inputs_embedding,
        allow_cow_input_materialize_forward=[0],
        error_inputs_func=error_inputs_embedding,
        supports_forward_ad=True,
        supports_fwgrad_bwgrad=True,
        skips=(
            # lambda 实现
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
            # 在 CI 中失败 https://github.com/pytorch/pytorch/issues/85377
            DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_compare_cpu'),
            # 参考：https://github.com/pytorch/pytorch/issues/67084
            DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_view', device_type='cuda'),
            # 不是问题：embedding 对其输入执行奇怪的操作（它重新规范化）
            DecorateInfo(unittest.skip('Allowed exemption'), 'TestCompositeCompliance', 'test_operator'),
        ),
        supports_expanded_weight=True,
        supports_out=False,
    ),
    OpInfo(
        "nn.functional.embedding_bag",
        # 使用 lambda 重新排列位置参数。
        # 这是因为目前梯度测试仅测试 SampleInput 的 `input` 字段。
        op=lambda weight, idx, **kwargs: torch.nn.functional.embedding_bag(idx, weight, **kwargs),
        dtypes=floating_types_and(torch.bfloat16, torch.float16),
        dtypesIfCUDA=floating_types_and(torch.bfloat16, torch.float16),
        # mode `max` 和 dtype `bfloat16` 不支持反向传播
        backward_dtypesIfCUDA=floating_types_and(torch.float16),
        sample_inputs_func=sample_inputs_embedding_bag,
        skips=(
            # lambda 实现
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),
            DecorateInfo(unittest.expectedFailure, 'TestNormalizeOperators', 'test_normalize_operator_exhaustive'),
            # 不是问题：embedding_bag 对其输入执行奇怪的操作（它重新规范化）
            DecorateInfo(unittest.skip('Allowed exemption'), 'TestCompositeCompliance', 'test_operator'),
        ),
        gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
        supports_out=False,
        supports_gradgrad=False,
        allow_cow_input_materialize_forward=[0],
    ),
    OpInfo(
        "nn.functional.multi_head_attention_forward",  # 操作的名称
        op=lambda input, *args, **kwargs:
            wrapper_set_seed(torch.nn.functional.multi_head_attention_forward, input, *args, **kwargs),  # 使用wrapper_set_seed包装操作，以确保随机性可重复性
        dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 数据类型包括浮点数和半精度浮点数
        sample_inputs_func=sample_inputs_multi_head_attention_forward,  # 使用sample_inputs_multi_head_attention_forward函数生成样本输入
        skips=(
            # Tensor-likes are not close
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_noncontiguous_samples', dtypes=(torch.float32,)),  # 跳过不连续样本测试，针对torch.float32数据类型
            DecorateInfo(toleranceOverride({torch.float32: tol(atol=5e-3, rtol=0)}), 'TestDecomp', 'test_comprehensive'),  # 对于torch.float32数据类型，设置特定的容差
            # TODO skip this for now since we can't skip on runtime arch support (taken from scaled_dot_product_attention)
            DecorateInfo(unittest.skip("Skipped!"), 'TestInductorOpInfo', 'test_comprehensive'),  # 暂时跳过测试，因为无法在运行时架构支持上跳过（从scaled_dot_product_attention中得出）
            # randomness
            DecorateInfo(unittest.skip("Skipped!"), 'TestFwdGradients', 'test_forward_mode_AD'),  # 跳过前向梯度测试，因为输出是不确定的
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),  # 跳过测试，因为输出是非确定性的
            # lambda impl
            # AssertionError: JIT Test does not execute any logic
            DecorateInfo(unittest.expectedFailure, 'TestJit', 'test_variant_consistency_jit'),  # 预期的失败测试，因为JIT测试没有执行任何逻辑
            DecorateInfo(unittest.expectedFailure, "TestNormalizeOperators", "test_normalize_operator_exhaustive"),  # 预期的失败测试，因为normalize操作器测试耗尽
            # tests running very slowly break slow tests, so we skip them instead of using `slowTest`.
            DecorateInfo(unittest.skip("Skipped!"), 'TestCompositeCompliance', 'test_forward_ad'),  # 跳过测试，因为测试运行非常缓慢
            DecorateInfo(unittest.skip("Skipped!"), 'TestCompositeCompliance', 'test_operator'),  # 跳过测试，因为测试运行非常缓慢
            DecorateInfo(
                unittest.skip("Skipped - baddbmm decomp does not have enough precision for 16-bit float"),
                'TestDecomp',
                'test_comprehensive',
                dtypes=(torch.bfloat16, torch.float16),
            ),  # 跳过测试，因为baddbmm分解对于16位浮点数精度不足
            DecorateInfo(
                unittest.skip("Skipped - baddbmm decomp does not have enough precision for 16-bit float"),
                'TestDecomp',
                'test_quick',
                dtypes=(torch.bfloat16, torch.float16)
            )  # 跳过测试，因为baddbmm分解对于16位浮点数精度不足
        ),
        supports_out=False,  # 不支持输出
        supports_gradgrad=True,  # 支持二阶梯度
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        # Runs very slowly on slow gradcheck - alternatively reduce input sizes
        gradcheck_fast_mode=True,  # 使用快速模式进行梯度检查
    ),
    UnaryUfuncInfo(
        "nn.functional.softplus",  # 定义一个一元函数信息对象，表示对应的 PyTorch softplus 函数
        aten_backward_name='softplus_backward',  # 指定在 ATen 中的反向传播函数名
        ref=reference_softplus,  # 参考实现的引用，用于验证 softplus 函数的正确性
        sample_kwargs=lambda device, dtype, input: ({'beta': 3, 'threshold': .2}, {'beta': 3, 'threshold': .2}),  # 生成函数输入参数的示例
        sample_inputs_func=partial(sample_inputs_elementwise_unary, op_kwargs={'beta': 3, 'threshold': .2}),  # 生成函数输入的函数，带有特定的操作参数
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        dtypes=floating_types_and(torch.bfloat16, torch.float16),  # 支持的数据类型，包括半精度和浮点数精度
        decorators=(
            DecorateInfo(
                toleranceOverride
                ({  # 定义容忍度覆盖装饰器，用于设置测试容忍度
                    torch.half: tol(atol=1e-2, rtol=1e-2),  # 对半精度的容忍度设置
                    torch.bfloat16: tol(atol=1e-2, rtol=1e-2),  # 对 bfloat16 的容忍度设置
                }),
                'TestUnaryUfuncs'),  # 装饰器的名称，用于测试一元函数
        ),
    ),
    OpInfo(
        "nn.functional.mse_loss",  # 定义一个操作信息对象，表示 PyTorch 的均方误差损失函数
        aten_backward_name='mse_loss_backward',  # 指定在 ATen 中的反向传播函数名
        ref=loss_reference_reduction_wrapper(lambda input, target: (input - target) ** 2),  # 引用的损失函数实现，用于验证损失函数的正确性
        sample_inputs_func=sample_inputs_loss,  # 生成函数输入的函数，用于生成损失函数的示例输入
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        dtypes=floating_types_and(torch.float16),  # 支持的数据类型，仅包括浮点数精度
        backward_dtypes=floating_types(),  # 反向传播支持的数据类型
        dtypesIfCUDA=floating_types_and(torch.bfloat16, torch.float16),  # 在 CUDA 下支持的数据类型，包括半精度和浮点数精度
        backward_dtypesIfCUDA=floating_types_and(torch.bfloat16, torch.float16),  # 在 CUDA 下反向传播支持的数据类型
        skips=(
            # 出现 RuntimeError: input->type()->kind() == TypeKind::OptionalType
            # 在 "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp" 的 252 行，这可能是 PyTorch 的 bug
            DecorateInfo(unittest.expectedFailure, "TestJit", "test_variant_consistency_jit", dtypes=(torch.float32,),),  # 装饰器信息，标记这个测试在特定条件下应为预期失败
        ),
    ),
    OpInfo(
        "nn.functional.grid_sample",  # 定义一个操作信息对象，表示 PyTorch 的 grid_sample 函数
        dtypes=floating_types(),  # 支持的数据类型，包括所有浮点数精度
        dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),  # 在 CUDA 下支持的数据类型，包括半精度和 bfloat16
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_grid_sample,  # 生成函数输入的函数，用于生成 grid_sample 函数的示例输入
        reference_inputs_func=reference_inputs_grid_sample,  # 参考输入的函数，用于验证 grid_sample 函数的正确性
        supports_gradgrad=False,  # 不支持二阶导数的梯度检查
        gradcheck_nondet_tol=1e-15),  # 梯度检查的非确定性容忍度设置
    # TODO: delete this OpInfo once we add meta support for grid_sampler_3d
    OpInfo(
        "grid_sampler_2d",  # 定义一个操作信息对象，表示 PyTorch 的 grid_sampler_2d 函数
        dtypes=floating_types(),  # 支持的数据类型，包括所有浮点数精度
        dtypesIfCUDA=floating_types_and(torch.float16, torch.bfloat16),  # 在 CUDA 下支持的数据类型，包括半精度和 bfloat16
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_grid_sampler_2d,  # 生成函数输入的函数，用于生成 grid_sampler_2d 函数的示例输入
        supports_gradgrad=False,  # 不支持二阶导数的梯度检查
        gradcheck_nondet_tol=1e-15),  # 梯度检查的非确定性容忍度设置
    OpInfo(
        "argwhere",  # 定义操作信息对象，描述 np.argwhere 函数的测试信息
        ref=np.argwhere,  # 参考实现为 np.argwhere 函数
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括 torch.bool, torch.float16, torch.bfloat16
        supports_out=False,  # 不支持输出参数
        supports_autograd=False,  # 不支持自动求导
        sample_inputs_func=sample_inputs_argwhere,  # 使用 sample_inputs_argwhere 函数生成样本输入数据
        skips=(
            # 在 ROCm 上有编译器问题，需要跳过直到 ROCm5.5 版本
            DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_non_standard_bool_values', dtypes=[torch.bool], active_if=TEST_WITH_ROCM),
        ),  # 定义跳过的测试用例，针对特定条件进行跳过
    ),
    ReductionOpInfo(
        'all',  # 定义操作信息对象，描述 np.all 函数的测试信息
        identity=True,  # 具有恒等性质
        supports_autograd=False,  # 不支持自动求导
        result_dtype=torch.bool,  # 结果数据类型为 torch.bool
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括 torch.bool, torch.float16, torch.bfloat16
        ref=reference_reduction_numpy(np.all),  # 参考实现为 np.all 函数
        skips=(
            # FIXME: uint8 输入返回 uint8 而不是 bool
            DecorateInfo(unittest.expectedFailure, 'TestReductions', 'test_result_dtype', dtypes=[torch.uint8]),
        ),  # 定义跳过的测试用例，针对特定条件进行跳过
    ),
    ReductionOpInfo(
        'any',  # 定义操作信息对象，描述 np.any 函数的测试信息
        identity=False,  # 没有恒等性质
        supports_autograd=False,  # 不支持自动求导
        result_dtype=torch.bool,  # 结果数据类型为 torch.bool
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括 torch.bool, torch.float16, torch.bfloat16
        ref=reference_reduction_numpy(np.any),  # 参考实现为 np.any 函数
        skips=(
            # FIXME: uint8 输入返回 uint8 而不是 bool
            DecorateInfo(unittest.expectedFailure, 'TestReductions', 'test_result_dtype', dtypes=[torch.uint8]),
        ),  # 定义跳过的测试用例，针对特定条件进行跳过
    ),
    ReductionOpInfo(
        'amax',  # 定义操作信息对象，描述 np.amax 函数的测试信息
        nan_policy='propagate',  # NaN 策略为 propagate
        supports_forward_ad=True,  # 支持前向自动求导
        check_batched_forward_grad=False,  # 不检查批量化前向梯度
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型包括 torch.float16, torch.bfloat16, torch.bool
        ref=reference_reduction_numpy(np.amax),  # 参考实现为 np.amax 函数
        skips=(
            # FIXME: 当 dim=[] 时，会减少所有维度
            DecorateInfo(unittest.expectedFailure, 'TestReductions', 'test_dim_empty'),
            DecorateInfo(unittest.expectedFailure, 'TestReductions', 'test_dim_empty_keepdim'),
        ),  # 定义跳过的测试用例，针对特定条件进行跳过
        error_inputs_func=error_inputs_aminmax_amax_amin,  # 错误输入的生成函数
    ),
    ReductionOpInfo(
        'amin',  # 定义操作信息对象，描述 np.amin 函数的测试信息
        nan_policy='propagate',  # NaN 策略为 propagate
        supports_forward_ad=True,  # 支持前向自动求导
        check_batched_forward_grad=False,  # 不检查批量化前向梯度
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型包括 torch.float16, torch.bfloat16, torch.bool
        ref=reference_reduction_numpy(np.amin),  # 参考实现为 np.amin 函数
        skips=(
            # FIXME: 当 dim=[] 时，会减少所有维度
            DecorateInfo(unittest.expectedFailure, 'TestReductions', 'test_dim_empty'),
            DecorateInfo(unittest.expectedFailure, 'TestReductions', 'test_dim_empty_keepdim'),
        ),  # 定义跳过的测试用例，针对特定条件进行跳过
        error_inputs_func=error_inputs_aminmax_amax_amin,  # 错误输入的生成函数
    ),
    # 创建一个 ReductionOpInfo 对象，表示 argmax 操作的信息
    ReductionOpInfo(
        'argmax',  # 操作名称为 argmax
        supports_multiple_dims=False,  # 不支持多维度操作
        supports_autograd=False,  # 不支持自动求导
        assert_jit_shape_analysis=True,  # 断言 JIT 形状分析为真
        result_dtype=torch.int64,  # 结果数据类型为 torch.int64
        dtypes=all_types_and(torch.float16, torch.bfloat16),  # 支持的数据类型包括 torch.float16 和 torch.bfloat16
        ref=reference_reduction_numpy(np.argmax, supports_keepdims=False),  # 参考实现使用 numpy 的 argmax 函数，不支持 keepdims 参数
    ),

    # 创建一个 ReductionOpInfo 对象，表示 argmin 操作的信息
    ReductionOpInfo(
        'argmin',  # 操作名称为 argmin
        supports_multiple_dims=False,  # 不支持多维度操作
        supports_autograd=False,  # 不支持自动求导
        result_dtype=torch.int64,  # 结果数据类型为 torch.int64
        dtypes=all_types_and(torch.float16, torch.bfloat16),  # 支持的数据类型包括 torch.float16 和 torch.bfloat16
        ref=reference_reduction_numpy(np.argmin, supports_keepdims=False),  # 参考实现使用 numpy 的 argmin 函数，不支持 keepdims 参数
    ),

    # 创建一个 ReductionOpInfo 对象，表示 count_nonzero 操作的信息
    ReductionOpInfo(
        'count_nonzero',  # 操作名称为 count_nonzero
        identity=0,  # 单位元素为 0
        supports_out=False,  # 不支持输出参数
        supports_autograd=False,  # 不支持自动求导
        result_dtype=torch.int64,  # 结果数据类型为 torch.int64
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括 torch.bool, torch.float16 和 torch.bfloat16
        sample_inputs_func=sample_inputs_reduction_count_nonzero,  # 用于 count_nonzero 操作的示例输入函数
        ref=reference_reduction_numpy(np.count_nonzero),  # 参考实现使用 numpy 的 count_nonzero 函数
        skips=(
            # FIXME: count_nonzero 不接受 keepdim 关键字参数
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_default_keepdim'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_none_keepdim'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_single_keepdim'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_multi_keepdim'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_multi_unsorted_keepdim'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_offbounds_keepdim'),
            # FIXME: dim=[] 会减少所有维度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),
        ),
    ),
    ReductionOpInfo(
        'mean',  # 定义一个名为'mean'的操作信息对象
        nan_policy='propagate',  # 设置NaN策略为传播
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        # FIXME: mean在使用'out'重载时需要'dim'参数。
        # 添加它到'generate_args_kwargs'不起作用，因为这些参数也会传递给参考实现。
        supports_out=False,  # 不支持'out'参数
        assert_autodiffed=True,  # 断言自动微分已执行
        assert_jit_shape_analysis=True,  # 断言JIT形状分析已执行
        promotes_int_to_float=True,  # 推广整数转换为浮点数
        dtypes=floating_and_complex_types_and(torch.float16, torch.bfloat16),  # 数据类型为浮点数和复数类型，包括torch.float16和torch.bfloat16
        ref=reference_reduction_numpy(np.mean),  # 参考实现为NumPy的mean函数
        error_inputs_func=error_inputs_mean,  # 错误输入处理函数为error_inputs_mean
        skips=(  # 跳过以下测试：
            # FIXME: mean不支持在没有传递'dim'的情况下传递keepdim
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_default_keepdim'),
            # FIXME: mean在dim=[]时会减少所有维度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),
            # FIXME: 提高精度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input',
                         dtypes=[torch.float16]),  # 用torch.float16进行测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_extremal_values',
                         device_type='cuda', dtypes=[torch.complex64]),  # 在CUDA设备上用torch.complex64进行测试
        ),
    ),
    ReductionOpInfo(
        'nanmean',
        nan_policy='omit',  # 设置 NaN 值处理策略为忽略
        assert_autodiffed=True,  # 断言自动微分已启用
        promotes_int_to_float=True,  # 将整数升级为浮点数
        supports_forward_ad=True,  # 支持前向自动微分
        check_batched_forward_grad=False,  # 不检查批处理前向梯度
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 数据类型为浮点类型和 torch.float16, torch.bfloat16
        dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16, torch.chalf),  # 如果是 CUDA，数据类型为浮点和复数类型以及 torch.float16, torch.bfloat16, torch.chalf
        sample_inputs_func=sample_inputs_nan_reduction(supports_multiple_dims=True),  # 样本输入函数为支持多维度的 NaN reduction 样本输入
        ref=reference_reduction_numpy(np.nanmean),  # 参考值为 NumPy 中的 nanmean 函数
        skips=(
            # 下列测试被跳过：
            # AssertionError: False is not true : 自动微分测试失败。
            DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),
            # FIXME: prod reduces all dimensions when dim=[] 对于空维度，prod 减少所有维度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),
            # FIXME: improve precision 改进精度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input',
                         dtypes=[torch.float16]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_duplicate_values',
                         device_type='cuda', dtypes=[torch.float16]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_extremal_values',
                         device_type='cuda', dtypes=[torch.complex64]),
        ),
    ),
    ReductionOpInfo(
        'std',
        nan_policy='propagate',  # 设置 NaN 值传播策略
        supports_out=True,  # 支持输出参数
        complex_to_real=True,  # 复数转为实数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        assert_autodiffed=True,  # 断言自动微分已启用
        promotes_int_to_float=True,  # 将整数升级为浮点数
        check_batched_forward_grad=False,  # 不检查批处理前向梯度
        dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),  # 数据类型为半精度浮点和复数类型，以及 torch.half, torch.bfloat16
        dtypesIfCUDA=floating_and_complex_types_and(torch.half, torch.bfloat16),  # 如果是 CUDA，数据类型为半精度浮点和复数类型，以及 torch.half, torch.bfloat16
        sample_inputs_func=sample_inputs_std_var,  # 样本输入函数为标准差和方差的样本输入
        ref=reference_std_var(np.std),  # 参考值为标准差函数 np.std
        generate_args_kwargs=generate_std_var_kwargs,  # 生成参数和关键字参数的函数为生成标准差和方差的关键字参数
        skips=(
            # FIXME: cannot specify keepdim without dim 无法在没有维度的情况下指定 keepdim
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_default_keepdim'),
            # FIXME: dim=[] reduces all dimensions 对于空维度，减少所有维度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),
            # FIXME: improve precision 改进精度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input',
                         dtypes=(torch.float16,)),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_duplicate_values',
                         dtypes=(torch.float16,)),
        ),
    ),
    ReductionOpInfo(
        'std',  # 定义标准差操作
        variant_test_name='unbiased',  # 使用无偏标准差测试
        nan_policy='propagate',  # NaN策略设置为传播
        supports_out=False,  # 不支持输出参数
        complex_to_real=True,  # 支持复数到实数转换
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和反向梯度
        assert_autodiffed=True,  # 断言自动微分完成
        promotes_int_to_float=True,  # 推广整数到浮点数
        check_batched_forward_grad=False,  # 不检查批处理前向梯度
        dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),  # 数据类型包括浮点数和复数以及半精度和Bfloat16
        dtypesIfCUDA=floating_and_complex_types_and(torch.half, torch.bfloat16),  # CUDA环境下的数据类型
        sample_inputs_func=sample_inputs_std_var_unbiased,  # 用于标准差和方差无偏测试的样本输入函数
        skips=(  # 跳过的测试用例元组
            # FIXME: dim=[] reduces all dimensions
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),  # 跳过空维度测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),  # 跳过保持空维度的测试
        ),
    ),
    ReductionOpInfo(
        'var',  # 定义方差操作
        nan_policy='propagate',  # NaN策略设置为传播
        supports_out=True,  # 支持输出参数
        assert_autodiffed=True,  # 断言自动微分完成
        promotes_int_to_float=True,  # 推广整数到浮点数
        complex_to_real=True,  # 支持复数到实数转换
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和反向梯度
        check_batched_forward_grad=False,  # 不检查批处理前向梯度
        dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),  # 数据类型包括浮点数和复数以及半精度和Bfloat16
        dtypesIfCUDA=floating_and_complex_types_and(torch.half, torch.bfloat16),  # CUDA环境下的数据类型
        sample_inputs_func=sample_inputs_std_var,  # 用于标准差和方差测试的样本输入函数
        ref=reference_std_var(np.var),  # 参考实现为NumPy的方差函数
        generate_args_kwargs=generate_std_var_kwargs,  # 生成标准差和方差参数的函数
        skips=(  # 跳过的测试用例元组
            # FIXME: cannot specify keepdim without dim
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_default_keepdim'),  # 跳过默认保持维度的测试
            # FIXME: dim=[] reduces all dimensions
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),  # 跳过空维度测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),  # 跳过保持空维度的测试
            # FIXME: improve precision
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input'),  # 跳过小输入的参考值测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_duplicate_values'),  # 跳过重复值输入的参考值测试
            # NumPy is giving NaN for this
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_large_input'),  # 跳过大输入的参考值测试
        ),
    ),
    # 创建一个 ReductionOpInfo 对象，表示一个归约操作的信息
    ReductionOpInfo(
        'var',  # 归约操作的类型为 'var'，即方差
        variant_test_name='unbiased',  # 使用无偏估计进行测试
        nan_policy='propagate',  # 处理 NaN 值的策略为传播
        supports_out=False,  # 不支持输出参数
        complex_to_real=True,  # 支持将复数转换为实数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
        assert_autodiffed=True,  # 断言已自动微分
        promotes_int_to_float=True,  # 推广整数到浮点数
        check_batched_forward_grad=False,  # 不检查批处理前向梯度
        dtypes=floating_and_complex_types_and(torch.half, torch.bfloat16),  # 支持的数据类型包括浮点数和复数类型
        dtypesIfCUDA=floating_and_complex_types_and(torch.half, torch.bfloat16),  # 如果是CUDA，支持的数据类型同上
        sample_inputs_func=sample_inputs_std_var_unbiased,  # 获取标准无偏方差操作的样本输入函数
        skips=(
            # FIXME: dim=[] reduces all dimensions
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),  # 跳过测试：空维度 [] 归约所有维度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),  # 跳过测试：空维度 [] 保持维度不变
        ),
    ),
    # 创建另一个 ReductionOpInfo 对象，表示另一个归约操作的信息
    ReductionOpInfo(
        'prod',  # 归约操作的类型为 'prod'，即乘积
        identity=1,  # 乘积的单位元是 1
        nan_policy='propagate',  # 处理 NaN 值的策略为传播
        supports_multiple_dims=False,  # 不支持多维度
        # https://github.com/pytorch/pytorch/issues/80411
        gradcheck_fast_mode=True,  # 使用快速模式进行梯度检查
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向和后向梯度
        promotes_int_to_int64=True,  # 推广整数到 int64 类型
        gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,  # 梯度检查的非确定性容差值
        dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),  # 支持的数据类型包括所有类型和复数，还有 bool、bfloat16 和 float16
        dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 如果是CUDA，支持的数据类型同上
        sample_inputs_func=sample_inputs_prod,  # 获取乘积操作的样本输入函数
        ref=prod_numpy,  # 参考实现为 numpy 的乘积函数
        skips=(
            # FIXME: prod does not support passing keepdim without passing dim
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_default_keepdim'),  # 跳过测试：prod 不支持不传递 dim 参数时保持维度不变
            # FIXME: prod reduces all dimensions when dim=[]
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),  # 跳过测试：prod 在 dim=[] 时归约所有维度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),  # 跳过测试：prod 在 dim=[] 时保持维度不变
            # FIXME: prod does not support passing None to dim
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_none'),  # 跳过测试：prod 不支持将 None 传递给 dim 参数
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_none_keepdim'),  # 跳过测试：prod 不支持将 None 传递给 dim 参数且保持维度不变
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input',  # 跳过测试：小输入情况下的参考测试，数据类型包括 float16 和 complex64
                         dtypes=[torch.float16, torch.complex64]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_duplicate_values',  # 跳过测试：重复值情况下的参考测试，数据类型包括 uint8、float16 和 complex64
                         dtypes=[torch.uint8, torch.float16, torch.complex64]),
            # FIXME: ValueError: The data in MaskedTensor a and Tensor b do not match
            DecorateInfo(unittest.skip("Skipped!"), 'TestOperators', 'test_reduction_all',  # 跳过测试：所有元素归约测试，数据类型为 float16
                         dtypes=[torch.float16]),
        ),
    ),
    ReductionOpInfo(
        'sum',  # 指定操作为求和操作
        identity=0,  # 操作的单位元为0
        nan_policy='propagate',  # 处理NaN值的策略为传播
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向梯度与后向梯度的联合计算
        promotes_int_to_int64=True,  # 将整数类型提升为int64类型
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括所有类型以及特定的浮点数和布尔类型
        dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 如果是CUDA环境，支持的数据类型包括所有类型以及特定的浮点数、布尔类型和chalf类型
        ref=reference_reduction_numpy(np.sum),  # 参考实现为NumPy的sum函数
        error_inputs_sparse_func=error_inputs_sparse_reduction_sum,  # 处理稀疏输入时的错误函数为error_inputs_sparse_reduction_sum
        sample_inputs_sparse_coo_func=partial(sample_inputs_sparse_reduction_sum, layout=torch.sparse_coo),  # 生成稀疏输入COO格式样本的函数
        sample_inputs_sparse_csr_func=partial(sample_inputs_sparse_reduction_sum, layout=torch.sparse_csr),  # 生成稀疏输入CSR格式样本的函数
        sample_inputs_sparse_csc_func=partial(sample_inputs_sparse_reduction_sum, layout=torch.sparse_csc),  # 生成稀疏输入CSC格式样本的函数
        sample_inputs_sparse_bsr_func=partial(sample_inputs_sparse_reduction_sum, layout=torch.sparse_bsr),  # 生成稀疏输入BSR格式样本的函数
        sample_inputs_sparse_bsc_func=partial(sample_inputs_sparse_reduction_sum, layout=torch.sparse_bsc),  # 生成稀疏输入BSC格式样本的函数
        skips=(
            # FIXME: sum does not support passing keepdim without passing dim
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_default_keepdim'),  # 跳过测试：sum操作不支持在不传递dim参数的情况下传递keepdim参数
            # FIXME: sum reduces all dimensions when dim=[]
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),  # 跳过测试：当dim=[]时，sum操作会降低所有维度
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),  # 跳过测试：空dim时保持维度的行为
            # FIXME: improve precision
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input',
                         dtypes=[torch.float16]),  # 跳过测试：改进精度，针对小输入测试，数据类型为torch.float16
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_duplicate_values',
                         dtypes=[torch.float16]),  # 跳过测试：改进精度，针对重复数值测试，数据类型为torch.float16
            DecorateInfo(unittest.skip("Skipped!"), 'TestOperators', 'test_reduction_all',
                         dtypes=[torch.float32]),  # 跳过测试：测试所有操作，数据类型为torch.float32
        ),
    ),
    # 创建一个 ReductionOpInfo 对象，指定操作为 'nansum'
    ReductionOpInfo(
        'nansum',
        # 操作的身份元素
        identity=0,
        # 处理 NaN 值的策略为忽略
        nan_policy='omit',
        # 支持输出
        supports_out=True,
        # 将 int 类型提升为 int64 类型
        promotes_int_to_int64=True,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 不检查批处理的前向梯度
        check_batched_forward_grad=False,
        # 支持前向梯度和后向梯度
        supports_fwgrad_bwgrad=True,
        # 支持的数据类型包括所有类型和 torch.bool, torch.float16, torch.bfloat16
        dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),
        # CUDA 下支持的数据类型包括所有类型、复数类型和 torch.bool, torch.float16, torch.bfloat16, torch.chalf
        dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),
        # 获取样本输入函数，支持多维度
        sample_inputs_func=sample_inputs_nan_reduction(supports_multiple_dims=True),
        # 参考实现为 numpy 的 np.nansum 函数
        ref=reference_reduction_numpy(np.nansum),
        # 跳过以下测试用例
        skips=(
            # 报告 PyTorch 的错误
            DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),
            # FIXME: 当 dim=[] 时，nansum 减少所有维度
            DecorateInfo(unittest.expectedFailure, 'TestReductions', 'test_dim_empty'),
            DecorateInfo(unittest.expectedFailure, 'TestReductions', 'test_dim_empty_keepdim'),
            # FIXME: 不稳定的测试，所以跳过而不是标记为预期失败
            # numpy 中可能有低精度的参考实现
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input',
                         dtypes=[torch.float16]),
        ),
    ),
    # 创建一个 OpInfo 对象，指定操作为 'nn.functional.ctc_loss'
    OpInfo(
        "nn.functional.ctc_loss",
        # 浮点类型的数据类型
        dtypes=floating_types(),
        # 不支持输出
        supports_out=False,
        # 获取样本输入函数
        sample_inputs_func=sample_inputs_ctc_loss,
        # 跳过以下测试用例
        skips=(
            # https://github.com/pytorch/pytorch/issues/67462
            # torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0
            DecorateInfo(
                unittest.expectedFailure,
                "TestBwdGradients",
                "test_fn_grad",
                dtypes=(torch.float64,),
            ),
            # RuntimeError: derivative for aten::_ctc_loss_backward is not implemented
            DecorateInfo(
                unittest.expectedFailure,
                "TestBwdGradients",
                "test_fn_gradgrad",
                dtypes=(torch.float64,),
            ),
            # RuntimeError: derivative for aten::_ctc_loss_backward is not implemented
            DecorateInfo(
                unittest.skip("Skipped!"),
                "TestJit",
                "test_variant_consistency_jit",
                dtypes=(torch.float32,),
            ),
            # Ref: https://github.com/pytorch/pytorch/issues/85231
            # ASAN 下失败
            DecorateInfo(unittest.skip("Fails with ASAN"),
                         'TestProxyTensorOpInfo',
                         'test_make_fx_fake_exhaustive', active_if=TEST_WITH_ASAN),
        ),
    ),
    # 创建一个 OpInfo 对象，指定操作为 'nn.functional.cosine_embedding_loss'
    OpInfo(
        "nn.functional.cosine_embedding_loss",
        # 所有类型和 torch.half, torch.bfloat16, torch.bool 的数据类型
        dtypes=all_types_and(torch.half, torch.bfloat16, torch.bool),
        # 不支持输出
        supports_out=False,
        # 支持前向自动微分
        supports_forward_ad=True,
        # 支持前向梯度和后向梯度
        supports_fwgrad_bwgrad=True,
        # 获取样本输入函数
        sample_inputs_func=sample_inputs_cosine_embedding_loss,
    ),
    OpInfo(
        "nn.functional.nll_loss",  # 定义操作信息对象，操作名称为 nn.functional.nll_loss
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 支持的数据类型包括浮点类型和 torch.float16、torch.bfloat16
        supports_out=False,  # 不支持输出参数
        sample_inputs_func=sample_inputs_nll_loss,  # 样本输入函数为 sample_inputs_nll_loss
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        assert_jit_shape_analysis=True,  # 断言 JIT 形状分析为真
        skips=(  # 跳过的测试集合开始
            # RuntimeError:
            # undefined value tensor:
            #   File "<string>", line 3
            # def the_method(i0, i1):
            #     return torch.nn.functional.nll_loss(i0, i1, weight=tensor([8.4784, 1.7658, 4.3228], dtype=torch.float32))
            #                                                        ~~~~~~ <--- HERE
            DecorateInfo(unittest.skip("Skipped!"), "TestJit", "test_variant_consistency_jit", dtypes=(torch.float32,),),
            # Fails for unknown reason: https://github.com/pytorch/pytorch/issues/120782
            DecorateInfo(
                unittest.skip("Skipped!"),
                "TestCompositeCompliance",
                "test_cow_input",
                device_type='cuda',
            ),
            DecorateInfo(unittest.skip("FP16 nll_loss cases have not been enabled on MPS yet"),
                         dtypes=(torch.half,), device_type="mps"),
        ),  # 跳过的测试集合结束
    ),
    OpInfo(
        "nn.functional.gaussian_nll_loss",  # 定义操作信息对象，操作名称为 nn.functional.gaussian_nll_loss
        dtypes=floating_types_and(torch.half, torch.bfloat16),  # 支持的数据类型包括浮点类型和 torch.half、torch.bfloat16
        gradcheck_fast_mode=True,  # 使用快速梯度检查模式
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        sample_inputs_func=sample_inputs_gaussian_nll_loss,  # 样本输入函数为 sample_inputs_gaussian_nll_loss
        error_inputs_func=error_inputs_gaussian_nll_loss,  # 错误输入函数为 error_inputs_gaussian_nll_loss
        skips=(  # 跳过的测试集合开始
            # Pre-existing condition (calls .item); needs to be fixed
            DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_backward'),
            DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_forward_ad'),
            # Pre-existing condition (calls .item); needs to be fixed
            DecorateInfo(unittest.expectedFailure, 'TestCompositeCompliance', 'test_operator'),
            # JIT does not support variadic tensors.
            # RuntimeError: input->type()->kind() == TypeKind::OptionalType
            # INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270,
            # please report a bug to PyTorch.
            DecorateInfo(unittest.skip("Skipped!"), "TestJit", "test_variant_consistency_jit", dtypes=(torch.float32,),),
        ),  # 跳过的测试集合结束
    ),
    OpInfo(
        "nn.functional.hinge_embedding_loss",  # 定义操作信息对象，操作名称为 nn.functional.hinge_embedding_loss
        dtypes=floating_types_and(torch.half, torch.bfloat16),  # 支持的数据类型包括浮点类型和 torch.half、torch.bfloat16
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动微分
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        sample_inputs_func=sample_inputs_hinge_embedding_loss,  # 样本输入函数为 sample_inputs_hinge_embedding_loss
        error_inputs_func=error_inputs_hinge_embedding_loss,  # 错误输入函数为 error_inputs_hinge_embedding_loss
        reference_inputs_func=reference_inputs_hinge_embedding_loss,  # 参考输入函数为 reference_inputs_hinge_embedding_loss
    ),
    # 定义 OpInfo 对象，描述 nn.functional.huber_loss 函数
    OpInfo(
        "nn.functional.huber_loss",
        aten_backward_name='huber_loss_backward',  # 指定对应的 ATen 后向函数名
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 支持的数据类型包括浮点数和特定的浮点数类型
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持正向自动求导
        sample_inputs_func=sample_inputs_huber_loss,  # 提供生成样例输入的函数
        error_inputs_func=error_inputs_huber_loss,  # 提供生成错误输入的函数
        skips=(
            # 跳过的测试条件，这里跳过 JIT 不支持可变长度张量的情况
            DecorateInfo(unittest.skip("Skipped!"), "TestJit", "test_variant_consistency_jit", dtypes=(torch.float32,),),
        )
    ),

    # 定义 OpInfo 对象，描述 nn.functional.pdist 函数
    OpInfo(
        "nn.functional.pdist",
        ref=reference_pdist,  # 参考实现的函数引用
        sample_inputs_func=sample_inputs_pdist,  # 提供生成样例输入的函数
        dtypes=floating_types(),  # 支持的数据类型包括所有浮点数类型
        supports_out=False,  # 不支持输出参数
        supports_gradgrad=False,  # 不支持二阶梯度计算
        skips=(
            # 跳过的测试条件，这里跳过在 MPS 上暂不支持的情况
            DecorateInfo(unittest.skip("Unsupported on MPS for now"), 'TestCommon', 'test_numpy_ref_mps'),
        )
    ),

    # 定义 OpInfo 对象，描述 nn.functional.poisson_nll_loss 函数
    OpInfo(
        "nn.functional.poisson_nll_loss",
        dtypes=all_types_and(torch.half, torch.bfloat16),  # 支持的数据类型包括所有类型和半精度浮点数
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持正向自动求导
        supports_fwgrad_bwgrad=True,  # 支持正向梯度和反向梯度计算
        sample_inputs_func=sample_inputs_poisson_nll_loss,  # 提供生成样例输入的函数
        error_inputs_func=error_inputs_poisson_nll_loss,  # 提供生成错误输入的函数
    ),

    # 定义 OpInfo 对象，描述 argsort 函数
    OpInfo(
        "argsort",
        dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型包括所有类型和布尔类型、半精度浮点数、bf16 浮点数
        dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),  # CUDA 下支持的数据类型包括半精度浮点数和 bf16 浮点数
        sample_inputs_func=sample_inputs_sort,  # 提供生成样例输入的函数
        supports_out=False,  # 不支持输出参数
        supports_autograd=False,  # 不支持自动求导
        skips=(
            # 跳过的测试条件，这里跳过 JIT 不支持的情况
            DecorateInfo(
                unittest.skip("Skipped!"),
                "TestJit",
                "test_variant_consistency_jit",
                dtypes=(torch.float32,),  # 仅在 float32 数据类型下跳过
            ),
        ),
    ),

    # 定义 OpInfo 对象，描述 repeat_interleave 函数
    OpInfo(
        "repeat_interleave",
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16, torch.chalf),  # 支持的数据类型包括所有类型和复数类型以及布尔类型、半精度浮点数、bf16 浮点数、复数 chalf
        backward_dtypesIfCUDA=floating_and_complex_types_and(torch.float16, torch.bfloat16, torch.chalf),  # CUDA 下支持的反向传播数据类型包括半精度浮点数、bf16 浮点数、复数 chalf
        sample_inputs_func=sample_inputs_repeat_interleave,  # 提供生成样例输入的函数
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持正向自动求导
        supports_fwgrad_bwgrad=True,  # 支持正向梯度和反向梯度计算
        # 详见 https://github.com/pytorch/pytorch/pull/78358
        check_batched_forward_grad=False,  # 不检查批处理的正向梯度
        skips=(
            # 跳过的测试条件，这里跳过 JIT 不支持的情况
            DecorateInfo(
                unittest.skip("Skipped!"),
                "TestJit",
                "test_variant_consistency_jit",
                dtypes=(torch.float32, torch.complex64),  # 仅在 float32 和 complex64 数据类型下跳过
            ),
        ),
    ),
    OpInfo(
        "nn.functional.pairwise_distance",  # 定义操作名称为 "nn.functional.pairwise_distance"
        ref=lambda a, b, p=2.0, eps=1e-6, keepdim=False: (  # 定义参考实现函数，计算两个张量的距离
            np.sum(np.abs(a - b + eps) ** p, axis=-1, keepdims=keepdim) ** (1 / p)  # 计算两个张量的 p 范数
        ),
        sample_inputs_func=sample_inputs_pairwise_distance,  # 设置用于样本输入生成的函数
        dtypes=all_types_and_complex_and(torch.float16, torch.bfloat16),  # 支持的数据类型
        supports_out=False,  # 不支持输出张量
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向后向梯度一致性
        skips=(  # 跳过测试信息
            DecorateInfo(
                unittest.skip("Skipped!"),  # 使用 unittest.skip 跳过测试
                "TestJit",  # 测试类名称
                "test_variant_consistency_jit",  # 测试方法名称
                dtypes=(torch.float32, torch.complex64),  # 跳过的数据类型
            ),
        ),
    ),
    OpInfo(
        "nn.functional.pixel_shuffle",  # 定义操作名称为 "nn.functional.pixel_shuffle"
        sample_inputs_func=sample_inputs_pixel_shuffle,  # 设置用于样本输入生成的函数
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型
        supports_out=False,  # 不支持输出张量
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向后向梯度一致性
        skips=(  # 跳过测试信息
            DecorateInfo(
                unittest.skip("Skipped!"),  # 使用 unittest.skip 跳过测试
                "TestJit",  # 测试类名称
                "test_variant_consistency_jit",  # 测试方法名称
                dtypes=(torch.float32, torch.complex64),  # 跳过的数据类型
            ),
        ),
    ),
    OpInfo(
        "nn.functional.pixel_unshuffle",  # 定义操作名称为 "nn.functional.pixel_unshuffle"
        sample_inputs_func=sample_inputs_pixel_unshuffle,  # 设置用于样本输入生成的函数
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型
        supports_out=False,  # 不支持输出张量
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向后向梯度一致性
        skips=(  # 跳过测试信息
            DecorateInfo(
                unittest.skip("Skipped!"),  # 使用 unittest.skip 跳过测试
                "TestJit",  # 测试类名称
                "test_variant_consistency_jit",  # 测试方法名称
                dtypes=(torch.float32, torch.complex64),  # 跳过的数据类型
            ),
        ),
    ),
    OpInfo(
        "nn.functional.channel_shuffle",  # 定义操作名称为 "nn.functional.channel_shuffle"
        sample_inputs_func=sample_inputs_channel_shuffle,  # 设置用于样本输入生成的函数
        dtypes=all_types_and(torch.bool, torch.float16, torch.bfloat16),  # 支持的数据类型
        backward_dtypes=integral_types_and(torch.bool),  # 反向传播支持的数据类型
        supports_out=False,  # 不支持输出张量
        supports_autograd=False,  # 不支持自动梯度
        allow_cow_input_materialize_forward=[0],  # 允许 Copy-On-Write 输入材料化前向
        skips=(  # 跳过测试信息
            # MPS 设备上不支持的操作，因此预期测试失败
            DecorateInfo(unittest.expectedFailure, 'TestConsistency'),
            # vmap: 不支持调用随机运算符
            DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_vmap_exhaustive"),
            DecorateInfo(unittest.skip("Test expects tensor input"), "TestVmapOperatorsOpInfo", "test_op_has_batch_rule"),
            DecorateInfo(unittest.expectedFailure, 'TestInductorOpInfo', 'test_comprehensive'),
            DecorateInfo(unittest.expectedFailure, 'TestDTensorOps', 'test_dtensor_op_db'),
            DecorateInfo(unittest.expectedFailure, "TestMeta", "test_dispatch_symbolic_meta_outplace_all_strides"),
        ),
    ),
    OpInfo(
        "nn.functional.kl_div",
        sample_inputs_func=sample_inputs_kl_div,  # 设置用于kl_div函数的样本输入生成函数
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 定义支持的数据类型为浮点类型和bfloat16
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
    ),
    OpInfo(
        "diagflat",
        ref=lambda input, offset=0: np.diagflat(input, k=offset),  # 定义引用函数为生成对角矩阵的函数
        sample_inputs_func=sample_inputs_diagflat,  # 设置用于diagflat函数的样本输入生成函数
        dtypes=all_types_and_complex_and(torch.bool, torch.bfloat16, torch.float16),  # 定义支持的数据类型为所有类型包括复数和torch.bool, torch.bfloat16, torch.float16
        dtypesIfCUDA=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),  # 定义CUDA环境下支持的数据类型
        supports_out=False,  # 不支持输出参数
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        # See https://github.com/pytorch/pytorch/pull/78358
        check_batched_forward_grad=False,  # 关闭批处理前向梯度检查
    ),
    OpInfo(
        'scatter_reduce',
        variant_test_name='sum',
        # 复杂梯度处理不完善，scatter_reduce尚未添加到gen_variable_type的白名单中，因此不添加复数类型到数据类型中
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 定义支持的数据类型为所有类型和torch.float16, torch.bfloat16, torch.bool
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        sample_inputs_func=sample_inputs_scatter_reduce,  # 设置用于scatter_reduce函数的样本输入生成函数
    ),
    OpInfo(
        'scatter_reduce',
        variant_test_name='prod',
        # 复杂梯度处理不完善，scatter_reduce尚未添加到gen_variable_type的白名单中，因此不添加复数类型到数据类型中
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 定义支持的数据类型为所有类型和torch.float16, torch.bfloat16, torch.bool
        dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),  # 定义CUDA环境下支持的数据类型
        sample_inputs_func=sample_inputs_scatter_reduce,  # 设置用于scatter_reduce函数的样本输入生成函数
        skips=(
            # 未实现
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', 'test_forward_mode_AD'),
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', 'test_inplace_forward_mode_AD'),
            DecorateInfo(unittest.expectedFailure, 'TestFwdGradients', 'test_fn_fwgrad_bwgrad'),
        ),
    ),
    OpInfo(
        'scatter_reduce',
        variant_test_name='mean',
        # 复杂梯度处理不完善，scatter_reduce尚未添加到gen_variable_type的白名单中，因此不添加复数类型到数据类型中
        dtypes=all_types_and(torch.float16, torch.bfloat16),  # 定义支持的数据类型为所有类型和torch.float16, torch.bfloat16
        dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),  # 定义CUDA环境下支持的数据类型
        supports_forward_ad=True,  # 支持前向自动求导
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        sample_inputs_func=sample_inputs_scatter_reduce,  # 设置用于scatter_reduce函数的样本输入生成函数
    ),
    OpInfo(
        'scatter_reduce',
        variant_test_name='amin',
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 定义支持的数据类型为所有类型和torch.float16, torch.bfloat16, torch.bool
        dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),  # 定义CUDA环境下支持的数据类型
        supports_forward_ad=True,  # 支持前向自动求导
        check_batched_forward_grad=False,  # 关闭批处理前向梯度检查
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和反向梯度
        sample_inputs_func=sample_inputs_scatter_reduce,  # 设置用于scatter_reduce函数的样本输入生成函数
    ),
    OpInfo(
        'scatter_reduce',  # 操作名称为'scatter_reduce'
        variant_test_name='amax',  # 变体测试名称为'amax'
        dtypes=all_types_and(torch.float16, torch.bfloat16, torch.bool),  # 支持的数据类型包括torch.float16, torch.bfloat16, torch.bool
        dtypesIfCUDA=all_types_and(torch.float16, torch.bfloat16),  # 在CUDA下支持的数据类型包括torch.float16, torch.bfloat16
        supports_forward_ad=True,  # 支持前向自动求导
        check_batched_forward_grad=False,  # 不检查批处理的前向梯度
        supports_fwgrad_bwgrad=True,  # 支持前向梯度和后向梯度
        sample_inputs_func=sample_inputs_scatter_reduce,  # 使用sample_inputs_scatter_reduce函数生成示例输入
    ),
    OpInfo(
        '_segment_reduce',  # 操作名称为'_segment_reduce'
        aten_name='segment_reduce',  # 对应的ATen函数名称为'segment_reduce'
        variant_test_name='lengths',  # 变体测试名称为'lengths'
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 支持的浮点数数据类型包括torch.float16, torch.bfloat16
        supports_out=False,  # 不支持输出参数
        # RuntimeError: derivative for aten::_segment_reduce_backward is not implemented
        supports_gradgrad=False,  # 不支持二阶导数
        sample_inputs_func=sample_inputs_segment_reduce,  # 使用sample_inputs_segment_reduce函数生成示例输入
        skips=(
            # FIXME: CUDA driver API confirmed a leak in
            # __main__.TestJitCUDA.test_variant_consistency_jit_segment_reduce_cuda_float32
            DecorateInfo(
                unittest.skip("Skipped!"),  # 使用unittest.skip函数跳过测试
                "TestJit",  # 测试类名称为'TestJit'
                "test_variant_consistency_jit",  # 测试方法名称为'test_variant_consistency_jit'
                device_type="cuda",  # 在CUDA设备上执行测试
            ),
        ),
    ),
    OpInfo(
        '_segment_reduce',  # 操作名称为'_segment_reduce'
        aten_name='segment_reduce',  # 对应的ATen函数名称为'segment_reduce'
        variant_test_name='offsets',  # 变体测试名称为'offsets'
        dtypes=floating_types_and(torch.float16, torch.bfloat16),  # 支持的浮点数数据类型包括torch.float16, torch.bfloat16
        supports_out=False,  # 不支持输出参数
        # RuntimeError: derivative for aten::_segment_reduce_backward is not implemented
        supports_gradgrad=False,  # 不支持二阶导数
        sample_inputs_func=partial(sample_inputs_segment_reduce, mode='offsets'),  # 使用带有mode='offsets'参数的sample_inputs_segment_reduce函数生成示例输入
        skips=(
            # FIXME: CUDA driver API confirmed a leak in
            # __main__.TestJitCUDA.test_variant_consistency_jit_segment_reduce_cuda_float32
            DecorateInfo(
                unittest.skip("Skipped!"),  # 使用unittest.skip函数跳过测试
                "TestJit",  # 测试类名称为'TestJit'
                "test_variant_consistency_jit",  # 测试方法名称为'test_variant_consistency_jit'
                device_type="cuda",  # 在CUDA设备上执行测试
            ),
        ),
    ),
# 向操作数据库中添加操作信息定义
op_db += opinfo.definitions.op_db

# 用于存储实验性Python参考操作信息的注册表
python_ref_db = [
    #
    # 单目素元操作信息
    #
    ElementwiseUnaryPythonRefInfo(
        "_refs.abs",
        torch_opinfo_name="abs",
        skips=(
            # 引用：https://github.com/pytorch/pytorch/issues/49224
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_small',
                         dtypes=[torch.int8], active_if=TEST_WITH_ASAN),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.acos",
        torch_opinfo_name="acos",
        skips=(
            # 在某些Windows作业中以错误的虚数符号失败
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_normal',
                         device_type='cuda', dtypes=[torch.cdouble],
                         active_if=IS_WINDOWS),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cuda', dtypes=[torch.cdouble],
                         active_if=IS_WINDOWS),
            # 在某些Windows作业中以错误的虚数符号失败
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_small',
                         device_type='cuda', dtypes=[torch.cdouble],
                         active_if=IS_WINDOWS),
            # 在某些Windows作业中以错误的虚数符号失败
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cuda', dtypes=[torch.cdouble],
                         active_if=IS_WINDOWS),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
        )
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.acosh",  # 创建 ElementwiseUnaryPythonRefInfo 对象，引用 "_refs.acosh"
        torch_opinfo_name="acosh",  # 设置 torch 操作的名称为 "acosh"
        skips=(  # 创建一个元组 skips，包含多个 DecorateInfo 对象，用于跳过测试条件
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',  # 调用 unittest 的 skip 方法创建跳过装饰器
                         'test_reference_numerics_normal',  # 指定跳过的测试方法为 'test_reference_numerics_normal'
                         device_type='cuda',  # 在 CUDA 设备上跳过测试
                         dtypes=[torch.cdouble],  # 适用于 torch.cdouble 类型的数据
                         active_if=IS_WINDOWS),  # 仅在 Windows 平台下激活跳过条件
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',  # 跳过测试 'test_reference_numerics_extremal'
                         device_type='cuda',  # 在 CUDA 设备上跳过测试
                         dtypes=[torch.cdouble],  # 适用于 torch.cdouble 类型的数据
                         active_if=IS_WINDOWS),  # 仅在 Windows 平台下激活跳过条件
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',  # 跳过测试 'test_reference_numerics_extremal'
                         device_type='cpu',  # 在 CPU 设备上跳过测试
                         dtypes=[torch.cfloat, torch.cdouble]),  # 适用于 torch.cfloat 和 torch.cdouble 类型的数据
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',  # 跳过测试 'test_reference_numerics_large'
                         device_type='cpu',  # 在 CPU 设备上跳过测试
                         dtypes=[torch.cfloat, torch.cdouble]),  # 适用于 torch.cfloat 和 torch.cdouble 类型的数据
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',  # 跳过测试 'test_reference_numerics_extremal'
                         device_type='cuda',  # 在 CUDA 设备上跳过测试
                         dtypes=[torch.cdouble],  # 适用于 torch.cdouble 类型的数据
                         active_if=IS_WINDOWS),  # 仅在 Windows 平台下激活跳过条件
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',  # 跳过测试 'test_reference_numerics_large'
                         device_type='cuda',  # 在 CUDA 设备上跳过测试
                         dtypes=[torch.cdouble],  # 适用于 torch.cdouble 类型的数据
                         active_if=IS_WINDOWS),
            # Failing with wrong imaginary sign on at least some Windows jobs
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_small',  # 跳过测试 'test_reference_numerics_small'
                         device_type='cuda',  # 在 CUDA 设备上跳过测试
                         dtypes=[torch.cdouble],  # 适用于 torch.cdouble 类型的数据
                         active_if=IS_WINDOWS),  # 仅在 Windows 平台下激活跳过条件
        ),
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理 torch 中的 asin 函数
    ElementwiseUnaryPythonRefInfo(
        "_refs.asin",
        torch_opinfo_name="asin",
        # 设置修饰器，用于特定测试和设备类型
        decorators=[
            DecorateInfo(
                toleranceOverride({torch.float16: tol(atol=1e-05, rtol=1e-03)}),
                'TestUnaryUfuncs', device_type='cuda'),
            precisionOverride({torch.bfloat16: 1e-2}),
        ],
        # 设置跳过条件，用于指定的测试情况和设备类型
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cuda', dtypes=[torch.cdouble],
                         active_if=IS_WINDOWS),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cuda', dtypes=[torch.cdouble],
                         active_if=IS_WINDOWS),
        ),
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理 torch 中的 asinh 函数
    ElementwiseUnaryPythonRefInfo(
        "_refs.asinh",
        torch_opinfo_name="asinh",
        # 设置修饰器，用于指定的精度覆盖
        decorators=(precisionOverride({torch.bfloat16: 5e-2}),),
        # 设置跳过条件，用于指定的测试情况和设备类型
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_small',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_normal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cuda', dtypes=[torch.cdouble],
                         active_if=IS_WINDOWS),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cuda', dtypes=[torch.cdouble],
                         active_if=IS_WINDOWS),
        ),
    ),
    # 创建 PythonRefInfo 对象，处理 torch 中的 lerp 函数
    PythonRefInfo(
        "_refs.lerp",
        torch_opinfo_name="lerp",
    ),
    PythonRefInfo(
        "_refs.ones",  # 创建一个 PythonRefInfo 对象，关联到 "_refs.ones"
        torch_opinfo_name="ones",  # 设置 torch_opinfo_name 属性为 "ones"
        skips=(  # 设置 skips 属性为包含以下测试信息的元组
            # 以下是一些假定输入为张量或张量序列的测试
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 标记预期失败的测试
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 标记预期失败的测试
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),  # 标记预期失败的测试
        ),
    ),
    PythonRefInfo(
        "_refs.zeros",  # 创建一个 PythonRefInfo 对象，关联到 "_refs.zeros"
        torch_opinfo_name="zeros",  # 设置 torch_opinfo_name 属性为 "zeros"
        skips=(  # 设置 skips 属性为包含以下测试信息的元组
            # 以下是一些假定输入为张量或张量序列的测试
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 标记预期失败的测试
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 标记预期失败的测试
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),  # 标记预期失败的测试
        ),
    ),
    PythonRefInfo(
        "_refs.cauchy",  # 创建一个 PythonRefInfo 对象，关联到 "_refs.cauchy"
        torch_opinfo_name="cauchy",  # 设置 torch_opinfo_name 属性为 "cauchy"
        decorators=(  # 设置 decorators 属性为包含以下装饰器信息的元组
            # TODO: RuntimeError: no _refs support for torch.rand_like
            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),  # 标记测试跳过并附带注释信息
                         'TestCommon',
                         'test_python_ref'),
            # AssertionError: Tensor-likes are not close!
            DecorateInfo(unittest.skip("Expected: cauchy is not comparable"),  # 标记测试跳过并附带注释信息
                         'TestCommon',
                         'test_out'),
            DecorateInfo(unittest.skip("Expected: cauchy is not comparable"),  # 标记测试跳过并附带注释信息
                         'TestCommon',
                         'test_out_warning'),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor'),  # 标记预期失败的测试
            DecorateInfo(unittest.skip("Expected: cauchy is not comparable"),  # 标记测试跳过并附带注释信息
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip('output is non-deterministic'),  # 标记测试跳过并附带注释信息
                         'TestCommon',
                         'test_compare_cpu'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 标记预期失败的测试
        )
    ),
    # 创建一个 PythonRefInfo 对象，用于描述 "_refs.exponential" 的信息
    PythonRefInfo(
        "_refs.exponential",  # 设置函数名为 "exponential"
        torch_opinfo_name="exponential",  # 在 torch_opinfo_name 中指定为 "exponential"
        supports_out=True,  # 支持输出参数
        decorators=(  # 使用装饰器进行修饰
            # 装饰器：unittest.expectedFailure，用于处理不支持 rand_like 的数据类型
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_meta',
                         dtypes=(torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64)),
            # 装饰器：unittest.skip，用于跳过测试 'test_dtypes'，显示信息为 'Skipped!'
            DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_dtypes'),

            # TODO: RuntimeError: no _refs support for torch.rand_like 的测试标记为跳过
            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
                         'TestCommon',
                         'test_python_ref'),

            # AssertionError: Tensor-likes are not close! 的测试标记为跳过，显示信息为 'Expected: exponential is not comparable'
            DecorateInfo(unittest.skip("Expected: exponential is not comparable"),
                         'TestCommon',
                         'test_out'),
            # 同上，针对 test_out_warning 测试
            DecorateInfo(unittest.skip("Expected: exponential is not comparable"),
                         'TestCommon',
                         'test_out_warning'),

            # 预期失败的测试：test_python_ref_executor
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor'),

            # 预期失败的测试：test_python_ref_torch_fallback，显示信息为 'Expected: exponential is not comparable'
            DecorateInfo(unittest.skip("Expected: exponential is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),

            # 装饰器：unittest.skip，用于跳过测试 'test_compare_cpu'，显示信息为 'output is non-deterministic'
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),

            # 预期失败的测试：test_neg_view
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
        )
    ),
    # 创建一个 PythonRefInfo 对象，用于存储关于"_refs.geometric"的参考信息
    PythonRefInfo(
        "_refs.geometric",
        torch_opinfo_name="geometric",
        supports_out=True,
        decorators=(
            # 装饰器列表开始，用于设置测试用例的装饰器
            # 跳过不支持 rand_like 的数据类型的测试
            DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_dtypes'),
            # 预期的失败：对于指定的数据类型，测试 Python 参考元数据
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_meta',
                         dtypes=(torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64)),
            # 预期的失败：测试 Python 参考的 Torch 回退，使用指定的数据类型
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64)),

            # TODO: RuntimeError: no _refs support for torch.rand_like
            # 跳过此测试，因为目前不支持 torch.rand_like 的 _refs
            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
                         'TestCommon',
                         'test_python_ref'),
            # 跳过此测试，因为在 CUDA 设备上执行时会出现 RuntimeError
            DecorateInfo(unittest.skip("Expected: geometric is not comparable"),
                         'TestCommon',
                         'test_python_ref_executor', device_type='cuda'),

            # AssertionError: Tensor-likes are not close!
            # 跳过此测试，因为预期的 geometric 不可比较
            DecorateInfo(unittest.skip("Expected: geometric is not comparable"),
                         'TestCommon',
                         'test_out'),
            # 跳过此测试，因为预期的 geometric 不可比较
            DecorateInfo(unittest.skip("Expected: geometric is not comparable"),
                         'TestCommon',
                         'test_out_warning'),
            # 跳过此测试，因为预期的 geometric 不可比较
            DecorateInfo(unittest.skip("Expected: geometric is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            # 跳过此测试，因为输出是非确定性的
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
            # 预期的失败：测试负数视图
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
        )
    ),
    PythonRefInfo(
        "_refs.log_normal",  # 创建 PythonRefInfo 对象，代表 log_normal 操作的引用信息
        torch_opinfo_name="log_normal",  # 指定 Torch 操作的名称为 log_normal
        supports_out=True,  # 指示该操作支持输出参数
        decorators=(
            # TODO: RuntimeError: no _refs support for torch.rand_like
            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),  # 添加装饰器信息，用于跳过测试用例
                         'TestCommon',  # 指定测试类名为 TestCommon
                         'test_python_ref'),  # 指定测试方法名为 test_python_ref

            # AssertionError: Tensor-likes are not close!
            DecorateInfo(unittest.skip("Expected: log_normal is not comparable"),  # 添加装饰器信息，用于跳过测试用例
                         'TestCommon',  # 指定测试类名为 TestCommon
                         'test_python_ref_executor', device_type='cuda'),  # 指定测试方法名为 test_python_ref_executor，设备类型为 'cuda'

            # 添加装饰器信息，用于跳过测试用例，预期测试用例不通过
            DecorateInfo(unittest.skip("Expected: log_normal is not comparable"),
                         'TestCommon',
                         'test_out'),
            DecorateInfo(unittest.skip("Expected: log_normal is not comparable"),
                         'TestCommon',
                         'test_out_warning'),
            DecorateInfo(unittest.skip("Expected: log_normal is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 添加预期测试失败的装饰器信息
        )
    ),
    PythonRefInfo(
        "_refs.normal",  # 创建 PythonRefInfo 对象，代表 normal 操作的引用信息
        torch_opinfo_name="normal",  # 指定 Torch 操作的名称为 normal
        supports_out=True,  # 指示该操作支持输出参数
        decorators=(
            # TODO: RuntimeError: no _refs support for torch.rand_like
            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),  # 添加装饰器信息，用于跳过测试用例
                         'TestCommon',  # 指定测试类名为 TestCommon
                         'test_python_ref'),

            # AssertionError: Tensor-likes are not close!
            DecorateInfo(unittest.skip("Expected: normal is not comparable"),  # 添加装饰器信息，用于跳过测试用例
                         'TestCommon',  # 指定测试类名为 TestCommon
                         'test_out'),
            DecorateInfo(unittest.skip("Expected: normal is not comparable"),
                         'TestCommon',
                         'test_out_warning'),
            DecorateInfo(unittest.skip("Expected: normal is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: normal is not comparable"), 'TestDecomp', 'test_comprehensive'),
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
            DecorateInfo(unittest.skip("make_traced() doesn't set seed properly!"), 'TestCommon', 'test_python_ref_executor'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 添加预期测试失败的装饰器信息
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
        )
    ),
    PythonRefInfo(
        "_refs.normal",
        torch_opinfo_name="normal",
        torch_opinfo_variant_name="number_mean",
        supports_out=True,
        decorators=(
            # TODO: 标记为需要处理的问题：RuntimeError: no _refs support for torch.rand_like
            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
                         'TestCommon',
                         'test_python_ref'),

            # AssertionError: Tensor-likes are not close!
            # 标记为跳过的测试：预期结果为 normal 不可比较
            DecorateInfo(unittest.skip("Expected: normal is not comparable"),
                         'TestCommon',
                         'test_out'),
            DecorateInfo(unittest.skip("Expected: normal is not comparable"),
                         'TestCommon',
                         'test_out_warning'),
            DecorateInfo(unittest.skip("Expected: normal is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: normal is not comparable"), 'TestDecomp', 'test_comprehensive'),
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
            DecorateInfo(unittest.skip("make_traced() doesn't set seed properly!"), 'TestCommon', 'test_python_ref_executor'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),
        )
    ),
    PythonRefInfo(
        "_refs.normal_",
        op=torch.Tensor.normal_,
        torch_opinfo_name="normal",
        torch_opinfo_variant_name="in_place",
        supports_out=False,
        decorators=(
            # 跳过测试，因为不支持 torch.rand_like 的 _refs
            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
                         'TestCommon',
                         'test_python_ref'),

            # 跳过测试，因为预期 normal 无法比较
            DecorateInfo(unittest.skip("Expected: normal is not comparable"),
                         'TestCommon',
                         'test_out'),
            DecorateInfo(unittest.skip("Expected: normal is not comparable"),
                         'TestCommon',
                         'test_out_warning'),
            DecorateInfo(unittest.skip("Expected: normal is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: normal is not comparable"), 'TestDecomp', 'test_comprehensive'),
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
            DecorateInfo(unittest.skip("make_traced() doesn't set seed properly!"), 'TestCommon', 'test_python_ref_executor'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 预期测试失败
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 预期测试失败
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),  # 预期测试失败
        )
    ),
    PythonRefInfo(
        "_refs.arange",
        torch_opinfo_name="arange",
        skips=(
            # Tests that assume input is a tensor or sequence of tensors
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 预期测试失败
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 预期测试失败
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),  # 预期测试失败
        ),
    ),
    PythonRefInfo(
        "_refs.linspace",
        torch_opinfo_name="linspace",
        skips=(
            # 跳过以下测试，因为它们假设输入是张量或张量序列
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),

            # 在某些整数类型上，CPU 实现存在问题
            # https://github.com/pytorch/pytorch/issues/81996
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64), device_type="cpu"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                         dtypes=(torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64), device_type="cpu"),

            # 由于精度问题，某些输入在 CUDA 实现上存在一位偏差
            # https://github.com/pytorch/pytorch/issues/82230
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                         dtypes=(torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor',
                         dtypes=(torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
        ),
    ),
    PythonRefInfo(
        "_refs.linspace",
        torch_opinfo_name="linspace",
        torch_opinfo_variant_name="tensor_overload",
        skips=(
            # 跳过以下测试用例，因为它们会导致 TypeError: 'int' object is not subscriptable 异常
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),

            # 跳过以下测试用例，因为在某些整数类型上 CPU 实现存在问题
            # https://github.com/pytorch/pytorch/issues/81996
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64), device_type="cpu"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                         dtypes=(torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64), device_type="cpu"),

            # 跳过以下测试用例，因为在某些输入上 CUDA 实现存在精度问题导致结果偏离预期
            # https://github.com/pytorch/pytorch/issues/82230
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                         dtypes=(torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor',
                         dtypes=(torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
        ),
    ),
    PythonRefInfo(
        "_refs.logspace",
        torch_opinfo_name="logspace",
        skips=(
            # 跳过以下测试用例，因为它们假定输入是张量或张量序列
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_conj_view'),

            # 跳过以下测试用例，因为在将浮点数转换为整数时存在一位偏移的问题
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                         dtypes=(torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor',
                         dtypes=(torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
        ),
    ),
    PythonRefInfo(
        "_refs.logspace",  # 创建 PythonRefInfo 对象，用于记录 logspace 函数的参考信息
        torch_opinfo_name="logspace",  # 指定 Torch 操作的名称为 logspace
        torch_opinfo_variant_name="tensor_overload",  # 指定 Torch 操作的变体名称为 tensor_overload
        skips=(  # 设置跳过的测试用例列表
            # TypeError: 'int' object is not subscriptable
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_neg_view'),  # 标记预期失败的测试用例
            DecorateInfo(unittest.expectedFailure, 'TestMathBits', 'test_conj_view'),  # 标记预期失败的测试用例

            # Off-by-one issue when casting floats to ints
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',  # 标记预期失败的测试用例，指定数据类型和设备类型
                         dtypes=(torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref',  # 标记预期失败的测试用例，指定数据类型和设备类型
                         dtypes=(torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor',  # 标记预期失败的测试用例，指定数据类型和设备类型
                         dtypes=(torch.int16, torch.int32, torch.int64),
                         device_type="cuda"),
        ),
    ),
    PythonRefInfo(
        "_refs.meshgrid",  # 创建 PythonRefInfo 对象，用于记录 meshgrid 函数的参考信息
        torch_opinfo_name="meshgrid",  # 指定 Torch 操作的名称为 meshgrid
        torch_opinfo_variant_name="variadic_tensors",  # 指定 Torch 操作的变体名称为 variadic_tensors
    ),
    PythonRefInfo(
        "_refs.take_along_dim",  # 创建 PythonRefInfo 对象，用于记录 take_along_dim 函数的参考信息
        torch_opinfo_name="take_along_dim",  # 指定 Torch 操作的名称为 take_along_dim
        skips=(  # 设置跳过的测试用例列表
            DecorateInfo(unittest.expectedFailure,  # 标记预期失败的测试用例，指定测试类和方法名
                         'TestCommon',
                         'test_python_ref'),
        ),
    ),
    PythonRefInfo(
        "_refs.to",  # 创建 PythonRefInfo 对象，用于记录 to 函数的参考信息
        torch_opinfo_name="to",  # 指定 Torch 操作的名称为 to
    ),
    PythonRefInfo(
        "_refs.triu",  # 创建 PythonRefInfo 对象，用于记录 triu 函数的参考信息
        torch_opinfo_name="triu",  # 指定 Torch 操作的名称为 triu
    ),
    PythonRefInfo(
        "_refs.tril",  # 创建 PythonRefInfo 对象，用于记录 tril 函数的参考信息
        torch_opinfo_name="tril",  # 指定 Torch 操作的名称为 tril
    ),
    PythonRefInfo(
        "_refs.triu_indices",  # 创建 PythonRefInfo 对象，用于记录 triu_indices 函数的参考信息
        torch_opinfo_name="triu_indices",  # 指定 Torch 操作的名称为 triu_indices
        validate_view_consistency=False,  # 设置视图一致性验证为 False
        skips=(  # 设置跳过的测试用例列表
            # skip these tests since we have non tensor input
            DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_noncontiguous_samples'),  # 标记跳过的测试用例，指定测试类和方法名
            DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_variant_consistency_eager'),  # 标记跳过的测试用例，指定测试类和方法名
            DecorateInfo(unittest.skip('Skipped!'), 'TestJit', 'test_variant_consistency_jit'),  # 标记跳过的测试用例，指定测试类和方法名
            DecorateInfo(unittest.skip('Skipped!'), 'TestMathBits', 'test_neg_view'),  # 标记跳过的测试用例，指定测试类和方法名
        )),
    PythonRefInfo(
        "_refs.tril_indices",
        torch_opinfo_name="tril_indices",
        # 由于实现中使用了破坏视图一致性的 torch.stack
        validate_view_consistency=False,
        skips=(
            # 跳过这些测试，因为存在非张量输入
            DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_noncontiguous_samples'),
            DecorateInfo(unittest.skip('Skipped!'), 'TestCommon', 'test_variant_consistency_eager'),
            DecorateInfo(unittest.skip('Skipped!'), 'TestJit', 'test_variant_consistency_jit'),
            DecorateInfo(unittest.skip('Skipped!'), 'TestMathBits', 'test_neg_view'),
        )),
    PythonRefInfo(
        "_refs.meshgrid",
        torch_opinfo_name="meshgrid",
        torch_opinfo_variant_name="list_of_tensors",
    ),
    PythonRefInfo(
        "_refs.movedim",
        aliases=('moveaxis',),
        torch_opinfo_name="movedim",
    ),
    PythonRefInfo(
        "_refs.bucketize",
        torch_opinfo_name="bucketize",
        skips=(
            # 运行时错误: 似乎尝试从跟踪张量中获取值，出错！
            # 由 mid_val = boundaries[mid] 触发
            DecorateInfo(unittest.expectedFailure, "TestCommon", "test_python_ref_executor"),
        )
    ),
    PythonRefInfo(
        "_refs.equal",
        torch_opinfo_name="equal",
        skips=(
            # 运行时错误: 无法将 FakeTensor 转换为数字
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_meta',),
        )
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.atan",
        torch_opinfo_name="atan",
        decorators=(precisionOverride({torch.bfloat16: 1e-2}),),
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_small',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cuda', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=IS_WINDOWS),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cuda', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=IS_WINDOWS),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.atanh",
        torch_opinfo_name="atanh",
        decorators=(precisionOverride({torch.bfloat16: 1e-2}),),
        skips=(
            # 在特定的测试条件下跳过测试：TestUnaryUfuncs.test_reference_numerics_small
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_small',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            # 在特定的测试条件下跳过测试：TestUnaryUfuncs.test_reference_numerics_extremal
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            # 在特定的测试条件下跳过测试：TestUnaryUfuncs.test_reference_numerics_large
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            # 在特定的测试条件下跳过测试：TestUnaryUfuncs.test_reference_numerics_extremal
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cuda', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=IS_WINDOWS),
            # 在特定的测试条件下跳过测试：TestUnaryUfuncs.test_reference_numerics_large
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cuda', dtypes=[torch.cfloat],
                         active_if=IS_WINDOWS),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.bitwise_not",
        torch_opinfo_name="bitwise_not",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.ceil",
        torch_opinfo_name="ceil",
        # 在 int32 类型上存在的问题：https://github.com/pytorch/pytorch/issues/85258
        # Fails on int32
    ),
    PythonRefInfo(
        "_refs.item",
        torch_opinfo_name="item",
        skips=(
            # 在特定的测试条件下预期测试失败：TestCommon.test_python_ref_meta
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_meta'),
            # 在特定的测试条件下预期测试失败：TestCommon.test_python_ref_errors
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.conj_physical",
        torch_opinfo_name="conj_physical",
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于描述元素级的一元操作的参考信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.cos",  # 操作函数名称为 '_refs.cos'
        torch_opinfo_name="cos",  # Torch 中对应的操作函数名称为 'cos'
        decorators=(precisionOverride({torch.bfloat16: 1e-2}),),  # 添加修饰器，设置精度覆盖
        skips=(  # 设置跳过条件的元组，包含多个 DecorateInfo 对象
            # 跳过条件：在 Windows 平台、使用 CPU、复数类型 (torch.cfloat, torch.cdouble) 下的测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=(torch.cfloat, torch.cdouble,), device_type='cpu',
                         active_if=IS_WINDOWS),
            # 跳过条件：在 CUDA 平台、使用 GPU、双精度复数类型 (torch.cdouble) 下的测试
            # 但在 ROCm 平台上可以通过
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=(torch.cdouble,), device_type='cuda'),
            # 跳过条件：在 Windows 平台、使用 CPU、复数类型 (torch.cfloat, torch.cdouble) 下的极值测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=[torch.cfloat, torch.cdouble], active_if=IS_WINDOWS),
            # 跳过条件：在 macOS 平台、使用 CPU、复数类型 (torch.cfloat, torch.cdouble) 下的极值测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu',
                         dtypes=[torch.cfloat, torch.cdouble], active_if=IS_MACOS),
            # 期望测试失败条件：在 Windows 平台、使用 CUDA、半精度复数类型 (torch.chalf) 下的大数值测试
            # 预期出现 AssertionError: Tensor-likes are not close!
            # 最大的绝对差异为 nan 在索引 (700,) 处 (允许最多 1e-05 差异)
            # 最大的相对差异为 nan 在索引 (700,) 处 (允许最多 0.001 差异)
            DecorateInfo(unittest.expectedFailure, 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cuda',
                         dtypes=(torch.chalf,), active_if=IS_WINDOWS),
        ),
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理 _refs.cosh 函数信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.cosh",
        torch_opinfo_name="cosh",
        skips=(
            # 跳过测试装饰器信息，针对特定测试用例
            # 参考链接: https://github.com/pytorch/pytorch/issues/48641
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.int8]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=[torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=[torch.cfloat, torch.cdouble], active_if=IS_WINDOWS),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=[torch.cfloat, torch.cdouble], active_if=IS_WINDOWS),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu',
                         dtypes=[torch.cfloat, torch.cdouble], active_if=IS_MACOS),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu',
                         dtypes=[torch.cfloat, torch.cdouble], active_if=IS_MACOS),
            # 预期测试失败的装饰器信息，针对 CUDA 设备的测试用例
            # 出现 AssertionError: Tensor-likes are not close!
            # 最大绝对差异: 在索引 (6000,) 处为 nan（允许最大差异为 1e-05）
            # 最大相对差异: 在索引 (6000,) 处为 nan（允许最大相对差异为 0.001）
            DecorateInfo(unittest.expectedFailure, 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cuda',
                         dtypes=(torch.chalf,), active_if=IS_WINDOWS),
        ),
    ),

    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理 _refs.digamma 函数信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.digamma",
        torch_opinfo_name="digamma",
    ),

    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理 _refs.erf 函数信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.erf",
        torch_opinfo_name="erf",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.erfinv",
        torch_opinfo_name="erfinv",
        decorators=(precisionOverride({torch.float16: 1e-2,
                                       torch.bfloat16: 1e-2,
                                       torch.float32: 1e-4}),),
        skips=(
            # 引用：https://github.com/pytorch/pytorch/pull/49155#issuecomment-742664611
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                'test_reference_numerics_extremal',
                active_if=TEST_SCIPY and version.parse(scipy.__version__) < version.parse("1.4.0")),
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                'test_reference_numerics_large',
                active_if=TEST_SCIPY and version.parse(scipy.__version__) < version.parse("1.4.0")),
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                'test_reference_numerics_small',
                active_if=TEST_SCIPY and version.parse(scipy.__version__) < version.parse("1.4.0")),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.erfc",
        torch_opinfo_name="erfc",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.exp",
        torch_opinfo_name="exp",
        skips=(
            # 引用：https://github.com/pytorch/pytorch/issues/48010
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.expm1",
        torch_opinfo_name="expm1",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.exp2",
        torch_opinfo_name="exp2",
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=[torch.cdouble]),
            # 引用：https://github.com/pytorch/pytorch/issues/48010
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.fill",
        torch_opinfo_name="fill",
        supports_out=True,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.floor",
        torch_opinfo_name="floor",
        # 在 int32 类型上失败
        # https://github.com/pytorch/pytorch/issues/85258
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.frexp",
        torch_opinfo_name="frexp",
        # 在 Windows CI 上由于数值失败而跳过
        # 在文件早期的 frexp 也被跳过了
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs', 'test_reference_numerics_extremal',
                         active_if=IS_WINDOWS),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.frac",
        torch_opinfo_name="frac",
        # 在 bfloat16, float16, float32, float64 类型上被跳过
        skips=(
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                'test_reference_numerics_extremal',
                dtypes=(torch.bfloat16, torch.float16, torch.float32, torch.float64)),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.imag",
        torch_opinfo_name="imag",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.isfinite",
        torch_opinfo_name="isfinite",
        supports_out=True,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.isinf",
        torch_opinfo_name="isinf",
        supports_out=True,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.isposinf",
        torch_opinfo_name="isposinf",
        supports_out=True,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.isneginf",
        torch_opinfo_name="isneginf",
        supports_out=True,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.isnan",
        torch_opinfo_name="isnan",
        supports_out=True,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.isreal",
        torch_opinfo_name="isreal",
        supports_out=True,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.i0",
        torch_opinfo_name="i0",
        decorators=(precisionOverride({torch.bfloat16: 3e-1,
                                       torch.float16: 5e-1}),),
        skips=(
            DecorateInfo(unittest.skip("Skipped!"),
                         'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=(torch.int8,)),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.lgamma",
        torch_opinfo_name="lgamma",
        decorators=(precisionOverride({torch.float16: 7e-1}),),
        skips=(
            # 参考: https://github.com/pytorch/pytorch/pull/50140#issuecomment-756150214
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=[torch.float32, torch.float64], active_if=IS_WINDOWS),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=[torch.float32, torch.float64], active_if=IS_WINDOWS),
        ),
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于特殊函数 "_refs.special.multigammaln"
    # 设置 torch_opinfo_name 和 torch_opinfo_variant_name 为 "mvlgamma" 和 "mvlgamma_p_1"
    # 调用 skips_mvlgamma() 函数获取 skips 参数列表
    # 设置装饰器为 markDynamoStrictTest 和 xfailIfTorchDynamo
    ElementwiseUnaryPythonRefInfo(
        "_refs.special.multigammaln",
        torch_opinfo_name="mvlgamma",
        torch_opinfo_variant_name="mvlgamma_p_1",
        skips=skips_mvlgamma(),
        decorators=(
            DecorateInfo(torch.testing._internal.common_utils.markDynamoStrictTest, 'TestUnaryUfuncs',
                         'test_reference_numerics_large'),
            DecorateInfo(torch.testing._internal.common_utils.xfailIfTorchDynamo, 'TestUnaryUfuncs',
                         'test_reference_numerics_large'),
        ),
    ),
    
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于特殊函数 "_refs.special.multigammaln"
    # 设置 torch_opinfo_name 和 torch_opinfo_variant_name 为 "mvlgamma" 和 "mvlgamma_p_3"
    # 调用 skips_mvlgamma() 函数获取 skips 参数列表
    ElementwiseUnaryPythonRefInfo(
        "_refs.special.multigammaln",
        torch_opinfo_name="mvlgamma",
        torch_opinfo_variant_name="mvlgamma_p_3",
        skips=skips_mvlgamma(),
    ),
    
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于特殊函数 "_refs.special.multigammaln"
    # 设置 torch_opinfo_name 和 torch_opinfo_variant_name 为 "mvlgamma" 和 "mvlgamma_p_5"
    # 调用 skips_mvlgamma() 函数获取 skips 参数列表
    ElementwiseUnaryPythonRefInfo(
        "_refs.special.multigammaln",
        torch_opinfo_name="mvlgamma",
        torch_opinfo_variant_name="mvlgamma_p_5",
        skips=skips_mvlgamma(),
    ),
    
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于特殊函数 "_refs.log"
    # 设置 torch_opinfo_name 为 "log"
    # 设置 decorators 为 precisionOverride({torch.bfloat16: 5e-2})
    # 设置 skips 为 DecorateInfo 对象列表，包含 unittest.skip("Skipped!")
    ElementwiseUnaryPythonRefInfo(
        "_refs.log",
        torch_opinfo_name="log",
        decorators=(precisionOverride({torch.bfloat16: 5e-2}),),
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=IS_WINDOWS),
        ),
    ),
    
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于特殊函数 "_refs.log1p"
    # 设置 torch_opinfo_name 为 "log1p"
    ElementwiseUnaryPythonRefInfo(
        "_refs.log1p",
        torch_opinfo_name="log1p",
    ),
    
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于特殊函数 "_refs.log10"
    # 设置 torch_opinfo_name 为 "log10"
    # 设置 decorators 为 precisionOverride({torch.bfloat16: 5e-2})
    # 设置 skips 为 DecorateInfo 对象列表，包含 unittest.skip("Skipped!")
    ElementwiseUnaryPythonRefInfo(
        "_refs.log10",
        torch_opinfo_name="log10",
        decorators=(precisionOverride({torch.bfloat16: 5e-2}),),
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=IS_WINDOWS),
        ),
    ),
    
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于特殊函数 "_refs.log2"
    # 设置 torch_opinfo_name 为 "log2"
    # 设置 decorators 为 precisionOverride({torch.bfloat16: 1e-1})
    # 设置 skips 为 DecorateInfo 对象列表，包含 unittest.skip("Skipped!")
    ElementwiseUnaryPythonRefInfo(
        "_refs.log2",
        torch_opinfo_name="log2",
        decorators=(precisionOverride({torch.bfloat16: 1e-1}),),
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=[torch.cfloat, torch.cdouble]),
        ),
    ),
    
    # 创建 PythonRefInfo 对象，用于特殊函数 "_refs.logsumexp"
    # 设置 torch_opinfo_name 为 "logsumexp"
    # 添加注释说明 logsumexp 函数在 keepdim=False 时使用 squeeze 操作，
    # 该操作在 nvFuser 的 Python API 中尚未暴露
    PythonRefInfo(
        "_refs.logsumexp",
        torch_opinfo_name="logsumexp",
        # When keepdim=False logsumexp function uses squeeze operation
        # that is not yet exposed in nvFuser's Python API.
    ),
    
    # 创建 PythonRefInfo 对象，用于特殊函数 "_refs.log_softmax"
    # 设置 torch_opinfo_name 为 "log_softmax"
    # 设置 torch_opinfo_variant_name 为 "with_dtype"
    PythonRefInfo(
        "_refs.log_softmax",
        torch_opinfo_name="log_softmax",
        torch_opinfo_variant_name="with_dtype",
    ),
    
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于特殊函数 "_refs.nan_to_num"
    # 设置 torch_opinfo_name 为 "nan_to_num"
    ElementwiseUnaryPythonRefInfo(
        "_refs.nan_to_num",
        torch_opinfo_name="nan_to_num",
    ),
    
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于特殊函数 "_refs.neg"
    # 设置 torch_opinfo_name 为 "neg"
    ElementwiseUnaryPythonRefInfo(
        "_refs.neg",
        torch_opinfo_name="neg",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.positive",
        torch_opinfo_name="positive",
    ),
    # 定义了一个一元操作的参考信息，对应 torch 中的 positive 操作

    ElementwiseUnaryPythonRefInfo(
        "_refs.real",
        torch_opinfo_name="real",
    ),
    # 定义了一个一元操作的参考信息，对应 torch 中的 real 操作

    ElementwiseUnaryPythonRefInfo(
        "_refs.reciprocal",
        torch_opinfo_name="reciprocal",
        skips=(
            # 跳过特定测试用例，参考 GitHub 上的问题链接
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=[torch.cfloat, torch.cdouble]),
        ),
    ),
    # 定义了一个一元操作的参考信息，对应 torch 中的 reciprocal 操作，并指定了需要跳过的测试用例

    ElementwiseUnaryPythonRefInfo(
        "_refs.round",
        torch_opinfo_name="round",
        skips=(
            # 跳过特定测试用例，参考 GitHub 上的问题链接
            DecorateInfo(toleranceOverride({torch.bfloat16: tol(atol=1e-3, rtol=0.016)}),
                         "TestUnaryUfuncs", "test_reference_numerics_extremal",
                         device_type="cuda"),
            DecorateInfo(toleranceOverride({torch.bfloat16: tol(atol=1e-3, rtol=0.016)}),
                         "TestUnaryUfuncs", "test_reference_numerics_normal",
                         device_type="cuda"),
        ),
    ),
    # 定义了一个一元操作的参考信息，对应 torch 中的 round 操作，并指定了需要跳过的测试用例

    ElementwiseUnaryPythonRefInfo(
        "_refs.rsqrt",
        torch_opinfo_name="rsqrt",
        decorators=(precisionOverride({torch.half: 5e-2}),),
        skips=(
            # 跳过特定测试用例，参考 GitHub 上的问题链接
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=(torch.cfloat, torch.cdouble)),
            # 标记特定测试用例为预期失败
            DecorateInfo(unittest.expectedFailure, 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=(torch.chalf,)),
        ),
    ),
    # 定义了一个一元操作的参考信息，对应 torch 中的 rsqrt 操作，并指定了需要跳过的测试用例及其它修饰器
    ElementwiseUnaryPythonRefInfo(
        "_refs.sigmoid",  # 创建一个 ElementwiseUnaryPythonRefInfo 对象，用于 sigmoid 函数的参考信息
        torch_opinfo_name="sigmoid",  # 指定 Torch 操作的名称为 "sigmoid"
        aliases=('_refs.special.expit',),  # sigmoid 函数的别名为 '_refs.special.expit'
        # 设置不处理复杂极端值和大浮点数
        handles_complex_extremal_values=False,
        handles_large_floats=False,
        decorators=(  # 设置修饰器，针对不同数据类型设置精度限制
            precisionOverride({torch.float16: 1e-2,
                               torch.complex64: 1e-1,
                               torch.bfloat16: 1e-2}),
        ),
        skips=(  # 设置跳过测试的条件列表
            # 跳过包含复数数据类型的极端值测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=[torch.complex64, torch.cdouble]),
            # 跳过大浮点数数据类型的测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=[torch.chalf, torch.complex64, torch.cdouble])
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.sign",  # 创建一个 ElementwiseUnaryPythonRefInfo 对象，用于 sign 函数的参考信息
        torch_opinfo_name="sign",  # 指定 Torch 操作的名称为 "sign"
        skips=(  # 设置跳过测试的条件列表
            # 跳过包含特定浮点数数据类型的极端值测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=[torch.bfloat16, torch.float16, torch.float32,
                                 torch.float64]),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.sgn",  # 创建一个 ElementwiseUnaryPythonRefInfo 对象，用于 sgn 函数的参考信息
        torch_opinfo_name="sgn",  # 指定 Torch 操作的名称为 "sgn"
        # 设置不处理复杂极端值和大浮点数
        handles_complex_extremal_values=False,
        handles_large_floats=False,
        skips=(  # 设置跳过测试的条件列表
            # 跳过包含特定浮点数数据类型的极端值测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=[torch.bfloat16, torch.float16, torch.float32,
                                 torch.float64]),
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.signbit",  # 创建一个 ElementwiseUnaryPythonRefInfo 对象，用于 signbit 函数的参考信息
        torch_opinfo_name="signbit",  # 指定 Torch 操作的名称为 "signbit"
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.sin",
        torch_opinfo_name="sin",
        decorators=(precisionOverride({torch.bfloat16: 1e-2}),),
        skips=(
            # 在 CUDA 上失败但在 ROCm 上通过
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=(torch.cdouble,), device_type='cuda'),
            # 在 Windows 上激活时，对于 CPU 上的复数浮点数和双精度浮点数进行跳过
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         dtypes=(torch.cfloat, torch.cdouble,), device_type='cpu',
                         active_if=IS_WINDOWS),
            # 在 Windows 上激活时，对于 CPU 上的复数浮点数和双精度浮点数进行跳过
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=(torch.cfloat, torch.cdouble,), device_type='cpu',
                         active_if=IS_WINDOWS),
        ),
    ),
    
    ElementwiseUnaryPythonRefInfo(
        "_refs.sinc",
        torch_opinfo_name="sinc",
        decorators=(precisionOverride({torch.bfloat16: 1e-2,
                                       torch.float16: 1e-2}),),
        skips=(
            # 参考链接: https://github.com/pytorch/pytorch/issues/49133
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_small',
                         dtypes=[torch.cfloat]),
        ),
    ),
    
    ElementwiseUnaryPythonRefInfo(
        "_refs.sinh",
        torch_opinfo_name="sinh",
        decorators=(precisionOverride({torch.float16: 1e-2}),),
        skips=(
            # 在 MacOS 或 Windows 上激活时，对于 CPU 上的复数浮点数和双精度浮点数进行跳过
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=(IS_MACOS or IS_WINDOWS)),
            # 在 MacOS 或 Windows 上激活时，对于 CPU 上的复数浮点数和双精度浮点数进行跳过
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=(IS_MACOS or IS_WINDOWS)),
            # 参考链接: https://github.com/pytorch/pytorch/issues/48641
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=(torch.cdouble,)),
            # 参考链接: https://github.com/pytorch/pytorch/issues/48641
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.int8]),
        ),
    ),
    
    PythonRefInfo(
        "_refs.softmax",
        torch_opinfo_name="softmax",
        torch_opinfo_variant_name="with_dtype",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.sqrt",  # 定义一个 ElementwiseUnaryPythonRefInfo 对象，表示对 sqrt 函数的引用
        torch_opinfo_name="sqrt",  # 指定对应的 Torch 操作名称为 "sqrt"
        decorators=(  # 设置修饰器列表，用于精度和容差的覆盖
            precisionOverride({torch.bfloat16: 7e-2}),  # 对于 torch.bfloat16 类型，设置精度为 7e-2
            DecorateInfo(  # 创建 DecorateInfo 对象，用于特定测试用例的修饰
                toleranceOverride({torch.chalf: tol(atol=1e-2, rtol=0)}),  # 对于 torch.chalf 类型，设置容差为 tol(atol=1e-2, rtol=0)
                'TestUnaryUfuncs', 'test_reference_numerics_large'),  # 标记该修饰信息适用于 'TestUnaryUfuncs' 中的 'test_reference_numerics_large' 测试用例
        ),
        skips=(  # 设置跳过列表，用于标记不执行的情况
            # 引用：https://github.com/pytorch/pytorch/issues/47358
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=(torch.cfloat, torch.cdouble),
                         active_if=IS_MACOS),  # 标记在 macOS 下，针对 CPU 和指定数据类型不执行该测试用例
            # 引用：https://github.com/pytorch/pytorch/pull/47293#issuecomment-721774436
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=(torch.bfloat16,)),  # 标记针对 torch.bfloat16 类型不执行该测试用例
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.square",  # 定义一个 ElementwiseUnaryPythonRefInfo 对象，表示对 square 函数的引用
        torch_opinfo_name="square",  # 指定对应的 Torch 操作名称为 "square"
        decorators=(  # 设置修饰器列表，用于精度和容差的覆盖
            precisionOverride({torch.complex64: 3e-4, torch.bfloat16: 3e-1}),  # 对于 torch.complex64 和 torch.bfloat16 类型，设置精度
        ),
        skips=(  # 设置跳过列表，用于标记不执行的情况
            # AssertionError: 参考结果与精确计算相差较远 (2.2417024338305655e-07)
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref_executor', dtypes=(torch.complex64,)),  # 标记针对 torch.complex64 类型不执行该测试用例
            # 引用：https://github.com/pytorch/pytorch/issues/52549
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         dtypes=[torch.cfloat, torch.cdouble]),  # 标记针对 torch.cfloat 和 torch.cdouble 类型不执行该测试用例
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cuda', dtypes=[torch.cfloat, torch.cdouble]),  # 标记在 CUDA 设备上，针对 torch.cfloat 和 torch.cdouble 类型不执行该测试用例
        ),
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.tan",  # 定义一个 ElementwiseUnaryPythonRefInfo 对象，表示对 tan 函数的引用
        torch_opinfo_name="tan",  # 指定对应的 Torch 操作名称为 "tan"
        decorators=[  # 设置修饰器列表，用于容差的覆盖
            DecorateInfo(
                toleranceOverride({torch.complex64: tol(atol=1e-04, rtol=1e-05)}),  # 对于 torch.complex64 类型，设置容差
                'TestUnaryUfuncs', 'test_reference_numerics_extremal', device_type='cuda'),  # 标记该修饰信息适用于 'TestUnaryUfuncs' 中的 'test_reference_numerics_extremal' 测试用例，且在 CUDA 设备上
        ],
        skips=(  # 设置跳过列表，用于标记不执行的情况
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=(IS_MACOS or IS_WINDOWS)),  # 标记在 macOS 或 Windows 下，针对 CPU 和指定数据类型不执行该测试用例
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=(IS_MACOS or IS_WINDOWS)),  # 标记在 macOS 或 Windows 下，针对 CPU 和指定数据类型不执行该测试用例
        )
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.tanh",
        torch_opinfo_name="tanh",
        decorators=[
            DecorateInfo(
                toleranceOverride({torch.complex64: tol(atol=1e-04, rtol=2e-05)}),
                'TestUnaryUfuncs', 'test_reference_numerics_extremal', device_type='cuda'),
        ],
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_extremal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=(IS_MACOS or IS_WINDOWS)),
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_large',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble],
                         active_if=(IS_MACOS or IS_WINDOWS)),
        ),
    ),

这段代码定义了一个 `ElementwiseUnaryPythonRefInfo` 对象，用于描述 `_refs.tanh` 操作符的参考信息。包括对 `tanh` 函数的测试、修饰器信息以及在某些条件下跳过测试的情况。


    ElementwiseUnaryPythonRefInfo(
        "_refs.trunc",
        torch_opinfo_name="trunc",
        # Fails on int32
        # https://github.com/pytorch/pytorch/issues/85258
    ),

这段代码定义了一个 `ElementwiseUnaryPythonRefInfo` 对象，用于描述 `_refs.trunc` 操作符的参考信息。其中包含了一个注释，指出这个操作在 int32 类型上会失败，并提供了一个 GitHub 问题链接。


    PythonRefInfo(
        "_refs.special.log_softmax",
        torch_opinfo_name="log_softmax",  # alias
        torch_opinfo_variant_name="with_dtype",
        supports_out=False,
    ),

这段代码定义了一个 `PythonRefInfo` 对象，用于描述 `_refs.special.log_softmax` 操作符的参考信息。包括了 `log_softmax` 函数的别名、变体名称和不支持输出张量的信息。


    PythonRefInfo(
        "_refs.special.softmax",
        torch_opinfo_name="softmax",  # alias
        torch_opinfo_variant_name="with_dtype",
        supports_out=False,
    ),

这段代码定义了一个 `PythonRefInfo` 对象，用于描述 `_refs.special.softmax` 操作符的参考信息。包括了 `softmax` 函数的别名、变体名称和不支持输出张量的信息。


    ElementwiseUnaryPythonRefInfo(
        "_refs.special.logit",
        torch_opinfo_name="logit",
    ),

这段代码定义了一个 `ElementwiseUnaryPythonRefInfo` 对象，用于描述 `_refs.special.logit` 操作符的参考信息。描述了 `logit` 函数的基本信息。


    PythonRefInfo(
        "_refs.nn.functional.alpha_dropout",
        torch_opinfo_name="nn.functional.alpha_dropout",
        decorators=(
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestCommon',
                         'test_python_ref'),
            # AssertionError: Tensor-likes are not close!
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestCommon',
                         'test_python_ref_executor', device_type='cuda'),
            # AssertionError: Tensor-likes are not close!
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestMathBits',
                         'test_neg_view'),
            # AssertionError: Tensor-likes are not close!
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestCommon',
                         'test_compare_cpu'),
        )
    ),

这段代码定义了一个 `PythonRefInfo` 对象，用于描述 `_refs.nn.functional.alpha_dropout` 操作符的参考信息。包括了多个修饰器信息，用于指定在不同测试条件下跳过测试的情况。
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理 nn.functional.celu 函数的信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.celu",
        torch_opinfo_name="nn.functional.celu",
        supports_out=True,
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理 nn.functional.threshold 函数的信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.threshold",
        torch_opinfo_name="nn.functional.threshold",
        supports_out=True,
    ),
    # 创建 PythonRefInfo 对象，处理 nn.functional.dropout 函数的信息
    PythonRefInfo(
        "_refs.nn.functional.dropout",
        torch_opinfo_name="nn.functional.dropout",
        decorators=(
            # 添加装饰器信息，标记测试用例跳过，因为 dropout 函数不可比较
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestCommon',
                         'test_python_ref'),
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestCommon',
                         'test_out'),
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestCommon',
                         'test_out_warning'),
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestMathBits',
                         'test_conj_view'),
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestMathBits',
                         'test_neg_conj_view'),
            DecorateInfo(unittest.skip("Expected: dropout is not comparable"),
                         'TestMathBits',
                         'test_neg_view'),
            # 添加预期失败的装饰器，因为 dropout 函数执行上下文不同
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor'),
            # 添加装饰器信息，标记输出是非确定性的，因此跳过比较测试
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
        )
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理 nn.functional.elu 函数的信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.elu",
        torch_opinfo_name="nn.functional.elu",
        supports_out=True,
        decorators=[
            # 添加特定设备上的装饰器信息，覆盖默认容差设置
            DecorateInfo(
                toleranceOverride({
                    torch.float16: tol(atol=1e-03, rtol=1.2e-03),
                    torch.bfloat16: tol(atol=1e-03, rtol=1.2e-03)
                }),
                'TestUnaryUfuncs', device_type='cuda',
            ),
        ],
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理 nn.functional.hardtanh 函数的信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.hardtanh",
        torch_opinfo_name="nn.functional.hardtanh",
        supports_out=True,
    ),
    # 创建 PythonRefInfo 对象，处理 nn.functional.gelu 函数的信息（待转换为 UnaryOpInfo）
    PythonRefInfo(
        "_refs.nn.functional.gelu",
        torch_opinfo_name="nn.functional.gelu",
    ),
    PythonRefInfo(
        "_refs.nn.functional.layer_norm",
        torch_opinfo_name="nn.functional.layer_norm",
        skips=(
            # 定义一个跳过测试的装饰器信息，用于测试中跳过特定情况的测试用例
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref',
                         dtypes=(torch.float32,), device_type='cpu'),
        ),
    ),
    PythonRefInfo(
        "_refs.nn.functional.glu",
        torch_opinfo_name="nn.functional.glu",
        supports_out=True,
    ),
    PythonRefInfo(
        "_refs.nn.functional.pairwise_distance",
        torch_opinfo_name="nn.functional.pairwise_distance",
        supports_out=True,
    ),
    PythonRefInfo(
        "_refs.nn.functional.pdist",
        torch_opinfo_name="nn.functional.pdist",
        supports_out=True,
        skips=(
            # 定义一个期望的失败装饰器信息，用于测试中期望特定情况的测试用例失败
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref'),
        )),
    PythonRefInfo(
        "_refs.nn.functional.leaky_relu",
        torch_opinfo_name="nn.functional.leaky_relu",
        supports_out=True,
    ),
    PythonRefInfo(
        "_refs.nn.functional.log_softmax",
        torch_opinfo_name="log_softmax",  # 别名
        torch_opinfo_variant_name="with_dtype",
        supports_out=False,
    ),
    PythonRefInfo(
        "_refs.nn.functional.pixel_shuffle",
        torch_opinfo_name="nn.functional.pixel_shuffle",
    ),
    PythonRefInfo(
        "_refs.nn.functional.pixel_unshuffle",
        torch_opinfo_name="nn.functional.pixel_unshuffle",
    ),
    PythonRefInfo(
        "_refs.nn.functional.poisson_nll_loss",
        torch_opinfo_name="nn.functional.poisson_nll_loss",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.prelu",
        torch_opinfo_name="nn.functional.prelu",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.relu",
        torch_opinfo_name="nn.functional.relu",
        supports_out=True,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.relu6",
        torch_opinfo_name="nn.functional.relu6",
        supports_out=True,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.mish",
        torch_opinfo_name="nn.functional.mish",
        supports_out=True,
        decorators=[
            # 定义一个装饰器信息，用于测试中覆盖特定数据类型的容忍度
            DecorateInfo(
                toleranceOverride({torch.float16: tol(atol=1e-02, rtol=1e-03)}),
                'TestUnaryUfuncs',), ],
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.selu",  # 引用函数名为 nn.functional.selu 的 Python 参考信息
        torch_opinfo_name="nn.functional.selu",  # 对应的 PyTorch 操作名为 nn.functional.selu
        supports_out=True,  # 支持输出参数
        decorators=[  # 装饰器列表开始
            DecorateInfo(
                toleranceOverride({  # 设置容差覆盖字典
                    torch.float16: tol(atol=1e-2, rtol=1.8e-2),  # 对于 torch.float16 类型的容差设置
                    torch.bfloat16: tol(atol=1e-2, rtol=1.8e-2)   # 对于 torch.bfloat16 类型的容差设置
                }),
                'TestUnaryUfuncs', device_type='cuda',  # 测试装饰器信息，设备类型为 'cuda'
            ),  # DecorateInfo 对象结束
        ],  # 装饰器列表结束
    ),  # ElementwiseUnaryPythonRefInfo 对象结束

    PythonRefInfo(
        "_refs.nn.functional.softmax",  # 引用函数名为 nn.functional.softmax 的 Python 参考信息
        torch_opinfo_name="softmax",  # 对应的 PyTorch 操作名为 softmax（别名）
        torch_opinfo_variant_name="with_dtype",  # PyTorch 操作的变体名为 with_dtype
        supports_out=False,  # 不支持输出参数
    ),  # PythonRefInfo 对象结束

    PythonRefInfo(
        "_refs.nn.functional.softmin",  # 引用函数名为 nn.functional.softmin 的 Python 参考信息
        torch_opinfo_name="nn.functional.softmin",  # 对应的 PyTorch 操作名为 nn.functional.softmin
        torch_opinfo_variant_name="with_dtype",  # PyTorch 操作的变体名为 with_dtype
        supports_out=False,  # 不支持输出参数
    ),  # PythonRefInfo 对象结束

    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.softplus",  # 引用函数名为 nn.functional.softplus 的 Python 参考信息
        torch_opinfo_name="nn.functional.softplus",  # 对应的 PyTorch 操作名为 nn.functional.softplus
    ),  # ElementwiseUnaryPythonRefInfo 对象结束

    PythonRefInfo(
        "_refs.nn.functional.l1_loss",  # 引用函数名为 nn.functional.l1_loss 的 Python 参考信息
        torch_opinfo_name="nn.functional.l1_loss",  # 对应的 PyTorch 操作名为 nn.functional.l1_loss
    ),  # PythonRefInfo 对象结束

    PythonRefInfo(
        "_refs.nn.functional.margin_ranking_loss",  # 引用函数名为 nn.functional.margin_ranking_loss 的 Python 参考信息
        torch_opinfo_name="nn.functional.margin_ranking_loss",  # 对应的 PyTorch 操作名为 nn.functional.margin_ranking_loss
    ),  # PythonRefInfo 对象结束

    PythonRefInfo(
        "_refs.nn.functional.mse_loss",  # 引用函数名为 nn.functional.mse_loss 的 Python 参考信息
        torch_opinfo_name="nn.functional.mse_loss",  # 对应的 PyTorch 操作名为 nn.functional.mse_loss
    ),  # PythonRefInfo 对象结束

    PythonRefInfo(
        "_refs.nn.functional.smooth_l1_loss",  # 引用函数名为 nn.functional.smooth_l1_loss 的 Python 参考信息
        torch_opinfo_name="nn.functional.smooth_l1_loss",  # 对应的 PyTorch 操作名为 nn.functional.smooth_l1_loss
    ),  # PythonRefInfo 对象结束

    PythonRefInfo(
        "_refs.nn.functional.hinge_embedding_loss",  # 引用函数名为 nn.functional.hinge_embedding_loss 的 Python 参考信息
        torch_opinfo_name="nn.functional.hinge_embedding_loss",  # 对应的 PyTorch 操作名为 nn.functional.hinge_embedding_loss
    ),  # PythonRefInfo 对象结束

    PythonRefInfo(
        "_refs.nn.functional.nll_loss",  # 引用函数名为 nn.functional.nll_loss 的 Python 参考信息
        torch_opinfo_name="nn.functional.nll_loss",  # 对应的 PyTorch 操作名为 nn.functional.nll_loss
        supports_out=True,  # 支持输出参数
        validate_view_consistency=False,  # 禁用视图一致性验证
        skips=(  # 跳过装饰器列表开始
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor', device_type="cuda"  # 期望失败的测试信息，设备类型为 'cuda'
            ),  # DecorateInfo 对象结束
        ),  # 跳过装饰器列表结束
    ),  # PythonRefInfo 对象结束

    PythonRefInfo(
        "_refs.nn.functional.huber_loss",  # 引用函数名为 nn.functional.huber_loss 的 Python 参考信息
        torch_opinfo_name="nn.functional.huber_loss",  # 对应的 PyTorch 操作名为 nn.functional.huber_loss
        supports_out=True,  # 支持输出参数
    ),  # PythonRefInfo 对象结束
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于描述 _refs.nn.functional.tanhshrink 函数的参考信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.tanhshrink",
        torch_opinfo_name="nn.functional.tanhshrink",
        decorators=[
            # 添加装饰器信息，用于测试跳过此函数的情况
            DecorateInfo(unittest.skip("Skipped!"), 'TestUnaryUfuncs',
                         'test_reference_numerics_normal',
                         device_type='cpu', dtypes=[torch.cfloat, torch.cdouble]),
            # 添加装饰器信息，用于测试在极端情况下的数值参考
            DecorateInfo(
                toleranceOverride({torch.bfloat16: tol(atol=1e-02, rtol=1.6e-02),
                                   torch.complex64: tol(atol=6e-04, rtol=1e-05)}),
                'TestUnaryUfuncs', 'test_reference_numerics_extremal', device_type='cuda'),
        ],
        skips=(
            # 在每种情况下，PyTorch 会产生 NaN，而 NumPy 不会
            DecorateInfo(unittest.skip("Fails on some jobs works on others!"),
                         'TestUnaryUfuncs', "test_reference_numerics_large",
                         dtypes=(torch.complex64, torch.complex128),
                         active_if=(IS_MACOS)),
            # 跳过在某些作业中失败但在其他作业中正常的测试
            DecorateInfo(unittest.skip("Fails on some jobs works on others!"),
                         'TestUnaryUfuncs', "test_reference_numerics_extremal",
                         dtypes=(torch.complex64, torch.complex128),
                         device_type='cpu',
                         active_if=(IS_MACOS or IS_WINDOWS)),
        ),
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于描述 _refs.nn.functional.hardshrink 函数的参考信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.hardshrink",
        torch_opinfo_name="nn.functional.hardshrink",
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，用于描述 _refs.nn.functional.softshrink 函数的参考信息
    ElementwiseUnaryPythonRefInfo(
        "_refs.nn.functional.softshrink",
        torch_opinfo_name="nn.functional.softshrink",
    ),
    #
    # Elementwise Binary Reference OpInfos
    #
    # 创建 ElementwiseBinaryPythonRefInfo 对象，用于描述 _refs.add 函数的参考信息
    ElementwiseBinaryPythonRefInfo(
        "_refs.add",
        torch_opinfo_name="add",
        # 支持接受两个 Python 标量作为参数
        supports_two_python_scalars=True,
        # 支持接受一个 Python 标量作为参数
        supports_one_python_scalar=True,
        decorators=(
            # 添加装饰器信息，用于测试二元函数的数值参考
            DecorateInfo(
                toleranceOverride({torch.chalf: tol(atol=1e-2, rtol=0)}),
                'TestBinaryUfuncs', 'test_reference_numerics'),
        ),
        skips=(
            # 跳过在极端值情况下的测试
            DecorateInfo(unittest.skip("Skipped!"),
                         'TestBinaryUfuncs',
                         'test_reference_numerics_extremal_values',
                         dtypes=(torch.complex64, torch.complex128)),
        ),
    ),
    # 创建 ElementwiseBinaryPythonRefInfo 对象，用于描述 _refs.atan2 函数的参考信息
    ElementwiseBinaryPythonRefInfo(
        "_refs.atan2",
        torch_opinfo_name="atan2",
    ),
    # 创建 ElementwiseBinaryPythonRefInfo 对象，用于描述 _refs.bitwise_and 函数的参考信息
    ElementwiseBinaryPythonRefInfo(
        "_refs.bitwise_and",
        torch_opinfo_name="bitwise_and",
    ),
    # 创建 ElementwiseBinaryPythonRefInfo 对象，用于描述 _refs.bitwise_left_shift 函数的参考信息
    ElementwiseBinaryPythonRefInfo(
        "_refs.bitwise_left_shift",
        torch_opinfo_name="bitwise_left_shift",
        skips=(
            # 跳过某些输入会产生未定义输出的测试
            DecorateInfo(unittest.skip("Some inputs produce undefined outputs"), 'TestCommon', 'test_compare_cpu'),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.bitwise_right_shift",
        torch_opinfo_name="bitwise_right_shift",
        skips=(
            # 在某些输入条件下产生未定义的输出，因此跳过测试
            DecorateInfo(unittest.skip("Skipped some inputs produce undefined outputs"), 'TestCommon', 'test_compare_cpu'),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.bitwise_or",
        torch_opinfo_name="bitwise_or",
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.bitwise_xor",
        torch_opinfo_name="bitwise_xor",
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.copysign",
        torch_opinfo_name="copysign",
        skips=(
            # 运行时错误：预期被除数（b）与被除数（a）位于同一设备（cuda:0），但在 cpu 上找到！因此跳过测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs', 'test_type_promotion'),
            # FIXME 输出 0：元数据与真实实现不一致，因此预期测试失败
            DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_binary_ufuncs_mixed_dtype'),
        )
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.div",
        torch_opinfo_name="div",
        torch_opinfo_variant_name="no_rounding_mode",
        # 支持在 Python 中使用两个标量进行计算
        supports_two_python_scalars=True,
        # 支持在 Python 中使用一个标量进行计算
        supports_one_python_scalar=True,
        skips=(
            # 未实现错误：类型为 <class 'complex'> 的参数，因此跳过测试
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref_executor',
                dtypes=(torch.complex32, torch.complex64, torch.complex128,)
            ),
            # 参考结果（0.7433461727239705）与精确计算结果差距较大，因此预期测试失败
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                dtypes=(torch.complex32,), device_type="cuda"
            ),
            # 参考结果（0.7433461727239705）与精确计算结果差距较大，因此预期测试失败
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                dtypes=(torch.complex32,), device_type="cuda"
            ),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.div",
        torch_opinfo_name="div",
        torch_opinfo_variant_name="trunc_rounding",
        # 支持在 Python 中使用两个标量进行计算
        supports_two_python_scalars=True,
        # 支持在 Python 中使用一个标量进行计算
        supports_one_python_scalar=True,
        decorators=(
            # 查看问题 https://github.com/pytorch/pytorch/issues/111126
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.div",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 操作 "div"
        torch_opinfo_name="div",  # 设置 torch 操作的名称为 "div"
        torch_opinfo_variant_name="floor_rounding",  # 设置 torch 操作的变体名称为 "floor_rounding"
        # https://github.com/pytorch/pytorch/issues/76944
        supports_two_python_scalars=True,  # 支持两个 Python 标量作为参数
        supports_one_python_scalar=True,  # 支持一个 Python 标量作为参数
        decorators=(
            # See https://github.com/pytorch/pytorch/issues/111126
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),  # 标记为预期失败的测试用例装饰器
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.eq",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 操作 "eq"
        torch_opinfo_name="eq",  # 设置 torch 操作的名称为 "eq"
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.float_power",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 操作 "float_power"
        torch_opinfo_name="float_power",  # 设置 torch 操作的名称为 "float_power"
        skips=(
            # Test doesn't account for float -> double type promotion
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),  # 标记为预期失败的测试用例装饰器
            # Complex values error with: Greatest absolute difference: nan at index
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics_small_values',
                         dtypes=[torch.complex64, torch.complex128]),  # 标记为跳过的测试用例装饰器，指定数据类型为复数
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics_large_values',
                         dtypes=[torch.complex64, torch.complex128]),  # 标记为跳过的测试用例装饰器，指定数据类型为复数
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics_extremal_values',
                         dtypes=[torch.complex64, torch.complex128]),  # 标记为跳过的测试用例装饰器，指定数据类型为复数
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.logaddexp",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 操作 "logaddexp"
        torch_opinfo_name="logaddexp",  # 设置 torch 操作的名称为 "logaddexp"
        skips=(
            # failure due to mismatch in edge cases, which boils down to what torch.exp(inf + infj) should be
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref', device_type='cpu',
                         dtypes=(torch.complex64, torch.complex128)),  # 标记为预期失败的测试用例装饰器，指定设备类型和数据类型为复数
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback', device_type='cpu',
                         dtypes=(torch.complex64, torch.complex128)),  # 标记为预期失败的测试用例装饰器，指定设备类型和数据类型为复数
        ),
    ),
    PythonRefInfo(
        "_refs.logaddexp2",  # 创建一个 PythonRefInfo 对象，处理 torch 操作 "logaddexp2"
        torch_opinfo_name="logaddexp2",  # 设置 torch 操作的名称为 "logaddexp2"
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.floor_divide",  # 定义一个 ElementwiseBinaryPythonRefInfo 对象，用于 floor_divide 操作的参考信息
        torch_opinfo_name="floor_divide",  # 指定 PyTorch 中对应的操作名为 floor_divide
        rhs_make_tensor_kwargs=dict(exclude_zero=True),  # 关键字参数，右操作数生成张量时排除零值
        supports_two_python_scalars=True,  # 支持两个 Python 标量作为操作数
        supports_one_python_scalar=True,  # 支持一个 Python 标量作为操作数
        skips=(  # 跳过的测试信息元组
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref',
                         dtypes=(torch.bfloat16,)),  # 跳过指定数据类型为 torch.bfloat16 的 test_python_ref 测试
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.bfloat16,)),  # 跳过指定数据类型为 torch.bfloat16 的 test_python_ref_torch_fallback 测试
            DecorateInfo(unittest.skip('Skipped!'), 'TestBinaryUfuncs',
                         dtypes=(torch.bfloat16,)),  # 跳过指定数据类型为 torch.bfloat16 的 TestBinaryUfuncs 测试
            DecorateInfo(unittest.skip('Skipped!'), 'TestBinaryUfuncs',
                         'test_reference_numerics_small_values',
                         dtypes=(torch.int8,)),  # 跳过指定数据类型为 torch.int8 的 test_reference_numerics_small_values 测试
            DecorateInfo(unittest.skip('Skipped!'), 'TestBinaryUfuncs',
                         'test_reference_numerics_extremal_values',
                         dtypes=(torch.float16,)),  # 跳过指定数据类型为 torch.float16 的 test_reference_numerics_extremal_values 测试
            DecorateInfo(toleranceOverride({torch.float16: tol(atol=1e-3, rtol=5e-3)}),
                         'TestBinaryUfuncs', 'test_reference_numerics'),  # 对于 torch.float16 数据类型的 test_reference_numerics 测试，设置容差
            DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_binary_ufuncs_mixed_dtype'),  # 标记为预期失败的测试：test_binary_ufuncs_mixed_dtype，属于 TestMeta 测试类
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.fmax",  # 定义一个 ElementwiseBinaryPythonRefInfo 对象，用于 fmax 操作的参考信息
        torch_opinfo_name="fmax",  # 指定 PyTorch 中对应的操作名为 fmax
        supports_rhs_python_scalar=False,  # 不支持右操作数为 Python 标量
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.fmin",  # 定义一个 ElementwiseBinaryPythonRefInfo 对象，用于 fmin 操作的参考信息
        torch_opinfo_name="fmin",  # 指定 PyTorch 中对应的操作名为 fmin
        supports_rhs_python_scalar=False,  # 不支持右操作数为 Python 标量
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.fmod",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，表示 torch 函数 fmod 的参考信息
        torch_opinfo_name="fmod",  # 指定 Torch 操作的名称为 fmod
        rhs_make_tensor_kwargs={'exclude_zero': True},  # 右操作数为 Python 标量时的附加张量参数
        supports_rhs_python_scalar=True,  # 支持右操作数为 Python 标量
        skips=(  # 跳过一些测试用例
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref',
                         dtypes=(torch.bfloat16,), device_type='cpu'),  # 跳过指定的测试用例，测试 bfloat16 类型在 CPU 上
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.bfloat16,), device_type='cpu'),  # 跳过指定的测试用例，测试 bfloat16 类型在 CPU 上
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_contig_vs_every_other',
                         dtypes=(torch.bfloat16,)),  # 跳过指定的测试用例，测试 bfloat16 类型的二元函数
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_non_contig',
                         dtypes=(torch.bfloat16,)),  # 跳过指定的测试用例，测试 bfloat16 类型的非连续数组
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics',
                         dtypes=(torch.bfloat16,)),  # 跳过指定的测试用例，测试 bfloat16 类型的数值参考
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics_small_values',
                         dtypes=(torch.uint8,)),  # 跳过指定的测试用例，测试 uint8 类型的小数值参考
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.gcd",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，表示 torch 函数 gcd 的参考信息
        torch_opinfo_name="gcd",  # 指定 Torch 操作的名称为 gcd
        skips=(  # 标记为预期失败的测试用例
            DecorateInfo(unittest.expectedFailure,
                         'TestBinaryUfuncs',
                         'test_reference_numerics_small_values',
                         dtypes=(torch.int8,)),  # 预期测试 int8 类型的小数值参考会失败
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.ge",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，表示 torch 函数 ge 的参考信息
        torch_opinfo_name="ge",  # 指定 Torch 操作的名称为 ge
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.gt",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，表示 torch 函数 gt 的参考信息
        torch_opinfo_name="gt",  # 指定 Torch 操作的名称为 gt
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.heaviside",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，表示 torch 函数 heaviside 的参考信息
        torch_opinfo_name="heaviside",  # 指定 Torch 操作的名称为 heaviside
        supports_rhs_python_scalar=False,  # 不支持右操作数为 Python 标量
        skips=(  # 跳过一些测试用例
            # PyTorch 的 heaviside 函数似乎不会传播 NaN
            DecorateInfo(unittest.skip("Skipped!"),
                         'TestBinaryUfuncs',
                         'test_reference_numerics_extremal_values'),  # 跳过测试极端值的数值参考
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.hypot",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，表示 torch 函数 hypot 的参考信息
        torch_opinfo_name="hypot",  # 指定 Torch 操作的名称为 hypot
        supports_rhs_python_scalar=False,  # 不支持右操作数为 Python 标量
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.igamma",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，表示 torch 函数 igamma 的参考信息
        torch_opinfo_name="igamma",  # 指定 Torch 操作的名称为 igamma
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.igammac",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，表示 torch 函数 igammac 的参考信息
        torch_opinfo_name="igammac",  # 指定 Torch 操作的名称为 igammac
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.isclose",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.isclose"
        torch_opinfo_name="isclose",  # 设置 torch 中对应的操作名称为 "isclose"
        skips=(  # 定义跳过的测试情况列表
            # isclose 函数不会进行类型提升，这里是一个有意失败的测试用例
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),
            # isclose 函数在混合数据类型的情况下的测试用例，也是有意失败的
            DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_binary_ufuncs_mixed_dtype'),
            # 跳过极值情况下的参考数值测试
            DecorateInfo(unittest.skip("Skipped!"),
                         'TestBinaryUfuncs',
                         'test_reference_numerics_extremal_values'),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.lcm",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.lcm"
        torch_opinfo_name="lcm",  # 设置 torch 中对应的操作名称为 "lcm"
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.le",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.le"
        torch_opinfo_name="le",  # 设置 torch 中对应的操作名称为 "le"
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.logical_and",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.logical_and"
        torch_opinfo_name="logical_and",  # 设置 torch 中对应的操作名称为 "logical_and"
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.logical_not",  # 创建一个 ElementwiseUnaryPythonRefInfo 对象，处理 torch 函数 "_refs.logical_not"
        torch_opinfo_name="logical_not",  # 设置 torch 中对应的操作名称为 "logical_not"
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.logical_or",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.logical_or"
        torch_opinfo_name="logical_or",  # 设置 torch 中对应的操作名称为 "logical_or"
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.logical_xor",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.logical_xor"
        torch_opinfo_name="logical_xor",  # 设置 torch 中对应的操作名称为 "logical_xor"
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.lt",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.lt"
        torch_opinfo_name="lt",  # 设置 torch 中对应的操作名称为 "lt"
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.maximum",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.maximum"
        torch_opinfo_name="maximum",  # 设置 torch 中对应的操作名称为 "maximum"
        skips=(  # 定义跳过的测试情况列表
            # maximum 函数的参考实现中的错误测试用例
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.minimum",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.minimum"
        torch_opinfo_name="minimum",  # 设置 torch 中对应的操作名称为 "minimum"
        skips=(  # 定义跳过的测试情况列表
            # minimum 函数的参考实现中的错误测试用例
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.mul",  # 创建一个 ElementwiseBinaryPythonRefInfo 对象，处理 torch 函数 "_refs.mul"
        torch_opinfo_name="mul",  # 设置 torch 中对应的操作名称为 "mul"
        # 设置支持两个 Python 标量的操作
        supports_two_python_scalars=True,
        # 设置支持一个 Python 标量的操作
        supports_one_python_scalar=True,
        skips=(  # 定义跳过的测试情况列表
            # 参考结果与精确计算相比，误差更大
            # 在 torch.complex32 类型下的测试用例，这是一个有意失败的测试
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor',
                dtypes=(torch.complex32,),
            ),
            # 参考结果与精确计算相比，误差更大
            # 在 torch.complex32 类型下的测试用例，这是一个有意失败的测试，使用 CUDA 设备
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                dtypes=(torch.complex32,), device_type='cuda'
            ),
            # 参考结果与精确计算相比，误差更大
            # 在 torch.complex32 类型下的测试用例，这是一个有意失败的测试，使用 CUDA 设备
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                dtypes=(torch.complex32,), device_type='cuda'
            ),
        )
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.ne",
        torch_opinfo_name="ne",
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.nextafter",
        torch_opinfo_name="nextafter",
    ),



# 创建 ElementwiseBinaryPythonRefInfo 对象，处理 torch 操作 'ne'，并将结果存储在 '_refs.ne' 中
ElementwiseBinaryPythonRefInfo(
    "_refs.ne",
    torch_opinfo_name="ne",
),

# 创建 ElementwiseBinaryPythonRefInfo 对象，处理 torch 操作 'nextafter'，并将结果存储在 '_refs.nextafter' 中
ElementwiseBinaryPythonRefInfo(
    "_refs.nextafter",
    torch_opinfo_name="nextafter",
),
    # 创建 ElementwiseBinaryPythonRefInfo 实例，用于描述 _refs.pow 操作
    ElementwiseBinaryPythonRefInfo(
        "_refs.pow",
        torch_opinfo_name="pow",  # 设置 torch 操作名称为 pow
        decorators=(
            # 添加装饰信息，设置数值容差修正，用于 'TestBinaryUfuncs' 和 'test_reference_numerics' 测试
            DecorateInfo(
                toleranceOverride({torch.complex64: tol(atol=1e-4, rtol=1.3e-05)}),
                'TestBinaryUfuncs', 'test_reference_numerics'),
            # 添加装饰信息，设置数值容差修正，适用于 'TestBinaryUfuncs' 和 'test_scalar_support' 测试
            DecorateInfo(
                toleranceOverride({torch.complex64: tol(atol=1e-4, rtol=1.3e-05),
                                   torch.complex128: tol(atol=1e-4, rtol=1.3e-05)}),
                'TestBinaryUfuncs', 'test_scalar_support'),
        ),
        skips=(
            # 设置预期测试失败装饰信息，用于 'TestCommon' 和 'test_python_ref_executor' 测试，针对 torch.complex32 数据类型
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor',
                dtypes=(torch.complex32,),
            ),
            # 设置预期测试失败装饰信息，用于 'TestCommon' 和 'test_python_ref' 测试，针对 torch.complex32 数据类型和 CUDA 设备类型
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                dtypes=(torch.complex32,), device_type="cuda"
            ),
            # 设置预期测试失败装饰信息，用于 'TestCommon' 和 'test_python_ref_torch_fallback' 测试，针对 torch.complex32 数据类型和 CUDA 设备类型
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                dtypes=(torch.complex32,), device_type="cuda"
            ),
            # 设置跳过装饰信息，用于 'TestBinaryUfuncs' 和 'test_reference_numerics_small_values' 测试，针对整数数据类型（torch.int8, torch.int16, torch.int32, torch.int64）
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs',
                         'test_reference_numerics_small_values',
                         dtypes=[torch.int8, torch.int16, torch.int32, torch.int64]),
            # 设置跳过装饰信息，用于 'TestBinaryUfuncs' 和 'test_reference_numerics_large_values' 测试，针对整数数据类型（torch.int16, torch.int32, torch.int64）
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs',
                         'test_reference_numerics_large_values',
                         dtypes=[torch.int16, torch.int32, torch.int64]),
            # 设置跳过装饰信息，用于 'TestBinaryUfuncs' 和 'test_reference_numerics' 测试，针对 torch.complex32 数据类型
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics',
                         dtypes=(torch.complex32,)),
            # 设置跳过装饰信息，用于 'TestBinaryUfuncs' 和 'test_reference_numerics_small_values' 测试，针对复数数据类型（torch.complex32, torch.complex64, torch.complex128）
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics_small_values',
                         dtypes=(torch.complex32, torch.complex64, torch.complex128)),
            # 设置跳过装饰信息，用于 'TestBinaryUfuncs' 和 'test_reference_numerics_large_values' 测试，针对复数数据类型（torch.complex32, torch.complex64, torch.complex128）
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics_large_values',
                         dtypes=(torch.complex32, torch.complex64, torch.complex128)),
            # 设置跳过装饰信息，用于 'TestBinaryUfuncs' 和 'test_reference_numerics_extremal_values' 测试，针对复数数据类型（torch.complex32, torch.complex64, torch.complex128）
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics_extremal_values',
                         dtypes=(torch.complex32, torch.complex64, torch.complex128)),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.remainder",
        torch_opinfo_name="remainder",
        # 定义针对 'remainder' 操作的 Python 参考信息
        skips=(
            # 跳过特定测试用例，因为在 bfloat16 数据类型上有问题
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref',
                         dtypes=(torch.bfloat16,), device_type='cpu'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.bfloat16,), device_type='cpu'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics',
                         dtypes=(torch.bfloat16,)),
            DecorateInfo(unittest.skip("Skipped!"), 'TestBinaryUfuncs',
                         'test_reference_numerics_small_values',
                         dtypes=(torch.uint8,)),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.rsub",
        torch_opinfo_name="rsub",
        # 定义针对 'rsub' 操作的 Python 参考信息
        skips=(
            # 此测试用例预期失败，因为在 chalf 数据类型上的精确计算结果与参考结果有差距（结果为 nan）
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                         dtypes=(torch.chalf,), device_type='cpu'),
            # 此测试用例预期失败，因为在 chalf 数据类型上的精确计算结果与参考结果有差距（结果为 nan）
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.chalf,), device_type='cpu'),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.sub",
        torch_opinfo_name="sub",
        # 设置支持两个Python标量的选项为True
        supports_two_python_scalars=True,
        # 设置支持一个Python标量的选项为True
        supports_one_python_scalar=True,
        # 设置装饰器信息，用于测试二元ufuncs的参考数值
        decorators=(
            # 设置容差覆盖，用于torch.float16和torch.bfloat16类型的测试
            DecorateInfo(
                toleranceOverride({torch.float16: tol(atol=1e-2, rtol=0),
                                   torch.bfloat16: tol(atol=1e-5, rtol=5e-3),
                                   torch.complex32: tol(atol=1e-5, rtol=1e-3)}),
                'TestBinaryUfuncs', 'test_reference_numerics'),
            # 设置容差覆盖，用于torch.chalf类型的测试，设备类型为CPU
            DecorateInfo(
                toleranceOverride({torch.chalf: tol(atol=1e-2, rtol=0)}),
                'TestCommon', 'test_complex_half_reference_testing', device_type='cpu'),
            # 设置容差覆盖，用于torch.chalf类型的测试，设备类型为CPU
            DecorateInfo(
                toleranceOverride({torch.chalf: tol(atol=5e-3, rtol=0)}),
                'TestDecomp', 'test_comprehensive', device_type='cpu'),
            # 设置容差覆盖，用于torch.chalf类型的测试，设备类型为CPU
            DecorateInfo(
                toleranceOverride({torch.chalf: tol(atol=5e-3, rtol=0)}),
                'TestDecomp', 'test_quick', device_type='cpu'),
        ),
        # 设置跳过测试的装饰器信息
        skips=(
            # 跳过测试，提示信息为"Skipped!"
            DecorateInfo(unittest.skip("Skipped!"),
                         'TestBinaryUfuncs',
                         'test_reference_numerics',
                         dtypes=(torch.uint8,)),
            # 跳过测试，提示信息为"Skipped!"
            DecorateInfo(unittest.skip("Skipped!"),
                         'TestBinaryUfuncs',
                         'test_reference_numerics_small_values',
                         dtypes=(torch.uint8,)),
        ),
    ),
    ElementwiseBinaryPythonRefInfo(
        "_refs.true_divide",
        torch_opinfo_name="true_divide",
        # 设置支持两个Python标量的选项为True
        supports_two_python_scalars=True,
        # 设置支持一个Python标量的选项为True
        supports_one_python_scalar=True,
        # 设置跳过测试的装饰器信息
        skips=(
            # 预期测试失败，复杂类型(torch.complex32)的测试，设备类型为任意
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref_executor',
                dtypes=(torch.complex32,),
            ),
            # 预期测试失败，复杂类型(torch.complex32)的测试，设备类型为CUDA
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref',
                dtypes=(torch.complex32,), device_type="cuda"
            ),
            # 预期测试失败，复杂类型(torch.complex32)的测试，设备类型为CUDA
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref_torch_fallback',
                dtypes=(torch.complex32,), device_type="cuda"
            ),
        ),
    ),
    #
    # Elementwise Ternary Reference OpInfos
    #
    PythonRefInfo(
        "_refs.addcdiv",
        torch_opinfo_name="addcdiv",
    ),
    # 定义一个 PythonRefInfo 对象，用于记录 _refs.addcmul 操作的参考信息
    PythonRefInfo(
        "_refs.addcmul",
        torch_opinfo_name="addcmul",
        skips=(
            # 跳过以下测试用例，因为精确计算和 torch 结果的差异超过了允许的范围
            # 错误修正建议：在 test_ops.py:TestCommon._ref_test_helper 中启用基于数据类型的容差
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref',
                         dtypes=(torch.float16,), device_type="cpu"),
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref_torch_fallback',
                         dtypes=(torch.float16,), device_type="cpu"),
        ),
    ),
    # 定义一个 ElementwiseBinaryPythonRefInfo 对象，用于记录 _refs.clamp_min 操作的参考信息
    ElementwiseBinaryPythonRefInfo(
        "_refs.clamp_min",
        torch_opinfo_name="clamp_min",
        skips=(
            # 禁用测试错误，因为支持 rhs 是非张量的 Python 标量
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),
        ),
    ),
    # 定义一个 ElementwiseBinaryPythonRefInfo 对象，用于记录 _refs.clamp_max 操作的参考信息
    ElementwiseBinaryPythonRefInfo(
        "_refs.clamp_max",
        torch_opinfo_name="clamp_max",
        skips=(
            # 禁用测试错误，因为支持 rhs 是非张量的 Python 标量
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),
        ),
    ),
    # 定义一个 PythonRefInfo 对象，用于记录 _refs.clamp 操作的参考信息
    PythonRefInfo(
        "_refs.clamp",
        torch_opinfo_name="clamp",
    ),
    # 定义一个 PythonRefInfo 对象，用于记录 _refs.nn.functional.triplet_margin_loss 操作的参考信息
    PythonRefInfo(
        "_refs.nn.functional.triplet_margin_loss",
        torch_opinfo_name="nn.functional.triplet_margin_loss",
        supports_out=False,
        # TODO: 使用了最小值和 clamp
        skips=(
            # 跳过以下测试用例，因为张量类型不接近！
            # 最大绝对差异在 (4,) 索引处为 6.103515625e-05（允许最多 1e-05）
            # 最大相对差异在 (4,) 索引处为 8.519846983548175e-06（允许最多 1.3e-06）
            DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_python_ref',
                         dtypes=(torch.uint8,), device_type="cpu"),
        )
    ),
    # 定义一个 ElementwiseBinaryPythonRefInfo 对象，用于记录 _refs.xlogy 操作的参考信息
    ElementwiseBinaryPythonRefInfo(
        "_refs.xlogy",
        torch_opinfo_name="xlogy",
        supports_one_python_scalar=True,
    ),
    #
    # Elementwise Binary Special OpInfos
    #
    # 定义一个 ElementwiseBinaryPythonRefInfo 对象，用于记录 _refs.special.xlog1py 操作的参考信息
    ElementwiseBinaryPythonRefInfo(
        "_refs.special.xlog1py",
        torch_opinfo_name="special.xlog1py",
        supports_one_python_scalar=True,
    ),
    #
    # Data Conversion & Data Movement Opinfos
    #
    # 定义一个 ElementwiseUnaryPythonRefInfo 对象，用于记录 _refs._conversions.bfloat16 操作的参考信息
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.bfloat16",
        torch_opinfo_name="bfloat16",
        # TODO: 如果 self 已经具有正确的 dtype 和 device，则返回 self，忽略 memory_format。
        # 参考 https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理布尔类型的转换
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.bool",
        torch_opinfo_name="bool",
        # 如果 self 已经具有正确的数据类型和设备，则返回 self，忽略内存格式
        # 参考：https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理字节类型的转换
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.byte",
        torch_opinfo_name="byte",
        # 如果 self 已经具有正确的数据类型和设备，则返回 self，忽略内存格式
        # 参考：https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
        # 跳过特定的测试用例
        skips=(
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),
        )
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理字符类型的转换
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.char",
        torch_opinfo_name="char",
        # 如果 self 已经具有正确的数据类型和设备，则返回 self，忽略内存格式
        # 参考：https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
        # 跳过特定的测试用例
        skips=(
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),
        )
    ),
    # 创建 ElementwiseBinaryPythonRefInfo 对象，处理复数类型的转换
    ElementwiseBinaryPythonRefInfo(
        "_refs._conversions.complex",
        torch_opinfo_name="complex",
        error_inputs_func=partial(error_inputs_complex, is_ref=True),
        # 跳过特定的测试用例，因为测试未考虑复数类型的类型提升语义
        skips=(
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),
            DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_binary_ufuncs_mixed_dtype'),
        )
    ),
    # 创建 ElementwiseBinaryPythonRefInfo 对象，处理极坐标类型的转换
    ElementwiseBinaryPythonRefInfo(
        "_refs._conversions.polar",
        torch_opinfo_name="polar",
        # 跳过特定的测试用例，因为测试未考虑复数类型的类型提升语义
        skips=(
            DecorateInfo(unittest.expectedFailure, 'TestBinaryUfuncs', 'test_type_promotion'),
            DecorateInfo(unittest.expectedFailure, 'TestMeta', 'test_binary_ufuncs_mixed_dtype'),
        )
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理双精度浮点数类型的转换
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.double",
        torch_opinfo_name="double",
        # 如果 self 已经具有正确的数据类型和设备，则返回 self，忽略内存格式
        # 参考：https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
    ),
    # 创建 ElementwiseUnaryPythonRefInfo 对象，处理单精度浮点数类型的转换
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.float",
        torch_opinfo_name="float",
        # 如果 self 已经具有正确的数据类型和设备，则返回 self，忽略内存格式
        # 参考：https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.half",
        torch_opinfo_name="half",
        # TODO: If self already has the correct dtype and device, then self is
        # returned ignoring memory_format.
        # https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.int",
        torch_opinfo_name="int",
        # TODO: If self already has the correct dtype and device, then self is
        # returned ignoring memory_format.
        # https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
        # 跳过特定的测试用例
        skips=(
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),
        )
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.long",
        torch_opinfo_name="long",
        # TODO: If self already has the correct dtype and device, then self is
        # returned ignoring memory_format.
        # https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
        # 跳过特定的测试用例
        skips=(
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),
        )
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.short",
        torch_opinfo_name="short",
        # TODO: If self already has the correct dtype and device, then self is
        # returned ignoring memory_format.
        # https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
        # 跳过特定的测试用例
        skips=(
            DecorateInfo(unittest.skip('Overflow when downcasting signed type is undefined'), 'TestCommon', 'test_compare_cpu'),
        )
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.chalf",
        torch_opinfo_name="chalf",
        # TODO: If self already has the correct dtype and device, then self is
        # returned ignoring memory_format.
        # https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.cfloat",
        torch_opinfo_name="cfloat",
        # TODO: If self already has the correct dtype and device, then self is
        # returned ignoring memory_format.
        # https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs._conversions.cdouble",
        torch_opinfo_name="cdouble",
        # TODO: If self already has the correct dtype and device, then self is
        # returned ignoring memory_format.
        # https://github.com/pytorch/pytorch/issues/86558
        validate_view_consistency=False,
    ),
    PythonRefInfo(
        "_refs.clone",
        torch_opinfo_name="clone",
    ),
    PythonRefInfo(
        "_refs.alias_copy",
        torch_opinfo_name="alias_copy",
    ),
    PythonRefInfo(
        "_refs.atleast_1d",
        torch_opinfo_name="atleast_1d",
        validate_view_consistency=False,
    ),
    PythonRefInfo(
        "_refs.atleast_2d",
        torch_opinfo_name="atleast_2d",
        validate_view_consistency=False,
    ),
    PythonRefInfo(
        "_refs.atleast_3d",
        torch_opinfo_name="atleast_3d",
        validate_view_consistency=False,
    ),
    PythonRefInfo(
        "_refs.as_strided",
        torch_opinfo_name="as_strided",
        # FIXME: doesn't support chalf
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),
        skips=(
            # 当 storage_offset 被包含时，cloned_mutable_input.is_same(returned_output) 内部断言失败
            DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_neg_conj_view'),
        ),
    ),
    PythonRefInfo(
        "_refs.as_strided_copy",
        torch_opinfo_name="as_strided_copy",
        # FIXME: doesn't support chalf
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),
        skips=(
            # 当 storage_offset 被包含时，cloned_mutable_input.is_same(returned_output) 内部断言失败
            DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_neg_conj_view'),
        ),
    ),
    PythonRefInfo(
        "_refs.as_strided",
        torch_opinfo_name="as_strided",
        torch_opinfo_variant_name="partial_views",
        # FIXME: doesn't support chalf
        dtypes=all_types_and_complex_and(torch.bool, torch.float16, torch.bfloat16),
        skips=(
            # 当 storage_offset 被包含时，cloned_mutable_input.is_same(returned_output) 内部断言失败
            DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.skip("Errors when storage_offset is included"), 'TestMathBits', 'test_neg_conj_view'),
            # 预期测试失败
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_compare_cpu'),
        ),
    ),
    PythonRefInfo(
        "_refs.as_strided_scatter",
        torch_opinfo_name="as_strided_scatter",
        # 返回一个中间张量的视图（as_strided）
        validate_view_consistency=False,
    ),
    PythonRefInfo(
        "_refs.block_diag",
        torch_opinfo_name="block_diag",
    ),
    PythonRefInfo(
        "_refs.broadcast_shapes",
        torch_opinfo_name="broadcast_shapes",
    ),
    PythonRefInfo(
        "_refs.broadcast_tensors",
        torch_opinfo_name="broadcast_tensors",
    ),
    PythonRefInfo(
        "_refs.broadcast_to",
        torch_opinfo_name="broadcast_to",
    ),
    PythonRefInfo(
        "_refs.cat",
        torch_opinfo_name="cat",
        skips=(
            # FIXME: AssertionError: RuntimeError not raised
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),
        ),
    ),
    PythonRefInfo(
        "_refs.chunk",
        torch_opinfo_name="chunk",
    ),
    PythonRefInfo(
        "_refs.column_stack",
        torch_opinfo_name="column_stack",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.conj",
        torch_opinfo_name="conj",
    ),
    PythonRefInfo(
        "_refs.constant_pad_nd",
        torch_opinfo_name="constant_pad_nd",
    ),
    PythonRefInfo(
        "_refs.contiguous",
        torch_opinfo_name="contiguous",
    ),
    ElementwiseUnaryPythonRefInfo(
        "_refs.deg2rad",
        torch_opinfo_name="deg2rad",
        decorators=(precisionOverride({torch.bfloat16: 7e-1,
                                       torch.float16: 7e-1}),),
    ),
    PythonRefInfo(
        "_refs.dsplit",
        torch_opinfo_name="dsplit",
    ),
    PythonRefInfo(
        "_refs.diag",
        torch_opinfo_name="diag",
    ),
    PythonRefInfo(
        "_refs.diagonal",
        torch_opinfo_name="diagonal",
    ),
    PythonRefInfo(
        "_refs.diagonal_copy",
        torch_opinfo_name="diagonal_copy",
    ),
    PythonRefInfo(
        "_refs.diagonal_scatter",
        torch_opinfo_name="diagonal_scatter",
        supports_out=True,
        # returns a view of an intermediate tensor (as_strided)
        validate_view_consistency=False,
    ),
    PythonRefInfo(
        "_refs.diag_embed",
        torch_opinfo_name="diag_embed",
        supports_out=True,
    ),
    PythonRefInfo(
        "_refs.dstack",
        torch_opinfo_name="dstack",
        skips=(
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),
        ),
    ),
    PythonRefInfo(
        "_refs.expand",
        torch_opinfo_name="expand",
    ),
    PythonRefInfo(
        "_refs.expand_as",
        torch_opinfo_name="expand_as",
    ),
    PythonRefInfo(
        "_refs.flatten",
        torch_opinfo_name="flatten",
    ),
    PythonRefInfo(
        "_refs.flip",
        torch_opinfo_name="flip",
    ),
    PythonRefInfo(
        "_refs.fliplr",
        torch_opinfo_name="fliplr",
    ),
    PythonRefInfo(
        "_refs.flipud",
        torch_opinfo_name="flipud",
    ),
    PythonRefInfo(
        "_refs.hstack",
        torch_opinfo_name="hstack",
        skips=(
            # https://github.com/pytorch/pytorch/issues/78613
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),
        ),
    ),
    PythonRefInfo(
        "_refs.narrow",
        torch_opinfo_name="narrow",
        error_inputs_func=partial(error_inputs_narrow_narrow_copy, is_narrow=True, is_ref=True),
    ),
    
    PythonRefInfo(
        "_refs.narrow_copy",
        torch_opinfo_name="narrow_copy",
        supports_out=True,
        error_inputs_func=partial(error_inputs_narrow_narrow_copy, is_narrow=False, is_ref=True),
    ),
    
    PythonRefInfo(
        "_refs.nn.functional.group_norm",
        torch_opinfo_name="nn.functional.group_norm",
        validate_view_consistency=False,
    ),
    
    PythonRefInfo(
        "_refs.native_layer_norm",
        torch_opinfo_name="native_layer_norm",
        skips=(
            DecorateInfo(unittest.skip("Skipped!"), "TestCommon", "test_python_ref",
                         device_type="cpu", dtypes=(torch.float32,)),
            DecorateInfo(unittest.skip("Skipped!"), "TestCommon", "test_python_ref_torch_fallback",
                         device_type="cpu", dtypes=(torch.float32,)),
        ),
    ),
    
    PythonRefInfo(
        "_refs.permute",
        torch_opinfo_name="permute",
    ),
    
    ElementwiseUnaryPythonRefInfo(
        "_refs.rad2deg",
        torch_opinfo_name="rad2deg",
        decorators=(precisionOverride({torch.bfloat16: 7e-1,
                                       torch.float16: 7e-1}),),
    ),
    
    PythonRefInfo(
        "_refs.ravel",
        torch_opinfo_name="ravel",
    ),
    
    PythonRefInfo(
        "_refs.renorm",
        torch_opinfo_name="renorm",
    ),
    
    PythonRefInfo(
        "_refs.repeat",
        torch_opinfo_name="repeat",
        validate_view_consistency=False,
    ),
    
    PythonRefInfo(
        "_refs.reshape",
        torch_opinfo_name="reshape",
    ),
    
    PythonRefInfo(
        "_refs.reshape_as",
        torch_opinfo_name="reshape_as",
    ),
    
    PythonRefInfo(
        "_refs.roll",
        torch_opinfo_name="roll",
        validate_view_consistency=False,
    ),
    
    PythonRefInfo(
        "_refs.rot90",
        torch_opinfo_name="rot90",
        validate_view_consistency=False,
    ),
    
    PythonRefInfo(
        "_refs.select_scatter",
        torch_opinfo_name="select_scatter",
    ),
    
    PythonRefInfo(
        "_refs.stack",
        torch_opinfo_name="stack",
        validate_view_consistency=False,
    ),
    
    PythonRefInfo(
        "_refs.squeeze",
        torch_opinfo_name="squeeze",
    ),
    
    PythonRefInfo(
        "_refs.squeeze",
        torch_opinfo_name="squeeze",
        torch_opinfo_variant_name="multiple",
    ),
    
    PythonRefInfo(
        "_refs.tensor_split",
        torch_opinfo_name="tensor_split",
        skips=(
            # TensorMeta doesn't support tolist
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_meta'),
            # RuntimeError: no _refs support for torch.Tensor.tolist
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref'),
        ),
    ),
    PythonRefInfo(
        "_refs.hsplit",
        torch_opinfo_name="hsplit",
    ),
    PythonRefInfo(
        "_refs.vsplit",
        torch_opinfo_name="vsplit",
    ),
    PythonRefInfo(
        "_refs.dot",
        torch_opinfo_name="dot",
        error_inputs_func=partial(error_inputs_dot_vdot, is_ref=True),
        # 下面的代码注释指出了在 ATen 中，使用 .conj() 不能正确设置 ._is_view()
        validate_view_consistency=False,
        skips=(
            # 当 torch.Tensor.is_conj 时，会出现 RuntimeError: no _refs support
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref', dtypes=[torch.complex64, torch.complex128]),
        ),
    ),
    PythonRefInfo(
        "_refs.vdot",
        torch_opinfo_name="vdot",
        error_inputs_func=partial(error_inputs_dot_vdot, is_ref=True),
        # 下面的代码注释指出了在 ATen 中，使用 .conj() 不能正确设置 ._is_view()
        validate_view_consistency=False,
        skips=(
            # 当 torch.Tensor.is_conj 时，会出现 RuntimeError: no _refs support
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref', dtypes=[torch.complex64, torch.complex128]),
        ),
    ),
    PythonRefInfo(
        "_refs.transpose",
        torch_opinfo_name="transpose",
    ),
    PythonRefInfo(
        "_refs.t",
        torch_opinfo_name="t",
    ),
    PythonRefInfo(
        "_refs.T",
        torch_opinfo_name="T",
        error_inputs_func=partial(error_inputs_T, has_ndims_error=True),
    ),
    PythonRefInfo(
        "_refs.unfold",
        torch_opinfo_name="unfold",
    ),
    PythonRefInfo(
        "_refs.unfold_copy",
        torch_opinfo_name="unfold_copy",
        supports_out=True,
    ),
    PythonRefInfo(
        "_refs.unsqueeze",
        torch_opinfo_name="unsqueeze",
    ),
    PythonRefInfo(
        "_refs.view",
        torch_opinfo_name="view",
    ),
    PythonRefInfo(
        "_refs.view_as",
        torch_opinfo_name="view_as",
    ),
    PythonRefInfo(
        "_refs.vstack",
        torch_opinfo_name="vstack",
        skips=(
            # https://github.com/pytorch/pytorch/issues/78613
            # 由于该问题，标记为预期失败
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),
        ),
    ),
    PythonRefInfo(
        "_refs.unflatten",
        torch_opinfo_name="unflatten",
    ),
    PythonRefInfo(
        "_refs.unbind",
        torch_opinfo_name="unbind",
    ),
    #
    # Reduction Reference OpInfos
    #
    ReductionPythonRefInfo(
        "_refs.all",
        torch_opinfo_name="all",
        skips=(
            # 当输入是 uint8 时，返回类型应为 bool，但实际上返回了 uint8
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_result_dtype',
                dtypes=[torch.uint8]),
        ),
    ),
    ReductionPythonRefInfo(
        "_refs.amax",  # 创建一个 ReductionPythonRefInfo 对象，处理 torch 中的 amax 操作
        torch_opinfo_name="amax",  # 设置 torch 中对应的操作名称为 amax
        error_inputs_func=partial(error_inputs_aminmax_amax_amin, is_ref=True),  # 设置错误输入处理函数为 error_inputs_aminmax_amax_amin 的部分应用
        skips=(  # 设置需要跳过的测试用例列表
            # FIXME: 当 dim=[] 时会对所有维度进行归约
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty'),  # 期望测试用例 'test_dim_empty' 失败
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty_keepdim'),  # 期望测试用例 'test_dim_empty_keepdim' 失败
        ),
    ),
    ReductionPythonRefInfo(
        "_refs.amin",  # 创建一个 ReductionPythonRefInfo 对象，处理 torch 中的 amin 操作
        torch_opinfo_name="amin",  # 设置 torch 中对应的操作名称为 amin
        error_inputs_func=partial(error_inputs_aminmax_amax_amin, is_ref=True),  # 设置错误输入处理函数为 error_inputs_aminmax_amax_amin 的部分应用
        skips=(  # 设置需要跳过的测试用例列表
            # FIXME: 当 dim=[] 时会对所有维度进行归约
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty'),  # 期望测试用例 'test_dim_empty' 失败
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty_keepdim'),  # 期望测试用例 'test_dim_empty_keepdim' 失败
        ),
    ),
    ReductionPythonRefInfo(
        "_refs.any",  # 创建一个 ReductionPythonRefInfo 对象，处理 torch 中的 any 操作
        torch_opinfo_name="any",  # 设置 torch 中对应的操作名称为 any
        skips=(  # 设置需要跳过的测试用例列表
            # FIXME: 当 uint8 类型的输入返回 uint8 而不是 bool 类型时
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_result_dtype',
                dtypes=[torch.uint8]),  # 期望测试用例 'test_result_dtype' 失败，指定 dtypes 为 [torch.uint8]
        ),
    ),
    ReductionPythonRefInfo(
        "_refs.count_nonzero",  # 创建一个 ReductionPythonRefInfo 对象，处理 torch 中的 count_nonzero 操作
        torch_opinfo_name="count_nonzero",  # 设置 torch 中对应的操作名称为 count_nonzero
        skips=(  # 设置需要跳过的测试用例列表
            # FIXME: count_nonzero 操作不接受 keepdim 参数
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions',
                'test_dim_default_keepdim'),  # 跳过测试用例 'test_dim_default_keepdim'
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions', 'test_dim_none_keepdim'),  # 跳过测试用例 'test_dim_none_keepdim'
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions', 'test_dim_single_keepdim'),  # 跳过测试用例 'test_dim_single_keepdim'
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),  # 跳过测试用例 'test_dim_empty_keepdim'
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions', 'test_dim_multi_keepdim'),  # 跳过测试用例 'test_dim_multi_keepdim'
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions',
                'test_dim_multi_unsorted_keepdim'),  # 跳过测试用例 'test_dim_multi_unsorted_keepdim'
            # FIXME: 当 dim=[] 时会对所有维度进行归约
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),  # 跳过测试用例 'test_dim_empty'
        ),
    ),
    ReductionPythonRefInfo(
        "_refs.mean",  # 创建一个 ReductionPythonRefInfo 对象，处理 torch 中的 mean 操作
        torch_opinfo_name="mean",  # 设置 torch 中对应的操作名称为 mean
        supports_out=True,  # 设置支持输出参数 out
        error_inputs_func=partial(error_inputs_mean, is_ref=True),  # 设置错误输入处理函数为 error_inputs_mean 的部分应用
        skips=(  # 设置需要跳过的测试用例列表
            # FIXME: 当 dim=[] 时会对所有维度进行归约
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty'),  # 期望测试用例 'test_dim_empty' 失败
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty_keepdim'),  # 期望测试用例 'test_dim_empty_keepdim' 失败
        ),
    ),
    ReductionPythonRefInfo(
        "_refs.std",
        torch_opinfo_name="std",
        supports_out=True,
        skips=(
            # FIXME: reduces all dimensions when dim=[]
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty'),
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty_keepdim'),
            # FIXME: improve precision
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input',
                dtypes=(torch.float16,)),
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions',
                'test_ref_duplicate_values',
                dtypes=(torch.float16,)),
        ),
    ),
    # std_mean and var_mean are not ReductionInfos
    PythonRefInfo(
        "_refs.std_mean",
        torch_opinfo_name="std_mean",
    ),
    # 创建一个描述 sum 操作的 ReductionPythonRefInfo 对象
    ReductionPythonRefInfo(
        "_refs.sum",
        torch_opinfo_name="sum",
        supports_out=True,
        skips=(
            # FIXME: doesn't test out behavior properly for this operator
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
            # FIXME: mean reduces all dimensions when dim=[]
            DecorateInfo(unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty'),
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions', 'test_dim_empty_keepdim'),
            # FIXME: improve precision
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input',
                dtypes=[torch.float16]),
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions',
                'test_ref_duplicate_values',
                dtypes=[torch.float16]),
            # FIXME: doesn't test all dtypes for float32
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestOperators', 'test_reduction_all',
                dtypes=[torch.float32]),
        ),
    ),
    # 创建一个描述 cumsum 操作的 PythonRefInfo 对象
    PythonRefInfo(
        "_refs.cumsum",
        torch_opinfo_name="cumsum",
        supports_out=True,
        skips=(
            # doesn't test out behavior properly for this operator
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
        ),
    ),
    # 创建一个描述 cumprod 操作的 PythonRefInfo 对象
    PythonRefInfo(
        "_refs.cumprod",
        torch_opinfo_name="cumprod",
        supports_out=True,
        skips=(
            # doesn't test out behavior properly for this operator
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
        ),
    ),
    # 创建一个描述 sum_to_size 操作的 PythonRefInfo 对象
    PythonRefInfo(
        "_refs.sum_to_size",
        torch_opinfo_name="sum_to_size",
        validate_view_consistency=False,
    ),
    # 创建一个 ReductionPythonRefInfo 对象，用于描述 "_refs.prod" 运算符的参考信息
    ReductionPythonRefInfo(
        "_refs.prod",
        torch_opinfo_name="prod",  # 指定与 Torch 中的 "prod" 运算符对应的名称
        supports_out=True,  # 支持输出参数
        supports_multiple_dims=True,  # 支持多维度操作
        skips=(
            # FIXME: 该测试未正确测试运算符的输出行为
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_out'),
            # FIXME: 当 dim=[] 时会减少所有维度
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty'),
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty_keepdim'),
            # FIXME: 提高计算精度
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input',
                dtypes=[torch.float16, torch.complex64]),
        ),
    ),
    # 创建一个 ReductionPythonRefInfo 对象，用于描述 "_refs.var" 运算符的参考信息
    ReductionPythonRefInfo(
        "_refs.var",
        torch_opinfo_name="var",  # 指定与 Torch 中的 "var" 运算符对应的名称
        supports_out=True,  # 支持输出参数
        skips=(
            # FIXME: 当 dim=[] 时会减少所有维度
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty'),
            DecorateInfo(
                unittest.expectedFailure, 'TestReductions', 'test_dim_empty_keepdim'),
            # FIXME: 提高计算精度
            DecorateInfo(
                unittest.skip("Skipped!"), 'TestReductions', 'test_ref_small_input'),
        ),
    ),
    # 创建一个 PythonRefInfo 对象，用于描述 "_refs.var_mean" 运算符的参考信息
    PythonRefInfo(
        "_refs.var_mean",
        torch_opinfo_name="var_mean",  # 指定与 Torch 中的 "var_mean" 运算符对应的名称
        validate_view_consistency=False,  # 禁用视图一致性验证
    ),
    #
    # 线性代数运算符
    #
    # 创建一个 PythonRefInfo 对象，用于描述 "_refs.addr" 运算符的参考信息
    PythonRefInfo(
        "_refs.addr",
        torch_opinfo_name="addr",  # 指定与 Torch 中的 "addr" 运算符对应的名称
        decorators=(
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref',),  # 使用装饰器指定预期失败的测试用例
        ),
    ),
    # 创建一个 PythonRefInfo 对象，用于描述 "_refs.trace" 运算符的参考信息
    PythonRefInfo(
        "_refs.trace",
        torch_opinfo_name="trace",  # 指定与 Torch 中的 "trace" 运算符对应的名称
    ),
    # 创建一个 PythonRefInfo 对象，用于描述 "_refs.norm" 运算符的参考信息
    PythonRefInfo(
        "_refs.norm",
        torch_opinfo_name="norm",  # 指定与 Torch 中的 "norm" 运算符对应的名称
        supports_out=True,  # 支持输出参数
        # 使用 vector_norm 进行计算，而 vector_norm 受 https://github.com/pytorch/pytorch/issues/77216 影响
        validate_view_consistency=False,  # 禁用视图一致性验证
    ),
    #
    # 张量创建参考操作信息
    #
    PythonRefInfo(
        "_refs.empty",
        torch_opinfo_name="empty",
        skips=(
            # 装饰器信息：跳过测试，因为预期 empty 不可比较
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_python_ref'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_out'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_out_warning'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestMathBits',
                         'test_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestMathBits',
                         'test_neg_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestMathBits',
                         'test_neg_view'),
            # FIXME: 应该不检查空结果
            DecorateInfo(unittest.skip("Can't check result for empty"), 'TestCommon', 'test_python_ref_executor'),
            # 装饰器信息：跳过测试，因为输出不确定性
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
        ),
    ),
    PythonRefInfo(
        "_refs.empty_like",
        torch_opinfo_name="empty_like",
        skips=(
            # 使用装饰器跳过测试，因为 empty_like 的结果无法比较
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_python_ref'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_out'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_out_warning'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestMathBits',
                         'test_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestMathBits',
                         'test_neg_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestMathBits',
                         'test_neg_view'),
            # FIXME: 应该不比较 empty_like 的结果
            DecorateInfo(unittest.skip("Can't check result for empty_like"), 'TestCommon', 'test_python_ref_executor'),
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
        ),
    ),
    PythonRefInfo(
        "_refs.randn",
        torch_opinfo_name="randn",
        op=lambda *args, **kwargs: wrapper_set_seed(refs.randn, *args, **kwargs),
        skips=(
            # 参见 https://github.com/pytorch/pytorch/issues/85121
            DecorateInfo(unittest.skip("make_traced() doesn't set seed properly!"),
                         'TestCommon',
                         'test_python_ref_executor'),
            # 这些测试期望输入为张量或张量序列
            DecorateInfo(unittest.skip("Test expects tensor input"), "TestCommon", "test_noncontiguous_samples"),
            DecorateInfo(unittest.skip("Test expects tensor input"), 'TestMathBits', 'test_neg_view'),
            DecorateInfo(unittest.skip("Test expects tensor input"), 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.skip("Test expects tensor input"), 'TestMathBits', 'test_neg_conj_view'),
        ),
    ),
    PythonRefInfo(
        "_refs.eye",
        torch_opinfo_name="eye",
        skips=(
            # 跳过这些测试，因为我们没有张量输入
            DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_conj_view'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_conj_view'),
            DecorateInfo(unittest.skip("Skipped!"), 'TestMathBits', 'test_neg_view'),
        ),
    ),
    PythonRefInfo(
        "_refs.new_empty",
        torch_opinfo_name="new_empty",
        skips=(
            # 跳过以下测试，因为预期的空值不可比较
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_python_ref'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_out'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestCommon',
                         'test_out_warning'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestMathBits',
                         'test_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestMathBits',
                         'test_neg_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty is not comparable"),
                         'TestMathBits',
                         'test_neg_view'),
            # FIXME: 应该不比较 empty_like 的结果
            DecorateInfo(unittest.skip("Can't check result for new_empty"), 'TestCommon', 'test_python_ref_executor'),
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
        ),
    ),
    PythonRefInfo(
        "_refs.new_empty_strided",
        torch_opinfo_name="new_empty_strided",
        skips=(
            # 跳过以下测试，因为预期的 empty_strided 不可比较
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestCommon',
                         'test_python_ref'),
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestMathBits',
                         'test_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestMathBits',
                         'test_neg_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestMathBits',
                         'test_neg_view'),
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestCommon',
                         'test_python_ref_executor'),
            DecorateInfo(unittest.skip('output is non-deterministic'), 'TestCommon', 'test_compare_cpu'),
        ),
    ),
    PythonRefInfo(
        "_refs.empty_strided",  # 定义一个 PythonRefInfo 对象，用于处理 empty_strided 操作的参考信息
        torch_opinfo_name="empty_strided",  # 指定对应的 torch 操作名称为 empty_strided
        skips=(  # 定义一组 DecorateInfo 对象，这些对象用于跳过特定的测试用例
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),  # 跳过的原因：empty_strided 不可比较
                         'TestCommon',  # 所属的测试类为 TestCommon
                         'test_python_ref'),  # 具体的测试方法为 test_python_ref
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestCommon',
                         'test_python_ref_torch_fallback'),
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestMathBits',
                         'test_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestMathBits',
                         'test_neg_conj_view'),
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestMathBits',
                         'test_neg_view'),
            DecorateInfo(unittest.skip("Expected: empty_strided is not comparable"),
                         'TestCommon',
                         'test_python_ref_executor'),
            DecorateInfo(unittest.skip('output is non-deterministic'),  # 跳过的原因：输出是不确定的
                         'TestCommon',
                         'test_compare_cpu'),
        ),
    ),
    PythonRefInfo(
        "_refs.new_full",  # 定义一个 PythonRefInfo 对象，用于处理 new_full 操作的参考信息
        torch_opinfo_name="new_full",  # 指定对应的 torch 操作名称为 new_full
    ),
    PythonRefInfo(
        "_refs.new_ones",  # 定义一个 PythonRefInfo 对象，用于处理 new_ones 操作的参考信息
        torch_opinfo_name="new_ones",  # 指定对应的 torch 操作名称为 new_ones
    ),
    PythonRefInfo(
        "_refs.new_zeros",  # 定义一个 PythonRefInfo 对象，用于处理 new_zeros 操作的参考信息
        torch_opinfo_name="new_zeros",  # 指定对应的 torch 操作名称为 new_zeros
    ),
    #
    # Conditional Reference OpInfos
    #
    PythonRefInfo(
        "_refs.masked_fill",  # 定义一个 PythonRefInfo 对象，用于处理 masked_fill 操作的参考信息
        torch_opinfo_name="masked_fill",  # 指定对应的 torch 操作名称为 masked_fill
        skips=(  # 定义一组 DecorateInfo 对象，用于跳过特定的测试用例
            DecorateInfo(unittest.expectedFailure,  # 标记预期的测试失败
                         'TestCommon',
                         'test_python_ref_errors'),  # 具体的测试方法为 test_python_ref_errors
        ),
    ),
    PythonRefInfo(
        "_refs.where",  # 定义一个 PythonRefInfo 对象，用于处理 where 操作的参考信息
        torch_opinfo_name="where",  # 指定对应的 torch 操作名称为 where
        op=lambda self, condition, other: refs.where(condition, self, other),  # 定义操作的具体实现
        supports_out=False,  # 指明不支持输出参数 out
        skips=(  # 定义一组 DecorateInfo 对象，用于跳过特定的测试用例
            DecorateInfo(unittest.expectedFailure,  # 标记预期的测试失败
                         'TestCommon',
                         'test_python_ref_errors',  # 具体的测试方法为 test_python_ref_errors
                         device_type='cuda'),  # 限制在 CUDA 设备上
        ),
    ),
    PythonRefInfo(
        "_refs.index_select",  # 定义一个 PythonRefInfo 对象，用于处理 index_select 操作的参考信息
        torch_opinfo_name="index_select",  # 指定对应的 torch 操作名称为 index_select
        # empty_strided
        skips=(  # 定义一组 DecorateInfo 对象，用于跳过特定的测试用例
            # no _refs support for Tensor.__setitem__
            DecorateInfo(unittest.expectedFailure,  # 标记预期的测试失败
                         'TestCommon',
                         'test_python_ref'),  # 具体的测试方法为 test_python_ref
            # Sample out= with a stride of zero. This _out operation checks that the input has no
            # inner overlap
            DecorateInfo(unittest.expectedFailure,  # 标记预期的测试失败
                         'TestCommon',
                         'test_python_ref_errors'),  # 具体的测试方法为 test_python_ref_errors
        )
    ),
    PythonRefInfo(
        "_refs.index_copy",  # 定义一个 PythonRefInfo 对象，用于处理 index_copy 操作的参考信息
        torch_opinfo_name="index_copy",  # 指定对应的 torch 操作名称为 index_copy
        # empty_strided
        skips=(  # 定义一组 DecorateInfo 对象，用于跳过特定的测试用例
            # no _refs support for Tensor.__setitem__
            DecorateInfo(unittest.expectedFailure,  # 标记预期的测试失败
                         'TestCommon',
                         'test_python_ref'),  # 具体的测试方法为 test_python_ref
        ),
    ),
    # 创建 PythonRefInfo 对象，表示 _refs.index_add 操作
    PythonRefInfo(
        "_refs.index_add",
        torch_opinfo_name="index_add",
        # 该操作在跳过测试时的配置
        skips=(
            # Tensor.__setitem__ 不支持 _refs，故测试预期失败
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref'),
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref_errors'),
        ),
    ),
    # 创建 PythonRefInfo 对象，表示 _refs.index_fill 操作
    PythonRefInfo(
        "_refs.index_fill",
        torch_opinfo_name="index_fill",
        # 该操作在跳过测试时的配置
        skips=(
            # Tensor.__setitem__ 不支持 _refs，故测试预期失败
            DecorateInfo(unittest.expectedFailure, 'TestCommon', 'test_python_ref'),)
    ),
    #
    # 与测试相关的函数
    #
    # 创建 PythonRefInfo 对象，表示 _refs.allclose 操作
    PythonRefInfo(
        "_refs.allclose",
        torch_opinfo_name="allclose",
    ),
    #
    # 各种杂项函数
    #
    # 创建 PythonRefInfo 对象，表示 _refs.stft 操作
    PythonRefInfo(
        "_refs.stft",
        torch_opinfo_name="stft",
        # 该操作在跳过测试时的配置
        skips=[
            # 运行时错误：aten.pad 不支持 _refs
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref'
            ),
        ],
    ),
    # 创建 PythonRefInfo 对象，表示 _refs.istft 操作
    PythonRefInfo(
        "_refs.istft",
        torch_opinfo_name="istft",
        # 该操作在跳过测试时的配置
        skips=[
            # 运行时错误：aten.unfold_backward 不支持 _refs
            DecorateInfo(
                unittest.expectedFailure, 'TestCommon', 'test_python_ref'
            ),
        ],
    ),
    # 创建 PythonRefInfo 对象，表示 _refs.view_as_complex 操作
    PythonRefInfo(
        "_refs.view_as_complex",
        torch_opinfo_name="view_as_complex",
    ),
# 将 opinfo.definitions.python_ref_db 添加到 python_ref_db 中
python_ref_db += opinfo.definitions.python_ref_db

# 常见运算符分组

# 选择所有操作符和 Python 参考数据库的结合体
ops_and_refs = op_db + python_ref_db

# 选择所有一元通用函数信息的列表
unary_ufuncs = [op for op in ops_and_refs if isinstance(op, UnaryUfuncInfo)]

# 选择所有二元通用函数信息的列表
binary_ufuncs = [op for op in ops_and_refs if isinstance(op, BinaryUfuncInfo)]

# 选择所有二元通用函数信息的元组
binary_ufuncs_and_refs = tuple(op for op in ops_and_refs if isinstance(op, BinaryUfuncInfo))

# 选择所有频谱函数信息的列表
spectral_funcs = [op for op in ops_and_refs if isinstance(op, SpectralFuncInfo)]

# 选择所有支持稀疏输入的一元通用函数信息的列表
sparse_unary_ufuncs = [op for op in op_db if isinstance(op, UnaryUfuncInfo) and op.supports_sparse]

# 选择所有支持稀疏 CSR 格式输入的一元通用函数信息的列表
sparse_csr_unary_ufuncs = [op for op in op_db if isinstance(op, UnaryUfuncInfo) and op.supports_sparse_csr]

# 选择所有支持稀疏输入的归约操作信息的列表
sparse_reduction_ops = [op for op in op_db if isinstance(op, ReductionOpInfo) and op.supports_sparse]

# 选择所有形状函数信息的列表
shape_funcs = [op for op in ops_and_refs if isinstance(op, ShapeFuncInfo)]

# 选择所有归约操作信息的列表
reduction_ops = [op for op in ops_and_refs if isinstance(op, ReductionOpInfo)]

# 选择所有带有引用的归约操作信息的列表
reference_filtered_ops = [op for op in reduction_ops if op.ref is not None]

# 选择所有以 'masked.' 开头的带有引用的归约操作信息的列表
reference_masked_ops = [op for op in reference_filtered_ops if op.name.startswith('masked.')]

# 选择所有支持稀疏输入并以 'masked.' 开头的归约操作信息的列表
sparse_masked_reduction_ops = [op for op in sparse_reduction_ops if op.name.startswith('masked.')]

# TODO: review porting these to make_tensor

# 根据指定的形状、最大索引和设备，生成索引变量
def index_variable(shape, max_indices, device=torch.device('cpu')):
    if not isinstance(shape, tuple):
        shape = (shape,)
    # 使用随机数生成索引，并乘以最大索引，然后向下取整，转换为长整型
    index = torch.rand(*shape, dtype=torch.double, device=device).mul_(max_indices).floor_().long()
    return index

# 根据指定的形状、索引维度、最大索引和设备，生成聚集变量
def gather_variable(shape, index_dim, max_indices, duplicate=False, device=torch.device('cpu')):
    assert len(shape) == 2
    assert index_dim < 2
    batch_dim = 1 - index_dim
    index = torch.zeros(*shape, dtype=torch.long, device=device)
    # 对于每个索引维度，生成随机置换的索引，并进行复制
    for i in range(shape[index_dim]):
        index.select(index_dim, i).copy_(
            torch.randperm(max_indices, device=device)[:shape[batch_dim]])
    if duplicate:
        index.select(batch_dim, 0).copy_(index.select(batch_dim, 1))
    return index

# 生成一个伯努利分布的标量张量
def bernoulli_scalar():
    return torch.tensor(0, dtype=torch.bool).bernoulli_()

# 生成一个不全为零的掩码张量，其形状由参数指定
def mask_not_all_zeros(shape):
    assert len(shape) > 0
    while True:
        result = torch.randn(shape).gt(0)
        # 如果掩码中至少有一个非零元素，则返回该掩码
        if result.sum() > 0:
            return result

# 从 functorch 复制而来，返回一个失败测试信息元组
def xfail(op_name, variant_name='', *, device_type=None, dtypes=None):
    return (op_name, variant_name, device_type, dtypes, True)

# 返回一个跳过测试的信息元组
def skip(op_name, variant_name='', *, device_type=None, dtypes=None):
    return (op_name, variant_name, device_type, dtypes, False)

# 跳过一组测试操作
def skipOps(test_case_name, base_test_name, to_skip):
    all_opinfos = op_db
    # 遍历需要跳过的测试用例列表
    for xfail in to_skip:
        # 解包需要跳过的测试用例信息
        op_name, variant_name, device_type, dtypes, expected_failure = xfail
        # 根据操作名和变体名筛选出匹配的操作信息对象列表
        matching_opinfos = [o for o in all_opinfos
                            if o.name == op_name and o.variant_test_name == variant_name]
        # 确保至少找到一个匹配的操作信息对象，否则报错
        assert len(matching_opinfos) >= 1, f"Couldn't find OpInfo for {xfail}"
        # 遍历匹配到的操作信息对象列表
        for op in matching_opinfos:
            # 将操作信息对象的装饰器列表转换为普通列表
            decorators = list(op.decorators)
            # 根据预期的失败情况，创建对应的装饰器信息对象并添加到装饰器列表中
            if expected_failure:
                decorator = DecorateInfo(unittest.expectedFailure,
                                         test_case_name, base_test_name,
                                         device_type=device_type, dtypes=dtypes)
            else:
                decorator = DecorateInfo(unittest.skip("Skipped!"),
                                         test_case_name, base_test_name,
                                         device_type=device_type, dtypes=dtypes)
            decorators.append(decorator)
            # 将更新后的装饰器列表转换为元组并重新赋值给操作信息对象
            op.decorators = tuple(decorators)

    # 定义一个不修改任何函数的装饰器函数
    def wrapped(fn):
        return fn
    # 返回装饰器函数 wrapped
    return wrapped
```