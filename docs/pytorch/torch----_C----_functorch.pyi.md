# `.\pytorch\torch\_C\_functorch.pyi`

```
# mypy: allow-untyped-defs
# 导入需要的模块和类
from enum import Enum
from torch import Tensor

# 定义在 torch/csrc/functorch/init.cpp 中的函数原型

# 设置是否包含动态层级键值对的函数原型
def _set_dynamic_layer_keys_included(included: bool) -> None: ...

# 获取未包装的张量的函数原型
def get_unwrapped(tensor: Tensor) -> Tensor: ...

# 判断张量是否为批量张量的函数原型
def is_batchedtensor(tensor: Tensor) -> bool: ...

# 判断张量是否为函数式张量的函数原型
def is_functionaltensor(tensor: Tensor) -> bool: ...

# 判断张量是否为 Functorch 封装的张量的函数原型
def is_functorch_wrapped_tensor(tensor: Tensor) -> bool: ...

# 判断张量是否为梯度追踪张量的函数原型
def is_gradtrackingtensor(tensor: Tensor) -> bool: ...

# 判断张量是否为旧版批量张量的函数原型
def is_legacy_batchedtensor(tensor: Tensor) -> bool: ...

# 获取张量的批量维度（如果有的话）的函数原型
def maybe_get_bdim(tensor: Tensor) -> int: ...

# 获取张量的级别（如果有的话）的函数原型
def maybe_get_level(tensor: Tensor) -> int: ...

# 获取当前级别（如果有的话）的函数原型
def maybe_current_level() -> int | None: ...

# 如果张量已失效，则取消包装的函数原型
def unwrap_if_dead(tensor: Tensor) -> Tensor: ...

# 取消梯度追踪的函数原型
def _unwrap_for_grad(tensor: Tensor, level: int) -> Tensor: ...

# 包装为梯度追踪的函数原型
def _wrap_for_grad(tensor: Tensor, level: int) -> Tensor: ...

# 取消批量处理的函数原型
def _unwrap_batched(tensor: Tensor, level: int) -> tuple[Tensor, int | None]: ...

# 获取当前级别的函数原型
def current_level() -> int: ...

# 计算 JVP 解释器数量的函数原型
def count_jvp_interpreters() -> int: ...

# 增加批量维度的函数原型
def _add_batch_dim(tensor: Tensor, bdim: int, level: int) -> Tensor: ...

# 允许单级自动求导函数的设置函数原型
def set_single_level_autograd_function_allowed(allowed: bool) -> None: ...

# 获取是否允许单级自动求导函数的函数原型
def get_single_level_autograd_function_allowed() -> bool: ...

# 取消函数式张量的包装的函数原型
def _unwrap_functional_tensor(tensor: Tensor, reapply_views: bool) -> Tensor: ...

# 包装函数式张量的函数原型
def _wrap_functional_tensor(tensor: Tensor, level: int) -> Tensor: ...

# 增加 Vmap 嵌套深度的函数原型
def _vmap_increment_nesting(batch_size: int, randomness: str) -> int: ...

# 减少 Vmap 嵌套深度的函数原型
def _vmap_decrement_nesting() -> int: ...

# 增加梯度追踪嵌套深度的函数原型
def _grad_increment_nesting() -> int: ...

# 减少梯度追踪嵌套深度的函数原型
def _grad_decrement_nesting() -> int: ...

# 增加 JVP 嵌套深度的函数原型
def _jvp_increment_nesting() -> int: ...

# 减少 JVP 嵌套深度的函数原型
def _jvp_decrement_nesting() -> int: ...

# 定义在 aten/src/ATen/functorch/Interpreter.h 中的枚举类型 TransformType
class TransformType(Enum):
    Torch: TransformType = ...
    Vmap: TransformType = ...
    Grad: TransformType = ...
    Jvp: TransformType = ...
    Functionalize: TransformType = ...

# 定义在 aten/src/ATen/functorch/Interpreter.h 中的枚举类型 RandomnessType
class RandomnessType(Enum):
    Error: TransformType = ...
    Same: TransformType = ...
    Different: TransformType = ...

# 定义在 aten/src/ATen/functorch/Interpreter.h 中的 CInterpreter 类
class CInterpreter:
    # 返回变换类型的函数原型
    def key(self) -> TransformType: ...
    # 返回级别的函数原型
    def level(self) -> int: ...

# 定义在 aten/src/ATen/functorch/Interpreter.h 中的 CGradInterpreterPtr 类
class CGradInterpreterPtr:
    # 使用 CInterpreter 对象初始化的函数原型
    def __init__(self, interpreter: CInterpreter) -> None: ...
    # 将张量提升的函数原型
    def lift(self, Tensor) -> Tensor: ...
    # 返回前一个梯度模式的函数原型
    def prevGradMode(self) -> bool: ...

# 定义在 aten/src/ATen/functorch/Interpreter.h 中的 CJvpInterpreterPtr 类
class CJvpInterpreterPtr:
    # 使用 CInterpreter 对象初始化的函数原型
    def __init__(self, interpreter: CInterpreter) -> None: ...
    # 将张量提升的函数原型
    def lift(self, Tensor) -> Tensor: ...
    # 返回前一个前向梯度模式的函数原型
    def prevFwdGradMode(self) -> bool: ...

# 定义在 aten/src/ATen/functorch/Interpreter.h 中的 CFunctionalizeInterpreterPtr 类
class CFunctionalizeInterpreterPtr:
    # 使用 CInterpreter 对象初始化的函数原型
    def __init__(self, interpreter: CInterpreter) -> None: ...
    # 返回变换类型的函数原型
    def key(self) -> TransformType: ...
    # 返回级别的函数原型
    def level(self) -> int: ...
    # 返回是否添加后向视图的函数原型
    def functionalizeAddBackViews(self) -> bool: ...

# 定义在 aten/src/ATen/functorch/Interpreter.h 中的 CVmapInterpreterPtr 类
class CVmapInterpreterPtr:
    # 使用 CInterpreter 对象初始化的函数原型
    def __init__(self, interpreter: CInterpreter) -> None: ...
    # 返回变换类型的函数原型
    def key(self) -> TransformType: ...
    # 返回级别的函数原型
    def level(self) -> int: ...
    # 返回批处理大小的函数原型
    def batchSize(self) -> int: ...
    # 返回随机性类型的函数原型
    def randomness(self) -> RandomnessType: ...

# 定义 DynamicLayer 类
class DynamicLayer: ...

# 获取动态层级堆栈深度的函数原型
def get_dynamic_layer_stack_depth() -> int: ...
# 获取解释器栈的当前状态并返回一个 CInterpreter 对象列表
def get_interpreter_stack() -> list[CInterpreter]: ...

# 查看解释器栈顶部的 CInterpreter 对象，但不移除它
def peek_interpreter_stack() -> CInterpreter: ...

# 弹出动态层堆栈的顶部元素，并返回弹出的 DynamicLayer 对象
def pop_dynamic_layer_stack() -> DynamicLayer: ...

# 弹出动态层堆栈中的元素，并将栈恢复到指定的深度
def pop_dynamic_layer_stack_and_undo_to_depth(int) -> None: ...

# 将指定的 DynamicLayer 对象推入动态层堆栈，并返回堆栈的新深度
def push_dynamic_layer_stack(dl: DynamicLayer) -> int: ...
```