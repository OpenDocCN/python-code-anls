# `.\pytorch\benchmarks\dynamo\summarize_perf.py`

```py
import logging  # 导入日志记录模块
import os  # 导入操作系统功能模块
import re  # 导入正则表达式模块
from collections import defaultdict  # 导入默认字典模块

import click  # 导入命令行参数解析模块
import pandas as pd  # 导入处理数据的模块
from tabulate import tabulate  # 导入表格化输出模块


def gmean(s):
    return s.product() ** (1 / len(s))  # 计算给定序列的几何平均值


def find_csv_files(path, perf_compare):
    """
    递归搜索目录及其子目录中所有包含目标字符串的 CSV 文件。
    """

    def is_csv(f):
        if perf_compare:
            regex = r"training_(torchbench|huggingface|timm_models)\.csv"
            return re.match(regex, f) is not None  # 检查文件名是否符合特定的正则表达式
        else:
            return f.endswith("_performance.csv")  # 检查文件名是否以特定字符串结尾

    csv_files = []
    for root, dirs, files in os.walk(path):  # 遍历指定目录及其子目录中的文件
        for file in files:
            if is_csv(file):  # 如果文件是符合条件的 CSV 文件
                csv_files.append(os.path.join(root, file))  # 将文件的完整路径添加到列表中
    return csv_files  # 返回所有符合条件的 CSV 文件路径列表


@click.command()
@click.argument("directory", default="artifacts")  # 设置默认的命令行参数，指定 CSV 文件所在的目录
@click.option("--amp", is_flag=True)  # 命令行选项，用于指定是否包含 amp 类型的统计
@click.option("--float32", is_flag=True)  # 命令行选项，用于指定是否包含 float32 类型的统计
@click.option(
    "--perf-compare",
    is_flag=True,
    help="Set if the CSVs were generated by running manually the action rather than picking them from the nightly job",
)  # 命令行选项，用于指定是否为手动运行生成的 CSV 文件，而不是从夜间任务中选择的
def main(directory, amp, float32, perf_compare):
    """
    给定包含多个 CSV 文件的目录，聚合并生成类似于 https://torchci-git-fork-huydhn-add-compilers-bench-74abf8-fbopensource.vercel.app/benchmark/compilers 上 web UI 的汇总统计信息。

    如果您下载了来自 CI 的 CSV 文件并且需要快速查看聚合统计信息，则此功能非常有用。
    CSV 文件的命名约定应与 CI 中使用的完全相同。

    您可能还对以下内容感兴趣：
    https://docs.google.com/document/d/1DQQxIgmKa3eF0HByDTLlcJdvefC4GwtsklJUgLs09fQ/edit# 解释了如何解释原始 csv 数据。
    """
    dtypes = ["amp", "float32"]  # 初始化数据类型列表，默认包含 amp 和 float32

    if amp and not float32:  # 如果指定了 --amp 选项但未指定 --float32 选项
        dtypes = ["amp"]  # 设置数据类型列表为仅包含 amp
    if float32 and not amp:  # 如果指定了 --float32 选项但未指定 --amp 选项
        dtypes = ["float32"]  # 设置数据类型列表为仅包含 float32

    dfs = defaultdict(list)  # 使用默认字典，键对应文件名，值为对应文件的数据框列表
    for f in find_csv_files(directory, perf_compare):  # 遍历指定目录中符合条件的 CSV 文件
        try:
            dfs[os.path.basename(f)].append(pd.read_csv(f))  # 将读取的 CSV 文件添加到对应文件名的数据框列表中
        except Exception:
            logging.warning("failed parsing %s", f)  # 记录警告信息，指示解析文件时出错
            raise  # 抛出异常

    # dtype -> statistic -> benchmark -> compiler -> value
    results = defaultdict(  # 使用默认字典，第一级键为数据类型
        lambda: defaultdict(  # 第二级键为统计量
            lambda: defaultdict(dict)  # 第三级键为基准测试，值为字典，键为编译器，值为对应的数值
        )
    )
    for k, v in sorted(dfs.items()):
        # 遍历 dfs 字典中的每对键值对，按键排序处理
        if perf_compare:
            # 如果 perf_compare 为真
            regex = r"training_(torchbench|huggingface|timm_models)\.csv"
            # 定义正则表达式，匹配训练相关的性能文件名格式
            m = re.match(regex, k)
            # 尝试对 k 进行正则匹配
            assert m is not None, k
            # 确保正则匹配成功，否则断言失败并打印 k
            compiler = "inductor"
            # 设置编译器为 "inductor"
            benchmark = m.group(1)
            # 提取匹配组1，作为基准名称
            dtype = "float32"
            # 设置数据类型为 "float32"
            mode = "training"
            # 设置模式为 "training"
            device = "cuda"
            # 设置设备为 "cuda"
        else:
            # 如果 perf_compare 不为真
            regex = (
                "(.+)_"
                "(torchbench|huggingface|timm_models)_"
                "(float32|amp)_"
                "(inference|training)_"
                "(cpu|cuda)_"
                r"performance\.csv"
            )
            # 定义更复杂的正则表达式，匹配性能文件名格式
            m = re.match(regex, k)
            # 尝试对 k 进行正则匹配
            compiler = m.group(1)
            # 提取匹配组1，作为编译器名称
            benchmark = m.group(2)
            # 提取匹配组2，作为基准名称
            dtype = m.group(3)
            # 提取匹配组3，作为数据类型
            mode = m.group(4)
            # 提取匹配组4，作为模式
            device = m.group(5)
            # 提取匹配组5，作为设备类型

        df = pd.concat(v)
        # 合并 v 中的所有 DataFrame 到一个 DataFrame 中
        df = df.dropna().query("speedup != 0")
        # 删除空值行并筛选出 speedup 不为零的数据行

        statistics = {
            "speedup": gmean(df["speedup"]),
            # 计算 speedup 的几何平均值
            "comptime": df["compilation_latency"].mean(),
            # 计算编译延迟的平均值
            "memory": gmean(df["compression_ratio"]),
            # 计算压缩比率的几何平均值
        }

        if dtype not in dtypes:
            continue
            # 如果 dtype 不在 dtypes 中，跳过当前循环

        for statistic, v in statistics.items():
            # 遍历 statistics 字典中的每个统计指标及其值
            results[f"{device} {dtype} {mode}"][statistic][benchmark][compiler] = v
            # 将统计结果存入结果字典中的相应位置

    descriptions = {
        "speedup": "Geometric mean speedup",
        "comptime": "Mean compilation time",
        "memory": "Peak memory compression ratio",
    }

    for dtype_mode, r in results.items():
        # 遍历结果字典中的每个设备-数据类型-模式组合及其对应的结果数据
        print(f"# {dtype_mode} performance results")
        # 打印当前组合的性能结果标题
        for statistic, data in r.items():
            # 遍历当前结果数据中的每个统计指标及其数据
            print(f"## {descriptions[statistic]}")
            # 打印当前统计指标的描述

            table = []
            # 初始化空列表，用于存储表格数据
            for row_name in data[next(iter(data.keys()))]:
                # 遍历当前数据中第一个键的所有行名（假设数据非空）
                row = [row_name]
                # 创建包含当前行名的列表
                for col_name in data:
                    # 遍历当前数据中的每个列名
                    row.append(round(data[col_name][row_name], 2))
                    # 将每个列名对应行名的数据取两位小数后加入行列表中
                table.append(row)
                # 将当前行列表加入表格列表中

            headers = list(data.keys())
            # 获取数据字典的所有键，作为表格的列标题
            print(tabulate(table, headers=headers))
            # 使用 tabulate 函数打印格式化的表格
            print()
            # 打印空行，用于分隔不同统计指标的输出
# 调用主程序入口函数 `main()`
main()
```