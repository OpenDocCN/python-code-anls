# `.\pytorch\tools\pyi\gen_pyi.py`

```py
# 从未来导入注释语法，用于支持类型提示的声明
from __future__ import annotations

# 导入命令行参数解析模块
import argparse
# 导入集合模块，用于特定数据结构的操作
import collections
# 导入模块动态载入功能
import importlib
# 导入系统相关模块
import sys
# 导入漂亮的打印格式模块
from pprint import pformat
# 导入类型提示相关模块
from typing import Sequence
# 导入单元测试模块的模拟对象和补丁
from unittest.mock import Mock, patch
# 导入警告模块中的警告函数
from warnings import warn

# 从自定义工具模块导入相关功能
from tools.autograd.gen_python_functions import (
    group_overloads,  # 导入函数重载分组功能
    load_signatures,   # 导入加载签名的功能
    should_generate_py_binding,  # 导入判断是否生成 Python 绑定的功能
)

# 从 torchgen.api.python 模块导入相关类和函数
from torchgen.api.python import (
    PythonSignatureGroup,            # 导入 Python 签名组类
    PythonSignatureNativeFunctionPair,  # 导入 Python 原生函数对类
    returns_structseq_pyi,           # 导入返回结构序列类型提示的函数
)

# 从 torchgen.gen 模块导入解析本地 YAML 文件的功能
from torchgen.gen import parse_native_yaml, parse_tags_yaml
# 从 torchgen.model 模块导入私有的 TorchDispatchModeKey 类、DispatchKey 类和 Variant 类
from torchgen.model import _TorchDispatchModeKey, DispatchKey, Variant
# 从 torchgen.utils 模块导入文件管理器类
from torchgen.utils import FileManager

"""
This module implements generation of type stubs for PyTorch,
enabling use of autocomplete in IDEs like PyCharm, which otherwise
don't understand C extension modules.

At the moment, this module only handles type stubs for torch and
torch.Tensor.  It should eventually be expanded to cover all functions
which come are autogenerated.

Here's our general strategy:

- We start off with a hand-written __init__.pyi.in file.  This
  file contains type definitions for everything we cannot automatically
  generate, including pure Python definitions directly in __init__.py
  (the latter case should be pretty rare).

- We go through automatically bound functions based on the
  type information recorded in native_functions.yaml and
  generate type hints for them (generate_type_hints)

There are a number of type hints which we've special-cased;
read gen_pyi for the gory details.
"""

def get_py_torch_functions(
    python_funcs: Sequence[PythonSignatureNativeFunctionPair],
    method: bool = False,
) -> Sequence[PythonSignatureGroup]:
    """
    Get declarations (grouped by name) which should be generated
    as either functions in the "torch" module or methods on Tensor.
    """

    def should_bind_function(python_func: PythonSignatureNativeFunctionPair) -> bool:
        return (
            should_generate_py_binding(python_func.function)  # 检查函数是否应生成 Python 绑定
            and not python_func.function.python_module  # 确保函数不是 Python 模块
            and Variant.function in python_func.function.variants  # 检查函数是否是函数变体
        )

    def should_bind_method(python_func: PythonSignatureNativeFunctionPair) -> bool:
        return (
            should_generate_py_binding(python_func.function)  # 检查函数是否应生成 Python 绑定
            and not python_func.function.python_module  # 确保函数不是 Python 模块
            and Variant.method in python_func.function.variants  # 检查函数是否是方法变体
        )

    should_bind = should_bind_method if method else should_bind_function
    # 返回按名称分组的生成声明，以作为“torch”模块函数或“Tensor”方法生成
    return group_overloads([f for f in python_funcs if should_bind(f)])

# TODO: Consider defining some aliases for our Union[...] types, to make
# the stubs to read on the human eye.

# 定义设备参数的字符串常量
DEVICE_PARAM = "device: Optional[DeviceLikeType] = None"
# 定义工厂参数的字符串常量，包括数据类型、设备参数、梯度需求和固定内存等
FACTORY_PARAMS = f"dtype: Optional[_dtype] = None, {DEVICE_PARAM}, requires_grad: _bool = False, pin_memory: _bool = False"

# NOTE: specifying indices for Tensor.__getitem__
# 定义一个字符串，描述 leaf_types 的类型，表示可以是 None、_bool、_int、slice、ellipsis 或 Tensor，不包括 SupportsIndex
_leaf_types = "Union[None, _bool, _int, slice, ellipsis, Tensor]"

# 定义一个字符串，描述 index 的类型，表示可以是 SupportsIndex，或者 _leaf_types，或者 _NestedSequence[_leaf_types] 中的一种
_index = f"Union[SupportsIndex, {_leaf_types}, _NestedSequence[{_leaf_types}]]"

# 定义常量 INDICES 的字符串，表示可以是 index，或者是一个元组，其中元素可以是 index 的任意组合，包括嵌套序列
INDICES = f"indices: Union[{_index}, tuple[{_index}, ...]]"

# 定义一个列表 blocklist，包含需要屏蔽的函数或方法名，用于标记不需要特殊处理的名称
blocklist = [
    "__init_subclass__",
    "__new__",
    "__subclasshook__",
    "cdist",
    "device",
    "grad",
    "requires_grad",
    "range",
    "einsum",
    "broadcast_tensors",
    "align_tensors",
    "meshgrid",
    "cartesian_prod",
    "block_diag",
    "norm",
    "chain_matmul",
    "stft",
    "tensordot",
    "split",
    "unique_consecutive",
    "atleast_1d",
    "atleast_2d",
    "atleast_3d",
    "add",
    "add_",
    "add_out",
    "sub",
    "sub_",
    "sub_out",
    "mul",
    "mul_",
    "mul_out",
    "div",
    "div_",
    "div_out",
    "true_divide",
    "true_divide_",
    "true_divide_out",
    "floor_divide",
    "floor_divide_",
    "floor_divide_out",
    "to",
    "_to_copy",
    "copy_",
]

# 定义一个元组 binary_ops，包含二元操作的方法名，涵盖加、减、乘、除等运算
binary_ops = (
    "add", "sub", "mul", "div", "pow", "lshift", "rshift", "mod", "truediv",
    "matmul", "floordiv", "radd", "rsub", "rmul", "rtruediv", "rfloordiv", "rpow",
    "and", "or", "xor", "rand", "ror", "rxor",
    "iadd", "iand", "idiv", "ilshift", "imul", "ior", "irshift", "isub", "ixor", "ifloordiv", "imod"
)

# 定义一个元组 symmetric_comparison_ops，包含对称比较操作的方法名，如相等和不等
symmetric_comparison_ops = ("eq", "ne")

# 定义一个元组 asymmetric_comparison_ops，包含非对称比较操作的方法名，如大于、小于等
asymmetric_comparison_ops = ("ge", "gt", "lt", "le")

# 将对称和非对称比较操作合并成一个元组 comparison_ops
comparison_ops = symmetric_comparison_ops + asymmetric_comparison_ops

# 定义一个元组 unary_ops，包含一元操作的方法名，如取反、绝对值等
unary_ops = ("neg", "abs", "invert")
# 定义一个元组，包含了需要进行类型转换的操作的名称
to_py_type_ops = ("bool", "float", "complex", "long", "index", "int", "nonzero")
# 创建一个包含所有操作的列表，包括二元操作、比较操作、一元操作和类型转换操作
all_ops = binary_ops + comparison_ops + unary_ops + to_py_type_ops

# 定义一个函数，根据操作名称返回操作特殊函数的签名列表
def sig_for_ops(opname: str) -> list[str]:
    """sig_for_ops(opname : str) -> List[str]
    
    Returns signatures for operator special functions (__add__ etc.)"""
    
    # 断言操作名称以双下划线开始和结束，用来确保操作名称是特殊函数
    assert opname.endswith("__") and opname.startswith("__"), f"Unexpected op {opname}"

    # 提取操作名称（去除开头和结尾的双下划线）
    name = opname[2:-2]
    if name in binary_ops:
        # 如果是二元操作，返回其特殊函数的签名列表
        return [f"def {opname}(self, other: Any) -> Tensor: ..."]
    elif name in comparison_ops:
        # 如果是比较操作，生成相应的签名，并在需要时添加类型忽略注释
        sig = f"def {opname}(self, other: Any) -> Tensor: ..."
        if name in symmetric_comparison_ops:
            sig += "  # type: ignore[override]"
        return [sig]
    elif name in unary_ops:
        # 如果是一元操作，返回其特殊函数的签名列表
        return [f"def {opname}(self) -> Tensor: ..."]
    elif name in to_py_type_ops:
        # 如果是类型转换操作，根据具体的操作名称确定返回值的类型
        if name in {"bool", "float", "complex"}:
            tname = name
        elif name == "nonzero":
            tname = "bool"
        else:
            tname = "int"
        # 根据返回值类型生成相应的签名
        if tname in {"float", "int", "bool", "complex"}:
            tname = "builtins." + tname
        return [f"def {opname}(self) -> {tname}: ..."]
    else:
        # 如果操作名称不在已知的操作列表中，抛出异常
        raise Exception("unknown op", opname)  # noqa: TRY002

# 定义一个函数，根据给定的PythonSignatureGroup生成类型提示列表
def generate_type_hints(sig_group: PythonSignatureGroup) -> list[str]:
    type_hints: list[str] = []
    
    # 如果签名在blocklist中，并且不是过时的，直接返回空列表
    if sig_group.signature.name in blocklist and not sig_group.signature.deprecated:
        return type_hints
    
    # 如果签名是过时的，并且存在outplace变体，生成功能变体的签名
    if sig_group.signature.deprecated and sig_group.outplace is not None:
        type_hint = sig_group.signature.signature_str_pyi(skip_outputs=True)
        type_hints.append(type_hint)
    
    # 生成功能变体的签名，如果存在outplace变体，则生成out变体
    type_hint = sig_group.signature.signature_str_pyi(
        skip_outputs=sig_group.outplace is None
    )
    type_hints.append(type_hint)
    
    # 有些操作还有一个可变参数的变体签名
    type_hint_vararg = sig_group.signature.signature_str_pyi_vararg(
        skip_outputs=sig_group.outplace is None
    )
    if type_hint_vararg:
        type_hints.append(type_hint_vararg)
    
    return type_hints

# 定义一个函数，根据名称和参数列表生成最大池分发的字典
def get_max_pool_dispatch(name: str, arg_list: list[str]) -> dict[str, list[str]]:
    # 找到"{return_indices}"在参数列表中的位置索引
    flag_pos = arg_list.index("{return_indices}")
    # 如果return_indices是一个位置参数，那么它之前的所有参数不能有默认值
    # 生成位置参数的函数定义模板，不返回索引
    arg_list_positional = (
        [
            ", ".join(single_arg.split(" = ")[0] for single_arg in arg.split(", "))
            for arg in arg_list[: flag_pos + 1]
        ]
        + ["/"]
        + arg_list[flag_pos + 1 :]
    )
    # 创建一个关键字参数的副本，将return_indices强制设为关键字参数
    arg_list_keyword = arg_list.copy()
    arg_list_keyword.insert(flag_pos, "*")
    # 定义一个函数模板字符串，包含函数名、参数和返回类型的占位符
    tmpl = "def {name}({args}) -> {{return_type}}: ..."
    # 返回一个字典，包含三种函数定义的字符串模板
    return {
        name: [
            # 使用位置参数模板，指定不返回索引的返回类型为Tensor
            tmpl.format(name=name, args=", ".join(arg_list)).format(
                return_indices="return_indices: Literal[False] = False",
                return_type="Tensor",
            ),
            # 使用位置参数+斜杠(/)的模板，指定返回类型为Tuple[Tensor, Tensor]
            tmpl.format(name=name, args=", ".join(arg_list_positional)).format(
                return_indices="return_indices: Literal[True]",
                return_type="Tuple[Tensor, Tensor]",
            ),
            # 使用关键字参数的模板，指定返回类型为Tuple[Tensor, Tensor]
            tmpl.format(name=name, args=", ".join(arg_list_keyword)).format(
                return_indices="return_indices: Literal[True]",
                return_type="Tuple[Tensor, Tensor]",
            ),
        ]
    }
# 生成神经网络功能函数的定义，接受一个文件管理器作为参数
def gen_nn_functional(fm: FileManager) -> None:
    # 定义输入张量的字符串常量
    INPUT = "input: Tensor"
    # 定义卷积核大小的字符串常量，可以是整数或大小类型的联合
    KERNEL_SIZE = "kernel_size: Union[_int, _size]"
    # 定义步幅和填充的字符串，联合使用可选的整数或大小类型，默认步幅为None，填充为0
    STRIDE_PADDING = ", ".join(
        [
            "stride: Optional[Union[_int, _size]] = None",
            "padding: Union[_int, _size] = 0",
        ]
    )

    # TODO `torch._C._nn` 的列表是不完整的

    # 未排序的 `_nn` 函数提示信息的字典，键为函数名，值为函数签名列表
    unsorted_c_nn_function_hints: dict[str, list[str]] = {}

    # 遍历维度为2和3的元组
    for d in (2, 3):
        # 更新未排序的 `_nn` 函数提示信息字典
        unsorted_c_nn_function_hints.update(
            {
                # 平均池化函数的提示信息
                f"avg_pool{d}d": [
                    # 定义 `avg_pool{d}d` 函数的签名字符串
                    f"def avg_pool{d}d({{}}) -> Tensor: ...".format(
                        ", ".join(
                            [
                                f"{INPUT}",  # 输入张量
                                f"{KERNEL_SIZE}",  # 卷积核大小
                                f"{STRIDE_PADDING}",  # 步幅和填充
                                "ceil_mode: bool = False",  # 是否启用 ceil 模式
                                "count_include_pad: bool = True",  # 是否包含填充在内
                                "divisor_override: Optional[int] = None",  # 覆盖除数的选项
                            ]
                        )
                    )
                ],
                # 分数最大池化函数的提示信息
                f"fractional_max_pool{d}d": [
                    # 定义 `fractional_max_pool{d}d` 函数的签名字符串
                    f"def fractional_max_pool{d}d({{}}) -> {{}}: ...".format(
                        ", ".join(
                            [
                                f"{INPUT}",  # 输入张量
                                f"{KERNEL_SIZE}",  # 卷积核大小
                                "output_size: Union[_int, _size]",  # 输出大小
                                "_random_samples: Tensor",  # 随机样本
                            ]
                        ),
                        "Tuple[Tensor, Tensor]",  # 返回类型为元组，包含两个张量
                    )
                ],
                # 自适应最大池化函数的提示信息
                f"adaptive_max_pool{d}d": [
                    # 定义 `adaptive_max_pool{d}d` 函数的签名字符串
                    f"def adaptive_max_pool{d}d({{}}) -> {{}}: ...".format(
                        ", ".join([f"{INPUT}", "output_size: Union[_int, _size]"]),  # 输入张量和输出大小
                        "Tuple[Tensor, Tensor]",  # 返回类型为元组，包含两个张量
                    )
                ],
            }
        )

    # 已排序的 `_nn` 函数提示信息列表
    c_nn_function_hints: list[str] = []
    # 按键名对未排序的 `_nn` 函数提示信息进行排序，并逐个处理其中的提示信息列表
    for _, hints in sorted(unsorted_c_nn_function_hints.items()):
        # 如果提示信息列表的长度大于1，表示有多个重载版本，为每个版本前添加 `@overload`
        if len(hints) > 1:
            hints = ["@overload\n" + h for h in hints]
        # 将处理后的提示信息添加到已排序的 `_nn` 函数提示信息列表中
        c_nn_function_hints += hints

    # 从 `torch` 中导入的函数列表，被导入到 `torch.nn.functional` 中，可能经过 `_add_docstr` 调用筛选
    torch_imports = [
        "conv1d", "conv2d", "conv3d", "conv_transpose1d", "conv_transpose2d",
        "conv_transpose3d", "conv_tbc", "avg_pool1d", "adaptive_avg_pool1d",
        "relu_", "selu_", "celu_", "prelu", "rrelu_", "hardshrink", "bilinear",
        "pixel_shuffle", "pixel_unshuffle", "channel_shuffle", "native_channel_shuffle",
        "pairwise_distance", "pdist", "cosine_similarity",
    ]
    # 生成从 `torch` 导入函数的语句列表
    imported_hints = [f"from torch import {_} as {_}" for _ in torch_imports]
    # 从 `torch._C._nn` 中导入到 `torch.nn.functional` 的函数列表
    c_nn_imports = [
        "avg_pool2d",            # 二维平均池化
        "avg_pool3d",            # 三维平均池化
        "hardtanh_",             # 硬切线激活函数
        "elu_",                  # ELU激活函数
        "leaky_relu_",           # Leaky ReLU激活函数
        "gelu",                  # GELU激活函数
        "softplus",              # Softplus激活函数
        "softshrink",            # Softshrink激活函数
        "linear",                # 线性层
        "pad",                   # 填充函数
        "one_hot",               # One-hot编码函数
        "scaled_dot_product_attention",  # 缩放点积注意力函数
    ]
    # 将导入的函数提示添加到 `imported_hints` 列表中
    imported_hints += [f"from torch._C._nn import {_} as {_}" for _ in c_nn_imports]
    # `log_sigmoid` 函数来自 `torch._C._nn`，但使用别名 `logsigmoid`
    imported_hints.append(
        "from torch._C._nn import log_sigmoid\nlogsigmoid = log_sigmoid"
    )

    # 由 `torch._jit_internal.boolean_dispatch` 生成的函数分发提示，位于 `nn.functional` 中
    unsorted_dispatched_hints: dict[str, list[str]] = {}

    # 针对每个维度（1、2、3），获取对应的最大池化函数的分发提示
    for d in (1, 2, 3):
        unsorted_dispatched_hints.update(
            **get_max_pool_dispatch(
                f"max_pool{d}d",  # 最大池化函数名
                [
                    f"{INPUT}",               # 输入参数
                    f"{KERNEL_SIZE}",         # 核大小参数
                    f"{STRIDE_PADDING}",      # 步幅和填充参数
                    "dilation: Union[_int, _size] = 1",  # 扩张参数
                    "ceil_mode: bool = False",  # 是否使用 ceil 模式
                    "{return_indices}",       # 是否返回索引
                ],
            ),
            **get_max_pool_dispatch(
                f"fractional_max_pool{d}d",  # 分数最大池化函数名
                [
                    f"{INPUT}",               # 输入参数
                    f"{KERNEL_SIZE}",         # 核大小参数
                    "output_size: Optional[Union[_int, _size]] = None",  # 输出大小参数
                    "output_ratio: Optional[_ratio_any_t] = None",      # 输出比率参数
                    "{return_indices}",       # 是否返回索引
                    "_random_samples: Optional[Tensor] = None",         # 随机样本参数
                ],
            ),
            **get_max_pool_dispatch(
                f"adaptive_max_pool{d}d",   # 自适应最大池化函数名
                [f"{INPUT}",                 # 输入参数
                 "output_size: Union[_int, _size]",  # 输出大小参数
                 "{return_indices}"],        # 是否返回索引
            ),
        )

    # 删除 `unsorted_dispatched_hints` 中的 `fractional_max_pool1d`，因为不存在这个函数
    del unsorted_dispatched_hints["fractional_max_pool1d"]

    # 对 `unsorted_dispatched_hints` 中的提示进行排序，并将多个提示的情况下添加 `@overload` 标记
    dispatched_hints: list[str] = []
    for _, hints in sorted(unsorted_dispatched_hints.items()):
        if len(hints) > 1:
            hints = ["@overload\n" + h for h in hints]
        dispatched_hints += hints

    # 使用模板写入 `torch/nn/functional.pyi` 文件，替换相应的模板参数
    fm.write_with_template(
        "torch/nn/functional.pyi",
        "torch/nn/functional.pyi.in",
        lambda: {
            "imported_hints": imported_hints,      # 导入的函数提示列表
            "dispatched_hints": dispatched_hints,  # 分发的函数提示列表
        },
    )

    # 使用模板写入 `torch/_C/_nn.pyi` 文件，替换相应的模板参数
    fm.write_with_template(
        "torch/_C/_nn.pyi",
        "torch/_C/_nn.pyi.in",
        lambda: {
            "c_nn_function_hints": c_nn_function_hints,  # C 库中的函数提示
        },
    )
"""
We gather the docstrings for torch with the following steps:
1. Mock torch and torch._C, which are the only dependencies of the docs files
2. Mock the _add_docstr function to save the docstrings
3. Import the docs files to trigger mocked _add_docstr and collect docstrings
"""


# 定义函数 gather_docstrs，返回一个字典，包含从torch模块中收集到的文档字符串
def gather_docstrs() -> dict[str, str]:
    # 创建一个空字典，用于存储收集到的文档字符串
    docstrs = {}

    # 定义 mock_add_docstr 函数，用于模拟 _add_docstr 并保存文档字符串到 docstrs 字典中
    def mock_add_docstr(func: Mock, docstr: str) -> None:
        docstrs[func._extract_mock_name()] = docstr.strip()

    # 在上下文管理器内部，使用 patch.dict 和 patch.object 进行模块和路径的临时更改
    with patch.dict(sys.modules), patch.object(sys, "path", sys.path + ["torch"]):
        # 模拟 torch 模块和 torch._C._add_docstr
        sys.modules["torch"] = Mock(name="torch")
        sys.modules["torch._C"] = Mock(_add_docstr=mock_add_docstr)

        try:
            # 手动导入 torch._torch_docs 和 torch._tensor_docs 触发模拟的 _add_docstr 并收集文档字符串
            sys.modules["torch._torch_docs"] = importlib.import_module("_torch_docs")
            sys.modules["torch._tensor_docs"] = importlib.import_module("_tensor_docs")
        except ModuleNotFoundError:
            # 如果这些模块无法导入，以警告方式跳过文档字符串的处理
            warn(
                "Failed to import _torch_docs/_tensor_docs, skipping docstring in pyi files."
            )

    # 返回收集到的文档字符串字典
    return docstrs


# 定义函数 add_docstr_to_hint，将文档字符串添加到类型提示中
def add_docstr_to_hint(docstr: str, hint: str) -> str:
    # 如果类型提示中包含 "..."，表示处理函数或方法
    if "..." in hint:
        assert hint.endswith("..."), f"Hint `{hint}` does not end with '...'"
        hint = hint[:-3]  # 移除末尾的 "..."
        # 返回格式化后的类型提示和文档字符串
        return "\n    ".join([hint, 'r"""'] + docstr.split("\n") + ['"""', "..."])
    else:
        # 处理属性或属性的文档字符串添加
        return f'{hint}\nr"""{docstr}"""\n'


# 定义函数 gen_pyi，生成 torch 的 pyi 文件
def gen_pyi(
    native_yaml_path: str,
    tags_yaml_path: str,
    deprecated_yaml_path: str,
    fm: FileManager,
) -> None:
    """gen_pyi()

    This function generates a pyi file for torch.
    """

    # 一些逻辑与 tools/autograd/gen_python_functions.py 中的 generate_python_signature 重叠
    # 该函数专门用于生成 mypy 类型签名，而另一个函数用于自定义格式的参数检查
    # 如果更新了这个函数，需要考虑是否需要更新另一个文件

    # 用于存储 NamedTuple 定义的字典
    structseqs: dict[str, str] = {}

    # 为顶层函数生成类型签名
    unsorted_function_hints: dict[str, list[str]] = collections.defaultdict(list)

    for n, n1, n2 in [
        ("csr", "crow", "col"),
        ("csc", "ccol", "row"),
        ("bsr", "crow", "col"),
        ("bsc", "ccol", "row"),
    ]:
        unsorted_function_hints.update(
            {
                f"sparse_{n}_tensor": [
                    f"def sparse_{n}_tensor({{}}) -> Tensor: ...".format(
                        ", ".join(
                            [
                                f"{n1}_indices: Union[Tensor, List]",
                                f"{n2}_indices: Union[Tensor, List]",
                                "values: Union[Tensor, List]",
                                "size: Optional[_size] = None",
                                "*",
                                "dtype: Optional[_dtype] = None",
                                "device: Optional[DeviceLikeType] = None",
                                "requires_grad: _bool = False",
                                "check_invariants: Optional[_bool] = None",
                            ]
                        ),
                    )
                ],
            }
        )
    )

    # 添加针对除法操作的函数签名提示
    for binop in ["true_divide", "floor_divide"]:
        unsorted_function_hints[binop].append(
            f"def {binop}(input: Union[Tensor, Number], other: Union[Tensor, Number], "
            "*, out: Optional[Tensor] = None) -> Tensor: ..."
        )

    # 添加针对乘法操作的函数签名提示
    for binop in ["mul"]:
        unsorted_function_hints[binop].append(
            f"def {binop}(input: Union[Tensor, Number, _complex], other: Union[Tensor, Number, _complex], "
            "*, out: Optional[Tensor] = None) -> Tensor: ..."
        )

    # 添加针对加法和减法操作的函数签名提示
    for binop in ["add", "sub"]:
        unsorted_function_hints[binop].append(
            f"def {binop}(input: Union[Tensor, Number, _complex], other: Union[Tensor, Number, _complex], "
            "*, alpha: Optional[Union[Number, _complex]] = 1, out: Optional[Tensor] = None) -> Tensor: ..."
        )

    # 解析本地 YAML 文件，获取原生函数列表
    native_functions = parse_native_yaml(
        native_yaml_path, tags_yaml_path
    ).native_functions

    # 过滤并保留应生成 Python 绑定的原生函数
    native_functions = list(filter(should_generate_py_binding, native_functions))

    # 加载函数签名
    function_signatures = load_signatures(
        native_functions, deprecated_yaml_path, method=False, pyi=True
    )

    # 根据函数签名获取按照 PyTorch 格式的函数分组
    sig_groups = get_py_torch_functions(function_signatures)

    # 对函数分组进行排序，并遍历处理每个函数组
    for group in sorted(sig_groups, key=lambda g: g.signature.name):
        name = group.signature.name
        # 添加函数签名提示到未排序函数提示列表中
        unsorted_function_hints[name] += generate_type_hints(group)

        # 获取返回的结构化序列的 Pyi 描述
        structseq = returns_structseq_pyi(group.signature)
        if structseq is not None and not group.signature.deprecated:
            # 对于不废弃的结构化序列，将其添加到结构化序列字典中
            tuple_name, tuple_def = structseq
            if tuple_name in structseqs:
                assert structseqs[tuple_name] == tuple_def
            else:
                structseqs[tuple_name] = tuple_def
    def replace_special_case(hint: str) -> str:
        # 替换特定的提示字符串，确保与指定的枚举保持同步
        hint = hint.replace("at::Reduction::Mean", "1")
        # 将特定字符串替换为指定格式，用 Optional[Tensor] 替换 : Tensor = None
        hint = hint.replace(": Tensor = None", ": Optional[Tensor] = None")
        # 匹配两种情况，并替换为更具体的格式
        hint = hint.replace(
            "Tuple[Tensor, ...], List[Tensor]] = None",
            "Tuple[Tensor, ...], List[Tensor], None] = None",
        )
        return hint

    # 收集文档字符串
    docstrs = gather_docstrs()
    # 存储函数的类型提示
    function_hints = []
    # 遍历未排序的函数类型提示字典，按名称排序处理
    for name, hints in sorted(unsorted_function_hints.items()):
        # 对每个提示应用特殊情况替换函数
        hints = [replace_special_case(h) for h in hints]
        # 如果提示数量大于1，则添加 @overload 注解
        if len(hints) > 1:
            hints = ["@overload\n" + h for h in hints]
        # 获取函数名称对应的文档字符串
        docstr = docstrs.get(f"torch.{name}")
        # 如果存在文档字符串，则为每个提示添加文档字符串
        if docstr is not None:
            hints = [add_docstr_to_hint(docstr, h) for h in hints]
        # 将处理后的提示添加到函数类型提示列表中
        function_hints += hints

    # 为 Tensor 方法生成类型签名
    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    # 未排序的 Tensor 方法类型提示字典
    unsorted_tensor_method_hints: dict[str, list[str]] = collections.defaultdict(list)
    # 遍历二元操作列表，如 "true_divide" 和 "floor_divide"
    for binop in ["true_divide", "floor_divide"]:
        # 对于每个操作，处理是否为原地操作
        for inplace in [False, True]:
            out_suffix = ", *, out: Optional[Tensor] = None"
            # 如果是原地操作，则调整操作名称并更新输出后缀
            if inplace:
                binop += "_"
                out_suffix = ""
            # 将方法定义添加到对应操作名称的列表中
            unsorted_tensor_method_hints[binop].append(
                f"def {binop}(self, other: Union[Tensor, Number, torch.SymInt, torch.SymFloat]{out_suffix})"
                " -> Tensor: ..."
            )
    # 对于 "mul" 操作，重复上述过程
    for binop in ["mul"]:
        for inplace in [False, True]:
            out_suffix = ", *, out: Optional[Tensor] = None"
            if inplace:
                binop += "_"
                out_suffix = ""
            unsorted_tensor_method_hints[binop].append(
                f"def {binop}(self, other: Union[Tensor, Number, _complex, torch.SymInt, torch.SymFloat]{out_suffix})"
                " -> Tensor: ..."
            )
    # 对于 "add" 和 "sub" 操作，同样重复上述过程
    for binop in ["add", "sub"]:
        for inplace in [False, True]:
            out_suffix = ", out: Optional[Tensor] = None"
            if inplace:
                binop += "_"
                out_suffix = ""
            unsorted_tensor_method_hints[binop].append(
                f"def {binop}(self, other: Union[Tensor, Number, _complex, torch.SymInt, torch.SymFloat], "
                f"*, alpha: Optional[Union[Number, _complex]] = 1{out_suffix})"
                " -> Tensor: ..."
            )
    # 简单的类型转换方法
    simple_conversions = [
        "byte",
        "char",
        "double",
        "float",
        "half",
        "int",
        "long",
        "short",
        "bool",
        "bfloat16",
    ]
    # 为每个简单类型转换方法添加类型签名定义
    for name in simple_conversions:
        unsorted_tensor_method_hints[name].append(f"def {name}(self) -> Tensor: ...")
    # 加载张量方法的签名，但不包括已弃用的签名
    # TODO: 可能需要添加已弃用的签名
    tensor_method_signatures = load_signatures(
        native_functions,
        deprecated_yaml_path,
        method=True,
        skip_deprecated=True,
        pyi=True,
    )
    # 获取张量方法的签名分组
    tensor_method_sig_groups = get_py_torch_functions(
        tensor_method_signatures, method=True
    )

    # 遍历每个签名分组，按名称排序
    for group in sorted(tensor_method_sig_groups, key=lambda g: g.signature.name):
        name = group.signature.name
        unsorted_tensor_method_hints[name] += generate_type_hints(group)

        # 检查是否有返回结构序列的 PYI 定义，并且不是已弃用的函数
        structseq = returns_structseq_pyi(group.signature)
        if structseq is not None and not group.signature.deprecated:
            # 目前不包括已弃用的结构序列定义
            tuple_name, tuple_def = structseq
            if tuple_name in structseqs:
                assert structseqs[tuple_name] == tuple_def
            else:
                structseqs[tuple_name] = tuple_def

    # 为所有操作生成特殊方法的签名
    for op in all_ops:
        name = f"__{op}__"
        unsorted_tensor_method_hints[name] += sig_for_ops(name)

    tensor_method_hints = []
    # 按名称排序未排序的张量方法提示
    for name, hints in sorted(unsorted_tensor_method_hints.items()):
        if len(hints) > 1:
            hints = ["@overload\n" + h for h in hints]
        docstr = docstrs.get(f"torch._C.TensorBase.{name}")
        if docstr is not None:
            hints = [add_docstr_to_hint(docstr, h) for h in hints]
        tensor_method_hints += hints

    # TODO: 为 nn 缺少类型提示

    # 生成结构序列定义
    structseq_defs = [f"{defn}\n" for defn in structseqs.values()]

    # 为传统类生成类型签名
    legacy_storage_base_hints = ["class StorageBase(object): ..."]

    legacy_class_hints = []
    # 为 dtype 类生成类型签名
    for c in (
        "DoubleTensor",
        "FloatTensor",
        "BFloat16Tensor",
        "LongTensor",
        "IntTensor",
        "ShortTensor",
        "HalfTensor",
        "CharTensor",
        "ByteTensor",
        "BoolTensor",
    ):
        legacy_class_hints.append(f"class {c}(Tensor): ...")

    # TODO: 不要在此处明确列出 dtypes；从规范来源获取
    # 定义包含数据类型提示的列表
    dtype_class_hints = [
        f"{n}: dtype = ..."
        for n in [
            "float32",
            "float",
            "float64",
            "double",
            "float16",
            "bfloat16",
            "float8_e4m3fn",
            "float8_e4m3fnuz",
            "float8_e5m2",
            "float8_e5m2fnuz",
            "half",
            "uint8",
            "uint16",
            "uint32",
            "uint64",
            "int8",
            "int16",
            "short",
            "int32",
            "int",
            "int64",
            "long",
            "complex32",
            "complex64",
            "chalf",
            "cfloat",
            "complex128",
            "cdouble",
            "quint8",
            "qint8",
            "qint32",
            "bool",
            "quint4x2",
            "quint2x4",
            "bits1x8",
            "bits2x4",
            "bits4x2",
            "bits8",
            "bits16",
        ]
    ]

    # 生成 __all__ 指令
    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    # 仅包含包含提示的函数名称，以防止未定义的符号包含在 `__all__` 指令中。
    hinted_function_names = [
        name for name, hint in unsorted_function_hints.items() if hint
    ]
    # 将所有符号按字母顺序排序并添加到 `__all__` 指令中
    all_symbols = sorted(list(structseqs.keys()) + hinted_function_names)
    all_directive = pformat(all_symbols, width=100, compact=True).split("\n")
    all_directive[0] = f"__all__ = {all_directive[0]}"

    # 分发键提示
    # ~~~~~~~~~~~~~~~~~~
    dispatch_key_hints = [f"{d.name}: DispatchKey = ..." for d in DispatchKey]
    # Torch 分发模式键提示
    torch_dispatch_mode_key_hints = [
        f"{k.name}: _TorchDispatchModeKey = ..." for k in _TorchDispatchModeKey
    ]

    # 标签枚举类型提示
    # ~~~~~~~~~~~~~~~~~~~~

    # 解析标签 YAML 文件中的标签名称并排序
    tag_names = sorted(parse_tags_yaml(tags_yaml_path))
    # 创建标签属性字符串，将每个标签名称与其索引作为 _int 类型关联
    tag_attributes = "\n".join(
        f"{name}: _int = {index}" for index, name in enumerate(tag_names)
    )

    # 写出存根文件
    # ~~~~~~~~~~~~~~~~~~

    # 定义用于填充存根文件的环境变量字典
    env = {
        "structseq_defs": structseq_defs,
        "function_hints": function_hints,
        "tensor_method_hints": tensor_method_hints,
        "legacy_class_hints": legacy_class_hints,
        "legacy_storage_base_hints": legacy_storage_base_hints,
        "dtype_class_hints": dtype_class_hints,
        "dispatch_key_hints": dispatch_key_hints,
        "torch_dispatch_mode_key_hints": torch_dispatch_mode_key_hints,
        "all_directive": all_directive,
        "tag_attributes": tag_attributes,
    }
    # 使用模板和环境变量字典写入存根文件
    fm.write_with_template(
        "torch/_C/__init__.pyi",
        "torch/_C/__init__.pyi.in",
        lambda: {
            "generated_comment": "@" + "generated from torch/_C/__init__.pyi.in",
            **env,
        },
    )
    fm.write_with_template(
        "torch/_C/_VariableFunctions.pyi",  # 使用模板写入文件 torch/_C/_VariableFunctions.pyi
        "torch/_C/_VariableFunctions.pyi.in",  # 读取模板文件 torch/_C/_VariableFunctions.pyi.in
        lambda: {
            "generated_comment": "@"
            + "generated from torch/_C/_VariableFunctions.pyi.in",  # 添加生成注释
            **env,  # 使用环境变量
        },
    )
    fm.write_with_template(
        "torch/_VF.pyi",  # 使用模板写入文件 torch/_VF.pyi
        "torch/_C/_VariableFunctions.pyi.in",  # 读取模板文件 torch/_C/_VariableFunctions.pyi.in
        lambda: {
            "generated_comment": "@"
            + "generated from torch/_C/_VariableFunctions.pyi.in",  # 添加生成注释
            **env,  # 使用环境变量
        },
    )
    fm.write_with_template(
        "torch/return_types.pyi",  # 使用模板写入文件 torch/return_types.pyi
        "torch/_C/return_types.pyi.in",  # 读取模板文件 torch/_C/return_types.pyi.in
        lambda: {
            "generated_comment": "@"
            + "generated from torch/_C/return_types.pyi",  # 添加生成注释
            **env,  # 使用环境变量
        },
    )
    gen_nn_functional(fm)  # 生成神经网络函数
# 定义主函数，程序的入口点
def main() -> None:
    # 创建参数解析器对象，并设置描述信息
    parser = argparse.ArgumentParser(description="Generate type stubs for PyTorch")
    
    # 添加命令行参数：native-functions-path，用于指定 native_functions.yaml 文件路径
    parser.add_argument(
        "--native-functions-path",
        metavar="NATIVE",
        default="aten/src/ATen/native/native_functions.yaml",
        help="path to native_functions.yaml",
    )
    
    # 添加命令行参数：tags-path，用于指定 tags.yaml 文件路径
    parser.add_argument(
        "--tags-path",
        metavar="TAGS",
        default="aten/src/ATen/native/tags.yaml",
        help="path to tags.yaml",
    )
    
    # 添加命令行参数：deprecated-functions-path，用于指定 deprecated.yaml 文件路径
    parser.add_argument(
        "--deprecated-functions-path",
        metavar="DEPRECATED",
        default="tools/autograd/deprecated.yaml",
        help="path to deprecated.yaml",
    )
    
    # 添加命令行参数：out，用于指定输出目录路径，默认为当前目录
    parser.add_argument(
        "--out", metavar="OUT", default=".", help="path to output directory"
    )
    
    # 解析命令行参数，并将其存储在 args 对象中
    args = parser.parse_args()
    
    # 创建 FileManager 对象 fm，用于文件管理，指定安装目录和模板目录
    fm = FileManager(install_dir=args.out, template_dir=".", dry_run=False)
    
    # 调用 gen_pyi 函数，生成 Python 类型注解文件
    gen_pyi(
        args.native_functions_path, args.tags_path, args.deprecated_functions_path, fm
    )


# 如果当前脚本作为主程序运行，则调用 main 函数
if __name__ == "__main__":
    main()
```