# `.\pytorch\.github\scripts\file_io_utils.py`

```
import json  # 导入处理 JSON 格式数据的模块
import re  # 导入正则表达式模块，用于文本操作
import shutil  # 导入文件操作模块，用于文件和目录的高级操作
from pathlib import Path  # 导入 Path 类，用于跨平台处理文件路径
from typing import Any, List  # 导入类型提示模块，用于类型注解

import boto3  # type: ignore[import]  # 导入 AWS SDK，用于与 Amazon S3 服务交互


def zip_folder(folder_to_zip: Path, dest_file_base_name: Path) -> Path:
    """
    Returns the path to the resulting zip file, with the appropriate extension added if needed
    """
    # 如果目标文件名已经以 .zip 结尾，则去掉后缀，因为 shutil.make_archive 会自动添加 .zip 后缀
    if dest_file_base_name.suffix == ".zip":
        dest_file_base_name = dest_file_base_name.with_suffix("")

    # 确保目标文件所在目录存在，如果不存在则创建
    ensure_dir_exists(dest_file_base_name.parent)

    # 打印正在压缩的文件夹路径和目标文件名
    print(f"Zipping {folder_to_zip}\n     to {dest_file_base_name}")

    # 将文件夹压缩成 zip 文件，返回生成的 zip 文件路径
    return Path(shutil.make_archive(str(dest_file_base_name), "zip", folder_to_zip))


def unzip_folder(zip_file_path: Path, unzip_to_folder: Path) -> None:
    """
    Returns the path to the unzipped folder
    """
    # 打印正在解压的 zip 文件路径和解压目标文件夹路径
    print(f"Unzipping {zip_file_path}")
    print(f"       to {unzip_to_folder}")

    # 解压 zip 文件到指定的目标文件夹
    shutil.unpack_archive(zip_file_path, unzip_to_folder, "zip")


def ensure_dir_exists(dir: Path) -> None:
    """
    Ensures that the directory exists, creating it if necessary
    """
    # 创建目录，如果父目录不存在也会创建
    dir.mkdir(parents=True, exist_ok=True)


def copy_file(source_file: Path, dest_file: Path) -> None:
    """
    Copies a file from source to destination
    """
    # 确保目标文件所在目录存在，如果不存在则创建
    ensure_dir_exists(dest_file.parent)

    # 复制文件
    shutil.copyfile(source_file, dest_file)


def load_json_file(file_path: Path) -> Any:
    """
    Returns the deserialized json object from the file
    """
    # 从文件中读取 JSON 数据并反序列化为 Python 对象
    with open(file_path) as f:
        return json.load(f)


def write_json_file(file_path: Path, content: Any) -> None:
    """
    Writes the content as JSON to the specified file path
    """
    # 确保文件所在目录存在，如果不存在则创建
    dir = file_path.parent
    ensure_dir_exists(dir)

    # 将内容序列化为 JSON 格式并写入文件
    with open(file_path, "w") as f:
        json.dump(content, f, indent=2)


def sanitize_for_s3(text: str) -> str:
    """
    Replaces characters not allowed in S3 keys with underscores
    """
    # 将 S3 对象键中不允许的字符替换为下划线
    return re.sub(r"[^a-zA-Z0-9_-]", "_", text)


def upload_file_to_s3(file_name: Path, bucket: str, key: str) -> None:
    """
    Uploads a file to Amazon S3 bucket with the specified key
    """
    # 打印正在上传的文件名和目标 S3 存储桶以及对象键
    print(f"Uploading {file_name}")
    print(f"       to s3://{bucket}/{key}")

    # 使用 boto3 客户端上传文件到 S3
    boto3.client("s3").upload_file(
        str(file_name),
        bucket,
        key,
    )


def download_s3_objects_with_prefix(
    bucket_name: str, prefix: str, download_folder: Path
) -> List[Path]:
    """
    Downloads objects from Amazon S3 bucket with the specified prefix to the local folder
    """
    # 创建 S3 资源
    s3 = boto3.resource("s3")
    bucket = s3.Bucket(bucket_name)

    downloads = []

    # 遍历 S3 存储桶中指定前缀的对象
    for obj in bucket.objects.filter(Prefix=prefix):
        # 下载到本地的文件路径
        download_path = download_folder / obj.key

        # 确保下载目录存在，如果不存在则创建
        ensure_dir_exists(download_path.parent)

        # 打印正在下载的 S3 对象路径和本地文件路径
        print(f"Downloading s3://{bucket.name}/{obj.key}")
        print(f"         to {download_path}")

        # 下载 S3 对象到本地
        s3.Object(bucket.name, obj.key).download_file(str(download_path))
        downloads.append(download_path)

    # 如果没有匹配指定前缀的文件，则打印提示信息
    if len(downloads) == 0:
        print(
            f"There were no files matching the prefix `{prefix}` in bucket `{bucket.name}`"
        )

    return downloads
```