# `.\pytorch\torch\csrc\inductor\aoti_torch\generated\c_shim_cuda.h`

```
// WARNING: THIS FILE IS AUTOGENERATED BY torchgen. DO NOT MODIFY BY HAND.
// See https://github.com/pytorch/pytorch/blob/7e86a7c0155295539996e0cf422883571126073e/torchgen/gen.py#L2424-L2436 for details

#pragma once

#include <torch/csrc/inductor/aoti_torch/c/shim.h>

#ifdef __cplusplus
extern "C" {
#endif

// 定义导出函数 aoti_torch_cuda__adaptive_avg_pool2d，接受输入张量 self 和输出尺寸数组 output_size
// 返回 AOTITorchError 错误码，并存储结果在 ret0 中
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__adaptive_avg_pool2d(AtenTensorHandle self, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0);

// 定义反向传播函数 aoti_torch_cuda__adaptive_avg_pool2d_backward，接受梯度张量 grad_output 和输入张量 self
// 返回 AOTITorchError 错误码，并存储结果在 ret0 中
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__adaptive_avg_pool2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle* ret0);

// 定义函数 aoti_torch_cuda__adaptive_avg_pool3d，接受输入张量 self 和输出尺寸数组 output_size
// 返回 AOTITorchError 错误码，并存储结果在 ret0 中
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__adaptive_avg_pool3d(AtenTensorHandle self, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0);

// 定义反向传播函数 aoti_torch_cuda__adaptive_avg_pool3d_backward，接受梯度张量 grad_output 和输入张量 self
// 返回 AOTITorchError 错误码，并存储结果在 ret0 中
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__adaptive_avg_pool3d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle* ret0);

// 定义函数 aoti_torch_cuda__addmm_activation，接受输入张量 self、mat1、mat2 和相关参数
// 返回 AOTITorchError 错误码，并存储结果在 ret0 中
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__addmm_activation(AtenTensorHandle self, AtenTensorHandle mat1, AtenTensorHandle mat2, double beta, double alpha, int32_t use_gelu, AtenTensorHandle* ret0);

// 定义函数 aoti_torch_cuda__cdist_backward，接受梯度张量 grad、输入张量 x1、x2、距离度量参数 p 和输出张量 cdist
// 返回 AOTITorchError 错误码，并存储结果在 ret0 中
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__cdist_backward(AtenTensorHandle grad, AtenTensorHandle x1, AtenTensorHandle x2, double p, AtenTensorHandle cdist, AtenTensorHandle* ret0);

// 定义函数 aoti_torch_cuda__cdist_forward，接受输入张量 x1、x2、距离度量参数 p 和计算模式数组 compute_mode
// 返回 AOTITorchError 错误码，并存储结果在 ret0 中
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__cdist_forward(AtenTensorHandle x1, AtenTensorHandle x2, double p, int64_t* compute_mode, AtenTensorHandle* ret0);

// 定义函数 aoti_torch_cuda__cudnn_rnn，接受输入张量 input、权重数组 weight、隐藏状态 hx、单元状态 cx 等参数
// 返回 AOTITorchError 错误码，并存储多个结果在 ret0, ret1, ret2, ret3, ret4 中
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__cudnn_rnn(AtenTensorHandle input, const AtenTensorHandle* weight, int64_t weight_len_, int64_t weight_stride0, AtenTensorHandle* weight_buf, AtenTensorHandle hx, AtenTensorHandle* cx, int64_t mode, int64_t hidden_size, int64_t proj_size, int64_t num_layers, int32_t batch_first, double dropout, int32_t train, int32_t bidirectional, const int64_t* batch_sizes, int64_t batch_sizes_len_, AtenTensorHandle* dropout_state, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3, AtenTensorHandle* ret4);

// 定义函数 aoti_torch_cuda__efficient_attention_backward，接受梯度张量 grad_out_、query、key、value 等多个参数
// 返回 AOTITorchError 错误码，并存储多个结果在 ret0, ret1, ret2, ret3 中
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__efficient_attention_backward(AtenTensorHandle grad_out_, AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, AtenTensorHandle* bias, AtenTensorHandle out, AtenTensorHandle* cu_seqlens_q, AtenTensorHandle* cu_seqlens_k, int64_t max_seqlen_q, int64_t max_seqlen_k, AtenTensorHandle logsumexp, double dropout_p, AtenTensorHandle philox_seed, AtenTensorHandle philox_offset, int64_t custom_mask_type, int32_t bias_requires_grad, double* scale, int64_t* num_splits_key, int64_t* window_size, int32_t shared_storage_dqdkdv, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3);

#ifdef __cplusplus
}
#endif
// 定义了一个 AOTI_TORCH_EXPORT 的函数 aoti_torch_cuda__efficient_attention_forward，用于执行 CUDA 下的 efficient attention forward 操作
// 函数参数包括 query, key, value 张量，可能的偏置 bias，以及与序列长度相关的参数和计算配置
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__efficient_attention_forward(AtenTensorHandle query, AtenTensorHandle key, AtenTensorHandle value, AtenTensorHandle* bias, AtenTensorHandle* cu_seqlens_q, AtenTensorHandle* cu_seqlens_k, int64_t* max_seqlen_q, int64_t* max_seqlen_k, double dropout_p, int64_t custom_mask_type, int32_t compute_log_sumexp, double* scale, AtenTensorHandle* seqlen_k, int64_t* window_size, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3, int64_t* ret4, int64_t* ret5);

// 定义了一个 AOTI_TORCH_EXPORT 的函数 aoti_torch_cuda__efficientzerotensor，用于生成 CUDA 下的零张量
// 函数参数包括张量大小 size，数据类型 dtype，存储布局 layout，设备信息 device，以及其他相关配置
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__efficientzerotensor(const int64_t* size, int64_t size_len_, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0);

// 定义了一个 AOTI_TORCH_EXPORT 的函数 aoti_torch_cuda__embedding_bag，用于执行 CUDA 下的 embedding bag 操作
// 函数参数包括权重 weight，索引 indices，偏移 offsets，梯度缩放 scale_grad_by_freq，以及其他相关配置
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__embedding_bag(AtenTensorHandle weight, AtenTensorHandle indices, AtenTensorHandle offsets, int32_t scale_grad_by_freq, int64_t mode, int32_t sparse, AtenTensorHandle* per_sample_weights, int32_t include_last_offset, int64_t padding_idx, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3);

// 定义了一个 AOTI_TORCH_EXPORT 的函数 aoti_torch_cuda__embedding_bag_dense_backward，用于执行 CUDA 下的 embedding bag 密集反向传播
// 函数参数包括梯度 grad，索引 indices，offset2bag，bag_size，以及其他相关配置
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__embedding_bag_dense_backward(AtenTensorHandle grad, AtenTensorHandle indices, AtenTensorHandle offset2bag, AtenTensorHandle bag_size, AtenTensorHandle maximum_indices, int64_t num_weights, int32_t scale_grad_by_freq, int64_t mode, AtenTensorHandle* per_sample_weights, int64_t padding_idx, AtenTensorHandle* ret0);

// 定义了一个 AOTI_TORCH_EXPORT 的函数 aoti_torch_cuda__embedding_bag_forward_only，用于执行 CUDA 下的 embedding bag 仅前向传播
// 函数参数与 aoti_torch_cuda__embedding_bag 相似，不同之处在于没有梯度相关的参数
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__embedding_bag_forward_only(AtenTensorHandle weight, AtenTensorHandle indices, AtenTensorHandle offsets, int32_t scale_grad_by_freq, int64_t mode, int32_t sparse, AtenTensorHandle* per_sample_weights, int32_t include_last_offset, int64_t padding_idx, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2, AtenTensorHandle* ret3);

// 定义了一个 AOTI_TORCH_EXPORT 的函数 aoti_torch_cuda__embedding_bag_per_sample_weights_backward，用于执行 CUDA 下的 embedding bag 根据样本权重的反向传播
// 函数参数包括梯度 grad，权重 weight，索引 indices，偏移 offsets，offset2bag，以及其他相关配置
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__embedding_bag_per_sample_weights_backward(AtenTensorHandle grad, AtenTensorHandle weight, AtenTensorHandle indices, AtenTensorHandle offsets, AtenTensorHandle offset2bag, int64_t mode, int64_t padding_idx, AtenTensorHandle* ret0);

// 定义了一个 AOTI_TORCH_EXPORT 的函数 aoti_torch_cuda__fft_c2c，用于执行 CUDA 下的复数到复数的快速傅里叶变换
// 函数参数包括张量 self，维度 dim，归一化 normalization，前向或反向标志 forward
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__fft_c2c(AtenTensorHandle self, const int64_t* dim, int64_t dim_len_, int64_t normalization, int32_t forward, AtenTensorHandle* ret0);

// 定义了一个 AOTI_TORCH_EXPORT 的函数 aoti_torch_cuda__fft_r2c，用于执行 CUDA 下的实数到复数的快速傅里叶变换
// 函数参数与 aoti_torch_cuda__fft_c2c 类似，增加了是否单边 onesided 参数
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__fft_r2c(AtenTensorHandle self, const int64_t* dim, int64_t dim_len_, int64_t normalization, int32_t onesided, AtenTensorHandle* ret0);
# 定义了一个导出函数，用于计算 Flash Attention 的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__flash_attention_backward(
    AtenTensorHandle grad_out,        // 梯度输出张量
    AtenTensorHandle query,           // 查询张量
    AtenTensorHandle key,             // 键张量
    AtenTensorHandle value,           // 值张量
    AtenTensorHandle out,             // 输出张量
    AtenTensorHandle logsumexp,       // 对数总和指数张量
    AtenTensorHandle cum_seq_q,       // 查询序列累积张量
    AtenTensorHandle cum_seq_k,       // 键序列累积张量
    int64_t max_q,                    // 最大查询长度
    int64_t max_k,                    // 最大键长度
    double dropout_p,                 // 丢弃概率
    int32_t is_causal,                // 是否因果
    AtenTensorHandle philox_seed,     // 随机数生成种子张量
    AtenTensorHandle philox_offset,   // 随机数生成偏移张量
    double* scale,                    // 缩放因子指针
    int64_t* window_size_left,        // 左窗口大小指针
    int64_t* window_size_right,       // 右窗口大小指针
    AtenTensorHandle* ret0,           // 返回值0的指针
    AtenTensorHandle* ret1,           // 返回值1的指针
    AtenTensorHandle* ret2            // 返回值2的指针
);

# 定义了一个导出函数，用于计算 Flash Attention 的前向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__flash_attention_forward(
    AtenTensorHandle query,           // 查询张量
    AtenTensorHandle key,             // 键张量
    AtenTensorHandle value,           // 值张量
    AtenTensorHandle* cum_seq_q,      // 查询序列累积张量的指针
    AtenTensorHandle* cum_seq_k,      // 键序列累积张量的指针
    int64_t max_q,                    // 最大查询长度
    int64_t max_k,                    // 最大键长度
    double dropout_p,                 // 丢弃概率
    int32_t is_causal,                // 是否因果
    int32_t return_debug_mask,        // 是否返回调试掩码
    double* scale,                    // 缩放因子指针
    int64_t* window_size_left,        // 左窗口大小指针
    int64_t* window_size_right,       // 右窗口大小指针
    AtenTensorHandle* seqused_k,      // 序列使用的键张量的指针
    AtenTensorHandle* alibi_slopes,   // 被解释的斜率张量的指针
    AtenTensorHandle* ret0,           // 返回值0的指针
    AtenTensorHandle* ret1,           // 返回值1的指针
    AtenTensorHandle* ret2,           // 返回值2的指针
    AtenTensorHandle* ret3,           // 返回值3的指针
    AtenTensorHandle* ret4            // 返回值4的指针
);

# 定义了一个导出函数，用于帮助实现融合移动平均和观察偏量的功能
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__fused_moving_avg_obs_fq_helper(
    AtenTensorHandle self,            // 自身张量
    AtenTensorHandle observer_on,     // 观察器开启张量
    AtenTensorHandle fake_quant_on,   // 伪量化开启张量
    AtenTensorHandle running_min,     // 运行时最小值张量
    AtenTensorHandle running_max,     // 运行时最大值张量
    AtenTensorHandle scale,           // 缩放张量
    AtenTensorHandle zero_point,      // 零点张量
    double averaging_const,           // 平均常数
    int64_t quant_min,                // 量化最小值
    int64_t quant_max,                // 量化最大值
    int64_t ch_axis,                  // 通道轴
    int32_t per_row_fake_quant,       // 每行伪量化
    int32_t symmetric_quant,          // 对称量化
    AtenTensorHandle* ret0,           // 返回值0的指针
    AtenTensorHandle* ret1            // 返回值1的指针
);

# 定义了一个导出函数，用于帮助实现函数式融合移动平均和观察偏量的功能
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__fused_moving_avg_obs_fq_helper_functional(
    AtenTensorHandle self,            // 自身张量
    AtenTensorHandle observer_on,     // 观察器开启张量
    AtenTensorHandle fake_quant_on,   // 伪量化开启张量
    AtenTensorHandle running_min,     // 运行时最小值张量
    AtenTensorHandle running_max,     // 运行时最大值张量
    AtenTensorHandle scale,           // 缩放张量
    AtenTensorHandle zero_point,      // 零点张量
    double averaging_const,           // 平均常数
    int64_t quant_min,                // 量化最小值
    int64_t quant_max,                // 量化最大值
    int64_t ch_axis,                  // 通道轴
    int32_t per_row_fake_quant,       // 每行伪量化
    int32_t symmetric_quant,          // 对称量化
    AtenTensorHandle* ret0,           // 返回值0的指针
    AtenTensorHandle* ret1,           // 返回值1的指针
    AtenTensorHandle* ret2,           // 返回值2的指针
    AtenTensorHandle* ret3,           // 返回值3的指针
    AtenTensorHandle* ret4,           // 返回值4的指针
    AtenTensorHandle* ret5            // 返回值5的指针
);

# 定义了一个导出函数，用于计算 PDist 的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__pdist_backward(
    AtenTensorHandle grad,            // 梯度张量
    AtenTensorHandle self,            // 自身张量
    double p,                         // 范数值
    AtenTensorHandle pdist,           // PDist 张量
    AtenTensorHandle* ret0            // 返回值0的指针
);

# 定义了一个导出函数，用于计算 PDist 的前向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__pdist_forward(
    AtenTensorHandle self,            // 自身张量
    double p,                         // 范数值
    AtenTensorHandle* ret0            // 返回值0的指针
);

# 定义了一个导出函数，用于高效计算缩放点积注意力
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__scaled_dot_product_efficient_attention(
    AtenTensorHandle query,           // 查询张量
    AtenTensorHandle key,             // 键张量
    AtenTensorHandle value,           // 值张量
    AtenTensorHandle* attn_bias,      // 注意力偏置张量的指针
    int32_t compute_log_sumexp,       // 是否计算对数总和指数
    double dropout_p,                 // 丢弃概率
    int32_t is_causal,                // 是否因果
    double* scale,                    // 缩放因子指针
    AtenTensorHandle* ret0,           // 返回值0的指针
    AtenTensorHandle* ret1,           // 返回值1的指针
    AtenTensorHandle* ret2,           // 返回值2的指针
    AtenTensorHandle* ret3            // 返回值3的指针
);
// 定义了 AOTI Torch 库中的 CUDA 函数，实现了效率高的注意力机制反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__scaled_dot_product_efficient_attention_backward(
    AtenTensorHandle grad_out_,        // 梯度输出的张量句柄
    AtenTensorHandle query,            // 查询张量句柄
    AtenTensorHandle key,              // 键张量句柄
    AtenTensorHandle value,            // 值张量句柄
    AtenTensorHandle attn_bias,        // 注意力偏置张量句柄
    AtenTensorHandle out,              // 输出张量句柄
    AtenTensorHandle logsumexp,        // 对数求和张量句柄
    AtenTensorHandle philox_seed,      // Philox 随机数生成种子张量句柄
    AtenTensorHandle philox_offset,    // Philox 随机数生成偏移张量句柄
    double dropout_p,                  // dropout 概率
    const int32_t* grad_input_mask,    // 梯度输入掩码数组
    int64_t grad_input_mask_len_,      // 梯度输入掩码长度
    int32_t is_causal,                 // 是否因果
    double* scale,                     // 缩放因子指针
    AtenTensorHandle* ret0,            // 返回的张量句柄指针
    AtenTensorHandle* ret1,            // 返回的张量句柄指针
    AtenTensorHandle* ret2,            // 返回的张量句柄指针
    AtenTensorHandle* ret3             // 返回的张量句柄指针
);

// 定义了 AOTI Torch 库中的 CUDA 函数，实现了闪光注意力机制
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__scaled_dot_product_flash_attention(
    AtenTensorHandle query,            // 查询张量句柄
    AtenTensorHandle key,              // 键张量句柄
    AtenTensorHandle value,            // 值张量句柄
    double dropout_p,                  // dropout 概率
    int32_t is_causal,                 // 是否因果
    int32_t return_debug_mask,         // 是否返回调试掩码
    double* scale,                     // 缩放因子指针
    AtenTensorHandle* ret0,            // 返回的张量句柄指针
    AtenTensorHandle* ret1,            // 返回的张量句柄指针
    AtenTensorHandle* ret2,            // 返回的张量句柄指针
    AtenTensorHandle* ret3,            // 返回的张量句柄指针
    int64_t* ret4,                     // 返回的整数指针
    int64_t* ret5,                     // 返回的整数指针
    AtenTensorHandle* ret6,            // 返回的张量句柄指针
    AtenTensorHandle* ret7,            // 返回的张量句柄指针
    AtenTensorHandle* ret8             // 返回的张量句柄指针
);

// 定义了 AOTI Torch 库中的 CUDA 函数，实现了闪光注意力机制的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__scaled_dot_product_flash_attention_backward(
    AtenTensorHandle grad_out,         // 梯度输出张量句柄
    AtenTensorHandle query,            // 查询张量句柄
    AtenTensorHandle key,              // 键张量句柄
    AtenTensorHandle value,            // 值张量句柄
    AtenTensorHandle out,              // 输出张量句柄
    AtenTensorHandle logsumexp,        // 对数求和张量句柄
    AtenTensorHandle cum_seq_q,        // 累计序列查询张量句柄
    AtenTensorHandle cum_seq_k,        // 累计序列键张量句柄
    int64_t max_q,                     // 最大查询长度
    int64_t max_k,                     // 最大键长度
    double dropout_p,                  // dropout 概率
    int32_t is_causal,                 // 是否因果
    AtenTensorHandle philox_seed,      // Philox 随机数生成种子张量句柄
    AtenTensorHandle philox_offset,    // Philox 随机数生成偏移张量句柄
    double* scale,                     // 缩放因子指针
    AtenTensorHandle* ret0,            // 返回的张量句柄指针
    AtenTensorHandle* ret1,            // 返回的张量句柄指针
    AtenTensorHandle* ret2             // 返回的张量句柄指针
);

// 定义了 AOTI Torch 库中的 CUDA 函数，实现了张量的缩放矩阵乘法
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__scaled_mm(
    AtenTensorHandle self,             // 张量句柄
    AtenTensorHandle mat2,             // 第二个矩阵张量句柄
    AtenTensorHandle scale_a,          // 缩放因子 A 张量句柄
    AtenTensorHandle scale_b,          // 缩放因子 B 张量句柄
    AtenTensorHandle* bias,            // 偏置张量句柄指针
    AtenTensorHandle* scale_result,    // 缩放结果张量句柄指针
    int32_t* out_dtype,                // 输出数据类型指针
    int32_t use_fast_accum,            // 是否使用快速累积
    AtenTensorHandle* ret0             // 返回的张量句柄指针
);

// 定义了 AOTI Torch 库中的 CUDA 函数，实现了分段归约的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__segment_reduce_backward(
    AtenTensorHandle grad,             // 梯度张量句柄
    AtenTensorHandle output,           // 输出张量句柄
    AtenTensorHandle data,             // 数据张量句柄
    const char* reduce,                // 归约操作字符串
    AtenTensorHandle* lengths,         // 长度张量句柄指针
    AtenTensorHandle* offsets,         // 偏移张量句柄指针
    int64_t axis,                      // 轴
    double* initial,                   // 初始值指针
    AtenTensorHandle* ret0             // 返回的张量句柄指针
);

// 定义了 AOTI Torch 库中的 CUDA 函数，实现了融合 LSTM 单元的计算
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__thnn_fused_lstm_cell(
    AtenTensorHandle input_gates,      // 输入门张量句柄
    AtenTensorHandle hidden_gates,     // 隐藏门张量句柄
    AtenTensorHandle cx,               // 细胞状态张量句柄
    AtenTensorHandle* input_bias,      // 输入偏置张量句柄指针
    AtenTensorHandle* hidden_bias,     // 隐藏偏置张量句柄指针
    AtenTensorHandle* ret0,            // 返回的张量句柄指针
    AtenTensorHandle* ret1,            // 返回的张量句柄指针
    AtenTensorHandle* ret2             // 返回的张量句柄指针
);

// 定义了 AOTI Torch 库中的 CUDA 函数，实现了将稠密张量转换为稀疏张量
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda__to_sparse(
    AtenTensorHandle self,             // 自身张量句柄
    int32_t* layout,                   // 布局指针
    const int64_t** blocksize,         // 块大小指针的指针
# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行二维自适应最大池化操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_adaptive_max_pool2d(AtenTensorHandle self, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行二维自适应最大池化反向传播操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_adaptive_max_pool2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle indices, AtenTensorHandle* ret0);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行三维自适应最大池化操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_adaptive_max_pool3d(AtenTensorHandle self, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行三维自适应最大池化反向传播操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_adaptive_max_pool3d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle indices, AtenTensorHandle* ret0);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行批量矩阵乘法加法操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_addbmm(AtenTensorHandle self, AtenTensorHandle batch1, AtenTensorHandle batch2, double beta, double alpha, AtenTensorHandle* ret0);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行矩阵乘法加法操作，结果写入指定输出张量
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_addmm_out(AtenTensorHandle out, AtenTensorHandle self, AtenTensorHandle mat1, AtenTensorHandle mat2, double beta, double alpha);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行矩阵向量加法操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_addmv(AtenTensorHandle self, AtenTensorHandle mat, AtenTensorHandle vec, double beta, double alpha, AtenTensorHandle* ret0);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，计算张量的角度
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_angle(AtenTensorHandle self, AtenTensorHandle* ret0);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行二维平均池化操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_avg_pool2d(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, int32_t ceil_mode, int32_t count_include_pad, int64_t* divisor_override, AtenTensorHandle* ret0);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行二维平均池化反向传播操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_avg_pool2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, int32_t ceil_mode, int32_t count_include_pad, int64_t* divisor_override, AtenTensorHandle* ret0);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行三维平均池化操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_avg_pool3d(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, int32_t ceil_mode, int32_t count_include_pad, int64_t* divisor_override, AtenTensorHandle* ret0);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，执行三维平均池化反向传播操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_avg_pool3d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, int32_t ceil_mode, int32_t count_include_pad, int64_t* divisor_override, AtenTensorHandle* ret0);

# 定义了 AOTI_TORCH_EXPORT 宏的 CUDA 函数，生成一个按照伯努利分布填充的张量
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_bernoulli__Tensor(AtenTensorHandle self, AtenTensorHandle p, AtenGeneratorHandle* generator);
# 定义一个导出到 Torch 的 CUDA 函数，计算 Bernoulli 分布下的随机变量，返回错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_bernoulli__float(AtenTensorHandle self, double p, AtenGeneratorHandle* generator);

# 定义一个导出到 Torch 的 CUDA 函数，计算两个张量的批矩阵乘积，输出到指定的张量
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_bmm_out(AtenTensorHandle out, AtenTensorHandle self, AtenTensorHandle mat2);

# 定义一个导出到 Torch 的 CUDA 函数，根据给定的边界将张量进行分桶操作，返回错误码和处理后的张量
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_bucketize_Tensor(AtenTensorHandle self, AtenTensorHandle boundaries, int32_t out_int32, int32_t right, AtenTensorHandle* ret0);

# 定义一个导出到 Torch 的 CUDA 函数，将多个张量沿指定维度拼接，返回拼接后的张量
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_cat(const AtenTensorHandle* tensors, int64_t tensors_len_, int64_t dim, AtenTensorHandle* ret0);

# 定义一个导出到 Torch 的 CUDA 函数，计算给定张量的 Cholesky 分解的逆矩阵，返回处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_cholesky_inverse(AtenTensorHandle self, int32_t upper, AtenTensorHandle* ret0);

# 定义一个导出到 Torch 的 CUDA 函数，解 Cholesky 系统方程组，返回处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_cholesky_solve(AtenTensorHandle self, AtenTensorHandle input2, int32_t upper, AtenTensorHandle* ret0);

# 定义一个导出到 Torch 的 CUDA 函数，进行卷积操作，返回处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_convolution(AtenTensorHandle input, AtenTensorHandle weight, AtenTensorHandle* bias, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t transposed, const int64_t* output_padding, int64_t output_padding_len_, int64_t groups, AtenTensorHandle* ret0);

# 定义一个导出到 Torch 的 CUDA 函数，卷积的反向传播，返回多个处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_convolution_backward(AtenTensorHandle grad_output, AtenTensorHandle input, AtenTensorHandle weight, const int64_t** bias_sizes, int64_t bias_sizes_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t transposed, const int64_t* output_padding, int64_t output_padding_len_, int64_t groups, const int32_t* output_mask, int64_t output_mask_len_, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2);

# 定义一个导出到 Torch 的 CUDA 函数，计算给定张量在指定维度上的累积最大值，返回处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_cummax(AtenTensorHandle self, int64_t dim, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

# 定义一个导出到 Torch 的 CUDA 函数，计算给定张量在指定维度上的累积最小值，返回处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_cummin(AtenTensorHandle self, int64_t dim, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

# 定义一个导出到 Torch 的 CUDA 函数，计算给定张量在指定维度上的累积乘积，返回处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_cumprod(AtenTensorHandle self, int64_t dim, int32_t* dtype, AtenTensorHandle* ret0);

# 定义一个导出到 Torch 的 CUDA 函数，计算给定张量在指定维度上的累积和，返回处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_cumsum(AtenTensorHandle self, int64_t dim, int32_t* dtype, AtenTensorHandle* ret0);

# 定义一个导出到 Torch 的 CUDA 函数，计算给定张量的指数分布，返回处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_exponential(AtenTensorHandle self, double lambd, AtenGeneratorHandle* generator, AtenTensorHandle* ret0);

# 定义一个导出到 Torch 的 CUDA 函数，进行二维分数最大池化操作，返回处理后的张量和错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_fractional_max_pool2d(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle random_samples, AtenTensorHandle* ret0, AtenTensorHandle* ret1);
// 导出的函数，用于在 CUDA 上执行二维分数最大池化的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_fractional_max_pool2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle indices, AtenTensorHandle* ret0);

// 导出的函数，用于在 CUDA 上执行三维分数最大池化
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_fractional_max_pool3d(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle random_samples, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

// 导出的函数，用于在 CUDA 上执行三维分数最大池化的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_fractional_max_pool3d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle indices, AtenTensorHandle* ret0);

// 导出的函数，用于在 CUDA 上执行张量的最大公约数计算
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_gcd(AtenTensorHandle self, AtenTensorHandle other, AtenTensorHandle* ret0);

// 导出的函数，用于在 CUDA 上执行张量的 QR 分解
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_geqrf(AtenTensorHandle self, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

// 导出的函数，用于在 CUDA 上执行二维网格采样器的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_grid_sampler_2d_backward(AtenTensorHandle grad_output, AtenTensorHandle input, AtenTensorHandle grid, int64_t interpolation_mode, int64_t padding_mode, int32_t align_corners, const int32_t* output_mask, int64_t output_mask_len_, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

// 导出的函数，用于在 CUDA 上执行张量的直方图计数
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_histc(AtenTensorHandle self, int64_t bins, double min, double max, AtenTensorHandle* ret0);

// 导出的函数，用于在 CUDA 上执行张量的索引操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_index_Tensor(AtenTensorHandle self, const AtenTensorHandle** indices, int64_t indices_len_, AtenTensorHandle* ret0);

// 导出的函数，用于在 CUDA 上执行张量的索引赋值操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_index_put(AtenTensorHandle self, const AtenTensorHandle** indices, int64_t indices_len_, AtenTensorHandle values, int32_t accumulate, AtenTensorHandle* ret0);

// 导出的函数，用于在 CUDA 上执行张量的索引约减操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_index_reduce(AtenTensorHandle self, int64_t dim, AtenTensorHandle index, AtenTensorHandle source, const char* reduce, int32_t include_self, AtenTensorHandle* ret0);

// 导出的函数，用于在 CUDA 上执行张量的第 k 小值和索引计算
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_kthvalue(AtenTensorHandle self, int64_t k, int64_t dim, int32_t keepdim, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

// 导出的函数，用于在 CUDA 上执行张量的对数累积和计算
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_logcumsumexp(AtenTensorHandle self, int64_t dim, AtenTensorHandle* ret0);

// 导出的函数，用于在 CUDA 上执行 LU 分解的解包操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_lu_unpack(AtenTensorHandle LU_data, AtenTensorHandle LU_pivots, int32_t unpack_data, int32_t unpack_pivots, AtenTensorHandle* ret0, AtenTensorHandle* ret1, AtenTensorHandle* ret2);

// 导出的函数，用于在 CUDA 上执行张量的掩码散布操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_masked_scatter(AtenTensorHandle self, AtenTensorHandle mask, AtenTensorHandle source, AtenTensorHandle* ret0);
# 定义了一系列使用 CUDA 加速的 Torch 操作函数，这些函数都是导出的 API 接口

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_masked_scatter_backward(AtenTensorHandle grad_output, AtenTensorHandle mask, const int64_t* sizes, int64_t sizes_len_, AtenTensorHandle* ret0);
# 定义了一个 CUDA 加速的 Torch 反向传播函数，用于处理带掩码的散射操作的梯度计算

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_max_pool2d_with_indices(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t ceil_mode, AtenTensorHandle* ret0, AtenTensorHandle* ret1);
# 定义了一个 CUDA 加速的 Torch 2D 最大池化函数，同时返回池化结果和索引

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_max_pool2d_with_indices_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t ceil_mode, AtenTensorHandle indices, AtenTensorHandle* ret0);
# 定义了一个 CUDA 加速的 Torch 2D 最大池化反向传播函数，用于计算最大池化操作的梯度

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_max_pool3d_with_indices(AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t ceil_mode, AtenTensorHandle* ret0, AtenTensorHandle* ret1);
# 定义了一个 CUDA 加速的 Torch 3D 最大池化函数，同时返回池化结果和索引

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_max_pool3d_with_indices_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* kernel_size, int64_t kernel_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, const int64_t* dilation, int64_t dilation_len_, int32_t ceil_mode, AtenTensorHandle indices, AtenTensorHandle* ret0);
# 定义了一个 CUDA 加速的 Torch 3D 最大池化反向传播函数，用于计算最大池化操作的梯度

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_max_unpool2d(AtenTensorHandle self, AtenTensorHandle indices, const int64_t* output_size, int64_t output_size_len_, AtenTensorHandle* ret0);
# 定义了一个 CUDA 加速的 Torch 2D 最大反池化函数，根据索引和输出大小进行反池化操作

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_max_unpool3d(AtenTensorHandle self, AtenTensorHandle indices, const int64_t* output_size, int64_t output_size_len_, const int64_t* stride, int64_t stride_len_, const int64_t* padding, int64_t padding_len_, AtenTensorHandle* ret0);
# 定义了一个 CUDA 加速的 Torch 3D 最大反池化函数，根据索引、输出大小、步长和填充进行反池化操作

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_median(AtenTensorHandle self, AtenTensorHandle* ret0);
# 定义了一个 CUDA 加速的 Torch 中位数计算函数

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_mm_out(AtenTensorHandle out, AtenTensorHandle self, AtenTensorHandle mat2);
# 定义了一个 CUDA 加速的 Torch 矩阵乘法函数，将结果存储到指定的输出张量中

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_mode(AtenTensorHandle self, int64_t dim, int32_t keepdim, AtenTensorHandle* ret0, AtenTensorHandle* ret1);
# 定义了一个 CUDA 加速的 Torch 模式计算函数，返回张量在指定维度上的众数和对应的出现次数

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_mul_Scalar(AtenTensorHandle self, double other, AtenTensorHandle* ret0);
# 定义了一个 CUDA 加速的 Torch 标量乘法函数，将张量与标量相乘

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_mul_Tensor(AtenTensorHandle self, AtenTensorHandle other, AtenTensorHandle* ret0);
# 定义了一个 CUDA 加速的 Torch 张量乘法函数，将两个张量相乘

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_nanmedian(AtenTensorHandle self, AtenTensorHandle* ret0);
# 定义了一个 CUDA 加速的 Torch NaN 中位数计算函数
// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，用于执行 dropout 操作，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_native_dropout(AtenTensorHandle input, double p, int32_t* train, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，用于计算非零元素的索引，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_nonzero(AtenTensorHandle self, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，执行正态分布函数操作，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_normal_functional(AtenTensorHandle self, double mean, double std, AtenGeneratorHandle* generator, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，执行 QR 分解的相关操作，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_ormqr(AtenTensorHandle self, AtenTensorHandle input2, AtenTensorHandle input3, int32_t left, int32_t transpose, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，用于执行极坐标转换操作，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_polar(AtenTensorHandle abs, AtenTensorHandle angle, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，执行标量的幂运算，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_pow_Scalar(double self, AtenTensorHandle exponent, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，执行张量与标量的幂运算，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_pow_Tensor_Scalar(AtenTensorHandle self, double exponent, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，执行张量与张量的幂运算，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_pow_Tensor_Tensor(AtenTensorHandle self, AtenTensorHandle exponent, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，生成随机数张量，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_rand(const int64_t* size, int64_t size_len_, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，生成带有指定生成器的随机数张量，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_rand_generator(const int64_t* size, int64_t size_len_, AtenGeneratorHandle* generator, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，生成指定范围内的随机整数张量，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_randint(int64_t high, const int64_t* size, int64_t size_len_, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，生成带有指定生成器的指定范围内的随机整数张量，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_randint_generator(int64_t high, const int64_t* size, int64_t size_len_, AtenGeneratorHandle* generator, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，生成指定范围内的低位随机整数张量，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_randint_low(int64_t low, int64_t high, const int64_t* size, int64_t size_len_, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，生成指定范围内的低位随机整数张量并写入指定输出张量，无返回值
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_randint_low_out(AtenTensorHandle out, int64_t low, int64_t high, const int64_t* size, int64_t size_len_);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，生成指定大小的标准正态分布随机数张量，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_randn(const int64_t* size, int64_t size_len_, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0);

// 定义 AOTI_TORCH_EXPORT 宏，声明一个 CUDA 版本的函数，生成带有指定生成器的指定大小的标准正态分布随机数张量，返回 AOTITorchError 错误码
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_randn_generator(const int64_t* size, int64_t size_len_, AtenGeneratorHandle* generator, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0);
// 定义了一个名为 aoti_torch_cuda_randperm 的函数声明，返回 AOTITorchError 类型，用于生成 CUDA 设备上的随机排列张量
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_randperm(int64_t n, int32_t* dtype, int32_t* layout, int32_t* device, int32_t device_index_, int32_t* pin_memory, AtenTensorHandle* ret0);

// 定义了一个名为 aoti_torch_cuda_repeat_interleave_Tensor 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行 Tensor 的重复插值操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_repeat_interleave_Tensor(AtenTensorHandle repeats, int64_t* output_size, AtenTensorHandle* ret0);

// 定义了一个名为 aoti_torch_cuda_replication_pad1d_backward 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行 1D 复制填充的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_replication_pad1d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* padding, int64_t padding_len_, AtenTensorHandle* ret0);

// 定义了一个名为 aoti_torch_cuda_replication_pad2d_backward 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行 2D 复制填充的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_replication_pad2d_backward(AtenTensorHandle grad_output, AtenTensorHandle self, const int64_t* padding, int64_t padding_len_, AtenTensorHandle* ret0);

// 定义了一个名为 aoti_torch_cuda_reshape 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行张量的重塑操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_reshape(AtenTensorHandle self, const int64_t* shape, int64_t shape_len_, AtenTensorHandle* ret0);

// 定义了一个名为 aoti_torch_cuda_resize_ 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行张量的调整大小操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_resize_(AtenTensorHandle self, const int64_t* size, int64_t size_len_, int32_t* memory_format);

// 定义了一个名为 aoti_torch_cuda_resize_as_ 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行张量的按照模板调整大小操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_resize_as_(AtenTensorHandle self, AtenTensorHandle the_template, int32_t* memory_format);

// 定义了一个名为 aoti_torch_cuda_scatter_src_out 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行张量的分散操作（通过源张量）
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_scatter_src_out(AtenTensorHandle out, AtenTensorHandle self, int64_t dim, AtenTensorHandle index, AtenTensorHandle src);

// 定义了一个名为 aoti_torch_cuda_scatter_value_out 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行张量的分散操作（通过值）
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_scatter_value_out(AtenTensorHandle out, AtenTensorHandle self, int64_t dim, AtenTensorHandle index, double value);

// 定义了一个名为 aoti_torch_cuda_scatter_reduce_two_out 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行张量的分散操作（通过两个张量进行缩减）
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_scatter_reduce_two_out(AtenTensorHandle out, AtenTensorHandle self, int64_t dim, AtenTensorHandle index, AtenTensorHandle src, const char* reduce, int32_t include_self);

// 定义了一个名为 aoti_torch_cuda_segment_reduce 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行张量的分段缩减操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_segment_reduce(AtenTensorHandle data, const char* reduce, AtenTensorHandle* lengths, AtenTensorHandle* indices, AtenTensorHandle* offsets, int64_t axis, int32_t unsafe, double* initial, AtenTensorHandle* ret0);

// 定义了一个名为 aoti_torch_cuda_slice_Tensor 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行张量的切片操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_slice_Tensor(AtenTensorHandle self, int64_t dim, int64_t* start, int64_t* end, int64_t step, AtenTensorHandle* ret0);

// 定义了一个名为 aoti_torch_cuda_soft_margin_loss_backward 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行软边损失函数的反向传播
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_soft_margin_loss_backward(AtenTensorHandle grad_output, AtenTensorHandle self, AtenTensorHandle target, int64_t reduction, AtenTensorHandle* ret0);

// 定义了一个名为 aoti_torch_cuda_sort 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行张量的排序操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_sort(AtenTensorHandle self, int64_t dim, int32_t descending, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

// 定义了一个名为 aoti_torch_cuda_sort_stable 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上执行稳定排序操作
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_sort_stable(AtenTensorHandle self, int32_t* stable, int64_t dim, int32_t descending, AtenTensorHandle* ret0, AtenTensorHandle* ret1);

// 定义了一个名为 aoti_torch_cuda_to_sparse 的函数声明，返回 AOTITorchError 类型，用于在 CUDA 设备上将稠密张量转换为稀疏张量
AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_to_sparse(AtenTensorHandle self, int32_t* layout, const int64_t** blocksize, int64_t blocksize_len_, int64_t* dense_dim, AtenTensorHandle* ret0);
# 定义了一系列在 CUDA 上执行的 Torch 操作的导出函数，用于 C++ 调用

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_topk(AtenTensorHandle self, int64_t k, int64_t dim, int32_t largest, int32_t sorted, AtenTensorHandle* ret0, AtenTensorHandle* ret1);
# 在 CUDA 上执行 Top-K 操作，返回指定维度上的最大（或最小）的 k 个元素，支持按大小排序

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_triangular_solve(AtenTensorHandle self, AtenTensorHandle A, int32_t upper, int32_t transpose, int32_t unitriangular, AtenTensorHandle* ret0, AtenTensorHandle* ret1);
# 在 CUDA 上执行三角矩阵求解操作，支持上三角或下三角矩阵的求解，可选是否转置和单位上三角

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_uniform(AtenTensorHandle self, double from, double to, AtenGeneratorHandle* generator, AtenTensorHandle* ret0);
# 在 CUDA 上生成均匀分布的随机数张量，范围从 from 到 to，使用给定的随机数生成器

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_upsample_bicubic2d_backward(AtenTensorHandle grad_output, const int64_t* output_size, int64_t output_size_len_, const int64_t* input_size, int64_t input_size_len_, int32_t align_corners, double* scales_h, double* scales_w, AtenTensorHandle* ret0);
# 在 CUDA 上执行双三次插值的二维上采样的反向传播操作，支持自定义输出和输入大小，以及对齐角点的选项

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_upsample_linear1d_backward(AtenTensorHandle grad_output, const int64_t* output_size, int64_t output_size_len_, const int64_t* input_size, int64_t input_size_len_, int32_t align_corners, double* scales, AtenTensorHandle* ret0);
# 在 CUDA 上执行线性插值的一维上采样的反向传播操作，支持自定义输出和输入大小，以及对齐角点的选项

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_upsample_trilinear3d_backward(AtenTensorHandle grad_output, const int64_t* output_size, int64_t output_size_len_, const int64_t* input_size, int64_t input_size_len_, int32_t align_corners, double* scales_d, double* scales_h, double* scales_w, AtenTensorHandle* ret0);
# 在 CUDA 上执行三线性插值的三维上采样的反向传播操作，支持自定义输出和输入大小，以及对齐角点的选项

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_view_dtype(AtenTensorHandle self, int32_t dtype, AtenTensorHandle* ret0);
# 在 CUDA 上将张量视图转换为指定的数据类型的张量视图，返回转换后的张量视图

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_view_as_complex(AtenTensorHandle self, AtenTensorHandle* ret0);
# 在 CUDA 上将实部张量视图转换为复数张量视图，返回转换后的复数张量视图

AOTI_TORCH_EXPORT AOTITorchError aoti_torch_cuda_view_as_real(AtenTensorHandle self, AtenTensorHandle* ret0);
# 在 CUDA 上将复数张量视图转换为实部张量视图，返回转换后的实部张量视图

#ifdef __cplusplus
} // extern "C"
#endif
```