# `.\pytorch\torch\csrc\inductor\aoti_runtime\model.h`

```py
#pragma once
// 预处理指令：确保本文件只被编译一次

#include <dlfcn.h>
// 动态链接库加载相关的头文件
#include <fcntl.h>
// 文件控制相关的头文件
#include <sys/mman.h>
// 内存映射相关的头文件
#include <unistd.h>
// POSIX 系统服务的头文件
#include <optional>
// 可选值的头文件
#include <regex>
// 正则表达式的头文件
#include <stdexcept>
// 标准异常类的头文件
#include <unordered_map>
// 无序映射的头文件

// WARNING: Be careful when adding new includes here. This header will be used
// in model.so, and should not refer to any aten/c10 headers except the stable
// C ABI defined in torch/csrc/inductor/aoti_torch/c/shim.h. The same rule
// applies to other files under torch/csrc/inductor/aoti_runtime/.
#include <torch/csrc/inductor/aoti_runtime/device_utils.h>
// 使用到的设备工具函数的头文件
#include <torch/csrc/inductor/aoti_runtime/utils.h>
// 使用到的工具函数的头文件

#define AOTI_RUNTIME_CHECK(EXPR, MSG) \
  do {                                \
    bool ok = EXPR;                   \
    if (!ok) {                        \
      throw std::runtime_error(MSG);  \
    }                                 \
  } while (0)
// 定义一个宏，用于检查运行时条件是否满足，不满足则抛出异常

// At codegen time, we write out a binary file called constants.bin.
// We then turn the raw binary to an object file that exposes this
// symbol and link it into the final .so.
// For information on the binary format, see `man objcopy`, under
// the "binary-architecture" flag:
// https://man7.org/linux/man-pages/man1/objcopy.1.html
// todo: use #embed in C++ 23 once available
// The constants are NOT readonly because they may be mutated.
extern uint8_t _binary_constants_bin_start[];
extern uint8_t _binary_constants_bin_end[];
// 定义两个外部符号，用于指向二进制文件 constants.bin 的起始和结束位置

#define AOTI_CONST_GPU_ALIGNMENT 64
// 定义 GPU 对齐的常量值为 64

namespace {
// 匿名命名空间，用于限定作用域，避免全局变量污染
#ifdef USE_CUDA

using CUDAPtr = std::unique_ptr<void, std::function<void(void*)>>;
// 使用 std::unique_ptr 包装 CUDA 内存，使用自定义的释放器

CUDAPtr RAII_cudaMalloc(size_t num_bytes) {
  void* data_ptr;
  AOTI_RUNTIME_DEVICE_CHECK(cudaMalloc((void**)&data_ptr, num_bytes));
  auto deleter = [](void* ptr) { AOTI_RUNTIME_DEVICE_CHECK(cudaFree(ptr)); };
  return CUDAPtr(data_ptr, deleter);
}
// 在 CUDA 环境下，封装 cudaMalloc 和 cudaFree 操作，返回一个 CUDA 内存的 RAII 封装对象

#endif // USE_CUDA

} // anonymous namespace
// 结束匿名命名空间

namespace torch {
namespace aot_inductor {
using ConstantMap = std::unordered_map<std::string, RAIIAtenTensorHandle>;
// 定义常量映射类型，将字符串映射到 RAIIAtenTensorHandle 对象

// valid device strs are: cpu, cuda, cuda:0, cuda:1, ...
// Update the list here if more devices are supported in the future
inline void parse_device_str(
    const std::string& device_str,
    int32_t& device_type,
    int32_t& device_idx) {
  std::regex re("(cpu|cuda)(:([0-9]+))?");
  // 定义正则表达式，用于匹配设备字符串格式
  std::smatch sm;
  bool matched = std::regex_match(device_str, sm, re);
  // 尝试匹配设备字符串和正则表达式
  AOTI_RUNTIME_CHECK(matched, "Invalid device: " + device_str);
  // 如果匹配失败，抛出运行时异常

  if (sm[1].str() == "cpu") {
    device_type = aoti_torch_device_type_cpu();
    // 如果匹配到 cpu，则设备类型为 CPU
  } else if (sm[1].str() == "cuda") {
    device_type = aoti_torch_device_type_cuda();
    // 如果匹配到 cuda，则设备类型为 CUDA
  } else {
    AOTI_RUNTIME_CHECK(false, "Invalid device: " + device_str);
    // 如果匹配到未知设备类型，则抛出运行时异常
  }

  if (sm[3].matched) {
    device_idx = stoi(sm[3].str());
    // 如果匹配到设备索引，则将其转换为整数
  } else {
    device_idx = -1;
    // 否则设备索引为 -1
  }
}

// Defines the base class for AOTInductorModel, which is generated by the
// AOTInductor cpp codegen. Since we do not need dynamic dispatch, we rely
// on curiously recurring template pattern (CRTP) to save some runtime
// v-table overhead. The generated AOTInductorModel is specialized with


注释部分已经添加完毕，对代码中的各个部分进行了简洁明了的解释。
// 定义模板类 AOTInductorModelBase，用于AOT（Ahead-of-Time）模型的导入
template <typename Model>
class AOTInductorModelBase {
 public:
  // 构造函数，初始化模型的输入、输出和常量信息，设置设备字符串及可选的Cubin目录
  AOTInductorModelBase(
      size_t num_inputs,
      size_t num_outputs,
      size_t num_constants,
      const std::string& device_str,
      std::optional<std::string> cubin_dir)
      : inputs_info_(num_inputs),
        outputs_info_(num_outputs),
        constants_info_(num_constants),
        cubin_dir_(cubin_dir) {
    // 解析设备字符串，确定设备类型和索引
    parse_device_str(device_str, device_type_, device_idx_);

#ifdef USE_CUDA
    // 如果使用CUDA并且设备索引为-1，获取当前CUDA设备索引
    if (device_idx_ == -1) {
      AOTI_RUNTIME_DEVICE_CHECK(cudaGetDevice(&device_idx_));
    }
#endif // USE_CUDA
  }

  // 析构函数，释放资源，包括CUDA事件对象
  ~AOTInductorModelBase() {
#ifdef USE_CUDA
    // 如果运行已完成，销毁CUDA事件对象
    if (run_finished_) {
      auto code = cudaEventDestroy(*run_finished_);
      if (code != cudaSuccess) {
        std::cerr << "Failed to destroy CUDA event in AOTInductor model: "
                  << cudaGetErrorString(code) << std::endl;
      }
    }
#endif // USE_CUDA
  }

  // 禁用移动构造函数和赋值运算符
  AOTInductorModelBase(AOTInductorModelBase&&) = delete;
  AOTInductorModelBase& operator=(AOTInductorModelBase&&) = delete;
  AOTInductorModelBase(const AOTInductorModelBase&) = delete;
  AOTInductorModelBase& operator=(const AOTInductorModelBase&) = delete;

  // 运行模型的方法，根据是否使用CUDA执行不同逻辑
  void run(
      AtenTensorHandle* input_handles, // 输入张量句柄数组；句柄被窃取，数组本身被借用
      AtenTensorHandle* output_handles, // 输出张量句柄数组；句柄将被调用者窃取，数组本身被借用
      DeviceStreamType stream,
      AOTIProxyExecutorHandle proxy_executor) {
#ifdef USE_CUDA
    // 如果运行未完成，创建CUDA事件对象
    if (!run_finished_) {
      cudaEvent_t run_finished;
      AOTI_RUNTIME_DEVICE_CHECK(cudaEventCreate(&run_finished));
      run_finished_.emplace(run_finished);
    }

    // 转换模型指针为具体的模型类型，并执行具体的运行实现方法
    auto* model = static_cast<Model*>(this);
    model->run_impl(input_handles, output_handles, stream, proxy_executor);
    // 记录CUDA事件
    AOTI_RUNTIME_DEVICE_CHECK(cudaEventRecord(*run_finished_, stream));
#else // !USE_CUDA
    // 如果不使用CUDA，标记运行已完成
    run_finished_ = true;
    auto* model = static_cast<Model*>(this);
    model->run_impl(input_handles, output_handles, stream, proxy_executor);
#endif // USE_CUDA
  }

  // 执行常量折叠运算的方法，根据是否使用CUDA执行不同逻辑
  std::unordered_map<std::string, AtenTensorHandle> run_const_fold(
      DeviceStreamType stream,
      AOTIProxyExecutorHandle proxy_executor,
      bool initialization = false) {
#ifdef USE_CUDA
    // 如果运行未完成，创建CUDA事件对象
    if (!run_finished_) {
      cudaEvent_t run_finished;
      AOTI_RUNTIME_DEVICE_CHECK(cudaEventCreate(&run_finished));
      run_finished_.emplace(run_finished);
    }
#else // USE_CUDA
    // 如果不使用CUDA，标记运行已完成
    run_finished_ = true;
#endif // USE_CUDA

    // 转换模型指针为具体的模型类型，并执行常量折叠的具体实现方法
    auto* model = static_cast<Model*>(this);
    auto folded_constants =
        model->const_run_impl(stream, proxy_executor, initialization);

#ifdef USE_CUDA
    // 如果使用CUDA，记录CUDA事件
    AOTI_RUNTIME_DEVICE_CHECK(cudaEventRecord(*run_finished_, stream));
#endif // USE_CUDA

    // 返回常量折叠后的结果
    return folded_constants;
  }

 private:
  // 输入信息的向量
  std::vector<InputInfo> inputs_info_;
  // 输出信息的向量
  std::vector<OutputInfo> outputs_info_;
  // 常量信息的向量
  std::vector<ConstantInfo> constants_info_;
  // 可选的Cubin目录
  std::optional<std::string> cubin_dir_;
  // 设备类型
  DeviceType device_type_;
  // 设备索引
  int device_idx_ = -1;
  // CUDA事件对象指针，用于标记运行是否完成
  std::optional<cudaEvent_t> run_finished_;
};
#endif // USE_CUDA
// 函数结束，当未定义 USE_CUDA 时结束条件编译

    return folded_constants;
  }

  void load_constants() {
    // 获取常数数量并预留容量
    size_t num_constants = this->num_constants();
    constants_map_->reserve(num_constants);

    // 存储常数内部偏移的向量
    std::vector<size_t> constants_internal_offset(num_constants);

    // 如果设备类型不是 CPU，则计算 CUDA 常数块的大小和内部偏移
    if (device_type_ != aoti_torch_device_type_cpu()) {
      size_t blob_size = 0;
      compute_cuda_constant_blob(blob_size, constants_internal_offset);
#ifdef USE_CUDA
      // 当定义了 USE_CUDA 时，分配 CUDA 内存块
      constant_blob_ = RAII_cudaMalloc(blob_size);
#endif
    }

    // 初始化已读取的字节数
    size_t bytes_read = 0;

    // 遍历所有常数
    for (size_t i = 0; i < num_constants; i++) {
      // 检查是否从折叠常数中获取
      bool from_folded = this->constant_from_folded(i);
#ifndef USE_CUDA
      // 如果未定义 USE_CUDA 并且来源于折叠常数，则跳过
      if (from_folded) {
        continue;
      }
#endif // USE_CUDA

      // 获取常数的名称、数据大小和内部指针
      std::string name = this->constant_name(i);
      size_t data_size = this->constant_data_size(i);
      uint8_t* internal_ptr = (data_size != 0)
          ? constant_ptr(
                constants_internal_offset[i],
                bytes_read,
                data_size,
                from_folded)
          : nullptr;
      bytes_read += data_size;

      // 从内存中创建 at::Tensor
      auto dtype = this->constant_dtype(i);
      auto ndim = this->constant_ndim(i);
      auto size = this->constant_shape(i);
      auto stride = this->constant_stride(i);
      auto offset = this->constant_offset(i);
      auto layout = this->constant_layout(i);
      auto opaque_metadata_ptr = this->opaque_metadata(i);
      auto opaque_metadata_size = this->opaque_metadata_size(i);

      AtenTensorHandle tensor_handle;

      // 根据不同的宏选择使用不同版本的创建张量函数
#ifdef AOTI_USE_CREATE_TENSOR_FROM_BLOB_V1
      // 当 opaque_metadata_size 不为 0 时，需要使用 aoti_torch_create_tensor_from_blob_v2 函数
      AOTI_RUNTIME_CHECK(
          opaque_metadata_size == 0,
          "Expect opaque_metadata_size to be 0 when AOTI_USE_CREATE_TENSOR_FROM_BLOB_V1 is defined");
      AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_create_tensor_from_blob(
          internal_ptr,
          ndim,
          size,
          stride,
          offset,
          dtype,
          device_type_,
          device_idx_,
          &tensor_handle));
#else
      // 使用 aoti_torch_create_tensor_from_blob_v2 函数创建张量
      AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_create_tensor_from_blob_v2(
          internal_ptr,
          ndim,
          size,
          stride,
          offset,
          dtype,
          device_type_,
          device_idx_,
          &tensor_handle,
          layout,
          opaque_metadata_ptr,
          opaque_metadata_size));
#endif // AOTI_USE_CREATE_TENSOR_FROM_BLOB_V1

      // 将常数名称和张量句柄插入常数映射
      constants_map_->emplace(std::move(name), tensor_handle);
    }

    // 如果存在常数映射，则更新常数数组
    if (constants_map_) {
      this->update_constants_array_from_map();
    }
  }

#ifdef USE_CUDA
  // 当定义了 USE_CUDA 时，释放常数块并返回其右值引用
  CUDAPtr&& release_constant_blob() {
    return std::move(constant_blob_);
  }
#endif

  // 返回常数数组的共享指针
  std::shared_ptr<std::vector<ConstantHandle>> get_constants_array() {
    return constants_;
  }

  // 获取设备索引的常数方法
  const int32_t get_device_idx() const {
    // 返回当前设备索引值
    return device_idx_;
    }
    
    // 返回指向常量内存块的指针，可以根据参数指定的偏移量、读取的字节数、数据大小和是否跳过复制操作来进行操作
    uint8_t* constant_ptr(
        size_t constant_offset,  // 常量偏移量，指定要访问的常量数据在内存中的位置
        size_t bytes_read,       // 已读取的字节数，用于定位常量数据的读取位置
        size_t data_size,        // 数据大小，指定常量数据块的总大小
        bool skip_copy           // 是否跳过复制操作的标志，用于指示是否直接返回数据的指针而不进行额外的复制
    ) {
#ifdef USE_CUDA
    // 获取常量数据的指针，该数据在编译时打包到模型中
    auto* constants_ptr = static_cast<uint8_t*>(constant_blob_.get());
    // 计算内部指针，指向常量数据的特定偏移量
    uint8_t* internal_ptr = constants_ptr + constant_offset;
    // 将数据复制到 GPU 内存中
    // TODO: 处理共享存储的情况。
    if (!skip_copy) {
      AOTI_RUNTIME_DEVICE_CHECK(cudaMemcpy(
          internal_ptr,
          _get_constants_start() + bytes_read,
          data_size,
          cudaMemcpyHostToDevice));
    }
    // 返回内部指针，指向已复制到 GPU 的数据
    return internal_ptr;

#else
    // 获取常量的指针，该数据在编译时打包到模型中
    AOTI_RUNTIME_CHECK(!skip_copy, "pure cpu mode doesn't support skip copy");
    // 返回指向常量数据的指针，位于编译时指定的偏移量处
    return _get_constants_start() + bytes_read;
#endif // USE_CUDA
  }

  void compute_cuda_constant_blob(
      size_t& blob_size,
      std::vector<size_t>& constants_internal_offset) {
#ifdef USE_CUDA
    size_t num_constants = this->num_constants();
    // 计算在 GPU 上所需的 blob 大小，并进行 64 字节对齐
    blob_size = 0;
    for (size_t i = 0; i < num_constants; i++) {
      size_t data_size = this->constant_data_size(i);
      if (data_size % AOTI_CONST_GPU_ALIGNMENT) {
        data_size = AOTI_CONST_GPU_ALIGNMENT +
            (data_size / AOTI_CONST_GPU_ALIGNMENT) * AOTI_CONST_GPU_ALIGNMENT;
      }
      // 记录每个常量在 blob 中的偏移量
      constants_internal_offset[i] = blob_size;
      blob_size += data_size;
    }
#endif // USE_CUDA
  }

  size_t num_inputs() const {
    return inputs_info_.size();
  }

  size_t num_outputs() const {
    return outputs_info_.size();
  }

  size_t num_constants() const {
    return constants_info_.size();
  }

  const char* input_name(int64_t idx) const {
    return inputs_info_.at(idx).name;
  }

  const char* output_name(int64_t idx) const {
    return outputs_info_.at(idx).name;
  }

  const char* constant_name(int64_t idx) const {
    return constants_info_.at(idx).name;
  }

  size_t constant_ndim(int64_t idx) {
    return constants_info_.at(idx).shape.size();
  }

  const int64_t* constant_shape(int64_t idx) const {
    return constants_info_.at(idx).shape.data();
  }

  const int64_t* constant_stride(int64_t idx) const {
    return constants_info_.at(idx).stride.data();
  }

  int32_t constant_dtype(int64_t idx) const {
    return constants_info_.at(idx).dtype;
  }

  int32_t constant_layout(int64_t idx) const {
    return constants_info_.at(idx).layout;
  }

  size_t constant_offset(int64_t idx) const {
    return constants_info_.at(idx).offset;
  }

  size_t constant_data_size(int64_t idx) const {
    return constants_info_.at(idx).data_size;
  }

  const char* constant_original_fqn(int64_t idx) const {
    return constants_info_.at(idx).original_fqn;
  }

  const uint8_t* opaque_metadata(int64_t idx) const {
    return constants_info_.at(idx).opaque_metadata.data();
  }

  size_t opaque_metadata_size(int64_t idx) {
    return constants_info_.at(idx).opaque_metadata.size();
  }

  bool constant_from_folded(int64_t idx) const {
    return constants_info_.at(idx).from_folded;
  }

  const char* get_in_spec() const {
    // 返回输入规格的 C 字符串表示
    return in_spec_.c_str();
  }

  // 返回输出规格的 C 字符串表示
  const char* get_out_spec() const {
    return out_spec_.c_str();
  }

  // 从常量映射更新常量数组。如果 constants_map_ 未准备好，则抛出运行时错误。
  void update_constants_array_from_map() {
    if (!constants_map_) {
      throw std::runtime_error{
          "constants_map_ was not ready when constants_ is trying to be constructed from it!"};
    }
    // 如果 constants_ 为空，则创建一个大小为 constants_info_.size() 的新常量数组。
    if (!constants_) {
      constants_ =
          std::make_shared<std::vector<ConstantHandle>>(constants_info_.size());
    } else {
      // 否则，调整现有 constants_ 的大小以匹配 constants_info_ 的大小。
      constants_->resize(constants_info_.size());
    }
    int idx = 0;
    // 遍历 constants_info_ 中的每个常量信息项。
    for (const auto& info : constants_info_) {
      // 查找 constants_map_ 中是否存在当前常量信息项的名称。
      const auto it = constants_map_->find(info.name);
      // 如果找到对应的映射，则将其加入 constants_ 中相应位置的常量句柄。
      if (it != constants_map_->end()) {
        constants_->at(idx) = ConstantHandle(it->second);
      }
      idx++;
    }
  }

  // 更新常量映射并可选地重新映射常量数组。
  void update_constants_map(
      std::shared_ptr<ConstantMap> constants_map,
      bool remap_constants_array = true) {
    // 将给定的常量映射赋值给 constants_map_。
    constants_map_ = std::move(constants_map);
    // 如果 remap_constants_array 为 true，则调用 update_constants_array_from_map() 重新映射常量数组。
    if (remap_constants_array) {
      update_constants_array_from_map();
    }
  }

  // 更新常量数组，用于在运行时查找相应的常量张量。
  void update_constants_array(
      std::shared_ptr<std::vector<ConstantHandle>> constants_array) {
    // 将给定的常量数组赋值给 constants_。
    constants_ = std::move(constants_array);
  }

  /// 返回模型是否已完成的布尔值。
  bool is_finished() {
#ifdef USE_CUDA
    // 如果未初始化 CUDA 事件，则抛出运行时错误
    if (!run_finished_) {
      throw std::runtime_error{"Model CUDA event was not initialized"};
    }

    // 查询 CUDA 事件的状态
    auto event_status = cudaEventQuery(*run_finished_);
    // 如果事件已完成，返回 true
    if (event_status == cudaSuccess) {
      return true;
    } else if (event_status == cudaErrorNotReady) { // 如果事件未完成，返回 false
      return false;
    }

    // 如果查询失败，抛出运行时错误，并显示 CUDA 错误信息
    throw std::runtime_error(
        std::string("The model did not finish successfully. Error: ") +
        cudaGetErrorString(cudaGetLastError()));
#else // !USE_CUDA
    // 如果未使用 CUDA，直接返回运行完成的状态
    return run_finished_;
#endif // USE_CUDA
  }

  /// 同步完成事件。
  void wait_for_completion() {
#ifdef USE_CUDA
    // 如果未初始化 CUDA 事件，则抛出运行时错误
    if (!run_finished_) {
      throw std::runtime_error{"Model event was not initialized"};
    }

    // 同步 CUDA 事件
    AOTI_RUNTIME_DEVICE_CHECK(cudaEventSynchronize(*run_finished_));
#endif // USE_CUDA
  }

 protected:
  uint8_t* _get_constants_start() {
#ifndef USE_MMAP_SELF
    // 如果未定义使用自定义的内存映射，则返回常量的起始地址
    return const_cast<uint8_t*>(_binary_constants_bin_start);
#else
    // 如果使用自定义的内存映射
    if (self_mmap) {
      return self_mmap;  // 返回自定义映射的地址
    }
    Dl_info dl_info;
    // 获取常量附加到二进制文件中的指针
    AOTI_RUNTIME_CHECK(
        dladdr(__func__, &dl_info), "Can't find shared library name");
    int fd = open(dl_info.dli_fname, O_RDONLY);
    AOTI_RUNTIME_CHECK(fd >= 0, "Shared library file cannot be opened");
    auto fsize = lseek(fd, 0, SEEK_END);  // 获取文件大小
    auto weights_size =
        reinterpret_cast<const uint64_t*>(_binary_constants_bin_start)[0];  // 获取权重大小
    auto magic_number =
        reinterpret_cast<const uint64_t*>(_binary_constants_bin_start)[1];  // 获取魔数
    auto weights_offset = fsize - weights_size;  // 计算权重偏移量
    // 权重偏移量必须对齐到 16K 边界
    AOTI_RUNTIME_CHECK(
        (weights_offset & 0x3fff) == 0,
        "weights_offset must be aligned to 16K boundary");
    // 执行内存映射
    auto ptr = mmap(
        NULL,
        weights_size,
        PROT_READ | PROT_WRITE,
        MAP_PRIVATE,
        fd,
        weights_offset);
    close(fd);  // 关闭文件描述符
    // 检查内存映射是否成功
    AOTI_RUNTIME_CHECK(ptr != MAP_FAILED, "mmap() failed");
    self_mmap = static_cast<uint8_t*>(ptr);  // 存储映射的地址
    // 检查权重数据是否损坏
    AOTI_RUNTIME_CHECK(
        reinterpret_cast<uint64_t*>(
            self_mmap + weights_size - sizeof(uint64_t))[0] == magic_number,
        "Weigths data seems corrupt");
    return self_mmap;  // 返回映射的起始地址
#endif
  }
  struct ParamInfo {
    const char* name = nullptr;
  };

  struct ConstInfo {
    const char* name = nullptr;
    std::vector<int64_t> shape;
    std::vector<int64_t> stride;
    int32_t dtype;
    int64_t offset;
    size_t data_size;
    int32_t layout;
    std::vector<uint8_t> opaque_metadata;
    int64_t opaque_metadata_size;
    const char* original_fqn = nullptr;
    bool from_folded;
  };

  std::vector<ParamInfo> inputs_info_;
  std::vector<ParamInfo> outputs_info_;
  std::vector<ConstInfo> constants_info_;
  std::string in_spec_;
  std::string out_spec_;

  std::shared_ptr<ConstantMap> constants_map_;
  std::shared_ptr<std::vector<ConstantHandle>> constants_;

#ifdef USE_CUDA
  // 用于存储 CUDA 的常量 at::Tensor 的 blob 存储
  CUDAPtr constant_blob_;
#endif // USE_CUDA
#ifdef USE_MMAP_SELF
  // 如果定义了 USE_MMAP_SELF 宏，则声明一个指向 uint8_t 类型的空指针 self_mmap
  uint8_t* self_mmap = NULL;
#endif

  // CUDA 二进制文件目录的可选项，例如编译的内核文件等
  const std::optional<std::string> cubin_dir_;

  // 记录模型是否完成推断运行，以便其拥有的 AOTModelContainer 可以重用此实例
#ifdef USE_CUDA
  // 如果使用 CUDA，记录推断运行是否完成的可选 CUDA 事件
  std::optional<cudaEvent_t> run_finished_;
#else // !USE_CUDA
  // 如果不使用 CUDA，则记录推断运行是否完成的布尔值
  bool run_finished_;
#endif

  // 生成的模型使用此设备索引创建 CUDA 保护
  int32_t device_type_;
  int32_t device_idx_;
};

// Codegen-ed 类可以从此类派生以保持对加载的内核的指针引用
class AOTInductorModelKernelsBase {
 public:
  virtual ~AOTInductorModelKernelsBase() = default;
};

class AOTInductorModel : public AOTInductorModelBase<AOTInductorModel> {
 public:
  // 构造函数，初始化 AOTInductorModel 对象
  AOTInductorModel(
      std::shared_ptr<ConstantMap> constants_map,
      std::shared_ptr<std::vector<ConstantHandle>> constants_array,
      const std::string& device_str,
      std::optional<std::string> cubin_dir);

  // 运行常量推断实现，返回名称到 AtenTensorHandle 映射的无序映射
  std::unordered_map<std::string, AtenTensorHandle> const_run_impl(
      DeviceStreamType stream,
      AOTIProxyExecutorHandle proxy_executor,
      bool initialization = false);

  // 内部运行常量推断实现，填充输出处理句柄数组
  void _const_run_impl(
      std::vector<AtenTensorHandle>& output_handles,
      DeviceStreamType stream,
      AOTIProxyExecutorHandle proxy_executor);

  // 运行实现函数，处理输入和输出 AtenTensorHandle 数组，处理流和代理执行器
  void run_impl(
      AtenTensorHandle*
          input_handles, // 输入 AtenTensorHandle 数组；句柄被窃取，数组本身被借用
      AtenTensorHandle*
          output_handles, // 输出 AtenTensorHandle 数组；句柄将被调用者窃取，数组本身被借用
      DeviceStreamType stream,
      AOTIProxyExecutorHandle proxy_executor);

  // 使用最小数组引用接口运行实现，处理输入和输出，处理流和代理执行器
  template <typename Inputs, typename Outputs>
  Outputs run_impl_minimal_arrayref_interface(
      const Inputs& inputs,
      DeviceStreamType stream,
      AOTIProxyExecutorHandle proxy_executor);

  // 静态工厂方法，创建 AOTInductorModel 的唯一指针
  static std::unique_ptr<AOTInductorModel> Create(
      std::shared_ptr<ConstantMap> constants_map,
      std::shared_ptr<std::vector<ConstantHandle>> constants_array,
      const std::string& device_str,
      std::optional<std::string> cubin_dir) {
    return std::make_unique<AOTInductorModel>(
        std::move(constants_map),
        std::move(constants_array),
        device_str,
        cubin_dir);
  }

 private:
  std::unique_ptr<AOTInductorModelKernelsBase> kernels_;
};

} // namespace aot_inductor
} // namespace torch
```