# `.\yolov8\ultralytics\utils\callbacks\clearml.py`

```
# Ultralytics YOLO ğŸš€, AGPL-3.0 license

# å¼•å…¥å¿…è¦çš„æ—¥å¿—å™¨ã€è®¾ç½®å’Œæµ‹è¯•è¿è¡ŒçŠ¶æ€çš„æ ‡å¿—
from ultralytics.utils import LOGGER, SETTINGS, TESTS_RUNNING

# å°è¯•å¯¼å…¥å¹¶éªŒè¯ ClearML ç›¸å…³çš„è®¾ç½®å’Œç¯å¢ƒ
try:
    # ç¡®ä¿ä¸åœ¨è¿è¡Œ pytest æ—¶è®°å½•æ—¥å¿—
    assert not TESTS_RUNNING
    # ç¡®ä¿ ClearML æ•´åˆå·²å¯ç”¨
    assert SETTINGS["clearml"] is True
    import clearml
    from clearml import Task

    # ç¡®ä¿ clearml åŒ…å·²æˆåŠŸå¯¼å…¥ä¸”æœ‰ç‰ˆæœ¬ä¿¡æ¯
    assert hasattr(clearml, "__version__")

except (ImportError, AssertionError):
    clearml = None


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ç”¨äºå°†æ–‡ä»¶è·¯å¾„åˆ—è¡¨ä¸­çš„å›¾åƒä½œä¸ºè°ƒè¯•æ ·æœ¬è®°å½•åˆ° ClearML ä»»åŠ¡ä¸­
def _log_debug_samples(files, title="Debug Samples") -> None:
    """
    Log files (images) as debug samples in the ClearML task.

    Args:
        files (list): A list of file paths in PosixPath format.
        title (str): A title that groups together images with the same values.
    """
    import re

    # å¦‚æœå½“å‰å­˜åœ¨ ClearML ä»»åŠ¡ï¼Œåˆ™ä¾æ¬¡å¤„ç†æ–‡ä»¶
    if task := Task.current_task():
        for f in files:
            if f.exists():
                # ä»æ–‡ä»¶åä¸­æå–æ‰¹æ¬¡å·å¹¶è½¬æ¢ä¸ºæ•´æ•°
                it = re.search(r"_batch(\d+)", f.name)
                iteration = int(it.groups()[0]) if it else 0
                # å°†å›¾åƒæ–‡ä»¶æŠ¥å‘Šåˆ° ClearML ä»»åŠ¡æ—¥å¿—
                task.get_logger().report_image(
                    title=title, series=f.name.replace(it.group(), ""), local_path=str(f), iteration=iteration
                )


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ç”¨äºå°†ä¿å­˜çš„å›¾åƒæ–‡ä»¶ä½œä¸ºç»˜å›¾è®°å½•åˆ° ClearML çš„ç»˜å›¾éƒ¨åˆ†
def _log_plot(title, plot_path) -> None:
    """
    Log an image as a plot in the plot section of ClearML.

    Args:
        title (str): The title of the plot.
        plot_path (str): The path to the saved image file.
    """
    import matplotlib.image as mpimg
    import matplotlib.pyplot as plt

    # è¯»å–å›¾åƒæ–‡ä»¶å¹¶åˆ›å»ºç»˜å›¾å¯¹è±¡
    img = mpimg.imread(plot_path)
    fig = plt.figure()
    ax = fig.add_axes([0, 0, 1, 1], frameon=False, aspect="auto", xticks=[], yticks=[])  # ä¸æ˜¾ç¤ºåˆ»åº¦
    ax.imshow(img)

    # æŠ¥å‘Š Matplotlib ç»˜åˆ¶çš„å›¾åƒåˆ° ClearML ä»»åŠ¡æ—¥å¿—
    Task.current_task().get_logger().report_matplotlib_figure(
        title=title, series="", figure=fig, report_interactive=False
    )


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œåœ¨é¢„è®­ç»ƒè¿‡ç¨‹å¼€å§‹æ—¶åˆå§‹åŒ–å¹¶è¿æ¥/è®°å½•ä»»åŠ¡åˆ° ClearML
def on_pretrain_routine_start(trainer):
    """Runs at start of pretraining routine; initializes and connects/ logs task to ClearML."""
    try:
        # å¦‚æœå½“å‰å­˜åœ¨ ClearML ä»»åŠ¡ï¼Œåˆ™æ›´æ–° PyTorch å’Œ Matplotlib çš„ç»‘å®š
        if task := Task.current_task():
            # è­¦å‘Šï¼šç¡®ä¿ç¦ç”¨è‡ªåŠ¨çš„ PyTorch å’Œ Matplotlib ç»‘å®šï¼
            # æˆ‘ä»¬æ­£åœ¨æ‰‹åŠ¨åœ¨é›†æˆä¸­è®°å½•è¿™äº›ç»˜å›¾å’Œæ¨¡å‹æ–‡ä»¶
            from clearml.binding.frameworks.pytorch_bind import PatchPyTorchModelIO
            from clearml.binding.matplotlib_bind import PatchedMatplotlib

            PatchPyTorchModelIO.update_current_task(None)
            PatchedMatplotlib.update_current_task(None)
        else:
            # å¦åˆ™åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„ ClearML ä»»åŠ¡
            task = Task.init(
                project_name=trainer.args.project or "YOLOv8",
                task_name=trainer.args.name,
                tags=["YOLOv8"],
                output_uri=True,
                reuse_last_task_id=False,
                auto_connect_frameworks={"pytorch": False, "matplotlib": False},
            )
            # è®°å½•è­¦å‘Šä¿¡æ¯ï¼Œæç¤ºç”¨æˆ·å¦‚ä½•åœ¨è¿œç¨‹ç¯å¢ƒè¿è¡Œ YOLO
            LOGGER.warning(
                "ClearML Initialized a new task. If you want to run remotely, "
                "please add clearml-init and connect your arguments before initializing YOLO."
            )
        # å°†è®­ç»ƒå™¨å‚æ•°è¿æ¥åˆ° ClearML ä»»åŠ¡
        task.connect(vars(trainer.args), name="General")
    # æ•è·æ‰€æœ‰å¼‚å¸¸å¹¶å°†å…¶å­˜å‚¨åœ¨å˜é‡eä¸­
    except Exception as e:
        # ä½¿ç”¨WARNINGçº§åˆ«çš„æ—¥å¿—è®°å½•å™¨LOGGERè®°å½•è­¦å‘Šæ¶ˆæ¯ï¼ŒæŒ‡å‡ºClearMLæœªæ­£ç¡®åˆå§‹åŒ–ï¼Œ
        # å› æ­¤ä¸èƒ½è®°å½•è¿™æ¬¡è¿è¡Œçš„æ—¥å¿—ã€‚åŒæ—¶è¾“å‡ºå¼‚å¸¸ä¿¡æ¯eã€‚
        LOGGER.warning(f"WARNING âš ï¸ ClearML installed but not initialized correctly, not logging this run. {e}")
def on_train_epoch_end(trainer):
    """Logs debug samples for the first epoch of YOLO training and report current training progress."""
    # è·å–å½“å‰ä»»åŠ¡å¯¹è±¡ï¼Œå¦‚æœå­˜åœ¨
    if task := Task.current_task():
        # å¦‚æœå½“å‰æ˜¯ç¬¬ä¸€ä¸ª epochï¼Œåˆ™è®°å½•è°ƒè¯•æ ·æœ¬
        if trainer.epoch == 1:
            _log_debug_samples(sorted(trainer.save_dir.glob("train_batch*.jpg")), "Mosaic")
        # æŠ¥å‘Šå½“å‰è®­ç»ƒè¿›åº¦
        for k, v in trainer.label_loss_items(trainer.tloss, prefix="train").items():
            task.get_logger().report_scalar("train", k, v, iteration=trainer.epoch)
        # æŠ¥å‘Šå½“å‰å­¦ä¹ ç‡
        for k, v in trainer.lr.items():
            task.get_logger().report_scalar("lr", k, v, iteration=trainer.epoch)


def on_fit_epoch_end(trainer):
    """Reports model information to logger at the end of an epoch."""
    # è·å–å½“å‰ä»»åŠ¡å¯¹è±¡ï¼Œå¦‚æœå­˜åœ¨
    if task := Task.current_task():
        # æŠ¥å‘Šæ¯ä¸ª epoch çš„è€—æ—¶
        task.get_logger().report_scalar(
            title="Epoch Time", series="Epoch Time", value=trainer.epoch_time, iteration=trainer.epoch
        )
        # æŠ¥å‘ŠéªŒè¯æŒ‡æ ‡
        for k, v in trainer.metrics.items():
            task.get_logger().report_scalar("val", k, v, iteration=trainer.epoch)
        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ª epochï¼ŒæŠ¥å‘Šæ¨¡å‹ä¿¡æ¯ç»™æ—¥å¿—è®°å½•å™¨
        if trainer.epoch == 0:
            from ultralytics.utils.torch_utils import model_info_for_loggers

            for k, v in model_info_for_loggers(trainer).items():
                task.get_logger().report_single_value(k, v)


def on_val_end(validator):
    """Logs validation results including labels and predictions."""
    # å¦‚æœå­˜åœ¨å½“å‰ä»»åŠ¡å¯¹è±¡
    if Task.current_task():
        # è®°å½•éªŒè¯ç»“æœçš„æ ‡ç­¾å’Œé¢„æµ‹
        _log_debug_samples(sorted(validator.save_dir.glob("val*.jpg")), "Validation")


def on_train_end(trainer):
    """Logs final model and its name on training completion."""
    # è·å–å½“å‰ä»»åŠ¡å¯¹è±¡ï¼Œå¦‚æœå­˜åœ¨
    if task := Task.current_task():
        # è®°å½•æœ€ç»ˆç»“æœï¼Œå¦‚æ··æ·†çŸ©é˜µå’Œç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿
        files = [
            "results.png",
            "confusion_matrix.png",
            "confusion_matrix_normalized.png",
            *(f"{x}_curve.png" for x in ("F1", "PR", "P", "R")),
        ]
        # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
        files = [(trainer.save_dir / f) for f in files if (trainer.save_dir / f).exists()]  # filter
        for f in files:
            _log_plot(title=f.stem, plot_path=f)
        # æŠ¥å‘Šæœ€ç»ˆæŒ‡æ ‡
        for k, v in trainer.validator.metrics.results_dict.items():
            task.get_logger().report_single_value(k, v)
        # è®°å½•æœ€ç»ˆæ¨¡å‹
        task.update_output_model(model_path=str(trainer.best), model_name=trainer.args.name, auto_delete_file=False)


callbacks = (
    {
        "on_pretrain_routine_start": on_pretrain_routine_start,
        "on_train_epoch_end": on_train_epoch_end,
        "on_fit_epoch_end": on_fit_epoch_end,
        "on_val_end": on_val_end,
        "on_train_end": on_train_end,
    }
    if clearml
    else {}
)
```