# `.\yolov8\tests\test_integrations.py`

```
# Ultralytics YOLO ğŸš€, AGPL-3.0 license

# å¼•å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import contextlib
import os
import subprocess
import time
from pathlib import Path

import pytest

# ä»è‡ªå®šä¹‰çš„æ¨¡å—å¯¼å…¥å¸¸é‡å’Œå‡½æ•°
from tests import MODEL, SOURCE, TMP
from ultralytics import YOLO, download
from ultralytics.utils import DATASETS_DIR, SETTINGS
from ultralytics.utils.checks import check_requirements

# ä½¿ç”¨ pytest æ ‡è®°ï¼Œå½“æ¡ä»¶ä¸æ»¡è¶³æ—¶è·³è¿‡æµ‹è¯•
@pytest.mark.skipif(not check_requirements("ray", install=False), reason="ray[tune] not installed")
def test_model_ray_tune():
    """Tune YOLO model using Ray for hyperparameter optimization."""
    # è°ƒç”¨ YOLO ç±»æ¥è¿›è¡Œæ¨¡å‹è°ƒå‚
    YOLO("yolov8n-cls.yaml").tune(
        use_ray=True, data="imagenet10", grace_period=1, iterations=1, imgsz=32, epochs=1, plots=False, device="cpu"
    )

# ä½¿ç”¨ pytest æ ‡è®°ï¼Œå½“æ¡ä»¶ä¸æ»¡è¶³æ—¶è·³è¿‡æµ‹è¯•
@pytest.mark.skipif(not check_requirements("mlflow", install=False), reason="mlflow not installed")
def test_mlflow():
    """Test training with MLflow tracking enabled (see https://mlflow.org/ for details)."""
    # è®¾ç½® MLflow è·Ÿè¸ªå¼€å¯
    SETTINGS["mlflow"] = True
    # è°ƒç”¨ YOLO ç±»æ¥è¿›è¡Œæ¨¡å‹è®­ç»ƒ
    YOLO("yolov8n-cls.yaml").train(data="imagenet10", imgsz=32, epochs=3, plots=False, device="cpu")

# ä½¿ç”¨ pytest æ ‡è®°ï¼Œå½“æ¡ä»¶ä¸æ»¡è¶³æ—¶è·³è¿‡æµ‹è¯•
@pytest.mark.skipif(True, reason="Test failing in scheduled CI https://github.com/ultralytics/ultralytics/pull/8868")
@pytest.mark.skipif(not check_requirements("mlflow", install=False), reason="mlflow not installed")
def test_mlflow_keep_run_active():
    """Ensure MLflow run status matches MLFLOW_KEEP_RUN_ACTIVE environment variable settings."""
    import mlflow

    # è®¾ç½® MLflow è·Ÿè¸ªå¼€å¯
    SETTINGS["mlflow"] = True
    run_name = "Test Run"
    os.environ["MLFLOW_RUN"] = run_name

    # æµ‹è¯• MLFLOW_KEEP_RUN_ACTIVE=True çš„æƒ…å†µ
    os.environ["MLFLOW_KEEP_RUN_ACTIVE"] = "True"
    YOLO("yolov8n-cls.yaml").train(data="imagenet10", imgsz=32, epochs=1, plots=False, device="cpu")
    # è·å–å½“å‰ MLflow è¿è¡Œçš„çŠ¶æ€
    status = mlflow.active_run().info.status
    assert status == "RUNNING", "MLflow run should be active when MLFLOW_KEEP_RUN_ACTIVE=True"

    run_id = mlflow.active_run().info.run_id

    # æµ‹è¯• MLFLOW_KEEP_RUN_ACTIVE=False çš„æƒ…å†µ
    os.environ["MLFLOW_KEEP_RUN_ACTIVE"] = "False"
    YOLO("yolov8n-cls.yaml").train(data="imagenet10", imgsz=32, epochs=1, plots=False, device="cpu")
    # è·å–æŒ‡å®šè¿è¡Œ ID çš„ MLflow è¿è¡ŒçŠ¶æ€
    status = mlflow.get_run(run_id=run_id).info.status
    assert status == "FINISHED", "MLflow run should be ended when MLFLOW_KEEP_RUN_ACTIVE=False"

    # æµ‹è¯• MLFLOW_KEEP_RUN_ACTIVE æœªè®¾ç½®çš„æƒ…å†µ
    os.environ.pop("MLFLOW_KEEP_RUN_ACTIVE", None)
    YOLO("yolov8n-cls.yaml").train(data="imagenet10", imgsz=32, epochs=1, plots=False, device="cpu")
    # è·å–æŒ‡å®šè¿è¡Œ ID çš„ MLflow è¿è¡ŒçŠ¶æ€
    status = mlflow.get_run(run_id=run_id).info.status
    assert status == "FINISHED", "MLflow run should be ended by default when MLFLOW_KEEP_RUN_ACTIVE is not set"

# ä½¿ç”¨ pytest æ ‡è®°ï¼Œå½“æ¡ä»¶ä¸æ»¡è¶³æ—¶è·³è¿‡æµ‹è¯•
@pytest.mark.skipif(not check_requirements("tritonclient", install=False), reason="tritonclient[all] not installed")
def test_triton():
    """
    Test NVIDIA Triton Server functionalities with YOLO model.

    See https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver.
    """
    # æ£€æŸ¥ tritonclient æ˜¯å¦å®‰è£…
    check_requirements("tritonclient[all]")
    # å¯¼å…¥ Triton çš„æ¨ç†æœåŠ¡å™¨å®¢æˆ·ç«¯æ¨¡å—
    from tritonclient.http import InferenceServerClient  # noqa
    # Create variables
    model_name = "yolo"  # è®¾ç½®æ¨¡å‹åç§°ä¸º "yolo"
    triton_repo = TMP / "triton_repo"  # Tritonä»“åº“è·¯å¾„è®¾ä¸ºä¸´æ—¶æ–‡ä»¶ç›®å½•ä¸‹çš„ triton_repo æ–‡ä»¶å¤¹
    triton_model = triton_repo / model_name  # Tritonæ¨¡å‹è·¯å¾„ä¸º Tritonä»“åº“è·¯å¾„ä¸‹çš„æ¨¡å‹åç§°æ–‡ä»¶å¤¹è·¯å¾„

    # Export model to ONNX
    f = YOLO(MODEL).export(format="onnx", dynamic=True)  # å°†æ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼æ–‡ä»¶ï¼Œå¹¶ä¿å­˜è·¯å¾„åˆ°å˜é‡f

    # Prepare Triton repo
    (triton_model / "1").mkdir(parents=True, exist_ok=True)  # åœ¨ Tritonæ¨¡å‹è·¯å¾„ä¸‹åˆ›å»ºç‰ˆæœ¬å·ä¸º1çš„å­æ–‡ä»¶å¤¹ï¼Œè‹¥å­˜åœ¨åˆ™å¿½ç•¥
    Path(f).rename(triton_model / "1" / "model.onnx")  # å°†å¯¼å‡ºçš„ONNXæ¨¡å‹æ–‡ä»¶ç§»åŠ¨åˆ° Tritonæ¨¡å‹è·¯å¾„ä¸‹çš„ç‰ˆæœ¬1æ–‡ä»¶å¤¹ä¸­å‘½åä¸ºmodel.onnx
    (triton_model / "config.pbtxt").touch()  # åœ¨ Tritonæ¨¡å‹è·¯å¾„ä¸‹åˆ›å»ºä¸€ä¸ªåä¸ºconfig.pbtxtçš„ç©ºæ–‡ä»¶

    # Define image https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver
    tag = "nvcr.io/nvidia/tritonserver:23.09-py3"  # å®šä¹‰Dockeré•œåƒæ ‡ç­¾ä¸ºnvcr.io/nvidia/tritonserver:23.09-py3ï¼Œå¤§å°ä¸º6.4 GB

    # Pull the image
    subprocess.call(f"docker pull {tag}", shell=True)  # ä½¿ç”¨Dockerå‘½ä»¤æ‹‰å–æŒ‡å®šæ ‡ç­¾çš„é•œåƒ

    # Run the Triton server and capture the container ID
    container_id = (
        subprocess.check_output(
            f"docker run -d --rm -v {triton_repo}:/models -p 8000:8000 {tag} tritonserver --model-repository=/models",
            shell=True,
        )
        .decode("utf-8")
        .strip()
    )  # å¯åŠ¨ Triton æœåŠ¡å™¨ï¼Œå¹¶è·å–å®¹å™¨çš„ID

    # Wait for the Triton server to start
    triton_client = InferenceServerClient(url="localhost:8000", verbose=False, ssl=False)  # åˆ›å»º Triton å®¢æˆ·ç«¯å®ä¾‹è¿æ¥åˆ°æœ¬åœ°çš„ Triton æœåŠ¡å™¨ï¼Œç«¯å£ä¸º8000ï¼Œå…³é—­è¯¦ç»†ä¿¡æ¯è¾“å‡ºï¼Œä¸ä½¿ç”¨SSL

    # Wait until model is ready
    for _ in range(10):  # å¾ªç¯10æ¬¡
        with contextlib.suppress(Exception):  # å¿½ç•¥å¼‚å¸¸
            assert triton_client.is_model_ready(model_name)  # æ–­è¨€æ£€æŸ¥æ¨¡å‹æ˜¯å¦å‡†å¤‡å°±ç»ª
            break  # å¦‚æœæ¨¡å‹å°±ç»ªï¼Œè·³å‡ºå¾ªç¯
        time.sleep(1)  # ç­‰å¾…1ç§’é’Ÿ

    # Check Triton inference
    YOLO(f"http://localhost:8000/{model_name}", "detect")(SOURCE)  # ä½¿ç”¨å¯¼å‡ºçš„æ¨¡å‹è¿›è¡Œ Triton æ¨ç†ï¼Œä¼ å…¥å‚æ•°SOURCEä½œä¸ºè¾“å…¥

    # Kill and remove the container at the end of the test
    subprocess.call(f"docker kill {container_id}", shell=True)  # ä½¿ç”¨Dockerå‘½ä»¤ç»ˆæ­¢æŒ‡å®šIDçš„å®¹å™¨å¹¶åˆ é™¤
@pytest.mark.skipif(not check_requirements("pycocotools", install=False), reason="pycocotools not installed")
def test_pycocotools():
    """Validate YOLO model predictions on COCO dataset using pycocotools."""
    from ultralytics.models.yolo.detect import DetectionValidator
    from ultralytics.models.yolo.pose import PoseValidator
    from ultralytics.models.yolo.segment import SegmentationValidator

    # Download annotations after each dataset downloads first
    url = "https://github.com/ultralytics/assets/releases/download/v8.2.0/"

    # è®¾ç½®æ£€æµ‹æ¨¡å‹çš„å‚æ•°å’Œåˆå§‹åŒ–æ£€æµ‹å™¨
    args = {"model": "yolov8n.pt", "data": "coco8.yaml", "save_json": True, "imgsz": 64}
    validator = DetectionValidator(args=args)
    # è¿è¡Œæ£€æµ‹å™¨ï¼Œæ‰§è¡Œè¯„ä¼°
    validator()
    # æ ‡è®°ä¸ºCOCOæ•°æ®é›†
    validator.is_coco = True
    # ä¸‹è½½å®ä¾‹æ³¨é‡Šæ–‡ä»¶
    download(f"{url}instances_val2017.json", dir=DATASETS_DIR / "coco8/annotations")
    # å¯¹è¯„ä¼°çš„JSONæ–‡ä»¶è¿›è¡Œè¯„ä¼°
    _ = validator.eval_json(validator.stats)

    # è®¾ç½®åˆ†å‰²æ¨¡å‹çš„å‚æ•°å’Œåˆå§‹åŒ–åˆ†å‰²å™¨
    args = {"model": "yolov8n-seg.pt", "data": "coco8-seg.yaml", "save_json": True, "imgsz": 64}
    validator = SegmentationValidator(args=args)
    # è¿è¡Œåˆ†å‰²å™¨ï¼Œæ‰§è¡Œè¯„ä¼°
    validator()
    # æ ‡è®°ä¸ºCOCOæ•°æ®é›†
    validator.is_coco = True
    # ä¸‹è½½å®ä¾‹æ³¨é‡Šæ–‡ä»¶
    download(f"{url}instances_val2017.json", dir=DATASETS_DIR / "coco8-seg/annotations")
    # å¯¹è¯„ä¼°çš„JSONæ–‡ä»¶è¿›è¡Œè¯„ä¼°
    _ = validator.eval_json(validator.stats)

    # è®¾ç½®å§¿åŠ¿ä¼°è®¡æ¨¡å‹çš„å‚æ•°å’Œåˆå§‹åŒ–å§¿åŠ¿ä¼°è®¡å™¨
    args = {"model": "yolov8n-pose.pt", "data": "coco8-pose.yaml", "save_json": True, "imgsz": 64}
    validator = PoseValidator(args=args)
    # è¿è¡Œå§¿åŠ¿ä¼°è®¡å™¨ï¼Œæ‰§è¡Œè¯„ä¼°
    validator()
    # æ ‡è®°ä¸ºCOCOæ•°æ®é›†
    validator.is_coco = True
    # ä¸‹è½½äººä½“å…³é”®ç‚¹æ³¨é‡Šæ–‡ä»¶
    download(f"{url}person_keypoints_val2017.json", dir=DATASETS_DIR / "coco8-pose/annotations")
    # å¯¹è¯„ä¼°çš„JSONæ–‡ä»¶è¿›è¡Œè¯„ä¼°
    _ = validator.eval_json(validator.stats)
```