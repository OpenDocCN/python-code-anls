# `.\yolov8\ultralytics\utils\callbacks\wb.py`

```
# Ultralytics YOLO ğŸš€, AGPL-3.0 license

# å¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œå˜é‡
from ultralytics.utils import SETTINGS, TESTS_RUNNING  # ä»ultralytics.utilsä¸­å¯¼å…¥SETTINGSå’ŒTESTS_RUNNINGå˜é‡
from ultralytics.utils.torch_utils import model_info_for_loggers  # ä»ultralytics.utils.torch_utilsä¸­å¯¼å…¥model_info_for_loggerså‡½æ•°

try:
    assert not TESTS_RUNNING  # ç¡®ä¿ä¸æ˜¯åœ¨è¿è¡Œæµ‹è¯•æ—¶è®°å½•æ—¥å¿—ï¼Œæ–­è¨€ä¸åº”è¯¥æ˜¯pytest
    assert SETTINGS["wandb"] is True  # éªŒè¯W&Bé›†æˆæ˜¯å¦å¯ç”¨

    # å°è¯•å¯¼å…¥å¹¶éªŒè¯wandbæ¨¡å—
    import wandb as wb
    assert hasattr(wb, "__version__")  # ç¡®ä¿wandbæ¨¡å—å·²ç»æ­£ç¡®å¯¼å…¥ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç›®å½•
    _processed_plots = {}

except (ImportError, AssertionError):
    wb = None  # å¦‚æœå¯¼å…¥å¤±è´¥æˆ–è€…æ–­è¨€å¤±è´¥ï¼Œåˆ™å°†wbè®¾ä¸ºNone


def _custom_table(x, y, classes, title="Precision Recall Curve", x_title="Recall", y_title="Precision"):
    """
    Create and log a custom metric visualization to wandb.plot.pr_curve.

    This function crafts a custom metric visualization that mimics the behavior of the default wandb precision-recall
    curve while allowing for enhanced customization. The visual metric is useful for monitoring model performance across
    different classes.

    Args:
        x (List): Values for the x-axis; expected to have length N.
        y (List): Corresponding values for the y-axis; also expected to have length N.
        classes (List): Labels identifying the class of each point; length N.
        title (str, optional): Title for the plot; defaults to 'Precision Recall Curve'.
        x_title (str, optional): Label for the x-axis; defaults to 'Recall'.
        y_title (str, optional): Label for the y-axis; defaults to 'Precision'.

    Returns:
        (wandb.Object): A wandb object suitable for logging, showcasing the crafted metric visualization.
    """
    import pandas  # ç”¨äºæ›´å¿«çš„å¯¼å…¥ultralyticsçš„ä½œç”¨åŸŸ

    # åˆ›å»ºä¸€ä¸ªåŒ…å«xã€yå’Œclassesçš„DataFrameå¯¹è±¡ï¼Œå¹¶ä¿ç•™å°æ•°ç‚¹åä¸‰ä½
    df = pandas.DataFrame({"class": classes, "y": y, "x": x}).round(3)
    fields = {"x": "x", "y": "y", "class": "class"}
    string_fields = {"title": title, "x-axis-title": x_title, "y-axis-title": y_title}
    
    # ä½¿ç”¨wandb.plot_tableå°†æ•°æ®è¡¨æ ¼åŒ–ï¼Œå¹¶æŒ‡å®šç›¸å…³å­—æ®µå’Œå­—ç¬¦ä¸²å­—æ®µ
    return wb.plot_table(
        "wandb/area-under-curve/v0", wb.Table(dataframe=df), fields=fields, string_fields=string_fields
    )


def _plot_curve(
    x,
    y,
    names=None,
    id="precision-recall",
    title="Precision Recall Curve",
    x_title="Recall",
    y_title="Precision",
    num_x=100,
    only_mean=False,
):
    """
    Log a metric curve visualization.

    This function generates a metric curve based on input data and logs the visualization to wandb.
    The curve can represent aggregated data (mean) or individual class data, depending on the 'only_mean' flag.
    """
    # å‡½æ•°ç”¨äºç”ŸæˆåŸºäºè¾“å…¥æ•°æ®çš„åº¦é‡æ›²çº¿ï¼Œå¹¶å°†å…¶è®°å½•åˆ°wandbä¸­
    pass  # è¯¥å‡½æ•°å½“å‰æ²¡æœ‰å®ç°ä»»ä½•åŠŸèƒ½ï¼Œåªæ˜¯ä¸€ä¸ªå ä½ç¬¦
    Args:
        x (np.ndarray): Data points for the x-axis with length N.
        y (np.ndarray): Corresponding data points for the y-axis with shape CxN, where C is the number of classes.
        names (list, optional): Names of the classes corresponding to the y-axis data; length C. Defaults to [].
        id (str, optional): Unique identifier for the logged data in wandb. Defaults to 'precision-recall'.
        title (str, optional): Title for the visualization plot. Defaults to 'Precision Recall Curve'.
        x_title (str, optional): Label for the x-axis. Defaults to 'Recall'.
        y_title (str, optional): Label for the y-axis. Defaults to 'Precision'.
        num_x (int, optional): Number of interpolated data points for visualization. Defaults to 100.
        only_mean (bool, optional): Flag to indicate if only the mean curve should be plotted. Defaults to True.

    Note:
        The function leverages the '_custom_table' function to generate the actual visualization.
    """
    import numpy as np

    # Create new x
    if names is None:
        names = []
    # Generate a new array of x values by linearly interpolating between the first and last x values
    x_new = np.linspace(x[0], x[-1], num_x).round(5)

    # Create arrays for logging
    # Convert x_new to a list for logging purposes
    x_log = x_new.tolist()
    # Interpolate the mean values of y across the new x values and convert to list for logging
    y_log = np.interp(x_new, x, np.mean(y, axis=0)).round(3).tolist()

    # Conditionally log either only the mean curve or all curves
    if only_mean:
        # Create a table with x and y data and log a line plot with WandB
        table = wb.Table(data=list(zip(x_log, y_log)), columns=[x_title, y_title])
        wb.run.log({title: wb.plot.line(table, x_title, y_title, title=title)})
    else:
        # Prepare to log multiple curves with individual class names
        classes = ["mean"] * len(x_log)
        for i, yi in enumerate(y):
            x_log.extend(x_new)  # Add new x values for the current class
            y_log.extend(np.interp(x_new, x, yi))  # Interpolate y values for the current class
            classes.extend([names[i]] * len(x_new))  # Append corresponding class names

        # Log a custom table visualization with WandB, without committing the log immediately
        wb.log({id: _custom_table(x_log, y_log, classes, title, x_title, y_title)}, commit=False)
# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè®°å½•æŒ‡å®šæ­¥éª¤ä¸­å°šæœªè®°å½•çš„è¾“å…¥å­—å…¸ä¸­çš„å›¾è¡¨
def _log_plots(plots, step):
    # ä½¿ç”¨æµ…æ‹·è´ä»¥é˜²æ­¢è¿­ä»£è¿‡ç¨‹ä¸­æ›´æ”¹ plots å­—å…¸
    for name, params in plots.copy().items():
        # è·å–å›¾è¡¨çš„æ—¶é—´æˆ³
        timestamp = params["timestamp"]
        # å¦‚æœæœªè®°å½•è¿‡è¿™ä¸ªå›¾è¡¨ï¼ˆæ ¹æ®æ—¶é—´æˆ³åˆ¤æ–­ï¼‰
        if _processed_plots.get(name) != timestamp:
            # è®°å½•å›¾è¡¨åˆ° wandb çš„è¿è¡Œæ—¥å¿—ä¸­ï¼Œä½¿ç”¨å›¾è¡¨åç§°ä½œä¸ºé”®ï¼Œå›¾åƒæ–‡ä»¶è·¯å¾„ä½œä¸ºå€¼
            wb.run.log({name.stem: wb.Image(str(name))}, step=step)
            # æ›´æ–°å·²å¤„ç†çš„å›¾è¡¨è®°å½•
            _processed_plots[name] = timestamp


# å½“è®­ç»ƒå‰ä¾‹ç¨‹å¼€å§‹æ—¶æ‰§è¡Œçš„å›è°ƒå‡½æ•°ï¼Œæ ¹æ®æ¨¡å—çš„å­˜åœ¨åˆå§‹åŒ–å¹¶å¯åŠ¨é¡¹ç›®
def on_pretrain_routine_start(trainer):
    # å¦‚æœ wb.run ä¸å­˜åœ¨ï¼Œåˆ™åˆå§‹åŒ–ä¸€ä¸ª wandb è¿è¡Œæ—¶
    wb.run or wb.init(project=trainer.args.project or "YOLOv8", name=trainer.args.name, config=vars(trainer.args))


# æ¯ä¸ªè®­ç»ƒå‘¨æœŸç»“æŸæ—¶è®°å½•è®­ç»ƒæŒ‡æ ‡å’Œæ¨¡å‹ä¿¡æ¯çš„å›è°ƒå‡½æ•°
def on_fit_epoch_end(trainer):
    # è®°å½•è®­ç»ƒæŒ‡æ ‡åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­ï¼Œä½¿ç”¨å½“å‰å‘¨æœŸæ•°ä½œä¸ºæ­¥éª¤
    wb.run.log(trainer.metrics, step=trainer.epoch + 1)
    # è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å›¾è¡¨åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­
    _log_plots(trainer.plots, step=trainer.epoch + 1)
    # è®°å½•éªŒè¯é›†çš„å›¾è¡¨åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­
    _log_plots(trainer.validator.plots, step=trainer.epoch + 1)
    # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªå‘¨æœŸï¼Œè®°å½•æ¨¡å‹ä¿¡æ¯åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­
    if trainer.epoch == 0:
        wb.run.log(model_info_for_loggers(trainer), step=trainer.epoch + 1)


# æ¯ä¸ªè®­ç»ƒå‘¨æœŸç»“æŸæ—¶è®°å½•æŒ‡æ ‡å’Œä¿å­˜å›¾åƒçš„å›è°ƒå‡½æ•°
def on_train_epoch_end(trainer):
    # è®°å½•è®­ç»ƒæŸå¤±é¡¹åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­ï¼Œä½¿ç”¨å½“å‰å‘¨æœŸæ•°ä½œä¸ºæ­¥éª¤
    wb.run.log(trainer.label_loss_items(trainer.tloss, prefix="train"), step=trainer.epoch + 1)
    # è®°å½•å½“å‰å­¦ä¹ ç‡åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­ï¼Œä½¿ç”¨å½“å‰å‘¨æœŸæ•°ä½œä¸ºæ­¥éª¤
    wb.run.log(trainer.lr, step=trainer.epoch + 1)
    # å¦‚æœæ˜¯ç¬¬äºŒä¸ªå‘¨æœŸï¼Œè®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å›¾è¡¨åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­
    if trainer.epoch == 1:
        _log_plots(trainer.plots, step=trainer.epoch + 1)


# è®­ç»ƒç»“æŸæ—¶ä¿å­˜æœ€ä½³æ¨¡å‹ä½œä¸º artifact çš„å›è°ƒå‡½æ•°
def on_train_end(trainer):
    # è®°å½•éªŒè¯é›†çš„å›¾è¡¨åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­ï¼Œä½¿ç”¨å½“å‰å‘¨æœŸæ•°ä½œä¸ºæ­¥éª¤
    _log_plots(trainer.validator.plots, step=trainer.epoch + 1)
    # è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å›¾è¡¨åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­ï¼Œä½¿ç”¨å½“å‰å‘¨æœŸæ•°ä½œä¸ºæ­¥éª¤
    _log_plots(trainer.plots, step=trainer.epoch + 1)
    # åˆ›å»ºä¸€ä¸ªç±»å‹ä¸º "model" çš„ artifactï¼Œç”¨äºä¿å­˜æœ€ä½³æ¨¡å‹
    art = wb.Artifact(type="model", name=f"run_{wb.run.id}_model")
    # å¦‚æœå­˜åœ¨æœ€ä½³æ¨¡å‹æ–‡ä»¶ï¼Œåˆ™å°†å…¶æ·»åŠ åˆ° artifact ä¸­
    if trainer.best.exists():
        art.add_file(trainer.best)
        # è®°å½• artifact åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­ï¼Œå¹¶æŒ‡å®šåˆ«åä¸º "best"
        wb.run.log_artifact(art, aliases=["best"])
    # éå†éªŒè¯é›†çš„æŒ‡æ ‡æ›²çº¿å¹¶ç»˜åˆ¶åˆ° wandb è¿è¡Œæ—¥å¿—ä¸­
    for curve_name, curve_values in zip(trainer.validator.metrics.curves, trainer.validator.metrics.curves_results):
        x, y, x_title, y_title = curve_values
        _plot_curve(
            x,
            y,
            names=list(trainer.validator.metrics.names.values()),
            id=f"curves/{curve_name}",
            title=curve_name,
            x_title=x_title,
            y_title=y_title,
        )
    # ç»“æŸ wandb è¿è¡Œæ—¥å¿—ï¼Œå¿…é¡»è°ƒç”¨ä»¥å®Œæˆè¿è¡Œ
    wb.run.finish()  # required or run continues on dashboard


# å®šä¹‰å›è°ƒå‡½æ•°é›†åˆï¼Œæ ¹æ® wandb æ˜¯å¦å¯ç”¨æ¥å†³å®šåŒ…å«å“ªäº›å›è°ƒå‡½æ•°
callbacks = (
    {
        "on_pretrain_routine_start": on_pretrain_routine_start,
        "on_train_epoch_end": on_train_epoch_end,
        "on_fit_epoch_end": on_fit_epoch_end,
        "on_train_end": on_train_end,
    }
    if wb  # å¦‚æœ wb å¯ç”¨ï¼Œåˆ™åŒ…å«ä¸Šè¿°å››ä¸ªå›è°ƒå‡½æ•°
    else {}  # å¦åˆ™ä¸ºç©ºå­—å…¸
)
```