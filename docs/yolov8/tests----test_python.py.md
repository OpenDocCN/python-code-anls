# `.\yolov8\tests\test_python.py`

```
# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import contextlib  # ä¸Šä¸‹æ–‡ç®¡ç†å·¥å…·
import urllib  # URL å¤„ç†æ¨¡å—
from copy import copy  # å¤åˆ¶å¯¹è±¡çš„æµ…æ‹·è´
from pathlib import Path  # å¤„ç†è·¯å¾„çš„å¯¹è±¡

import cv2  # OpenCV åº“
import numpy as np  # æ•°ç»„æ“ä½œåº“
import pytest  # æµ‹è¯•æ¡†æ¶
import torch  # PyTorch æ·±åº¦å­¦ä¹ åº“
import yaml  # YAML æ ¼å¼å¤„ç†åº“
from PIL import Image  # Python å›¾åƒåº“

from tests import CFG, IS_TMP_WRITEABLE, MODEL, SOURCE, TMP  # å¯¼å…¥æµ‹è¯•æ¨¡å—
from ultralytics import RTDETR, YOLO  # å¯¼å…¥ YOLO å’Œ RTDETR æ¨¡å‹ç±»
from ultralytics.cfg import MODELS, TASK2DATA, TASKS  # å¯¼å…¥é…ç½®ç›¸å…³æ¨¡å—
from ultralytics.data.build import load_inference_source  # å¯¼å…¥æ•°æ®æ„å»ºå‡½æ•°
from ultralytics.utils import (  # å¯¼å…¥å·¥å…·å‡½æ•°å’Œå˜é‡
    ASSETS,
    DEFAULT_CFG,
    DEFAULT_CFG_PATH,
    LOGGER,
    ONLINE,
    ROOT,
    WEIGHTS_DIR,
    WINDOWS,
    checks,
)
from ultralytics.utils.downloads import download  # å¯¼å…¥ä¸‹è½½å‡½æ•°
from ultralytics.utils.torch_utils import TORCH_1_9  # å¯¼å…¥ PyTorch å·¥å…·å‡½æ•°


def test_model_forward():
    """Test the forward pass of the YOLO model."""
    model = YOLO(CFG)  # ä½¿ç”¨ç»™å®šé…ç½®åˆ›å»º YOLO æ¨¡å‹å¯¹è±¡
    model(source=None, imgsz=32, augment=True)  # æµ‹è¯•ä¸åŒå‚æ•°çš„æ¨¡å‹å‰å‘ä¼ æ’­


def test_model_methods():
    """Test various methods and properties of the YOLO model to ensure correct functionality."""
    model = YOLO(MODEL)  # ä½¿ç”¨ç»™å®šæ¨¡å‹è·¯å¾„åˆ›å»º YOLO æ¨¡å‹å¯¹è±¡

    # Model methods
    model.info(verbose=True, detailed=True)  # è°ƒç”¨æ¨¡å‹çš„ä¿¡æ¯æ‰“å°æ–¹æ³•ï¼Œè¯¦ç»†å±•ç¤º
    model = model.reset_weights()  # é‡ç½®æ¨¡å‹çš„æƒé‡
    model = model.load(MODEL)  # åŠ è½½æŒ‡å®šæ¨¡å‹
    model.to("cpu")  # å°†æ¨¡å‹è½¬ç§»åˆ° CPU è®¾å¤‡
    model.fuse()  # èåˆæ¨¡å‹
    model.clear_callback("on_train_start")  # æ¸…é™¤æŒ‡å®šçš„å›è°ƒå‡½æ•°
    model.reset_callbacks()  # é‡ç½®æ‰€æœ‰å›è°ƒå‡½æ•°

    # Model properties
    _ = model.names  # è·å–æ¨¡å‹çš„ç±»åˆ«åç§°
    _ = model.device  # è·å–æ¨¡å‹å½“å‰è®¾å¤‡
    _ = model.transforms  # è·å–æ¨¡å‹çš„æ•°æ®è½¬æ¢
    _ = model.task_map  # è·å–æ¨¡å‹çš„ä»»åŠ¡æ˜ å°„


def test_model_profile():
    """Test profiling of the YOLO model with `profile=True` to assess performance and resource usage."""
    from ultralytics.nn.tasks import DetectionModel  # å¯¼å…¥æ£€æµ‹æ¨¡å‹ç±»

    model = DetectionModel()  # åˆ›å»ºæ£€æµ‹æ¨¡å‹å¯¹è±¡
    im = torch.randn(1, 3, 64, 64)  # åˆ›å»ºè¾“å…¥å¼ é‡
    _ = model.predict(im, profile=True)  # ä½¿ç”¨æ€§èƒ½åˆ†ææ¨¡å¼è¿›è¡Œæ¨¡å‹é¢„æµ‹


@pytest.mark.skipif(not IS_TMP_WRITEABLE, reason="directory is not writeable")
def test_predict_txt():
    """Tests YOLO predictions with file, directory, and pattern sources listed in a text file."""
    txt_file = TMP / "sources.txt"  # åˆ›å»ºä¸´æ—¶æ–‡ä»¶è·¯å¾„
    with open(txt_file, "w") as f:
        for x in [ASSETS / "bus.jpg", ASSETS, ASSETS / "*", ASSETS / "**/*.jpg"]:
            f.write(f"{x}\n")  # å°†å¤šç§æ•°æ®æºå†™å…¥æ–‡æœ¬æ–‡ä»¶

    _ = YOLO(MODEL)(source=txt_file, imgsz=32)  # ä½¿ç”¨æ–‡æœ¬æ–‡ä»¶ä¸­çš„æ•°æ®æºè¿›è¡Œ YOLO æ¨¡å‹é¢„æµ‹


@pytest.mark.parametrize("model_name", MODELS)
def test_predict_img(model_name):
    """Test YOLO model predictions on various image input types and sources, including online images."""
    model = YOLO(WEIGHTS_DIR / model_name)  # ä½¿ç”¨ç»™å®šæ¨¡å‹åç§°åŠ è½½ YOLO æ¨¡å‹

    im = cv2.imread(str(SOURCE))  # è¯»å–è¾“å…¥å›¾åƒä¸º numpy æ•°ç»„
    assert len(model(source=Image.open(SOURCE), save=True, verbose=True, imgsz=32)) == 1  # ä½¿ç”¨ PIL å›¾åƒè¿›è¡Œæ¨¡å‹é¢„æµ‹
    assert len(model(source=im, save=True, save_txt=True, imgsz=32)) == 1  # ä½¿ç”¨ numpy æ•°ç»„è¿›è¡Œæ¨¡å‹é¢„æµ‹
    assert len(model(torch.rand((2, 3, 32, 32)), imgsz=32)) == 2  # ä½¿ç”¨ Tensor æ•°æ®è¿›è¡Œæ‰¹å¤„ç†é¢„æµ‹
    assert len(model(source=[im, im], save=True, save_txt=True, imgsz=32)) == 2  # ä½¿ç”¨å¤šä¸ªè¾“å…¥è¿›è¡Œæ‰¹å¤„ç†é¢„æµ‹
    assert len(list(model(source=[im, im], save=True, stream=True, imgsz=32))) == 2  # ä½¿ç”¨æµå¼æ•°æ®è¿›è¡Œé¢„æµ‹
    assert len(model(torch.zeros(320, 640, 3).numpy().astype(np.uint8), imgsz=32)) == 1  # ä½¿ç”¨ Tensor è½¬æ¢ä¸º numpy æ•°ç»„è¿›è¡Œé¢„æµ‹
    batch = [
        str(SOURCE),  # å°† SOURCE è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å­˜å‚¨åœ¨åˆ—è¡¨ä¸­ï¼Œè¡¨ç¤ºæ–‡ä»¶å
        Path(SOURCE),  # ä½¿ç”¨ SOURCE åˆ›å»ºä¸€ä¸ª Path å¯¹è±¡ï¼Œå¹¶å­˜å‚¨åœ¨åˆ—è¡¨ä¸­ï¼Œè¡¨ç¤ºè·¯å¾„
        "https://github.com/ultralytics/assets/releases/download/v0.0.0/zidane.jpg" if ONLINE else SOURCE,  # å¦‚æœ ONLINE å˜é‡ä¸ºçœŸï¼Œåˆ™ä½¿ç”¨ GitHub ä¸Šçš„ URLï¼Œå¦åˆ™ä½¿ç”¨ SOURCE å˜é‡ï¼Œè¡¨ç¤ºç»Ÿä¸€èµ„æºæ ‡è¯†ç¬¦ï¼ˆURIï¼‰
        cv2.imread(str(SOURCE)),  # ä½¿ç”¨ OpenCV è¯»å– SOURCE å˜é‡æŒ‡å®šçš„å›¾åƒï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨åˆ—è¡¨ä¸­
        Image.open(SOURCE),  # ä½¿ç”¨ PIL åº“æ‰“å¼€ SOURCE å˜é‡æŒ‡å®šçš„å›¾åƒï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨åˆ—è¡¨ä¸­
        np.zeros((320, 640, 3), dtype=np.uint8),  # åˆ›å»ºä¸€ä¸ª 320x640 å¤§å°ï¼Œæ•°æ®ç±»å‹ä¸º uint8 çš„å…¨é›¶æ•°ç»„ï¼Œå¹¶å­˜å‚¨åœ¨åˆ—è¡¨ä¸­ï¼Œè¡¨ç¤ºä½¿ç”¨ numpy åº“
    ]
    assert len(model(batch, imgsz=32)) == len(batch)  # æ–­è¨€æ¨¡å‹å¤„ç†æ‰¹é‡æ•°æ®çš„è¾“å‡ºé•¿åº¦ä¸è¾“å…¥åˆ—è¡¨ batch çš„é•¿åº¦ç›¸åŒ
@pytest.mark.parametrize("model", MODELS)
def test_predict_visualize(model):
    """Test model prediction methods with 'visualize=True' to generate and display prediction visualizations."""
    # ä½¿ç”¨ä¸åŒçš„æ¨¡å‹å‚æ•°åŒ–æµ‹è¯•æ¨¡å‹çš„é¢„æµ‹æ–¹æ³•ï¼Œè®¾ç½® visualize=True ä»¥ç”Ÿæˆå’Œæ˜¾ç¤ºé¢„æµ‹çš„å¯è§†åŒ–ç»“æœ
    YOLO(WEIGHTS_DIR / model)(SOURCE, imgsz=32, visualize=True)


def test_predict_grey_and_4ch():
    """Test YOLO prediction on SOURCE converted to greyscale and 4-channel images with various filenames."""
    # æµ‹è¯• YOLO æ¨¡å‹åœ¨å°† SOURCE è½¬æ¢ä¸ºç°åº¦å›¾å’Œå››é€šé“å›¾åƒï¼Œå¹¶ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶åè¿›è¡Œæµ‹è¯•
    im = Image.open(SOURCE)
    directory = TMP / "im4"
    directory.mkdir(parents=True, exist_ok=True)

    source_greyscale = directory / "greyscale.jpg"
    source_rgba = directory / "4ch.png"
    source_non_utf = directory / "non_UTF_æµ‹è¯•æ–‡ä»¶_tÃ©st_image.jpg"
    source_spaces = directory / "image with spaces.jpg"

    im.convert("L").save(source_greyscale)  # å°†å›¾åƒè½¬æ¢ä¸ºç°åº¦å›¾å¹¶ä¿å­˜
    im.convert("RGBA").save(source_rgba)  # å°†å›¾åƒè½¬æ¢ä¸ºå››é€šé“ PNG å¹¶ä¿å­˜
    im.save(source_non_utf)  # ä½¿ç”¨åŒ…å«é UTF å­—ç¬¦çš„æ–‡ä»¶åä¿å­˜å›¾åƒ
    im.save(source_spaces)  # ä½¿ç”¨åŒ…å«ç©ºæ ¼çš„æ–‡ä»¶åä¿å­˜å›¾åƒ

    # æ¨æ–­è¿‡ç¨‹
    model = YOLO(MODEL)
    for f in source_rgba, source_greyscale, source_non_utf, source_spaces:
        for source in Image.open(f), cv2.imread(str(f)), f:
            # å¯¹æ¯ä¸ªæ–‡ä»¶è¿›è¡Œæ¨¡å‹é¢„æµ‹ï¼Œè®¾ç½® save=True å’Œ verbose=Trueï¼Œimgsz=32
            results = model(source, save=True, verbose=True, imgsz=32)
            assert len(results) == 1  # éªŒè¯æ˜¯å¦è¿è¡Œäº†ä¸€æ¬¡å›¾åƒé¢„æµ‹
        f.unlink()  # æ¸…ç†ç”Ÿæˆçš„ä¸´æ—¶æ–‡ä»¶


@pytest.mark.slow
@pytest.mark.skipif(not ONLINE, reason="environment is offline")
def test_youtube():
    """Test YOLO model on a YouTube video stream, handling potential network-related errors."""
    # åœ¨ YouTube è§†é¢‘æµä¸Šæµ‹è¯• YOLO æ¨¡å‹ï¼Œå¤„ç†å¯èƒ½å‡ºç°çš„ç½‘ç»œç›¸å…³é”™è¯¯
    model = YOLO(MODEL)
    try:
        model.predict("https://youtu.be/G17sBkb38XQ", imgsz=96, save=True)
    # å¤„ç†å› ç½‘ç»œè¿æ¥é—®é¢˜å¼•èµ·çš„é”™è¯¯ï¼Œä¾‹å¦‚ 'urllib.error.HTTPError: HTTP Error 429: Too Many Requests'
    except (urllib.error.HTTPError, ConnectionError) as e:
        LOGGER.warning(f"WARNING: YouTube Test Error: {e}")


@pytest.mark.skipif(not ONLINE, reason="environment is offline")
@pytest.mark.skipif(not IS_TMP_WRITEABLE, reason="directory is not writeable")
def test_track_stream():
    """
    Tests streaming tracking on a short 10 frame video using ByteTrack tracker and different GMC methods.

    Note imgsz=160 required for tracking for higher confidence and better matches.
    """
    # æµ‹è¯•åœ¨çŸ­10å¸§è§†é¢‘ä¸Šä½¿ç”¨ ByteTrack è·Ÿè¸ªå™¨å’Œä¸åŒçš„å…¨å±€è¿åŠ¨è¡¥å¿ï¼ˆGMCï¼‰æ–¹æ³•è¿›è¡Œå®æ—¶è·Ÿè¸ª

    video_url = "https://github.com/ultralytics/assets/releases/download/v0.0.0/decelera_portrait_min.mov"
    model = YOLO(MODEL)
    model.track(video_url, imgsz=160, tracker="bytetrack.yaml")  # ä½¿ç”¨ ByteTrack è·Ÿè¸ªå™¨è¿›è¡Œè·Ÿè¸ª
    model.track(video_url, imgsz=160, tracker="botsort.yaml", save_frames=True)  # æµ‹è¯•å¸§ä¿å­˜åŠŸèƒ½

    # æµ‹è¯•ä¸åŒçš„å…¨å±€è¿åŠ¨è¡¥å¿ï¼ˆGMCï¼‰æ–¹æ³•
    for gmc in "orb", "sift", "ecc":
        with open(ROOT / "cfg/trackers/botsort.yaml", encoding="utf-8") as f:
            data = yaml.safe_load(f)
        tracker = TMP / f"botsort-{gmc}.yaml"
        data["gmc_method"] = gmc
        with open(tracker, "w", encoding="utf-8") as f:
            yaml.safe_dump(data, f)
        model.track(video_url, imgsz=160, tracker=tracker)


def test_val():
    # è¿™æ˜¯ä¸€ä¸ªç©ºæµ‹è¯•å‡½æ•°ï¼Œæ²¡æœ‰ä»»ä½•ä»£ç å†…å®¹
    # ä½¿ç”¨ YOLO æ¨¡å‹çš„éªŒè¯æ¨¡å¼è¿›è¡Œæµ‹è¯•
    # å®ä¾‹åŒ– YOLO ç±»ï¼Œå¹¶è°ƒç”¨å…¶ val æ–¹æ³•ï¼Œä¼ å…¥ä»¥ä¸‹å‚æ•°ï¼š
    #   - data="coco8.yaml": æŒ‡å®šé…ç½®æ–‡ä»¶ä¸º "coco8.yaml"
    #   - imgsz=32: æŒ‡å®šå›¾åƒå°ºå¯¸ä¸º 32
    #   - save_hybrid=True: è®¾ç½®ä¿å­˜æ··åˆç»“æœä¸º True
    YOLO(MODEL).val(data="coco8.yaml", imgsz=32, save_hybrid=True)
def test_train_scratch():
    """Test training the YOLO model from scratch using the provided configuration."""
    # åˆ›å»ºä¸€ä¸ª YOLO æ¨¡å‹å¯¹è±¡ï¼Œä½¿ç”¨ç»™å®šçš„é…ç½® CFG
    model = YOLO(CFG)
    # ä½¿ç”¨æŒ‡å®šå‚æ•°è®­ç»ƒæ¨¡å‹ï¼šæ•°æ®ä¸º coco8.yamlï¼Œè®­ç»ƒå‘¨æœŸä¸º 2ï¼Œå›¾åƒå¤§å°ä¸º 32 åƒç´ ï¼Œç¼“å­˜æ–¹å¼ä¸ºç£ç›˜ï¼Œæ‰¹é‡å¤§å°ä¸º -1ï¼Œå…³é—­é©¬èµ›å…‹æ•ˆæœï¼Œå‘½åä¸º "model"
    model.train(data="coco8.yaml", epochs=2, imgsz=32, cache="disk", batch=-1, close_mosaic=1, name="model")
    # ä½¿ç”¨æ¨¡å‹å¤„ç† SOURCE æ•°æ®
    model(SOURCE)


def test_train_pretrained():
    """Test training of the YOLO model starting from a pre-trained checkpoint."""
    # åˆ›å»ºä¸€ä¸ª YOLO æ¨¡å‹å¯¹è±¡ï¼Œä»é¢„è®­ç»ƒçš„æ£€æŸ¥ç‚¹ WEIGHTS_DIR / "yolov8n-seg.pt" å¼€å§‹
    model = YOLO(WEIGHTS_DIR / "yolov8n-seg.pt")
    # ä½¿ç”¨æŒ‡å®šå‚æ•°è®­ç»ƒæ¨¡å‹ï¼šæ•°æ®ä¸º coco8-seg.yamlï¼Œè®­ç»ƒå‘¨æœŸä¸º 1ï¼Œå›¾åƒå¤§å°ä¸º 32 åƒç´ ï¼Œç¼“å­˜æ–¹å¼ä¸º RAMï¼Œå¤åˆ¶ç²˜è´´æ¦‚ç‡ä¸º 0.5ï¼Œæ··åˆæ¯”ä¾‹ä¸º 0.5ï¼Œå‘½åä¸º 0
    model.train(data="coco8-seg.yaml", epochs=1, imgsz=32, cache="ram", copy_paste=0.5, mixup=0.5, name=0)
    # ä½¿ç”¨æ¨¡å‹å¤„ç† SOURCE æ•°æ®
    model(SOURCE)


def test_all_model_yamls():
    """Test YOLO model creation for all available YAML configurations in the `cfg/models` directory."""
    # éå† cfg/models ç›®å½•ä¸‹æ‰€æœ‰çš„ YAML é…ç½®æ–‡ä»¶
    for m in (ROOT / "cfg" / "models").rglob("*.yaml"):
        # å¦‚æœæ–‡ä»¶ååŒ…å« "rtdetr"
        if "rtdetr" in m.name:
            # å¦‚æœä½¿ç”¨çš„æ˜¯ Torch ç‰ˆæœ¬ 1.9 åŠä»¥ä¸Š
            if TORCH_1_9:
                # åˆ›å»º RTDETR æ¨¡å‹å¯¹è±¡ï¼Œä¼ å…¥ m.name æ–‡ä»¶åï¼Œå¯¹ SOURCE æ•°æ®è¿›è¡Œå¤„ç†ï¼Œå›¾åƒå¤§å°ä¸º 640
                _ = RTDETR(m.name)(SOURCE, imgsz=640)  # å¿…é¡»ä¸º 640
        else:
            # åˆ›å»º YOLO æ¨¡å‹å¯¹è±¡ï¼Œä¼ å…¥ m.name æ–‡ä»¶å
            YOLO(m.name)


def test_workflow():
    """Test the complete workflow including training, validation, prediction, and exporting."""
    # åˆ›å»ºä¸€ä¸ª YOLO æ¨¡å‹å¯¹è±¡ï¼Œä½¿ç”¨æŒ‡å®šçš„ MODEL
    model = YOLO(MODEL)
    # è®­ç»ƒæ¨¡å‹ï¼šæ•°æ®ä¸º coco8.yamlï¼Œè®­ç»ƒå‘¨æœŸä¸º 1ï¼Œå›¾åƒå¤§å°ä¸º 32 åƒç´ ï¼Œä¼˜åŒ–å™¨é€‰æ‹© SGD
    model.train(data="coco8.yaml", epochs=1, imgsz=32, optimizer="SGD")
    # è¿›è¡Œæ¨¡å‹éªŒè¯ï¼Œå›¾åƒå¤§å°ä¸º 32 åƒç´ 
    model.val(imgsz=32)
    # å¯¹ SOURCE æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œå›¾åƒå¤§å°ä¸º 32 åƒç´ 
    model.predict(SOURCE, imgsz=32)
    # å¯¼å‡ºæ¨¡å‹ä¸º TorchScript æ ¼å¼
    model.export(format="torchscript")


def test_predict_callback_and_setup():
    """Test callback functionality during YOLO prediction setup and execution."""

    def on_predict_batch_end(predictor):
        """Callback function that handles operations at the end of a prediction batch."""
        # è·å– predictor.batch çš„è·¯å¾„ã€å›¾åƒå’Œæ‰¹é‡å¤§å°
        path, im0s, _ = predictor.batch
        # å°† im0s è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆå¦‚æœä¸æ˜¯ï¼‰ï¼Œä»¥ä¾¿å¤„ç†å¤šå›¾åƒæƒ…å†µ
        im0s = im0s if isinstance(im0s, list) else [im0s]
        # åˆ›å»ºä¸é¢„æµ‹ç»“æœã€å›¾åƒå’Œæ‰¹é‡å¤§å°ç›¸å…³è”çš„å…ƒç»„åˆ—è¡¨
        bs = [predictor.dataset.bs for _ in range(len(path))]
        predictor.results = zip(predictor.results, im0s, bs)  # results is List[batch_size]

    # åˆ›å»ºä¸€ä¸ª YOLO æ¨¡å‹å¯¹è±¡ï¼Œä½¿ç”¨æŒ‡å®šçš„ MODEL
    model = YOLO(MODEL)
    # æ·»åŠ  on_predict_batch_end å›è°ƒå‡½æ•°åˆ°æ¨¡å‹ä¸­
    model.add_callback("on_predict_batch_end", on_predict_batch_end)

    # åŠ è½½æ¨ç†æ•°æ®æºï¼Œè·å–æ•°æ®é›†çš„æ‰¹é‡å¤§å°
    dataset = load_inference_source(source=SOURCE)
    bs = dataset.bs  # noqa access predictor properties
    # å¯¹æ•°æ®é›†è¿›è¡Œé¢„æµ‹ï¼Œæµå¼å¤„ç†ï¼Œå›¾åƒå¤§å°ä¸º 160 åƒç´ 
    results = model.predict(dataset, stream=True, imgsz=160)  # source already setup
    # éå†é¢„æµ‹ç»“æœåˆ—è¡¨
    for r, im0, bs in results:
        # æ‰“å°å›¾åƒå½¢çŠ¶ä¿¡æ¯
        print("test_callback", im0.shape)
        # æ‰“å°æ‰¹é‡å¤§å°ä¿¡æ¯
        print("test_callback", bs)
        # è·å–é¢„æµ‹ç»“æœçš„è¾¹ç•Œæ¡†å¯¹è±¡
        boxes = r.boxes  # Boxes object for bbox outputs
        print(boxes)


@pytest.mark.parametrize("model", MODELS)
def test_results(model):
    """Ensure YOLO model predictions can be processed and printed in various formats."""
    # ä½¿ç”¨æŒ‡å®šæ¨¡å‹ WEIGHTS_DIR / model åˆ›å»º YOLO æ¨¡å‹å¯¹è±¡ï¼Œå¹¶å¯¹ SOURCE æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œå›¾åƒå¤§å°ä¸º 160 åƒç´ 
    results = YOLO(WEIGHTS_DIR / model)([SOURCE, SOURCE], imgsz=160)
    # éå†é¢„æµ‹ç»“æœåˆ—è¡¨
    for r in results:
        # å°†ç»“æœè½¬æ¢ä¸º CPU ä¸Šçš„ numpy æ•°ç»„
        r = r.cpu().numpy()
        # æ‰“å° numpy æ•°ç»„çš„å±æ€§ä¿¡æ¯åŠè·¯å¾„
        print(r, len(r), r.path)  # print numpy attributes
        # å°†ç»“æœè½¬æ¢ä¸º CPU ä¸Šçš„ torch.float32 ç±»å‹
        r = r.to(device="cpu", dtype=torch.float32)
        # å°†ç»“æœä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ï¼Œä¿å­˜ç½®ä¿¡åº¦ä¿¡æ¯
        r.save_txt(txt_file=TMP / "runs/tests/label.txt", save_conf=True)
        # å°†ç»“æœä¸­çš„åŒºåŸŸè£å‰ªä¿å­˜åˆ°æŒ‡å®šç›®å½•
        r.save_crop(save_dir=TMP / "runs/tests/crops/")
        # å°†ç»“æœè½¬æ¢ä¸º JSON æ ¼å¼ï¼Œå¹¶è¿›è¡Œè§„èŒƒåŒ–å¤„ç†
        r.tojson(normalize=True)
        # ç»˜åˆ¶ç»“æœçš„å›¾åƒï¼Œè¿”å› PIL å›¾åƒ
        r.plot(pil=True)
        # ç»˜åˆ¶ç»“æœçš„ç½®ä¿¡åº¦å›¾åŠè¾¹ç•Œæ¡†ä¿¡æ¯
        r.plot(conf=True, boxes=True)
        # å†æ¬¡æ‰“å°ç»“æœåŠè·¯å¾„ä¿¡æ¯
        print(r, len(r), r.path)  # print after methods


def test_labels_and_crops():
    # è¿™ä¸ªå‡½æ•°æ˜¯ç©ºçš„ï¼Œæœªæä¾›ä»£ç 
    pass
    """Test output from prediction args for saving YOLO detection labels and crops; ensures accurate saving."""
    # å®šä¹‰å›¾ç‰‡åˆ—è¡¨ï¼ŒåŒ…æ‹¬æºè·¯å¾„å’ŒæŒ‡å®šçš„å›¾åƒæ–‡ä»¶è·¯å¾„
    imgs = [SOURCE, ASSETS / "zidane.jpg"]
    # ä½¿ç”¨é¢„è®­ç»ƒçš„ YOLO æ¨¡å‹å¤„ç†å›¾åƒåˆ—è¡¨ï¼Œè®¾ç½®å›¾åƒå¤§å°ä¸º160ï¼Œä¿å­˜æ£€æµ‹ç»“æœçš„æ–‡æœ¬å’Œè£å‰ªå›¾åƒ
    results = YOLO(WEIGHTS_DIR / "yolov8n.pt")(imgs, imgsz=160, save_txt=True, save_crop=True)
    # ä¿å­˜è·¯å¾„ä¸ºç»“æœä¸­ç¬¬ä¸€ä¸ªå…ƒç´ çš„ä¿å­˜ç›®å½•
    save_path = Path(results[0].save_dir)
    # éå†æ¯ä¸ªç»“æœ
    for r in results:
        # æå–å›¾åƒæ–‡ä»¶åä½œä¸ºæ ‡ç­¾æ–‡ä»¶åçš„åŸºç¡€
        im_name = Path(r.path).stem
        # æå–æ¯ä¸ªæ£€æµ‹æ¡†çš„ç±»åˆ«ç´¢å¼•ï¼Œè½¬æ¢ä¸ºæ•´æ•°åˆ—è¡¨
        cls_idxs = r.boxes.cls.int().tolist()
        # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶è·¯å¾„æ˜¯å¦å­˜åœ¨
        labels = save_path / f"labels/{im_name}.txt"
        assert labels.exists()  # æ–­è¨€æ ‡ç­¾æ–‡ä»¶å­˜åœ¨
        # æ£€æŸ¥æ£€æµ‹ç»“æœçš„æ•°é‡æ˜¯å¦ä¸æ ‡ç­¾æ–‡ä»¶ä¸­çš„è¡Œæ•°åŒ¹é…
        assert len(r.boxes.data) == len([line for line in labels.read_text().splitlines() if line])
        # è·å–æ‰€æœ‰è£å‰ªå›¾åƒçš„è·¯å¾„
        crop_dirs = list((save_path / "crops").iterdir())
        crop_files = [f for p in crop_dirs for f in p.glob("*")]
        # æ–­è¨€æ¯ä¸ªç±»åˆ«ç´¢å¼•å¯¹åº”çš„è£å‰ªç›®å½•åœ¨è£å‰ªç›®å½•ä¸­å­˜åœ¨
        assert all(r.names.get(c) in {d.name for d in crop_dirs} for c in cls_idxs)
        # æ–­è¨€è£å‰ªæ–‡ä»¶æ•°é‡ä¸æ£€æµ‹æ¡†æ•°é‡ç›¸åŒ¹é…
        assert len([f for f in crop_files if im_name in f.name]) == len(r.boxes.data)
@pytest.mark.skipif(not ONLINE, reason="environment is offline")
# æ ‡è®°ä¸ºè·³è¿‡æµ‹è¯•ï¼Œå¦‚æœç¯å¢ƒå¤„äºç¦»çº¿çŠ¶æ€
def test_data_utils():
    """Test utility functions in ultralytics/data/utils.py, including dataset stats and auto-splitting."""
    # å¯¼å…¥éœ€è¦æµ‹è¯•çš„å‡½æ•°å’Œæ¨¡å—
    from ultralytics.data.utils import HUBDatasetStats, autosplit
    from ultralytics.utils.downloads import zip_directory

    # from ultralytics.utils.files import WorkingDirectory
    # with WorkingDirectory(ROOT.parent / 'tests'):

    # éå†ä»»åŠ¡åˆ—è¡¨ï¼Œè¿›è¡Œæµ‹è¯•
    for task in TASKS:
        # æ„å»ºæ•°æ®æ–‡ä»¶çš„è·¯å¾„ï¼Œä¾‹å¦‚ coco8.zip
        file = Path(TASK2DATA[task]).with_suffix(".zip")  # i.e. coco8.zip
        # ä¸‹è½½æ•°æ®æ–‡ä»¶
        download(f"https://github.com/ultralytics/hub/raw/main/example_datasets/{file}", unzip=False, dir=TMP)
        # åˆ›å»ºæ•°æ®é›†ç»Ÿè®¡å¯¹è±¡
        stats = HUBDatasetStats(TMP / file, task=task)
        # ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯çš„ JSON æ–‡ä»¶
        stats.get_json(save=True)
        # å¤„ç†å›¾åƒæ•°æ®
        stats.process_images()

    # è‡ªåŠ¨åˆ’åˆ†æ•°æ®é›†
    autosplit(TMP / "coco8")
    # å‹ç¼©æŒ‡å®šè·¯å¾„ä¸‹çš„æ–‡ä»¶å¤¹
    zip_directory(TMP / "coco8/images/val")  # zip


@pytest.mark.skipif(not ONLINE, reason="environment is offline")
# æ ‡è®°ä¸ºè·³è¿‡æµ‹è¯•ï¼Œå¦‚æœç¯å¢ƒå¤„äºç¦»çº¿çŠ¶æ€
def test_data_converter():
    """Test dataset conversion functions from COCO to YOLO format and class mappings."""
    # å¯¼å…¥éœ€è¦æµ‹è¯•çš„å‡½æ•°
    from ultralytics.data.converter import coco80_to_coco91_class, convert_coco

    # ä¸‹è½½ COCO æ•°æ®é›†çš„å®ä¾‹æ–‡ä»¶
    file = "instances_val2017.json"
    download(f"https://github.com/ultralytics/assets/releases/download/v0.0.0/{file}", dir=TMP)
    # å°† COCO æ•°æ®é›†è½¬æ¢ä¸º YOLO æ ¼å¼
    convert_coco(labels_dir=TMP, save_dir=TMP / "yolo_labels", use_segments=True, use_keypoints=False, cls91to80=True)
    # å°† COCO80 ç±»åˆ«æ˜ å°„ä¸º COCO91 ç±»åˆ«
    coco80_to_coco91_class()


def test_data_annotator():
    """Automatically annotate data using specified detection and segmentation models."""
    # å¯¼å…¥è‡ªåŠ¨æ ‡æ³¨æ•°æ®çš„å‡½æ•°
    from ultralytics.data.annotator import auto_annotate

    # ä½¿ç”¨æŒ‡å®šçš„æ£€æµ‹å’Œåˆ†å‰²æ¨¡å‹è‡ªåŠ¨æ ‡æ³¨æ•°æ®
    auto_annotate(
        ASSETS,
        det_model=WEIGHTS_DIR / "yolov8n.pt",
        sam_model=WEIGHTS_DIR / "mobile_sam.pt",
        output_dir=TMP / "auto_annotate_labels",
    )


def test_events():
    """Test event sending functionality."""
    # å¯¼å…¥äº‹ä»¶å‘é€åŠŸèƒ½æ¨¡å—
    from ultralytics.hub.utils import Events

    # åˆ›å»ºäº‹ä»¶å¯¹è±¡
    events = Events()
    events.enabled = True
    cfg = copy(DEFAULT_CFG)  # does not require deepcopy
    cfg.mode = "test"
    # å‘é€äº‹ä»¶
    events(cfg)


def test_cfg_init():
    """Test configuration initialization utilities from the 'ultralytics.cfg' module."""
    # å¯¼å…¥é…ç½®åˆå§‹åŒ–ç›¸å…³çš„å‡½æ•°
    from ultralytics.cfg import check_dict_alignment, copy_default_cfg, smart_value

    # æ£€æŸ¥å­—å…¸å¯¹é½æ€§
    with contextlib.suppress(SyntaxError):
        check_dict_alignment({"a": 1}, {"b": 2})
    # å¤åˆ¶é»˜è®¤é…ç½®
    copy_default_cfg()
    # åˆ é™¤å¤åˆ¶çš„é…ç½®æ–‡ä»¶
    (Path.cwd() / DEFAULT_CFG_PATH.name.replace(".yaml", "_copy.yaml")).unlink(missing_ok=False)
    # å¯¹å¤šä¸ªå€¼åº”ç”¨æ™ºèƒ½åŒ–å¤„ç†
    [smart_value(x) for x in ["none", "true", "false"]]


def test_utils_init():
    """Test initialization utilities in the Ultralytics library."""
    # å¯¼å…¥åˆå§‹åŒ–å·¥å…·å‡½æ•°
    from ultralytics.utils import get_git_branch, get_git_origin_url, get_ubuntu_version, is_github_action_running

    # è·å– Ubuntu ç‰ˆæœ¬ä¿¡æ¯
    get_ubuntu_version()
    # æ£€æŸ¥æ˜¯å¦åœ¨ GitHub Action ç¯å¢ƒä¸‹è¿è¡Œ
    is_github_action_running()
    # è·å– Git ä»“åº“çš„è¿œç¨‹ URL
    get_git_origin_url()
    # è·å– Git åˆ†æ”¯ä¿¡æ¯
    get_git_branch()


def test_utils_checks():
    """Test various utility checks for filenames, git status, requirements, image sizes, and versions."""
    # å¯¼å…¥å„ç§æ£€æŸ¥å‡½æ•°
    from ultralytics.utils import checks

    # æ£€æŸ¥ YOLOv5u æ–‡ä»¶åæ ¼å¼
    checks.check_yolov5u_filename("yolov5n.pt")
    # æ£€æŸ¥ Git ä»“åº“çŠ¶æ€
    checks.git_describe(ROOT)
    # æ£€æŸ¥é¡¹ç›®çš„è¦æ±‚æ˜¯å¦ç¬¦åˆ requirements.txt ä¸­æŒ‡å®šçš„ä¾èµ–
    checks.check_requirements()  # check requirements.txt
    
    # æ£€æŸ¥å›¾åƒå¤§å°æ˜¯å¦åœ¨æŒ‡å®šèŒƒå›´å†…ï¼Œç¡®ä¿å®½åº¦å’Œé«˜åº¦å‡ä¸è¶…è¿‡ 600 åƒç´ 
    checks.check_imgsz([600, 600], max_dim=1)
    
    # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ˜¾ç¤ºå›¾åƒï¼Œè‹¥ä¸èƒ½æ˜¾ç¤ºåˆ™å‘å‡ºè­¦å‘Š
    checks.check_imshow(warn=True)
    
    # æ£€æŸ¥æŒ‡å®šæ¨¡å—çš„ç‰ˆæœ¬æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Œè¿™é‡Œæ£€æŸ¥ ultralytics æ¨¡å—æ˜¯å¦è‡³å°‘æ˜¯ 8.0.0 ç‰ˆæœ¬
    checks.check_version("ultralytics", "8.0.0")
    
    # æ‰“å°å½“å‰è®¾ç½®å’Œå‚æ•°ï¼Œç”¨äºè°ƒè¯•å’Œç¡®è®¤è¿è¡Œæ—¶çš„é…ç½®
    checks.print_args()
@pytest.mark.skipif(WINDOWS, reason="Windows profiling is extremely slow (cause unknown)")
# å¦‚æœåœ¨ Windows ä¸‹è¿è¡Œï¼Œè·³è¿‡æ­¤æµ‹è¯•ï¼ŒåŸå› æ˜¯ Windows ä¸Šçš„æ€§èƒ½åˆ†æéå¸¸ç¼“æ…¢ï¼ˆåŸå› ä¸æ˜ï¼‰
def test_utils_benchmarks():
    """Benchmark model performance using 'ProfileModels' from 'ultralytics.utils.benchmarks'."""
    # å¯¼å…¥æ€§èƒ½åˆ†æå·¥å…· 'ProfileModels' æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½
    from ultralytics.utils.benchmarks import ProfileModels

    # ä½¿ç”¨ ProfileModels ç±»æ¥å¯¹ 'yolov8n.yaml' æ¨¡å‹è¿›è¡Œæ€§èƒ½åˆ†æï¼Œè®¾ç½®å›¾åƒå¤§å°ä¸º 32ï¼Œæœ€å°è¿è¡Œæ—¶é—´ä¸º 1 ç§’ï¼Œè¿è¡Œ 3 æ¬¡ï¼Œé¢„çƒ­ 1 æ¬¡
    ProfileModels(["yolov8n.yaml"], imgsz=32, min_time=1, num_timed_runs=3, num_warmup_runs=1).profile()


def test_utils_torchutils():
    """Test Torch utility functions including profiling and FLOP calculations."""
    # å¯¼å…¥ç›¸å…³æ¨¡å—å’Œå‡½æ•°è¿›è¡Œæµ‹è¯•ï¼ŒåŒ…æ‹¬æ€§èƒ½åˆ†æå’Œ FLOP è®¡ç®—
    from ultralytics.nn.modules.conv import Conv
    from ultralytics.utils.torch_utils import get_flops_with_torch_profiler, profile, time_sync

    # åˆ›å»ºä¸€ä¸ªéšæœºå¼ é‡ä½œä¸ºè¾“å…¥
    x = torch.randn(1, 64, 20, 20)
    # åˆ›å»ºä¸€ä¸ª Conv æ¨¡å‹å®ä¾‹
    m = Conv(64, 64, k=1, s=2)

    # ä½¿ç”¨ profile å‡½æ•°å¯¹æ¨¡å‹ m è¿›è¡Œæ€§èƒ½åˆ†æï¼Œè¿è¡Œ 3 æ¬¡
    profile(x, [m], n=3)
    # ä½¿ç”¨ get_flops_with_torch_profiler å‡½æ•°è·å–æ¨¡å‹ m çš„ FLOP
    get_flops_with_torch_profiler(m)
    # æ‰§è¡Œæ—¶é—´åŒæ­¥æ“ä½œ
    time_sync()


@pytest.mark.slow
@pytest.mark.skipif(not ONLINE, reason="environment is offline")
# å¦‚æœå¤„äºç¦»çº¿ç¯å¢ƒï¼Œè·³è¿‡æ­¤æµ‹è¯•
def test_utils_downloads():
    """Test file download utilities from ultralytics.utils.downloads."""
    # å¯¼å…¥æ–‡ä»¶ä¸‹è½½å·¥å…·å‡½æ•° get_google_drive_file_info
    from ultralytics.utils.downloads import get_google_drive_file_info

    # è°ƒç”¨ get_google_drive_file_info å‡½æ•°ä¸‹è½½ç‰¹å®š Google Drive æ–‡ä»¶çš„ä¿¡æ¯
    get_google_drive_file_info("https://drive.google.com/file/d/1cqT-cJgANNrhIHCrEufUYhQ4RqiWG_lJ/view?usp=drive_link")


def test_utils_ops():
    """Test utility operations functions for coordinate transformation and normalization."""
    # å¯¼å…¥åæ ‡è½¬æ¢å’Œå½’ä¸€åŒ–ç­‰æ“ä½œå‡½æ•°
    from ultralytics.utils.ops import (
        ltwh2xywh,
        ltwh2xyxy,
        make_divisible,
        xywh2ltwh,
        xywh2xyxy,
        xywhn2xyxy,
        xywhr2xyxyxyxy,
        xyxy2ltwh,
        xyxy2xywh,
        xyxy2xywhn,
        xyxyxyxy2xywhr,
    )

    # ä½¿ç”¨ make_divisible å‡½æ•°ï¼Œç¡®ä¿ 17 èƒ½å¤Ÿè¢« 8 æ•´é™¤
    make_divisible(17, torch.tensor([8]))

    # åˆ›å»ºéšæœºæ¡†åæ ‡å¼ é‡
    boxes = torch.rand(10, 4)  # xywh
    # æ£€æŸ¥é€šè¿‡ xywh2xyxy å’Œ xyxy2xywh å‡½æ•°çš„è½¬æ¢åçš„å¼ é‡æ˜¯å¦ç›¸ç­‰
    torch.allclose(boxes, xyxy2xywh(xywh2xyxy(boxes)))
    # æ£€æŸ¥é€šè¿‡ xywhn2xyxy å’Œ xyxy2xywhn å‡½æ•°çš„è½¬æ¢åçš„å¼ é‡æ˜¯å¦ç›¸ç­‰
    torch.allclose(boxes, xyxy2xywhn(xywhn2xyxy(boxes)))
    # æ£€æŸ¥é€šè¿‡ ltwh2xywh å’Œ xywh2ltwh å‡½æ•°çš„è½¬æ¢åçš„å¼ é‡æ˜¯å¦ç›¸ç­‰
    torch.allclose(boxes, ltwh2xywh(xywh2ltwh(boxes)))
    # æ£€æŸ¥é€šè¿‡ xyxy2ltwh å’Œ ltwh2xyxy å‡½æ•°çš„è½¬æ¢åçš„å¼ é‡æ˜¯å¦ç›¸ç­‰
    torch.allclose(boxes, xyxy2ltwh(ltwh2xyxy(boxes)))

    # åˆ›å»ºå¸¦æœ‰æ–¹å‘ä¿¡æ¯çš„éšæœºæ¡†åæ ‡å¼ é‡
    boxes = torch.rand(10, 5)  # xywhr for OBB
    # éšæœºç”Ÿæˆæ–¹å‘ä¿¡æ¯
    boxes[:, 4] = torch.randn(10) * 30
    # æ£€æŸ¥é€šè¿‡ xywhr2xyxyxyxy å’Œ xyxyxyxy2xywhr å‡½æ•°çš„è½¬æ¢åçš„å¼ é‡æ˜¯å¦ç›¸ç­‰ï¼Œç›¸å¯¹è¯¯å·®å®¹å¿åº¦ä¸º 1e-3
    torch.allclose(boxes, xyxyxyxy2xywhr(xywhr2xyxyxyxy(boxes)), rtol=1e-3)


def test_utils_files():
    """Test file handling utilities including file age, date, and paths with spaces."""
    # å¯¼å…¥æ–‡ä»¶å¤„ç†å·¥å…·å‡½æ•°ï¼ŒåŒ…æ‹¬æ–‡ä»¶å¹´é¾„ã€æ—¥æœŸå’Œå¸¦ç©ºæ ¼è·¯å¾„çš„å¤„ç†
    from ultralytics.utils.files import file_age, file_date, get_latest_run, spaces_in_path

    # è·å–æŒ‡å®šæ–‡ä»¶çš„å¹´é¾„
    file_age(SOURCE)
    # è·å–æŒ‡å®šæ–‡ä»¶çš„æ—¥æœŸ
    file_date(SOURCE)
    # è·å–æ ¹ç›®å½•ä¸‹è¿è¡Œè®°å½•çš„æœ€æ–°ä¸€æ¬¡è¿è¡Œ
    get_latest_run(ROOT / "runs")

    # åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ç©ºæ ¼è·¯å¾„çš„ä¸´æ—¶ç›®å½•
    path = TMP / "path/with spaces"
    path.mkdir(parents=True, exist_ok=True)
    # åœ¨å¸¦æœ‰ç©ºæ ¼è·¯å¾„çš„ä¸´æ—¶ç›®å½•ä¸­æ‰§è¡Œ spaces_in_path å‡½æ•°ï¼Œè¿”å›å¤„ç†åçš„æ–°è·¯å¾„å¹¶æ‰“å°
    with spaces_in_path(path) as new_path:
        print(new_path)


@pytest.mark.slow
def test_utils_patches_torch_save():
    """Test torch_save backoff when _torch_save raises RuntimeError to ensure robustness."""
    # å¯¼å…¥æµ‹è¯•å‡½æ•°å’Œ mock
    from unittest.mock import MagicMock, patch

    # å¯¼å…¥è¦æµ‹è¯•çš„å‡½æ•° torch_save
    from ultralytics.utils.patches import torch_save

    # åˆ›å»ºä¸€ä¸ª mock å¯¹è±¡ï¼Œæ¨¡æ‹Ÿ RuntimeError å¼‚å¸¸
    mock = MagicMock(side_effect=RuntimeError)

    # ä½¿ç”¨ patch æ›¿æ¢ _torch_save å‡½æ•°ï¼Œä½¿å…¶åœ¨è°ƒç”¨æ—¶æŠ›å‡º RuntimeError å¼‚å¸¸
    with patch("ultralytics.utils.patches._torch_save", new=mock):
        # æ–­è¨€è°ƒç”¨ torch_save å‡½æ•°æ—¶ä¼šæŠ›å‡º RuntimeError å¼‚å¸¸
        with pytest.raises(RuntimeError):
            torch_save(torch.zeros(1), TMP / "test.pt")
    # æ–­è¨€ï¼ŒéªŒè¯ mock å¯¹è±¡çš„æ–¹æ³•è¢«è°ƒç”¨çš„æ¬¡æ•°æ˜¯å¦ç­‰äº 4
    assert mock.call_count == 4, "torch_save was not attempted the expected number of times"
def test_nn_modules_conv():
    """Test Convolutional Neural Network modules including CBAM, Conv2, and ConvTranspose."""
    from ultralytics.nn.modules.conv import CBAM, Conv2, ConvTranspose, DWConvTranspose2d, Focus

    c1, c2 = 8, 16  # è¾“å…¥é€šé“æ•°å’Œè¾“å‡ºé€šé“æ•°
    x = torch.zeros(4, c1, 10, 10)  # BCHWï¼Œåˆ›å»ºä¸€ä¸ªå¤§å°ä¸º4x8x10x10çš„å¼ é‡ï¼ˆæ‰¹é‡å¤§å°xé€šé“æ•°xé«˜åº¦xå®½åº¦ï¼‰

    # è¿è¡Œæ‰€æœ‰æœªåœ¨æµ‹è¯•ä¸­æ¶µç›–çš„æ¨¡å—
    DWConvTranspose2d(c1, c2)(x)  # ä½¿ç”¨DWConvTranspose2dè¿›è¡Œè½¬ç½®å·ç§¯æ“ä½œ
    ConvTranspose(c1, c2)(x)  # ä½¿ç”¨ConvTransposeè¿›è¡Œè½¬ç½®å·ç§¯æ“ä½œ
    Focus(c1, c2)(x)  # ä½¿ç”¨Focusæ¨¡å—å¤„ç†è¾“å…¥
    CBAM(c1)(x)  # ä½¿ç”¨CBAMæ¨¡å—å¤„ç†è¾“å…¥

    # åˆå¹¶æ“ä½œ
    m = Conv2(c1, c2)  # åˆ›å»ºConv2å¯¹è±¡
    m.fuse_convs()  # èåˆå·ç§¯æ“ä½œ
    m(x)  # å¯¹è¾“å…¥xè¿›è¡ŒConv2æ“ä½œ


def test_nn_modules_block():
    """Test various blocks in neural network modules including C1, C3TR, BottleneckCSP, C3Ghost, and C3x."""
    from ultralytics.nn.modules.block import C1, C3TR, BottleneckCSP, C3Ghost, C3x

    c1, c2 = 8, 16  # è¾“å…¥é€šé“æ•°å’Œè¾“å‡ºé€šé“æ•°
    x = torch.zeros(4, c1, 10, 10)  # BCHWï¼Œåˆ›å»ºä¸€ä¸ªå¤§å°ä¸º4x8x10x10çš„å¼ é‡ï¼ˆæ‰¹é‡å¤§å°xé€šé“æ•°xé«˜åº¦xå®½åº¦ï¼‰

    # è¿è¡Œæ‰€æœ‰æœªåœ¨æµ‹è¯•ä¸­æ¶µç›–çš„æ¨¡å—
    C1(c1, c2)(x)  # ä½¿ç”¨C1æ¨¡å—å¤„ç†è¾“å…¥
    C3x(c1, c2)(x)  # ä½¿ç”¨C3xæ¨¡å—å¤„ç†è¾“å…¥
    C3TR(c1, c2)(x)  # ä½¿ç”¨C3TRæ¨¡å—å¤„ç†è¾“å…¥
    C3Ghost(c1, c2)(x)  # ä½¿ç”¨C3Ghostæ¨¡å—å¤„ç†è¾“å…¥
    BottleneckCSP(c1, c2)(x)  # ä½¿ç”¨BottleneckCSPæ¨¡å—å¤„ç†è¾“å…¥


@pytest.mark.skipif(not ONLINE, reason="environment is offline")
def test_hub():
    """Test Ultralytics HUB functionalities (e.g. export formats, logout)."""
    from ultralytics.hub import export_fmts_hub, logout
    from ultralytics.hub.utils import smart_request

    export_fmts_hub()  # è°ƒç”¨å¯¼å‡ºæ ¼å¼å‡½æ•°
    logout()  # æ‰§è¡Œæ³¨é”€æ“ä½œ
    smart_request("GET", "https://github.com", progress=True)  # å‘èµ·ä¸€ä¸ªGETè¯·æ±‚è‡³GitHub


@pytest.fixture
def image():
    """Load and return an image from a predefined source using OpenCV."""
    return cv2.imread(str(SOURCE))  # ä½¿ç”¨OpenCVä»é¢„å®šä¹‰æºåŠ è½½å¹¶è¿”å›ä¸€å¼ å›¾åƒ


@pytest.mark.parametrize(
    "auto_augment, erasing, force_color_jitter",
    [
        (None, 0.0, False),
        ("randaugment", 0.5, True),
        ("augmix", 0.2, False),
        ("autoaugment", 0.0, True),
    ],
)
def test_classify_transforms_train(image, auto_augment, erasing, force_color_jitter):
    """Tests classification transforms during training with various augmentations to ensure proper functionality."""
    from ultralytics.data.augment import classify_augmentations

    transform = classify_augmentations(
        size=224,
        mean=(0.5, 0.5, 0.5),
        std=(0.5, 0.5, 0.5),
        scale=(0.08, 1.0),
        ratio=(3.0 / 4.0, 4.0 / 3.0),
        hflip=0.5,
        vflip=0.5,
        auto_augment=auto_augment,
        hsv_h=0.015,
        hsv_s=0.4,
        hsv_v=0.4,
        force_color_jitter=force_color_jitter,
        erasing=erasing,
    )

    transformed_image = transform(Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)))

    assert transformed_image.shape == (3, 224, 224)  # æ–­è¨€è½¬æ¢åå›¾åƒçš„å½¢çŠ¶ä¸º(3, 224, 224)
    assert torch.is_tensor(transformed_image)  # æ–­è¨€è½¬æ¢åå›¾åƒæ˜¯ä¸€ä¸ªPyTorchå¼ é‡
    assert transformed_image.dtype == torch.float32  # æ–­è¨€è½¬æ¢åå›¾åƒçš„æ•°æ®ç±»å‹ä¸ºtorch.float32


@pytest.mark.slow
@pytest.mark.skipif(not ONLINE, reason="environment is offline")
def test_model_tune():
    """Tune YOLO model for performance improvement."""
    YOLO("yolov8n-pose.pt").tune(data="coco8-pose.yaml", plots=False, imgsz=32, epochs=1, iterations=2, device="cpu")
    # ä½¿ç”¨ YOLO æ¨¡å‹åŠ è½½ "yolov8n-cls.pt" æƒé‡æ–‡ä»¶ï¼Œå¹¶è¿›è¡Œè°ƒå‚å’Œå¾®è°ƒ
    YOLO("yolov8n-cls.pt").tune(data="imagenet10", plots=False, imgsz=32, epochs=1, iterations=2, device="cpu")
# å®šä¹‰æµ‹è¯•å‡½æ•°ï¼Œç”¨äºæµ‹è¯•æ¨¡å‹åµŒå…¥ï¼ˆembeddingsï¼‰
def test_model_embeddings():
    """Test YOLO model embeddings."""
    # åˆ›å»º YOLO æ£€æµ‹æ¨¡å‹å¯¹è±¡ï¼Œä½¿ç”¨æŒ‡å®šæ¨¡å‹
    model_detect = YOLO(MODEL)
    # åˆ›å»º YOLO åˆ†å‰²æ¨¡å‹å¯¹è±¡ï¼Œä½¿ç”¨æŒ‡å®šæƒé‡æ–‡ä»¶
    model_segment = YOLO(WEIGHTS_DIR / "yolov8n-seg.pt")

    # åˆ†åˆ«æµ‹è¯•æ‰¹æ¬¡å¤§å°ä¸º1å’Œ2çš„æƒ…å†µ
    for batch in [SOURCE], [SOURCE, SOURCE]:  # test batch size 1 and 2
        # æ–­è¨€æ£€æµ‹æ¨¡å‹è¿”å›çš„åµŒå…¥ç‰¹å¾é•¿åº¦ä¸æ‰¹æ¬¡å¤§å°ç›¸åŒ
        assert len(model_detect.embed(source=batch, imgsz=32)) == len(batch)
        # æ–­è¨€åˆ†å‰²æ¨¡å‹è¿”å›çš„åµŒå…¥ç‰¹å¾é•¿åº¦ä¸æ‰¹æ¬¡å¤§å°ç›¸åŒ
        assert len(model_segment.embed(source=batch, imgsz=32)) == len(batch)


# ä½¿ç”¨ pytest.mark.skipif æ ‡è®°ï¼Œå¦‚æœæ¡ä»¶æ»¡è¶³ï¼Œåˆ™è·³è¿‡è¯¥æµ‹è¯•
@pytest.mark.skipif(checks.IS_PYTHON_3_12, reason="YOLOWorld with CLIP is not supported in Python 3.12")
# å®šä¹‰æµ‹è¯•å‡½æ•°ï¼Œæµ‹è¯•æ”¯æŒ CLIP çš„ YOLO æ¨¡å‹
def test_yolo_world():
    """Tests YOLO world models with CLIP support, including detection and training scenarios."""
    # åˆ›å»º YOLO World æ¨¡å‹å¯¹è±¡ï¼ŒåŠ è½½æŒ‡å®šæ¨¡å‹
    model = YOLO("yolov8s-world.pt")  # no YOLOv8n-world model yet
    # è®¾ç½®æ¨¡å‹çš„åˆ†ç±»ç±»åˆ«ä¸º ["tree", "window"]
    model.set_classes(["tree", "window"])
    # è¿è¡Œæ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œè®¾å®šç½®ä¿¡åº¦é˜ˆå€¼ä¸º 0.01
    model(SOURCE, conf=0.01)

    # åˆ›å»º YOLO Worldv2 æ¨¡å‹å¯¹è±¡ï¼ŒåŠ è½½æŒ‡å®šæ¨¡å‹
    model = YOLO("yolov8s-worldv2.pt")  # no YOLOv8n-world model yet
    # ä»é¢„è®­ç»ƒæ¨¡å‹å¼€å§‹è®­ç»ƒï¼Œæœ€åé˜¶æ®µåŒ…æ‹¬è¯„ä¼°
    # ä½¿ç”¨ dota8.yamlï¼Œè¯¥æ–‡ä»¶å°‘é‡ç±»åˆ«ä»¥å‡å°‘ CLIP æ¨¡å‹æ¨ç†æ—¶é—´
    model.train(
        data="dota8.yaml",
        epochs=1,
        imgsz=32,
        cache="disk",
        close_mosaic=1,
    )

    # æµ‹è¯• WorWorldTrainerFromScratch
    from ultralytics.models.yolo.world.train_world import WorldTrainerFromScratch

    # åˆ›å»º YOLO Worldv2 æ¨¡å‹å¯¹è±¡ï¼ŒåŠ è½½æŒ‡å®šæ¨¡å‹
    model = YOLO("yolov8s-worldv2.yaml")  # no YOLOv8n-world model yet
    # ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹
    model.train(
        data={"train": {"yolo_data": ["dota8.yaml"]}, "val": {"yolo_data": ["dota8.yaml"]}},
        epochs=1,
        imgsz=32,
        cache="disk",
        close_mosaic=1,
        trainer=WorldTrainerFromScratch,
    )


# å®šä¹‰æµ‹è¯•å‡½æ•°ï¼Œæµ‹è¯• YOLOv10 æ¨¡å‹çš„è®­ç»ƒã€éªŒè¯å’Œé¢„æµ‹æ­¥éª¤ï¼Œä½¿ç”¨æœ€å°é…ç½®
def test_yolov10():
    """Test YOLOv10 model training, validation, and prediction steps with minimal configurations."""
    # åˆ›å»º YOLOv10n æ¨¡å‹å¯¹è±¡ï¼ŒåŠ è½½æŒ‡å®šæ¨¡å‹é…ç½®æ–‡ä»¶
    model = YOLO("yolov10n.yaml")
    # è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨ coco8.yaml æ•°æ®é›†ï¼Œè®­ç»ƒ1è½®ï¼Œå›¾åƒå°ºå¯¸ä¸º32ï¼Œä½¿ç”¨ç£ç›˜ç¼“å­˜ï¼Œå…³é—­é©¬èµ›å…‹
    model.train(data="coco8.yaml", epochs=1, imgsz=32, close_mosaic=1, cache="disk")
    # éªŒè¯æ¨¡å‹ï¼Œä½¿ç”¨ coco8.yaml æ•°æ®é›†ï¼Œå›¾åƒå°ºå¯¸ä¸º32
    model.val(data="coco8.yaml", imgsz=32)
    # è¿›è¡Œé¢„æµ‹ï¼Œå›¾åƒå°ºå¯¸ä¸º32ï¼Œä¿å­˜æ–‡æœ¬è¾“å‡ºå’Œè£å‰ªåçš„å›¾åƒï¼Œè¿›è¡Œæ•°æ®å¢å¼º
    model.predict(imgsz=32, save_txt=True, save_crop=True, augment=True)
    # å¯¹ç»™å®šçš„ SOURCE æ•°æ®è¿›è¡Œé¢„æµ‹
    model(SOURCE)
```