# `.\yolov8\ultralytics\data\build.py`

```
# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import os
import random
from pathlib import Path

import numpy as np
import torch
from PIL import Image
from torch.utils.data import dataloader, distributed

# å¯¼å…¥è‡ªå®šä¹‰æ•°æ®é›†ç±»
from ultralytics.data.dataset import GroundingDataset, YOLODataset, YOLOMultiModalDataset
# å¯¼å…¥æ•°æ®åŠ è½½å™¨
from ultralytics.data.loaders import (
    LOADERS,
    LoadImagesAndVideos,
    LoadPilAndNumpy,
    LoadScreenshots,
    LoadStreams,
    LoadTensor,
    SourceTypes,
    autocast_list,
)
# å¯¼å…¥æ•°æ®ç›¸å…³çš„å·¥å…·å‡½æ•°å’Œå¸¸é‡
from ultralytics.data.utils import IMG_FORMATS, PIN_MEMORY, VID_FORMATS
# å¯¼å…¥è¾…åŠ©å·¥å…·
from ultralytics.utils import RANK, colorstr
# å¯¼å…¥æ£€æŸ¥å‡½æ•°
from ultralytics.utils.checks import check_file


class InfiniteDataLoader(dataloader.DataLoader):
    """
    Dataloader that reuses workers.

    Uses same syntax as vanilla DataLoader.
    """

    def __init__(self, *args, **kwargs):
        """Dataloader that infinitely recycles workers, inherits from DataLoader."""
        super().__init__(*args, **kwargs)
        # ä½¿ç”¨ _RepeatSampler æ¥æ— é™å¾ªç¯åˆ©ç”¨æ•°æ®åŠ è½½å™¨çš„å·¥ä½œçº¿ç¨‹
        object.__setattr__(self, "batch_sampler", _RepeatSampler(self.batch_sampler))
        # åˆ›å»ºè¿­ä»£å™¨
        self.iterator = super().__iter__()

    def __len__(self):
        """Returns the length of the batch sampler's sampler."""
        return len(self.batch_sampler.sampler)

    def __iter__(self):
        """Creates a sampler that repeats indefinitely."""
        for _ in range(len(self)):
            yield next(self.iterator)

    def reset(self):
        """
        Reset iterator.

        This is useful when we want to modify settings of dataset while training.
        """
        # é‡ç½®è¿­ä»£å™¨ï¼Œå…è®¸åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿®æ”¹æ•°æ®é›†è®¾ç½®
        self.iterator = self._get_iterator()


class _RepeatSampler:
    """
    Sampler that repeats forever.

    Args:
        sampler (Dataset.sampler): The sampler to repeat.
    """

    def __init__(self, sampler):
        """Initializes an object that repeats a given sampler indefinitely."""
        self.sampler = sampler

    def __iter__(self):
        """Iterates over the 'sampler' and yields its contents."""
        while True:
            yield from iter(self.sampler)


def seed_worker(worker_id):  # noqa
    """Set dataloader worker seed https://pytorch.org/docs/stable/notes/randomness.html#dataloader."""
    # è®¾ç½®æ•°æ®åŠ è½½å™¨çš„å·¥ä½œçº¿ç¨‹ç§å­
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)


def build_yolo_dataset(cfg, img_path, batch, data, mode="train", rect=False, stride=32, multi_modal=False):
    """Build YOLO Dataset."""
    # æ ¹æ® multi_modal å‚æ•°é€‰æ‹© YOLO å•æ¨¡æ€æˆ–å¤šæ¨¡æ€æ•°æ®é›†
    dataset = YOLOMultiModalDataset if multi_modal else YOLODataset
    # è¿”å›ä¸€ä¸ªæ•°æ®é›†å¯¹è±¡ï¼Œç”¨äºè®­ç»ƒæˆ–æ¨æ–­
    return dataset(
        img_path=img_path,           # å›¾åƒè·¯å¾„
        imgsz=cfg.imgsz,             # å›¾åƒå°ºå¯¸
        batch_size=batch,            # æ‰¹å¤„ç†å¤§å°
        augment=mode == "train",     # æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼ºï¼ˆè®­ç»ƒæ¨¡å¼ä¸‹ï¼‰
        hyp=cfg,                     # è®­ç»ƒè¶…å‚æ•°é…ç½®
        rect=cfg.rect or rect,       # æ˜¯å¦ä½¿ç”¨çŸ©å½¢æ‰¹å¤„ç†ï¼ˆä»é…ç½®æ–‡ä»¶æˆ–å‚æ•°ä¸­è·å–ï¼‰
        cache=cfg.cache or None,     # æ˜¯å¦ç¼“å­˜æ•°æ®ï¼ˆä»é…ç½®æ–‡ä»¶æˆ–å‚æ•°ä¸­è·å–ï¼‰
        single_cls=cfg.single_cls or False,  # æ˜¯å¦å•ç±»åˆ«è®­ç»ƒï¼ˆä»é…ç½®æ–‡ä»¶æˆ–å‚æ•°ä¸­è·å–ï¼Œé»˜è®¤ä¸ºFalseï¼‰
        stride=int(stride),          # æ­¥å¹…å¤§å°ï¼ˆè½¬æ¢ä¸ºæ•´æ•°ï¼‰
        pad=0.0 if mode == "train" else 0.5,  # å¡«å……å€¼ï¼ˆè®­ç»ƒæ¨¡å¼ä¸‹ä¸º0.0ï¼Œæ¨æ–­æ¨¡å¼ä¸‹ä¸º0.5ï¼‰
        prefix=colorstr(f"{mode}: "),  # æ—¥å¿—å‰ç¼€ï¼ŒåŒ…å«æ¨¡å¼ä¿¡æ¯
        task=cfg.task,               # ä»»åŠ¡ç±»å‹ï¼ˆä»é…ç½®æ–‡ä»¶ä¸­è·å–ï¼‰
        classes=cfg.classes,         # ç±»åˆ«åˆ—è¡¨ï¼ˆä»é…ç½®æ–‡ä»¶ä¸­è·å–ï¼‰
        data=data,                   # æ•°æ®é›†å¯¹è±¡
        fraction=cfg.fraction if mode == "train" else 1.0,  # æ•°æ®é›†åˆ†æ•°ï¼ˆè®­ç»ƒæ¨¡å¼ä¸‹ä»é…ç½®æ–‡ä»¶è·å–ï¼Œæ¨æ–­æ¨¡å¼ä¸‹ä¸º1.0ï¼‰
    )
# æ„å»ºç”¨äº YOLO æ•°æ®é›†çš„æ•°æ®åŠ è½½å™¨
def build_grounding(cfg, img_path, json_file, batch, mode="train", rect=False, stride=32):
    """Build YOLO Dataset."""
    # è¿”å›ä¸€ä¸ª GroundingDataset å¯¹è±¡ï¼Œç”¨äºè®­ç»ƒæˆ–éªŒè¯
    return GroundingDataset(
        img_path=img_path,  # å›¾åƒæ–‡ä»¶è·¯å¾„
        json_file=json_file,  # åŒ…å«æ ‡æ³¨ä¿¡æ¯çš„ JSON æ–‡ä»¶è·¯å¾„
        imgsz=cfg.imgsz,  # å›¾åƒå°ºå¯¸
        batch_size=batch,  # æ‰¹å¤„ç†å¤§å°
        augment=mode == "train",  # æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼º
        hyp=cfg,  # é…ç½®ä¿¡æ¯å¯¹è±¡ï¼Œå¯èƒ½éœ€è¦é€šè¿‡ get_hyps_from_cfg å‡½æ•°è·å–
        rect=cfg.rect or rect,  # æ˜¯å¦ä½¿ç”¨çŸ©å½¢æ‰¹å¤„ç†
        cache=cfg.cache or None,  # æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        single_cls=cfg.single_cls or False,  # æ˜¯å¦ä¸ºå•ç±»åˆ«æ£€æµ‹
        stride=int(stride),  # æ­¥é•¿
        pad=0.0 if mode == "train" else 0.5,  # è¾¹ç¼˜å¡«å……
        prefix=colorstr(f"{mode}: "),  # è¾“å‡ºå‰ç¼€
        task=cfg.task,  # YOLO çš„ä»»åŠ¡ç±»å‹
        classes=cfg.classes,  # ç±»åˆ«ä¿¡æ¯
        fraction=cfg.fraction if mode == "train" else 1.0,  # æ•°æ®é›†çš„ä½¿ç”¨æ¯”ä¾‹
    )


# æ„å»ºç”¨äºè®­ç»ƒæˆ–éªŒè¯é›†çš„ DataLoader
def build_dataloader(dataset, batch, workers, shuffle=True, rank=-1):
    """Return an InfiniteDataLoader or DataLoader for training or validation set."""
    # é™åˆ¶æ‰¹å¤„ç†å¤§å°ä¸è¶…è¿‡æ•°æ®é›†çš„å¤§å°
    batch = min(batch, len(dataset))
    nd = torch.cuda.device_count()  # CUDA è®¾å¤‡æ•°é‡
    nw = min(os.cpu_count() // max(nd, 1), workers)  # ç¡®å®šä½¿ç”¨çš„å·¥ä½œçº¿ç¨‹æ•°é‡
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)
    generator = torch.Generator()
    generator.manual_seed(6148914691236517205 + RANK)  # è®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨ç§å­
    # è¿”å›ä¸€ä¸ª InfiniteDataLoader æˆ– DataLoader å¯¹è±¡
    return InfiniteDataLoader(
        dataset=dataset,  # æ•°æ®é›†å¯¹è±¡
        batch_size=batch,  # æ‰¹å¤„ç†å¤§å°
        shuffle=shuffle and sampler is None,  # æ˜¯å¦æ‰“ä¹±æ•°æ®é¡ºåº
        num_workers=nw,  # å·¥ä½œçº¿ç¨‹æ•°é‡
        sampler=sampler,  # åˆ†å¸ƒå¼é‡‡æ ·å™¨
        pin_memory=PIN_MEMORY,  # æ˜¯å¦å°†æ•°æ®ä¿å­˜åœ¨å›ºå®šå†…å­˜ä¸­
        collate_fn=getattr(dataset, "collate_fn", None),  # æ•°æ®é›†çš„æ•´ç†å‡½æ•°
        worker_init_fn=seed_worker,  # å·¥ä½œçº¿ç¨‹åˆå§‹åŒ–å‡½æ•°
        generator=generator,  # éšæœºæ•°ç”Ÿæˆå™¨
    )


# æ£€æŸ¥è¾“å…¥æ•°æ®æºçš„ç±»å‹ï¼Œå¹¶è¿”å›ç›¸åº”çš„æ ‡å¿—å€¼
def check_source(source):
    """Check source type and return corresponding flag values."""
    webcam, screenshot, from_img, in_memory, tensor = False, False, False, False, False
    if isinstance(source, (str, int, Path)):  # æ£€æŸ¥æ˜¯å¦ä¸ºå­—ç¬¦ä¸²ã€æ•´æ•°æˆ–è·¯å¾„
        source = str(source)
        is_file = Path(source).suffix[1:] in (IMG_FORMATS | VID_FORMATS)  # æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„å›¾åƒæˆ–è§†é¢‘æ ¼å¼
        is_url = source.lower().startswith(("https://", "http://", "rtsp://", "rtmp://", "tcp://"))  # æ£€æŸ¥æ˜¯å¦ä¸º URL
        webcam = source.isnumeric() or source.endswith(".streams") or (is_url and not is_file)  # æ˜¯å¦ä¸ºæ‘„åƒå¤´
        screenshot = source.lower() == "screen"  # æ˜¯å¦ä¸ºå±å¹•æˆªå›¾
        if is_url and is_file:
            source = check_file(source)  # ä¸‹è½½æ–‡ä»¶
    elif isinstance(source, LOADERS):  # æ£€æŸ¥æ˜¯å¦ä¸ºç‰¹å®šåŠ è½½å™¨ç±»å‹
        in_memory = True  # æ˜¯å¦åœ¨å†…å­˜ä¸­
    elif isinstance(source, (list, tuple)):  # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ—è¡¨æˆ–å…ƒç»„
        source = autocast_list(source)  # è½¬æ¢åˆ—è¡¨å…ƒç´ ä¸º PIL å›¾åƒæˆ– np æ•°ç»„
        from_img = True  # æ˜¯å¦ä»å›¾åƒè·å–
    elif isinstance(source, (Image.Image, np.ndarray)):  # æ£€æŸ¥æ˜¯å¦ä¸º PIL å›¾åƒæˆ– np æ•°ç»„
        from_img = True  # æ˜¯å¦ä»å›¾åƒè·å–
    elif isinstance(source, torch.Tensor):  # æ£€æŸ¥æ˜¯å¦ä¸º PyTorch å¼ é‡
        tensor = True  # æ˜¯å¦ä¸ºå¼ é‡
    else:
        raise TypeError("Unsupported image type. For supported types see https://docs.ultralytics.com/modes/predict")  # æŠ›å‡ºé”™è¯¯ï¼Œä¸æ”¯æŒçš„å›¾åƒç±»å‹

    return source, webcam, screenshot, from_img, in_memory, tensor  # è¿”å›æºæ•°æ®åŠç›¸å…³æ ‡å¿—å€¼


# åŠ è½½æ¨æ–­æ•°æ®æºï¼Œç”¨äºç›®æ ‡æ£€æµ‹ï¼Œå¹¶åº”ç”¨å¿…è¦çš„è½¬æ¢
def load_inference_source(source=None, batch=1, vid_stride=1, buffer=False):
    """
    Loads an inference source for object detection and applies necessary transformations.
    """
    # è¿”å›ä¸€ä¸ª InfiniteDataLoader å¯¹è±¡ï¼Œç”¨äºæ¨æ–­æ•°æ®æºåŠ è½½
    return InfiniteDataLoader(
        dataset=dataset,  # æ•°æ®é›†å¯¹è±¡
        batch_size=batch,  # æ‰¹å¤„ç†å¤§å°
        shuffle=shuffle and sampler is None,  # æ˜¯å¦æ‰“ä¹±æ•°æ®é¡ºåº
        num_workers=nw,  # å·¥ä½œçº¿ç¨‹æ•°é‡
        sampler=sampler,  # åˆ†å¸ƒå¼é‡‡æ ·å™¨
        pin_memory=PIN_MEMORY,  # æ˜¯å¦å°†æ•°æ®ä¿å­˜åœ¨å›ºå®šå†…å­˜ä¸­
        collate_fn=getattr(dataset, "collate_fn", None),  # æ•°æ®é›†çš„æ•´ç†å‡½æ•°
        worker_init_fn=seed_worker,  # å·¥ä½œçº¿ç¨‹åˆå§‹åŒ–å‡½æ•°
        generator=generator,  # éšæœºæ•°ç”Ÿæˆå™¨
    )
    Args:
        source (str, Path, Tensor, PIL.Image, np.ndarray): æ¥æ”¶æ¨ç†è¾“å…¥çš„æºæ•°æ®ç±»å‹ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶è·¯å¾„ã€å¼ é‡ã€å›¾åƒå¯¹è±¡ç­‰ã€‚
        batch (int, optional): æ•°æ®åŠ è½½å™¨çš„æ‰¹å¤§å°ã€‚é»˜è®¤ä¸º1ã€‚
        vid_stride (int, optional): è§†é¢‘æºçš„å¸§é—´éš”ã€‚é»˜è®¤ä¸º1ã€‚
        buffer (bool, optional): å†³å®šæµå¼å¸§æ˜¯å¦ç¼“å­˜ã€‚é»˜è®¤ä¸ºFalseã€‚

    Returns:
        dataset (Dataset): è¿”å›ç‰¹å®šè¾“å…¥æºçš„æ•°æ®é›†å¯¹è±¡ã€‚
    """
    # æ£€æŸ¥è¾“å…¥æºçš„ç±»å‹å¹¶è¿›è¡Œé€‚é…
    source, stream, screenshot, from_img, in_memory, tensor = check_source(source)
    
    # å¦‚æœæ•°æ®æºåœ¨å†…å­˜ä¸­ï¼Œåˆ™ä½¿ç”¨å…¶ç±»å‹ï¼›å¦åˆ™æ ¹æ®æºçš„ä¸åŒé€‰æ‹©æºç±»å‹
    source_type = source.source_type if in_memory else SourceTypes(stream, screenshot, from_img, tensor)

    # æ•°æ®åŠ è½½å™¨é€‰æ‹©
    if tensor:
        # å¦‚æœè¾“å…¥æºæ˜¯å¼ é‡ï¼Œåˆ™åŠ è½½å¼ é‡æ•°æ®é›†
        dataset = LoadTensor(source)
    elif in_memory:
        # å¦‚æœè¾“å…¥æºåœ¨å†…å­˜ä¸­ï¼Œåˆ™ç›´æ¥ä½¿ç”¨è¯¥æºä½œä¸ºæ•°æ®é›†
        dataset = source
    elif stream:
        # å¦‚æœè¾“å…¥æºæ˜¯æµå¼æ•°æ®ï¼ˆè§†é¢‘æµï¼‰ï¼Œåˆ™åŠ è½½æµæ•°æ®é›†
        dataset = LoadStreams(source, vid_stride=vid_stride, buffer=buffer)
    elif screenshot:
        # å¦‚æœè¾“å…¥æºæ˜¯æˆªå›¾ï¼Œåˆ™åŠ è½½æˆªå›¾æ•°æ®é›†
        dataset = LoadScreenshots(source)
    elif from_img:
        # å¦‚æœè¾“å…¥æºæ˜¯PILå›¾åƒæˆ–numpyæ•°ç»„ï¼Œåˆ™åŠ è½½å¯¹åº”æ•°æ®é›†
        dataset = LoadPilAndNumpy(source)
    else:
        # å…¶ä»–æƒ…å†µä¸‹ï¼ˆå›¾ç‰‡æˆ–è§†é¢‘æ–‡ä»¶ï¼‰ï¼ŒåŠ è½½å›¾ç‰‡å’Œè§†é¢‘æ•°æ®é›†
        dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)

    # å°†æºç±»å‹é™„åŠ åˆ°æ•°æ®é›†å¯¹è±¡
    setattr(dataset, "source_type", source_type)

    # è¿”å›åˆ›å»ºçš„æ•°æ®é›†å¯¹è±¡
    return dataset
```