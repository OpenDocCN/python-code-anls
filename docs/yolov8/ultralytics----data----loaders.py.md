# `.\yolov8\ultralytics\data\loaders.py`

```
# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import glob  # å¯¼å…¥globæ¨¡å—ï¼Œç”¨äºè·å–æ–‡ä»¶è·¯å¾„åˆ—è¡¨
import math  # å¯¼å…¥mathæ¨¡å—ï¼Œæä¾›æ•°å­¦è®¡ç®—å‡½æ•°
import os  # å¯¼å…¥osæ¨¡å—ï¼Œç”¨äºä¸æ“ä½œç³»ç»Ÿè¿›è¡Œäº¤äº’
import time  # å¯¼å…¥timeæ¨¡å—ï¼Œæä¾›æ—¶é—´ç›¸å…³å‡½æ•°
from dataclasses import dataclass  # å¯¼å…¥dataclassç±»ï¼Œç”¨äºåˆ›å»ºæ•°æ®ç±»
from pathlib import Path  # å¯¼å…¥Pathç±»ï¼Œç”¨äºå¤„ç†è·¯å¾„
from threading import Thread  # å¯¼å…¥Threadç±»ï¼Œç”¨äºå®ç°å¤šçº¿ç¨‹æ“ä½œ
from urllib.parse import urlparse  # å¯¼å…¥urlparseå‡½æ•°ï¼Œç”¨äºè§£æURL

import cv2  # å¯¼å…¥cv2æ¨¡å—ï¼ŒOpenCVåº“
import numpy as np  # å¯¼å…¥numpyåº“ï¼Œç”¨äºæ•°å€¼è®¡ç®—
import requests  # å¯¼å…¥requestsæ¨¡å—ï¼Œç”¨äºHTTPè¯·æ±‚
import torch  # å¯¼å…¥torchæ¨¡å—ï¼ŒPyTorchæ·±åº¦å­¦ä¹ åº“
from PIL import Image  # å¯¼å…¥Imageç±»ï¼ŒPythonå›¾åƒå¤„ç†åº“PILçš„ä¸€éƒ¨åˆ†

from ultralytics.data.utils import FORMATS_HELP_MSG, IMG_FORMATS, VID_FORMATS  # å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—çš„ç‰¹å®šå†…å®¹
from ultralytics.utils import IS_COLAB, IS_KAGGLE, LOGGER, ops  # å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—çš„ç‰¹å®šå†…å®¹
from ultralytics.utils.checks import check_requirements  # å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—çš„ç‰¹å®šå‡½æ•°


@dataclass
class SourceTypes:
    """Class to represent various types of input sources for predictions."""
    
    stream: bool = False  # æ˜¯å¦ä¸ºæµç±»å‹è¾“å…¥ï¼Œé»˜è®¤ä¸ºFalse
    screenshot: bool = False  # æ˜¯å¦ä¸ºæˆªå›¾ç±»å‹è¾“å…¥ï¼Œé»˜è®¤ä¸ºFalse
    from_img: bool = False  # æ˜¯å¦ä¸ºå›¾åƒæ–‡ä»¶ç±»å‹è¾“å…¥ï¼Œé»˜è®¤ä¸ºFalse
    tensor: bool = False  # æ˜¯å¦ä¸ºå¼ é‡ç±»å‹è¾“å…¥ï¼Œé»˜è®¤ä¸ºFalse


class LoadStreams:
    """
    Stream Loader for various types of video streams, Supports RTSP, RTMP, HTTP, and TCP streams.

    Attributes:
        sources (str): The source input paths or URLs for the video streams.
        vid_stride (int): Video frame-rate stride, defaults to 1.
        buffer (bool): Whether to buffer input streams, defaults to False.
        running (bool): Flag to indicate if the streaming thread is running.
        mode (str): Set to 'stream' indicating real-time capture.
        imgs (list): List of image frames for each stream.
        fps (list): List of FPS for each stream.
        frames (list): List of total frames for each stream.
        threads (list): List of threads for each stream.
        shape (list): List of shapes for each stream.
        caps (list): List of cv2.VideoCapture objects for each stream.
        bs (int): Batch size for processing.

    Methods:
        __init__: Initialize the stream loader.
        update: Read stream frames in daemon thread.
        close: Close stream loader and release resources.
        __iter__: Returns an iterator object for the class.
        __next__: Returns source paths, transformed, and original images for processing.
        __len__: Return the length of the sources object.

    Example:
         ```py
         yolo predict source='rtsp://example.com/media.mp4'
         ```
    """
    def __init__(self, sources="file.streams", vid_stride=1, buffer=False):
        """Initialize instance variables and check for consistent input stream shapes."""
        torch.backends.cudnn.benchmark = True  # faster for fixed-size inference
        self.buffer = buffer  # buffer input streams
        self.running = True  # running flag for Thread
        self.mode = "stream"
        self.vid_stride = vid_stride  # video frame-rate stride

        # Read sources from file or use directly if already a list
        sources = Path(sources).read_text().rsplit() if os.path.isfile(sources) else [sources]
        n = len(sources)  # Number of sources
        self.bs = n  # Set batch size to number of sources
        self.fps = [0] * n  # Initialize frames per second list for each source
        self.frames = [0] * n  # Initialize frame count list for each source
        self.threads = [None] * n  # Initialize threads list for each source
        self.caps = [None] * n  # Initialize video capture objects list for each source
        self.imgs = [[] for _ in range(n)]  # Initialize empty list to store images for each source
        self.shape = [[] for _ in range(n)]  # Initialize empty list to store image shapes for each source
        self.sources = [ops.clean_str(x) for x in sources]  # Clean and store source names for later use

        for i, s in enumerate(sources):  # Loop through each source with index i and source s
            # Start thread to read frames from video stream
            st = f"{i + 1}/{n}: {s}... "

            # Check if source is a YouTube video and convert URL if necessary
            if urlparse(s).hostname in {"www.youtube.com", "youtube.com", "youtu.be"}:
                s = get_best_youtube_url(s)

            # Evaluate string if numeric (e.g., '0' for local webcam)
            s = eval(s) if s.isnumeric() else s

            # Raise error if trying to use webcam in Colab or Kaggle environments
            if s == 0 and (IS_COLAB or IS_KAGGLE):
                raise NotImplementedError(
                    "'source=0' webcam not supported in Colab and Kaggle notebooks. "
                    "Try running 'source=0' in a local environment."
                )

            # Initialize video capture object for the current source
            self.caps[i] = cv2.VideoCapture(s)

            # Raise error if video capture object fails to open
            if not self.caps[i].isOpened():
                raise ConnectionError(f"{st}Failed to open {s}")

            # Retrieve and store video properties: width, height, frames per second
            w = int(self.caps[i].get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(self.caps[i].get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = self.caps[i].get(cv2.CAP_PROP_FPS)
            
            # Calculate total frames; handle cases where frame count might be 0 or NaN
            self.frames[i] = max(int(self.caps[i].get(cv2.CAP_PROP_FRAME_COUNT)), 0) or float("inf")

            # Calculate frames per second, ensuring a minimum of 30 FPS
            self.fps[i] = max((fps if math.isfinite(fps) else 0) % 100, 0) or 30

            # Read the first frame to ensure successful connection
            success, im = self.caps[i].read()
            if not success or im is None:
                raise ConnectionError(f"{st}Failed to read images from {s}")

            # Store the first frame and its shape
            self.imgs[i].append(im)
            self.shape[i] = im.shape

            # Start a thread to continuously update frames for the current source
            self.threads[i] = Thread(target=self.update, args=([i, self.caps[i], s]), daemon=True)
            LOGGER.info(f"{st}Success âœ… ({self.frames[i]} frames of shape {w}x{h} at {self.fps[i]:.2f} FPS)")

            # Start the thread for reading frames
            self.threads[i].start()

        LOGGER.info("")  # Print a newline for logging clarity
    def update(self, i, cap, stream):
        """
        Read stream `i` frames in daemon thread.
        """
        n, f = 0, self.frames[i]  # åˆå§‹åŒ–å¸§å·å’Œå¸§æ•°ç»„
        while self.running and cap.isOpened() and n < (f - 1):
            if len(self.imgs[i]) < 30:  # ä¿æŒä¸è¶…è¿‡30å¸§çš„å›¾åƒç¼“å†²
                n += 1
                cap.grab()  # æ•è·è§†é¢‘å¸§ï¼Œä¸ç›´æ¥è¯»å–ï¼Œè€Œæ˜¯å…ˆæŠ“å–å†æ£€ç´¢
                if n % self.vid_stride == 0:  # æ¯ vid_stride å¸§æ‰§è¡Œä¸€æ¬¡
                    success, im = cap.retrieve()  # æ£€ç´¢å·²æŠ“å–çš„è§†é¢‘å¸§
                    if not success:
                        im = np.zeros(self.shape[i], dtype=np.uint8)  # å¦‚æœæ£€ç´¢å¤±è´¥ï¼Œåˆ›å»ºå…¨é›¶å›¾åƒ
                        LOGGER.warning("WARNING âš ï¸ Video stream unresponsive, please check your IP camera connection.")
                        cap.open(stream)  # å¦‚æœä¿¡å·ä¸¢å¤±ï¼Œé‡æ–°æ‰“å¼€æµ
                    if self.buffer:
                        self.imgs[i].append(im)  # å°†å›¾åƒå¸§æ·»åŠ åˆ°ç¼“å†²åŒº
                    else:
                        self.imgs[i] = [im]  # æ›¿æ¢å½“å‰ç¼“å†²åŒºçš„å›¾åƒå¸§
            else:
                time.sleep(0.01)  # ç­‰å¾…ç›´åˆ°ç¼“å†²åŒºä¸ºç©º

    def close(self):
        """
        Close stream loader and release resources.
        """
        self.running = False  # åœæ­¢çº¿ç¨‹çš„æ ‡å¿—
        for thread in self.threads:
            if thread.is_alive():
                thread.join(timeout=5)  # ç­‰å¾…çº¿ç¨‹ç»“æŸï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
        for cap in self.caps:  # éå†å­˜å‚¨çš„ VideoCapture å¯¹è±¡
            try:
                cap.release()  # é‡Šæ”¾è§†é¢‘æ•è·å¯¹è±¡
            except Exception as e:
                LOGGER.warning(f"WARNING âš ï¸ Could not release VideoCapture object: {e}")  # æ•è·å¼‚å¸¸å¹¶è®°å½•è­¦å‘Šä¿¡æ¯
        cv2.destroyAllWindows()  # å…³é—­æ‰€æœ‰ OpenCV çª—å£

    def __iter__(self):
        """
        Iterates through YOLO image feed and re-opens unresponsive streams.
        """
        self.count = -1  # åˆå§‹åŒ–è®¡æ•°å™¨
        return self

    def __next__(self):
        """
        Returns source paths, transformed and original images for processing.
        """
        self.count += 1  # è®¡æ•°å™¨è‡ªå¢

        images = []
        for i, x in enumerate(self.imgs):
            # ç­‰å¾…ç›´åˆ°æ¯ä¸ªç¼“å†²åŒºä¸­æœ‰å¸§å¯ç”¨
            while not x:
                if not self.threads[i].is_alive() or cv2.waitKey(1) == ord("q"):  # æ£€æŸ¥çº¿ç¨‹çŠ¶æ€æˆ–ç”¨æˆ·æ˜¯å¦æŒ‰ä¸‹ 'q'
                    self.close()  # å…³é—­å¯¹è±¡
                    raise StopIteration  # æŠ›å‡ºåœæ­¢è¿­ä»£å¼‚å¸¸
                time.sleep(1 / min(self.fps))  # ç­‰å¾…æ—¶é—´é—´éš”ï¼Œæœ€å° FPS
                x = self.imgs[i]  # æ›´æ–°ç¼“å†²åŒºçŠ¶æ€
                if not x:
                    LOGGER.warning(f"WARNING âš ï¸ Waiting for stream {i}")  # è®°å½•è­¦å‘Šä¿¡æ¯

            # ä» imgs ç¼“å†²åŒºä¸­è·å–å¹¶ç§»é™¤ç¬¬ä¸€å¸§å›¾åƒ
            if self.buffer:
                images.append(x.pop(0))
            # è·å–æœ€åä¸€å¸§å›¾åƒï¼Œå¹¶æ¸…ç©ºç¼“å†²åŒºçš„å…¶ä½™å›¾åƒå¸§
            else:
                images.append(x.pop(-1) if x else np.zeros(self.shape[i], dtype=np.uint8))
                x.clear()

        return self.sources, images, [""] * self.bs  # è¿”å›æºè·¯å¾„ã€è½¬æ¢åçš„å›¾åƒå’ŒåŸå§‹å›¾åƒåˆ—è¡¨

    def __len__(self):
        """
        Return the length of the sources object.
        """
        return self.bs  # è¿”å›æºå¯¹è±¡çš„é•¿åº¦ï¼Œå³ batch size
class LoadScreenshots:
    """
    YOLOv8 screenshot dataloader.

    This class manages the loading of screenshot images for processing with YOLOv8.
    Suitable for use with `yolo predict source=screen`.

    Attributes:
        source (str): The source input indicating which screen to capture.
        screen (int): The screen number to capture.
        left (int): The left coordinate for screen capture area.
        top (int): The top coordinate for screen capture area.
        width (int): The width of the screen capture area.
        height (int): The height of the screen capture area.
        mode (str): Set to 'stream' indicating real-time capture.
        frame (int): Counter for captured frames.
        sct (mss.mss): Screen capture object from `mss` library.
        bs (int): Batch size, set to 1.
        monitor (dict): Monitor configuration details.

    Methods:
        __iter__: Returns an iterator object.
        __next__: Captures the next screenshot and returns it.
    """

    def __init__(self, source):
        """Source = [screen_number left top width height] (pixels)."""
        # æ£€æŸ¥å¹¶ç¡®ä¿mssåº“å·²ç»å®‰è£…
        check_requirements("mss")
        # å¯¼å…¥mssåº“
        import mss  # noqa

        # è§£æsourceå‚æ•°ï¼Œæ ¹æ®å‚æ•°è®¾ç½®æˆªå›¾çš„å±å¹•åŒºåŸŸ
        source, *params = source.split()
        self.screen, left, top, width, height = 0, None, None, None, None  # default to full screen 0
        if len(params) == 1:
            self.screen = int(params[0])
        elif len(params) == 4:
            left, top, width, height = (int(x) for x in params)
        elif len(params) == 5:
            self.screen, left, top, width, height = (int(x) for x in params)
        
        # è®¾ç½®æˆªå›¾æ¨¡å¼ä¸ºå®æ—¶æµ
        self.mode = "stream"
        # åˆå§‹åŒ–å¸§è®¡æ•°å™¨
        self.frame = 0
        # åˆ›å»ºmsså¯¹è±¡ç”¨äºå±å¹•æˆªå›¾
        self.sct = mss.mss()
        # è®¾ç½®æ‰¹å¤„ç†å¤§å°ä¸º1
        self.bs = 1
        # è®¾ç½®å¸§ç‡ä¸º30å¸§æ¯ç§’
        self.fps = 30

        # è§£æmonitorå‚æ•°ï¼Œæ ¹æ®å±å¹•å’Œæˆªå›¾åŒºåŸŸè®¾ç½®ç›‘è§†å™¨é…ç½®
        monitor = self.sct.monitors[self.screen]
        self.top = monitor["top"] if top is None else (monitor["top"] + top)
        self.left = monitor["left"] if left is None else (monitor["left"] + left)
        self.width = width or monitor["width"]
        self.height = height or monitor["height"]
        self.monitor = {"left": self.left, "top": self.top, "width": self.width, "height": self.height}

    def __iter__(self):
        """Returns an iterator of the object."""
        return self

    def __next__(self):
        """mss screen capture: get raw pixels from the screen as np array."""
        # ä½¿ç”¨msså¯¹è±¡è·å–å±å¹•æˆªå›¾ï¼Œå¹¶å°†åƒç´ è½¬æ¢ä¸ºnumpyæ•°ç»„
        im0 = np.asarray(self.sct.grab(self.monitor))[:, :, :3]  # BGRA to BGR
        s = f"screen {self.screen} (LTWH): {self.left},{self.top},{self.width},{self.height}: "

        # å¢åŠ å¸§è®¡æ•°
        self.frame += 1
        # è¿”å›æˆªå›¾ç›¸å…³ä¿¡æ¯
        return [str(self.screen)], [im0], [s]  # screen, img, string
    # å®šä¹‰ä¸€ä¸ªæ•°æ®åŠ è½½å™¨ç±»ï¼Œç”¨äºåŠ è½½å›¾åƒå’Œè§†é¢‘æ–‡ä»¶
    class Dataloader:
        """
        Attributes:
            files (list): List of image and video file paths.
            nf (int): Total number of files (images and videos).
            video_flag (list): Flags indicating whether a file is a video (True) or an image (False).
            mode (str): Current mode, 'image' or 'video'.
            vid_stride (int): Stride for video frame-rate, defaults to 1.
            bs (int): Batch size, set to 1 for this class.
            cap (cv2.VideoCapture): Video capture object for OpenCV.
            frame (int): Frame counter for video.
            frames (int): Total number of frames in the video.
            count (int): Counter for iteration, initialized at 0 during `__iter__()`.

        Methods:
            _new_video(path): Create a new cv2.VideoCapture object for a given video path.
        """

        def __init__(self, path, batch=1, vid_stride=1):
            """Initialize the Dataloader and raise FileNotFoundError if file not found."""
            parent = None
            if isinstance(path, str) and Path(path).suffix == ".txt":  # *.txt file with img/vid/dir on each line
                parent = Path(path).parent
                path = Path(path).read_text().splitlines()  # list of sources
            files = []
            for p in sorted(path) if isinstance(path, (list, tuple)) else [path]:
                a = str(Path(p).absolute())  # do not use .resolve() https://github.com/ultralytics/ultralytics/issues/2912
                if "*" in a:
                    files.extend(sorted(glob.glob(a, recursive=True)))  # glob
                elif os.path.isdir(a):
                    files.extend(sorted(glob.glob(os.path.join(a, "*.*"))))  # dir
                elif os.path.isfile(a):
                    files.append(a)  # files (absolute or relative to CWD)
                elif parent and (parent / p).is_file():
                    files.append(str((parent / p).absolute()))  # files (relative to *.txt file parent)
                else:
                    raise FileNotFoundError(f"{p} does not exist")

            # Define files as images or videos
            images, videos = [], []
            for f in files:
                suffix = f.split(".")[-1].lower()  # Get file extension without the dot and lowercase
                if suffix in IMG_FORMATS:
                    images.append(f)
                elif suffix in VID_FORMATS:
                    videos.append(f)
            ni, nv = len(images), len(videos)

            self.files = images + videos
            self.nf = ni + nv  # number of files
            self.ni = ni  # number of images
            self.video_flag = [False] * ni + [True] * nv
            self.mode = "image"
            self.vid_stride = vid_stride  # video frame-rate stride
            self.bs = batch
            if any(videos):
                self._new_video(videos[0])  # new video
            else:
                self.cap = None
            if self.nf == 0:
                raise FileNotFoundError(f"No images or videos found in {p}. {FORMATS_HELP_MSG}")

        def __iter__(self):
            """Returns an iterator object for VideoStream or ImageFolder."""
            self.count = 0
            return self
    def __next__(self):
        """Returns the next batch of images or video frames along with their paths and metadata."""
        paths, imgs, info = [], [], []  # åˆå§‹åŒ–ç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨è·¯å¾„ã€å›¾åƒ/è§†é¢‘å¸§å’Œå…ƒæ•°æ®ä¿¡æ¯
        while len(imgs) < self.bs:  # å½“å›¾åƒ/è§†é¢‘å¸§åˆ—è¡¨é•¿åº¦å°äºæ‰¹æ¬¡å¤§å°æ—¶æ‰§è¡Œå¾ªç¯
            if self.count >= self.nf:  # å¦‚æœè®¡æ•°å™¨è¶…è¿‡æ–‡ä»¶æ€»æ•°ï¼Œåˆ™è¡¨ç¤ºæ–‡ä»¶åˆ—è¡¨ç»“æŸ
                if imgs:
                    return paths, imgs, info  # è¿”å›æœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡
                else:
                    raise StopIteration  # å¦åˆ™æŠ›å‡ºè¿­ä»£ç»“æŸå¼‚å¸¸

            path = self.files[self.count]  # è·å–å½“å‰æ–‡ä»¶è·¯å¾„
            if self.video_flag[self.count]:  # æ£€æŸ¥å½“å‰æ–‡ä»¶æ˜¯å¦ä¸ºè§†é¢‘
                self.mode = "video"  # è®¾ç½®æ¨¡å¼ä¸ºè§†é¢‘
                if not self.cap or not self.cap.isOpened():  # å¦‚æœè§†é¢‘æ•è·å¯¹è±¡ä¸å­˜åœ¨æˆ–æœªæ‰“å¼€
                    self._new_video(path)  # åˆ›å»ºæ–°çš„è§†é¢‘æ•è·å¯¹è±¡

                for _ in range(self.vid_stride):  # å¾ªç¯æŠ“å–è§†é¢‘å¸§
                    success = self.cap.grab()
                    if not success:
                        break  # å¦‚æœæŠ“å–å¤±è´¥ï¼Œåˆ™é€€å‡ºå¾ªç¯

                if success:  # å¦‚æœæŠ“å–æˆåŠŸ
                    success, im0 = self.cap.retrieve()  # æ£€ç´¢æŠ“å–çš„è§†é¢‘å¸§
                    if success:
                        self.frame += 1  # å¸§æ•°åŠ ä¸€
                        paths.append(path)  # æ·»åŠ è·¯å¾„åˆ°åˆ—è¡¨
                        imgs.append(im0)  # æ·»åŠ å›¾åƒå¸§åˆ°åˆ—è¡¨
                        info.append(f"video {self.count + 1}/{self.nf} (frame {self.frame}/{self.frames}) {path}: ")  # æ·»åŠ è§†é¢‘ä¿¡æ¯åˆ°åˆ—è¡¨
                        if self.frame == self.frames:  # å¦‚æœè¾¾åˆ°è§†é¢‘å¸§æ•°çš„æœ€å¤§å€¼
                            self.count += 1  # è®¡æ•°å™¨åŠ ä¸€
                            self.cap.release()  # é‡Šæ”¾è§†é¢‘æ•è·å¯¹è±¡
                else:
                    # å¦‚æœå½“å‰è§†é¢‘ç»“æŸæˆ–æ‰“å¼€å¤±è´¥ï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªæ–‡ä»¶
                    self.count += 1
                    if self.cap:
                        self.cap.release()  # é‡Šæ”¾è§†é¢‘æ•è·å¯¹è±¡
                    if self.count < self.nf:
                        self._new_video(self.files[self.count])  # åˆ›å»ºæ–°çš„è§†é¢‘æ•è·å¯¹è±¡
            else:
                self.mode = "image"  # è®¾ç½®æ¨¡å¼ä¸ºå›¾åƒ
                im0 = cv2.imread(path)  # è¯»å–å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
                if im0 is None:
                    LOGGER.warning(f"WARNING âš ï¸ Image Read Error {path}")  # å¦‚æœå›¾åƒè¯»å–å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä¿¡æ¯
                else:
                    paths.append(path)  # æ·»åŠ è·¯å¾„åˆ°åˆ—è¡¨
                    imgs.append(im0)  # æ·»åŠ å›¾åƒåˆ°åˆ—è¡¨
                    info.append(f"image {self.count + 1}/{self.nf} {path}: ")  # æ·»åŠ å›¾åƒä¿¡æ¯åˆ°åˆ—è¡¨
                self.count += 1  # è®¡æ•°å™¨åŠ ä¸€ï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªæ–‡ä»¶
                if self.count >= self.ni:  # å¦‚æœè®¡æ•°å™¨è¶…è¿‡å›¾åƒæ€»æ•°
                    break  # è·³å‡ºå¾ªç¯ï¼Œç»“æŸå›¾åƒåˆ—è¡¨çš„è¯»å–

        return paths, imgs, info  # è¿”å›è·¯å¾„ã€å›¾åƒ/è§†é¢‘å¸§å’Œå…ƒæ•°æ®ä¿¡æ¯åˆ—è¡¨

    def _new_video(self, path):
        """Creates a new video capture object for the given path."""
        self.frame = 0  # åˆå§‹åŒ–å¸§æ•°
        self.cap = cv2.VideoCapture(path)  # åˆ›å»ºæ–°çš„è§†é¢‘æ•è·å¯¹è±¡
        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))  # è·å–è§†é¢‘å¸§ç‡
        if not self.cap.isOpened():
            raise FileNotFoundError(f"Failed to open video {path}")  # å¦‚æœè§†é¢‘æ‰“å¼€å¤±è´¥ï¼ŒæŠ›å‡ºæ–‡ä»¶æœªæ‰¾åˆ°å¼‚å¸¸
        self.frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT) / self.vid_stride)  # è®¡ç®—è§†é¢‘å¸§æ•°

    def __len__(self):
        """Returns the number of batches in the object."""
        return math.ceil(self.nf / self.bs)  # è¿”å›å¯¹è±¡ä¸­æ‰¹æ¬¡çš„æ•°é‡ï¼Œå‘ä¸Šå–æ•´
    """
    Load images from PIL and Numpy arrays for batch processing.

    This class is designed to manage loading and pre-processing of image data from both PIL and Numpy formats.
    It performs basic validation and format conversion to ensure that the images are in the required format for
    downstream processing.

    Attributes:
        paths (list): List of image paths or autogenerated filenames.
        im0 (list): List of images stored as Numpy arrays.
        mode (str): Type of data being processed, defaults to 'image'.
        bs (int): Batch size, equivalent to the length of `im0`.

    Methods:
        _single_check(im): Validate and format a single image to a Numpy array.
    """

    def __init__(self, im0):
        """Initialize PIL and Numpy Dataloader."""
        if not isinstance(im0, list):
            im0 = [im0]
        # Generate filenames or use existing ones from input images
        self.paths = [getattr(im, "filename", f"image{i}.jpg") for i, im in enumerate(im0)]
        # Validate and convert each image in `im0` to Numpy arrays
        self.im0 = [self._single_check(im) for im in im0]
        # Set the processing mode to 'image'
        self.mode = "image"
        # Set the batch size to the number of images in `im0`
        self.bs = len(self.im0)

    @staticmethod
    def _single_check(im):
        """Validate and format an image to numpy array."""
        # Ensure `im` is either a PIL.Image or np.ndarray
        assert isinstance(im, (Image.Image, np.ndarray)), f"Expected PIL/np.ndarray image type, but got {type(im)}"
        if isinstance(im, Image.Image):
            # Convert PIL.Image to RGB mode if not already
            if im.mode != "RGB":
                im = im.convert("RGB")
            # Convert PIL.Image to Numpy array and reverse channels
            im = np.asarray(im)[:, :, ::-1]
            im = np.ascontiguousarray(im)  # Make sure the array is contiguous
        return im

    def __len__(self):
        """Returns the length of the 'im0' attribute."""
        return len(self.im0)

    def __next__(self):
        """Returns batch paths, images, processed images, None, ''."""
        if self.count == 1:  # loop only once as it's batch inference
            raise StopIteration
        self.count += 1
        return self.paths, self.im0, [""] * self.bs

    def __iter__(self):
        """Enables iteration for class LoadPilAndNumpy."""
        self.count = 0
        return self


class LoadTensor:
    """
    Load images from torch.Tensor data.

    This class manages the loading and pre-processing of image data from PyTorch tensors for further processing.

    Attributes:
        im0 (torch.Tensor): The input tensor containing the image(s).
        bs (int): Batch size, inferred from the shape of `im0`.
        mode (str): Current mode, set to 'image'.
        paths (list): List of image paths or filenames.
        count (int): Counter for iteration, initialized at 0 during `__iter__()`.

    Methods:
        _single_check(im, stride): Validate and possibly modify the input tensor.
    """

    def __init__(self, im0) -> None:
        """Initialize Tensor Dataloader."""
        # Validate and store the input tensor `im0`
        self.im0 = self._single_check(im0)
        # Infer batch size from the first dimension of the tensor
        self.bs = self.im0.shape[0]
        # Set the processing mode to 'image'
        self.mode = "image"
        # Generate filenames or use existing ones from input tensors
        self.paths = [getattr(im, "filename", f"image{i}.jpg") for i, im in enumerate(im0)]

    @staticmethod
    # éªŒè¯å¹¶å°†å›¾åƒæ ¼å¼åŒ–ä¸º torch.Tensor
    def _single_check(im, stride=32):
        """Validate and format an image to torch.Tensor."""
        # æ„å»ºè­¦å‘Šä¿¡æ¯ï¼Œç¡®ä¿è¾“å…¥çš„ torch.Tensor åº”ä¸º BCHW æ ¼å¼ï¼Œå³ shape(1, 3, 640, 640)ï¼Œä¸”èƒ½è¢«æŒ‡å®šçš„æ­¥é•¿ stride æ•´é™¤ã€‚å¦‚æœä¸å…¼å®¹åˆ™æŠ›å‡ºé”™è¯¯ã€‚
        s = (
            f"WARNING âš ï¸ torch.Tensor inputs should be BCHW i.e. shape(1, 3, 640, 640) "
            f"divisible by stride {stride}. Input shape{tuple(im.shape)} is incompatible."
        )
        # æ£€æŸ¥è¾“å…¥å›¾åƒçš„ç»´åº¦æ˜¯å¦ä¸º4ç»´ï¼Œå¦‚æœä¸æ˜¯ï¼Œåˆ™å°è¯•åœ¨ç¬¬0ç»´åº¦ä¸Šå¢åŠ ä¸€ä¸ªç»´åº¦ã€‚
        if len(im.shape) != 4:
            if len(im.shape) != 3:
                raise ValueError(s)
            # è®°å½•è­¦å‘Šæ—¥å¿—ï¼Œè¡¨ç¤ºè¾“å…¥å›¾åƒç»´åº¦ä¸ç¬¦åˆè¦æ±‚
            LOGGER.warning(s)
            im = im.unsqueeze(0)
        # æ£€æŸ¥å›¾åƒçš„é«˜åº¦å’Œå®½åº¦æ˜¯å¦èƒ½è¢«æŒ‡å®šçš„æ­¥é•¿æ•´é™¤ï¼Œå¦‚æœä¸èƒ½åˆ™æŠ›å‡ºé”™è¯¯ã€‚
        if im.shape[2] % stride or im.shape[3] % stride:
            raise ValueError(s)
        # å¦‚æœå›¾åƒä¸­çš„æœ€å¤§å€¼è¶…è¿‡äº†1.0åŠ ä¸Š torch.float32 ç±»å‹çš„è¯¯å·®å…è®¸å€¼ï¼Œè®°å½•è­¦å‘Šæ—¥å¿—ï¼Œå¹¶å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸º float ç±»å‹åå½’ä¸€åŒ–åˆ°0.0-1.0èŒƒå›´å†…ã€‚
        if im.max() > 1.0 + torch.finfo(im.dtype).eps:  # torch.float32 eps is 1.2e-07
            LOGGER.warning(
                f"WARNING âš ï¸ torch.Tensor inputs should be normalized 0.0-1.0 but max value is {im.max()}. "
                f"Dividing input by 255."
            )
            im = im.float() / 255.0

        return im

    # è¿”å›ä¸€ä¸ªè¿­ä»£å™¨å¯¹è±¡
    def __iter__(self):
        """Returns an iterator object."""
        self.count = 0
        return self

    # è¿”å›è¿­ä»£å™¨çš„ä¸‹ä¸€ä¸ªé¡¹ç›®
    def __next__(self):
        """Return next item in the iterator."""
        # å¦‚æœè®¡æ•°å™¨è¾¾åˆ°1ï¼ŒæŠ›å‡º StopIteration å¼‚å¸¸
        if self.count == 1:
            raise StopIteration
        # å¢åŠ è®¡æ•°å™¨çš„å€¼ï¼Œå¹¶è¿”å›è·¯å¾„ã€im0 å’Œç©ºåˆ—è¡¨ç»„æˆçš„å…ƒç»„
        self.count += 1
        return self.paths, self.im0, [""] * self.bs

    # è¿”å›æ‰¹å¤„ç†å¤§å°
    def __len__(self):
        """Returns the batch size."""
        return self.bs
def autocast_list(source):
    """
    Merges a list of source of different types into a list of numpy arrays or PIL images.

    Args:
        source (list): A list containing elements of various types like filenames, URIs, PIL Images, or numpy arrays.

    Returns:
        list: A list containing PIL Images or numpy arrays converted from the input sources.

    Raises:
        TypeError: If the input element is not of a supported type.

    """
    files = []
    for im in source:
        if isinstance(im, (str, Path)):  # filename or uri
            # Open the image from URL if it starts with "http", otherwise directly open as file
            files.append(Image.open(requests.get(im, stream=True).raw if str(im).startswith("http") else im))
        elif isinstance(im, (Image.Image, np.ndarray)):  # PIL or np Image
            files.append(im)
        else:
            raise TypeError(
                f"type {type(im).__name__} is not a supported Ultralytics prediction source type. \n"
                f"See https://docs.ultralytics.com/modes/predict for supported source types."
            )

    return files


def get_best_youtube_url(url, method="pytube"):
    """
    Retrieves the URL of the best quality MP4 video stream from a given YouTube video.

    Args:
        url (str): The URL of the YouTube video.
        method (str): The method to use for extracting video info. Default is "pytube". Other options are "pafy" and
            "yt-dlp".

    Returns:
        str: The URL of the best quality MP4 video stream, or None if no suitable stream is found.

    """
    if method == "pytube":
        # Ensure compatibility with pytubefix library version
        check_requirements("pytubefix>=6.5.2")
        from pytubefix import YouTube

        # Fetch video streams filtered by MP4 format and only video streams
        streams = YouTube(url).streams.filter(file_extension="mp4", only_video=True)
        # Sort streams by resolution in descending order
        streams = sorted(streams, key=lambda s: s.resolution, reverse=True)
        for stream in streams:
            # Check if stream resolution is at least 1080p
            if stream.resolution and int(stream.resolution[:-1]) >= 1080:
                return stream.url

    elif method == "pafy":
        # Ensure necessary libraries are installed and import pafy
        check_requirements(("pafy", "youtube_dl==2020.12.2"))
        import pafy  # noqa

        # Fetch the best available MP4 video stream URL
        return pafy.new(url).getbestvideo(preftype="mp4").url
    # å¦‚æœä¸‹è½½æ–¹æ³•ä¸º "yt-dlp"ï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹ä»£ç å—
    elif method == "yt-dlp":
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³ä½¿ç”¨ yt-dlp çš„è¦æ±‚
        check_requirements("yt-dlp")
        # å¯¼å…¥ yt_dlp æ¨¡å—
        import yt_dlp

        # ä½¿ç”¨ yt-dlp.YoutubeDL åˆ›å»ºä¸€ä¸ªå®ä¾‹ ydlï¼Œå¹¶è®¾ç½®å‚æ•° {"quiet": True}
        with yt_dlp.YoutubeDL({"quiet": True}) as ydl:
            # è°ƒç”¨ extract_info æ–¹æ³•ä»æŒ‡å®šçš„ url æå–è§†é¢‘ä¿¡æ¯ï¼Œä½†ä¸ä¸‹è½½è§†é¢‘
            info_dict = ydl.extract_info(url, download=False)

        # éå†è§†é¢‘æ ¼å¼ä¿¡æ¯åˆ—è¡¨ï¼ˆåå‘éå†ï¼Œå› ä¸ºæœ€ä½³æ ¼å¼é€šå¸¸åœ¨æœ€åï¼‰
        for f in reversed(info_dict.get("formats", [])):
            # æ£€æŸ¥å½“å‰æ ¼å¼æ˜¯å¦æ»¡è¶³æ¡ä»¶ï¼šè§†é¢‘ç¼–è§£ç å™¨å­˜åœ¨ã€æ— éŸ³é¢‘ã€æ‰©å±•åä¸º mp4ã€è‡³å°‘ 1920x1080 å¤§å°
            good_size = (f.get("width") or 0) >= 1920 or (f.get("height") or 0) >= 1080
            if good_size and f["vcodec"] != "none" and f["acodec"] == "none" and f["ext"] == "mp4":
                # å¦‚æœç¬¦åˆæ¡ä»¶ï¼Œè¿”å›è¯¥æ ¼å¼çš„è§†é¢‘ URL
                return f.get("url")
# å®šä¹‰å¸¸é‡ LOADERSï¼ŒåŒ…å«å››ä¸ªä¸åŒçš„åŠ è½½å™¨ç±»
LOADERS = (LoadStreams, LoadPilAndNumpy, LoadImagesAndVideos, LoadScreenshots)
```