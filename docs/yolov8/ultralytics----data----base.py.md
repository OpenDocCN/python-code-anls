# `.\yolov8\ultralytics\data\base.py`

```
# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import glob  # å¯¼å…¥ç”¨äºè·å–æ–‡ä»¶è·¯å¾„çš„æ¨¡å—
import math  # å¯¼å…¥æ•°å­¦å‡½æ•°æ¨¡å—
import os  # å¯¼å…¥æ“ä½œç³»ç»ŸåŠŸèƒ½æ¨¡å—
import random  # å¯¼å…¥ç”Ÿæˆéšæœºæ•°çš„æ¨¡å—
from copy import deepcopy  # å¯¼å…¥æ·±æ‹·è´å‡½æ•°
from multiprocessing.pool import ThreadPool  # å¯¼å…¥å¤šçº¿ç¨‹æ± æ¨¡å—
from pathlib import Path  # å¯¼å…¥å¤„ç†è·¯å¾„çš„æ¨¡å—
from typing import Optional  # å¯¼å…¥ç±»å‹æç¤ºæ¨¡å—

import cv2  # å¯¼å…¥OpenCVå›¾åƒå¤„ç†åº“
import numpy as np  # å¯¼å…¥NumPyæ•°å€¼è®¡ç®—åº“
import psutil  # å¯¼å…¥è¿›ç¨‹å’Œç³»ç»Ÿä¿¡æ¯è·å–æ¨¡å—
from torch.utils.data import Dataset  # å¯¼å…¥PyTorchæ•°æ®é›†åŸºç±»

from ultralytics.data.utils import FORMATS_HELP_MSG, HELP_URL, IMG_FORMATS  # å¯¼å…¥è‡ªå®šä¹‰æ•°æ®å¤„ç†å·¥å…·
from ultralytics.utils import DEFAULT_CFG, LOCAL_RANK, LOGGER, NUM_THREADS, TQDM  # å¯¼å…¥è‡ªå®šä¹‰å·¥å…·å‡½æ•°


class BaseDataset(Dataset):
    """
    Base dataset class for loading and processing image data.

    Args:
        img_path (str): Path to the folder containing images.
        imgsz (int, optional): Image size. Defaults to 640.
        cache (bool, optional): Cache images to RAM or disk during training. Defaults to False.
        augment (bool, optional): If True, data augmentation is applied. Defaults to True.
        hyp (dict, optional): Hyperparameters to apply data augmentation. Defaults to None.
        prefix (str, optional): Prefix to print in log messages. Defaults to ''.
        rect (bool, optional): If True, rectangular training is used. Defaults to False.
        batch_size (int, optional): Size of batches. Defaults to None.
        stride (int, optional): Stride. Defaults to 32.
        pad (float, optional): Padding. Defaults to 0.0.
        single_cls (bool, optional): If True, single class training is used. Defaults to False.
        classes (list): List of included classes. Default is None.
        fraction (float): Fraction of dataset to utilize. Default is 1.0 (use all data).

    Attributes:
        im_files (list): List of image file paths.
        labels (list): List of label data dictionaries.
        ni (int): Number of images in the dataset.
        ims (list): List of loaded images.
        npy_files (list): List of numpy file paths.
        transforms (callable): Image transformation function.
    """

    def __init__(
        self,
        img_path,
        imgsz=640,
        cache=False,
        augment=True,
        hyp=DEFAULT_CFG,
        prefix="",
        rect=False,
        batch_size=16,
        stride=32,
        pad=0.5,
        single_cls=False,
        classes=None,
        fraction=1.0,
        ):
        # åˆå§‹åŒ–æ•°æ®é›†å¯¹è±¡ï¼Œè®¾ç½®å„ç§å‚æ•°å’Œå±æ€§
        """Initialize BaseDataset with given configuration and options."""
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        super().__init__()
        # è®¾ç½®å›¾ç‰‡è·¯å¾„
        self.img_path = img_path
        # å›¾åƒå¤§å°
        self.imgsz = imgsz
        # æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼º
        self.augment = augment
        # æ˜¯å¦å•ç±»åˆ«
        self.single_cls = single_cls
        # æ•°æ®é›†å‰ç¼€
        self.prefix = prefix
        # æ•°æ®é›†é‡‡æ ·æ¯”ä¾‹
        self.fraction = fraction
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶è·¯å¾„
        self.im_files = self.get_img_files(self.img_path)
        # è·å–æ ‡ç­¾
        self.labels = self.get_labels()
        # æ›´æ–°æ ‡ç­¾ï¼Œæ ¹æ®æ˜¯å¦å•ç±»åˆ«å’ŒæŒ‡å®šçš„ç±»åˆ«
        self.update_labels(include_class=classes)  # single_cls and include_class
        # å›¾åƒæ•°é‡
        self.ni = len(self.labels)  # number of images
        # æ˜¯å¦ä½¿ç”¨çŸ©å½¢è¾¹ç•Œæ¡†
        self.rect = rect
        # æ‰¹å¤„ç†å¤§å°
        self.batch_size = batch_size
        # æ­¥é•¿
        self.stride = stride
        # å¡«å……
        self.pad = pad
        # å¦‚æœä½¿ç”¨çŸ©å½¢è¾¹ç•Œæ¡†ï¼Œç¡®ä¿æŒ‡å®šäº†æ‰¹å¤„ç†å¤§å°
        if self.rect:
            assert self.batch_size is not None
            # è®¾ç½®çŸ©å½¢è¾¹ç•Œæ¡†å‚æ•°
            self.set_rectangle()

        # ç”¨äºé©¬èµ›å…‹å›¾åƒçš„ç¼“å†²çº¿ç¨‹
        self.buffer = []  # buffer size = batch size
        # æœ€å¤§ç¼“å†²é•¿åº¦ï¼Œæœ€å°ä¸ºå›¾åƒæ•°é‡ã€æ‰¹å¤„ç†å¤§å°çš„8å€ã€1000ä¸­çš„æœ€å°å€¼ï¼ˆå¦‚æœè¿›è¡Œæ•°æ®å¢å¼ºï¼‰
        self.max_buffer_length = min((self.ni, self.batch_size * 8, 1000)) if self.augment else 0

        # ç¼“å­˜å›¾åƒï¼ˆç¼“å­˜é€‰é¡¹åŒ…æ‹¬ True, False, None, "ram", "disk"ï¼‰
        self.ims, self.im_hw0, self.im_hw = [None] * self.ni, [None] * self.ni, [None] * self.ni
        # ç”Ÿæˆæ¯ä¸ªå›¾åƒæ–‡ä»¶å¯¹åº”çš„ .npy æ–‡ä»¶è·¯å¾„
        self.npy_files = [Path(f).with_suffix(".npy") for f in self.im_files]
        # è®¾ç½®ç¼“å­˜é€‰é¡¹
        self.cache = cache.lower() if isinstance(cache, str) else "ram" if cache is True else None
        # å¦‚æœç¼“å­˜é€‰é¡¹æ˜¯ "ram" å¹¶ä¸”å†…å­˜ä¸­å·²å­˜åœ¨ç¼“å­˜ï¼Œæˆ–è€…ç¼“å­˜é€‰é¡¹æ˜¯ "disk"ï¼Œåˆ™è¿›è¡Œå›¾åƒç¼“å­˜
        if (self.cache == "ram" and self.check_cache_ram()) or self.cache == "disk":
            self.cache_images()

        # æ„å»ºå›¾åƒè½¬æ¢æ“ä½œ
        self.transforms = self.build_transforms(hyp=hyp)
    def get_img_files(self, img_path):
        """Read image files."""
        try:
            f = []  # image filesåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å›¾åƒæ–‡ä»¶è·¯å¾„
            for p in img_path if isinstance(img_path, list) else [img_path]:
                p = Path(p)  # å°†è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡ï¼Œä»¥ä¿è¯åœ¨ä¸åŒæ“ä½œç³»ç»Ÿä¸Šçš„å…¼å®¹æ€§
                if p.is_dir():  # å¦‚æœæ˜¯ç›®å½•
                    f += glob.glob(str(p / "**" / "*.*"), recursive=True)
                    # è·å–ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶çš„è·¯å¾„ï¼Œå¹¶åŠ å…¥åˆ°fåˆ—è¡¨ä¸­
                    # ä½¿ç”¨globæ¨¡å—ï¼Œæ”¯æŒé€’å½’æŸ¥æ‰¾
                    # ä½¿ç”¨pathlibçš„æ–¹å¼ï¼šF = list(p.rglob('*.*'))  
                elif p.is_file():  # å¦‚æœæ˜¯æ–‡ä»¶
                    with open(p) as t:
                        t = t.read().strip().splitlines()  # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œå¹¶æŒ‰è¡Œåˆ†å‰²
                        parent = str(p.parent) + os.sep
                        # è·å–æ–‡ä»¶çš„çˆ¶ç›®å½•ï¼Œå¹¶åœ¨æ¯ä¸ªæ–‡ä»¶è·¯å¾„å‰æ·»åŠ çˆ¶ç›®å½•è·¯å¾„ï¼Œå¤„ç†æœ¬åœ°åˆ°å…¨å±€è·¯å¾„çš„è½¬æ¢
                        f += [x.replace("./", parent) if x.startswith("./") else x for x in t]
                        # å°†æ–‡ä»¶è·¯å¾„æ·»åŠ åˆ°fåˆ—è¡¨ä¸­ï¼Œå¤„ç†ç›¸å¯¹è·¯å¾„
                        # ä½¿ç”¨pathlibçš„æ–¹å¼ï¼šF += [p.parent / x.lstrip(os.sep) for x in t]
                else:
                    raise FileNotFoundError(f"{self.prefix}{p} does not exist")
                    # å¦‚æœæ—¢ä¸æ˜¯æ–‡ä»¶ä¹Ÿä¸æ˜¯ç›®å½•ï¼Œåˆ™æŠ›å‡ºæ–‡ä»¶ä¸å­˜åœ¨çš„å¼‚å¸¸
            im_files = sorted(x.replace("/", os.sep) for x in f if x.split(".")[-1].lower() in IMG_FORMATS)
            # å¯¹fåˆ—è¡¨ä¸­çš„æ–‡ä»¶è·¯å¾„è¿›è¡Œç­›é€‰ï¼Œä¿ç•™ç¬¦åˆå›¾åƒæ ¼å¼çš„æ–‡ä»¶è·¯å¾„ï¼Œå¹¶æ’åº
            # ä½¿ç”¨pathlibçš„æ–¹å¼ï¼šself.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])
            assert im_files, f"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}"
            # å¦‚æœim_filesä¸ºç©ºï¼Œåˆ™æŠ›å‡ºæ–­è¨€é”™è¯¯ï¼Œè¡¨ç¤ºæœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶
        except Exception as e:
            raise FileNotFoundError(f"{self.prefix}Error loading data from {img_path}\n{HELP_URL}") from e
            # æ•è·æ‰€æœ‰å¼‚å¸¸ï¼Œå¹¶æŠ›å‡ºå¸¦æœ‰è¯¦ç»†ä¿¡æ¯çš„æ–‡ä»¶åŠ è½½é”™è¯¯å¼‚å¸¸
        if self.fraction < 1:
            im_files = im_files[: round(len(im_files) * self.fraction)]  # ä¿ç•™æ•°æ®é›†çš„ä¸€éƒ¨åˆ†æ¯”ä¾‹
            # å¦‚æœfractionå°äº1ï¼Œåˆ™æ ¹æ®fractionä¿ç•™im_filesä¸­çš„éƒ¨åˆ†æ–‡ä»¶è·¯å¾„
        return im_files
        # è¿”å›å¤„ç†åçš„å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨

    def update_labels(self, include_class: Optional[list]):
        """Update labels to include only these classes (optional)."""
        include_class_array = np.array(include_class).reshape(1, -1)
        # å°†include_classè½¬æ¢ä¸ºNumPyæ•°ç»„ï¼Œå¹¶è¿›è¡Œå½¢çŠ¶é‡å¡‘
        for i in range(len(self.labels)):
            if include_class is not None:  # å¦‚æœinclude_classä¸ä¸ºç©º
                cls = self.labels[i]["cls"]
                bboxes = self.labels[i]["bboxes"]
                segments = self.labels[i]["segments"]
                keypoints = self.labels[i]["keypoints"]
                j = (cls == include_class_array).any(1)
                # æ‰¾åˆ°æ ‡ç­¾ä¸­ä¸include_classç›¸åŒ¹é…çš„ç±»åˆ«ç´¢å¼•
                self.labels[i]["cls"] = cls[j]  # æ›´æ–°ç±»åˆ«
                self.labels[i]["bboxes"] = bboxes[j]  # æ›´æ–°è¾¹ç•Œæ¡†
                if segments:  # å¦‚æœå­˜åœ¨åˆ†å‰²ä¿¡æ¯
                    self.labels[i]["segments"] = [segments[si] for si, idx in enumerate(j) if idx]
                    # æ›´æ–°åˆ†å‰²ä¿¡æ¯ï¼Œåªä¿ç•™ä¸include_classåŒ¹é…çš„åˆ†å‰²
                if keypoints is not None:  # å¦‚æœå­˜åœ¨å…³é”®ç‚¹ä¿¡æ¯
                    self.labels[i]["keypoints"] = keypoints[j]  # æ›´æ–°å…³é”®ç‚¹ä¿¡æ¯
            if self.single_cls:  # å¦‚æœæ ‡ç­¾æ˜¯å•ç±»åˆ«çš„
                self.labels[i]["cls"][:, 0] = 0  # å°†æ‰€æœ‰ç±»åˆ«æ ‡è®°ä¸º0
    def load_image(self, i, rect_mode=True):
        """Loads 1 image from dataset index 'i', returns (im, resized hw)."""
        # ä»æ•°æ®é›†ç´¢å¼• 'i' åŠ è½½ä¸€å¼ å›¾ç‰‡ï¼Œå¹¶è¿”å›åŸå›¾å’Œè°ƒæ•´å¤§å°åçš„å°ºå¯¸
        im, f, fn = self.ims[i], self.im_files[i], self.npy_files[i]
        
        if im is None:  # not cached in RAM
            # å¦‚æœå›¾åƒæœªè¢«ç¼“å­˜åœ¨å†…å­˜ä¸­
            if fn.exists():  # load npy
                # å¦‚æœå­˜åœ¨å¯¹åº”çš„ *.npy æ–‡ä»¶ï¼Œåˆ™åŠ è½½è¯¥æ–‡ä»¶
                try:
                    im = np.load(fn)
                except Exception as e:
                    # æ•è·å¼‚å¸¸ï¼Œè­¦å‘Šå¹¶åˆ é™¤æŸåçš„ *.npy å›¾åƒæ–‡ä»¶
                    LOGGER.warning(f"{self.prefix}WARNING âš ï¸ Removing corrupt *.npy image file {fn} due to: {e}")
                    Path(fn).unlink(missing_ok=True)
                    # ä»åŸå§‹å›¾åƒæ–‡ä»¶åŠ è½½å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
                    im = cv2.imread(f)  # BGR
            else:  # read image
                # å¦åˆ™ï¼Œç›´æ¥ä»åŸå§‹å›¾åƒæ–‡ä»¶ä¸­è¯»å–å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
                im = cv2.imread(f)  # BGR
            
            # å¦‚æœæœªèƒ½æˆåŠŸåŠ è½½å›¾åƒï¼Œåˆ™æŠ›å‡ºæ–‡ä»¶æœªæ‰¾åˆ°å¼‚å¸¸
            if im is None:
                raise FileNotFoundError(f"Image Not Found {f}")

            h0, w0 = im.shape[:2]  # orig hw
            if rect_mode:  # resize long side to imgsz while maintaining aspect ratio
                # å¦‚æœçŸ©å½¢æ¨¡å¼ä¸ºçœŸï¼Œåˆ™å°†é•¿è¾¹è°ƒæ•´åˆ°æŒ‡å®šçš„imgszå¤§å°ï¼Œå¹¶ä¿æŒçºµæ¨ªæ¯”
                r = self.imgsz / max(h0, w0)  # ratio
                if r != 1:  # if sizes are not equal
                    # è®¡ç®—è°ƒæ•´åçš„å®½é«˜ï¼Œå¹¶è¿›è¡Œæ’å€¼ç¼©æ”¾
                    w, h = (min(math.ceil(w0 * r), self.imgsz), min(math.ceil(h0 * r), self.imgsz))
                    im = cv2.resize(im, (w, h), interpolation=cv2.INTER_LINEAR)
            elif not (h0 == w0 == self.imgsz):  # resize by stretching image to square imgsz
                # å¦åˆ™ï¼Œå°†å›¾åƒæ‹‰ä¼¸è°ƒæ•´åˆ°æ­£æ–¹å½¢å¤§å°imgsz
                im = cv2.resize(im, (self.imgsz, self.imgsz), interpolation=cv2.INTER_LINEAR)

            # å¦‚æœè¿›è¡Œæ•°æ®å¢å¼ºè®­ç»ƒï¼Œåˆ™å°†å¤„ç†åçš„å›¾åƒæ•°æ®å’ŒåŸå§‹ã€è°ƒæ•´åçš„å°ºå¯¸ä¿å­˜åˆ°ç¼“å†²åŒº
            if self.augment:
                self.ims[i], self.im_hw0[i], self.im_hw[i] = im, (h0, w0), im.shape[:2]  # im, hw_original, hw_resized
                self.buffer.append(i)
                if 1 < len(self.buffer) >= self.max_buffer_length:  # prevent empty buffer
                    # å¦‚æœç¼“å†²åŒºé•¿åº¦è¶…è¿‡æœ€å¤§é•¿åº¦é™åˆ¶ï¼Œåˆ™å¼¹å‡ºæœ€æ—§çš„å…ƒç´ 
                    j = self.buffer.pop(0)
                    if self.cache != "ram":
                        # å¦‚æœä¸æ˜¯RAMç¼“å­˜ï¼Œåˆ™æ¸…ç©ºè¯¥ä½ç½®çš„å›¾åƒå’Œå°ºå¯¸æ•°æ®
                        self.ims[j], self.im_hw0[j], self.im_hw[j] = None, None, None

            # è¿”å›åŠ è½½çš„å›¾åƒã€åŸå§‹å°ºå¯¸å’Œè°ƒæ•´åçš„å°ºå¯¸
            return im, (h0, w0), im.shape[:2]

        # å¦‚æœå›¾åƒå·²ç¼“å­˜åœ¨å†…å­˜ä¸­ï¼Œåˆ™ç›´æ¥è¿”å›å·²ç¼“å­˜çš„å›¾åƒåŠå…¶åŸå§‹å’Œè°ƒæ•´åçš„å°ºå¯¸
        return self.ims[i], self.im_hw0[i], self.im_hw[i]

    def cache_images(self):
        """Cache images to memory or disk."""
        b, gb = 0, 1 << 30  # bytes of cached images, bytes per gigabytes
        # æ ¹æ®ç¼“å­˜é€‰é¡¹é€‰æ‹©ä¸åŒçš„ç¼“å­˜å‡½æ•°å’Œå­˜å‚¨ä»‹è´¨
        fcn, storage = (self.cache_images_to_disk, "Disk") if self.cache == "disk" else (self.load_image, "RAM")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†å›¾åƒç¼“å­˜æ“ä½œ
        with ThreadPool(NUM_THREADS) as pool:
            # å¹¶è¡ŒåŠ è½½å›¾åƒæˆ–æ‰§è¡Œç¼“å­˜æ“ä½œ
            results = pool.imap(fcn, range(self.ni))
            # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºç¼“å­˜è¿›åº¦
            pbar = TQDM(enumerate(results), total=self.ni, disable=LOCAL_RANK > 0)
            for i, x in pbar:
                if self.cache == "disk":
                    # å¦‚æœç¼“å­˜åˆ°ç£ç›˜ï¼Œåˆ™ç´¯åŠ ç¼“å­˜çš„å›¾åƒæ–‡ä»¶å¤§å°
                    b += self.npy_files[i].stat().st_size
                else:  # 'ram'
                    # å¦‚æœç¼“å­˜åˆ°RAMï¼Œåˆ™ç›´æ¥å°†åŠ è½½çš„å›¾åƒå’Œå…¶å°ºå¯¸ä¿å­˜åˆ°ç›¸åº”çš„ä½ç½®
                    self.ims[i], self.im_hw0[i], self.im_hw[i] = x
                    b += self.ims[i].nbytes
                # æ›´æ–°è¿›åº¦æ¡æè¿°ä¿¡æ¯ï¼Œæ˜¾ç¤ºå½“å‰ç¼“å­˜çš„æ€»é‡åŠå­˜å‚¨ä»‹è´¨
                pbar.desc = f"{self.prefix}Caching images ({b / gb:.1f}GB {storage})"
            pbar.close()
    def cache_images_to_disk(self, i):
        """Saves an image as an *.npy file for faster loading."""
        f = self.npy_files[i]  # è·å–ç¬¬ i ä¸ª *.npy æ–‡ä»¶çš„è·¯å¾„
        if not f.exists():  # å¦‚æœè¯¥æ–‡ä»¶ä¸å­˜åœ¨
            np.save(f.as_posix(), cv2.imread(self.im_files[i]), allow_pickle=False)  # å°†å¯¹åº”å›¾åƒä¿å­˜ä¸º *.npy æ–‡ä»¶

    def check_cache_ram(self, safety_margin=0.5):
        """Check image caching requirements vs available memory."""
        b, gb = 0, 1 << 30  # åˆå§‹åŒ–ç¼“å­˜å›¾åƒå ç”¨çš„å­—èŠ‚æ•°å’Œæ¯ä¸ª GB çš„å­—èŠ‚æ•°
        n = min(self.ni, 30)  # é€‰å– self.ni å’Œ 30 ä¸­è¾ƒå°çš„ä¸€ä¸ªä½œä¸ºé‡‡æ ·å›¾ç‰‡æ•°ç›®
        for _ in range(n):
            im = cv2.imread(random.choice(self.im_files))  # éšæœºé€‰å–ä¸€å¼ å›¾ç‰‡è¿›è¡Œè¯»å–
            ratio = self.imgsz / max(im.shape[0], im.shape[1])  # è®¡ç®—å›¾ç‰‡å°ºå¯¸ä¸æœ€å¤§å®½é«˜ä¹‹æ¯”
            b += im.nbytes * ratio**2  # è®¡ç®—æ¯å¼ å›¾ç‰‡å ç”¨çš„å†…å­˜å­—èŠ‚æ•°ï¼Œå¹¶æ ¹æ®æ¯”ç‡è¿›è¡ŒåŠ æƒæ±‚å’Œ
        mem_required = b * self.ni / n * (1 + safety_margin)  # è®¡ç®—éœ€è¦ç¼“å­˜æ•´ä¸ªæ•°æ®é›†æ‰€éœ€çš„å†…å­˜å¤§å°ï¼ˆGBï¼‰
        mem = psutil.virtual_memory()  # è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯
        success = mem_required < mem.available  # åˆ¤æ–­æ˜¯å¦æœ‰è¶³å¤Ÿçš„å†…å­˜æ¥ç¼“å­˜æ•°æ®é›†
        if not success:  # å¦‚æœå†…å­˜ä¸è¶³
            self.cache = None  # æ¸…ç©ºç¼“å­˜
            LOGGER.info(
                f"{self.prefix}{mem_required / gb:.1f}GB RAM required to cache images "
                f"with {int(safety_margin * 100)}% safety margin but only "
                f"{mem.available / gb:.1f}/{mem.total / gb:.1f}GB available, not caching images âš ï¸"
            )  # è®°å½•æ—¥å¿—ï¼Œæ˜¾ç¤ºç¼“å­˜å¤±è´¥çš„åŸå› å’Œç›¸å…³å†…å­˜ä¿¡æ¯
        return success  # è¿”å›æ˜¯å¦æˆåŠŸç¼“å­˜çš„å¸ƒå°”å€¼

    def set_rectangle(self):
        """Sets the shape of bounding boxes for YOLO detections as rectangles."""
        bi = np.floor(np.arange(self.ni) / self.batch_size).astype(int)  # è®¡ç®—æ¯å¼ å›¾ç‰‡æ‰€å±çš„æ‰¹æ¬¡ç´¢å¼•
        nb = bi[-1] + 1  # è®¡ç®—æ€»æ‰¹æ¬¡æ•°

        s = np.array([x.pop("shape") for x in self.labels])  # æå–æ ‡ç­¾ä¸­çš„å½¢çŠ¶ä¿¡æ¯ï¼ˆå®½é«˜ï¼‰
        ar = s[:, 0] / s[:, 1]  # è®¡ç®—å®½é«˜æ¯”
        irect = ar.argsort()  # å¯¹å®½é«˜æ¯”è¿›è¡Œæ’åºçš„ç´¢å¼•
        self.im_files = [self.im_files[i] for i in irect]  # æ ¹æ®æ’åºåçš„ç´¢å¼•é‡æ–°æ’åˆ—å›¾åƒæ–‡ä»¶è·¯å¾„
        self.labels = [self.labels[i] for i in irect]  # æ ¹æ®æ’åºåçš„ç´¢å¼•é‡æ–°æ’åˆ—æ ‡ç­¾
        ar = ar[irect]  # æ ¹æ®æ’åºåçš„ç´¢å¼•é‡æ–°æ’åˆ—å®½é«˜æ¯”

        # è®¾ç½®è®­ç»ƒå›¾åƒçš„å½¢çŠ¶
        shapes = [[1, 1]] * nb
        for i in range(nb):
            ari = ar[bi == i]  # æ‰¾å‡ºå±äºå½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰å›¾ç‰‡çš„å®½é«˜æ¯”
            mini, maxi = ari.min(), ari.max()  # è®¡ç®—å½“å‰æ‰¹æ¬¡å†…å®½é«˜æ¯”çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
            if maxi < 1:
                shapes[i] = [maxi, 1]  # å¦‚æœæœ€å¤§å®½é«˜æ¯”å°äº1ï¼Œåˆ™è®¾ä¸ºæœ€å¤§å®½åº¦ï¼Œé«˜åº¦ä¸º1
            elif mini > 1:
                shapes[i] = [1, 1 / mini]  # å¦‚æœæœ€å°å®½é«˜æ¯”å¤§äº1ï¼Œåˆ™è®¾ä¸ºå®½åº¦1ï¼Œé«˜åº¦ä¸ºæœ€å°é«˜åº¦çš„å€’æ•°

        self.batch_shapes = np.ceil(np.array(shapes) * self.imgsz / self.stride + self.pad).astype(int) * self.stride  # è®¡ç®—æ‰¹æ¬¡å½¢çŠ¶ï¼Œä¿è¯æ•´æ•°å€çš„æ­¥é•¿
        self.batch = bi  # è®°å½•æ¯å¼ å›¾åƒæ‰€å±çš„æ‰¹æ¬¡ç´¢å¼•

    def __getitem__(self, index):
        """Returns transformed label information for given index."""
        return self.transforms(self.get_image_and_label(index))  # è¿”å›ç»™å®šç´¢å¼•çš„å›¾åƒå’Œæ ‡ç­¾çš„è½¬æ¢ä¿¡æ¯
    def get_image_and_label(self, index):
        """Get and return label information from the dataset."""
        label = deepcopy(self.labels[index])  # åˆ›å»ºæ ‡ç­¾çš„æ·±å±‚å‰¯æœ¬ï¼Œç¡®ä¿ä¸å½±å“åŸå§‹æ•°æ® https://github.com/ultralytics/ultralytics/pull/1948
        label.pop("shape", None)  # å¦‚æœå­˜åœ¨å½¢çŠ¶ä¿¡æ¯ï¼Œä»æ ‡ç­¾ä¸­ç§»é™¤ï¼Œé€šå¸¸é€‚ç”¨äºçŸ©å½¢æ ‡æ³¨æ•°æ®
        # è½½å…¥å›¾åƒå¹¶å°†ç›¸å…³ä¿¡æ¯å­˜å…¥æ ‡ç­¾å­—å…¸
        label["img"], label["ori_shape"], label["resized_shape"] = self.load_image(index)
        # è®¡ç®—å›¾åƒç¼©æ”¾æ¯”ä¾‹ï¼Œç”¨äºè¯„ä¼°
        label["ratio_pad"] = (
            label["resized_shape"][0] / label["ori_shape"][0],
            label["resized_shape"][1] / label["ori_shape"][1],
        )
        if self.rect:
            # å¦‚æœä½¿ç”¨çŸ©å½¢æ¨¡å¼ï¼Œæ·»åŠ æ‰¹æ¬¡å¯¹åº”çš„å½¢çŠ¶ä¿¡æ¯åˆ°æ ‡ç­¾ä¸­
            label["rect_shape"] = self.batch_shapes[self.batch[index]]
        # æ›´æ–°æ ‡ç­¾ä¿¡æ¯å¹¶è¿”å›
        return self.update_labels_info(label)

    def __len__(self):
        """Returns the length of the labels list for the dataset."""
        # è¿”å›æ•°æ®é›†æ ‡ç­¾åˆ—è¡¨çš„é•¿åº¦
        return len(self.labels)

    def update_labels_info(self, label):
        """Custom your label format here."""
        # è‡ªå®šä¹‰æ ‡ç­¾æ ¼å¼çš„æ–¹æ³•ï¼Œç›´æ¥è¿”å›è¾“å…¥çš„æ ‡ç­¾
        return label

    def build_transforms(self, hyp=None):
        """
        Users can customize augmentations here.

        Example:
            ```py
            if self.augment:
                # Training transforms
                return Compose([])
            else:
                # Val transforms
                return Compose([])
            ```
        """
        # ç”¨æˆ·å¯ä»¥åœ¨æ­¤å¤„è‡ªå®šä¹‰æ•°æ®å¢å¼ºæ“ä½œï¼Œæ­¤å¤„æŠ›å‡ºæœªå®ç°é”™è¯¯ï¼Œé¼“åŠ±ç”¨æˆ·è¿›è¡Œå®šåˆ¶
        raise NotImplementedError

    def get_labels(self):
        """
        Users can customize their own format here.

        Note:
            Ensure output is a dictionary with the following keys:
            ```py
            dict(
                im_file=im_file,
                shape=shape,  # format: (height, width)
                cls=cls,
                bboxes=bboxes, # xywh
                segments=segments,  # xy
                keypoints=keypoints, # xy
                normalized=True, # or False
                bbox_format="xyxy",  # or xywh, ltwh
            )
            ```
        """
        # ç”¨æˆ·å¯ä»¥åœ¨æ­¤å¤„è‡ªå®šä¹‰æ ‡ç­¾è¾“å‡ºæ ¼å¼ï¼Œæ­¤å¤„æŠ›å‡ºæœªå®ç°é”™è¯¯ï¼Œé¼“åŠ±ç”¨æˆ·è¿›è¡Œå®šåˆ¶
        raise NotImplementedError
```