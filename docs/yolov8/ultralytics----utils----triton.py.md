# `.\yolov8\ultralytics\utils\triton.py`

```
# Ultralytics YOLO ğŸš€, AGPL-3.0 license

# å¼•å…¥å¿…è¦çš„ç±»å‹
from typing import List
# è§£æ URL çš„ç»„ä»¶
from urllib.parse import urlsplit

# å¼•å…¥ NumPy åº“
import numpy as np


class TritonRemoteModel:
    """
    ç”¨äºä¸è¿œç¨‹ Triton æ¨ç†æœåŠ¡å™¨æ¨¡å‹è¿›è¡Œäº¤äº’çš„å®¢æˆ·ç«¯ç±»ã€‚

    Attributes:
        endpoint (str): Triton æœåŠ¡å™¨ä¸Šæ¨¡å‹çš„åç§°ã€‚
        url (str): Triton æœåŠ¡å™¨çš„ URLã€‚
        triton_client: Triton å®¢æˆ·ç«¯ï¼ˆå¯ä»¥æ˜¯ HTTP æˆ– gRPCï¼‰ã€‚
        InferInput: Triton å®¢æˆ·ç«¯çš„è¾“å…¥ç±»ã€‚
        InferRequestedOutput: Triton å®¢æˆ·ç«¯çš„è¾“å‡ºè¯·æ±‚ç±»ã€‚
        input_formats (List[str]): æ¨¡å‹è¾“å…¥çš„æ•°æ®ç±»å‹ã€‚
        np_input_formats (List[type]): æ¨¡å‹è¾“å…¥çš„ NumPy æ•°æ®ç±»å‹ã€‚
        input_names (List[str]): æ¨¡å‹è¾“å…¥çš„åç§°åˆ—è¡¨ã€‚
        output_names (List[str]): æ¨¡å‹è¾“å‡ºçš„åç§°åˆ—è¡¨ã€‚
    """

    def __init__(self, url: str, endpoint: str = "", scheme: str = ""):
        """
        åˆå§‹åŒ– TritonRemoteModelã€‚

        å‚æ•°å¯ä»¥å•ç‹¬æä¾›ï¼Œä¹Ÿå¯ä»¥ä»å½¢å¦‚ <scheme>://<netloc>/<endpoint>/<task_name> çš„ 'url' å‚æ•°ä¸­è§£æã€‚

        Args:
            url (str): Triton æœåŠ¡å™¨çš„ URLã€‚
            endpoint (str): Triton æœåŠ¡å™¨ä¸Šæ¨¡å‹çš„åç§°ã€‚
            scheme (str): é€šä¿¡åè®®ï¼ˆ'http' æˆ– 'grpc'ï¼‰ã€‚
        """
        if not endpoint and not scheme:  # ä» URL å­—ç¬¦ä¸²ä¸­è§£ææ‰€æœ‰å‚æ•°
            splits = urlsplit(url)
            endpoint = splits.path.strip("/").split("/")[0]
            scheme = splits.scheme
            url = splits.netloc

        self.endpoint = endpoint
        self.url = url

        # æ ¹æ®é€šä¿¡åè®®é€‰æ‹© Triton å®¢æˆ·ç«¯
        if scheme == "http":
            import tritonclient.http as client  # noqa

            self.triton_client = client.InferenceServerClient(url=self.url, verbose=False, ssl=False)
            config = self.triton_client.get_model_config(endpoint)
        else:
            import tritonclient.grpc as client  # noqa

            self.triton_client = client.InferenceServerClient(url=self.url, verbose=False, ssl=False)
            config = self.triton_client.get_model_config(endpoint, as_json=True)["config"]

        # æŒ‰å­—æ¯é¡ºåºå¯¹è¾“å‡ºåç§°è¿›è¡Œæ’åºï¼Œä¾‹å¦‚ 'output0', 'output1' ç­‰ã€‚
        config["output"] = sorted(config["output"], key=lambda x: x.get("name"))

        # å®šä¹‰æ¨¡å‹å±æ€§
        type_map = {"TYPE_FP32": np.float32, "TYPE_FP16": np.float16, "TYPE_UINT8": np.uint8}
        self.InferRequestedOutput = client.InferRequestedOutput
        self.InferInput = client.InferInput
        self.input_formats = [x["data_type"] for x in config["input"]]
        self.np_input_formats = [type_map[x] for x in self.input_formats]
        self.input_names = [x["name"] for x in config["input"]]
        self.output_names = [x["name"] for x in config["output"]]
    # å®šä¹‰ä¸€ä¸ªç‰¹æ®Šæ–¹æ³• __call__ï¼Œå…è®¸å°†å®ä¾‹å¯¹è±¡åƒå‡½æ•°ä¸€æ ·è°ƒç”¨ï¼Œæ¥å—å¤šä¸ª numpy æ•°ç»„ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›å¤šä¸ª numpy æ•°ç»„ä½œä¸ºè¾“å‡º
    def __call__(self, *inputs: np.ndarray) -> List[np.ndarray]:
        """
        Call the model with the given inputs.

        Args:
            *inputs (List[np.ndarray]): Input data to the model.

        Returns:
            (List[np.ndarray]): Model outputs.
        """
        # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ¨ç†è¾“å…¥
        infer_inputs = []
        # è·å–è¾“å…¥æ•°ç»„çš„æ•°æ®ç±»å‹ï¼Œå‡è®¾æ‰€æœ‰è¾“å…¥æ•°ç»„çš„æ•°æ®ç±»å‹ç›¸åŒ
        input_format = inputs[0].dtype
        # éå†æ‰€æœ‰è¾“å…¥æ•°ç»„
        for i, x in enumerate(inputs):
            # å¦‚æœå½“å‰è¾“å…¥æ•°ç»„çš„æ•°æ®ç±»å‹ä¸é¢„æœŸçš„è¾“å…¥æ•°æ®ç±»å‹ä¸åŒ¹é…ï¼Œå°†å…¶è½¬æ¢ä¸ºé¢„æœŸçš„æ•°æ®ç±»å‹
            if x.dtype != self.np_input_formats[i]:
                x = x.astype(self.np_input_formats[i])
            # åˆ›å»ºä¸€ä¸ªæ¨ç†è¾“å…¥å¯¹è±¡ï¼ŒæŒ‡å®šè¾“å…¥åç§°ã€å½¢çŠ¶å’Œæ•°æ®ç±»å‹
            infer_input = self.InferInput(self.input_names[i], [*x.shape], self.input_formats[i].replace("TYPE_", ""))
            # å°† numpy æ•°ç»„çš„æ•°æ®å¤åˆ¶åˆ°æ¨ç†è¾“å…¥å¯¹è±¡ä¸­
            infer_input.set_data_from_numpy(x)
            # å°†æ¨ç†è¾“å…¥å¯¹è±¡æ·»åŠ åˆ°æ¨ç†è¾“å…¥åˆ—è¡¨ä¸­
            infer_inputs.append(infer_input)

        # æ ¹æ®è¾“å‡ºåç§°åˆ—è¡¨åˆ›å»ºæ¨ç†è¾“å‡ºå¯¹è±¡åˆ—è¡¨
        infer_outputs = [self.InferRequestedOutput(output_name) for output_name in self.output_names]
        # è°ƒç”¨ Triton å®¢æˆ·ç«¯è¿›è¡Œæ¨ç†ï¼Œä¼ å…¥æ¨¡å‹åç§°ã€è¾“å…¥åˆ—è¡¨å’Œè¾“å‡ºåˆ—è¡¨ï¼Œå¹¶è·å–æ¨ç†ç»“æœ
        outputs = self.triton_client.infer(model_name=self.endpoint, inputs=infer_inputs, outputs=infer_outputs)

        # å°†æ¯ä¸ªè¾“å‡ºç»“æœè½¬æ¢å›åŸå§‹è¾“å…¥æ•°æ®ç±»å‹ï¼Œå¹¶å­˜å‚¨åœ¨åˆ—è¡¨ä¸­è¿”å›
        return [outputs.as_numpy(output_name).astype(input_format) for output_name in self.output_names]
```