# `.\yolov8\ultralytics\utils\tuner.py`

```py
# å¯¼å…¥ subprocess æ¨¡å—ï¼Œç”¨äºæ‰§è¡Œå¤–éƒ¨å‘½ä»¤
import subprocess

# ä» ultralytics çš„ cfg æ¨¡å—ä¸­å¯¼å…¥ TASK2DATAã€TASK2METRICã€get_save_dir å‡½æ•°
from ultralytics.cfg import TASK2DATA, TASK2METRIC, get_save_dir
# ä» ultralytics çš„ utils æ¨¡å—ä¸­å¯¼å…¥ DEFAULT_CFGã€DEFAULT_CFG_DICTã€LOGGERã€NUM_THREADSã€checks å‡½æ•°
from ultralytics.utils import DEFAULT_CFG, DEFAULT_CFG_DICT, LOGGER, NUM_THREADS, checks


# å®šä¹‰å‡½æ•° run_ray_tuneï¼Œç”¨äºè¿è¡Œ Ray Tune è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜
def run_ray_tune(
    model, space: dict = None, grace_period: int = 10, gpu_per_trial: int = None, max_samples: int = 10, **train_args
):
    """
    Runs hyperparameter tuning using Ray Tune.

    Args:
        model (YOLO): Model to run the tuner on.
        space (dict, optional): The hyperparameter search space. Defaults to None.
        grace_period (int, optional): The grace period in epochs of the ASHA scheduler. Defaults to 10.
        gpu_per_trial (int, optional): The number of GPUs to allocate per trial. Defaults to None.
        max_samples (int, optional): The maximum number of trials to run. Defaults to 10.
        train_args (dict, optional): Additional arguments to pass to the `train()` method. Defaults to {}.

    Returns:
        (dict): A dictionary containing the results of the hyperparameter search.

    Example:
        ```python
        from ultralytics import YOLO

        # Load a YOLOv8n model
        model = YOLO('yolov8n.pt')

        # Start tuning hyperparameters for YOLOv8n training on the COCO8 dataset
        result_grid = model.tune(data='coco8.yaml', use_ray=True)
        ```
    """

    # åœ¨æ—¥å¿—ä¸­è¾“å‡ºä¸€æ¡ä¿¡æ¯ï¼Œå¼•å¯¼ç”¨æˆ·äº†è§£ RayTune çš„æ–‡æ¡£é“¾æ¥
    LOGGER.info("ğŸ’¡ Learn about RayTune at https://docs.ultralytics.com/integrations/ray-tune")
    
    # å¦‚æœ train_args ä¸º Noneï¼Œåˆ™å°†å…¶è®¾ä¸ºä¸€ä¸ªç©ºå­—å…¸
    if train_args is None:
        train_args = {}

    try:
        # å°è¯•å®‰è£… Ray Tune ç›¸å…³ä¾èµ–
        subprocess.run("pip install ray[tune]".split(), check=True)  # do not add single quotes here

        # å¯¼å…¥å¿…è¦çš„ Ray Tune æ¨¡å—
        import ray
        from ray import tune
        from ray.air import RunConfig
        from ray.air.integrations.wandb import WandbLoggerCallback
        from ray.tune.schedulers import ASHAScheduler
    except ImportError:
        # è‹¥å¯¼å…¥å¤±è´¥ï¼Œåˆ™æŠ›å‡º ModuleNotFoundError å¼‚å¸¸
        raise ModuleNotFoundError('Ray Tune required but not found. To install run: pip install "ray[tune]"')

    try:
        # å°è¯•å¯¼å…¥ wandb æ¨¡å—ï¼Œå¹¶ç¡®ä¿å…¶æœ‰ __version__ å±æ€§
        import wandb
        assert hasattr(wandb, "__version__")
    except (ImportError, AssertionError):
        # è‹¥å¯¼å…¥å¤±è´¥æˆ–ç¼ºå°‘ __version__ å±æ€§ï¼Œåˆ™å°† wandb è®¾ä¸º False
        wandb = False

    # ä½¿ç”¨ checks æ¨¡å—æ£€æŸ¥ ray çš„ç‰ˆæœ¬æ˜¯å¦ç¬¦åˆè¦æ±‚
    checks.check_version(ray.__version__, ">=2.0.0", "ray")
    # é»˜è®¤çš„è¶…å‚æ•°æœç´¢ç©ºé—´ï¼ŒåŒ…å«å„ç§è¶…å‚æ•°çš„å–å€¼èŒƒå›´æˆ–æ¦‚ç‡åˆ†å¸ƒ
    default_space = {
        # 'optimizer': tune.choice(['SGD', 'Adam', 'AdamW', 'NAdam', 'RAdam', 'RMSProp']),
        "lr0": tune.uniform(1e-5, 1e-1),  # åˆå§‹å­¦ä¹ ç‡èŒƒå›´
        "lrf": tune.uniform(0.01, 1.0),  # æœ€ç»ˆOneCycleLRå­¦ä¹ ç‡ (lr0 * lrf)
        "momentum": tune.uniform(0.6, 0.98),  # SGDåŠ¨é‡/Adam beta1
        "weight_decay": tune.uniform(0.0, 0.001),  # ä¼˜åŒ–å™¨æƒé‡è¡°å‡
        "warmup_epochs": tune.uniform(0.0, 5.0),  # é¢„çƒ­ epochs æ•°é‡ï¼ˆå…è®¸å°æ•°ï¼‰
        "warmup_momentum": tune.uniform(0.0, 0.95),  # é¢„çƒ­åˆå§‹åŠ¨é‡
        "box": tune.uniform(0.02, 0.2),  # ç›’æŸå¤±å¢ç›Š
        "cls": tune.uniform(0.2, 4.0),  # åˆ†ç±»æŸå¤±å¢ç›Šï¼ˆä¸åƒç´ ç¼©æ”¾æ¯”ä¾‹ç›¸å…³ï¼‰
        "hsv_h": tune.uniform(0.0, 0.1),  # å›¾åƒHSV-Hueå¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
        "hsv_s": tune.uniform(0.0, 0.9),  # å›¾åƒHSV-Saturationå¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
        "hsv_v": tune.uniform(0.0, 0.9),  # å›¾åƒHSV-Valueå¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
        "degrees": tune.uniform(0.0, 45.0),  # å›¾åƒæ—‹è½¬è§’åº¦èŒƒå›´ï¼ˆ+/- åº¦ï¼‰
        "translate": tune.uniform(0.0, 0.9),  # å›¾åƒå¹³ç§»èŒƒå›´ï¼ˆ+/- æ¯”ä¾‹ï¼‰
        "scale": tune.uniform(0.0, 0.9),  # å›¾åƒç¼©æ”¾èŒƒå›´ï¼ˆ+/- å¢ç›Šï¼‰
        "shear": tune.uniform(0.0, 10.0),  # å›¾åƒå‰ªåˆ‡èŒƒå›´ï¼ˆ+/- åº¦ï¼‰
        "perspective": tune.uniform(0.0, 0.001),  # å›¾åƒé€è§†å˜æ¢èŒƒå›´ï¼ˆ+/- æ¯”ä¾‹ï¼‰ï¼ŒèŒƒå›´ 0-0.001
        "flipud": tune.uniform(0.0, 1.0),  # å›¾åƒä¸Šä¸‹ç¿»è½¬æ¦‚ç‡
        "fliplr": tune.uniform(0.0, 1.0),  # å›¾åƒå·¦å³ç¿»è½¬æ¦‚ç‡
        "bgr": tune.uniform(0.0, 1.0),  # å›¾åƒé€šé“BGRè½¬æ¢æ¦‚ç‡
        "mosaic": tune.uniform(0.0, 1.0),  # å›¾åƒæ··åˆï¼ˆmosaicï¼‰æ¦‚ç‡
        "mixup": tune.uniform(0.0, 1.0),  # å›¾åƒæ··åˆï¼ˆmixupï¼‰æ¦‚ç‡
        "copy_paste": tune.uniform(0.0, 1.0),  # åˆ†å‰²å¤åˆ¶ç²˜è´´æ¦‚ç‡
    }

    # å°†æ¨¡å‹æ”¾å…¥Rayå­˜å‚¨
    task = model.task
    model_in_store = ray.put(model)

    def _tune(config):
        """
        ä½¿ç”¨æŒ‡å®šçš„è¶…å‚æ•°å’Œé¢å¤–çš„å‚æ•°è®­ç»ƒYOLOæ¨¡å‹ã€‚

        Args:
            config (dict): ç”¨äºè®­ç»ƒçš„è¶…å‚æ•°å­—å…¸ã€‚

        Returns:
            dict: è®­ç»ƒç»“æœå­—å…¸ã€‚
        """
        model_to_train = ray.get(model_in_store)  # ä»Rayå­˜å‚¨ä¸­è·å–è¦è°ƒæ•´çš„æ¨¡å‹
        model_to_train.reset_callbacks()  # é‡ç½®å›è°ƒå‡½æ•°
        config.update(train_args)  # æ›´æ–°è®­ç»ƒå‚æ•°
        results = model_to_train.train(**config)  # ä½¿ç”¨ç»™å®šçš„è¶…å‚æ•°è¿›è¡Œè®­ç»ƒ
        return results.results_dict  # è¿”å›è®­ç»ƒç»“æœå­—å…¸

    # è·å–æœç´¢ç©ºé—´
    if not space:
        space = default_space  # å¦‚æœæœªæä¾›æœç´¢ç©ºé—´ï¼Œåˆ™ä½¿ç”¨é»˜è®¤æœç´¢ç©ºé—´
        LOGGER.warning("WARNING âš ï¸ æ²¡æœ‰æä¾›æœç´¢ç©ºé—´ï¼Œä½¿ç”¨é»˜è®¤æœç´¢ç©ºé—´ã€‚")

    # è·å–æ•°æ®é›†
    data = train_args.get("data", TASK2DATA[task])  # è·å–æ•°æ®é›†
    space["data"] = data  # å°†æ•°æ®é›†æ·»åŠ åˆ°æœç´¢ç©ºé—´
    if "data" not in train_args:
        LOGGER.warning(f'WARNING âš ï¸ æ²¡æœ‰æä¾›æ•°æ®é›†ï¼Œä½¿ç”¨é»˜è®¤æ•°æ®é›† "data={data}".')

    # å®šä¹‰å¸¦æœ‰åˆ†é…èµ„æºçš„å¯è®­ç»ƒå‡½æ•°
    trainable_with_resources = tune.with_resources(_tune, {"cpu": NUM_THREADS, "gpu": gpu_per_trial or 0})
    # å®šä¹‰ ASHA è°ƒåº¦å™¨ç”¨äºè¶…å‚æ•°æœç´¢
    asha_scheduler = ASHAScheduler(
        time_attr="epoch",  # æŒ‡å®šæ—¶é—´å±æ€§ä¸º epoch
        metric=TASK2METRIC[task],  # è®¾ç½®ä¼˜åŒ–çš„æŒ‡æ ‡ä¸ºä»»åŠ¡å¯¹åº”çš„æŒ‡æ ‡
        mode="max",  # è®¾å®šä¼˜åŒ–æ¨¡å¼ä¸ºæœ€å¤§åŒ–
        max_t=train_args.get("epochs") or DEFAULT_CFG_DICT["epochs"] or 100,  # è®¾ç½®æœ€å¤§çš„è®­ç»ƒè½®æ•°
        grace_period=grace_period,  # è®¾ç½®ä¼˜é›…æœŸé—´
        reduction_factor=3,  # è®¾ç½®æ”¶æ•›å› å­
    )

    # å®šä¹‰ç”¨äºè¶…å‚æ•°æœç´¢çš„å›è°ƒå‡½æ•°
    tuner_callbacks = [WandbLoggerCallback(project="YOLOv8-tune")] if wandb else []

    # åˆ›å»º Ray Tune çš„è¶…å‚æ•°æœç´¢è°ƒè°å™¨
    tune_dir = get_save_dir(DEFAULT_CFG, name="tune").resolve()  # è·å–ä¿å­˜è°ƒä¼˜ç»“æœçš„ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿ç›®å½•å­˜åœ¨
    tune_dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºä¿å­˜è°ƒä¼˜ç»“æœçš„ç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
    tuner = tune.Tuner(
        trainable_with_resources,  # å¯è®­ç»ƒå‡½æ•°
        param_space=space,  # å‚æ•°ç©ºé—´
        tune_config=tune.TuneConfig(scheduler=asha_scheduler, num_samples=max_samples),  # è°ƒä¼˜é…ç½®
        run_config=RunConfig(callbacks=tuner_callbacks, storage_path=tune_dir),  # è¿è¡Œé…ç½®
    )

    # è¿è¡Œè¶…å‚æ•°æœç´¢
    tuner.fit()

    # è¿”å›è¶…å‚æ•°æœç´¢çš„ç»“æœ
    return tuner.get_results()
```